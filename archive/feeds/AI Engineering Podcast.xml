<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="xslsheet"?>
<rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:podcast="https://podcastindex.org/namespace/1.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <atom:link rel="self" type="application/atom+xml" href="https://serve.podhome.fm/rss/c9abdd38-a5dc-5eb2-96fd-f833f93208a7" title="MP3 Audio" />
    <atom:link rel="hub" href="https://pubsubhubbub.appspot.com/" />
    <podcast:podping usesPodping="true" />
    <podcast:podroll>
      <podcast:remoteItem feedGuid="1c0357c0-6aba-5766-a2d5-2090d8dab6bc" feedUrl="https://feeds.fireside.fm/dataengineering/rss" />
      <podcast:remoteItem feedGuid="0e91aeb8-10b7-54d0-8ded-d832dd2d857b" feedUrl="https://feeds.fireside.fm/pythonpodcast/rss" />
    </podcast:podroll>
    <image>
      <url>https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg</url>
      <title>AI Engineering Podcast</title>
      <link>https://www.aiengineeringpodcast.com</link>
    </image>
    <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
    <podcast:trailer pubdate="Fri, 3 Jun 2022 12:00:00 +0000" url="https://serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538342328863734a1e90-cdeb-4cc8-8d3f-33473c81129e.mp3" length="977060" type="audio/mpeg">Introducing The Show</podcast:trailer>
    <podcast:updateFrequency rrule="FREQ=WEEKLY;INTERVAL=3">Weekly</podcast:updateFrequency>
    <podcast:medium>podcast</podcast:medium>
    <title>AI Engineering Podcast</title>
    <description><![CDATA[This show is your guidebook to building scalable and maintainable AI systems. You will learn how to architect AI applications, apply AI to your work, and the considerations involved in building or customizing new models. Everything that you need to know to deliver real impact and value with machine learning and artificial intelligence.]]></description>
    <link>https://www.aiengineeringpodcast.com</link>
    <language>en</language>
    <copyright><![CDATA[© 2024 Boundless Notions, LLC.]]></copyright>
    <podcast:locked owner="hosts@aiengineeringpodcast.com">no</podcast:locked>
    <podcast:guid>c9abdd38-a5dc-5eb2-96fd-f833f93208a7</podcast:guid>
    <podcast:funding url="https://machinelearning.supercast.com/">Support the show!</podcast:funding>
    <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    <generator>Podhome (https://www.podhome.fm)</generator>
    <managingEditor>hosts@aiengineeringpodcast.com</managingEditor>
    <lastBuildDate>Mon, 23 Jun 2025 19:19:47 +0000</lastBuildDate>
    <pubDate>Mon, 23 Jun 2025 19:19:47 +0000</pubDate>
    <itunes:title>AI Engineering Podcast</itunes:title>
    <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
    <itunes:new-feed-url>https://serve.podhome.fm/rss/c9abdd38-a5dc-5eb2-96fd-f833f93208a7</itunes:new-feed-url>
    <itunes:author>Tobias Macey</itunes:author>
    <itunes:owner>
      <itunes:name>Tobias Macey</itunes:name>
      <itunes:email>hosts@aiengineeringpodcast.com</itunes:email>
    </itunes:owner>
    <itunes:explicit>false</itunes:explicit>
    <itunes:category text="Technology" />
    <itunes:category text="Education" />
    <itunes:type>episodic</itunes:type>
    <item>
      <title>Unlocking AI Potential with AMD's ROCm Stack</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast Anush Elangovan, VP of AI software at AMD, discusses the strategic integration of software and hardware at AMD. He emphasizes the open-source nature of their software, fostering innovation and collaboration in the AI ecosystem, and highlights AMD's performance and capability advantages over competitors like NVIDIA. Anush addresses challenges and opportunities in AI development, including quantization, model efficiency, and future deployment across various platforms, while also stressing the importance of open standards and flexible solutions that support efficient CPU-GPU communication and diverse AI workloads.<br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Anush Elangovan about AMD's work to expand the playing field for AI training and inference</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what your work at AMD is focused on?</li><li>A lot of the current attention on hardware for AI training and inference is focused on the raw GPU hardware. What is the role of the software stack in enabling and differentiating that underlying compute?</li><li>CUDA has gained a significant amount of attention and adoption in the numeric computation space (AI, ML, scientific computing, etc.). What are the elements of platform risk associated with relying on CUDA as a developer or organization?</li><li>The ROCm stack is the key element in AMD's AI and HPC strategy. What are the elements that comprise that ecosystem?<ul><li>What are the incentives for anyone outside of AMD to contribute to the ROCm project?</li></ul></li><li>How would you characterize the current competitive landscape for AMD across the AI/ML lifecycle stages? (pre-training, post-training, inference, fine-tuning)</li><li>For teams who are focused on inference compute for model serving, what do they need to know/care about in regards to AMD hardware and the ROCm stack?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen AMD/ROCm used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on AMD's AI software ecosystem?</li><li>When is AMD/ROCm the wrong choice?</li><li>What do you have planned for the future of ROCm?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/anushelangovan/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.image-net.org/" target="_blank">ImageNet</a></li><li><a href="https://www.amd.com/en.html" target="_blank">AMD</a></li><li><a href="https://github.com/ROCm/" target="_blank">ROCm</a></li><li><a href="https://en.wikipedia.org/wiki/CUDA" target="_blank">CUDA</a></li><li><a href="https://huggingface.co/" target="_blank">HuggingFace</a></li><li><a href="https://www.llama.com/models/llama-3/" target="_blank">Llama 3</a></li><li><a href="https://www.llama.com/models/llama-4/" target="_blank">Llama 4</a></li><li><a href="https://huggingface.co/Qwen" target="_blank">Qwen</a></li><li><a href="https://huggingface.co/deepseek-ai/DeepSeek-R1" target="_blank">DeepSeek R1</a></li><li><a href="https://www.amd.com/en/products/accelerators/instinct/mi300/mi300x.html" target="_blank">MI300X</a></li><li><a href="https://en.wikipedia.org/wiki/Symbian" target="_blank">Nokia Symbian</a></li><li><a href="https://en.wikipedia.org/wiki/UALink" target="_blank">UALink Standard</a></li><li><a href="https://huggingface.co/docs/optimum/en/concept_guides/quantization" target="_blank">Quantization</a></li><li><a href="https://github.com/ROCm/HIPIFY" target="_blank">HIPIFY</a></li><li><a href="https://github.com/ROCm/triton" target="_blank">ROCm Triton</a></li><li><a href="https://www.amd.com/en/products/processors/consumer/ryzen-ai.html" target="_blank">AMD Strix Halo</a></li><li><a href="https://www.amd.com/en/products/processors/server/epyc.html" target="_blank">AMD Epyc</a></li><li><a href="https://www.liquid.ai/research/liquid-neural-networks-research" target="_blank">Liquid Networks</a></li><li><a href="https://en.wikipedia.org/wiki/Mamba_(deep_learning_architecture)" target="_blank">MAMBA Architecture</a></li><li><a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)" target="_blank">Transformer Architecture</a></li><li><a href="https://en.wikipedia.org/wiki/Neural_processing_unit" target="_blank">NPU == Neural Processing Unit</a></li><li><a href="https://github.com/ggml-org/llama.cpp" target="_blank">llama.cpp</a></li><li><a href="https://ollama.com/" target="_blank">Ollama</a></li><li><a href="https://en.wikipedia.org/wiki/Perplexity" target="_blank">Perplexity Score</a></li><li><a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access" target="_blank">NUMA == Non-Uniform Memory Access</a></li><li><a href="https://github.com/vllm-project/" target="_blank">vLLM</a></li><li><a href="https://docs.sglang.ai/" target="_blank">SGLang</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">9f1410e3-4278-4244-91e6-93231214fd31</guid>
      <link>https://www.aiengineeringpodcast.com/amd-rocm-training-and-inference-episode-54</link>
      <pubDate>Mon, 23 Jun 2025 19:19:44 +0000</pubDate>
      <podcast:soundbite startTime="1466.87" duration="49.78">And then the other potential target for an end user is for people who wanna be able to do their own local inference on a laptop using these open models, and they wanna be able to do it reasonably, affordably without having to run their own power plant to be able to power the cards. And I'm wondering how you're thinking about that consumer grade aspect of AI and the ways that people are able to run them on their local laptops, on their desktop machines, or on edge compute for being able to bring this into more of a personalized mode without having to necessarily be a AI researcher and understand all of the things that they need to know to be able to quantize the models and fine tune them to be able to run effectively on the silicon that they have and whatever device they might have ready to hand?</podcast:soundbite>
      <podcast:soundbite startTime="182.86" duration="27.66">And and more importantly, it moves the industry forward with respect to, you know, the ecosystem it enables because AMD provides a very open environment for collaboration. And all our source code and software is open source, which allows for, innovation to go at the pace at which the people using our practitioners want to. Right? That is not, limited by the, the ability of what we we put out in closed source form.</podcast:soundbite>
      <podcast:soundbite startTime="654.32" duration="27.66">The way I would look at quantization is it almost gets to an art form because you have so many hyperparameters to tweak. Right? But you want to be able to preserve the quality of service of, like, you know, is your model outputting the same, thing? And and and some of it gets very subjective. Right? Like, I I've personally seen deployments where the customer is like, as long as the end user doesn't notice what's going on, you're good. You can quantize it. Right?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:42:18</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Unlocking AI Potential with AMD's ROCm Stack</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>54</itunes:episode>
      <podcast:episode>54</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6388628845029162589f1410e3-4278-4244-91e6-93231214fd31v1.mp3" length="40609849" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6388628845029162589f1410e3-4278-4244-91e6-93231214fd31v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_9f1410e3-4278-4244-91e6-93231214fd31638863031760206030.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/9f1410e3-4278-4244-91e6-93231214fd31638863031753792005.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/9f1410e3-4278-4244-91e6-93231214fd31638863031747570442.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/anushelangovan/">Anush Elangovan</podcast:person>
    </item>
    <item>
      <title>Applying AI To The Construction Industry At Buildots</title>
      <description><![CDATA[Summary<br />In this episode of the Machine Learning Podcast Ori Silberberg, VP of Engineering at Buildots, talks about transforming the construction industry with AI. Ori shares how Buildots uses computer vision and AI to optimize construction projects by providing real-time feedback, reducing delays, and improving efficiency. Learn about the complexities of digitizing the construction industry, the technical architecture of Buildoz, and how its AI-driven solutions create a digital twin of construction sites. Ori emphasizes the importance of explainability and actionable insights in AI decision-making, highlighting the potential of generative AI to further enhance the construction process from planning to execution.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Ori Silberberg about applications of AI for optimizing building construction</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Buildotds is and the story behind it?</li><li>What types of construction projects are you focused on? (e.g. residential, commercial, industrial, etc.)</li><li>What are the main types of inefficiencies that typically occur on those types of job sites?<ul><li>What are the manual and technical processes that the industry has typically relied on to address those sources of waste and delay?</li></ul></li><li>In many ways the construction industry is as old as civilization. What are the main ways that the information age has transformed construction?<ul><li>What are the elements of the construction industry that make it resistant to digital transformation?</li></ul></li><li>Can you describe how you are applying AI to this complex and messy problem?</li><li>What are the types of data that you are able to collect?<ul><li>How are you automating that data collection so that construction crews don't have to add extra work or distractions to their day?</li></ul></li><li>For construction crews that are using Buildots, can you talk through how it integrates into the overall process from site planning to project completion?</li><li>Can you describe the technical architecture of the Buildots platform?</li><li>Given the safety critical nature of construction, how does that influence the way that you think about the types of AI models that you use and where to apply them?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Buildots used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Buildots?</li><li>What do you have planned for the future of AI usage at Buildots?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/ori-silberberg/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://buildots.com/" target="_blank">Buildots</a></li><li><a href="https://en.wikipedia.org/wiki/Computer-aided_design" target="_blank">CAD == Computer Aided Design</a></li><li><a href="https://en.wikipedia.org/wiki/Computer_vision" target="_blank">Computer Vision</a></li><li><a href="https://en.wikipedia.org/wiki/Lidar" target="_blank">LIDAR</a></li><li><a href="https://en.wikipedia.org/wiki/General_contractor" target="_blank">GC == General Contractor</a></li><li><a href="https://kubernetes.io/" target="_blank">Kubernetes</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">396472ae-7247-4c2e-8806-9fdea9ce82a3</guid>
      <link>https://www.aiengineeringpodcast.com/buildots-ai-for-construction-episode-53</link>
      <pubDate>Sat, 14 Jun 2025 00:56:10 +0000</pubDate>
      <podcast:soundbite startTime="167.61" duration="24.72">Yeah. Honestly. So the construction industry is huge, depending on how you measure it, but it's, like, one of the biggest industries, in the world. And then the, you know, like, the estimates are talking about, like, 13,000,000,000,000, of an industry of an industry. Sorry. And it is believed to have about $1,000,000,000,000 caught $1,000,000,000,000 of loss caused by delays in this industry.</podcast:soundbite>
      <podcast:soundbite startTime="391.45" duration="29.67">At it seems like everything is very because, like, you know, no project is anytime similar to another project that we've already did. And even for the construction experts that we work with, every project is special, and every problem and inefficiency sounds special and unique, at glance. But then once you have the perspective that Buildlets now has, which is we see so many projects. We see hundreds of projects of all types. You see that the inefficiencies just boil down to additive issues.</podcast:soundbite>
      <podcast:soundbite startTime="1513.26" duration="28.71">Okay. So I'll do my best to find that without needing, like, a football field sized whiteboard behind me. Okay. So I'll look at what our technology is doing as, like, generating data, generating, more data that is getting more enriched and more complex the more you continue and and, like, getting away from the source, which are the three d models and the videos. So we create a detailed digital twin, a digital representation of the construction site in our database.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:49:29</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Applying AI To The Construction Industry At Buildots</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>53</itunes:episode>
      <podcast:episode>53</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638854588781000524396472ae-7247-4c2e-8806-9fdea9ce82a3v1.mp3" length="47513507" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638854588781000524396472ae-7247-4c2e-8806-9fdea9ce82a3v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_396472ae-7247-4c2e-8806-9fdea9ce82a3638854593557307694.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/396472ae-7247-4c2e-8806-9fdea9ce82a3638854593550583112.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/396472ae-7247-4c2e-8806-9fdea9ce82a3638854593545019993.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/ori-silberberg/">Ori Silberberg</podcast:person>
    </item>
    <item>
      <title>The Future of AI Systems: Open Models and Infrastructure Challenges</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Jamie De Guerre, founding SVP of product at Together.ai, explores the role of open models in the AI economy. As a veteran of the AI industry, including his time leading product marketing for AI and machine learning at Apple, Jamie shares insights on the challenges and opportunities of operating open models at speed and scale. He delves into the importance of open source in AI, the evolution of the open model ecosystem, and how Together.ai's AI acceleration cloud is contributing to this movement with a focus on performance and efficiency.<br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Jamie de Guerre about the role of open models in the AI economy and how to operate them at speed and at scale</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Together AI is and the story behind it?<ul><li>What are the key goals of the company?</li></ul></li><li>The initial rounds of open models were largely driven by massive tech companies. How would you characterize the current state of the ecosystem that is driving the creation and evolution of open models?</li><li>There was also a lot of argument about what "open source" and "open" means in the context of ML/AI models, and the different variations of licenses being attached to them (e.g. the Meta license for Llama models). What is the current state of the language used and understanding of the restrictions/freedoms afforded?</li><li>What are the phases of organizational/technical evolution from initial use of open models through fine-tuning, to custom model development?</li><li>Can you outline the technical challenges companies face when trying to train or run inference on large open models themselves?<ul><li>What factors should a company consider when deciding whether to fine-tune an existing open model versus attempting to train a specialized one from scratch?</li></ul></li><li>While Transformers dominate the LLM landscape, there's ongoing research into alternative architectures. Are you seeing significant interest or adoption of non-Transformer architectures for specific use cases?&nbsp;<ul><li>When might those other architectures be a better choice?</li></ul></li><li>While open models offer tremendous advantages like transparency, control, and cost-effectiveness, are there scenarios where relying solely on them might be disadvantageous?<ul><li>When might proprietary models or a hybrid approach still be the better choice for a specific problem?</li></ul></li><li>Building and scaling AI infrastructure is notoriously complex. What are the most significant technical or strategic challenges you've encountered at Together AI while enabling scalable access to open models for your users?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen open models/the TogetherAI platform used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on powering AI model training and inference?</li><li>Where do you see the open model space heading in the next 1-2 years? Any specific trends or breakthroughs you anticipate?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/jamiedeguerre/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.together.ai/" target="_blank">Together AI</a></li><li><a href="https://www.datacamp.com/tutorial/fine-tuning-large-language-models" target="_blank">Fine Tuning</a></li><li><a href="https://towardsdatascience.com/how-llms-work-pre-training-to-post-training-neural-networks-hallucinations-and-inference/" target="_blank">Post-Training</a></li><li><a href="https://www.salesforceairesearch.com/" target="_blank">Salesforce Research</a></li><li><a href="https://mistral.ai/" target="_blank">Mistral</a></li><li><a href="https://www.salesforce.com/agentforce/" target="_blank">Agentforce</a></li><li><a href="https://www.llama.com/" target="_blank">Llama Models</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank">RLHF == Reinforcement Learning from Human Feedback</a></li><li><a href="https://www.theainavigator.com/blog/what-is-reinforcement-learning-with-verifiable-rewards-rlvr" target="_blank">RLVR == Reinforcement Learning from Verifiable Rewards</a></li><li><a href="https://huggingface.co/blog/Kseniase/testtimecompute" target="_blank">Test Time Compute</a></li><li><a href="https://huggingface.co/" target="_blank">HuggingFace</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://deepmind.google/models/gemma/" target="_blank">Google Gemma</a></li><li><a href="https://www.llama.com/models/llama-4/" target="_blank">Llama 4 Maverick</a></li><li><a href="https://en.wikipedia.org/wiki/Prompt_engineering" target="_blank">Prompt Engineering</a></li><li><a href="https://github.com/vllm-project/vllm" target="_blank">vLLM</a></li><li><a href="https://docs.sglang.ai/" target="_blank">SGLang</a></li><li><a href="https://hazyresearch.stanford.edu/" target="_blank">Hazy Research</a> lab</li><li><a href="https://huggingface.co/blog/lbourdois/get-on-the-ssm-train" target="_blank">State Space Models</a></li><li><a href="https://hazyresearch.stanford.edu/blog/2023-03-07-hyena" target="_blank">Hyena Model</a></li><li><a href="https://en.wikipedia.org/wiki/Mamba_(deep_learning_architecture)" target="_blank">Mamba Architecture</a></li><li><a href="https://en.wikipedia.org/wiki/Diffusion_model" target="_blank">Diffusion Model Architecture</a></li><li><a href="https://en.wikipedia.org/wiki/Stable_Diffusion" target="_blank">Stable Diffusion</a></li><li><a href="https://bfl.ai/models/flux-kontext" target="_blank">Black Forest Labs Flux Model</a></li><li><a href="https://bfl.ai/models/flux-kontext" target="_blank">Nvidia Blackwell</a></li><li><a href="https://pytorch.org/" target="_blank">PyTorch</a></li><li><a href="https://www.rust-lang.org/" target="_blank">Rust</a></li><li><a href="https://huggingface.co/deepseek-ai/DeepSeek-R1" target="_blank">Deepseek R1</a></li><li><a href="https://huggingface.co/docs/hub/en/gguf" target="_blank">GGUF</a></li><li><a href="https://pikalabsai.org/" target="_blank">Pika Text To Video</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">f397f121-5ba8-484c-ba6e-dfc090f9fac2</guid>
      <link>https://www.aiengineeringpodcast.com/togetherai-open-model-ecosystem-episode-52</link>
      <pubDate>Sun, 1 Jun 2025 22:44:51 +0000</pubDate>
      <podcast:soundbite startTime="522.36" duration="24.57">You know, I think what is so fascinating about what's happening today in the AI industry is there's innovation at many different levels. And traditionally, like, the way we thought about things, the the the way that the messaging came out of these big labs was that all of the value of creating this intelligence came from massive pre pre training.</podcast:soundbite>
      <podcast:soundbite startTime="248.87" duration="16.11">And we have a very deep research heritage in our founding, and we found that a lot of the AI community was really exacerbated with the fact that there was finally massive improvement happening in the quality of AI models, but suddenly it was being done in a closed way.</podcast:soundbite>
      <podcast:soundbite startTime="2162.47" duration="10.42">And I think that that is the, you know, the rest of the iceberg that's under the water that makes it so much more challenging than you would expect when you kinda go in eyes open thinking about the expected challenges.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:51:01</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Future of AI Systems: Open Models and Infrastructure Challenges</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>52</itunes:episode>
      <podcast:episode>52</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638844133769997215f397f121-5ba8-484c-ba6e-dfc090f9fac2v1.mp3" length="48983410" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638844133769997215f397f121-5ba8-484c-ba6e-dfc090f9fac2v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_f397f121-5ba8-484c-ba6e-dfc090f9fac2638844146343895809.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/f397f121-5ba8-484c-ba6e-dfc090f9fac2638844146339725138.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/f397f121-5ba8-484c-ba6e-dfc090f9fac2638844146335435010.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/jamiedeguerre/">Jamie De Guerre</podcast:person>
    </item>
    <item>
      <title>The Rise of Agentic AI: Transforming Business Operations</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast, host Tobias Macey sits down with Ben Wilde, Head of Innovation at Georgian, to explore the transformative impact of agentic AI on business operations and the SaaS industry. From his early days working with vintage AI systems to his current focus on product strategy and innovation in AI, Ben shares his expertise on what he calls the "continuum" of agentic AI - from simple function calls to complex autonomous systems. Join them as they discuss the challenges and opportunities of integrating agentic AI into business systems, including organizational alignment, technical competence, and the need for standardization. They also dive into emerging protocols and the evolving landscape of AI-driven products and services, including usage-based pricing models and advancements in AI infrastructure and reliability.<br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Ben Wilde about the impact of agentic AI on business operations and SaaS as we know it</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by sharing your definition of what constitutes "agentic AI"?</li><li>There have been several generations of automation for business and product use cases. In your estimation, what are the substantive differences between agentic AI and e.g. RPA (Robotic Process Automation)?<ul><li>How do the inherent risks and operational overhead impact the calculus of whether and where to apply agentic capabilities?</li></ul></li><li>For teams that are aiming for agentic capabilities, what are the stepping stones along that path?</li><li>Beyond the technical capacity, there are numerous elements of organizational alignment that are required to make full use of the capabilities of agentic processes. What are some of the strategic investments that are necessary to get the whole business pointed in the same direction for adopting and benefitting from AI agents?</li><li>The most recent splash in the space of agentic AI is the introduction of the Model Context Protocol, and various responses to it. What do you see as the near and medium term impact of this effort on the ecosystem of AI agents and their architecture?</li><li>Software products have gone through several major evolutions since the days of CD-ROMs in the 90s. The current era has largely been oriented around the model of subscription-based software delivered via browser or mobile-based UIs over the internet. How does the pending age of AI agents upend that model?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen agentic AI used for business and product capabilities?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working with businesses adopting agentic AI capabilities?</li><li>When is agentic AI the wrong choice?</li><li>What are the ongoing developments in agentic capabilities that you are monitoring?</li></ul>Contact Info<br /><ul><li>Email</li><li><a href="https://www.linkedin.com/in/benrwilde/?originalSubdomain=ca" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://georgian.io/" target="_blank">Georgian</a></li><li><a href="https://georgian.io/agentic-platforms-and-applications/" target="_blank">Agentic Platforms And Applications</a></li><li><a href="https://en.wikipedia.org/wiki/Differential_privacy" target="_blank">Differential Privacy</a></li><li><a href="https://en.wikipedia.org/wiki/Agentic_AI" target="_blank">Agentic AI</a></li><li><a href="https://en.wikipedia.org/wiki/Language_model" target="_blank">Language Model</a></li><li><a href="https://en.wikipedia.org/wiki/Reasoning_language_model" target="_blank">Reasoning Model</a></li><li><a href="https://en.wikipedia.org/wiki/Robotic_process_automation" target="_blank">Robotic Process Automation</a></li><li><a href="https://ofac.treasury.gov/" target="_blank">OFAC</a></li><li><a href="https://openai.com/index/introducing-deep-research/" target="_blank">OpenAI Deep Research</a></li><li><a href="https://modelcontextprotocol.io/introduction" target="_blank">Model Context Protocol</a></li><li><a href="https://georgian.io/agentic-ai-adoption-insights-from-600-executives/" target="_blank">Georgian AI Adoption Survey</a></li><li><a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/" target="_blank">Google Agent to Agent Protocol</a></li><li><a href="https://graphql.org/" target="_blank">GraphQL</a></li><li><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" target="_blank">TPU == Tensor Processing Unit</a></li><li><a href="https://en.wikipedia.org/wiki/Chris_Lattner" target="_blank">Chris Lattner</a></li><li><a href="https://en.wikipedia.org/wiki/CUDA" target="_blank">CUDA</a></li><li><a href="https://en.wikipedia.org/wiki/Neuro-symbolic_AI" target="_blank">NeuroSymbolic AI</a></li><li><a href="https://en.wikipedia.org/wiki/Prolog" target="_blank">Prolog</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">e62eb282-801c-4c31-b45c-bb4a43185cbf</guid>
      <link>https://www.aiengineeringpodcast.com/agentic-ai-business-impact-episode-51</link>
      <pubDate>Wed, 21 May 2025 00:52:31 +0000</pubDate>
      <podcast:soundbite startTime="2055.28" duration="16.21">Yeah. I mean, it's a great question. It's it's a a debate that was kicked off back in December in earnest by Mandela from Microsoft saying that, you know, SaaS is dead. And I certainly don't subscribe to that perspective. What I do think is happening is a couple of things.</podcast:soundbite>
      <podcast:soundbite startTime="289.17" duration="27.49">I think the first thing I would say is my perspective, in my view, agentic AI is a pretty big tent. So I would view Agentic AI as a continuum that could include all those things. So, you know, you talked about the simple function call, you know, treating a language model or a large reasoning model as a as a function. You know, there can be reasoning and some level of weak agency that happens even within that function call. Right?</podcast:soundbite>
      <podcast:soundbite startTime="768.60" duration="25.04">Yeah. I I think it's a really good question, and it's going to be an ongoing thing for a while. So my worldview on this is that we're quite a way away from having systems that are reliable enough to not have humans in the loop for much of how we use these, technologies. And so and specifically, I'm talking about, you know, language models and reasoning models.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:01:57</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Rise of Agentic AI: Transforming Business Operations</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>51</itunes:episode>
      <podcast:episode>51</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638833852069853299e62eb282-801c-4c31-b45c-bb4a43185cbfv1.mp3" length="59490824" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638833852069853299e62eb282-801c-4c31-b45c-bb4a43185cbfv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_e62eb282-801c-4c31-b45c-bb4a43185cbf638833854916902418.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/e62eb282-801c-4c31-b45c-bb4a43185cbf638833854913714634.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/e62eb282-801c-4c31-b45c-bb4a43185cbf638833854909457794.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/benrwilde/?originalSubdomain=ca">Ben Wilde</podcast:person>
    </item>
    <item>
      <title>Protecting AI Systems: Understanding Vulnerabilities and Attack Surfaces</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Kasimir Schulz, Director of Security Research at HiddenLayer, talks about the complexities and security challenges in AI and machine learning models. Kasimir explains the concept of shadow genes and shadow logic, which involve identifying common subgraphs within neural networks to understand model ancestry and potential vulnerabilities, and emphasizes the importance of understanding the attack surface in AI integrations, scanning models for security threats, and evolving awareness in AI security practices to mitigate risks in deploying AI systems.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Kasimir Schulz about the relationships between the various models on the market and how that information helps with selecting and protecting models for your applications</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by outlining the current state of the threat landscape for ML and AI systems?</li><li>What are the main areas of overlap in risk profiles between prediction/classification and generative models? (primarily from an attack surface/methodology perspective)<ul><li>What are the significant points of divergence?</li></ul></li><li>What are some of the categories of potential damages that can be created through the deployment of compromised models?</li><li>How does the landscape of foundation models introduce new challenges around supply chain security for organizations building with AI?</li><li>You recently published your findings on the potential to inject subgraphs into model architectures that are invisible during normal operation of the model. Along with that you wrote about the subgraphs that are shared between different classes of models. What are the key learnings that you would like to highlight from that research?<ul><li>What action items can organizations and engineering teams take in light of that information?</li></ul></li><li>Platforms like HuggingFace offer numerous variations of popular models with variations around quantization, various levels of finetuning, model distillation, etc. That is obviously a benefit to knowledge sharing and ease of access, but how does that exacerbate the potential threat in the face of backdoored models?</li><li>Beyond explicit backdoors in model architectures, there are numerous attack vectors to generative models in the form of prompt injection, "jailbreaking" of system prompts, etc. How does the knowledge of model ancestry help with identifying and mitigating risks from that class of threat?<ul><li>A common response to that threat is the introduction of model guardrails with pre- and post-filtering of prompts and responses. How can that approach help to address the potential threat of backdoored models as well?</li></ul></li><li>For a malicious actor that develops one of these attacks, what is the vector for introducing the compromised model into an organization?<ul><li>Once that model is in use, what are the possible means by which the malicious actor can detect its presence for purposes of exploitation?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen the information about model ancestry used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on ShadowLogic/ShadowGenes?</li><li>What are some of the other means by which the operation of ML and AI systems introduce attack vectors to organizations running them?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/kasimir-schulz/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://hiddenlayer.com/" target="_blank">HiddenLayer</a></li><li><a href="https://en.wikipedia.org/wiki/Zero-day_vulnerability" target="_blank">Zero-Day Vulnerability</a></li><li><a href="https://hiddenlayer.com/innovation-hub/mcp-model-context-pitfalls-in-an-agentic-world/" target="_blank">MCP Blog Post</a></li><li><a href="https://docs.python.org/3/library/pickle.html" target="_blank">Python Pickle Object Serialization</a></li><li><a href="https://huggingface.co/docs/safetensors/en/index" target="_blank">SafeTensors</a></li><li><a href="https://en.wikipedia.org/wiki/DeepSeek" target="_blank">Deepseek</a></li><li><a href="https://huggingface.co/docs/transformers/en/index" target="_blank">Huggingface Transformers</a></li><li><a href="https://arxiv.org/pdf/2406.11880" target="_blank">KROP == Knowledge Return Oriented Prompting</a></li><li><a href="https://xkcd.com/327" target="_blank">XKCD "Little Bobby Tables"</a></li><li><a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank">OWASP Top 10 For LLMs</a></li><li><a href="https://www.cve.org/Media/News/item/news/2024/10/15/New-CVE-Artificial-Intelligence-Working-Group" target="_blank">CVE AI Systems Working Group</a></li><li><a href="https://kaushiksp.medium.com/refusal-vector-ablation-in-llms-35aa646ff4a9" target="_blank">Refusal Vector Ablation</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_model" target="_blank">Foundation Model</a></li><li><a href="https://hiddenlayer.com/innovation-hub/shadowlogic/" target="_blank">ShadowLogic</a></li><li><a href="https://hiddenlayer.com/innovation-hub/shadowgenes-uncovering-model-genealogy/" target="_blank">ShadowGenes</a></li><li><a href="https://en.wikipedia.org/wiki/Bytecode" target="_blank">Bytecode</a></li><li><a href="https://en.wikipedia.org/wiki/Residual_neural_network" target="_blank">ResNet == Resideual Neural Network</a></li><li><a href="https://en.wikipedia.org/wiki/You_Only_Look_Once" target="_blank">YOLO == You Only Look Once</a></li><li><a href="https://netron.app/" target="_blank">Netron</a></li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" target="_blank">BERT</a></li><li><a href="https://huggingface.co/docs/transformers/en/model_doc/roberta" target="_blank">RoBERTA</a></li><li><a href="https://www.shodan.io/" target="_blank">Shodan</a></li><li><a href="https://en.wikipedia.org/wiki/Capture_the_flag_(cybersecurity)" target="_blank">CTF == Capture The Flag</a></li><li><a href="https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-v2-is-now-available-in-amazon-bedrock/" target="_blank">Titan Bedrock Image Generator</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">012350a4-d95b-4694-aeb8-f267bc35ff38</guid>
      <link>https://www.aiengineeringpodcast.com/hiddenlayer-shadow-logic-shadow-genes-ai-security-episode-50</link>
      <pubDate>Sat, 3 May 2025 22:32:44 +0000</pubDate>
      <podcast:soundbite startTime="515.92" duration="51.35">Yeah. So it's actually funny enough. The overlap is a lot bigger than you would think for the just types of attacks that you can do. What's really kind of the main attack that you can do and the main vulnerability of these types of models is that in most applications, the entire input that goes into the model is completely user controlled. And what that means is, you know, with software, you might have an API endpoint, and you can query just part of that API endpoint. But all of the data, everything else is controlled by a server, is controlled by access management. But with a model, every single thing that is processed in that model most likely came from the user, except for, like, you know, the little cases with, a system prompt, for example, that might come from the system. But the main chunk of it is from that user. And then the goal for attacking both is the same as well, and that's controlling the output.</podcast:soundbite>
      <podcast:soundbite startTime="76.23" duration="41.49">It's definitely a very important area of research even before the current epoch of all of the generative AI systems just because of the fact that there is so much potential for issues and attacks because of the probabilistic nature of the software where you can't just run a static analyzer and say, oh, that's where the problem is. That's what I need to patch. You have to worry about so much of the overall process that goes into building these models and then operating them and maintaining them because it's not just a single application or a single process that you need to worry about. It's all of the data that goes into it, all of the code that goes into building it, and all of the process around actually keeping it secure in in its actual runtime.</podcast:soundbite>
      <podcast:soundbite startTime="1047.52" duration="47.51">Yeah. The other interesting shift in terms of the AI landscape that was brought in by the rise of generative models is the widespread use now of foundation models as a building block for systems that are being put into production and the fact that most of those foundation models are originating from a small handful of organizations and companies. And I'm wondering what you see as the level of risk both in terms of platform risk from a organizational perspective, but more specifically, security risk of these foundation models being distributed through systems such as Hugging Face and the fact that so many organizations are relying on a small pool of models to then go and build a wide breadth of services on top of?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:51:49</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Protecting AI Systems: Understanding Vulnerabilities and Attack Surfaces</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>50</itunes:episode>
      <podcast:episode>50</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638818928977984630012350a4-d95b-4694-aeb8-f267bc35ff38v1.mp3" length="49759625" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638818928977984630012350a4-d95b-4694-aeb8-f267bc35ff38v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_012350a4-d95b-4694-aeb8-f267bc35ff38638819082139986425.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/012350a4-d95b-4694-aeb8-f267bc35ff38638819082137981460.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/012350a4-d95b-4694-aeb8-f267bc35ff38638819082136077237.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Understanding The Operational And Organizational Challenges Of Agentic AI</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast Julian LaNeve, CTO of Astronomer, talks about transitioning from simple LLM applications to more complex agentic AI systems. Julian shares insights into the challenges and considerations of this evolution, emphasizing the importance of starting with simpler applications to build operational knowledge and intuition. He discusses the parallels between microservices and agentic AI, highlighting the need for careful orchestration and observability to manage complexity and ensure reliability, and explores the technical requirements for deploying AI systems, including data infrastructure, orchestration tools like Apache Airflow, and understanding the probabilistic nature of AI models.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Seamless data integration into AI applications often falls short, leading many to adopt RAG methods, which come with high costs, complexity, and limited scalability. Cognee offers a better solution with its open-source semantic memory engine that automates data ingestion and storage, creating dynamic knowledge graphs from your data. Cognee enables AI agents to understand the meaning of your data, resulting in accurate responses at a lower cost. Take full control of your data in LLM apps without unnecessary overhead. Visit <a href="https://www.aiengineeringpodcast.com/cognee" target="_blank">aiengineeringpodcast.com/cognee</a> to learn more and elevate your AI apps and agents.</li><li>Your host is Tobias Macey and today I'm interviewing Julian LaNeve about how to avoid putting the cart before the horse with AI applications. When do you move from "simple" LLM apps to agentic AI and what's the path to get there?</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>How do you technically distinguish "agentic AI" (e.g., involving planning, tool use, memory) from "simpler LLM workflows" (e.g., stateless transformations, RAG)? What are the key differences in operational complexity and potential failure modes?</li><li>What specific technical challenges (e.g., state management, observability, non-determinism, prompt fragility, cost explosion) are often underestimated when teams jump directly into building stateful, autonomous agents?</li><li>What are the pre-requisites from a data and infrastructure perspective before going to production with agentic applications?<ul><li>How does that differ from the chat-based systems that companies might be experimenting with?</li></ul></li><li>Technically, where do you most often see ambitious agent projects break down during development or early deployment?</li><li>Beyond generic data quality, what specific data engineering practices become critical when building reliable LLM applications? (e.g., Designing data pipelines for efficient RAG chunking/embedding, versioning prompts alongside data, caching strategies for LLM calls, managing vector database ETL).</li><li>From an implementation complexity standpoint, what characterizes tasks well-suited for initial LLM workflow adoption versus those genuinely requiring agentic capabilities?<ul><li>Can you share examples (anonymized if necessary) highlighting how organizations successfully engineered these simpler LLM workflows? What specific technical designs, tooling choices, or MLOps practices were key to their reliability and scalability?</li></ul></li><li>What are some hard-won technical or operational lessons from deploying and scaling LLM workflows in production environments? Any surprising performance bottlenecks, cost issues, or monitoring challenges engineers should anticipate?</li><li>What technical maturity signals (e.g., robust CI/CD for ML, established monitoring/alerting for pipelines, automated evaluation frameworks, cost tracking mechanisms) suggest an engineering team might be ready to tackle the challenges of building and operating agentic systems?</li><li>How does the technical stack and engineering process need to evolve when moving from orchestrated LLM workflows towards more complex agents involving memory, planning, and dynamic tool use? What new components and failure modes must be engineered for?</li><li>How do you foresee orchestration platforms evolving to better serve the needs of AI engineers building LLM apps?&nbsp;</li><li>What are the most interesting, innovative, or unexpected ways that you have seen organizations build toward advanced AI use cases?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on supporting AI services?</li><li>When is AI the wrong choice?</li><li>What is the single most critical piece of engineering advice you would give to fellow AI engineers who are tasked with integrating LLMs into production systems right now?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/julianlaneve" target="_blank">LinkedIn</a></li><li><a href="https://github.com/jlaneve" target="_blank">GitHub</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Links<br /><ul><li><a href="https://www.astronomer.io/" target="_blank">Astronomer</a></li><li><a href="https://airflow.apache.org/" target="_blank">Airflow</a></li><li><a href="https://www.anthropic.com/" target="_blank">Anthropic</a></li><li><a href="https://www.anthropic.com/engineering/building-effective-agents" target="_blank">Building Effective Agents</a> post from Anthropic</li><li><a href="https://www.astronomer.io/airflow/3-0/" target="_blank">Airflow 3.0</a></li><li><a href="https://microservices.io/" target="_blank">Microservices</a></li><li><a href="https://github.com/pydantic/pydantic-ai" target="_blank">Pydantic AI</a></li><li><a href="https://www.langchain.com/" target="_blank">Langchain</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">LlamaIndex</a></li><li><a href="https://leehanchung.github.io/blogs/2024/08/11/llm-as-a-judge/" target="_blank">LLM As A Judge</a></li><li><a href="https://www.swebench.com/" target="_blank">SWE (SoftWare Engineer) Bench</a></li><li><a href="https://www.cursor.com/" target="_blank">Cursor</a></li><li><a href="https://windsurf.com/editor" target="_blank">Windsurf</a></li><li><a href="https://opentelemetry.io/" target="_blank">OpenTelemetry</a></li><li><a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" target="_blank">DAG == Directed Acyclic Graph</a></li><li><a href="https://en.wikipedia.org/wiki/Halting_problem" target="_blank">Halting Problem</a></li><li><a href="https://arxiv.org/html/2410.15665v1" target="_blank">AI Long Term Memory</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">ff013f11-7e24-4273-8c44-cccb9dc9008d</guid>
      <link>https://www.aiengineeringpodcast.com/agentic-ai-operational-patterns-episode-49</link>
      <pubDate>Mon, 21 Apr 2025 15:36:05 +0000</pubDate>
      <podcast:soundbite startTime="705.36" duration="41.62">I think that microservices analogy is a great one to build around in this context because in microservices, when it first came to the general awareness of the engineering community. Everybody said, oh, great. Microservices are the way that you build software no matter what. And then everybody who had worked with them a lot really said, actually, it's more of an organizational efficiency than a technical efficiency, efficiency, and it can actually cause a lot more problems. And so I think that's a good parallel to this idea of agentic versus single LLM use cases where the purpose of microservices isn't necessarily to make your architecture great and make everything more maintainable.</podcast:soundbite>
      <podcast:soundbite startTime="3559.62" duration="48.10">One other piece that is critical and becoming more important in particularly in the current economy, but also as these systems evolve and as they're in such a constant state of flux as the idea of cost associated with running these applications. And I'm curious what are some of the gotchas that teams should be aware of as they move from, oh, I've got an LLM that I call periodically, and the cost isn't that bad. So I'm gonna go ahead and build an agent system, and then you have a multiplicative effect of the number of calls, the size of the context, etcetera, etcetera, and just some of the ways that that can act as a surprise and also a consideration at the organizational level before even investing in building something of that nature.</podcast:soundbite>
      <podcast:soundbite startTime="162.90" duration="35.28">In the context of AI applications, there are so called simple applications, which given the nature of the technology involved, I I would say is anything but simple, but comparatively. And then there is this broader category of applications that is termed agentic AI. And I'm wondering if you can just start by laying the groundwork for the conversation as far as what is the juxtaposition there of agentic AI? What does that involve in terms of technologies, competencies, as opposed to simpler LLMs and some of those operational characteristics that need to be accounted for?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:12:16</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Understanding The Operational And Organizational Challenges Of Agentic AI</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>49</itunes:episode>
      <podcast:episode>49</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638808461098030786ff013f11-7e24-4273-8c44-cccb9dc9008dv1.mp3" length="69383176" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638808461098030786ff013f11-7e24-4273-8c44-cccb9dc9008dv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ff013f11-7e24-4273-8c44-cccb9dc9008d638808465377955787.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ff013f11-7e24-4273-8c44-cccb9dc9008d638808465360661492.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ff013f11-7e24-4273-8c44-cccb9dc9008d638808465357923488.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/julianlaneve">Julian LaNeve</podcast:person>
    </item>
    <item>
      <title>The Power of Community in AI Development with Oumi</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Emmanouil (Manos) Koukoumidis, CEO of Oumi, about his vision for an open platform for building, evaluating, and deploying AI foundation models. Manos shares his journey from working on natural language AI services at Google Cloud to founding Oumi with a mission to advance open-source AI, emphasizing the importance of community collaboration and accessibility. He discusses the need for open-source models that are not constrained by proprietary APIs, highlights the role of Oumi in facilitating open collaboration, and touches on the complexities of model development, open data, and community-driven advancements in AI. He also explains how Oumi can be used throughout the entire lifecycle of AI model development, post-training, and deployment.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Manos Koukoumidis about Oumi, an all-in-one production-ready open platform to build, evaluate, and deploy AI models</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Oumi is and the story behind it?</li><li>There are numerous projects, both full suites and point solutions, focused on every aspect of "AI" development. What is the unique value that Oumi provides in this ecosystem?</li><li>You have stated the desire for Oumi to become the Linux of AI development. That is an ambitious goal and one that Linux itself didn't start with. What do you see as the biggest challenges that need addressing to reach a critical mass of adoption?</li><li>In the vein of "open source" AI, the most notable project that I'm aware of that fits the proper definition is the OLMO models from AI2. What lessons have you learned from their efforts that influence the ways that you think about your work on Oumi?</li><li>On the community building front, HuggingFace has been the main player. What do you see as the benefits and shortcomings of that platform in the context of your vision for open and collaborative AI?</li><li>Can you describe the overall design and architecture of Oumi?<ul><li>How did you approach the selection process for the different components that you are building on top of?</li><li>What are the extension points that you have incorporated to allow for customization/evolution?</li></ul></li><li>Some of the biggest barriers to entry for building foundation models are the cost and availability of hardware used for training, and the ability to collect and curate the data needed. How does Oumi help with addressing those challenges?</li><li>For someone who wants to build or contribute to an open source model, what does that process look like?<ul><li>How do you envision the community building/collaboration process?</li></ul></li><li>Your overall goal is to build a foundation for the growth and well-being of truly open AI. How are you thinking about the sustainability of the project and the funding needed to grow and support the community?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Oumi used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Oumi?</li><li>When is Oumi the wrong choice?</li><li>What do you have planned for the future of Oumi?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/koukoumidis/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://oumi.ai/" target="_blank">Oumi</a></li><li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/palm" target="_blank">Cloud PaLM</a></li><li><a href="https://deepmind.google/technologies/gemini/" target="_blank">Google Gemini</a></li><li><a href="https://deepmind.google/" target="_blank">DeepMind</a></li><li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank">LSTM == Long Short-Term Memory</a></li><li><a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture" target="_blank">Transfomers</a>)</li><li><a href="https://openai.com/index/chatgpt/" target="_blank">ChatGPT</a></li><li><a href="https://en.wikipedia.org/wiki/Partial_differential_equation" target="_blank">Partial Differential Equation</a></li><li><a href="https://allenai.org/olmo" target="_blank">OLMO</a></li><li><a href="https://opensource.org/ai" target="_blank">OSI AI definition</a></li><li><a href="https://mlflow.org/" target="_blank">MLFlow</a></li><li><a href="https://metaflow.org/" target="_blank">Metaflow</a></li><li><a href="https://docs.skypilot.co/en/latest/docs/index.html" target="_blank">SkyPilot</a></li><li><a href="https://www.llama.com/" target="_blank">Llama</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Synthetic_data" target="_blank">Synthetic Data</a><ul><li><a href="https://www.aiengineeringpodcast.com/gretel-syntehtic-data-for-ai-episode-46" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge" target="_blank">LLM As Judge</a></li><li><a href="https://github.com/sgl-project/sglang" target="_blank">SGLang</a></li><li><a href="https://github.com/vllm-project/vllm" target="_blank">vLLM</a></li><li><a href="https://gorilla.cs.berkeley.edu/leaderboard.html" target="_blank">Function Calling Leaderboard</a></li><li><a href="https://en.wikipedia.org/wiki/DeepSeek" target="_blank">Deepseek</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33e</guid>
      <link>https://www.aiengineeringpodcast.com/oumi-open-source-foundation-model-framework-episode-48</link>
      <pubDate>Sun, 16 Mar 2025 23:37:27 +0000</pubDate>
      <podcast:soundbite startTime="420.28" duration="23.98">On that note of open versus closed in terms of models, there's been a lot of conversation around what that even means where the initial batch of models that were available for people to download and run were termed open source, and then there is a lot of debate about what does that even mean for a model to be open source because it's not just the code. The data is equally important as well as the parameters that go into training and tuning, etcetera.</podcast:soundbite>
      <podcast:soundbite startTime="158.68" duration="36.43">You've mentioned a lot of your background and the fact that you're building Oomi. Wondering if you can just give a bit of an overview about what it is that you're building and why you decided to leave what you were doing at Google and start this new venture at this time. Yeah. Yeah. So Oomi is, a platform and a community to advance Frontier AI in the open. This is, exactly the opposite of what I was, doing before at Google even before JetCBT started, like, a couple before, I was announced. A couple months before that, I was starting the effort for what became Cloud Palm and then again, rebranded later as Gemini.</podcast:soundbite>
      <podcast:soundbite startTime="929.29" duration="31.14">So digging into Oomie itself, as I was preparing for this interview, I saw a couple of references to the fact that you're aiming for it to become the Linux of the AI ecosystem where it is the common substrate that becomes as natural as, water to fish or air to people living on land. And Linux, even itself, never actually set out with that mission. It was just, hey. Here's something, and then it just gained adoption because of the fact that it was accessible. People could use it.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:56:12</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Power of Community in AI Development with Oumi</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>48</itunes:episode>
      <podcast:episode>48</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638777602422836825cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33ev1.mp3" length="53971349" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638777602422836825cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33ev1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33e638777650285947207.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33e638777650283869037.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/cc360a0e-4cdb-4ec7-bfcc-7b80acf2d33e638777650282058933.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Arch Gateway: Add AI To Your Apps Without Custom Development</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Adil Hafiz talks about the Arch project, a gateway designed to simplify the integration of AI agents into business systems. He discusses how the gateway uses Rust and Envoy to provide a unified interface for handling prompts and integrating large language models (LLMs), allowing developers to focus on core business logic rather than AI complexities. The conversation also touches on the target audience, challenges, and future directions for the project, including plans to develop a leading planning LLM and enhance agent interoperability.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Adil Hafeez about the Arch project, a gateway for your AI agents</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Arch is and the story behind it?</li><li>How do you think about the target audience for Arch and the types of problems/projects that they are responsible for?</li><li>The general category of LLM gateways is largely oriented toward abstracting the specific model provider being called. What are the areas of overlap and differentiation in Arch?</li><li>Many of the features in Arch are also available in AI frameworks (e.g. LangChain, LlamaIndex, etc.), such as request routing, guardrails, and tool calling. How do you think about the architectural tradeoffs of having that functionality in a gateway service?</li><li>What is the workflow for someone building an application with Arch?</li><li>Can you describe the architecture and components of the Arch gateway?</li><li>With the pace of change in the AI/LLM ecosystem, how have you designed the Arch project to allow for rapid evolution and extensibility?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Arch used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Arch?</li><li>When is Arch the wrong choice?</li><li>What do you have planned for the future of Arch?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/adilhafeez/" target="_blank">LinkedIn</a></li><li><a href="https://github.com/adilhafeez" target="_blank">GitHub</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://archgw.com/" target="_blank">Arch Gateway</a></li><li><a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank">Gradient Boosting</a></li><li><a href="https://www.envoyproxy.io/" target="_blank">Envoy</a></li><li><a href="https://portkey.ai/blog/what-is-an-llm-gateway" target="_blank">LLM Gateway</a></li><li><a href="https://huggingface.co/" target="_blank">Huggingface</a></li><li><a href="https://huggingface.co/katanemo" target="_blank">Katanemo Models</a></li><li><a href="https://github.com/QwenLM/Qwen2.5" target="_blank">Qwen2.5</a></li><li><a href="https://doc.rust-lang.org/clippy/" target="_blank">Rust Clippy</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">983b2955-7a34-4e7a-a197-473d4b3fb48d</guid>
      <link>https://www.aiengineeringpodcast.com/arch-prompt-gateway-episode-47</link>
      <pubDate>Wed, 26 Feb 2025 00:55:40 +0000</pubDate>
      <podcast:soundbite startTime="144.51" duration="28.59">Yeah. %. So Arch Arch Gateway is an open source, agentic, edge and SLM proxy designed for prompts. So we talked to, like, many developers, like hundreds of developers, and one consistent theme that emerged in our conversation was that they wanted to build, quickly they they wanted to build apps quickly tailored to their business systems and APIs to support, knowledge based applications and agentic, and solve agentic tasks.</podcast:soundbite>
      <podcast:soundbite startTime="1469.98" duration="30.63">So there are two key areas of investment which are very important to us. Number one is to build, world's leading planning LLM. That'll be adaptation of our function calling model today And agent to agent interpret operability standards are another one. We wanted to open up the use cases for developers to provide basic tools and knowledge is how they can drive agents that can communicate with each other. These are the two scenarios that are coming up a lot in our customer conversation, and we are excited about this work.</podcast:soundbite>
      <podcast:soundbite startTime="694.17" duration="26.84">So, Salman, my other, cofounder, he and I have spent many years in infrastructure, companies. He spent many years at Amazon, s three EC two. I spent a lot of years Amazon and Lyft. Our core principle when you were developing this gateway was to, you know, develop it such such a way that it brings ease of use to the AI developers, and it's scalable and it's maintainable. So with that, we have two major components.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:31:25</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Arch Gateway: Add AI To Your Apps Without Custom Development</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>47</itunes:episode>
      <podcast:episode>47</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638761275952711729983b2955-7a34-4e7a-a197-473d4b3fb48dv1.mp3" length="30176698" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638761275952711729983b2955-7a34-4e7a-a197-473d4b3fb48dv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_983b2955-7a34-4e7a-a197-473d4b3fb48d638761281171877905.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/983b2955-7a34-4e7a-a197-473d4b3fb48d638761281169831147.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/983b2955-7a34-4e7a-a197-473d4b3fb48d638761281167592404.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/adilhafeez/">Adil Hafeez</podcast:person>
    </item>
    <item>
      <title>The Role Of Synthetic Data In Building Better AI Applications</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Ali Golshan, co-founder and CEO of Gretel.ai, talks about the transformative role of synthetic data in AI systems. Ali explains how synthetic data can be purpose-built for AI use cases, emphasizing privacy, quality, and structural stability. He highlights the shift from traditional methods to using language models, which offer enhanced capabilities in understanding data's deep structure and generating high-quality datasets. The conversation explores the challenges and techniques of integrating synthetic data into AI systems, particularly in production environments, and concludes with insights into the future of synthetic data, including its application in various industries, the importance of privacy regulations, and the ongoing evolution of AI systems.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Seamless data integration into AI applications often falls short, leading many to adopt RAG methods, which come with high costs, complexity, and limited scalability. Cognee offers a better solution with its open-source semantic memory engine that automates data ingestion and storage, creating dynamic knowledge graphs from your data. Cognee enables AI agents to understand the meaning of your data, resulting in accurate responses at a lower cost. Take full control of your data in LLM apps without unnecessary overhead. Visit <a href="https://www.aiengineeringpodcast.com/cognee" target="_blank">aiengineeringpodcast.com/cognee</a> to learn more and elevate your AI apps and agents.</li><li>Your host is Tobias Macey and today I'm interviewing Ali Golshan about the role of synthetic data in building, scaling, and improving AI systems</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by summarizing what you mean by synthetic data in the context of this conversation?</li><li>How have the capabilities around the generation and integration of synthetic data changed across the pre- and post-LLM timelines?</li><li>What are the motivating factors that would lead a team or organization to invest in synthetic data generation capacity?</li><li>What are the main methods used for generation of synthetic data sets?<ul><li>How does that differ across open-source and commercial offerings?</li></ul></li><li>From a surface level it seems like synthetic data generation is a straight-forward exercise that can be owned by an engineering team. What are the main "gotchas" that crop up as you move along the adoption curve?<ul><li>What are the scaling characteristics of synthetic data generation as you go from prototype to production scale?</li></ul></li><li>domains/data types that are inappropriate for synthetic use cases (e.g. scientific or educational content)</li><li>managing appropriate distribution of values in the generation process</li><li>Beyond just producing large volumes of semi-random data (structured or otherwise), what are the other processes involved in the workflow of synthetic data and its integration into the different systems that consume it?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen synthetic data generation used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on synthetic data generation?</li><li>When is synthetic data the wrong choice?</li><li>What do you have planned for the future of synthetic data capabilities at Gretel?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/ali-golshan/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://gretel.ai/" target="_blank">Gretel</a></li><li><a href="https://hadoop.apache.org/" target="_blank">Hadoop</a></li><li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank">LSTM == Long Short-Term Memory</a></li><li><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" target="_blank">GAN == Generative Adversarial Network</a></li><li><a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/" target="_blank">Textbooks are all you need</a> MSFT paper</li><li><a href="https://www.illumina.com/" target="_blank">Illumina</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">c32d793f-d2ec-4c1f-a1d1-b8920d65e935</guid>
      <link>https://www.aiengineeringpodcast.com/gretel-syntehtic-data-for-ai-episode-46</link>
      <pubDate>Sun, 16 Feb 2025 15:29:40 +0000</pubDate>
      <podcast:soundbite startTime="2289.43" duration="23.99">They couldn't go across hospitals. But what they didn't want is is to give the, like, the doctor a snowflake environment and go say go query it. So what they wanted to do was actually have a large language model builder, like an AI assistant that can talk to all the data and the physician could just ask it questions. So they're using us to create differentially private versions of synthetic data from all the hospital systems and then use that corpus to train the model on.</podcast:soundbite>
      <podcast:soundbite startTime="183.63" duration="24.98">And so synthetic data is definitely a core piece of what you're doing at Gretl. But before we dig too much into that, I'm wondering if you could just start by summarizing and framing what we even mean by the term synthetic data because it can mean a few different things from I just cat dev null into a file somewhere to, somebody who manually generates a bunch of stuff. I'm just wondering if we can set the framing of the conversation.</podcast:soundbite>
      <podcast:soundbite startTime="544.63" duration="23.82">And I think that's the tipping point that language models created for us. In terms of the actual motivating factors for synthetic data? You mentioned a few of them, but I'm curious if you can talk to also maybe some of the ways that the purpose of synthetic data and its application has changed across that pre LLM or in post LLM epoch.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:54:21</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Role Of Synthetic Data In Building Better AI Applications</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>46</itunes:episode>
      <podcast:episode>46</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638748385953076521c32d793f-d2ec-4c1f-a1d1-b8920d65e935v1.mp3" length="52194474" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638748385953076521c32d793f-d2ec-4c1f-a1d1-b8920d65e935v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_c32d793f-d2ec-4c1f-a1d1-b8920d65e935638753165708292098.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c32d793f-d2ec-4c1f-a1d1-b8920d65e935638753165704588776.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c32d793f-d2ec-4c1f-a1d1-b8920d65e935638753165701763024.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/ali-golshan/">Ali Golshan</podcast:person>
    </item>
    <item>
      <title>Optimize Your AI Applications Automatically With The TensorZero LLM Gateway</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast Viraj Mehta, CTO and co-founder of TensorZero, talks about the use of LLM gateways for managing interactions between client-side applications and various AI models. He highlights the benefits of using such a gateway, including standardized communication, credential management, and potential features like request-response caching and audit logging. The conversation also explores TensorZero's architecture and functionality in optimizing AI applications by managing structured data inputs and outputs, as well as the challenges and opportunities in automating prompt generation and maintaining interaction history for optimization purposes.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Seamless data integration into AI applications often falls short, leading many to adopt RAG methods, which come with high costs, complexity, and limited scalability. Cognee offers a better solution with its open-source semantic memory engine that automates data ingestion and storage, creating dynamic knowledge graphs from your data. Cognee enables AI agents to understand the meaning of your data, resulting in accurate responses at a lower cost. Take full control of your data in LLM apps without unnecessary overhead. Visit <a href="https://www.aiengineeringpodcast.com/cognee" target="_blank">aiengineeringpodcast.com/cognee</a> to learn more and elevate your AI apps and agents.&nbsp;</li><li>Your host is Tobias Macey and today I'm interviewing Viraj Mehta about the purpose of an LLM gateway and his work on TensorZero</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>What is an LLM gateway?<ul><li>What purpose does it serve in an AI application architecture?</li></ul></li><li>What are some of the different features and capabilities that an LLM gateway might be expected to provide?</li><li>Can you describe what TensorZero is and the story behind it?<ul><li>What are the core problems that you are trying to address with Tensor0 and for whom?</li></ul></li><li>One of the core features that you are offering is management of interaction history. How does this compare to the "memory" functionality offered by e.g. LangChain, Cognee, Mem0, etc.?</li><li>How does the presence of TensorZero in an application architecture change the ways that an AI engineer might approach the logic and control flows in a chat-based or agent-oriented project?</li><li>Can you describe the workflow of building with Tensor0 and some specific examples of how it feeds back into the performance/behavior of an LLM?</li><li>What are some of the ways in which the addition of Tensor0 or another LLM gateway might have a negative effect on the design or operation of an AI application?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen TensorZero used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on TensorZero?</li><li>When is TensorZero the wrong choice?</li><li>What do you have planned for the future of TensorZero?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/virajrmehta/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.tensorzero.com/" target="_blank">TensorZero</a></li><li><a href="https://www.tensorops.ai/post/llm-gateways-in-production-centralized-access-security-and-monitoring" target="_blank">LLM Gateway</a></li><li><a href="https://www.litellm.ai/" target="_blank">LiteLLM</a></li><li><a href="https://openai.com/" target="_blank">OpenAI</a></li><li><a href="https://cloud.google.com/vertex-ai" target="_blank">Google Vertex</a></li><li><a href="https://www.anthropic.com/" target="_blank">Anthropic</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Tokamak" target="_blank">Tokamak Reactor</a></li><li><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=4pHjHBkAAAAJ&amp;sortby=pubdate&amp;citation_for_view=4pHjHBkAAAAJ:M3ejUd6NZC8C" target="_blank">Viraj RLHF Paper</a></li><li><a href="https://arxiv.org/abs/1502.06362" target="_blank">Contextual Dueling Bandits</a></li><li><a href="https://www.superannotate.com/blog/direct-preference-optimization-dpo" target="_blank">Direct Preference Optimization</a></li><li><a href="https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process" target="_blank">Partially Observable Markov Decision Process</a></li><li><a href="https://dspy.ai/" target="_blank">DSPy</a></li><li><a href="https://pytorch.org/" target="_blank">PyTorch</a></li><li><a href="https://www.cognee.ai" target="_blank">Cognee</a></li><li><a href="https://github.com/mem0ai/mem0" target="_blank">Mem0</a></li><li><a href="https://www.langchain.com/langgraph" target="_blank">LangGraph</a></li><li><a href="https://en.wikipedia.org/wiki/Douglas_Hofstadter" target="_blank">Douglas Hofstadter</a></li><li><a href="https://github.com/openai/gym" target="_blank">OpenAI Gym</a></li><li><a href="https://en.wikipedia.org/wiki/OpenAI_o1" target="_blank">OpenAI o1</a></li><li><a href="https://en.wikipedia.org/wiki/OpenAI_o3" target="_blank">OpenAI o3</a></li><li><a href="https://www.promptingguide.ai/techniques/cot" target="_blank">Chain Of Thought</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">c93f9b44-5412-4e68-8e3a-4dee94a1a3da</guid>
      <link>https://www.aiengineeringpodcast.com/tensorzero-llm-gateway-prompt-optimization-episode-45</link>
      <pubDate>Wed, 22 Jan 2025 16:32:38 +0000</pubDate>
      <podcast:soundbite startTime="172.10" duration="23.21">And so that is a bug that hasn't left since those maybe 2016, I think. And so that has ultimately brought you to tensor 0, but before we get too deep into what you're building specifically, I just wanted to get an understanding about what even is an LLM gateway, and what is its purpose in the overall architecture of an AI application.</podcast:soundbite>
      <podcast:soundbite startTime="3412.01" duration="29.30">And so, really, what we want in order to do that is a bunch of different problems that cover different problem spaces where we can run a bunch of examples, fill up the data model, then run the technique, and then see how much better it got. And so today that involves, you know, kind of building a bunch of ad hoc scripts that run a bunch of examples for each, like set up the environment, set up the example, run a bunch of episodes of interaction and then run the script for improvement and then run a bunch more episodes to see how it did.</podcast:soundbite>
      <podcast:soundbite startTime="3700.72" duration="16.79">And so I'm gonna, I think, put the onus on the business professionals who interact with AI folks and AI systems and say, like, how can like, the the management technology of how do we start to measure and optimize and, like, use these things in a serious way requires some development yet.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:03:05</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Optimize Your AI Applications Automatically With The TensorZero LLM Gateway</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>45</itunes:episode>
      <podcast:episode>45</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638729251179606751c93f9b44-5412-4e68-8e3a-4dee94a1a3dav1.mp3" length="60570229" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638729251179606751c93f9b44-5412-4e68-8e3a-4dee94a1a3dav1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_c93f9b44-5412-4e68-8e3a-4dee94a1a3da638729317827918114.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c93f9b44-5412-4e68-8e3a-4dee94a1a3da638729317825075843.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c93f9b44-5412-4e68-8e3a-4dee94a1a3da638729317821995474.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/virajrmehta/">Viraj Mehta</podcast:person>
    </item>
    <item>
      <title>Harnessing The Engine Of AI</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Ron Green, co-founder and CTO of KungFu AI, talks about the evolving landscape of AI systems and the challenges of harnessing generative AI engines. Ron shares his insights on the limitations of large language models (LLMs) as standalone solutions and emphasizes the need for human oversight, multi-agent systems, and robust data management to support AI initiatives. He discusses the potential of domain-specific AI solutions, RAG approaches, and mixture of experts to enhance AI capabilities while addressing risks. The conversation also explores the evolving AI ecosystem, including tooling and frameworks, strategic planning, and the importance of interpretability and control in AI systems. Ron expresses optimism about the future of AI, predicting significant advancements in the next 20 years and the integration of AI capabilities into everyday software applications.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Seamless data integration into AI applications often falls short, leading many to adopt RAG methods, which come with high costs, complexity, and limited scalability. Cognee offers a better solution with its open-source semantic memory engine that automates data ingestion and storage, creating dynamic knowledge graphs from your data. Cognee enables AI agents to understand the meaning of your data, resulting in accurate responses at a lower cost. Take full control of your data in LLM apps without unnecessary overhead. Visit <a href="https://www.aiengineeringpodcast.com/cognee" target="_blank">aiengineeringpodcast.com/cognee</a> to learn more and elevate your AI apps and agents.&nbsp;</li><li>Your host is Tobias Macey and today I'm interviewing Ron Green about the wheels that we need for harnessing the power of the generative AI engine</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what you see as the main shortcomings of LLMs as a stand-alone solution (to anything)?</li><li>The most established vehicle for harnessing LLM capabilities is the RAG pattern. What are the main limitations of that as a "product" solution?</li><li>The idea of multi-agent or mixture-of-experts systems is a more sophisticated approach that is gaining some attention. What do you see as the pro/con conversation around that pattern?</li><li>Beyond the system patterns that are being developed there is also a rapidly shifting ecosystem of frameworks, tools, and point solutions that plugin to various points of the AI lifecycle. How does that volatility hinder the adoption of generative AI in different contexts?<ul><li>In addition to the tooling, the models themselves are rapidly changing. How much does that influence the ways that organizations are thinking about whether and when to test the waters of AI?</li></ul></li><li>Continuing on the metaphor of LLMs and engines and the need for vehicles, where are we on the timeline in relation to the model T Ford?<ul><li>What are the vehicle categories that we still need to design and develop? (e.g. sedans, mini-vans, freight trucks, etc.)</li></ul></li><li>The current transformer architecture is starting to reach scaling limits that lead to diminishing returns. Given your perspective as an industry veteran, what are your thoughts on the future trajectory of AI model architectures?<ul><li>What is the ongoing role of regression style ML in the landscape of generative AI?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen LLMs used to power a "vehicle"?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working in this phase of AI?</li><li>When is generative AI/LLMs the wrong choice?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/rongreen/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.kungfu.ai/" target="_blank">Kungfu.ai</a></li><li><a href="https://www.llama.com/" target="_blank">Llama</a> open generative AI models</li><li><a href="https://openai.com/index/chatgpt/" target="_blank">ChatGPT</a></li><li><a href="https://github.com/features/copilot" target="_blank">Copilot</a></li><li><a href="https://www.cursor.com/" target="_blank">Cursor</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://huggingface.co/blog/moe" target="_blank">Mixture of Experts</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank">Random Forest</a></li><li><a href="https://en.wikipedia.org/wiki/Supervised_learning" target="_blank">Supervised Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning" target="_blank">Active Learning</a>)</li><li><a href="https://yann.lecun.com/" target="_blank">Yann LeCunn</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank">RLHF == Reinforcement Learning from Human Feedback</a></li><li><a href="https://en.wikipedia.org/wiki/Ford_Model_T" target="_blank">Model T Ford</a></li><li><a href="https://github.com/state-spaces/mamba" target="_blank">Mamba selective state space</a></li><li><a href="https://news.mit.edu/2021/machine-learning-adapts-0128" target="_blank">Liquid Network</a></li><li><a href="https://www.promptingguide.ai/techniques/cot" target="_blank">Chain of thought</a></li><li><a href="https://openai.com/o1/" target="_blank">OpenAI o1</a></li><li><a href="https://en.wikipedia.org/wiki/Marvin_Minsky" target="_blank">Marvin Minsky</a></li><li><a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture" target="_blank">Von Neumann Architecture</a></li><li><a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a></li><li><a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" target="_blank">Multilayer Perceptron</a></li><li><a href="https://builtin.com/data-science/dot-product-matrix" target="_blank">Dot Product</a></li><li><a href="https://en.wikipedia.org/wiki/Diffusion_model" target="_blank">Diffusion Model</a></li><li><a href="https://en.wikipedia.org/wiki/Gaussian_noise" target="_blank">Gaussian Noise</a></li><li><a href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/" target="_blank">AlphaFold 3</a></li><li><a href="https://www.anthropic.com/" target="_blank">Anthropic</a></li><li><a href="https://paperswithcode.com/method/sparse-autoencoder" target="_blank">Sparse Autoencoder</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">83919d06-231e-49e0-94fa-f30bc0078077</guid>
      <link>https://www.aiengineeringpodcast.com/kungu-ai-llm-guidance-episode-44</link>
      <pubDate>Mon, 16 Dec 2024 01:59:45 +0000</pubDate>
      <podcast:soundbite startTime="160.08" duration="22.68">Yeah. It's definitely funny that the cycles that the industry goes through of we hit a certain peak and we think, oh, we've done as much as we can here, and we're on a glide path and then everything stalls out. And we have to go through another cycle of discovery to realize, oh, this actually was just a local maxima. There's a whole other mountain range to climb.</podcast:soundbite>
      <podcast:soundbite startTime="863.90" duration="37.03">I this is actually a a topic I'm pretty passionate about because I'm a big believer in the power of generative AI. I absolutely think it's a transformative capability. But I personally think at this stage in our maturation, most companies should be looking at what what I call domain specific AIs. And I I you know, it's really kind of immaterial whether you're you're looking at, like, as you said, deep learning or random forest or or, hell, you know, even even linear regression or something like that.</podcast:soundbite>
      <podcast:soundbite startTime="301.42" duration="35.75">And it and it's not it's it's not just, like, hallucinations, which I think are probably the biggest risks. But we've we've done many generative AI production engagements at Kung Fu AI. And the main challenge is you may want to steer the model away from certain domains. Right? As a company, you may, I won't name the company we're working with, but we're doing this generative AI project for, sort of a photo, site where you could put together, you know, scrapbooks and and photo books and things like that.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:55:13</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Harnessing The Engine Of AI</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>44</itunes:episode>
      <podcast:episode>44</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63869892309983673583919d06-231e-49e0-94fa-f30bc0078077v1.mp3" length="53029499" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63869892309983673583919d06-231e-49e0-94fa-f30bc0078077v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_83919d06-231e-49e0-94fa-f30bc0078077638699109033670777.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/83919d06-231e-49e0-94fa-f30bc0078077638699109026905470.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/83919d06-231e-49e0-94fa-f30bc0078077638699109018598010.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/rongreen/">Ron Green</podcast:person>
    </item>
    <item>
      <title>The Complex World of Generative AI Governance</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast Jim Olsen, CTO of ModelOp, talks about the governance of generative AI models and applications. Jim shares his extensive experience in software engineering and machine learning, highlighting the importance of governance in high-risk applications like healthcare. He explains that governance is more about the use cases of AI models rather than the models themselves, emphasizing the need for proper inventory and monitoring to ensure compliance and mitigate risks. The conversation covers challenges organizations face in implementing AI governance policies, the importance of technical controls for data governance, and the need for ongoing monitoring and baselines to detect issues like PII disclosure and model drift. Jim also discusses the balance between innovation and regulation, particularly with evolving regulations like those in the EU, and provides valuable perspectives on the current state of AI governance and the need for robust model lifecycle management.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Jim Olsen about governance of your generative AI models and applications</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what governance means in the context of generative AI models? (e.g. governing the models, their applications, their outputs, etc.)</li><li>Governance is typically a hybrid endeavor of technical and organizational policy creation and enforcement. From the organizational perspective, what are some of the difficulties that teams are facing in understanding what those policies need to encompass?<ul><li>How much familiarity with the capabilities and limitations of the models is necessary to engage productively with policy debates?</li></ul></li><li>The regulatory landscape around AI is still very nascent. Can you give an overview of the current state of legal burden related to AI?<ul><li>What are some of the regulations that you consider necessary but as-of-yet absent?</li></ul></li><li>Data governance as a practice typically relates to controls over who can access what information and how it can be used. The controls for those policies are generally available in the data warehouse, business intelligence, etc. What are the different dimensions of technical controls that are needed in the application of generative AI systems?<ul><li>How much of the controls that are present for governance of analytical systems are applicable to the generative AI arena?</li></ul></li><li>What are the elements of risk that change when considering internal vs. consumer facing applications of generative AI?<ul><li>How do the modalities of the AI models impact the types of risk that are involved? (e.g. language vs. vision vs. audio)</li></ul></li><li>What are some of the technical aspects of the AI tools ecosystem that are in greatest need of investment to ease the burden of risk and validation of model use?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen AI governance implemented?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on AI governance?</li><li>What are the technical, social, and organizational trends of AI risk and governance that you are monitoring?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/jimolsen/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.modelop.com/" target="_blank">ModelOp</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_model" target="_blank">Foundation Models</a></li><li><a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation" target="_blank">GDPR</a></li><li><a href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target="_blank">EU AI Regulation</a></li><li><a href="https://www.llama.com/llama2/" target="_blank">Llama 2</a></li><li><a href="https://aws.amazon.com/bedrock/" target="_blank">AWS Bedrock</a></li><li><a href="https://en.wikipedia.org/wiki/Shadow_IT" target="_blank">Shadow IT</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://github.com/NVIDIA/NeMo" target="_blank">Nvidia NEMO</a></li><li><a href="https://www.langchain.com/" target="_blank">LangChain</a></li><li><a href="https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html" target="_blank">Shapley Values</a></li><li><a href="https://llm-guard.com/output_scanners/gibberish/" target="_blank">Gibberish Detection</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">4cedae93-56d3-4942-adcd-f44533982a5e</guid>
      <link>https://www.aiengineeringpodcast.com/ai-governance-challenges-and-techniques-episode-43</link>
      <pubDate>Sun, 1 Dec 2024 22:20:36 +0000</pubDate>
      <podcast:soundbite startTime="605.38" duration="34.95">Yeah. Well, because of the that model, I mean, they obviously do offer their own version where you get an isolated version. They claim that they they're not storing any of that information, etcetera, etcetera. And then it comes down to a trust situation with the the vendor and contracts and all that fun stuff. But what I am seeing is a lot of people who are more sensitive to their information are exploring either private, like, llama 2 instances, etcetera, where they host them on-site or private cloud kind of situations like using an Amazon Bedrock within your own secure private cloud instance, etcetera.</podcast:soundbite>
      <podcast:soundbite startTime="96.69" duration="24.55">And in the context of governance for the current generation of AI models, which typically means generative AI, so large language models, some of these vision models that are able to produce images and video, and, obviously, the the fields expanding as we speak. I'm wondering if you can just start by giving a bit of an overview about what governance even means for those types of technologies.</podcast:soundbite>
      <podcast:soundbite startTime="2346.80" duration="28.32">And in your experience of working in this space of model governance, AI regulations, helping organizations come to grips with what is possible for managing that risk and helping them to understand what are appropriate policies and technical controls around that. I'm wondering what are some of the most interesting or innovative or unexpected ways that you've seen companies, address that challenge of AI governance?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:54:19</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Complex World of Generative AI Governance</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>43</itunes:episode>
      <podcast:episode>43</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386868753996455194cedae93-56d3-4942-adcd-f44533982a5ev1.mp3" length="52150460" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386868753996455194cedae93-56d3-4942-adcd-f44533982a5ev1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_4cedae93-56d3-4942-adcd-f44533982a5e638699992872296999.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/4cedae93-56d3-4942-adcd-f44533982a5e638699992866216408.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/4cedae93-56d3-4942-adcd-f44533982a5e638699992859690917.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/jimolsen/">Jim Olsen</podcast:person>
    </item>
    <item>
      <title>Building Semantic Memory for AI With Cognee</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast, Vasilije Markovich talks about enhancing Large Language Models (LLMs) with memory to improve their accuracy. He discusses the concept of memory in LLMs, which involves managing context windows to enhance reasoning without the high costs of traditional training methods. He explains the challenges of forgetting in LLMs due to context window limitations and introduces the idea of hierarchical memory, where immediate retrieval and long-term information storage are balanced to improve application performance. Vasilije also shares his work on Cognee, a tool he's developing to manage semantic memory in AI systems, and discusses its potential applications beyond its core use case. He emphasizes the importance of combining cognitive science principles with data engineering to push the boundaries of AI capabilities and shares his vision for the future of AI systems, highlighting the role of personalization and the ongoing development of Cognee to support evolving AI architectures.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Vasilije Markovic about adding memory to LLMs to improve their accuracy</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what "memory" is in the context of LLM systems?</li><li>What are the symptoms of "forgetting" that manifest when interacting with LLMs?<ul><li>How do these issues manifest between single-turn vs. multi-turn interactions?</li></ul></li><li>How does the lack of hierarchical and evolving memory limit the capabilities of LLM systems?</li><li>What are the technical/architectural requirements to add memory to an LLM system/application?</li><li>How does Cognee help to address the shortcomings of current LLM/RAG architectures?</li><li>Can you describe how Cognee is implemented?<ul><li>Recognizing that it has only existed for a short time, how have the design and scope of Cognee evolved since you first started working on it?</li></ul></li><li>What are the data structures that are most useful for managing the memory structures?</li><li>For someone who wants to incorporate Cognee into their LLM architecture, what is involved in integrating it into their applications?<ul><li>How does it change the way that you think about the overall requirements for an LLM application?</li></ul></li><li>For systems that interact with multiple LLMs, how does Cognee manage context across those systems? (e.g. different agents for different use cases)</li><li>There are other systems that are being built to manage user personalization in LLm applications, how do the goals of Cognee relate to those use cases? (e.g. Mem0 - <a href="https://github.com/mem0ai/mem0)" target="_blank">https://github.com/mem0ai/mem0)</a></li><li>What are the unknowns that you are still navigating with Cognee?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Cognee used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Cognee?</li><li>When is Cognee the wrong choice?</li><li>What do you have planned for the future of Cognee?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/vasilije-markovic-13302471/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.cognee.ai/" target="_blank">Cognee</a></li><li><a href="https://en.wikipedia.org/wiki/Montenegro" target="_blank">Montenegro</a></li><li><a href="https://en.wikipedia.org/wiki/Catastrophic_interference" target="_blank">Catastrophic Forgetting</a></li><li><a href="https://poly.ai/blog/multi-turn-conversations-what-are-they-and-why-do-they-matter-for-your-customers/" target="_blank">Multi-Turn Interaction</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://neo4j.com/blog/graphrag-manifesto/" target="_blank">GraphRAG</a><ul><li><a href="https://www.aiengineeringpodcast.com/graphrag-knowledge-graph-semantic-retrieval-episode-37" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Long-term_memory" target="_blank">Long-term memory</a></li><li><a href="https://en.wikipedia.org/wiki/Short-term_memory" target="_blank">Short-term memory</a></li><li><a href="https://www.langchain.com/" target="_blank">Langchain</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">LlamaIndex</a></li><li><a href="https://haystack.deepset.ai/" target="_blank">Haystack</a></li><li><a href="https://dlthub.com/" target="_blank">dlt</a><ul><li><a href="https://www.dataengineeringpodcast.com/dlt-pure-python-data-integration-episode-441" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.pinecone.io/" target="_blank">Pinecone</a><ul><li><a href="https://www.dataengineeringpodcast.com/pinecone-vector-database-similarity-search-episode-189/" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://weaviate.io/blog/what-is-agentic-rag" target="_blank">Agentic RAG</a></li><li><a href="https://airflow.apache.org/" target="_blank">Airflow</a></li><li><a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" target="_blank">DAG == Directed Acyclic Graph</a></li><li><a href="https://github.com/FalkorDB/falkordb" target="_blank">FalkorDB</a></li><li><a href="https://neo4j.com/" target="_blank">Neo4J</a></li><li><a href="https://pydantic.dev/" target="_blank">Pydantic</a></li><li><a href="https://aws.amazon.com/ecs/" target="_blank">AWS ECS</a></li><li><a href="https://aws.amazon.com/sns/" target="_blank">AWS SNS</a></li><li><a href="https://aws.amazon.com/sqs/" target="_blank">AWS SQS</a></li><li><a href="https://aws.amazon.com/lambda/" target="_blank">AWS Lambda</a></li><li><a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge" target="_blank">LLM As Judge</a></li><li><a href="https://www.mem0.ai/" target="_blank">Mem0</a></li><li><a href="https://qdrant.tech/" target="_blank">QDrant</a></li><li><a href="https://lancedb.com/" target="_blank">LanceDB</a></li><li><a href="https://duckdb.org/" target="_blank">DuckDB</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">5cf44e6c-5145-4fc7-b12c-27deaa398b62</guid>
      <link>https://www.aiengineeringpodcast.com/cognee-llm-semantic-memory-episode-42</link>
      <pubDate>Mon, 25 Nov 2024 02:36:34 +0000</pubDate>
      <podcast:soundbite startTime="2320.69" duration="43.35">And as you continue to iterate on the design and use cases of Cogni and try to navigate the constant shifts in the LLM and AI ecosystem, what are some of the unknowns that you're still navigating? So many. I mean, I don't know. It's a startup. I think everything is unknown, except the knowns, which you want to be unknown sometimes because it's bad news. I think in this context, we are facing, a lot of questions on, what will be the data stack of the future. Right? So what will we need to actually use the LLMs in production together with its more traditional systems and how will these interfaces look like?</podcast:soundbite>
      <podcast:soundbite startTime="412.23" duration="33.53">And I'm wondering what that aspect of hierarchical and evolving memory means in the context of LLMs and some of the ways that the current application architecture is not up to the task of being able to support those more nuanced elements of memory and retrieval? Yeah. That's a great question. So when we talk about what is a memory currently for LLMs, we have, like, maybe let's let's go back to the basics. We have in context what we copied to the LLM and we say this is your memory. As we said, like, it's limited, we forget.</podcast:soundbite>
      <podcast:soundbite startTime="99.89" duration="45.49">And so in the context of LLMs, you mentioned that you're working on building a system to add semantic memory to those applications, and I'm wondering if you can just describe a bit about what that term memory means in the context of LLM systems? That's a great question. So how I look at memory in context of, LLM systems is pretty much based on in context learning. So if we have an LLM, we can give it some sentence or 2 or 10, which we all do when we copy paste some context for it to reason on. We effectively are giving it some memory it can operate on. And, this, compared to the traditional, let's say, training and fine tuning methods is, something we can do for almost no money.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:55:01</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Building Semantic Memory for AI With Cognee</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>42</itunes:episode>
      <podcast:episode>42</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386809732931624315cf44e6c-5145-4fc7-b12c-27deaa398b62v1.mp3" length="52829966" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386809732931624315cf44e6c-5145-4fc7-b12c-27deaa398b62v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_5cf44e6c-5145-4fc7-b12c-27deaa398b62638680989850780634.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5cf44e6c-5145-4fc7-b12c-27deaa398b62638680989848145445.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5cf44e6c-5145-4fc7-b12c-27deaa398b62638680989845151368.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/vasilije-markovic-13302471/">Vasilije Markovich</podcast:person>
    </item>
    <item>
      <title>The Impact of Generative AI on Software Development</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering Podcast, Tanner Burson, VP of Engineering at Prismatic, talks about the evolving impact of generative AI on software developers. Tanner shares his insights from engineering leadership and data engineering initiatives, discussing how AI is blurring the lines of developer roles and the strategic value of AI in software development. He explores the current landscape of AI tools, such as GitHub's Copilot, and their influence on productivity and workflow, while also touching on the challenges and opportunities presented by AI in code generation, review, and tooling. Tanner emphasizes the need for human oversight to maintain code quality and security, and offers his thoughts on the future of AI in development, the importance of balancing innovation with practicality, and the evolving role of engineers in an AI-driven landscape.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Tanner Burson about the impact of generative AI on software developers</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what types of roles and work you consider encompassed by the term "developers" for the purpose of this conversation?</li><li>How does your work at Prismatic give you visibility and insight into the effects of AI on developers and their work?</li><li>There have been many competing narratives about AI and how much of the software development process it is capable of encompassing. What is your top-level view on what the long-term impact on the job prospects of software developers will be as a result of generative AI?</li><li>There are many obvious examples of utilities powered by generative AI that are focused on software development. What do you see as the categories or specific tools that are most impactful to the development cycle?</li><li>In what ways do you find familiarity with/understanding of LLM internals useful when applying them to development processes?</li><li>As an engineering leader, how are you evaluating and guiding your team on the use of AI powered tools?<ul><li>What are some of the risks that you are guarding against as a result of AI in the development process?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen AI used in the development process?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while using AI for software development?</li><li>When is AI the wrong choice for a developer?</li><li>What are your projections for the near to medium term impact on the developer experience as a result of generative AI?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/tannerburson/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://prismatic.io/" target="_blank">Prismatic</a></li><li><a href="https://arstechnica.com/ai/2024/10/google-ceo-says-over-25-of-new-google-code-is-generated-by-ai/" target="_blank">Google AI Development announcement</a></li><li><a href="https://www.tabnine.com/" target="_blank">Tabnine</a><ul><li><a href="https://www.aiengineeringpodcast.com/tabnine-generative-ai-developer-assistant-episode-24" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://github.com/features/copilot" target="_blank">GitHub Copilot</a></li><li><a href="https://github.com/plandex-ai/plandex" target="_blank">Plandex</a></li><li><a href="https://platform.openai.com/docs/overview" target="_blank">OpenAI API</a></li><li><a href="https://aws.amazon.com/q/" target="_blank">Amazon Q</a></li><li><a href="https://ollama.com/" target="_blank">Ollama</a></li><li><a href="https://huggingface.co/docs/transformers/en/index" target="_blank">Huggingface Transformers</a></li><li><a href="https://www.anthropic.com/" target="_blank">Anthropic</a></li><li><a href="https://www.langchain.com/" target="_blank">Langchain</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">Llamaindex</a></li><li><a href="https://haystack.deepset.ai/" target="_blank">Haystack</a></li><li><a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank">Llama 3.2</a></li><li><a href="https://github.com/QwenLM/Qwen2.5-Coder" target="_blank">Qwen2.5-Coder</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">c8c79dba-ef70-4ed0-a468-80da70fbbc19</guid>
      <link>https://www.aiengineeringpodcast.com/generative-ai-in-software-development-episode-41</link>
      <pubDate>Fri, 22 Nov 2024 22:27:10 +0000</pubDate>
      <podcast:soundbite startTime="621.29" duration="33.00">Digging now into some of the actual workflow impact and the ways that AI is impacting the day to day of engineers as they conduct their work in the present. There are a lot of different utilities, maybe the most broadly known one being GitHub's Copilot and various approximations of that. And I'm wondering what you see as the general categories of tools that are most impactful, both positive or negative, and then maybe that are most useful in that development cycle.</podcast:soundbite>
      <podcast:soundbite startTime="2365.16" duration="35.17">Yeah. I think that that makes a a a ton of sense, and I get it at a simple level. Almost anything I've ever gotten better at in my life required me to do more of it, not less of it. And so if if an individual's goal is to become a better software developer, better software engineer, you know, more more productive portion of of their team and the the rest of it, the idea that you will get there solely by, delegating more of, the work to an AI tool seems counterproductive in the long term.</podcast:soundbite>
      <podcast:soundbite startTime="251.51" duration="38.81">One of the overall narratives that has been going back and forth over the past definitely the past year, maybe the past 2 to 3, depending on how you want to frame it, is the tension between the AI maximalists and the AI skeptics where you have some famous announcements from, I think it was the CTO at AWS saying that AI is going to put all the engineers out of a job where we don't need any more engineers. We're just gonna let AI do all the work. And then you have some very prominent and senior engineers who are saying, I've tried to use AI to do my work, and it's garbage, and I have to correct it. And it actually takes me more time to use it than if I just did it myself.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:52:58</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Impact of Generative AI on Software Development</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>41</itunes:episode>
      <podcast:episode>41</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638678406181004931c8c79dba-ef70-4ed0-a468-80da70fbbc19v1.mp3" length="50866008" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638678406181004931c8c79dba-ef70-4ed0-a468-80da70fbbc19v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_c8c79dba-ef70-4ed0-a468-80da70fbbc19638679111764518564.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c8c79dba-ef70-4ed0-a468-80da70fbbc19638679111759665742.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c8c79dba-ef70-4ed0-a468-80da70fbbc19638679111751773179.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/tannerburson/">Tanner Burson</podcast:person>
    </item>
    <item>
      <title>ML Infrastructure Without The Ops: Simplifying The ML Developer Experience With Runhouse</title>
      <description><![CDATA[Summary<br />Machine learning workflows have long been complex and difficult to operationalize. They are often characterized by a period of research, resulting in an artifact that gets passed to another engineer or team to prepare for running in production. The MLOps category of tools have tried to build a new set of utilities to reduce that friction, but have instead introduced a new barrier at the team and organizational level. Donny Greenberg took the lessons that he learned on the PyTorch team at Meta and created Runhouse. In this episode he explains how, by reducing the number of opinions in the framework, he has also reduced the complexity of moving from development to production for ML systems.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Donny Greenberg about Runhouse and the current state of ML infrastructure</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>What are the core elements of infrastructure for ML and AI?<ul><li>How has that changed over the past ~5 years?</li><li>For the past few years the MLOps and data engineering stacks were built and managed separately. How does the current generation of tools and product requirements influence the present and future approach to those domains?</li></ul></li><li>There are numerous projects that aim to bridge the complexity gap in running Python and ML code from your laptop up to distributed compute on clouds (e.g. Ray, Metaflow, Dask, Modin, etc.). How do you view the decision process for teams trying to understand which tool(s) to use for managing their ML/AI developer experience?</li><li>Can you describe what Runhouse is and the story behind it?<ul><li>What are the core problems that you are working to solve?</li><li>What are the main personas that you are focusing on? (e.g. data scientists, DevOps, data engineers, etc.)</li><li>How does Runhouse factor into collaboration across skill sets and teams?</li></ul></li><li>Can you describe how Runhouse is implemented?<ul><li>How has the focus on developer experience informed the way that you think about the features and interfaces that you include in Runhouse?</li></ul></li><li>How do you think about the role of Runhouse in the integration with the AI/ML and data ecosystem?</li><li>What does the workflow look like for someone building with Runhouse?</li><li>What is involved in managing the coordination of compute and data locality to reduce networking costs and latencies?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Runhouse used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Runhouse?</li><li>When is Runhouse the wrong choice?</li><li>What do you have planned for the future of Runhouse?</li><li>What is your vision for the future of infrastructure and developer experience in ML/AI?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/greenbergdon/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.run.house/" target="_blank">Runhouse</a><ul><li><a href="https://github.com/run-house/runhouse" target="_blank">GitHub</a></li></ul></li><li><a href="https://pytorch.org/" target="_blank">PyTorch</a><ul><li><a href="https://www.pythonpodcast.com/pytorch-deep-learning-epsiode-202" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://kubernetes.io/" target="_blank">Kubernetes</a></li><li><a href="https://en.wikipedia.org/wiki/Bin_packing_problem" target="_blank">Bin Packing</a></li><li><a href="https://en.wikipedia.org/wiki/Linear_regression" target="_blank">Linear Regression</a></li><li><a href="https://developers.google.com/machine-learning/decision-forests/intro-to-gbdt" target="_blank">Gradient Boosted Decision Tree</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture" target="_blank">Transformer Architecture</a>)</li><li><a href="https://slurm.schedmd.com/documentation.html" target="_blank">Slurm</a></li><li><a href="https://aws.amazon.com/sagemaker/" target="_blank">Sagemaker</a></li><li><a href="https://cloud.google.com/vertex-ai?hl=en" target="_blank">Vertex AI</a></li><li><a href="https://metaflow.org/" target="_blank">Metaflow</a><ul><li><a href="https://www.pythonpodcast.com/metaflow-machine-learning-operations-episode-274" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://mlflow.org/" target="_blank">MLFlow</a></li><li><a href="https://www.dask.org/" target="_blank">Dask</a><ul><li><a href="https://www.dataengineeringpodcast.com/episode-2-dask-with-matthew-rocklin" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.ray.io/" target="_blank">Ray</a><ul><li><a href="https://www.pythonpodcast.com/ray-distributed-computing-episode-258" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://spark.apache.org/" target="_blank">Spark</a></li><li><a href="https://www.databricks.com/" target="_blank">Databricks</a></li><li><a href="https://www.snowflake.com/en/" target="_blank">Snowflake</a></li><li><a href="https://argo-cd.readthedocs.io/en/stable/" target="_blank">ArgoCD</a></li><li><a href="https://pytorch.org/tutorials/beginner/dist_overview.html" target="_blank">PyTorch Distributed</a></li><li><a href="https://horovod.ai/" target="_blank">Horovod</a></li><li><a href="https://github.com/ggerganov/llama.cpp" target="_blank">Llama.cpp</a></li><li><a href="https://www.prefect.io/" target="_blank">Prefect</a><ul><li><a href="https://www.dataengineeringpodcast.com/prefect-workflow-engine-episode-86" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://airflow.apache.org/" target="_blank">Airflow</a></li><li><a href="https://en.wikipedia.org/wiki/Out_of_memory" target="_blank">OOM == Out of Memory</a></li><li><a href="https://wandb.ai/site/" target="_blank">Weights and Biases</a></li><li><a href="https://knative.dev/docs/" target="_blank">KNative</a></li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model" target="_blank">BERT</a> language model</li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">bd3e1488-da51-4aa8-afb1-962bc5866457</guid>
      <link>https://www.aiengineeringpodcast.com/runhouse-ml-infrastructure-simplified-episode-40</link>
      <pubDate>Mon, 11 Nov 2024 00:51:37 +0000</pubDate>
      <podcast:soundbite startTime="127.88" duration="18.88">And from your perspective of working in the space, working at Meta, where you've got exposure to very large scale and complex AI and ML workflows, what do you see as the core elements of infrastructure for these ML and AI capabilities and applications and maybe some of the ways that that's changed over the past few years?</podcast:soundbite>
      <podcast:soundbite startTime="802.07" duration="21.94">Another interesting aspect of the ML infrastructure space is that I think maybe around 2019, 2020, there was a large investment in the overall idea of MLOps and building largely a separate stack of infrastructure and suite of tools for that machine learning practitioner, distinct from the work that was being done in data engineering.</podcast:soundbite>
      <podcast:soundbite startTime="418.12" duration="22.33">And the curve ball that has really come in the last couple of years is the shift of a lot of the ML and AI focus from deep learning and your traditional linear aggression style ML workflows to now everything is transformer models, building off of these large language foundation models or multimodal models and being able to serve those for inference largely with some sort of context corpus.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:16:12</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>ML Infrastructure Without The Ops: Simplifying The ML Developer Experience With Runhouse</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>40</itunes:episode>
      <podcast:episode>40</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638668760280576680bd3e1488-da51-4aa8-afb1-962bc5866457v1.mp3" length="73164627" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638668760280576680bd3e1488-da51-4aa8-afb1-962bc5866457v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_bd3e1488-da51-4aa8-afb1-962bc5866457638668830908641018.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/bd3e1488-da51-4aa8-afb1-962bc5866457638668830890599277.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/bd3e1488-da51-4aa8-afb1-962bc5866457638668830887276432.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/greenbergdon/">Donnie Greenberg</podcast:person>
    </item>
    <item>
      <title>Building AI Systems on Postgres: An Inside Look at pgai Vectorizer</title>
      <description><![CDATA[Summary<br />With the growth of vector data as a core element of any AI application comes the need to keep those vectors up to date. When you go beyond prototypes and into production you will need a way to continue experimenting with new embedding models, chunking strategies, etc. You will also need a way to keep the embeddings up to date as your data changes. The team at Timescale created the pgai Vectorizer toolchain to let you manage that work in your Postgres database. In this episode Avthar Sewrathan explains how it works and how you can start using it today.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Avthar Sewrathan about the pgai extension for Postgres and how to run your AI workflows in your database</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what pgai Vectorizer is and the story behind it?</li><li>What are the benefits of using the database engine to execute AI workflows?<ul><li>What types of operations does pgai Vectorizer enable?</li><li>What are some common generative AI patterns that can't be done with pgai?</li></ul></li><li>AI applications require a large and complex set of dependencies. How does that work with pgai Vectorizer and the Python runtime in Postgres?<ul><li>What are some of the other challenges or system pressures that are introduced by running these AI workflows in the database context?</li></ul></li><li>Can you describe how the pgai extension is implemented?</li><li>With the rapid pace of change in the AI ecosystem, how has that informed the set of features that make sense in pgai Vectorizer and won't require rebuilding in 6 months?</li><li>Can you describe the workflow of using pgai Vectorizer to build and maintain a set of embeddings in their database?<ul><li>How can pgai Vectorizer help with the situation of migrating to a new embedding model and having to reindex all of the content?</li></ul></li><li>How do you think about the developer experience for people who are working with pgai Vectorizer, as compared to using e.g. LangChain, LlamaIndex, etc.?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen pgai Vectorizer used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on pgai Vectorizer?</li><li>When is pgai Vectorizer the wrong choice?</li><li>What do you have planned for the future of pgai Vectorizer?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/avthars/" target="_blank">LinkedIn</a></li><li><a href="https://avthar.com/" target="_blank">Website</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.timescale.com/" target="_blank">Timescale</a></li><li><a href="https://github.com/timescale/pgai" target="_blank">pgai</a></li><li><a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture" target="_blank">Transformer</a> architecture for deep learning</li><li><a href="https://en.wikipedia.org/wiki/Neural_network_(machine_learning" target="_blank">Neural Networks</a></li><li><a href="https://github.com/pgvector/pgvector" target="_blank">pgvector</a></li><li><a href="https://github.com/timescale/pgvectorscale" target="_blank">pgvectorscale</a></li><li><a href="https://modal.com/docs" target="_blank">Modal</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a></li><li><a href="https://en.wikipedia.org/wiki/Semantic_search" target="_blank">Semantic Search</a></li><li><a href="https://ollama.com/" target="_blank">Ollama</a></li><li><a href="https://neo4j.com/blog/graphrag-manifesto/" target="_blank">GraphRAG</a></li><li><a href="https://github.com/bitnine-oss/agensgraph" target="_blank">agensgraph</a></li><li><a href="https://www.langchain.com/" target="_blank">LangChain</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">LlamaIndex</a></li><li><a href="https://haystack.deepset.ai/" target="_blank">Haystack</a></li><li><a href="https://skyzh.github.io/write-you-a-vector-db/cpp-05-ivfflat.html" target="_blank">IVFFlat</a></li><li><a href="https://skyzh.github.io/write-you-a-vector-db/cpp-06-02-hnsw.html" target="_blank">HNSW</a></li><li><a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/09853c7fb1d3f8ee67a61b6bf4a7f8e6-Paper.pdf" target="_blank">DiskANN</a></li><li><a href="https://docs.replit.com/replitai/agent" target="_blank">Repl.it Agent</a></li><li><a href="https://en.wikipedia.org/wiki/Okapi_BM25" target="_blank">BM25</a></li><li><a href="https://www.postgresql.org/docs/current/datatype-textsearch.html#DATATYPE-TSVECTOR" target="_blank">TSVector</a></li><li><a href="https://www.paradedb.com/" target="_blank">ParadeDB</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">ed13d1c2-d85b-430b-9058-916a2fe48dae</guid>
      <link>https://www.aiengineeringpodcast.com/pgai-vectorizer-postgres-vector-embedding-episode-39</link>
      <pubDate>Mon, 11 Nov 2024 00:42:46 +0000</pubDate>
      <podcast:soundbite startTime="169.11" duration="26.88">Fantastic. So the story behind how it got started is actually really simple. Initially, we didn't actually set out to build PG dotai. We saw, there was an extension called PG Vector that was getting kind of popular, in late 2022, early 2023, and we decided to to support it on the timescale hosted product, and we thought that would be the end of the day. Hey. PG vector, it has vector search. That should be, you know, all you need to power these AI applications.</podcast:soundbite>
      <podcast:soundbite startTime="509.92" duration="35.10">That's a good question. And I think off the bat, I must say I 100% agree with you. It's kinda dangerous to run too many things on the same server as you're running a database because, you know, you want your database to be able to be performant and respond well to all the user load that is coming onto it. And so what we said is that, okay, what do you actually get from having your, embeddings running in the same place as your database is that you get the ability to manage your embedding creation and updating in the same place that your data actually lives.</podcast:soundbite>
      <podcast:soundbite startTime="2384.50" duration="31.92">I think there's a couple of interesting use cases that we've seen, PGAI, as a suite of tools used. I think the first one, I'll just talk about the PGAI extension. So one of the ways that someone used it was actually for moderation where they're running a I think it's some sort of blog or some sort of forum, and every message that they that a user posts gets, catalogued in a in a in a database table. And what they decided to do is to say, hey. What if we actually could make our moderation easier by automating that with LLMs?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:53:50</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Building AI Systems on Postgres: An Inside Look at pgai Vectorizer</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>39</itunes:episode>
      <podcast:episode>39</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638665426253011221ed13d1c2-d85b-430b-9058-916a2fe48daev1.mp3" length="51691673" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638665426253011221ed13d1c2-d85b-430b-9058-916a2fe48daev1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ed13d1c2-d85b-430b-9058-916a2fe48dae638665435110699734.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ed13d1c2-d85b-430b-9058-916a2fe48dae638665435107158784.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ed13d1c2-d85b-430b-9058-916a2fe48dae638665435103670317.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/avthars/">Avthar Sewrathan</podcast:person>
    </item>
    <item>
      <title>Running Generative AI Models In Production</title>
      <description><![CDATA[Summary<br />In this episode Philip Kiely from BaseTen talks about the intricacies of running open models in production. Philip shares his journey into AI and ML engineering, highlighting the importance of understanding product-level requirements and selecting the right model for deployment. The conversation covers the operational aspects of deploying AI models, including model evaluation, compound AI, and model serving frameworks such as TensorFlow Serving and AWS SageMaker. Philip also discusses the challenges of model quantization, rapid model evolution, and monitoring and observability in AI systems, offering valuable insights into the future trends in AI, including local inference and the competition between open source and proprietary models.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Philip Kiely about running open models in production</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by giving an overview of the major decisions to be made when planning the deployment of a generative AI model?</li><li>How does the model selected in the beginning of the process influence the downstream choices?</li><li>In terms of application architecture, the major patterns that I've seen are RAG, fine-tuning, multi-agent, or large model. What are the most common methods that you see? (and any that I failed to mention)<ul><li>How have the rapid succession of model generations impacted the ways that teams think about their overall application? (capabilities, features, architecture, etc.)</li></ul></li><li>In terms of model serving, I know that Baseten created Truss. What are some of the other notable options that teams are building with?<ul><li>What is the role of the serving framework in the context of the application?</li></ul></li><li>There are also a large number of inference engines that have been released. What are the major players in that arena?<ul><li>What are the features and capabilities that they are each basing their competitive advantage on?</li></ul></li><li>For someone who is new to AI Engineering, what are some heuristics that you would recommend when choosing an inference engine?</li><li>Once a model (or set of models) is in production and serving traffic it's necessary to have visibility into how it is performing. What are the key metrics that are necessary to monitor for generative AI systems?<ul><li>In the event that one (or more) metrics are trending negatively, what are the levers that teams can pull to improve them?</li></ul></li><li>When running models constructed with e.g. linear regression or deep learning there was a common issue with "concept drift". How does that manifest in the context of large language models, particularly when coupled with performance optimization?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen teams manage the serving of open gen AI models?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working with generative AI model serving?</li><li>When is Baseten the wrong choice?</li><li>What are the future trends and technology investments that you are focused on in the space of AI model serving?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/philipkiely/" target="_blank">LinkedIn</a></li><li><a href="https://x.com/philip_kiely" target="_blank">Twitter</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.baseten.co/" target="_blank">Baseten</a><ul><li><a href="https://www.aiengineeringpodcast.com/wrap-your-model-in-a-full-stack-application-in-an-afternoon-with-baseten" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Copyleft" target="_blank">Copyleft</a></li><li><a href="https://www.llama.com/" target="_blank">Llama Models</a></li><li><a href="https://www.nomic.ai/blog/posts/nomic-embed-text-v1" target="_blank">Nomic</a></li><li><a href="https://allenai.org/olmo" target="_blank">Olmo</a></li><li><a href="https://allenai.org/" target="_blank">Allen Institute for AI</a></li><li><a href="https://www.baseten.co/library/playground-v2-aesthetic/" target="_blank">Playground 2</a></li><li><a href="https://calmfund.com/thesis#:~:text=The%20Essential%20Ingredient%3A%20The%20Peace%20Dividend%20of%20the%20SaaS%20Wars&amp;text=A%20peace%20dividend%20refers%20to,put%20it%20to%20better%20uses." target="_blank">The Peace Dividend Of The SaaS Wars</a></li><li><a href="https://vercel.com/" target="_blank">Vercel</a></li><li><a href="https://www.netlify.com/" target="_blank">Netlify</a></li><li><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://www.baseten.co/blog/compound-ai-systems-explained/" target="_blank">Compound AI</a></li><li><a href="https://www.langchain.com/" target="_blank">Langchain</a></li><li><a href="https://github.com/dottxt-ai/outlines" target="_blank">Outlines</a> Structured output for AI systems</li><li><a href="https://docs.baseten.co/deploy/overview" target="_blank">Truss</a></li><li><a href="https://docs.baseten.co/chains/overview" target="_blank">Chains</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">Llamaindex</a></li><li><a href="https://www.ray.io/" target="_blank">Ray</a></li><li><a href="https://mlflow.org/" target="_blank">MLFlow</a></li><li><a href="https://github.com/replicate/cog" target="_blank">Cog</a> (Replicate) containers for ML</li><li><a href="https://www.bentoml.com/" target="_blank">BentoML</a></li><li><a href="https://www.djangoproject.com/" target="_blank">Django</a></li><li><a href="https://wsgi.readthedocs.io/en/latest/what.html" target="_blank">WSGI</a></li><li><a href="https://uwsgi-docs.readthedocs.io/en/latest/" target="_blank">uWSGI</a></li><li><a href="https://gunicorn.org/" target="_blank">Gunicorn</a></li><li><a href="https://zapier.com/" target="_blank">Zapier</a></li><li><a href="https://github.com/vllm-project/vllm" target="_blank">vLLM</a></li><li><a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank">TensorRT-LLM</a></li><li><a href="https://developer.nvidia.com/tensorrt" target="_blank">TensorRT</a></li><li><a href="https://www.baseten.co/blog/introduction-to-quantizing-ml-models/" target="_blank">Quantization</a></li><li><a href="https://arxiv.org/abs/2106.09685" target="_blank">LoRA</a> Low Rank Adaptation of Large Language Models</li><li><a href="https://en.wikipedia.org/wiki/Decision_tree_pruning" target="_blank">Pruning</a></li><li><a href="https://en.wikipedia.org/wiki/Knowledge_distillation" target="_blank">Distillation</a></li><li><a href="https://grafana.com/" target="_blank">Grafana</a></li><li><a href="https://pytorch.org/blog/hitchhikers-guide-speculative-decoding/" target="_blank">Speculative Decoding</a></li><li><a href="https://groq.com/" target="_blank">Groq</a></li><li><a href="https://www.runpod.io/" target="_blank">Runpod</a></li><li><a href="https://lambdalabs.com/" target="_blank">Lambda Labs</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">fb7787ba-54c5-4fa1-88ff-0391aba9a01a</guid>
      <link>https://www.aiengineeringpodcast.com/running-open-models-in-production-episode-38</link>
      <pubDate>Mon, 28 Oct 2024 00:03:01 +0000</pubDate>
      <podcast:soundbite startTime="1361.10" duration="18.90">Once you have settled on your model selection, you have your overall architecture and some of the logic built, you also have to tackle the question of the model serving framework. I know that at base 10, you've got the trust framework, and you also have chains, which was built on top of that.</podcast:soundbite>
      <podcast:soundbite startTime="753.67" duration="13.38">Well, first, you should probably go back to those evals like we were talking about earlier and see, hey, maybe 70 b is going to do exactly what I need as well, and then I get all those latency and cost benefits out of the box, and then I can go optimize it.</podcast:soundbite>
      <podcast:soundbite startTime="149.02" duration="14.11">You know, a truly open model is usually defined as open weights, open data, and open code. So you can see everything that went into it, you can see everything that went out of it, and you can see the process that got there.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:57:37</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Running Generative AI Models In Production</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>38</itunes:episode>
      <podcast:episode>38</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638656700325499663fb7787ba-54c5-4fa1-88ff-0391aba9a01av1.mp3" length="55316680" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638656700325499663fb7787ba-54c5-4fa1-88ff-0391aba9a01av1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_fb7787ba-54c5-4fa1-88ff-0391aba9a01a638656704288106992.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/fb7787ba-54c5-4fa1-88ff-0391aba9a01a638656704285082126.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/fb7787ba-54c5-4fa1-88ff-0391aba9a01a638656704282950765.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/philipkiely/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638656704089121917philip_kiely.jpg">Philip Kiely</podcast:person>
    </item>
    <item>
      <title>Enhancing AI Retrieval with Knowledge Graphs: A Deep Dive into GraphRAG</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast, Philip Rathle, CTO of Neo4J, talks about the intersection of knowledge graphs and AI retrieval systems, specifically Retrieval Augmented Generation (RAG). He delves into GraphRAG, a novel approach that combines knowledge graphs with vector-based similarity search to enhance generative AI models. Philip explains how GraphRAG works by integrating a graph database for structured data storage, providing more accurate and explainable AI responses, and addressing limitations of traditional retrieval systems. The conversation covers technical aspects such as data modeling, entity extraction, and ontology use cases, as well as the infrastructure and workflow required to support GraphRAG, setting the stage for innovative applications across various industries.<br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Philip Rathle about the application of knowledge graphs in AI retrieval systems</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what GraphRAG is?<ul><li>What are the capabilities that graph structures offer beyond vector/similarity-based retrieval methods of prompting?</li></ul></li><li>What are some examples of the ways that semantic limitations of nearest-neighbor vector retrieval fail to provide relevant results?</li><li>What are the technical requirements to implement graph-augmented retrieval?<ul><li>What are the concrete ways in which the embedding and retrieval steps of a typical RAG pipeline need to be modified to account for the addition of the graph?</li></ul></li><li>Many tutorials for building vector-based knowledge repositories skip over considerations around data modeling. For building a graph-based knowledge repository there obviously needs to be a bit more work put in. What are the key design choices that need to be made for implementing the graph for an AI application?<ul><li>How does the selection of the ontology/taxonomy impact the performance and capabilities of the resulting application?</li></ul></li><li>Building a fully functional knowledge graph can be a significant undertaking on its own. How can LLMs and AI models help with the construction and maintenance of that knowledge repository?<ul><li>What are some of the validation methods that should be brought to bear to ensure that the resulting graph properly represents the knowledge domain that you are trying to model?</li></ul></li><li>Vector embedding and retrieval are a core building block for a majority of AI application frameworks. How much support do you see for GraphRAG in the ecosystem?<ul><li>For the case where someone is using a framework that does not explicitly implement GraphRAG techniques, what are some of the implementation strategies that you have seen be most effective for adding that functionality?</li></ul></li><li>What are some of the ways that the combination of vector search and knowledge graphs are useful independent of their combination with language models?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen GraphRAG used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on GraphRAG applications?</li><li>When is GraphRAG the wrong choice?</li><li>What are the opportunities for improvement in the design and implementation of graph-based retrieval systems?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/prathle/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what are the biggest gaps in tooling, technology, or training for AI systems today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://neo4j.com/" target="_blank">Neo4J</a></li><li><a href="https://neo4j.com/blog/graphrag-manifesto/" target="_blank">GraphRAG Manifesto</a></li><li><a href="https://github.blog/ai-and-ml/generative-ai/what-is-retrieval-augmented-generation-and-what-does-it-do-for-generative-ai/" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Very_large_database" target="_blank">VLDB == Very Large DataBases</a></li><li><a href="https://en.wikipedia.org/wiki/Knowledge_graph" target="_blank">Knowledge Graph</a></li><li><a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search" target="_blank">Nearest Neighbor Search</a></li><li><a href="https://en.wikipedia.org/wiki/PageRank" target="_blank">PageRank</a></li><li><a href="https://blog.google/products/search/introducing-knowledge-graph-things-not/" target="_blank">Things Not Strings</a>) Google Knowledge Graph Paper</li><li><a href="https://github.com/pgvector/pgvector" target="_blank">pgvector</a></li><li><a href="https://www.pinecone.io/" target="_blank">Pinecone</a><ul><li><a href="https://www.dataengineeringpodcast.com/pinecone-vector-database-similarity-search-episode-189/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://neo4j.com/docs/getting-started/data-modeling/relational-to-graph-modeling/" target="_blank">Tables To Labels</a></li><li><a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank">NLP == Natural Language Processing</a></li><li><a href="https://graph.build/resources/ontology" target="_blank">Ontology</a></li><li><a href="https://www.langchain.com/" target="_blank">LangChain</a></li><li><a href="https://www.llamaindex.ai/" target="_blank">LlamaIndex</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank">RLHF == Reinforcement Learning with Human Feedback</a></li><li><a href="https://senzing.com/" target="_blank">Senzing</a></li><li><a href="https://neo4j.com/labs/genai-ecosystem/neoconverse/" target="_blank">NeoConverse</a></li><li><a href="https://en.wikipedia.org/wiki/Cypher_(query_language" target="_blank">Cypher</a> query language</li><li><a href="https://www.gqlstandards.org/" target="_blank">GQL</a> query standard</li><li><a href="https://aws.amazon.com/bedrock/" target="_blank">AWS Bedrock</a></li><li><a href="https://cloud.google.com/vertex-ai" target="_blank">Vertex AI</a></li><li><a href="https://www.sequoiacap.com/podcast/training-data-sebastian-siemiatkowski/" target="_blank">Sequoia Training Data - Klarna episode</a></li><li><a href="https://en.wikipedia.org/wiki/Ouroboros" target="_blank">Ouroboros</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">8b355c65-8ba8-4d98-a951-ba90dc34a2a9</guid>
      <link>https://www.aiengineeringpodcast.com/graphrag-knowledge-graph-semantic-retrieval-episode-37</link>
      <pubDate>Tue, 10 Sep 2024 01:32:14 +0000</pubDate>
      <podcast:soundbite startTime="50.74" duration="28.38">And do you remember how you first got involved in the data and machine learning space? Yeah. So I got involved with data long before I got involved with machine learning, and it was really my first job coming out of school. I was working doing, you know, a software project, and I would write queries, and then we would go to this DPA who would go and work some incomprehensible magic. And then the query would suddenly run a 100 times faster. I was like, wow. What's going on there?</podcast:soundbite>
      <podcast:soundbite startTime="587.70" duration="29.18">Another interesting aspect of the space of retrieval augmented generation is that a lot of the examples are very naive and simplistic of, oh, you just throw your document at this embedding function. It generates the vector representation. You store that in the database. And then when you go to retrieve something semantically proximate, you get the result back. But many of these vector databases also have capabilities to add additional metadata, apply filtering rules to the retrieval.</podcast:soundbite>
      <podcast:soundbite startTime="856.95" duration="39.44">Another aspect of this concept of filtering or graph traversal is the way that you think about modeling of the data. As I mentioned, a lot of the tutorials are very straightforward of you just feed your document into this embedding model, maybe do some chunk, size tuning, or maybe let the model do that for you, and then you pull the data back out. As we discussed, some of these different vector stores are adding more nuanced capabilities around metadata, various attributes that you can attach to those documents. If you're building a knowledge graph, that can be an entire project in and of itself, and data modeling is obviously very important.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:59:06</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Enhancing AI Retrieval with Knowledge Graphs: A Deep Dive into GraphRAG</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>37</itunes:episode>
      <podcast:episode>37</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386144015864977238b355c65-8ba8-4d98-a951-ba90dc34a2a9v1.mp3" length="56745103" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6386144015864977238b355c65-8ba8-4d98-a951-ba90dc34a2a9v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_8b355c65-8ba8-4d98-a951-ba90dc34a2a9638614403770445074.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/8b355c65-8ba8-4d98-a951-ba90dc34a2a9638614403762674716.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/8b355c65-8ba8-4d98-a951-ba90dc34a2a9638614403756038999.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/prathle/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638614403698257240philip_rathle.jpg">Philip Rathle</podcast:person>
    </item>
    <item>
      <title>Harnessing Generative AI for Effective Digital Advertising Campaigns</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast Praveen Gujar, Director of Product at LinkedIn, talks about the applications of generative AI in digital advertising. He highlights the key areas of digital advertising, including audience targeting, content creation, and ROI measurement, and delves into how generative AI is revolutionizing these aspects. Praveen shares successful case studies of generative AI in digital advertising, including campaigns by Heinz, the Barbie movie, and Maggi, and discusses the potential pitfalls and risks associated with AI-powered tools. He concludes with insights into the future of generative AI in digital advertising, highlighting the importance of cultural transformation and the synergy between human creativity and AI.<br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Praveen Gujar about the applications of generative AI in digital advertising</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by defining "digital advertising" for the scope of this conversation?<ul><li>What are the key elements/characteristics/goals of digital avertising?</li></ul></li><li>In the world before generative AI, what did a typical end-to-end advertising campaign workflow look like?<ul><li>What are the stages of that workflow where generative AI are proving to be most useful?<ul><li>How do the current limitations of generative AI (e.g. hallucinations, non-determinism) impact the ways in which they can be used?</li></ul></li></ul></li><li>What are the technological and organizational systems that need to be implemented to effectively apply generative AI in public-facing applications that are so closely tied to brand/company image?<ul><li>What are the elements of user education/expectation setting that are necessary when working with marketing/advertising personnel to help avoid damage to the brands?</li></ul></li><li>What are some examples of applications for generative AI in digital advertising that have gone well?<ul><li>Any that have gone wrong?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen generative AI used in digital advertising?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on digital advertising applications of generative AI?</li><li>When is generative AI the wrong choice?</li><li>What are your future predictions for the use of generative AI in dgital advertising?</li></ul>Contact Info<br /><ul><li><a href="https://www.praveengujar.com/" target="_blank">Website</a></li><li><a href="https://www.linkedin.com/in/praveengujar/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://generativeai.net/" target="_blank">Generative AI</a></li><li><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">LLM == Large Language Model</a></li><li><a href="https://openai.com/index/dall-e/" target="_blank">Dall-E</a>)</li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank">RLHF == Reinforcement Learning fHuman Feedback</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">652d37e9-80c2-45b3-8fc3-1dd8329dca7b</guid>
      <link>https://www.aiengineeringpodcast.com/praveen-gujar-generative-ai-digital-advertising-episode-36</link>
      <pubDate>Mon, 2 Sep 2024 16:17:37 +0000</pubDate>
      <podcast:soundbite startTime="1846.95" duration="40.76">I think, the challenging, thing basically is, number one thing, I was recently presenting in one of the marketing conference. And number one thing that I basically emphasized again and again, which has been a very key learning, we shouldn't think about, Gen AI or AI basically replacing human beings, but how, humans and AI can coexist and complement each other. What we have seen again and again with evidence is a combination of AI systems plus human creativity is a clear winner. I think this is the case where 1 plus 1 is 3 rather than 2.</podcast:soundbite>
      <podcast:soundbite startTime="39.60" duration="26.89">So to begin with, my name is Praveen Gujjar. I'm a director of product at LinkedIn, and, my expertise, involves digital advertising cloud, and, all of these areas are really powered by AI and generated AI systems as well. Over the course of last 15 years, I have been instrumental in building large scale enterprise products, in companies like LinkedIn, Amazon, as well as, Twitter.</podcast:soundbite>
      <podcast:soundbite startTime="266.57" duration="29.47">So if you break it down, digital advertising has a few key areas. One is targeting your audience, reaching them. Second one is reaching them with specific message at the time they are most active, and in the channel, they are most active. And when when we talk about channel today, you have, proliferation of devices that you use. You use TV. You use mobile. You use desktops. Reaching them in the right channel, in the social media or email or anything else is very relevant as well.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:41:49</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Harnessing Generative AI for Effective Digital Advertising Campaigns</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>36</itunes:episode>
      <podcast:episode>36</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638608236870238918652d37e9-80c2-45b3-8fc3-1dd8329dca7bv1.mp3" length="40155274" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638608236870238918652d37e9-80c2-45b3-8fc3-1dd8329dca7bv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_652d37e9-80c2-45b3-8fc3-1dd8329dca7b638608906989122809.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/652d37e9-80c2-45b3-8fc3-1dd8329dca7b638608906982943285.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/652d37e9-80c2-45b3-8fc3-1dd8329dca7b638608906976637886.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/praveengujar/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638565005910367050praveen_gujar.jpg">Praveen Gujar</podcast:person>
    </item>
    <item>
      <title>Building Scalable ML Systems on Kubernetes</title>
      <description><![CDATA[Summary<br />In this episode of the AI Engineering podcast, host Tobias Macy interviews Tammer Saleh, founder of SuperOrbital, about the potentials and pitfalls of using Kubernetes for machine learning workloads. The conversation delves into the specific needs of machine learning workflows, such as model tracking, versioning, and the use of Jupyter Notebooks, and how Kubernetes can support these tasks. Tammer emphasizes the importance of a unified API for different teams and the flexibility Kubernetes provides in handling various workloads. Finally, Tammer offers advice for teams considering Kubernetes for their machine learning workloads and discusses the future of Kubernetes in the ML ecosystem, including areas for improvement and innovation.<br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Tammer Saleh about the potentials and pitfalls of using Kubernetes for your ML workloads.</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in Kubernetes?</li><li>For someone who is unfamiliar with Kubernetes, how would you summarize it?</li><li>For the context of this conversation, can you describe the different phases of ML that we're talking about?</li><li>Kubernetes was originally designed to handle scaling and distribution of stateless processes. ML is an inherently stateful problem domain. What challenges does that add for K8s environments?</li><li>What are the elements of an ML workflow that lend themselves well to a Kubernetes environment?</li><li>How much Kubernetes knowledge does an ML/data engineer need to know to get their work done?</li><li>What are the sharp edges of Kubernetes in the context of ML projects?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working with Kubernetes?</li><li>When is Kubernetes the wrong choice for ML?</li><li>What are the aspects of Kubernetes (core or the ecosystem) that you are keeping an eye on which will help improve its utility for ML workloads?</li></ul>Contact Info<br /><ul><li><a target="_blank">Email</a></li><li><a href="https://www.linkedin.com/in/tammersaleh/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest gap in the tooling or technology for ML workloads today?</li></ul>Links<br /><ul><li><a href="https://superorbital.io" target="_blank">SuperOrbital</a></li><li><a href="https://www.cloudfoundry.org/" target="_blank">CloudFoundry</a></li><li><a href="https://www.heroku.com/" target="_blank">Heroku</a></li><li><a href="https://12factor.net/" target="_blank">12 Factor Model</a></li><li><a href="https://kubernetes.io/" target="_blank">Kubernetes</a></li><li><a href="https://docs.docker.com/compose/" target="_blank">Docker Compose</a></li><li><a href="https://superorbital.io/training/core-kubernetes/" target="_blank">Core K8s Class</a></li><li><a href="https://jupyter.org/" target="_blank">Jupyter Notebook</a></li><li><a href="https://www.crossplane.io/" target="_blank">Crossplane</a></li><li><a href="https://www.dndbeyond.com/monsters/16967-ochre-jelly" target="_blank">Ochre Jelly</a></li><li><a href="https://landscape.cncf.io/" target="_blank">CNCF (Cloud Native Computing Foundation) Landscape</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" target="_blank">Stateful Set</a></li><li><a href="https://github.blog/ai-and-ml/generative-ai/what-is-retrieval-augmented-generation-and-what-does-it-do-for-generative-ai/" target="_blank">RAG == Retrieval Augmented Generation</a><ul><li><a href="https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://www.kubeflow.org/" target="_blank">Kubeflow</a></li><li><a href="https://flyte.org/" target="_blank">Flyte</a><ul><li><a href="https://www.dataengineeringpodcast.com/flyte-data-orchestration-machine-learning-episode-291" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.pachyderm.com/" target="_blank">Pachyderm</a><ul><li><a href="https://www.dataengineeringpodcast.com/epsiode-1-pachyderm-with-daniel-whitenack" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.coreweave.com/" target="_blank">CoreWeave</a></li><li><a href="https://kubernetes.io/docs/reference/kubectl/" target="_blank">Kubectl ("koob-cuddle")</a></li><li><a href="https://helm.sh/" target="_blank">Helm</a></li><li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" target="_blank">CRD == Custom Resource Definition</a></li><li><a href="https://horovod.ai/" target="_blank">Horovod</a><ul><li><a href="https://www.pythonpodcast.com/ludwig-horovod-distributed-declarative-deep-learning-episode-341" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://temporal.io/" target="_blank">Temporal</a></li><li><a href="https://slurm.schedmd.com/overview.html" target="_blank">Slurm</a></li><li><a href="https://www.ray.io/" target="_blank">Ray</a></li><li><a href="https://www.dask.org/" target="_blank">Dask</a></li><li><a href="https://en.wikipedia.org/wiki/InfiniBand" target="_blank">Infiniband</a></li></ul>The intro and outro music is from <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Love_death_and_a_drunken_monkey/04_-_The_Hug" target="_blank">The Hug</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a> / <a href="http://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA</a>]]></description>
      <guid isPermaLink="false">2bf0c225-05ff-45be-8e75-5cc0243fc2b7</guid>
      <link>https://www.aiengineeringpodcast.com/kubernetes-for-machine-learning-episode-35</link>
      <pubDate>Thu, 15 Aug 2024 15:17:21 +0000</pubDate>
      <podcast:soundbite startTime="2735.84" duration="50.89">I think this is going to be I think this is really interesting because until now, the Kubernetes core team has kind of I don't wanna say rested on their laurels. They're all doing really hard work. But project has moved into a polish and fit phase, right, where the major features are pretty much done, and the core team has been focused on fixing all those those bugs, looking for rough edges, improving things like stateful workload management. But none of it's been, like, fundamental changes to Kubernetes. And I think that the ML industry is starting to push the boundaries of what the core team ever expected workflows to look like, and because of that, is gonna be putting pressure on the core team to go back to the drawing board for some of these larger features. It's gonna it's gonna force Kubernetes to evolve when Kubernetes had moved out of an evolution phase.</podcast:soundbite>
      <podcast:soundbite startTime="708.11" duration="28.96">The other interesting element of Kubernetes is that it it has become, I guess, the, the ochre jelly, if you will, of the cloud ecosystem where it just consumes everything that it touches and everything that comes in contact with it. And as a result, when people think Kubernetes and the inherent complexity that you already mentioned, that complexity balloons to encompass all of the things that Kubernetes has consumed in the process or that have become attached to it as a result.</podcast:soundbite>
      <podcast:soundbite startTime="244.35" duration="31.39">So, anyways, because of that, like, I kinda naturally transitioned into cloud and, moved into Pivotal, ran engineering for Pivotal Cloud Foundry, and then, formed SuperOrbital shortly after. With the ML workloads, it's really interesting. Now first of all, I just wanna say, like, I I'm not a lawyer. Right? I am not an ML engineer. That is not my trade. I I wrote a couple of neural networks when I was in college. Like, we've we've all tried neural nets in college. Right?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:50:22</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Building Scalable ML Systems on Kubernetes</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>35</itunes:episode>
      <podcast:episode>35</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385926065994753172bf0c225-05ff-45be-8e75-5cc0243fc2b7v1.mp3" length="48365749" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385926065994753172bf0c225-05ff-45be-8e75-5cc0243fc2b7v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_2bf0c225-05ff-45be-8e75-5cc0243fc2b7638593310891584452.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/2bf0c225-05ff-45be-8e75-5cc0243fc2b7638593310878867988.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/2bf0c225-05ff-45be-8e75-5cc0243fc2b7638593310873143606.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/tammersaleh/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638593276711694629tammer_saleh.jpg">Tammer Saleh</podcast:person>
    </item>
    <item>
      <title>Expert Insights On Retrieval Augmented Generation And How To Build It</title>
      <description><![CDATA[Summary<br />In this episode we're joined by Matt Zeiler, founder and CEO of Clarifai, as he dives into the technical aspects of retrieval augmented generation (RAG). From his journey into AI at the University of Toronto to founding one of the first deep learning AI companies, Matt shares his insights on the evolution of neural networks and generative models over the last 15 years. He explains how RAG addresses issues with large language models, including data staleness and hallucinations, by providing dynamic access to information through vector databases and embedding models. Throughout the conversation, Matt and host Tobias Macy discuss everything from architectural requirements to operational considerations, as well as the practical applications of RAG in industries like intelligence, healthcare, and finance. Tune in for a comprehensive look at RAG and its future trends in AI.<br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Matt Zeiler, Founder &amp; CEO of Clarifai, about the technical aspects of RAG, including the architectural requirements, edge cases, and evolutionary characteristics</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in the area of data management?</li><li>Can you describe what RAG (Retrieval Augmented Generation) is?</li><li>What are the contexts in which you would want to use RAG?</li><li>What are the alternatives to RAG?</li><li>What are the architectural/technical components that are required for production grade RAG?</li><li>Getting a quick proof-of-concept working for RAG is fairly straightforward. What are the failures modes/edge cases that start to surface as you scale the usage and complexity?</li><li>The first step of building the corpus for RAG is to generate the embeddings. Can you talk through the planning and design process? (e.g. model selection for embeddings, storage capacity/latency, etc.)</li><li>How does the modality of the input/output affect this and downstream decisions? (e.g. text vs. image vs. audio, etc.)</li><li>What are the features of a vector store that are most critical for RAG?</li><li>The set of available generative models is expanding and changing at breakneck speed. What are the foundational aspects that you look for in selecting which model(s) to use for the output?</li><li>Vector databases have been gaining ground for search functionality, even without generative AI. What are some of the other ways that elements of RAG can be re-purposed?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen RAG used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on RAG?</li><li>When is RAG the wrong choice?</li><li>What are the main trends that you are following for RAG and its component elements going forward?</li></ul>Contact Info<br /><ul><li><a href="https://www.matthewzeiler.com/" target="_blank">Website</a></li><li><a href="https://www.linkedin.com/in/mattzeiler/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. [Podcast.__init__]() covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.clarifai.com/" target="_blank">Clarifai</a></li><li><a href="http://www.cs.toronto.edu/~hinton/" target="_blank">Geoff Hinton</a></li><li><a href="https://yann.lecun.com/" target="_blank">Yann Lecun</a></li><li><a href="https://en.wikipedia.org/wiki/Neural_network_(machine_learning)" target="_blank">Neural Networks</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep Learning</a></li><li><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">Retrieval Augmented Generation</a></li><li><a href="https://medium.com/@crskilpatrick807/context-windows-the-short-term-memory-of-large-language-models-ab878fc6f9b5" target="_blank">Context Window</a></li><li><a href="https://en.wikipedia.org/wiki/Vector_database" target="_blank">Vector Database</a></li><li><a href="https://www.promptingguide.ai/" target="_blank">Prompt Engineering</a></li><li><a href="https://mistral.ai/" target="_blank">Mistral</a></li><li><a href="https://llama.meta.com/" target="_blank">Llama 3</a></li><li><a href="https://huggingface.co/blog/embedding-quantization" target="_blank">Embedding Quantization</a></li><li><a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" target="_blank">Active Learning</a></li><li><a href="https://deepmind.google/technologies/gemini/" target="_blank">Google Gemini</a></li><li><a href="https://en.wikipedia.org/wiki/Attention_(machine_learning)" target="_blank">AI Model Attention</a></li><li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" target="_blank">Recurrent Network</a></li><li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank">Convolutional Network</a></li><li><a href="https://medium.com/@ashpaklmulani/improve-retrieval-augmented-generation-rag-with-re-ranking-31799c670f8e" target="_blank">Reranking Model</a></li><li><a href="https://en.wikipedia.org/wiki/Stop_word" target="_blank">Stop Words</a></li><li><a href="https://huggingface.co/blog/mteb" target="_blank">Massive Text Embedding Benchmark (MTEB)</a></li><li><a href="https://retool.com/blog/state-of-ai-h1-2024" target="_blank">Retool State of AI Report</a></li><li><a href="https://github.com/pgvector/pgvector" target="_blank">pgvector</a></li><li><a href="https://milvus.io/" target="_blank">Milvus</a></li><li><a href="https://qdrant.tech/" target="_blank">Qdrant</a></li><li><a href="https://www.pinecone.io/" target="_blank">Pinecone</a></li><li><a href="https://huggingface.co/open-llm-leaderboard" target="_blank">OpenLLM Leaderboard</a></li><li><a href="https://en.wikipedia.org/wiki/Semantic_search" target="_blank">Semantic Search</a></li><li><a href="https://www.hashicorp.com/" target="_blank">Hashicorp</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">1c5152b9-c566-4436-97d8-b27753298092</guid>
      <link>https://www.aiengineeringpodcast.com/retrieval-augmented-generation-implementation-episode-34</link>
      <pubDate>Sun, 28 Jul 2024 20:10:28 +0000</pubDate>
      <podcast:soundbite startTime="88.08" duration="34.21">You mentioned that you kind of fell into machine learning and AI. You've been in it for a while now. Obviously, the thing that has sucked all of the air out of the room when anybody says AI is generative models, in particular, large language models. And I'm wondering, given your history in the space and the fact that you've been working in it for a while, what your perspective is on the utility and the lasting power of large language models and generative AI and the role that so called traditional AI or more statistical models plays in this current landscape?</podcast:soundbite>
      <podcast:soundbite startTime="613.07" duration="17.16">Digging further into that collection of tools that are being stitched together, can you give an overview of what you see as the typical architecture and the technical components for being able to actually bring RAG to bear and some of the operational considerations around that?</podcast:soundbite>
      <podcast:soundbite startTime="3286.76" duration="34.04">To that point, there's always the there's always a gradient of I can throw together a prototype really quickly, but I don't actually understand what's happening to I'm a subject matter expert in, in this case, machine learning, but maybe I don't have all the operational capabilities. What is the level of domain knowledge and expertise in that context of machine learning and AI that's necessary to be able to effectively apply these AI bottles and rag stacks to a problem domain and build a product around it.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:03:21</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Expert Insights On Retrieval Augmented Generation And How To Build It</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>34</itunes:episode>
      <podcast:episode>34</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385754419563965321c5152b9-c566-4436-97d8-b27753298092v1.mp3" length="60818316" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385754419563965321c5152b9-c566-4436-97d8-b27753298092v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_1c5152b9-c566-4436-97d8-b27753298092638577304341924222.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/1c5152b9-c566-4436-97d8-b27753298092638577304336506032.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/1c5152b9-c566-4436-97d8-b27753298092638577304334663140.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.matthewzeiler.com/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638577304268731421matt_zeiler.jpg">Matt Zeiler</podcast:person>
    </item>
    <item>
      <title>Barking Up The Wrong GPTree: Building Better AI With A Cognitive Approach</title>
      <description><![CDATA[Summary<br />Artificial intelligence has dominated the headlines for several months due to the successes of large language models. This has prompted numerous debates about the possibility of, and timeline for, artificial general intelligence (AGI). Peter Voss has dedicated decades of his life to the pursuit of truly intelligent software through the approach of cognitive AI. In this episode he explains his approach to building AI in a more human-like fashion and the emphasis on learning rather than statistical prediction.<br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Peter Voss about what is involved in making your AI applications more "human"</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by unpacking the idea of "human-like" AI?</li><li>How does that contrast with the conception of "AGI"?</li><li>The applications and limitations of GPT/LLM models have been dominating the popular conversation around AI. How do you see that impacting the overrall ecosystem of ML/AI applications and investment?</li><li>The fundamental/foundational challenge of every AI use case is sourcing appropriate data. What are the strategies that you have found useful to acquire, evaluate, and prepare data at an appropriate scale to build high quality models?&nbsp;</li><li>What are the opportunities and limitations of causal modeling techniques for generalized AI models?</li><li>As AI systems gain more sophistication there is a challenge with establishing and maintaining trust. What are the risks involved in deploying more human-level AI systems and monitoring their reliability?</li><li>What are the practical/architectural methods necessary to build more cognitive AI systems?</li><li>How would you characterize the ecosystem of tools/frameworks available for creating, evolving, and maintaining these applications?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen cognitive AI applied?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on desiging/developing cognitive AI systems?</li><li>When is cognitive AI the wrong choice?</li><li>What do you have planned for the future of cognitive AI applications at Aigo?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/vosspeter/" target="_blank">LinkedIn</a></li><li><a href="http://optimal.org/voss.html" target="_blank">Website</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://aigo.ai/" target="_blank">Aigo.ai</a></li><li><a href="https://aigo.ai/what-is-real-agi/" target="_blank">Artificial General Intelligence</a></li><li><a href="https://aigo.ai/cognitive-ai/" target="_blank">Cognitive AI</a></li><li><a href="https://en.wikipedia.org/wiki/Knowledge_graph" target="_blank">Knowledge Graph</a></li><li><a href="https://en.wikipedia.org/wiki/Causal_model" target="_blank">Causal Modeling</a></li><li><a href="https://en.wikipedia.org/wiki/Bayesian_statistics" target="_blank">Bayesian Statistics</a></li><li><a href="https://amzn.to/3UJKsmK" target="_blank">Thinking Fast &amp; Slow</a> by Daniel Kahneman (affiliate link)</li><li><a href="https://en.wikipedia.org/wiki/Agent-based_model" target="_blank">Agent-Based Modeling</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement Learning</a></li><li><a href="https://www.darpa.mil/about-us/darpa-perspective-on-ai" target="_blank">DARPA 3 Waves of AI</a> presentation</li><li><a href="https://arxiv.org/abs/2308.03598" target="_blank">Why Don't We Have AGI Yet?</a> whitepaper</li><li><a href="https://arxiv.org/abs/2309.01622" target="_blank">Concepts Is All You Need</a> Whitepaper</li><li><a href="https://en.wikipedia.org/wiki/Helen_Keller" target="_blank">Hellen Keller</a></li><li><a href="https://en.wikipedia.org/wiki/Stephen_Hawking" target="_blank">Stephen Hawking</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">5309f77c-df71-4a9a-9178-7c204480c4ef</guid>
      <link>https://www.aiengineeringpodcast.com/peter-voss-cognitive-ai-episode-33</link>
      <pubDate>Sun, 28 Jul 2024 20:10:14 +0000</pubDate>
      <podcast:soundbite startTime="1103.77" duration="38.01">So the approach that we're taking is basically saying your sense input is a computer desktop. You know? So you can basically have potentially very complex vision because you can be looking at a video. You can have a camera to the outside world. But you can also start with something much, much simpler in learning. So you can kind of gradually crank up the the resolution of vision that you have. And then the dexterity is basically a mouse and keyboard. And, you know, between those, you can interact with the world. So that is the approach we're taking.</podcast:soundbite>
      <podcast:soundbite startTime="153.44" duration="29.91">So what happened in the field of AI is that it really became narrow AI solving one problem at a time. So a good example of that would be Deep Blue, the IBM's world champion chess software, you know, whether it's container optimization or some medical diagnosis or whatever it might be, they're narrow problems that are solved. Even the go, you know, alpha go, it's just that one problem that that is being solved.</podcast:soundbite>
      <podcast:soundbite startTime="610.53" duration="33.85">So I think an AGI inherently has a lot of advantages over humans to avoid a lot of these mistakes. And, also, it it can plow through so much more information and double check things, whereas, you know, we wouldn't have the time, we wouldn't have the patience to do that. So I think, you know, we're in a much better place to have a robust system. And AGIs can, of course, also, check each other, which is also important because they may start off with different sources. They may have gone down a different path of understanding some particular problem.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:52:49</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Barking Up The Wrong GPTree: Building Better AI With A Cognitive Approach</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>33</itunes:episode>
      <podcast:episode>33</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385754412702070315309f77c-df71-4a9a-9178-7c204480c4efv1.mp3" length="50712237" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385754412702070315309f77c-df71-4a9a-9178-7c204480c4efv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_5309f77c-df71-4a9a-9178-7c204480c4ef638577941921108922.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5309f77c-df71-4a9a-9178-7c204480c4ef638577941917174948.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5309f77c-df71-4a9a-9178-7c204480c4ef638577941915219311.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/vosspeter/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638577941757631240peter_voss.jpg">Peter Voss</podcast:person>
    </item>
    <item>
      <title>Build Your Second Brain One Piece At A Time</title>
      <description><![CDATA[Summary<br />Generative AI promises to accelerate the productivity of human collaborators. Currently the primary way of working with these tools is through a conversational prompt, which is often cumbersome and unwieldy. In order to simplify the integration of AI capabilities into developer workflows Tsavo Knott helped create Pieces, a powerful collection of tools that complements the tools that developers already use. In this episode he explains the data collection and preparation process, the collection of model types and sizes that work together to power the experience, and how to incorporate it into your workflow to act as a second brain.<br /><br /><br />Announcements<br /><ul><li>Hello and welcome to the AI Engineering Podcast, your guide to the fast-moving world of building scalable and maintainable AI systems</li><li>Your host is Tobias Macey and today I'm interviewing Tsavo Knott about Pieces, a personal AI toolkit to improve the efficiency of developers</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Pieces is and the story behind it?</li><li>The past few months have seen an endless series of personalized AI tools launched. What are the features and focus of Pieces that might encourage someone to use it over the alternatives?</li><li>model selections</li><li>architecture of Pieces application</li><li>local vs. hybrid vs. online models</li><li>model update/delivery process</li><li>data preparation/serving for models in context of Pieces app</li><li>application of AI to developer workflows</li><li>types of workflows that people are building with pieces</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Pieces used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Pieces?</li><li>When is Pieces the wrong choice?</li><li>What do you have planned for the future of Pieces?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/tsavoknott/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. <a href="https://www.pythonpodcast.com" target="_blank">Podcast.__init__</a> covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.aiengineeringpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@aiengineeringpodcast.com with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://pieces.app/" target="_blank">Pieces</a></li><li><a href="https://en.wikipedia.org/wiki/AI_accelerator" target="_blank">NPU == Neural Processing Unit</a></li><li><a href="https://en.wikipedia.org/wiki/Google_Tensor" target="_blank">Tensor Chip</a></li><li><a href="https://github.com/microsoft/LoRA" target="_blank">LoRA == Low Rank Adaptation</a></li><li><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" target="_blank">Generative Adversarial Networks</a></li><li><a href="https://mistral.ai/" target="_blank">Mistral</a></li><li><a href="https://www.gnu.org/software/emacs/" target="_blank">Emacs</a></li><li><a href="https://www.vim.org/" target="_blank">Vim</a></li><li><a href="https://neovim.io/" target="_blank">NeoVim</a></li><li><a href="https://dart.dev/" target="_blank">Dart</a></li><li><a href="https://flutter.dev/" target="_blank">Flutter</a></li><li><a href="https://www.typescriptlang.org/" target="_blank">Typescript</a></li><li><a href="https://www.lua.org/" target="_blank">Lua</a></li><li><a href="https://github.blog/2024-04-04-what-is-retrieval-augmented-generation-and-what-does-it-do-for-generative-ai/" target="_blank">Retrieval Augmented Generation</a></li><li><a href="https://onnx.ai/" target="_blank">ONNX</a></li><li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank">LSTM == Long Short-Term Memory</a></li><li><a href="https://llama.meta.com/llama2/" target="_blank">LLama 2</a></li><li><a href="https://github.com/features/copilot" target="_blank">GitHub Copilot</a></li><li><a href="https://www.tabnine.com/" target="_blank">Tabnine</a></li><li><a href="https://www.themachinelearningpodcast.com/tabnine-generative-ai-developer-assistant-episode-24" target="_blank">Podcast Episode</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">ebccdc57-bfa8-42a5-800e-fa2cafe837d9</guid>
      <link>https://www.aiengineeringpodcast.com/episodepage/32</link>
      <pubDate>Sun, 28 Jul 2024 19:19:13 +0000</pubDate>
      <podcast:soundbite startTime="1940.94" duration="26.73">How do you think about what are the means that you are looking to for making this, monetizable so that you can actually justify the time and energy that it requires to build this whole system, and what are some of the ways that you can encourage engineers to use the platform without having fear that they are going to either end up getting priced out of it eventually or become the product eventually?</podcast:soundbite>
      <podcast:soundbite startTime="369.34" duration="33.59">There has been a lot of development and progress and churn in the overall space of personalized AI tools over the past few months to a year, particularly since the launch of Chat GPT and some of its different subsequent iterations. And I'm wondering what are some of the areas of focus of pieces and the capabilities that you're building into that that make it stand out from the alternatives and would encourage somebody to invest in integrating that into their workflow.</podcast:soundbite>
      <podcast:soundbite startTime="144.83" duration="18.28">I would say, you know, fundamentally, pieces is about changing the way that developers or professional creators at large interact with small bits of workflow material throughout that work in progress journey. Right? So if you think about it like developers, they're in 3 major locations, the browser, the IDE, and the collaborative environment.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:48:27</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build Your Second Brain One Piece At A Time</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>32</itunes:episode>
      <podcast:episode>32</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638577723125059337ebccdc57-bfa8-42a5-800e-fa2cafe837d9v1.mp3" length="46521640" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638577723125059337ebccdc57-bfa8-42a5-800e-fa2cafe837d9v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ebccdc57-bfa8-42a5-800e-fa2cafe837d9638577911454627214.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ebccdc57-bfa8-42a5-800e-fa2cafe837d9638577911451598917.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ebccdc57-bfa8-42a5-800e-fa2cafe837d9638577911449776412.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Guest" group="Cast" href="https://www.linkedin.com/in/tsavoknott/" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638577910973065655tsavo_knott.jpg">Tsavo Knott</podcast:person>
    </item>
    <item>
      <title>Strategies For Building A Product Using LLMs At DataChat</title>
      <description><![CDATA[Summary<br />Large Language Models (LLMs) have rapidly captured the attention of the world with their impressive capabilities. Unfortunately, they are often unpredictable and unreliable. This makes building a product based on their capabilities a unique challenge. Jignesh Patel is building DataChat to bring the capabilities of LLMs to organizational analytics, allowing anyone to have conversations with their business data. In this episode he shares the methods that he is using to build a product on top of this constantly shifting set of technologies.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Jignesh Patel about working with LLMs; understanding how they work and how to build your own</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by sharing some of the ways that you are working with LLMs currently?</li><li>What are the business challenges involved in building a product on top of an LLM model that you don't own or control?&nbsp;<ul><li>In the current age of business, your data is often your strategic advantage. How do you avoid losing control of, or leaking that data while interfacing with a hosted LLM API?</li></ul></li><li>What are the technical difficulties related to using an LLM as a core element of a product when they are largely a black box?&nbsp;<ul><li>What are some strategies for gaining visibility into the inner workings or decision making rules for these models?</li></ul></li><li>What are the factors, whether technical or organizational, that might motivate you to build your own LLM for a business or product?&nbsp;<ul><li>Can you unpack what it means to "build your own" when it comes to an LLM?</li></ul></li><li>In your work at DataChat, how has the progression of sophistication in LLM technology impacted your own product strategy?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen LLMs/DataChat used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working with LLMs?</li><li>When is an LLM the wrong choice?</li><li>What do you have planned for the future of DataChat?</li></ul>Contact Info<br /><ul><li><a href="https://jigneshpatel.org/" target="_blank">Website</a></li><li><a href="https://www.linkedin.com/in/jigneshmpatel/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://datachat.ai/" target="_blank">DataChat</a></li><li><a href="https://www.cmu.edu/" target="_blank">CMU == Carnegie Mellon University</a></li><li><a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank">SVM == Support Vector Machine</a></li><li><a href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence" target="_blank">Generative AI</a></li><li><a href="https://en.wikipedia.org/wiki/Genomics" target="_blank">Genomics</a></li><li><a href="https://en.wikipedia.org/wiki/Proteomics" target="_blank">Proteomics</a></li><li><a href="https://parquet.apache.org/" target="_blank">Parquet</a></li><li><a href="https://openai.com/blog/openai-codex" target="_blank">OpenAI Codex</a></li><li><a href="https://en.wikipedia.org/wiki/LLaMA" target="_blank">LLama</a></li><li><a href="https://mistral.ai/" target="_blank">Mistral</a></li><li><a href="https://cloud.google.com/vertex-ai" target="_blank">Google Vertex</a></li><li><a href="https://www.langchain.com/" target="_blank">Langchain</a></li><li><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">Retrieval Augmented Generation</a></li><li><a href="https://en.wikipedia.org/wiki/Prompt_engineering" target="_blank">Prompt Engineering</a></li><li><a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank">Ensemble Learning</a></li><li><a href="https://xgboost.readthedocs.io/en/stable/" target="_blank">XGBoost</a></li><li><a href="https://catboost.ai/" target="_blank">Catboost</a></li><li><a href="https://en.wikipedia.org/wiki/Linear_regression" target="_blank">Linear Regression</a></li><li><a href="https://www.investopedia.com/terms/c/cogs.asp" target="_blank">COGS == Cost Of Goods Sold</a></li><li><a href="https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html" target="_blank">Bruce Schneier - AI And Trust</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">f2db83e1-f565-4e25-aacb-0e50d463f055</guid>
      <link>https://www.aiengineeringpodcast.com/datachat-llm-product-business-episode-31</link>
      <pubDate>Sun, 3 Mar 2024 15:00:00 +0000</pubDate>
      <podcast:soundbite startTime="174.23" duration="31.75">So machine learning started for me back in those days mostly as a way in which to apply machine learning and apply machine learning on large volumes of data to get that insights. And, obviously, the machine learning methods back in those days, if you talk to any of the machine learning experts, they would have said, SVMs were the the algorithm and the framework to use, and everything could be solved with that. We obviously know things have passed, so you go through waves. And what was hot now is cold now, and maybe what is hot today might be cold, you know, a decade from now.</podcast:soundbite>
      <podcast:soundbite startTime="438.34" duration="28.17">We think of it as a toolbox in which the LLM is effectively a black box, and we learned that lesson the hard way. So in data chat today, if you ask a question against your data, you get a response back. But the processes that get carried out in a platform to generate that response has many steps. It's about a dozen steps now. And 1 of those 12 steps is going to be a call to an LLM. The rest of the magic comes from everything around it, and we'd have to treat that LLM as a black box.</podcast:soundbite>
      <podcast:soundbite startTime="2820.63" duration="31.24">So the basic things for which we were all excited about in big data, period, of being able to get information from data and carefully building all these methods and mechanisms to be able to ask questions on structured data, build these ETL pipelines, and stuff like that. I hope we don't lose track of how important that is because if you feed garbage in to an ML or Gen AI tool, you're gonna get garbage out. So that hard work that we have to keep doing is still necessary before you can use the power of any of these tools.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:48:41</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Strategies For Building A Product Using LLMs At DataChat</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>31</itunes:episode>
      <podcast:episode>31</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305382639202739073b4ea-08df-4d80-a57a-20c497e0da23v3.mp3" length="31492217" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305382639202739073b4ea-08df-4d80-a57a-20c497e0da23v3.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_9073b4ea-08df-4d80-a57a-20c497e0da23638558032789821698.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/9073b4ea-08df-4d80-a57a-20c497e0da23638558032786127574.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/9073b4ea-08df-4d80-a57a-20c497e0da23638558032783636904.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Improve The Success Rate Of Your Machine Learning Projects With bizML</title>
      <description><![CDATA[Summary<br />Machine learning is a powerful set of technologies, holding the potential to dramatically transform businesses across industries. Unfortunately, the implementation of ML projects often fail to achieve their intended goals. This failure is due to a lack of collaboration and investment across technological and organizational boundaries. To help improve the success rate of machine learning projects Eric Siegel developed the six step bizML framework, outlining the process to ensure that everyone understands the whole process of ML deployment. In this episode he shares the principles and promise of that framework and his motivation for encapsulating it in his book "The AI Playbook".<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Eric Siegel about how the bizML approach can help improve the success rate of your ML projects</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what bizML is and the story behind it?&nbsp;<ul><li>What are the key aspects of this approach that are different from the "industry standard" lifecycle of an ML project?</li></ul></li><li>What are the elements of your personal experience as an ML consultant that helped you develop the tenets of bizML?</li><li>Who are the personas that need to be involved in an ML project to increase the likelihood of success?&nbsp;<ul><li>Who do you find to be best suited to "own" or "lead" the process?</li></ul></li><li>What are the organizational patterns that might hinder the work of delivering on the goals of an ML initiative?</li><li>What are some of the misconceptions about the work involved in/capabilities of an ML model that you commonly encounter?</li><li>What is your main goal in writing your book "The AI Playbook"?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen the bizML process in action?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on ML projects and developing the bizML framework?</li><li>When is bizML the wrong choice?</li><li>What are the future developments in organizational and technical approaches to ML that will improve the success rate of AI projects?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/predictiveanalytics/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.machinelearningkeynote.com/the-ai-playbook" target="_blank">The AI Playbook</a>: Mastering the Rare Art of Machine Learning Deployment by Eric Siegel</li><li><a href="https://www.machinelearningkeynote.com/predictive-analytics" target="_blank">Predictive Analytics</a>: The Power to Predict Who Will Click, Buy, Lie, or Die by Eric Siegel</li><li><a href="https://www.columbia.edu/" target="_blank">Columbia University</a></li><li><a href="https://machinelearningweek.com/" target="_blank">Machine Learning Week Conference</a></li><li><a href="https://generativeaiworld.events/" target="_blank">Generative AI World</a></li><li><a href="https://www.predictiveanalyticsworld.com/machinelearningweek/workshops/machine-learning-course/" target="_blank">Machine Learning Leadership and Practice Course</a></li><li><a href="https://www.rexeranalytics.com/" target="_blank">Rexer Analytics</a></li><li><a href="https://www.kdnuggets.com/" target="_blank">KD Nuggets</a></li><li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a></li><li><a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank">Random Forest</a></li><li><a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank">Gradient Descent</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">005ebb79-3acb-4b13-b61f-9eb477728504</guid>
      <link>https://www.aiengineeringpodcast.com/bizml-machine-learning-business-process-episode-30</link>
      <pubDate>Sun, 18 Feb 2024 14:15:00 +0000</pubDate>
      <podcast:soundbite startTime="547.22" duration="29.33">I think it's also interesting to dig into that question of deployment because oftentimes, you say, oh, I've built this model. It can predict this thing based on these input values, but that doesn't necessarily encapsulate all of the other work that's necessary to productionize the model or the different systems that need to be able to interoperate with that model to get the desired outcome. And I'm wondering what are some of the shortcomings that you have seen in that conceptualization of what deployment even means.</podcast:soundbite>
      <podcast:soundbite startTime="2161.94" duration="66.00">And in your experience of working in this space, formulating this BizML process, working with customers and clients and people in your network to onboard them into this way of thought? What are some of the most interesting or innovative or unexpected ways that you've seen those ideas put into action? Well, you know, my my my favorite story is the 1 I lead and then actually kinda wrap up the book with, which is UPS, that dramatically improved the efficiency of their delivery of 16, 000, 000 packages a day. And Jack Levis so to sort of answer your previous question, here you have a guy who's not a data scientist, but obviously very savvy analytically. His title was senior director of process management, and he called it the project. He called it an, operations research project. Didn't call it machine learning. That job title and that term operations research is so boring. How are we gonna evangelize the world on the excitement of machine learning? Well, I don't know. But, look, sometimes value is more sexy. Right?</podcast:soundbite>
      <podcast:soundbite startTime="178.96" duration="38.22">Yeah. It's the 6 step practice playbook paradigm framework for running machine learning projects end to end so that they successfully deploy. You know, today, there is no established standardized practice for running these projects that's that's well known to business professionals, and it's really a business practice. In fact, in general, business professionals don't even realize there needs to be a specialized, very particular kind of business process that's well understood and collaboratively executed in order to make sure these models actually get deployed. And in fact, most new machine learning projects fail to achieve deployment.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:50:22</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Improve The Success Rate Of Your Machine Learning Projects With bizML</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>30</itunes:episode>
      <podcast:episode>30</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053865231438517725366-2c5b-484e-998b-591443f9a88bv1.mp3" length="35044755" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053865231438517725366-2c5b-484e-998b-591443f9a88bv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_17725366-2c5b-484e-998b-591443f9a88b638558032358335020.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/17725366-2c5b-484e-998b-591443f9a88b638558032354129769.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/17725366-2c5b-484e-998b-591443f9a88b638558032348174620.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Using Generative AI To Accelerate Feature Engineering At FeatureByte</title>
      <description><![CDATA[Summary<br />One of the most time consuming aspects of building a machine learning model is feature engineering. Generative AI offers the possibility of accelerating the discovery and creation of feature pipelines. In this episode Colin Priest explains how FeatureByte is applying generative AI models to the challenge of building and maintaining machine learning pipelines.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Colin Priest about applying generative AI to the task of building and deploying AI pipelines</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by giving the 30,000 foot view of the steps involved in an AI pipeline?&nbsp;<ul><li>Understand the problem</li><li>Feature ideation</li><li>Feature engineering</li><li>Experiment</li><li>Optimize</li><li>Productionize</li></ul></li><li>What are the stages of that process that are prone to repetition?&nbsp;<ul><li>What are the ways that teams typically try to automate those steps?</li></ul></li><li>What are the features of generative AI models that can be brought to bear on the design stage of an AI pipeline?&nbsp;<ul><li>What are the validation/verification processes that engineers need to apply to the generated suggestions?</li><li>What are the opportunities/limitations for unit/integration style tests?</li></ul></li><li>What are the elements of developer experience that need to be addressed to make the gen AI capabilities an enhancement instead of a distraction?&nbsp;<ul><li>What are the interfaces through which the AI functionality can/should be exposed?</li></ul></li><li>What are the aspects of pipeline and model deployment that can benefit from generative AI functionality?&nbsp;<ul><li>What are the potential risk factors that need to be considered when evaluating the application of this functionality?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen generative AI used in the development and maintenance of AI pipelines?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on the application of generative AI to the ML workflow?</li><li>When is generative AI the wrong choice?</li><li>What do you have planned for the future of FeatureByte's AI copilot capabiliteis?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/colinpriest/?originalSubdomain=sg" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://featurebyte.com/" target="_blank">FeatureByte</a></li><li><a href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence" target="_blank">Generative AI</a></li><li><a href="https://en.wikipedia.org/wiki/The_Art_of_War" target="_blank">The Art of War</a></li><li><a href="https://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank">OCR == Optical Character Recognition</a></li><li><a href="https://en.wikipedia.org/wiki/Genetic_algorithm" target="_blank">Genetic Algorithm</a></li><li><a href="https://en.wikipedia.org/wiki/Semantic_layer" target="_blank">Semantic Layer</a></li><li><a href="https://en.wikipedia.org/wiki/Prompt_engineering" target="_blank">Prompt Engineering</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a><br /><a href="https://machinelearning.supercast.com/" target="_blank">Support The Machine Learning Podcast</a>]]></description>
      <guid isPermaLink="false">ab8081e5-be14-4cef-b591-d644487f3702</guid>
      <link>https://www.aiengineeringpodcast.com/episodepage/29</link>
      <pubDate>Sun, 11 Feb 2024 22:00:00 +0000</pubDate>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:44:59</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Using Generative AI To Accelerate Feature Engineering At FeatureByte</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>29</itunes:episode>
      <podcast:episode>29</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053836951690244e27f34-de10-4f11-a76b-35cc95bef497.mp3" length="24464427" type="audio/mpeg" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Learn And Automate Critical Business Workflows With 8Flow</title>
      <description><![CDATA[Summary<br />Every business develops their own specific workflows to address their internal organizational needs. Not all of them are properly documented, or even visible. Workflow automation tools have tried to reduce the manual burden involved, but they are rigid and require substantial investment of time to discover and develop the routines. Boaz Hecht co-founded 8Flow to iteratively discover and automate pieces of workflows, bringing visibility and collaboration to the internal organizational processes that keep the business running.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Boaz Hecht about using AI to automate customer support at 8Flow</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what 8Flow is and the story behind it?</li><li>How does 8Flow compare to RPA tools that companies are using today?&nbsp;<ul><li>What are the opportunities for augmenting or integrating with RPA frameworks?</li></ul></li><li>What are the key selling points for the solution that you are building? (does AI sell? Or is it about the realized savings?)</li><li>What are the sources of signal that you are relying on to build model features?</li><li>Given the heterogeneity in tools and processes across customers, what are the common focal points that let you address the widest possible range of functionality?</li><li>Can you describe how 8Flow is implemented?&nbsp;<ul><li>How have the design and goals evolved since you first started working on it?</li></ul></li><li>What are the model categories that are most relevant for process automation in your product?</li><li>How have you approached the design and implementation of your MLOps workflow? (model training, deployment, monitoring, versioning, etc.)</li><li>What are the open questions around product focus and system design that you are still grappling with?</li><li>Given the relative recency of ML/AI as a profession and the massive growth in attention and activity, how are you addressing the challenge of obtaining and maximizing human talent?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen 8Flow used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on 8Flow?</li><li>When is 8Flow the wrong choice?</li><li>What do you have planned for the future of 8Flow?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/boazhecht/" target="_blank">LinkedIn</a></li><li><a href="https://boaz.org/" target="_blank">Personal Website</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://8flow.ai/" target="_blank">8Flow</a></li><li><a href="https://en.wikipedia.org/wiki/Robotic_process_automation" target="_blank">Robotic Process Automation</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a><br /><a href="https://machinelearning.supercast.com/" target="_blank">Support The Machine Learning Podcast</a>]]></description>
      <guid isPermaLink="false">d67fd8cb-e8e5-4360-81be-c89a9ee249d3</guid>
      <link>https://www.aiengineeringpodcast.com/8flow-business-workflow-automation-episode-28</link>
      <pubDate>Sun, 28 Jan 2024 23:00:00 +0000</pubDate>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:43:02</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Learn And Automate Critical Business Workflows With 8Flow</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>28</itunes:episode>
      <podcast:episode>28</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053862357184893285bc4-3975-462c-9730-58638e233517.mp3" length="27600147" type="audio/mpeg" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Considering The Ethical Responsibilities Of ML And AI Engineers</title>
      <description><![CDATA[Summary<br />Machine learning and AI applications hold the promise of drastically impacting every aspect of modern life. With that potential for profound change comes a responsibility for the creators of the technology to account for the ramifications of their work. In this episode Nicholas Cifuentes-Goodbody guides us through the minefields of social, technical, and ethical considerations that are necessary to ensure that this next generation of technical and economic systems are equitable and beneficial for the people that they impact.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Nicholas Cifuentes-Goodbody about the different elements of the machine learning workflow where ethics need to be considered</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>To start with, who is responsible for addressing the ethical concerns around AI?</li><li>What are the different ways that AI can have positive or negative outcomes from an ethical perspective?&nbsp;<ul><li>What is the role of practitioners/individual contributors in the identification and evaluation of ethical impacts of their work?</li></ul></li><li>What are some utilities that are helpful in identifying and addressing bias in training data?</li><li>How can practitioners address challenges of equity and accessibility in the delivery of AI products?</li><li>What are some of the options for reducing the energy consumption for training and serving AI?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen ML teams incorporate ethics into their work?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on ethical implications of ML?</li><li>What are some of the resources that you recommend for people who want to invest in their knowledge and application of ethics in the realm of ML?</li></ul>Contact Info<br /><ul><li><a href="https://www.wqu.edu/" target="_blank">WorldQuant University's Applied Data Science Lab</a></li><li><a href="https://www.linkedin.com/in/ncgoodbody/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://unesdoc.unesco.org/ark:/48223/pf0000381137" target="_blank">UNESCO Recommendation on the Ethics of Artificial Intelligence</a></li><li><a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target="_blank">European Union AI Act</a></li><li><a href="https://www.youtube.com/watch?v=epaowz3pI40" target="_blank">How machine learning helps advance access to human rights information</a></li><li><a href="https://www.haaretz.com/israel-news/security-aviation/2022-11-16/ty-article-static-ext/the-israelis-destabilizing-democracy-and-disrupting-elections-worldwide/00000186-461e-d80f-abff-6e9e08b10000" target="_blank">Disinformation, Team Jorge</a></li><li><a href="https://fsi-live.s3.us-west-1.amazonaws.com/s3fs-public/snapshot_vi-_countering_the_rise_of_digital_authoritarianism_0.pdf" target="_blank">China, AI, and Human Rights</a></li><li><a href="https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html" target="_blank">How China Is Using A.I. to Profile a Minority</a></li><li><a href="https://g.co/kgs/diKJwm" target="_blank">Weapons of Math Destruction</a></li><li><a href="https://fairlearn.org/" target="_blank">Fairlearn</a></li><li><a href="https://aif360.res.ibm.com/" target="_blank">AI Fairness 360</a></li><li><a href="https://www.nytimes.com/2023/10/19/technology/allen-institute-open-source-ai.html" target="_blank">Allen Institute for AI NYT</a></li><li><a href="https://allenai.org/" target="_blank">Allen Institute for AI</a></li><li><a href="https://huggingface.co/docs/transformers/index" target="_blank">Transformers</a></li><li><a href="https://ai-4-all.org/" target="_blank">AI4ALL</a></li><li><a href="https://wqu.edu/" target="_blank">WorldQuant University</a></li><li><a href="https://hbr.org/2023/07/how-to-make-generative-ai-greener" target="_blank">How to Make Generative AI Greener</a></li><li><a href="https://mlco2.github.io/impact/#compute" target="_blank">Machine Learning Emissions Calculator</a></li><li><a href="https://learning.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/" target="_blank">Practicing Trustworthy Machine Learning</a></li><li><a href="https://arxiv.org/abs/1906.02243" target="_blank">Energy and Policy Considerations for Deep Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank">Natural Language Processing</a></li><li><a href="https://en.wikipedia.org/wiki/Trolley_problem" target="_blank">Trolley Problem</a></li><li><a href="https://en.wikipedia.org/wiki/Protected_group" target="_blank">Protected Classes</a></li><li><a href="https://fairlearn.org/" target="_blank">fairlearn</a> (scikit-learn)</li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" target="_blank">BERT Model</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">76cadfbb-f0c5-429c-808d-512de30c9ec4</guid>
      <link>https://www.aiengineeringpodcast.com/ml-ai-ethical-considerations-episode-27</link>
      <pubDate>Sun, 28 Jan 2024 19:00:00 +0000</pubDate>
      <podcast:soundbite startTime="223.67" duration="32.37">And bringing us now to the question at hand of ethics and the ways that machine learning and AI can potentially be in conflict with or ways that you need to be thinking about the ethical implications of your work. Before we get too deep into ethical theories, the trolley problem, etcetera, who's responsible for identifying and addressing these concerns in the process of the ideation of what are we going to use AI for, how are we going to build it, how are we going to deliver it.</podcast:soundbite>
      <podcast:soundbite startTime="590.29" duration="24.04">And now digging into the models themselves, the impacts that they can have in the real world, we alluded to a toy example of acceptable ranges for a bank account. But what are some of the different ways that AI can and does have positive or negative impacts given the ways that ethics is or is not included in the development and deployment of those models?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:39:27</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Considering The Ethical Responsibilities Of ML And AI Engineers</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>27</itunes:episode>
      <podcast:episode>27</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538935475186ce719be1-47d3-4af9-a2ef-8b7c0ae2ca6fv2.mp3" length="24541066" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538935475186ce719be1-47d3-4af9-a2ef-8b7c0ae2ca6fv2.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ce719be1-47d3-4af9-a2ef-8b7c0ae2ca6f638558032178686221.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ce719be1-47d3-4af9-a2ef-8b7c0ae2ca6f638558032176377928.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ce719be1-47d3-4af9-a2ef-8b7c0ae2ca6f638558032174021809.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Build Intelligent Applications Faster With RelationalAI</title>
      <description><![CDATA[Summary<br />Building machine learning systems and other intelligent applications are a complex undertaking. This often requires retrieving data from a warehouse engine, adding an extra barrier to every workflow. The RelationalAI engine was built as a co-processor for your data warehouse that adds a greater degree of flexibility in the representation and analysis of the underlying information, simplifying the work involved. In this episode CEO Molham Aref explains how RelationalAI is designed, the capabilities that it adds to your data clouds, and how you can start using it to build more sophisticated applications on your data.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Molham Aref about RelationalAI and the principles behind it for powering intelligent applications</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what RelationalAI is and the story behind it?&nbsp;<ul><li>On your site you call your product an "AI Co-processor". Can you explain what you mean by that phrase?</li></ul></li><li>What are the primary use cases that you address with the RelationalAI product?&nbsp;<ul><li>What are the types of solutions that teams might build to address those problems in the absence of something like the RelationalAI engine?</li></ul></li><li>Can you describe the system design of RelationalAI?&nbsp;<ul><li>How have the design and goals of the platform changed since you first started working on it?</li></ul></li><li>For someone who is using RelationalAI to address a business need, what does the onboarding and implementation workflow look like?</li><li>What is your design philosophy for identifying the balance between automating the implementation of certain categories of application (e.g. NER) vs. providing building blocks and letting teams assemble them on their own?</li><li>What are the data modeling paradigms that teams should be aware of to make the best use of the RKGS platform and Rel language?</li><li>What are the aspects of customer education that you find yourself spending the most time on?</li><li>What are some of the most under-utilized or misunderstood capabilities of the RelationalAI platform that you think deserve more attention?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen the RelationalAI product used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on RelationalAI?</li><li>When is RelationalAI the wrong choice?</li><li>What do you have planned for the future of RelationalAI?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/molham/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://relational.ai/" target="_blank">RelationalAI</a></li><li><a href="https://www.snowflake.com/en/" target="_blank">Snowflake</a></li><li><a href="https://en.wikipedia.org/wiki/AI_winter" target="_blank">AI Winter</a></li><li><a href="https://cloud.google.com/bigquery" target="_blank">BigQuery</a></li><li><a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank">Gradient Descent</a></li><li><a href="https://en.wikipedia.org/wiki/B-tree" target="_blank">B-Tree</a></li><li><a href="https://en.wikipedia.org/wiki/Navigational_database" target="_blank">Navigational Database</a></li><li><a href="https://hadoop.apache.org/" target="_blank">Hadoop</a></li><li><a href="https://www.teradata.com/" target="_blank">Teradata</a></li><li><a href="https://relational.ai/blog/worst-case-optimal-join-algorithms-techniques-results-and-open-problems" target="_blank">Worst Case Optimal Join</a></li><li><a href="https://relational.ai/blog/semantic-optimizer" target="_blank">Semantic Query Optimization</a></li><li><a href="https://en.wikipedia.org/wiki/Relational_algebra" target="_blank">Relational Algebra</a></li><li><a href="https://en.wikipedia.org/wiki/Hypergraph" target="_blank">HyperGraph</a></li><li><a href="https://en.wikipedia.org/wiki/Linear_algebra" target="_blank">Linear Algebra</a></li><li><a href="https://en.wikipedia.org/wiki/Vector_database" target="_blank">Vector Database</a></li><li><a href="https://pathway.com/" target="_blank">Pathway</a><ul><li><a href="https://www.dataengineeringpodcast.com/pathway-database-that-thinks-episode-334/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.pinecone.io/" target="_blank">Pinecone</a><ul><li><a href="https://www.dataengineeringpodcast.com/pinecone-vector-database-similarity-search-episode-189/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">4b4bcf34-2eae-4fc2-9876-c16404db24af</guid>
      <link>https://www.aiengineeringpodcast.com/relational-ai-data-coprocessor-episode-26</link>
      <pubDate>Sun, 31 Dec 2023 03:00:00 +0000</pubDate>
      <podcast:soundbite startTime="3062.43" duration="8.74">And as you have been building this platform, building the business, what are the most interesting or unexpected or challenging lessons you've learned in the process?</podcast:soundbite>
      <podcast:soundbite startTime="1202.31" duration="16.53">So in terms of the actual platform that you're building, can you talk through what the system architecture looks like, some of the ways that you think about the technological underpinnings of the problem, and how you've approached that architectural design element?</podcast:soundbite>
      <podcast:soundbite startTime="165.12" duration="11.99">And now bringing us up to what you're building today with relational AI, can you give a bit of an overview about what that is and some of the story behind how it came to be and why this is where you wanna spend your time and energy?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:58:25</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build Intelligent Applications Faster With RelationalAI</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>26</itunes:episode>
      <podcast:episode>26</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538812200574770f88de-af2d-4b41-b125-75b348b8bae5v1.mp3" length="33182206" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538812200574770f88de-af2d-4b41-b125-75b348b8bae5v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_770f88de-af2d-4b41-b125-75b348b8bae5638558031649042804.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/770f88de-af2d-4b41-b125-75b348b8bae5638558031644109817.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/770f88de-af2d-4b41-b125-75b348b8bae5638558031642013429.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Building Better AI While Preserving User Privacy With TripleBlind</title>
      <description><![CDATA[Summary<br />Machine learning and generative AI systems have produced truly impressive capabilities. Unfortunately, many of these applications are not designed with the privacy of end-users in mind. TripleBlind is a platform focused on embedding privacy preserving techniques in the machine learning process to produce more user-friendly AI products. In this episode Gharib Gharibi explains how the current generation of applications can be susceptible to leaking user data and how to counteract those trends.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Gharib Gharibi about the challenges of bias and data privacy in generative AI models</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Generative AI has been gaining a lot of attention and speculation about its impact. What are some of the risks that these capabilities pose?&nbsp;<ul><li>What are the main contributing factors to their existing shortcomings?</li><li>What are some of the subtle ways that bias in the source data can manifest?</li></ul></li><li>In addition to inaccurate results, there is also a question of how user interactions might be re-purposed and potential impacts on data and personal privacy. What are the main sources of risk?</li><li>With the massive attention that generative AI has created and the perspectives that are being shaped by it, how do you see that impacting the general perception of other implementations of AI/ML?&nbsp;<ul><li>How can ML practitioners improve and convey the trustworthiness of their models to end users?</li><li>What are the risks for the industry if generative models fall out of favor with the public?</li></ul></li><li>How does your work at Tripleblind help to encourage a conscientious approach to AI?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen data privacy addressed in AI applications?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on privacy in AI?</li><li>When is TripleBlind the wrong choice?</li><li>What do you have planned for the future of TripleBlind?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/ggharibi/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://tripleblind.ai/" target="_blank">TripleBlind</a></li><li><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JicYPdAAAAAJ&amp;citation_for_view=JicYPdAAAAAJ:VN7nJs4JPk0C" target="_blank">ImageNet</a> Geoffrey Hinton Paper</li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" target="_blank">BERT</a> language model</li><li><a href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence" target="_blank">Generative AI</a></li><li><a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer" target="_blank">GPT == Generative Pre-trained Transformer</a></li><li><a href="https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html" target="_blank">HIPAA Safe Harbor Rules</a></li><li><a href="https://en.wikipedia.org/wiki/Federated_learning" target="_blank">Federated Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Differential_privacy" target="_blank">Differential Privacy</a></li><li><a href="https://en.wikipedia.org/wiki/Homomorphic_encryption" target="_blank">Homomorphic Encryption</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">dcafedc8-60b7-4382-abd9-1737054b76bd</guid>
      <link>https://www.aiengineeringpodcast.com/tripleblind-ai-user-privacy-episode-25</link>
      <pubDate>Wed, 22 Nov 2023 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="774.93" duration="20.63">So the risks here could be very serious. We need to be able to know where this data is collected, how is it being used, who has access to it. This data could be also repurposed, as you mentioned. You're not using my data to retrain your system, but maybe you are using it for targeted advertisement, for example. So it can have very serious implications.</podcast:soundbite>
      <podcast:soundbite startTime="395.27" duration="23.92">So I believe data algorithms and the oversight or the lack of oversight are the major reasons of hallucinations, knowledge cutoff, and not being able to cite their references. And as you said, they're very good at convincing generating very convincing, arguments. Right? Yeah. All you have to do is exude confidence that your answers are correct regardless of their actual factual basis.</podcast:soundbite>
      <podcast:soundbite startTime="639.43" duration="42.17">I believe, historically, our browsing data has been, like, a sensitive topic. But I believe today, our, chat history with chat GPT, for example, is probably way more sensitive than our browsing history. We're asking a lot of questions that could demonstrate our incompetency at work, for example. We are asking questions to, write a message or a letter to our significant other, maybe we are, not being very transparent that it was generated by AI. And if that piece of information was somehow leaked unintentionally, it can, cause some serious, some serious harms.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:46:54</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Building Better AI While Preserving User Privacy With TripleBlind</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>25</itunes:episode>
      <podcast:episode>25</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305386858341222aeb9164-6321-4df4-8945-60130f053694v2.mp3" length="31200314" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305386858341222aeb9164-6321-4df4-8945-60130f053694v2.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_2aeb9164-6321-4df4-8945-60130f053694638558031066002359.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/2aeb9164-6321-4df4-8945-60130f053694638558031063179148.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/2aeb9164-6321-4df4-8945-60130f053694638558031060043924.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Enhancing The Abilities Of Software Engineers With Generative AI At Tabnine</title>
      <description><![CDATA[Summary<br />Software development involves an interesting balance of creativity and repetition of patterns. Generative AI has accelerated the ability of developer tools to provide useful suggestions that speed up the work of engineers. Tabnine is one of the main platforms offering an AI powered assistant for software engineers. In this episode Eran Yahav shares the journey that he has taken in building this product and the ways that it enhances the ability of humans to get their work done, and when the humans have to adapt to the tool.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Eran Yahav about building an AI powered developer assistant at Tabnine</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Tabnine is and the story behind it?</li><li>What are the individual and organizational motivations for using AI to generate code?&nbsp;<ul><li>What are the real-world limitations of generative AI for creating software? (e.g. size/complexity of the outputs, naming conventions, etc.)</li><li>What are the elements of skepticism/oversight that developers need to exercise while using a system like Tabnine?</li></ul></li><li>What are some of the primary ways that developers interact with Tabnine during their development workflow?&nbsp;<ul><li>Are there any particular styles of software for which an AI is more appropriate/capable? (e.g. webapps vs. data pipelines vs. exploratory analysis, etc.)</li></ul></li><li>For natural languages there is a strong bias toward English in the current generation of LLMs. How does that translate into computer languages? (e.g. Python, Java, C++, etc.)</li><li>Can you describe the structure and implementation of Tabnine?&nbsp;<ul><li>Do you rely primarily on a single core model, or do you have multiple models with subspecialization?</li><li>How have the design and goals of the product changed since you first started working on it?</li></ul></li><li>What are the biggest challenges in building a custom LLM for code?&nbsp;<ul><li>What are the opportunities for specialization of the model architecture given the highly structured nature of the problem domain?</li></ul></li><li>For users of Tabnine, how do you assess/monitor the accuracy of recommendations?&nbsp;<ul><li>What are the feedback and reinforcement mechanisms for the model(s)?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen Tabnine's LLM powered coding assistant used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on AI assisted development at Tabnine?</li><li>When is an AI developer assistant the wrong choice?</li><li>What do you have planned for the future of Tabnine?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/eranyahav/?originalSubdomain=il" target="_blank">LinkedIn</a></li><li><a href="https://csaws.cs.technion.ac.il/%7Eyahave/" target="_blank">Website</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email hosts@themachinelearningpodcast.com) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.tabnine.com/" target="_blank">TabNine</a></li><li><a href="https://www.technion.ac.il/en/home-2/" target="_blank">Technion University</a></li><li><a href="https://en.wikipedia.org/wiki/Program_synthesis" target="_blank">Program Synthesis</a></li><li><a href="http://gptprompts.wikidot.com/context-stuffing" target="_blank">Context Stuffing</a></li><li><a href="https://elixir-lang.org/" target="_blank">Elixir</a></li><li><a href="https://en.wikipedia.org/wiki/Dependency_injection" target="_blank">Dependency Injection</a></li><li><a href="https://en.wikipedia.org/wiki/COBOL" target="_blank">COBOL</a></li><li><a href="https://en.wikipedia.org/wiki/Verilog" target="_blank">Verilog</a></li><li><a href="https://www.midjourney.com/home" target="_blank">MidJourney</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">2c55baa9-9509-4cff-99ff-7fc4cd7b76e8</guid>
      <link>https://www.aiengineeringpodcast.com/tabnine-generative-ai-developer-assistant-episode-24</link>
      <pubDate>Mon, 13 Nov 2023 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="490.56" duration="42.39">And so by being able to being able to reduce the total amount of time required to gain some of that context and knowledge, it allows that, subject matter expert to scale more effectively because they don't have to spend as much of their time on staring over somebody's shoulder while they write code and try to figure things out. Yeah. Absolutely. And it allows you to kind of get things right from the get go because you're getting help as you're generating the code. You may be generating in a way that will pass the review later. Right? So you it's not only that you get the expert knowledge. In a sense, you get the expert knowledge early enough, so you don't have to get rejected in code review and and redo, what you did. Right?</podcast:soundbite>
      <podcast:soundbite startTime="155.42" duration="71.01">And so for the Tab 9 project, can you describe a bit about what it is and some of the story behind how it came to be and why this is the problem that you want to spend your time and energy on? So Top 9 is an AI assistant for software development. It helps you with all software development maintenance tasks. It can help you generate code, generate test, generate documentation, review your code, and it will eventually help you drive the entire software development life cycle end to end using AI. So back, I think, in 2018, maybe, we were the first to bring AI code completions to market initially just in Java based on classical techniques. Let's call them more logic based and semantic techniques. But when we moved to use GPT based networks 2019 and extend the platform to support more native languages. Started by focusing on code completions because we saw that it's a good place to deliver a lot of value to developers. But the vision is much wider. I think it's pretty obvious now that the future of software development is AI driven. So, like, everything in software development is going to be assisted with AI.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:04:48</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Enhancing The Abilities Of Software Engineers With Generative AI At Tabnine</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>24</itunes:episode>
      <podcast:episode>24</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305391814178214a2ae2f2-3054-4952-a3aa-d0049cb51c4ev1.mp3" length="30190405" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305391814178214a2ae2f2-3054-4952-a3aa-d0049cb51c4ev1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_4a2ae2f2-3054-4952-a3aa-d0049cb51c4e638556314032238733.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/4a2ae2f2-3054-4952-a3aa-d0049cb51c4e638556314017841233.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/4a2ae2f2-3054-4952-a3aa-d0049cb51c4e638556313995613085.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
      <podcast:person role="Host" group="Cast" href="https://www.linkedin.com/in/eranyahav/?originalSubdomain=il">Eran Yahav</podcast:person>
    </item>
    <item>
      <title>Validating Machine Learning Systems For Safety Critical Applications With Ketryx</title>
      <description><![CDATA[Summary<br />Software systems power much of the modern world. For applications that impact the safety and well-being of people there is an extra set of precautions that need to be addressed before deploying to production. If machine learning and AI are part of that application then there is a greater need to validate the proper functionality of the models. In this episode Erez Kaminski shares the work that he is doing at Ketryx to make that validation easier to implement and incorporate into the ongoing maintenance of software and machine learning products.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Erez Kaminski about using machine learning in safety critical and highly regulated medical applications</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by describing some of the regulatory burdens placed on ML teams who are building solutions for medical applications?&nbsp;<ul><li>How do these requirements impact the development and validation processes of model design and development?</li></ul></li><li>What are some examples of the procedural and record-keeping aspects of the machine learning workflow that are required for FDA compliance?&nbsp;<ul><li>What are the opportunities for automating pieces of that overhead?</li></ul></li><li>Can you describe what you are doing at Ketryx to streamline the development/training/deployment of ML/AI applications for medical use cases?&nbsp;<ul><li>What are the ideas/assumptions that you had at the start of Ketryx that have been challenged/updated as you work with customers?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen ML used in medical applications?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Ketryx?</li><li>When is Ketryx the wrong choice?</li><li>What do you have planned for the future of Ketryx?</li></ul>Contact Info<br /><ul><li><a target="_blank">Email</a></li><li><a href="https://www.linkedin.com/in/erezkaminski/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers.</li></ul>Links<br /><ul><li><a href="https://www.ketryx.com/" target="_blank">Ketryx</a></li><li><a href="https://www.wolframalpha.com/" target="_blank">Wolfram Alpha</a></li><li><a href="https://www.wolfram.com/mathematica/" target="_blank">Mathematica</a></li><li><a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a></li><li><a href="https://www.cisa.gov/sbom" target="_blank">SBOM == Software Bill Of Materials</a></li><li><a href="https://en.wikipedia.org/wiki/Air_gap_(networking)" target="_blank">Air-gapped Systems</a></li><li><a href="https://en.wikipedia.org/wiki/AlexNet" target="_blank">AlexNet</a></li><li><a href="https://c3.ai/glossary/data-science/shapley-values/" target="_blank">Shapley Values</a></li><li><a href="https://github.com/shap/shap" target="_blank">SHAP</a><ul><li><a href="https://www.pythonpodcast.com/shap-explainable-machine-learning-episode-335/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank">Bayesian Statistics</a></li><li><a href="https://en.wikipedia.org/wiki/Causal_inference" target="_blank">Causal Modeling</a></li><li><a href="https://facebook.github.io/prophet/" target="_blank">Prophet</a></li><li><a href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-principles-software-validation" target="_blank">FDA Principles Of Software Validation</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">dd60b69a-2115-4c3c-b00f-b470011523fe</guid>
      <link>https://www.aiengineeringpodcast.com/ketryx-safety-critical-machine-learning-systems-episode-23</link>
      <pubDate>Wed, 8 Nov 2023 02:15:00 +0000</pubDate>
      <podcast:soundbite startTime="478.91" duration="52.35">That's such a good question, Tobias, and and it's actually the the first place where we started to work on on our company and and the product is how do we help people integrate open source software and, you know, kind of third party software into the regulated applications because it's it's complicated and people didn't use to develop with that much open source in the healthcare community, medical device community until kind of recently, and that's caused a lot of issues, right, because if you developed a medical device like 20 years ago, even a very advanced medical device, it would mostly have embedded software and a a very small amount of dependencies. And now, you know, you wanna spin up, some image classifier with TensorFlow. There's already a lot of dependencies going on in there. Could be, you know, in the many thousands easily. And I think there was it's it's it's not an impossible task.</podcast:soundbite>
      <podcast:soundbite startTime="191.86" duration="17.63">And the idea of safety critical, highly regulated systems is a massive area of active research and development in the software community, and I can only imagine at the additional levels of complexity that are involved when bringing ML into the equation.</podcast:soundbite>
      <podcast:soundbite startTime="2177.53" duration="5.14">As somebody who works in the software and technology industry, I'm constantly amazed that anything works.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:51:12</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Validating Machine Learning Systems For Safety Critical Applications With Ketryx</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>23</itunes:episode>
      <podcast:episode>23</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538396679611221335b8-9584-4f4c-8f8a-38bc6fe27fa5v2.mp3" length="28573474" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538396679611221335b8-9584-4f4c-8f8a-38bc6fe27fa5v2.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_221335b8-9584-4f4c-8f8a-38bc6fe27fa5638558030459889961.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/221335b8-9584-4f4c-8f8a-38bc6fe27fa5638558030456882166.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/221335b8-9584-4f4c-8f8a-38bc6fe27fa5638558030454108450.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Applying Declarative ML Techniques To Large Language Models For Better Results</title>
      <description><![CDATA[Summary<br />Large language models have gained a substantial amount of attention in the area of AI and machine learning. While they are impressive, there are many applications where they are not the best option. In this episode Piero Molino explains how declarative ML approaches allow you to make the best use of the available tools across use cases and data formats.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Piero Molino about the application of declarative ML in a world being dominated by large language models</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by summarizing your perspective on the effect that LLMs are having on the AI/ML industry?&nbsp;<ul><li>In a world where LLMs are being applied to a growing variety of use cases, what are the capabilities that they still lack?</li><li>How does declarative ML help to address those shortcomings?</li></ul></li><li>The majority of current hype is about commercial models (e.g. GPT-4). Can you summarize the current state of the ecosystem for open source LLMs?&nbsp;<ul><li>For teams who are investing in ML/AI capabilities, what are the sources of platform risk for LLMs?</li><li>What are the comparative benefits of using a declarative ML approach?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen LLMs used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on declarative ML in the age of LLMs?</li><li>When is an LLM the wrong choice?</li><li>What do you have planned for the future of declarative ML and Predibase?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/pieromolino/?locale=en_US" target="_blank">LinkedIn</a></li><li><a href="https://w4nderlu.st/" target="_blank">Website</a></li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Links<br /><ul><li><a href="https://predibase.com/" target="_blank">Predibase</a><ul><li><a href="https://www.themachinelearningpodcast.com/predibase-declarative-machine-learning-episode-4" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://ludwig.ai/latest/" target="_blank">Ludwig</a><ul><li><a href="https://www.pythonpodcast.com/ludwig-horovod-distributed-declarative-deep-learning-episode-341/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Recommender_system" target="_blank">Recommender Systems</a></li><li><a href="https://en.wikipedia.org/wiki/Information_retrieval" target="_blank">Information Retrieval</a></li><li><a href="https://thenewstack.io/what-is-a-real-vector-database/" target="_blank">Vector Database</a></li><li><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank">Transformer Model</a></li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" target="_blank">BERT</a></li><li><a href="https://www.linkedin.com/pulse/whats-context-window-anyway-caitie-doogan-phd/" target="_blank">Context Windows</a></li><li><a href="https://en.wikipedia.org/wiki/LLaMA" target="_blank">LLAMA</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">0a46e74a-ba2f-4163-b217-bfa5d06c670d</guid>
      <link>https://www.aiengineeringpodcast.com/predibase-declarative-ml-large-language-models-episode-22</link>
      <pubDate>Tue, 24 Oct 2023 23:00:00 +0000</pubDate>
      <podcast:soundbite startTime="1632.54" duration="112.14">The other thing that is brought up a lot for people who are actually working with large language models, even just recreationally, is the the challenge of hallucination where the models just completely forget what it is that they're trying to do, or they, base successive predictions on faulty information. And I'm wondering what you have seen as some of the useful mechanisms for being able to identify the occurrence of those hallucinations and, potentially counteract them or ways to, prevent those hallucinations from occurring in the first place? Yeah. So the those are like a big problem. I actually don't really like the term hallucination, because it makes you look like it's a bug while it's definitely a feature of these models. That's how they are trained. That's what they are supposed to do, really, generating text, so, you know, I wouldn't consider it. It is a bug in the term in in terms of what we want this model to do, but it's not a bug in terms of what they are supposed to do. So it is a big issue though. In particular, there's a lot of work that has been going on on the alignment side to try to limit, but it's kinda like a a a whack a mole, if you want. You identify areas where models, confidently provide answers and kinda address them partially through, like, multi hop reasoning and multi hop kind of interactions and, like, constitutional approaches to make to to limit the impact of it. I don't think anyone has found yet a mechanism for guaranteeing any, avoiding the problem altogether.</podcast:soundbite>
      <podcast:soundbite startTime="574.32" duration="38.76">On that point of open source models, the providers that brought about this initial wave of excitement, particularly in the general community, is the OpenAI, chat GPT, and GPT series of models. But as you mentioned, there are a number of open source offerings that have been fast followers and that are focusing on different niche use cases or different specific applications. I'm wondering if you can give a summary of your understanding of what that open source model landscape looks like and some of the ways that those models are looking to differentiate from OpenAI in particular, but also the other commercial, LLM providers.</podcast:soundbite>
      <podcast:soundbite startTime="202.46" duration="58.82">Yeah. It's certainly like a pretty big effect from many perspectives. On 1 hand, you have the fact that companies that before companies and also individuals that before were not thinking at AI at all or they were not thinking about it as something to pay attention to immediately or they were thinking about it as something futuristic that eventually they would have started to consider. Now by the availability of something like ChargeGPT and interfaces, they make it pretty tangible that these models have capabilities that are particularly useful for solving tasks and also for just interacting with with with data that opened up the possibility set of possibilities and imagination of people and companies. From the perspective of someone building machine learning tooling that made it so that there's way more people that now are interested in the space and way more demand.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:46:11</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Applying Declarative ML Techniques To Large Language Models For Better Results</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>22</itunes:episode>
      <podcast:episode>22</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539114707768c7ecb5b9-c120-4bd6-ba6e-b039eb8f5063v1.mp3" length="28038565" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539114707768c7ecb5b9-c120-4bd6-ba6e-b039eb8f5063v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_c7ecb5b9-c120-4bd6-ba6e-b039eb8f5063638558029337087696.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c7ecb5b9-c120-4bd6-ba6e-b039eb8f5063638558029321388185.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/c7ecb5b9-c120-4bd6-ba6e-b039eb8f5063638558029318452835.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Surveying The Landscape Of AI and ML From An Investor's Perspective</title>
      <description><![CDATA[Summary<br />Artificial Intelligence is experiencing a renaissance in the wake of breakthrough natural language models. With new businesses sprouting up to address the various needs of ML and AI teams across the industry, it is a constant challenge to stay informed. Matt Turck has been compiling a report on the state of ML, AI, and Data for his work at FirstMark Capital. In this episode he shares his findings on the ML and AI landscape and the interesting trends that are developing.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>As more people start using AI for projects, two things are clear: It’s a rapidly advancing field, but it’s tough to navigate. How can you get the best results for your use case? Instead of being subjected to a bunch of buzzword bingo, hear directly from pioneers in the developer and data science space on how they use graph tech to build AI-powered apps. . Attend the dev and ML talks at NODES 2023, a free online conference on October 26 featuring some of the brightest minds in tech. Check out the agenda and register today at <a href="https://Neo4j.com/NODES" target="_blank">Neo4j.com/NODES</a>.</li><li>Your host is Tobias Macey and today I'm interviewing Matt Turck about his work on the MAD (ML, AI, and Data) landscape and the insights he has gained on the ML ecosystem</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what the MAD landscape project is and the story behind it?</li><li>What are the major changes in the ML ecosystem that you have seen since you first started compiling the landscape?&nbsp;<ul><li>How have the developments in consumer-grade AI in recent years changed the business opportunities for ML/AI?</li></ul></li><li>What are the coarse divisions that you see as the boundaries that define the different categories for ML/AI in the landscape?</li><li>For ML infrastructure products/companies, what are the biggest challenges that they face in engineering and customer acquisition?</li><li>What are some of the challenges in building momentum for startups in AI (existing moats around data access, talent acquisition, etc.)?&nbsp;<ul><li>For products/companies that have ML/AI as their core offering, what are some strategies that they use to compete with "big tech" companies that already have a large corpus of data?</li></ul></li><li>What do you see as the societal vs. business importance of open source models as AI becomes more integrated into consumer facing products?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen ML/AI used in business and social contexts?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on the ML/AI elements of the MAD landscape?</li><li>When is ML/AI the wrong choice for businesses?</li><li>What are the areas of ML/AI that you are paying closest attention to in your own work?</li></ul>Contact Info<br /><ul><li><a href="https://mattturck.com/" target="_blank">Website</a></li><li><a href="https://twitter.com/mattturck" target="_blank">@mattturck</a> on Twitter</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://mad.firstmark.com/" target="_blank">MAD Landscape</a><ul><li><a href="https://www.dataengineeringpodcast.com/mad-landscape-2023-data-infrastructure-episode-369" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://firstmark.com/" target="_blank">First Mark Capital</a></li><li><a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank">Bayesian Techniques</a></li><li><a href="https://hadoop.apache.org/" target="_blank">Hadoop</a></li><li><a href="https://chat.openai.com/" target="_blank">ChatGPT</a></li><li><a href="https://news.agpt.co/" target="_blank">AutoGPT</a></li><li><a href="https://www.dataiku.com/" target="_blank">Dataiku</a></li><li><a href="https://generativeai.net/" target="_blank">Generative AI</a></li><li><a href="https://www.databricks.com/" target="_blank">Databricks</a></li><li><a href="https://ml-ops.org/" target="_blank">MLOps</a></li><li><a href="https://openai.com/" target="_blank">OpenAI</a></li><li><a href="https://www.anthropic.com/" target="_blank">Anthropic</a></li><li><a href="https://www.deepmind.com/" target="_blank">DeepMind</a></li><li><a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/" target="_blank">BloombergGPT</a></li><li><a href="https://huggingface.co/" target="_blank">HuggingFace</a></li><li><a href="https://www.imdb.com/title/tt9354944/" target="_blank">Jexi</a> Movie</li><li><a href="https://www.imdb.com/title/tt1798709/?ref_=fn_al_tt_1" target="_blank">"Her"</a> Movie</li><li><a href="https://www.synthesia.io/" target="_blank">Synthesia</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">a0bc589f-21ef-4f72-b094-248c122ae367</guid>
      <link>https://www.aiengineeringpodcast.com/mad-landscape-2023-ml-ai-episode-21</link>
      <pubDate>Sun, 15 Oct 2023 17:00:00 +0000</pubDate>
      <podcast:soundbite startTime="2341.17" duration="49.26">Yeah. I think open source is usually important, not for just, like, business reasons and technical reasons, but also most, like, society level kind of reasons. So, you know, the the the reasons why, OpenAI doesn't open up their models are, well, not publicized. You know, there's debate there, but, you know, certainly, that's that's rational for saying that there's some risk involved there. But we do need open source as a counterbalance to whatever power is going to be, accumulated by OpenAI and even, you know, further power accumulated by the big tech company. So I think that I think that's I think that's really important. That's certainly why, companies like Hugging Face are going to be immensely important to the ecosystem, even more so than they are now as the home of open source ML and AI.</podcast:soundbite>
      <podcast:soundbite startTime="70.22" duration="23.67">So, Matt, can you start by introducing yourself? Yeah. Absolutely. Thanks for having me. As you know, I'm a big fan of your work. So, my name is Matt Turk. I am a partner at Firstmark, which is an early stage venture firm based in New York. And, over the last, 10 or 15 years, I've been heavily focused on the world of data, data infrastructure, machine learning, and AI.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:02:34</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Surveying The Landscape Of AI and ML From An Investor's Perspective</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>21</itunes:episode>
      <podcast:episode>21</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053842947419628edf171-2056-418e-a006-422bc7015420v1.mp3" length="30432700" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053842947419628edf171-2056-418e-a006-422bc7015420v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_28edf171-2056-418e-a006-422bc7015420638558029075270558.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/28edf171-2056-418e-a006-422bc7015420638558029071863049.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/28edf171-2056-418e-a006-422bc7015420638558029068215707.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Applying Federated Machine Learning To Sensitive Healthcare Data At Rhino Health</title>
      <description><![CDATA[Summary<br />A core challenge of machine learning systems is getting access to quality data. This often means centralizing information in a single system, but that is impractical in highly regulated industries, such as healthchare. To address this hurdle Rhino Health is building a platform for federated learning on health data, so that everyone can maintain data privacy while benefiting from AI capabilities. In this episode Ittai Dayan explains the barriers to ML in healthcare and how they have designed the Rhino platform to overcome them.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Ittai Dayan about using federated learning at Rhino Health to bring AI capabilities to the tightly regulated healthcare industry</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Rhino Health is and the story behind it?</li><li>What is federated learning and what are the trade-offs that it introduces?&nbsp;<ul><li>What are the benefits to healthcare and pharmalogical organizations from using federated learning?</li></ul></li><li>What are some of the challenges that you face in validating that patient data is properly de-identified in the federated models?</li><li>Can you describe what the Rhino Health platform offers and how it is implemented?&nbsp;<ul><li>How have the design and goals of the system changed since you started working on it?</li></ul></li><li>What are the technological capabilities that are needed for an organization to be able to start using Rhino Health to gain insights into their patient and clinical data?&nbsp;<ul><li>How have you approached the design of your product to reduce the effort to onboard new customers and solutions?</li></ul></li><li>What are some examples of the types of automation that you are able to provide to your customers? (e.g. medical diagnosis, radiology review, health outcome predictions, etc.)</li><li>What are the ethical and regulatory challenges that you have had to address in the development of your platform?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Rhino Health used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Rhino Health?</li><li>When is Rhino Health the wrong choice?</li><li>What do you have planned for the future of Rhino Health?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/ittai-dayan/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.rhinohealth.com/" target="_blank">Rhino Health</a></li><li><a href="https://en.wikipedia.org/wiki/Federated_learning" target="_blank">Federated Learning</a></li><li><a href="https://www.nvidia.com/en-us/clara/" target="_blank">Nvidia Clara</a></li><li><a href="https://www.nvidia.com/en-us/data-center/dgx-platform/" target="_blank">Nvidia DGX</a></li><li><a href="https://www.melloddy.eu/" target="_blank">Melloddy</a></li><li><a href="https://github.com/flairNLP/flair" target="_blank">Flair NLP</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">57f350c9-4d8f-47be-8958-b5f96de28c21</guid>
      <link>https://www.aiengineeringpodcast.com/rhino-health-federated-machine-learning-episode-20</link>
      <pubDate>Mon, 11 Sep 2023 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="18.96" duration="11.38">Your host is Tobias Macy, and today I'm interviewing Ittai Dayan about using federated learning at Rhino Health to bring AI capabilities to the tightly regulated health care industry. So, Itay, can you start by introducing yourself?</podcast:soundbite>
      <podcast:soundbite startTime="731.97" duration="36.24">So federated learning is, I guess, a meta framework to machine learning frameworks. It is a an iterative process in which you train algorithms locally. You share the weights from these algorithms, with a global orchestrator. The global orchestrator blends these weights using averaging or other techniques, Then it in turn updates the algorithms that are local. It runs an additional epoch or however you defined until you reach an optimized model.</podcast:soundbite>
      <podcast:soundbite startTime="244.67" duration="23.21">We ran the study. The study actually happened much faster than I would have imagined. I think we got all sites signed up maybe 6 weeks and a few weeks later we already had an experiment running. Also due to our partners from NVIDIA we're using the early platform for federated learning called Clara FL and so clearly we were very excited about it.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:49:54</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Applying Federated Machine Learning To Sensitive Healthcare Data At Rhino Health</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>20</itunes:episode>
      <podcast:episode>20</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305390837444175f3a257b-7901-4160-b9c0-aebd58c9e101v1.mp3" length="32467510" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305390837444175f3a257b-7901-4160-b9c0-aebd58c9e101v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_5f3a257b-7901-4160-b9c0-aebd58c9e101638558028606399420.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5f3a257b-7901-4160-b9c0-aebd58c9e101638558028603589896.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/5f3a257b-7901-4160-b9c0-aebd58c9e101638558028601235032.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Using Machine Learning To Keep An Eye On The Planet</title>
      <description><![CDATA[Summary<br />Satellite imagery has given us a new perspective on our world, but it is limited by the field of view for the cameras. Synthetic Aperture Radar (SAR) allows for collecting images through clouds and in the dark, giving us a more consistent means of collecting data. In order to identify interesting details in such a vast amount of data it is necessary to use the power of machine learning. ICEYE has a fleet of satellites continuously collecting information about our planet. In this episode Tapio Friberg shares how they are applying ML to that data set to provide useful insights about fires, floods, and other terrestrial phenomena.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Tapio Friberg about building machine learning applications on top of SAR (Synthetic Aperture Radar) data to generate insights about our planet</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what ICEYE is and the story behind it?</li><li>What are some of the applications of ML at ICEYE?</li><li>What are some of the ways that SAR data poses a unique challenge to ML applications?</li><li>What are some of the elements of the ML workflow that you are able to use "off the shelf" and where are the areas that you have had to build custom solutions?</li><li>Can you share the structure of your engineering team and the role that the ML function plays in the larger organization?</li><li>What does the end-to-end workflow for your ML model development and deployment look like?&nbsp;<ul><li>What are the operational requirements for your models? (e.g. batch execution, real-time, interactive inference, etc.)</li></ul></li><li>In the model definitions, what are the elements of the source domain that create the largest challenges? (e.g. noise from backscatter, variance in resolution, etc.)</li><li>Once you have an output from an ML model how do you manage mapping between data domains to reflect insights from SAR sources onto a human understandable representation?</li><li>Given that SAR data and earth imaging is still a very niche domain, how does that influence your ability to hire for open positions and the ways that you think about your contributions to the overall ML ecosystem?</li><li>How can your work on using SAR as a representation of physical attributes help to improve capabilities in e.g. LIDAR, computer vision, etc.?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen ICEYE and SAR data used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on ML for SAR data?</li><li>What do you have planned for the future of ML applications at ICEYE?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/tapio-friberg-319212235/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.iceye.com/" target="_blank">ICEYE</a></li><li><a href="https://en.wikipedia.org/wiki/Synthetic-aperture_radar" target="_blank">SAR == Synthetic Aperture Radar</a></li><li><a href="https://en.wikipedia.org/wiki/Transfer_learning" target="_blank">Transfer Learning</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">8c85d226-2b6c-49f5-a849-a2d99c16896f</guid>
      <link>https://www.aiengineeringpodcast.com/iceye-ml-on-synthetic-aperture-radar-episode-19</link>
      <pubDate>Sat, 17 Jun 2023 14:00:00 +0000</pubDate>
      <podcast:soundbite startTime="128.04" duration="24.03">And also with the radar imagery, we are able to image through clouds and through through darkness. So there is no single time in the day or no weather conditions that we cannot observe. So for example, we have emitted through active volcanoes through the ash plume. We have witnessed extreme flooding through a hurricane and we have observed during a multi month cloudy season under Amazon rainforest.</podcast:soundbite>
      <podcast:soundbite startTime="1639.03" duration="16.86">So, what this looks like for an outside observer is that it looks like that there's a flying train, 50 meters away from the, train track. And that's just something that it's not an artifact in the sense that it's something that we did wrong. It's an artifact in the in that sense that that's just how the SORINs works.</podcast:soundbite>
      <podcast:soundbite startTime="305.32" duration="28.11">You know, I I often heard that there's, like, a discourse, about the challenges of Earth observation. And then quite often, the discourse turns into the amount of data. So everybody is saying that we have so much data and it's always terabytes of, data and 100 of millions of pixels and and this and this and this. But I never thought of that as a real challenge, or it is a real challenge but it's also the price of admission. So those problems, if you cannot solve those problems, you're already out of the game.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:42:33</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Using Machine Learning To Keep An Eye On The Planet</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>19</itunes:episode>
      <podcast:episode>19</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305393042659183f775db8-c78e-4c35-b6b7-ed11926df657v1.mp3" length="34749796" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305393042659183f775db8-c78e-4c35-b6b7-ed11926df657v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_3f775db8-c78e-4c35-b6b7-ed11926df657638558028169237870.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/3f775db8-c78e-4c35-b6b7-ed11926df657638558028166476882.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/3f775db8-c78e-4c35-b6b7-ed11926df657638558028163549427.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>The Role Of Model Development In Machine Learning Systems</title>
      <description><![CDATA[Summary<br />The focus of machine learning projects has long been the model that is built in the process. As AI powered applications grow in popularity and power, the model is just the beginning. In this episode Josh Tobin shares his experience from his time as a machine learning researcher up to his current work as a founder at Gantry, and the shift in focus from model development to machine learning systems.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Josh Tobin about the state of industry best practices for designing and building ML models</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by describing what a "traditional" process for building a model looks like?&nbsp;<ul><li>What are the forces that shaped those "best practices"?</li></ul></li><li>What are some of the practices that are still necessary/useful and what is becoming outdated?&nbsp;<ul><li>What are the changes in the ecosystem (tooling, research, communal knowledge, etc.) that are forcing teams to reconsider how they think about modeling?</li></ul></li><li>What are the most critical practices/capabilities for teams who are building services powered by ML/AI?&nbsp;<ul><li>What systems do they need to support them in those efforts?</li></ul></li><li>Can you describe what you are building at Gantry and how it aids in the process of developing/deploying/maintaining models with "modern" workflows?</li><li>What are the most challenging aspects of building a platform that supports ML teams in their workflows?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen teams approach model development/validation?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Gantry?</li><li>When is Gantry the wrong choice?</li><li>What are some of the resources that you find most helpful to stay apprised of how modeling and ML practices are evolving?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/josh-tobin-4b3b10a9/" target="_blank">LinkedIn</a></li><li><a href="http://josh-tobin.com/" target="_blank">Website</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://gantry.io/" target="_blank">Gantry</a></li><li><a href="https://fullstackdeeplearning.com/" target="_blank">Full Stack Deep Learning</a></li><li><a href="https://openai.com/" target="_blank">OpenAI</a></li><li><a href="https://www.kaggle.com/" target="_blank">Kaggle</a></li><li><a href="https://nips.cc/" target="_blank">NeurIPS == Neural Information Processing Systems Conference</a></li><li><a href="https://caffe.berkeleyvision.org/" target="_blank">Caffe</a></li><li><a href="https://github.com/Theano/Theano" target="_blank">Theano</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep Learning</a></li><li><a href="https://www.analyticsvidhya.com/blog/2022/01/different-types-of-regression-models/" target="_blank">Regression Model</a></li><li><a href="https://scikit-learn.org/" target="_blank">scikit-learn</a></li><li><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">Large Language Model</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_models" target="_blank">Foundation Models</a></li><li><a href="https://cohere.com/" target="_blank">Cohere</a></li><li><a href="https://en.wikipedia.org/wiki/Federated_learning" target="_blank">Federated Learning</a></li><li><a href="https://www.featurestore.org/" target="_blank">Feature Store</a></li><li><a href="https://www.getdbt.com/" target="_blank">dbt</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">87095652-f90b-4ea1-9534-644010cbd32c</guid>
      <link>https://www.aiengineeringpodcast.com/gantry-ml-model-development-episode-18</link>
      <pubDate>Mon, 29 May 2023 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="364.94" duration="31.96">And then the other piece that I'm interested in digging into is on that question of machine learning kind of as an analytics function versus machine learning being the product. And I think that might be the more interesting angle to go down right now and kind of what you see as being some of the pivotal forces that have moved us from the the idea of, you know, static analytics to predictive analytics to prescriptive analytics to now machine learning being the actual product that people are interacting with versus just a kind of sidecar function.</podcast:soundbite>
      <podcast:soundbite startTime="91.12" duration="25.40">And so the topic at hand is around the practice of modeling and what that really means in the current ML ecosystem and climate. And before we get too far down the road, I'm wondering if you can just start by giving what your sense of a so called traditional process for building a model looks like and some of the forces that helped to shape those, so called best practices at the time that they were established.</podcast:soundbite>
      <podcast:soundbite startTime="1564.55" duration="20.94">And so in terms of what you're building at Gantry, I'm curious if you can talk through some of the capabilities that you're providing and what you see as being the support structure that is necessary and useful for teams to be able to actually incorporate these models into their systems and be confident that they are doing what they want them to do?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:46:41</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>The Role Of Model Development In Machine Learning Systems</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>18</itunes:episode>
      <podcast:episode>18</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538775267270f3f16b20-e0b3-48ed-ac7e-6dee25e44376v6.mp3" length="33466610" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538775267270f3f16b20-e0b3-48ed-ac7e-6dee25e44376v6.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_f3f16b20-e0b3-48ed-ac7e-6dee25e44376638557328646479625.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/f3f16b20-e0b3-48ed-ac7e-6dee25e44376638557328642002344.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/f3f16b20-e0b3-48ed-ac7e-6dee25e44376638557328639261016.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Real-Time Machine Learning Has Entered The Realm Of The Possible</title>
      <description><![CDATA[Summary<br />Machine learning models have predominantly been built and updated in a batch modality. While this is operationally simpler, it doesn't always provide the best experience or capabilities for end users of the model. Tecton has been investing in the infrastructure and workflows that enable building and updating ML models with real-time data to allow you to react to real-world events as they happen. In this episode CTO Kevin Stumpf explores they benefits of real-time machine learning and the systems that are necessary to support the development and maintenance of those models.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Kevin Stumpf about the challenges and promise of real-time ML applications</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what real-time ML is and some examples of where it might be applied?</li><li>What are the operational and organizational requirements for being able to adopt real-time approaches for ML projects?</li><li>What are some of the ways that real-time requirements influence the scale/scope/architecture of an ML model?</li><li>What are some of the failure modes for real-time vs analytical or operational ML?</li><li>Given the low latency between source/input data being generated or received and a prediction being generated, how does that influence susceptibility to e.g. data drift?&nbsp;<ul><li>Data quality and accuracy also become more critical. What are some of the validation strategies that teams need to consider as they move to real-time?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen real-time ML applied?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on real-time ML systems?</li><li>When is real-time the wrong choice for ML?</li><li>What do you have planned for the future of real-time support for ML in Tecton?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/kevinstumpf/" target="_blank">LinkedIn</a></li><li><a href="https://twitter.com/kevinmstumpf?lang=en" target="_blank">@kevinmstumpf</a> on Twitter</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.tecton.ai/" target="_blank">Tecton</a><ul><li><a href="https://www.themachinelearningpodcast.com/tecton-machine-learning-feature-platform-episode-6/" target="_blank">Podcast Episode</a></li><li><a href="https://www.dataengineeringpodcast.com/tecton-mlops-feature-store-episode-166/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/" target="_blank">Uber Michelangelo</a></li><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Online_machine_learning" target="_blank">Online Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank">Random Forest</a></li><li><a href="https://openai.com/blog/chatgpt" target="_blank">ChatGPT</a></li><li><a href="https://xgboost.ai/" target="_blank">XGBoost</a></li><li><a href="https://en.wikipedia.org/wiki/Linear_regression" target="_blank">Linear Regression</a></li><li><a href="https://ploomber.io/blog/train-serve-skew/" target="_blank">Train-Serve Skew</a></li><li><a href="https://flink.apache.org/" target="_blank">Flink</a><ul><li><a href="https://www.dataengineeringpodcast.com/apache-flink-with-fabian-hueske-episode-57/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">4fdaba79-a772-428b-a47c-e35a32a77606</guid>
      <link>https://www.aiengineeringpodcast.com/tecton-real-time-machine-learning-episode-17</link>
      <pubDate>Thu, 9 Mar 2023 22:00:00 +0000</pubDate>
      <podcast:soundbite startTime="181.45" duration="33.87">And common examples here are, like, real time transaction fraud detection where somebody's swapping a credit card somewhere, and it's either immediately denied or accepted, or it's real time recommendations where the items that you've just clicked on in Amazon affect the next recommendations that you get on the page that you're gonna browse a couple seconds later, or dynamic pricing systems, which react to the movements of supply and demand literally in the moment.</podcast:soundbite>
      <podcast:soundbite startTime="985.27" duration="57.37">And as far as that kind of train, serve, skew challenge, it also feeds back into the question of data quality, particularly in an ML context where the quality of the data is a huge predictor of the quality of the output model. And I'm curious how teams are addressing some of the question of how to, you know, identify the critical elements of what quality data looks like for a given model and some of the kind of monitoring and ongoing validation that needs to be performed as new data as is fed into the platform so that you can, for instance, maybe, you know, shunt bad data into a dev letter queue to be reconsidered or, you know, factored into updated experimentation and to some of the aspects of kind of ongoing validation and maintenance of the model as it continues to serve without having to kind of take it down for maintenance or have it be spitting bad, you know, bad predictions for x period of time without being aware of it.</podcast:soundbite>
      <podcast:soundbite startTime="457.66" duration="42.56">And so typically what you'd find is that you either have, like trios of people like a data scientist and, data engineer and a software engineer work together or some lucky organization have them all baked into 1 in the form of a machine learning engineer. Some platforms, like, obviously, Tekton, is trying to make that significantly easier so you don't need as many folks with different backgrounds and whatnot to, to actually power real time machine learning. But good indicators that your organization is actually ready for real time ML is that you can already spin out APIs and services with ease, and you follow DevOps best practices already, and all that stuff is is not very, very foreign to you.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:34:30</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Real-Time Machine Learning Has Entered The Realm Of The Possible</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>17</itunes:episode>
      <podcast:episode>17</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538549358146df1881a1-5ea8-4c1c-9696-4bb4499b91ecv2.mp3" length="18373945" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538549358146df1881a1-5ea8-4c1c-9696-4bb4499b91ecv2.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_df1881a1-5ea8-4c1c-9696-4bb4499b91ec638557328418706281.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/df1881a1-5ea8-4c1c-9696-4bb4499b91ec638557328416488773.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/df1881a1-5ea8-4c1c-9696-4bb4499b91ec638557328412896483.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>How Shopify Built A Machine Learning Platform That Encourages Experimentation</title>
      <description><![CDATA[Summary<br />Shopify uses machine learning to power multiple features in their platform. In order to reduce the amount of effort required to develop and deploy models they have invested in building an opinionated platform for their engineers. They have gone through multiple iterations of the platform and their most recent version is called Merlin. In this episode Isaac Vidas shares the use cases that they are optimizing for, how it integrates into the rest of their data platform, and how they have designed it to let machine learning engineers experiment freely and safely.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Isaac Vidas about his work on the ML platform used by Shopify</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Shopify is and some of the ways that you are using ML at Shopify?&nbsp;<ul><li>What are the challenges that you have encountered as an organization in applying ML to your business needs?</li></ul></li><li>Can you describe how you have designed your current technical platform for supporting ML workloads?&nbsp;<ul><li>Who are the target personas for this platform?</li><li>What does the workflow look like for a given data scientist/ML engineer/etc.?</li></ul></li><li>What are the capabilities that you are trying to optimize for in your current platform?&nbsp;<ul><li>What are some of the previous iterations of ML infrastructure and process that you have built?</li><li>What are the most useful lessons that you gathered from those previous experiences that informed your current approach?</li></ul></li><li>How have the capabilities of the Merlin platform influenced the ways that ML is viewed and applied across Shopify?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Merlin used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Merlin?</li><li>When is Merlin the wrong choice?</li><li>What do you have planned for the future of Merlin?</li></ul>Contact Info<br /><ul><li><a href="https://twitter.com/kazuarous" target="_blank">@kazuaros</a> on Twitter</li><li><a href="https://www.linkedin.com/in/isaac-vidas/" target="_blank">LinkedIn</a></li><li><a href="https://github.com/kazuar" target="_blank">kazuar</a> on GitHub</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.shopify.com/" target="_blank">Shopify</a></li><li><a href="https://shopify.engineering/merlin-shopify-machine-learning-platform" target="_blank">Shopify Merlin</a></li><li><a href="https://cloud.google.com/vertex-ai" target="_blank">Vertex AI</a></li><li><a href="https://scikit-learn.org/stable/" target="_blank">scikit-learn</a></li><li><a href="https://xgboost.ai/" target="_blank">XGBoost</a></li><li><a href="https://docs.ray.io/en/latest/" target="_blank">Ray</a><ul><li><a href="https://www.pythonpodcast.com/ray-distributed-computing-episode-258/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://spark.apache.org/docs/latest/api/python/" target="_blank">PySpark</a></li><li><a href="https://en.wikipedia.org/wiki/GPT-3" target="_blank">GPT-3</a></li><li><a href="https://openai.com/blog/chatgpt/" target="_blank">ChatGPT</a></li><li><a href="https://ai.google/" target="_blank">Google AI</a></li><li><a href="https://pytorch.org/" target="_blank">PyTorch</a><ul><li><a href="https://www.pythonpodcast.com/pytorch-deep-learning-epsiode-202/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://www.dask.org/" target="_blank">Dask</a></li><li><a href="https://modin.readthedocs.io/en/stable/" target="_blank">Modin</a><ul><li><a href="https://www.pythonpodcast.com/modin-parallel-dataframe-episode-324/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://flink.apache.org/" target="_blank">Flink</a><ul><li><a href="https://www.dataengineeringpodcast.com/apache-flink-with-fabian-hueske-episode-57/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://feast.dev/" target="_blank">Feast Feature Store</a></li><li><a href="https://kubernetes.io/" target="_blank">Kubernetes</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">bb5034b4-ddaf-4f4f-b682-2bbfdeb18bd7</guid>
      <link>https://www.aiengineeringpodcast.com/shopify-merlin-ml-platform-episode-16</link>
      <pubDate>Thu, 2 Feb 2023 15:00:00 +0000</pubDate>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:06:12</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>How Shopify Built A Machine Learning Platform That Encourages Experimentation</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>16</itunes:episode>
      <podcast:episode>16</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053821746750948fd798e-d0ad-492f-b109-1383ef9e81a8.mp3" length="43038705" type="audio/mpeg" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Applying Machine Learning To The Problem Of Bad Data At Anomalo</title>
      <description><![CDATA[Summary<br />All data systems are subject to the "garbage in, garbage out" problem. For machine learning applications bad data can lead to unreliable models and unpredictable results. Anomalo is a product designed to alert on bad data by applying machine learning models to various storage and processing systems. In this episode Jeremy Stanley discusses the various challenges that are involved in building useful and reliable machine learning models with unreliable data and the interesting problems that they are solving in the process.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Your host is Tobias Macey and today I'm interviewing Jeremy Stanley about his work at Anomalo, applying ML to the problem of data quality monitoring</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Anomalo is and the story behind it?</li><li>What are some of the ML approaches that you are using to address challenges with data quality/observability?</li><li>What are some of the difficulties posed by your application of ML technologies on data sets that you don't control?&nbsp;<ul><li>How does the scale and quality of data that you are working with influence/constrain the algorithmic approaches that you are using to build and train your models?</li></ul></li><li>How have you implemented the infrastructure and workflows that you are using to support your ML applications?</li><li>What are some of the ways that you are addressing data quality challenges in your own platform?&nbsp;<ul><li>What are the opportunities that you have for dogfooding your product?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen Anomalo used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Anomalo?</li><li>When is Anomalo the wrong choice?</li><li>What do you have planned for the future of Anomalo?</li></ul>Contact Info<br /><ul><li><a href="https://twitter.com/jeremystan" target="_blank">@jeremystan</a> on Twitter</li><li><a href="https://www.linkedin.com/in/jeremystanley/" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.anomalo.com/" target="_blank">Anomalo</a><ul><li><a href="https://www.dataengineeringpodcast.com/anomalo-data-quality-platform-episode-256/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Partial_differential_equation" target="_blank">Partial Differential Equations</a></li><li><a href="https://en.wikipedia.org/wiki/Neural_network" target="_blank">Neural Network</a></li><li><a href="https://amzn.to/3k0Mpv8" target="_blank">Neural Networks For Pattern Recognition</a> by Christopher M. Bishop (affiliate link)</li><li><a href="https://developers.google.com/machine-learning/decision-forests/intro-to-gbdt" target="_blank">Gradient Boosted Decision Trees</a></li><li><a href="https://christophm.github.io/interpretable-ml-book/shapley.html" target="_blank">Shapley Values</a></li><li><a href="https://sentry.io" target="_blank">Sentry</a></li><li><a href="https://www.getdbt.com/" target="_blank">dbt</a></li><li><a href="https://altair-viz.github.io/" target="_blank">Altair</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">bea02319-c666-436b-9fe1-11ff1d4ed6ec</guid>
      <link>https://www.aiengineeringpodcast.com/anomalo-data-quality-monitoring-episode-15</link>
      <pubDate>Tue, 24 Jan 2023 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="221.29" duration="12.49">And so in terms of what you're doing now at Anamalo, can you describe a bit about what it is and some of the story behind it and why you decided that you wanted to spend your time and energy on this specific problem of data quality monitoring?</podcast:soundbite>
      <podcast:soundbite startTime="3071.72" duration="54.46">And as you continue to build and iterate on Anomilo and explore some of the different applications of machine learning to this problem space, what are some of the things you have planned for the near to medium term? Yeah. So there's a bunch of exciting things that we're doing with Anomalow. 1 of the things is where we began Anomalow really focused on data quality, this kind of deeper dive into the data itself and understanding as the data changed, you know, inside of the table, the actual records, their distribution, their values. But there's a lot of data that you can get about, tables in modern warehouses just from metadata and from SQL queries. And so we're expanding Anomalow to use a lot more of that data to do more, you know, fully automated monitoring for observability, and that's going to add a bunch of other features and functionality into Anomalow, and I think it will complement what we're doing in the deeper, you know, fully automated data quality monitoring.</podcast:soundbite>
      <podcast:soundbite startTime="548.25" duration="38.82">And so the final approach that 1 that we've invested the most in is what we call unsupervised data monitoring, and it's essentially building a machine learning model to detect material changes in a table. And to do that and be able to allocate the changes down to individual records. And the point of this is to have, you know, 1 algorithm you can point at a table, and it can online learn about that table and changes that are happening in the data over time to be able to detect really unusual changes that could be adverse and then explain those changes to the end user without having to boil the ocean and compute, you know, a whole bunch of different metrics.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:59:24</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Applying Machine Learning To The Problem Of Bad Data At Anomalo</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>15</itunes:episode>
      <podcast:episode>15</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053874545814414245e9d-c668-42c5-8bf9-6af3b2643c69v4.mp3" length="30010412" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053874545814414245e9d-c668-42c5-8bf9-6af3b2643c69v4.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_14245e9d-c668-42c5-8bf9-6af3b2643c69638557327871409249.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/14245e9d-c668-42c5-8bf9-6af3b2643c69638557327860014405.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/14245e9d-c668-42c5-8bf9-6af3b2643c69638557327856223115.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Build More Reliable Machine Learning Systems With The Dagster Orchestration Engine</title>
      <description><![CDATA[Summary<br />Building a machine learning model one time can be done in an ad-hoc manner, but if you ever want to update it and serve it in production you need a way of repeating a complex sequence of operations. Dagster is an orchestration engine that understands the data that it is manipulating so that you can move beyond coarse task-based representations of your dependencies. In this episode Sandy Ryza explains how his background in machine learning has informed his work on the Dagster project and the foundational principles that it is built on to allow for collaboration across data engineering and machine learning concerns.<br />Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you start by sharing a definition of "orchestration" in the context of machine learning projects?</li><li>What is your assessment of the state of the orchestration ecosystem as it pertains to ML?</li><li>modeling cycles and managing experiment iterations in the execution graph</li><li>how to balance flexibility with repeatability&nbsp;</li><li>What are the most interesting, innovative, or unexpected ways that you have seen orchestration implemented/applied for machine learning?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on orchestration of ML workflows?</li><li>When is Dagster the wrong choice?</li><li>What do you have planned for the future of ML support in Dagster?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/sandyryza/" target="_blank">LinkedIn</a></li><li><a href="https://twitter.com/s_ryz" target="_blank">@s_ryz</a> on Twitter</li><li><a href="https://github.com/sryza" target="_blank">sryza</a> on GitHub</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don't forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you've learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://dagster.io/" target="_blank">Dagster</a><ul><li><a href="https://www.dataengineeringpodcast.com/dagster-software-defined-assets-data-orchestration-episode-309/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.cloudera.com/" target="_blank">Cloudera</a></li><li><a href="https://hadoop.apache.org/" target="_blank">Hadoop</a></li><li><a href="https://spark.apache.org/" target="_blank">Apache Spark</a></li><li><a href="https://en.wikipedia.org/wiki/Peter_Norvig" target="_blank">Peter Norvig</a></li><li><a href="https://www.linkedin.com/in/josh-wills-13882b/" target="_blank">Josh Wills</a></li><li><a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop" target="_blank">REPL == Read Eval Print Loop</a></li><li><a href="https://posit.co/" target="_blank">RStudio</a></li><li><a href="https://en.wikipedia.org/wiki/Memoization" target="_blank">Memoization</a></li><li><a href="https://mlflow.org/" target="_blank">MLFlow</a></li><li><a href="https://kedro.readthedocs.io/en/stable/" target="_blank">Kedro</a><ul><li><a href="https://www.dataengineeringpodcast.com/kedro-data-pipeline-episode-100/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://metaflow.org/" target="_blank">Metaflow</a><ul><li><a href="https://www.pythonpodcast.com/metaflow-machine-learning-operations-episode-274/" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://www.kubeflow.org/" target="_blank">Kubeflow</a></li><li><a href="https://www.getdbt.com/" target="_blank">dbt</a><ul><li><a href="https://www.dataengineeringpodcast.com/dbt-data-analytics-episode-81/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://airbyte.com/" target="_blank">Airbyte</a><ul><li><a href="https://www.dataengineeringpodcast.com/airbyte-open-source-data-integration-episode-173/" target="_blank">Data Engineering Podcast Episode</a></li></ul></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/" target="_blank">Hitman's Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">a5f61e41-1d38-4835-b3be-469cd4aff668</guid>
      <link>https://www.aiengineeringpodcast.com/dagster-ml-orchestration-episode-14</link>
      <pubDate>Fri, 2 Dec 2022 00:00:00 +0000</pubDate>
      <podcast:soundbite startTime="1462.51" duration="23.81">I think the biggest 1 is we talked about before. Dijkstra takes this very asset oriented view. You know, modeling pipelines in terms of the assets they produce, not just the tasks that they run. I think that sort of shines especially in a cross team context. Because if you think about the interface between a data engineering team and a machine learning engineering team, it's normally a set of datasets that kind of sit at the boundary.</podcast:soundbite>
      <podcast:soundbite startTime="47.55" duration="20.54">So I was working at Cloudera almost 10 years ago. If you aren't familiar with Cloudera, it was basically the company or the first company that was trying to make money off of Hadoop. I was a software engineer, and my job there was contributing features to the open source MapReduce project and the open source, you know, Apache Spark project. I had taken ML classes in college.</podcast:soundbite>
      <podcast:soundbite startTime="300.59" duration="24.37">I think orchestration is fundamentally about modeling dependencies. In a world without orchestration, you end up with this big pile of stuff. So in the world of machine learning, the pile is gonna include chunks of code that transform data or train models or evaluate models. And then the pile is also gonna include data assets. So these are the datasets that you operate on, the machine learning models themselves.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:45:43</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build More Reliable Machine Learning Systems With The Dagster Orchestration Engine</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>14</itunes:episode>
      <podcast:episode>14</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053846104646175159ac5-5d5d-4265-8110-45ee0d55871fv5.mp3" length="30812782" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053846104646175159ac5-5d5d-4265-8110-45ee0d55871fv5.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_75159ac5-5d5d-4265-8110-45ee0d55871f638557327545940064.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/75159ac5-5d5d-4265-8110-45ee0d55871f638557327542577557.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/75159ac5-5d5d-4265-8110-45ee0d55871f638557327539543169.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Solve The Cold Start Problem For Machine Learning By Letting Humans Teach The Computer With Aitomatic</title>
      <description><![CDATA[Summary<br />Machine learning is a data-hungry approach to problem solving. Unfortunately, there are a number of problems that would benefit from the automation provided by artificial intelligence capabilities that don’t come with troves of data to build from. Christopher Nguyen and his team at Aitomatic are working to address the "cold start" problem for ML by letting humans generate models by sharing their expertise through natural language. In this episode he explains how that works, the various ways that we can start to layer machine learning capabilities on top of each other, as well as the risks involved in doing so without incorporating lessons learned in the growth of the software industry.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Your host is Tobias Macey and today I’m interviewing Christopher Nguyen about how to address the cold start problem for ML/AI projects</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what the "cold start" or "small data" problem is and its impact on an organization’s ability to invest in machine learning?</li><li>What are some examples of use cases where ML is a viable solution but there is a corresponding lack of usable data?</li><li>How does the model design influence the data requirements to build it? (e.g. statistical model vs. deep learning, etc.)</li><li>What are the available options for addressing a lack of data for ML?&nbsp;<ul><li>What are the characteristics of a given data set that make it suitable for ML use cases?</li></ul></li><li>Can you describe what you are building at Aitomatic and how it helps to address the cold start problem?&nbsp;<ul><li>How have the design and goals of the product changed since you first started working on it?</li></ul></li><li>What are some of the education challenges that you face when working with organizations to help them understand how to think about ML/AI investment and practical limitations? What are the most interesting, innovative, or unexpected ways that you have seen Aitomatic/H1st used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Aitomatic/H1st?</li><li>When is a human/knowledge driven approach to ML development the wrong choice?</li><li>What do you have planned for the future of Aitomatic?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/ctnguyen/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://twitter.com/pentagoniac?utm_source=rss&amp;utm_medium=rss" target="_blank">@pentagoniac</a> on Twitter</li><li><a href="https://scholar.google.com/citations?user=3KvkkfoAAAAJ&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">Google Scholar</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.aitomatic.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Aitomatic</a></li><li><a href="https://www.h1st.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Human First AI</a></li><li><a href="https://www.k1st.world/?utm_source=rss&amp;utm_medium=rss" target="_blank">Knowledge First World Symposium</a></li><li><a href="http://oldcomputers.net/atari800.html?utm_source=rss&amp;utm_medium=rss" target="_blank">Atari 800</a></li><li><a href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)?utm_source=rss&amp;utm_medium=rss" target="_blank">Cold start problem</a></li><li><a href="https://scale.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Scale AI</a></li><li><a href="https://snorkel.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Snorkel AI</a><ul><li><a href="https://www.themachinelearningpodcast.com/snorkel-ai-data-centric-machine-learning-episode-5/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Anomaly_detection?utm_source=rss&amp;utm_medium=rss" target="_blank">Anomaly Detection</a></li><li><a href="https://en.wikipedia.org/wiki/Expert_system?utm_source=rss&amp;utm_medium=rss" target="_blank">Expert Systems</a></li><li><a href="https://icml.cc/?utm_source=rss&amp;utm_medium=rss" target="_blank">ICML == International Conference on Machine Learning</a></li><li><a href="https://www.nist.gov/?utm_source=rss&amp;utm_medium=rss" target="_blank">NIST == National Institute of Standards and Technology</a></li><li><a href="https://en.wikipedia.org/wiki/Multimodal_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Multi-modal Model</a></li><li><a href="https://en.wikipedia.org/wiki/Support-vector_machine?utm_source=rss&amp;utm_medium=rss" target="_blank">SVM == Support Vector Machine</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Pytorch</a><ul><li><a href="https://www.pythonpodcast.com/pytorch-deep-learning-epsiode-202/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://oss.capital/?utm_source=rss&amp;utm_medium=rss" target="_blank">OSS Capital</a></li><li><a href="https://openai.com/dall-e-2/?utm_source=rss&amp;utm_medium=rss" target="_blank">DALL-E</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-09-28t02:22:24+00:00-21e8a843165c1b0</guid>
      <link>https://www.aiengineeringpodcast.com/aitomatic-machine-learning-cold-start-episode-13</link>
      <pubDate>Wed, 28 Sep 2022 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="860.75" duration="32.38">Machine learning based purely on data is not the future. Right? Once you have these models, you should be building on the shoulder to the giants. Right? Machines will increasingly understand more than just raw data. So there's a near future where the training and, you know, people refer to it, you know, as prompt engineering, but I think it's much deeper and much broader than that. Right? We will be able to train machine models, right, with knowledge, because they already possess some knowledge. And then we sort of just ladder up.</podcast:soundbite>
      <podcast:soundbite startTime="1782.43" duration="38.62">The main epiphany is, even for us, is, like, these companies have vast domain expertise. Right? They've been around for 20, 30 years. In some way, Silicon Valley, including myself, sometime we tend to go in and we say, you guys step aside. Right? Let me connect this up. Let me collect the data and I'll do everything that's needed. It turns out that doesn't work. I mean, I don't mean just culturally, but actually technically. So having a tool like this is not just technically pleasing, but it's also culturally appropriate for a conversation with these, both the executive level and and the line management level at these companies.</podcast:soundbite>
      <podcast:soundbite startTime="192.17" duration="25.66">So the cold start problem can be thought of as and anybody who is trying to apply machine learning algorithms into their actual, you know, work, into the actual applications, will run into this issue at some scale or other. Right? And machine learning, as you know, the food for machine learning is data. And so recently, there's been a recognition that data is not plentiful.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:52:07</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Solve The Cold Start Problem For Machine Learning By Letting Humans Teach The Computer With Aitomatic</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>13</itunes:episode>
      <podcast:episode>13</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538501791712d8088b4f-215f-4da8-9cec-469186ef7be1v6.mp3" length="40990276" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538501791712d8088b4f-215f-4da8-9cec-469186ef7be1v6.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_d8088b4f-215f-4da8-9cec-469186ef7be1638557327347624737.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/d8088b4f-215f-4da8-9cec-469186ef7be1638557327343923262.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/d8088b4f-215f-4da8-9cec-469186ef7be1638557327340831257.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Convert Your Unstructured Data To Embedding Vectors For More Efficient Machine Learning With Towhee</title>
      <description><![CDATA[Summary<br />Data is one of the core ingredients for machine learning, but the format in which it is understandable to humans is not a useful representation for models. Embedding vectors are a way to structure data in a way that is native to how models interpret and manipulate information. In this episode Frank Liu shares how the Towhee library simplifies the work of translating your unstructured data assets (e.g. images, audio, video, etc.) into embeddings that you can use efficiently for machine learning, and how it fits into your workflow for model development.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Your host is Tobias Macey and today I’m interviewing Frank Liu about how to use vector embeddings in your ML projects and how Towhee can reduce the effort involved</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Towhee is and the story behind it?</li><li>What is the problem that Towhee is aimed at solving?</li><li>What are the elements of generating vector embeddings that pose the greatest challenge or require the most effort?</li><li>Once you have an embedding, what are some of the ways that it might be used in a machine learning project?&nbsp;<ul><li>Are there any design considerations that need to be addressed in the form that an embedding takes and how it impacts the resultant model that relies on it? (whether for training or inference)</li></ul></li><li>Can you describe how the Towhee framework is implemented?&nbsp;<ul><li>What are some of the interesting engineering challenges that needed to be addressed?</li><li>How have the design/goals/scope of the project shifted since it began?</li></ul></li><li>What is the workflow for someone using Towhee in the context of an ML project?</li><li>What are some of the types optimizations that you have incorporated into Towhee?&nbsp;<ul><li>What are some of the scaling considerations that users need to be aware of as they increase the volume or complexity of data that they are processing?</li></ul></li><li>What are some of the ways that using Towhee impacts the way a data scientist or ML engineer approach the design development of their model code?</li><li>What are the interfaces available for integrating with and extending Towhee?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Towhee used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Towhee?</li><li>When is Towhee the wrong choice?</li><li>What do you have planned for the future of Towhee?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/fzliu/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://github.com/fzliu?utm_source=rss&amp;utm_medium=rss" target="_blank">fzliu</a> on GitHub</li><li><a href="https://frankzliu.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Website</a></li><li><a href="https://twitter.com/frankzliu?utm_source=rss&amp;utm_medium=rss" target="_blank">@frankzliu</a> on Twitter</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://towhee.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Towhee</a></li><li><a href="https://zilliz.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Zilliz</a></li><li><a href="https://milvus.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Milvus</a><ul><li><a href="https://www.dataengineeringpodcast.com/milvus-open-source-vector-database-episode-313/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Computer_vision?utm_source=rss&amp;utm_medium=rss" target="_blank">Computer Vision</a></li><li><a href="https://en.wikipedia.org/wiki/Tensor?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensor</a></li><li><a href="https://en.wikipedia.org/wiki/Autoencoder?utm_source=rss&amp;utm_medium=rss" target="_blank">Autoencoder</a></li><li><a href="https://en.wikipedia.org/wiki/Latent_space?utm_source=rss&amp;utm_medium=rss" target="_blank">Latent Space</a></li><li><a href="https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/?utm_source=rss&amp;utm_medium=rss" target="_blank">Diffusion Model</a></li><li><a href="https://en.wikipedia.org/wiki/HSL_and_HSV?utm_source=rss&amp;utm_medium=rss" target="_blank">HSL == Hue, Saturation, Lightness</a></li><li><a href="https://wandb.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Weights and Biases</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-09-21t02:08:04+00:00-205327875cb7472</guid>
      <link>https://www.aiengineeringpodcast.com/towhee-embedding-vector-etl-library-episode-12</link>
      <pubDate>Wed, 21 Sep 2022 15:00:00 +0000</pubDate>
      <podcast:soundbite startTime="670.02" duration="53.41">When it comes specifically to the idea of a vector database and a greater vector database ecosystem, absolutely, the main sort of applications that you see are in semantic search and vector search or understanding what we like to call unstructured data, Data that you can pass through machine learning models or data that you can, you know, pass through your own handcrafted algorithms to be able to get an embedding based off of that. But embeddings, the way that I like to think of them is that they are the language of computers. So we, for example, right now, we use English. There are multiple different human languages out there as well. There's French, German, you know, Swahili, you know, Mandarin, Japanese, so on and so forth. And the way that I like to think about it is that every machine learning model that we have, really, it is a way for computers to express themselves, a way for machines to express themselves.</podcast:soundbite>
      <podcast:soundbite startTime="76.05" duration="44.15">And do you remember how you first got involved in machine learning? Yeah. Absolutely. I mean, right out of grad school, I actually went to work at Yahoo. And it was a great opportunity for me to really be immersed in not just computer vision, but the broader machine learning world as well. Specifically, I was on the computer vision machine learning team over there. For the better part of 2 years. You know, back then, it was, you know, 2020 14, 2015. It was still very much the Wild West days of AI, of ML, really trying to figure out how do we use machine learning in production systems. Back then, there really wasn't a solid concept of what MLOps was. People really were still trying to figure out how to productionize their machine learning models.</podcast:soundbite>
      <podcast:soundbite startTime="2547.23" duration="62.20">For Tohi right now, we have you know, as I was mentioning earlier, it's really composed of these atomic units called operators. And going back to the idea that if I wanna create an embedding application or if I wanna create this vector data application, it's never just a single model. And these days, we've extended Tohi to be able to insert into vector databases such as Milvus and to be able to query across vector databases such as Milvus as well. And what we are really trying to do there is to say, in addition to the ETL side of things, in addition to just generating the embeddings, we also want you to be able to prototype the application as well. And we also want folks to be able to take this vector data and to push it to maybe other machine learning databases, maybe push it to feature stores, or maybe have this embedding you somewhere in Snowflake, for example.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:51:54</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Convert Your Unstructured Data To Embedding Vectors For More Efficient Machine Learning With Towhee</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>12</itunes:episode>
      <podcast:episode>12</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053924001635164068065-0706-47f6-a49d-dec651cb9318v18.mp3" length="38207080" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053924001635164068065-0706-47f6-a49d-dec651cb9318v18.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_64068065-0706-47f6-a49d-dec651cb9318638557327024382890.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/64068065-0706-47f6-a49d-dec651cb9318638557327020827285.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/64068065-0706-47f6-a49d-dec651cb9318638557327018037119.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Shedding Light On Silent Model Failures With NannyML</title>
      <description><![CDATA[Summary<br />Because machine learning models are constantly interacting with inputs from the real world they are subject to a wide variety of failures. The most commonly discussed error condition is concept drift, but there are numerous other ways that things can go wrong. In this episode Wojtek Kuberski explains how NannyML is designed to compare the predicted performance of your model against its actual behavior to identify silent failures and provide context to allow you to determine whether and how urgently to address them.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Your host is Tobias Macey and today I’m interviewing Wojtek Kuberski about NannyML and the work involved in post-deployment data science</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what NannyML is and the story behind it?</li><li>What is "post-deployment data science"?&nbsp;<ul><li>How does it differ from the metrics/monitoring approach to managing the model lifecycle?</li><li>Who is typically responsible for this work? How does NannyML augment their skills?</li><li>What are some of your experiences with model failure that motivated you to spend your time and focus on this problem?</li></ul></li><li>What are the main contributing factors to alert fatigue for ML systems?</li><li>What are some of the ways that a model can fail silently?&nbsp;<ul><li>How does NannyML detect those conditions?</li></ul></li><li>What are the remediation actions that might be necessary once an issue is detected in a model?</li><li>Can you describe how NannyML is implemented?&nbsp;<ul><li>What are some of the technical and UX design problems that you have had to address?</li><li>What are some of the ideas/assumptions that you have had to re-evaluate in the process of building NannyML?</li></ul></li><li>What additional capabilities are necessary for supporting less structured data?</li><li>Can you describe what is involved in setting up NannyML and how it fits into an ML engineer’s workflow?&nbsp;<ul><li>Once a model is deployed, what additional outputs/data can/should be collected to improve the utility of NannyML and feed into analysis of the real-world operation?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen NannyML used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on NannyML?</li><li>When is NannyML the wrong choice?</li><li>What do you have planned for the future of NannyML?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/wojtek-kuberski/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.nannyml.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">NannyML</a></li><li><a href="https://en.wikipedia.org/wiki/F-score?utm_source=rss&amp;utm_medium=rss" target="_blank">F1 Score</a></li><li><a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?utm_source=rss&amp;utm_medium=rss" target="_blank">ROC Curve</a></li><li><a href="https://en.wikipedia.org/wiki/Concept_drift?utm_source=rss&amp;utm_medium=rss" target="_blank">Concept Drift</a></li><li><a href="https://en.wikipedia.org/wiki/A/B_testing?utm_source=rss&amp;utm_medium=rss" target="_blank">A/B Testing</a></li><li><a href="https://jupyter.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Jupyter Notebook</a></li><li><a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture?utm_source=rss&amp;utm_medium=rss" target="_blank">Vector Embedding</a></li><li><a href="https://airflow.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Airflow</a></li><li><a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis?utm_source=rss&amp;utm_medium=rss" target="_blank">EDA == Exploratory Data Analysis</a></li><li><a href="https://amzn.to/3xiH71D?utm_source=rss&amp;utm_medium=rss" target="_blank">Inspired</a> book (affiliate link)</li><li><a href="https://zenml.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">ZenML</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-09-14t02:05:43+00:00-c51e55fa5102809</guid>
      <link>https://www.aiengineeringpodcast.com/nannyml-silent-model-failure-episode-11</link>
      <pubDate>Wed, 14 Sep 2022 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="706.13" duration="48.59">That is actually a very insightful question. And like you mentioned, there's definitely this feedback loop between the real world and the model itself. If you deploy, let's say, a churn model and the model works well, reduce the churn, which will also impact the population. So we're gonna have some kind of drift there already, which might mean, for example, that looks like the model is going to shit, but in reality, the model is still working while it's just population exchanging. So 1 thing that people definitely understand better, the data scientists that are working on these models, is how the real world interacts with the model and that it's a 2 way interaction. It's not just that model interacts with the world and changes the world, but also the other way around because the population will change, and if you return the model, the model is also going to be significantly significantly different.</podcast:soundbite>
      <podcast:soundbite startTime="65.84" duration="23.73">And today, I'm interviewing Wojtek Kubertski about Nanny ML and the work involved in post deployment data science. So, Wojtek, can you start by introducing yourself? Absolutely. So thanks for having me, Tobias. I'm a cofounder at Nenemel. What I do is basically everything that's related to tech. So I kinda manage the product side of things, the research side of things, which are actually separate in that email because we are a deep tech company.</podcast:soundbite>
      <podcast:soundbite startTime="167.53" duration="53.07">So as you mentioned, now you have cofounded a business in Nanny ML. I'm wondering if you can describe a bit about what it is that you're building there and some of the story behind why you decided that this was the problem that you wanted to spend your time and energy on. I started previous company, a consultancy, together also with my current cofounders at Nanny and El. And our goal was always to find a product that we could make big, basically, some unfulfilled need that we could try to fulfill. And we had a couple of ideas, but there was 1 thing that we came up over and over again with our consulting clients is that there was the question of what am I gonna do after you deploy these models for me? How do I make sure that these models actually keep on working? And we couldn't really make it our problem as part of the consulting because it was way too big to just do it as an kind of 1 off project.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:03:18</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Shedding Light On Silent Model Failures With NannyML</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>11</itunes:episode>
      <podcast:episode>11</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305388920143521a1acb91-7368-4459-941f-8653a2d3bb9bv6.mp3" length="45248386" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305388920143521a1acb91-7368-4459-941f-8653a2d3bb9bv6.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_1a1acb91-7368-4459-941f-8653a2d3bb9b638557326831943548.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/1a1acb91-7368-4459-941f-8653a2d3bb9b638557326817939532.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/1a1acb91-7368-4459-941f-8653a2d3bb9b638557326812224840.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>How To Design And Build Machine Learning Systems For Reasonable Scale</title>
      <description><![CDATA[Summary<br />Using machine learning in production requires a sophisticated set of cooperating technologies. A majority of resources that are available for understanding how to design and operate these platforms are focused on either simple examples that don’t scale, or over-engineered technologies designed for the massive scale of big tech companies. In this episode Jacopo Tagliabue shares his vision for "ML at reasonable scale" and how you can adopt these patterns for building your own platforms.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Your host is Tobias Macey and today I’m interviewing Jacopo Tagliabue about building "reasonable scale" ML systems</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>How would you describe the current state of the ecosystem for ML practitioners? (e.g. tool selection, availability of information/tutorials, etc.)&nbsp;<ul><li>What are some of the notable changes that you have seen over the past 2 – 5 years?</li><li>How have the evolutions in the data engineering space been reflected in/influenced the way that ML is being done?</li></ul></li><li>What are the challenges/points of friction that ML practitioners have to contend with when trying to get a model into production that isn’t just a toy?</li><li>You wrote a set of tutorials and accompanying code about performing ML at "reasonable scale". What are you aiming to represent with that phrasing?&nbsp;<ul><li>There is a paradox of choice for any newcomer to ML. What are some of the key capabilities that practitioners should use in their decision rubric when designing a "reasonable scale" system?</li><li>What are some of the common bottlenecks that crop up when moving from an initial test implementation to a scalable deployment that is serving customer traffic?</li></ul></li><li>How much of an impact does the type of ML problem being addressed have on the deployment and scalability elements of the system design? (e.g. NLP vs. computer vision vs. recommender system, etc.)</li><li>What are some of the misleading pieces of advice that you have seen from "big tech" tutorials about how to do ML that are unnecessary when running at smaller scales?</li><li>You also spend some time discussing the benefits of a "NoOps" approach to ML deployment. At what point do operations/infrastructure engineers need to get involved?&nbsp;<ul><li>What are the operational aspects of ML applications that infrastructure engineers working in product teams might be unprepared for?</li></ul></li><li>What are the most interesting, innovative, or unexpected system designs that you have seen for moderate scale MLOps?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on ML system design and implementation?</li><li>What are the aspects of ML systems design that you are paying attention to in the current ecosystem?</li><li>What advice do you have for additional references or research that ML practitioners would benefit from when designing their own production systems?</li></ul>Contact Info<br /><ul><li><a href="https://github.com/jacopotagliabue/?utm_source=rss&amp;utm_medium=rss" target="_blank">jacopotagliabue</a> on GitHub</li><li><a href="https://jacopotagliabue.it/?utm_source=rss&amp;utm_medium=rss" target="_blank">Website</a></li><li><a href="https://www.linkedin.com/in/jacopotagliabue/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://towardsdatascience.com/the-post-modern-stack-993ec3b044c1?utm_source=rss&amp;utm_medium=rss" target="_blank">The Post-Modern Stack: ML At Reasonable Scale</a></li><li><a href="https://www.coveo.com/en?utm_source=rss&amp;utm_medium=rss" target="_blank">Coveo</a></li><li><a href="https://en.wikipedia.org/wiki/Natural_language_processing?utm_source=rss&amp;utm_medium=rss" target="_blank">NLP == Natural Language Processing</a></li><li><a href="https://github.com/jacopotagliabue/reclist?utm_source=rss&amp;utm_medium=rss" target="_blank">RecList</a></li><li><a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging?utm_source=rss&amp;utm_medium=rss" target="_blank">Part of speech tagging</a></li><li><a href="https://en.wikipedia.org/wiki/Markov_model?utm_source=rss&amp;utm_medium=rss" target="_blank">Markov Model</a></li><li><a href="https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat?utm_source=rss&amp;utm_medium=rss" target="_blank">YDNABB (You Don’t Need A Bigger Boat)</a></li><li><a href="https://www.getdbt.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">dbt</a><ul><li><a href="https://www.dataengineeringpodcast.com/dbt-data-analytics-episode-81/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.seldon.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Seldon</a></li><li><a href="https://metaflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Metaflow</a><ul><li><a href="https://www.pythonpodcast.com/metaflow-machine-learning-operations-episode-274/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://www.snowflake.com/en/?utm_source=rss&amp;utm_medium=rss" target="_blank">Snowflake</a></li><li><a href="https://en.wikipedia.org/wiki/Information_retrieval?utm_source=rss&amp;utm_medium=rss" target="_blank">Information Retrieval</a></li><li><a href="https://continual.ai/post/the-modern-data-stack-ecosystem-fall-2021-edition?utm_source=rss&amp;utm_medium=rss" target="_blank">Modern Data Stack</a></li><li><a href="https://sqlite.org/index.html?utm_source=rss&amp;utm_medium=rss" target="_blank">SQLite</a></li><li><a href="https://spark.apache.org/sql/?utm_source=rss&amp;utm_medium=rss" target="_blank">Spark SQL</a></li><li><a href="https://aws.amazon.com/athena/?utm_source=rss&amp;utm_medium=rss" target="_blank">AWS Athena</a></li><li><a href="https://keras.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Keras</a></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">PyTorch</a></li><li><a href="https://luigi.readthedocs.io/en/stable/?utm_source=rss&amp;utm_medium=rss" target="_blank">Luigi</a></li><li><a href="https://airflow.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Airflow</a></li><li><a href="https://flask.palletsprojects.com/en/2.2.x/?utm_source=rss&amp;utm_medium=rss" target="_blank">Flask</a></li><li><a href="https://aws.amazon.com/fargate/?utm_source=rss&amp;utm_medium=rss" target="_blank">AWS Fargate</a></li><li><a href="https://aws.amazon.com/sagemaker/?utm_source=rss&amp;utm_medium=rss" target="_blank">AWS Sagemaker</a></li><li><a href="https://github.com/jacopotagliabue/recs-at-resonable-scale?utm_source=rss&amp;utm_medium=rss" target="_blank">Recommendations At Reasonable Scale</a></li><li><a href="https://www.pinecone.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Pinecone</a><ul><li><a href="https://www.dataengineeringpodcast.com/pinecone-vector-database-similarity-search-episode-189/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://redis.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Redis</a></li><li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm?utm_source=rss&amp;utm_medium=rss" target="_blank">KNN == K-Nearest Neighbors</a></li><li><a href="https://medium.com/@Pinterest_Engineering?utm_source=rss&amp;utm_medium=rss" target="_blank">Pinterest Engineering Blog</a></li><li><a href="https://materialize.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Materialize</a></li><li><a href="https://openai.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">OpenAI</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-09-10t12:57:48+00:00-15d6e33d7ed1f70</guid>
      <link>https://www.aiengineeringpodcast.com/reasonable-scale-machine-learning-systems-episode-10</link>
      <pubDate>Sat, 10 Sep 2022 13:00:00 +0000</pubDate>
      <podcast:soundbite startTime="229.77" duration="10.80">So the first question is, how about the tooling and things that makes you productive? I mean, it's awesome. It's the best way possible. It's best moment possible, at least in our season before, to be in this field as you don't have to do much anymore.</podcast:soundbite>
      <podcast:soundbite startTime="898.07" duration="27.10">The mistake we made, we made some mistakes because we knew that what we were doing was not optimal. But then the old daemon optimal solution at the time wasn't really possible. Our deployment our multi deployment package at the time was like, you know, a Flask app, a Docker app with you know? When you spin it up, what happens? It goes to s 3. You retrieve the latest, you know, the latest artifact that is there, and and then it's just gonna reboot the, basically, the container. It's gonna load that in memory, and then it's gonna serve a Flask endpoint in Python.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:54:10</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>How To Design And Build Machine Learning Systems For Reasonable Scale</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>10</itunes:episode>
      <podcast:episode>10</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538583652788ffbf0363-26f1-4f3f-add7-4c4f214a08b3v2.mp3" length="39242437" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538583652788ffbf0363-26f1-4f3f-add7-4c4f214a08b3v2.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ffbf0363-26f1-4f3f-add7-4c4f214a08b3638557326590850475.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ffbf0363-26f1-4f3f-add7-4c4f214a08b3638557326585593955.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ffbf0363-26f1-4f3f-add7-4c4f214a08b3638557326582882822.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Building A Business Powered By Machine Learning At Assembly AI</title>
      <description><![CDATA[Summary<br />The increasing sophistication of machine learning has enabled dramatic transformations of businesses and introduced new product categories. At Assembly AI they are offering advanced speech recognition and natural language models as an API service. In this episode founder Dylan Fox discusses the unique challenges of building a business with machine learning as the core product.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Your host is Tobias Macey and today I’m interviewing Dylan Fox about building and growing a business with ML as its core offering</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Assembly is and the story behind it?&nbsp;<ul><li>For anyone who isn’t familiar with your platform, can you describe the role that ML/AI plays in your product?</li></ul></li><li>What was your process for going from idea to prototype for an AI powered business?&nbsp;<ul><li>Can you offer parallels between your own experience and that of your peers who are building businesses oriented more toward pure software applications?</li></ul></li><li>How are you structuring your teams?</li><li>On the path to your current scale and capabilities how have you managed scoping of your model capabilities and operational scale to avoid getting bogged down or burnt out?</li><li>How do you think about scoping of model functionality to balance composability and system complexity?</li><li>What is your process for identifying and understanding which problems are suited to ML and when to rely on pure software?</li><li>You are constantly iterating on model performance and introducing new capabilities. How do you manage prototyping and experimentation cycles?&nbsp;<ul><li>What are the metrics that you track to identify whether and when to move from an experimental to an operational state with a model?</li><li>What is your process for understanding what’s possible and what can feasibly operate at scale?</li></ul></li><li>Can you describe your overall operational patterns delivery process for ML?</li><li>What are some of the most useful investments in tooling that you have made to manage development experience for your teams?</li><li>Once you have a model in operation, how do you manage performance tuning? (from both a model and an operational scalability perspective)</li><li>What are the most interesting, innovative, or unexpected aspects of ML development and maintenance that you have encountered while building and growing the Assembly platform?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Assembly?</li><li>When is ML the wrong choice?</li><li>What do you have planned for the future of Assembly?</li></ul>Contact Info<br /><ul><li><a href="https://twitter.com/youvegotfox?lang=en&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">@YouveGotFox</a> on Twitter</li><li><a href="https://www.linkedin.com/in/dylanbfox?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.assemblyai.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Assembly AI</a><ul><li><a href="https://www.pythonpodcast.com/assemblyai-deep-learning-speech-recognition-episode-326/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://learnpythonthehardway.org/python3/?utm_source=rss&amp;utm_medium=rss" target="_blank">Learn Python the Hard Way</a></li><li><a href="https://www.nltk.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">NLTK</a></li><li><a href="https://en.wikipedia.org/wiki/Natural_language_processing?utm_source=rss&amp;utm_medium=rss" target="_blank">NLP == Natural Language Processing</a></li><li><a href="https://en.wikipedia.org/wiki/Natural-language_understanding?utm_source=rss&amp;utm_medium=rss" target="_blank">NLU == Natural Language Understanding</a></li><li><a href="https://en.wikipedia.org/wiki/Speech_recognition?utm_source=rss&amp;utm_medium=rss" target="_blank">Speech Recognition</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://www.reddit.com/r/MachineLearning/?utm_source=rss&amp;utm_medium=rss" target="_blank">r/machinelearning</a></li><li><a href="https://scipy.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">SciPy</a></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">PyTorch</a></li><li><a href="https://github.com/google/jax?utm_source=rss&amp;utm_medium=rss" target="_blank">Jax</a></li><li><a href="https://huggingface.co/?utm_source=rss&amp;utm_medium=rss" target="_blank">HuggingFace</a></li><li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network?utm_source=rss&amp;utm_medium=rss" target="_blank">RNN == Recurrent Neural Network</a></li><li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network?utm_source=rss&amp;utm_medium=rss" target="_blank">CNN == Convolutional Neural Network</a></li><li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory?utm_source=rss&amp;utm_medium=rss" target="_blank">LSTM == Long Short Term Memory</a></li><li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model?utm_source=rss&amp;utm_medium=rss" target="_blank">Hidden Markov Models</a></li><li><a href="https://arxiv.org/abs/1412.5567?utm_source=rss&amp;utm_medium=rss" target="_blank">Baidu DeepSpeech</a></li><li><a href="https://en.wikipedia.org/wiki/Connectionist_temporal_classification?utm_source=rss&amp;utm_medium=rss" target="_blank">CTC (Connectionist Temporal Classification) Loss Model</a></li><li><a href="https://www.twilio.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Twilio</a></li><li><a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search?utm_source=rss&amp;utm_medium=rss" target="_blank">Grid Search</a></li><li><a href="https://www.nvidia.com/en-gb/data-center/tesla-k80/?utm_source=rss&amp;utm_medium=rss" target="_blank">K80 GPU</a></li><li><a href="https://www.nvidia.com/en-us/data-center/a100/?utm_source=rss&amp;utm_medium=rss" target="_blank">A100 GPU</a></li><li><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit?utm_source=rss&amp;utm_medium=rss" target="_blank">TPU == Tensor Processing Unit</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_models?utm_source=rss&amp;utm_medium=rss" target="_blank">Foundation Models</a></li><li><a href="https://bigscience.huggingface.co/blog/bloom?utm_source=rss&amp;utm_medium=rss" target="_blank">BLOOM Language Model</a></li><li><a href="https://openai.com/dall-e-2/?utm_source=rss&amp;utm_medium=rss" target="_blank">DALL-E 2</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-09-09t00:51:53+00:00-0cf97aaacb72e1d</guid>
      <link>https://www.aiengineeringpodcast.com/assembly-ai-machine-learning-product-episode-9</link>
      <pubDate>Fri, 9 Sep 2022 00:00:00 +0000</pubDate>
      <podcast:soundbite startTime="1344.34" duration="27.56">I mean, we could probably talk about that specific question for an entire hour, which I'm happy to. But it's a lot harder in a lot of ways, and I think there's shortcuts there's things you can do to try to be faster, especially in the early days, like everything I talked about, but it doesn't change the reality that you are gonna iterate more slowly, and you're not able to move as fast, or if your product is a machine learning model.</podcast:soundbite>
      <podcast:soundbite startTime="63.91" duration="19.08">So, Dylan, can you start by introducing yourself? Yeah. Thanks for having me on. My name is Dylan. I'm the founder of a company called AssemblyAI, and we are building out an API platform for transcribing and understanding audio with AI models for tasks like speech recognition and speech understanding.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:58:43</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Building A Business Powered By Machine Learning At Assembly AI</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>9</itunes:episode>
      <podcast:episode>9</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539045976436ca77da26-2de2-4314-a0ec-a1fec55b7b60v1.mp3" length="41279458" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539045976436ca77da26-2de2-4314-a0ec-a1fec55b7b60v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_ca77da26-2de2-4314-a0ec-a1fec55b7b60638557326133772505.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ca77da26-2de2-4314-a0ec-a1fec55b7b60638557326119038083.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/ca77da26-2de2-4314-a0ec-a1fec55b7b60638557326116563229.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Update Your Model's View Of The World In Real Time With Streaming Machine Learning Using River</title>
      <description><![CDATA[Summary<br />The majority of machine learning projects that you read about or work on are built around batch processes. The model is trained, and then validated, and then deployed, with each step being a discrete and isolated task. Unfortunately, the real world is rarely static, leading to concept drift and model failures. River is a framework for building streaming machine learning projects that can constantly adapt to new information. In this episode Max Halford explains how the project works, why you might (or might not) want to consider streaming ML, and how to get started building with River.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Your host is Tobias Macey and today I’m interviewing Max Halford about River, a Python toolkit for streaming and online machine learning</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what River is and the story behind it?</li><li>What is "online" machine learning?&nbsp;<ul><li>What are the practical differences with batch ML?</li><li>Why is batch learning so predominant?</li><li>What are the cases where someone would want/need to use online or streaming ML?</li></ul></li><li>The prevailing pattern for batch ML model lifecycles is to train, deploy, monitor, repeat. What does the ongoing maintenance for a streaming ML model look like?&nbsp;<ul><li>Concept drift is typically due to a discrepancy between the data used to train a model and the actual data being observed. How does the use of online learning affect the incidence of drift?</li></ul></li><li>Can you describe how the River framework is implemented?&nbsp;<ul><li>How have the design and goals of the project changed since you started working on it?</li></ul></li><li>How do the internal representations of the model differ from batch learning to allow for incremental updates to the model state?</li><li>In the documentation you note the use of Python dictionaries for state management and the flexibility offered by that choice. What are the benefits and potential pitfalls of that decision?</li><li>Can you describe the process of using River to design, implement, and validate a streaming ML model?&nbsp;<ul><li>What are the operational requirements for deploying and serving the model once it has been developed?</li></ul></li><li>What are some of the challenges that users of River might run into if they are coming from a batch learning background?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen River used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on River?</li><li>When is River the wrong choice?</li><li>What do you have planned for the future of River?</li></ul>Contact Info<br /><ul><li><a target="_blank">Email</a></li><li><a href="https://twitter.com/halford_max?utm_source=rss&amp;utm_medium=rss" target="_blank">@halford_max</a> on Twitter</li><li><a href="https://github.com/MaxHalford?utm_source=rss&amp;utm_medium=rss" target="_blank">MaxHalford</a> on GitHub</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://riverml.xyz/0.11.1/?utm_source=rss&amp;utm_medium=rss" target="_blank">River</a></li><li><a href="https://scikit-multiflow.github.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">scikit-multiflow</a></li><li><a href="https://en.wikipedia.org/wiki/Federated_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Federated Machine Learning</a></li><li><a href="https://arxiv.org/abs/1106.5730?context=cs&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">Hogwild!</a> Google Paper</li><li><a href="https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html?utm_source=rss&amp;utm_medium=rss" target="_blank">Chip Huyen concept drift blog post</a></li><li><a href="https://rise.cs.berkeley.edu/wp-content/uploads/2017/02/clipper_final.pdf?utm_source=rss&amp;utm_medium=rss" target="_blank">Dan Crenshaw Berkeley Clipper MLOps</a></li><li><a href="https://www.wikiwand.com/en/Robustness_principle?utm_source=rss&amp;utm_medium=rss" target="_blank">Robustness Principle</a></li><li><a href="https://www.kaggle.com/c/nyc-taxi-trip-duration?utm_source=rss&amp;utm_medium=rss" target="_blank">NY Taxi Dataset</a></li><li><a href="https://github.com/online-ml/river-torch?utm_source=rss&amp;utm_medium=rss" target="_blank">RiverTorch</a></li><li><a href="https://www.notion.so/d1e86fcdf21e4deda16eedab2b3361fb?v=503f44740b8b44a99a961aa96e9e46e1&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">River Public Roadmap</a></li><li><a href="https://github.com/online-ml/beaver?utm_source=rss&amp;utm_medium=rss" target="_blank">Beaver</a> tool for deploying online models</li><li><a href="https://prodi.gy/?utm_source=rss&amp;utm_medium=rss" target="_blank">Prodigy ML human in the loop labeling</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-08-26t01:44:54+00:00-e4398ef2e1f1982</guid>
      <link>https://www.aiengineeringpodcast.com/river-streaming-machine-learning-episode-8</link>
      <pubDate>Fri, 26 Aug 2022 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="2039.31" duration="34.61">And so digging now into River itself, can you talk through how you've implemented that framework and some of the design considerations that went into how do I think about exposing this online learning capability in a way that is accessible and understandable to people who are used to building batch models? So I like to think of Viva more as a library than a framework. If I'm not mistaken, framework kind of forces you into a certain behavior or way to do things, and there's an inversion of control where the framework is kind of designing things for you.</podcast:soundbite>
      <podcast:soundbite startTime="144.78" duration="27.26">When I was at university, I received a kind of normal introduction to a regular introduction to machine learning. And then I did some internships. I started PhD after my internships. And I also did a lot of travel competitions on the side. So I was kind of hooked into machine learning, and it always felt to me that something was off because when we were learning machine learning, everything made sense.</podcast:soundbite>
      <podcast:soundbite startTime="350.32" duration="33.29">1st, just to recap on machine learning, the whole point of machine learning is to teach a model to learn from data and to take decisions. So, you know, monkey see, monkey do. And the typical way you do that is that you fit a model to a bunch of data, and that's it really. But online machining is the equivalent of that, but for streaming data. So you stop thinking about data as a file or a table in a database, but you think of it as a flow of data stream.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:15:21</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Update Your Model's View Of The World In Real Time With Streaming Machine Learning Using River</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>8</itunes:episode>
      <podcast:episode>8</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305390078260397f5f468d-5131-4bb4-9d16-a0bc4ecc9b93v1.mp3" length="55222002" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305390078260397f5f468d-5131-4bb4-9d16-a0bc4ecc9b93v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_7f5f468d-5131-4bb4-9d16-a0bc4ecc9b93638557325825340349.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7f5f468d-5131-4bb4-9d16-a0bc4ecc9b93638557325819731016.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7f5f468d-5131-4bb4-9d16-a0bc4ecc9b93638557325816338561.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Using AI To Transform Your Business Without The Headache Using Graft</title>
      <description><![CDATA[Summary<br />Machine learning is a transformative tool for the organizations that can take advantage of it. While the frameworks and platforms for building machine learning applications are becoming more powerful and broadly available, there is still a significant investment of time, money, and talent required to take full advantage of it. In order to reduce that barrier further Adam Oliner and Brian Calvert, along with their other co-founders, started Graft. In this episode Adam and Brian explain how they have built a platform designed to empower everyone in the business to take part in designing and building ML projects, while managing the end-to-end workflow required to go from data to production.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Your host is Tobias Macey and today I’m interviewing Brian Calvert and Adam Oliner about Graft, a cloud-native platform designed to simplify the work of applying AI to business problems</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Graft is and the story behind it?</li><li>What is the core thesis of the problem you are targeting?&nbsp;<ul><li>How does the Graft product address that problem?</li><li>Who are the personas that you are focused on working with both now in your early stages and in the future as you evolve the product?</li></ul></li><li>What are the capabilities that can be unlocked in different organizations by reducing the friction and up-front investment required to adopt ML/AI?&nbsp;<ul><li>What are the user-facing interfaces that you are focused on providing to make that adoption curve as shallow as possible?&nbsp;<ul><li>What are some of the unavoidable bits of complexity that need to be surfaced to the end user?</li></ul></li></ul></li><li>Can you describe the infrastructure and platform design that you are relying on for the Graft product?&nbsp;<ul><li>What are some of the emerging "best practices" around ML/AI that you have been able to build on top of?&nbsp;<ul><li>As new techniques and practices are discovered/introduced how are you thinking about the adoption process and how/when to integrate them into the Graft product?</li></ul></li><li>What are some of the new engineering challenges that you have had to tackle as a result of your specific product?</li></ul></li><li>Machine learning can be a very data and compute intensive endeavor. How are you thinking about scalability in a multi-tenant system?&nbsp;<ul><li>Different model and data types can be widely divergent in terms of the cost (monetary, time, compute, etc.) required. How are you thinking about amortizing vs. passing through those costs to the end user?</li></ul></li><li>Can you describe the adoption/integration process for someone using Graft?&nbsp;<ul><li>Once they are onboarded and they have connected to their various data sources, what is the workflow for someone to apply ML capabilities to their problems?</li></ul></li><li>One of the challenges about the current state of ML capabilities and adoption is understanding what is possible and what is impractical. How have you designed Graft to help identify and expose opportunities for applying ML within the organization?</li><li>What are some of the challenges of customer education and overall messaging that you are working through?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Graft used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Graft?</li><li>When is Graft the wrong choice?</li><li>What do you have planned for the future of Graft?</li></ul>Contact Info<br /><ul><li>Brian&nbsp;<ul><li><a href="https://www.linkedin.com/in/brian-calvert-49a373133/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul></li><li>Adam&nbsp;<ul><li><a href="https://www.linkedin.com/in/ajoliner?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://graft.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Graft</a></li><li><a href="https://en.wikipedia.org/wiki/Particle_physics?utm_source=rss&amp;utm_medium=rss" target="_blank">High Energy Particle Physics</a></li><li><a href="https://home.cern/science/accelerators/large-hadron-collider?utm_source=rss&amp;utm_medium=rss" target="_blank">LHC</a></li><li><a href="https://www.getcruise.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Cruise</a></li><li><a href="https://slack.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Slack</a></li><li><a href="https://www.splunk.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Splunk</a></li><li><a href="https://en.wikipedia.org/wiki/Marvin_Minsky?utm_source=rss&amp;utm_medium=rss" target="_blank">Marvin Minsky</a></li><li><a href="https://en.wikipedia.org/wiki/Patrick_Winston?utm_source=rss&amp;utm_medium=rss" target="_blank">Patrick Henry Winston</a></li><li><a href="https://en.wikipedia.org/wiki/AI_winter?utm_source=rss&amp;utm_medium=rss" target="_blank">AI Winter</a></li><li><a href="https://en.wikipedia.org/wiki/Sebastian_Thrun?utm_source=rss&amp;utm_medium=rss" target="_blank">Sebastian Thrun</a></li><li><a href="https://www.darpa.mil/about-us/timeline/-grand-challenge-for-autonomous-vehicles?utm_source=rss&amp;utm_medium=rss" target="_blank">DARPA Grand Challenge</a></li><li><a href="https://home.cern/science/physics/higgs-boson?utm_source=rss&amp;utm_medium=rss" target="_blank">Higss Boson</a></li><li><a href="https://home.cern/science/physics/supersymmetry?utm_source=rss&amp;utm_medium=rss" target="_blank">Supersymmetry</a></li><li><a href="https://en.wikipedia.org/wiki/Kinematics?utm_source=rss&amp;utm_medium=rss" target="_blank">Kinematics</a></li><li><a href="https://en.wikipedia.org/wiki/Transfer_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Transfer Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_models?utm_source=rss&amp;utm_medium=rss" target="_blank">Foundation Models</a></li><li><a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture?utm_source=rss&amp;utm_medium=rss" target="_blank">ML Embeddings</a></li><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)?utm_source=rss&amp;utm_medium=rss" target="_blank">BERT</a></li><li><a href="https://airflow.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Airflow</a></li><li><a href="https://dagster.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Dagster</a></li><li><a href="https://www.prefect.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Prefect</a></li><li><a href="https://www.dask.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Dask</a></li><li><a href="https://www.kubeflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Kubeflow</a></li><li><a href="https://www.mysql.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">MySQL</a></li><li><a href="https://www.postgresql.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">PostgreSQL</a></li><li><a href="https://www.snowflake.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Snowflake</a></li><li><a href="https://aws.amazon.com/redshift/?utm_source=rss&amp;utm_medium=rss" target="_blank">Redshift</a></li><li><a href="https://aws.amazon.com/s3/?utm_source=rss&amp;utm_medium=rss" target="_blank">S3</a></li><li><a href="https://kubernetes.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Kubernetes</a></li><li><a href="https://github.com/pliang279/awesome-multimodal-ml?utm_source=rss&amp;utm_medium=rss" target="_blank">Multi-modal models</a></li><li><a href="https://en.wikipedia.org/wiki/Multi-task_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Multi-task models</a></li><li><a href="https://magic.wizards.com/en?utm_source=rss&amp;utm_medium=rss" target="_blank">Magic: The Gathering</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/[CC BY-SA 3.0](<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss</a>]]></description>
      <guid isPermaLink="false">podlove-2022-08-13t18:33:06+00:00-8f46146c472e4cc</guid>
      <link>https://www.aiengineeringpodcast.com/graft-modern-ai-platform-episode-7</link>
      <pubDate>Tue, 16 Aug 2022 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="60.61" duration="22.51">So, Brian, can you start by introducing yourself? Yeah. Hi. So Brian Calvert. I'm 1 of the cofounders, Craft with Adam and 4 other excellent folks. And, basically, I've kind of been in the data ML space in some fashion or another since my PhD where I worked on high high energy particle physics, analyzing bunch of data from the Large Hadron Collider.</podcast:soundbite>
      <podcast:soundbite startTime="382.31" duration="30.84">Adam is the originator of the idea for Graft, but I I think part of why what Adam presented resonated with me is that I'd also seen flavors of this too. What is this specifically? So I made mention that data really was 1 of those key requirements. For example, at Cruise, we were collecting all the simulation data and on road, all these sensors, all these derived things, like the car's perception of what objects were there, what were their kinematics, and using that in this very, like, self referential feedback loop to improve the car.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:07:34</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Using AI To Transform Your Business Without The Headache Using Graft</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>7</itunes:episode>
      <podcast:episode>7</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053896449456250f4ae4d-cc64-49e1-a5b1-914313213f12v1.mp3" length="50800779" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/63853053896449456250f4ae4d-cc64-49e1-a5b1-914313213f12v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_50f4ae4d-cc64-49e1-a5b1-914313213f12638557325563143728.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/50f4ae4d-cc64-49e1-a5b1-914313213f12638557325548169208.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/50f4ae4d-cc64-49e1-a5b1-914313213f12638557325543273546.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Accelerate Development And Delivery Of Your Machine Learning Projects With A Comprehensive Feature Platform</title>
      <description><![CDATA[Summary<br />In order for a machine learning model to build connections and context across the data that is fed into it the raw data needs to be engineered into semantic features. This is a process that can be tedious and full of toil, requiring constant upkeep and often leading to rework across projects and teams. In order to reduce the amount of wasted effort and speed up experimentation and training iterations a new generation of services are being developed. Tecton first built a feature store to serve as a central repository of engineered features and keep them up to date for training and inference. Since then they have expanded the set of tools and services to be a full-fledged feature platform. In this episode Kevin Stumpf explains the different capabilities and activities related to features that are necessary to maintain velocity in your machine learning projects.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Your host is Tobias Macey and today I’m interviewing Kevin Stumpf about the role of feature platforms in your ML engineering workflow</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what you mean by the term "feature platform"?&nbsp;<ul><li>What are the components and supporting capabilities that are needed for such a platform?</li></ul></li><li>How does the availability of engineered features impact the ability of an organization to put ML into production?</li><li>What are the points of friction that teams encounter when trying to build and maintain ML projects in the absence of a fully integrated feature platform?</li><li>Who are the target personas for the Tecton platform?&nbsp;<ul><li>What stages of the ML lifecycle does it address?</li></ul></li><li>Can you describe how you have designed the Tecton feature platform?&nbsp;<ul><li>How have the goals and capabilities of the product evolved since you started working on it?</li></ul></li><li>What is the workflow for an ML engineer or data scientist to build and maintain features and use them in the model development workflow?</li><li>What are the responsibilities of the MLOps stack that you have intentionally decided not to address?&nbsp;<ul><li>What are the interfaces and extension points that you offer for integrating with the other utilities needed to manage a full ML system?</li></ul></li><li>You wrote a post about the need to establish a DevOps approach to ML data. In keeping with that theme, can you describe how to think about the approach to testing and validation techniques for features and their outputs?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Tecton/Feast used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Tecton?</li><li>When is Tecton the wrong choice?</li><li>What do you have planned for the future of the Tecton feature platform?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/kevinstumpf/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://twitter.com/kevinmstumpf?lang=en&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">@kevinmstumpf</a> on Twitter</li><li><a href="https://github.com/kevinstumpf?utm_source=rss&amp;utm_medium=rss" target="_blank">kevinstumpf</a> on GitHub</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Links<br /><ul><li><a href="https://www.tecton.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tecton</a><ul><li><a href="https://www.dataengineeringpodcast.com/tecton-mlops-feature-store-episode-166/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://eng.uber.com/michelangelo-machine-learning-platform/?utm_source=rss&amp;utm_medium=rss" target="_blank">Uber Michaelangelo</a></li><li><a href="https://www.featurestore.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Feature Store</a></li><li><a href="https://www.snowflake.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Snowflake</a><ul><li><a href="https://www.dataengineeringpodcast.com/snowflakedb-cloud-data-warehouse-episode-110/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://aws.amazon.com/dynamodb/?utm_source=rss&amp;utm_medium=rss" target="_blank">DynamoDB</a></li><li><a href="https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew?utm_source=rss&amp;utm_medium=rss" target="_blank">Train/Serve Skew</a></li><li><a href="https://en.wikipedia.org/wiki/Lambda_architecture?utm_source=rss&amp;utm_medium=rss" target="_blank">Lambda Architecture</a></li><li><a href="https://redis.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Redis</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/[CC BY-SA 3.0](<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss</a>]]></description>
      <guid isPermaLink="false">podlove-2022-08-06t14:34:00+00:00-216b02e6499d16d</guid>
      <link>https://www.aiengineeringpodcast.com/tecton-machine-learning-feature-platform-episode-6</link>
      <pubDate>Sat, 6 Aug 2022 14:00:00 +0000</pubDate>
      <podcast:soundbite startTime="137.88" duration="38.62">Because without the platform in the earlier days, it just took several months to get any machine learning model into production for a lot of reasons that I'd be happy to go into, but it just took forever. And so we needed 1 centralized, standardized platform that could just automate away a lot of challenges around productionizing machine learning. And so we built Michelangelo, and that led to this nice Cambrian explosion of machine learning where all the different teams were now able to, with pretty low activation energy, get them all into production for use cases like fraud detection or recommendation systems, more dynamic pricing, ETA predictions, and you name it.</podcast:soundbite>
      <podcast:soundbite startTime="648.36" duration="36.86">I have the raw data available to be able to build these models. Now I actually want to go from this idea through to it's running in production. I'm able to make sure that it's healthy, and I can retrain it in the event that I have concept drift because the world is shifting around me. So you already made 1 big assumption, which is the data scientists actually has the data, and they have access to it. So that's great. That's 1 big first problem that a lot of companies first have to solve to be successful with an ML use case. But let's assume, okay. They have access to raw data. That's great. Now the challenges that they have to go through to actually get their features built and get them into production. Let's go through some concrete examples.</podcast:soundbite>
      <podcast:soundbite startTime="2304.26" duration="76.67">And as I was reading through that and thinking about my own experience of working in DevOps and working in software, the idea of testing and validation came to mind. And I'm wondering what your thoughts are on the overall approach to being able to test and validate the feature definitions and their outputs and ensure that you aren't introducing errors at that level, not necessarily digging into how that data plays with the actual model itself, but just being able to do the testing and validation of these features and ensuring that they stay within whatever bounds or parameters the creator of that feature wants to set. Yeah. That's super important. FAD was always front and center of our minds as we designed Tekton, and that's why we chose this features as code approach to Techton, where you manage the feature definitions in your own repository and where you roll them out using your existing CICD pipelines with our CLI. Because what that allows you to do is basically you'd create a new feature, you would check it into Git, Typically, somebody would be reviewing your pull request. And then once it's checked into Git, you'd have your CICD pipeline actually test and validate your feature before at the very end of it, once everything on screen, it would actually be rolled out to Tekton using our CLI.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:50:38</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Accelerate Development And Delivery Of Your Machine Learning Projects With A Comprehensive Feature Platform</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>6</itunes:episode>
      <podcast:episode>6</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305393614543207c1ca470-ca5a-4459-a018-f4297c421533v1.mp3" length="36914881" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305393614543207c1ca470-ca5a-4459-a018-f4297c421533v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_7c1ca470-ca5a-4459-a018-f4297c421533638557325095928593.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7c1ca470-ca5a-4459-a018-f4297c421533638557325092239971.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7c1ca470-ca5a-4459-a018-f4297c421533638557325086310382.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Build Better Models Through Data Centric Machine Learning Development With Snorkel AI</title>
      <description><![CDATA[Summary<br />Machine learning is a data hungry activity, and the quality of the resulting model is highly dependent on the quality of the inputs that it receives. Generating sufficient quantities of high quality labeled data is an expensive and time consuming process. In order to reduce that time and cost Alex Ratner and his team at Snorkel AI have built a system for powering data-centric machine learning development. In this episode he explains how the Snorkel platform allows domain experts to create labeling functions that translate their expertise into reusable logic that dramatically reduces the time needed to build training data sets and drives down the total cost.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Your host is Tobias Macey and today I’m interviewing Alex Ratner about Snorkel AI, a platform for data-centric machine learning workflows powered by programmatic data labeling techniques</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Snorkel AI is and the story behind it?</li><li>What are the problems that you are focused on solving?&nbsp;<ul><li>Which pieces of the ML lifecycle are you focused on?</li></ul></li><li>How did your experience building the open source Snorkel project and working with the community inform your product direction for Snorkel AI?&nbsp;<ul><li>How has the underlying Snorkel project evolved over the past 4 years?</li></ul></li><li>What are the deciding factors that an organization or ML team need to consider when evaluating existing labeling strategies against the programmatic approach that you provide?&nbsp;<ul><li>What are the features that Snorkel provides over and above managing code execution across the source data set?</li></ul></li><li>Can you describe what you have built at Snorkel AI and how it is implemented?&nbsp;<ul><li>What are some of the notable developments of the ML ecosystem that had a meaningful impact on your overall product vision/viability?</li></ul></li><li>Can you describe the workflow for an individual or team who is using Snorkel for generating their training data set?&nbsp;<ul><li>How does Snorkel integrate with the experimentation process to track how changes to labeling logic correlate with the performance of the resulting model?</li></ul></li><li>What are some of the complexities involved in designing and testing the labeling logic?&nbsp;<ul><li>How do you handle complex data formats such as audio, video, images, etc. that might require their own ML models to generate labels? (e.g. object detection for bounding boxes)</li></ul></li><li>With the increased scale and quality of labeled data that Snorkel AI offers, how does that impact the viability of autoML toolchains for generating useful models?</li><li>How are you managing the governance and feature boundaries between the open source Snorkel project and the business that you have built around it?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Snorkel AI used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Snorkel AI?</li><li>When is Snorkel AI the wrong choice?</li><li>What do you have planned for the future of Snorkel AI?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/alexander-ratner-038ba239/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://ajratner.github.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Website</a></li><li><a href="https://twitter.com/ajratner?utm_source=rss&amp;utm_medium=rss" target="_blank">@ajratner</a> on Twitter</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://snorkel.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Snorkel AI</a><ul><li><a href="https://www.dataengineeringpodcast.com/snorkel-with-alex-ratner-episode-15/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://www.washington.edu/?utm_source=rss&amp;utm_medium=rss" target="_blank">University of Washington</a></li><li><a href="https://github.com/snorkel-team/snorkel?utm_source=rss&amp;utm_medium=rss" target="_blank">Snorkel OSS</a></li><li><a href="https://en.wikipedia.org/wiki/Natural_language_processing?utm_source=rss&amp;utm_medium=rss" target="_blank">Natural Language Processing (NLP)</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">PyTorch</a><ul><li><a href="https://www.pythonpodcast.com/pytorch-deep-learning-epsiode-202/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Deep Learning</a></li><li><a href="https://en.wikipedia.org/wiki/Foundation_models?utm_source=rss&amp;utm_medium=rss" target="_blank">Foundation Models</a></li><li><a href="https://mlflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">MLFlow</a></li><li><a href="https://github.com/slundberg/shap?utm_source=rss&amp;utm_medium=rss" target="_blank">SHAP</a><ul><li><a href="https://www.pythonpodcast.com/shap-explainable-machine-learning-episode-335/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-07-29t02:17:09+00:00-df190a2e1abd670</guid>
      <link>https://www.aiengineeringpodcast.com/snorkel-ai-data-centric-machine-learning-episode-5</link>
      <pubDate>Fri, 29 Jul 2022 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="438.48" duration="19.99">Let let me dive in. And if I forget and you're curious, we can go back into why I say AI, not just machine learning. The TLDR is that we support today on our platform involves often the mix of, you know, learned components and other operators. So, you know, that's actually why, you know, I'm being more precise if I say AI in terms of the full output or that users build in our platform. But, mainly, I'll talk about the ML part today.</podcast:soundbite>
      <podcast:soundbite startTime="1592.78" duration="49.38">For organizations who are either starting their journey of implementing machine learning, and they are exploring the so called traditional approach of managing their labeled data, or they're already in that loop of, you know, we manually label our data or, you know, we hire 1 of these data labeling firms or we use something like Mechanical Turk. What are some of the kind of decision points or customer education that you work with them on to understand what is sort of the cost benefit of continuing with that manual labeling approach where you have a fairly high confidence that you're going to get a higher accuracy from those manual approaches versus going this programmatic path where maybe it complements the work that they're doing, but it allows them to scale more economically and effectively.</podcast:soundbite>
      <podcast:soundbite startTime="140.36" duration="26.61">Yeah. Well, you gotta cut me off if I ramble on too long about this, but let's see. I've coded since I was little, but I kinda did a detour into physics during undergrad. So then, you know, I was actually not a computer science major. I was working actually in some consulting I remember we were looking at the patent corpus, and I thought I started to think it was really fascinating that you had all this information about, you know, basically, everything anyone thought was worth, you know, patentable.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:53:49</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build Better Models Through Data Centric Machine Learning Development With Snorkel AI</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>5</itunes:episode>
      <podcast:episode>5</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305382990386707b865cbe-7f07-456a-ad33-2dddf9b07dd9v1.mp3" length="42788593" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305382990386707b865cbe-7f07-456a-ad33-2dddf9b07dd9v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_7b865cbe-7f07-456a-ad33-2dddf9b07dd9638557324820599445.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7b865cbe-7f07-456a-ad33-2dddf9b07dd9638557324812576521.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7b865cbe-7f07-456a-ad33-2dddf9b07dd9638557324805737289.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Declarative Machine Learning For High Performance Deep Learning Models With Predibase</title>
      <description><![CDATA[Summary<br />Deep learning is a revolutionary category of machine learning that accelerates our ability to build powerful inference models. Along with that power comes a great deal of complexity in determining what neural architectures are best suited to a given task, engineering features, scaling computation, etc. Predibase is building on the successes of the Ludwig framework for declarative deep learning and Horovod for horizontally distributing model training. In this episode CTO and co-founder of Predibase, Travis Addair, explains how they are reducing the burden of model development even further with their managed service for declarative and low-code ML and how they are integrating with the growing ecosystem of solutions for the full ML lifecycle.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Your host is Tobias Macey and today I’m interviewing Travis Addair about Predibase, a low-code platform for building ML models in a declarative format</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Predibase is and the story behind it?</li><li>Who is your target audience and how does that focus influence your user experience and feature development priorities?</li><li>How would you describe the semantic differences between your chosen terminology of "declarative ML" and the "autoML" nomenclature that many projects and products have adopted?&nbsp;<ul><li>Another platform that launched recently with a promise of "declarative ML" is Continual. How would you characterize your relative strengths?</li></ul></li><li>Can you describe how the Predibase platform is implemented?&nbsp;<ul><li>How have the design and goals of the product changed as you worked through the initial implementation and started working with early customers?</li><li>The operational aspects of the ML lifecycle are still fairly nascent. How have you thought about the boundaries for your product to avoid getting drawn into scope creep while providing a happy path to delivery?</li></ul></li><li>Ludwig is a core element of your platform. What are the other capabilities that you are layering around and on top of it to build a differentiated product?</li><li>In addition to the existing interfaces for Ludwig you created a new language in the form of PQL. What was the motivation for that decision?&nbsp;<ul><li>How did you approach the semantic and syntactic design of the dialect?</li><li>What is your vision for PQL in the space of "declarative ML" that you are working to define?</li></ul></li><li>Can you describe the available workflows for an individual or team that is using Predibase for prototyping and validating an ML model?&nbsp;<ul><li>Once a model has been deemed satisfactory, what is the path to production?</li></ul></li><li>How are you approaching governance and sustainability of Ludwig and Horovod while balancing your reliance on them in Predibase?</li><li>What are some of the notable investments/improvements that you have made in Ludwig during your work of building Predibase?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Predibase used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Predibase?</li><li>When is Predibase the wrong choice?</li><li>What do you have planned for the future of Predibase?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/travisaddair/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://github.com/tgaddair?utm_source=rss&amp;utm_medium=rss" target="_blank">tgaddair</a> on GitHub</li><li><a href="https://twitter.com/travisaddair?utm_source=rss&amp;utm_medium=rss" target="_blank">@travisaddair</a> on Twitter</li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://predibase.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Predibase</a></li><li><a href="https://horovod.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Horovod</a></li><li><a href="https://ludwig-ai.github.io/ludwig-docs/?utm_source=rss&amp;utm_medium=rss" target="_blank">Ludwig</a><ul><li><a href="https://www.pythonpodcast.com/ludwig-horovod-distributed-declarative-deep-learning-episode-341/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://en.wikipedia.org/wiki/Support-vector_machine?utm_source=rss&amp;utm_medium=rss" target="_blank">Support Vector Machine</a></li><li><a href="https://hadoop.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hadoop</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://eng.uber.com/michelangelo-machine-learning-platform/?utm_source=rss&amp;utm_medium=rss" target="_blank">Uber Michaelangelo</a></li><li><a href="https://en.wikipedia.org/wiki/Automated_machine_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">AutoML</a></li><li><a href="https://spark.apache.org/mllib/?utm_source=rss&amp;utm_medium=rss" target="_blank">Spark ML Lib</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Deep Learning</a></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">PyTorch</a></li><li><a href="https://continual.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Continual</a><ul><li><a href="https://www.dataengineeringpodcast.com/continual-declarative-machine-learning-episode-222/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://machinelearning.apple.com/research/overton?utm_source=rss&amp;utm_medium=rss" target="_blank">Overton</a></li><li><a href="https://kubernetes.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Kubernetes</a></li><li><a href="https://docs.ray.io/en/latest/?utm_source=rss&amp;utm_medium=rss" target="_blank">Ray</a></li><li><a href="https://developer.nvidia.com/nvidia-triton-inference-server?utm_source=rss&amp;utm_medium=rss" target="_blank">Nvidia Triton</a></li><li><a href="https://github.com/whylabs/whylogs?utm_source=rss&amp;utm_medium=rss" target="_blank">Whylogs</a><ul><li><a href="https://www.dataengineeringpodcast.com/whylogs-data-logging-data-observability-episode-283/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://wandb.ai/?utm_source=rss&amp;utm_medium=rss" target="_blank">Weights and Biases</a></li><li><a href="https://mlflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">MLFlow</a></li><li><a href="https://www.comet.com/site/?utm_source=rss&amp;utm_medium=rss" target="_blank">Comet</a></li><li><a href="https://en.wikipedia.org/wiki/Confusion_matrix?utm_source=rss&amp;utm_medium=rss" target="_blank">Confusion Matrices</a></li><li><a href="https://www.getdbt.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">dbt</a><ul><li><a href="https://www.dataengineeringpodcast.com/dbt-data-analytics-episode-81/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li><li><a href="https://pytorch.org/docs/stable/jit.html?utm_source=rss&amp;utm_medium=rss" target="_blank">Torchscript</a></li><li><a href="https://en.wikipedia.org/wiki/Self-supervised_learning?utm_source=rss&amp;utm_medium=rss" target="_blank">Self-supervised Learning</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-07-21t10:09:24+00:00-a0632a614d9bc23</guid>
      <link>https://www.aiengineeringpodcast.com/predibase-declarative-machine-learning-episode-4</link>
      <pubDate>Thu, 21 Jul 2022 23:00:00 +0000</pubDate>
      <podcast:soundbite startTime="1937.58" duration="24.74">And you mentioned the PQL dialect a couple of times, and I noticed that when I was going through some of the blog posts and and some of the early material that you have about what you're building at prediabase. And I'm wondering if you can speak to some of the motivation behind creating this new dialect and this new, I guess, language you could call it, and some of the ways that you think about the semantic and syntactic design of it.</podcast:soundbite>
      <podcast:soundbite startTime="191.02" duration="10.36">And I'm wondering if you can describe a bit more about what it is that you're building there and some of the story behind how you decided that this was a problem space that you wanted to spend your time and focus on.</podcast:soundbite>
      <podcast:soundbite startTime="662.06" duration="16.54">And I'm wondering if you can just talk to the differences in the nomenclature as far as what that really means and how the sort of expectations are different between an AutoML category of tool and a declarative ML category of tool?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>01:00:20</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Declarative Machine Learning For High Performance Deep Learning Models With Predibase</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>4</itunes:episode>
      <podcast:episode>4</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538841635223b2917f8d-14b0-4a17-bae8-81f31f643cedv1.mp3" length="48195459" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538841635223b2917f8d-14b0-4a17-bae8-81f31f643cedv1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_b2917f8d-14b0-4a17-bae8-81f31f643ced638557222324141111.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/b2917f8d-14b0-4a17-bae8-81f31f643ced638557222318905895.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/b2917f8d-14b0-4a17-bae8-81f31f643ced638557222315322362.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Stop Feeding Garbage Data To Your ML Models, Clean It Up With Galileo</title>
      <description><![CDATA[Summary<br />Machine learning is a force multiplier that can generate an outsized impact on your organization. Unfortunately, if you are feeding your ML model garbage data, then you will get orders of magnitude more garbage out of it. The team behind Galileo experienced that pain for themselves and have set out to make data management and cleaning for machine learning a first class concern in your workflow. In this episode Vikram Chatterji shares the story of how Galileo got started and how you can use their platform to fix your ML data so that you can get back to the fun parts.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Building good ML models is hard, but testing them properly is even harder. At Deepchecks, they built an open-source testing framework that follows best practices, ensuring that your models behave as expected. Get started quickly using their built-in library of checks for testing and validating your model’s behavior and performance, and extend it to meet your specific needs as your model evolves. Accelerate your machine learning projects by building trust in your models and automating the testing that you used to do manually. Go to <a href="https://www.themachinelearningpodcast.com/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/deepchecks</a> today to get started!</li><li>Your host is Tobias Macey and today I’m interviewing Vikram Chatterji about Galileo, a platform for uncovering and addressing data problems to improve your model quality</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Galileo is and the story behind it?</li><li>Who are the target users of the platform and what are the tools/workflows that you are replacing?&nbsp;<ul><li>How does that focus inform and influence the design and prioritization of features in the platform?</li></ul></li><li>What are some of the real-world impacts that you have experienced as a result of the kinds of data problems that you are addressing with Galileo?</li><li>Can you describe how the Galileo product is implemented?&nbsp;<ul><li>What are some of the assumptions that you had formed from your own experiences that have been challenged as you worked with early design partners?</li></ul></li><li>The toolchains and model architectures of any given team is unlikely to be a perfect match across departments or organizations. What are the core principles/concepts that you have hooked into in order to provide the broadest compatibility?&nbsp;<ul><li>What are the model types/frameworks/etc. that you have had to forego support for in the early versions of your product?</li></ul></li><li>Can you describe the workflow for someone building a machine learning model and how Galileo fits across the various stages of that cycle?&nbsp;<ul><li>What are some of the biggest difficulties posed by the non-linear nature of the experimentation cycle in model development?</li></ul></li><li>What are some of the ways that you work to quantify the impact of your tool on the productivity and profit contributions of an ML team/organization?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Galileo used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Galileo?</li><li>When is Galileo the wrong choice?</li><li>What do you have planned for the future of Galileo?</li></ul>Contact Info<br /><ul><li><a href="https://www.linkedin.com/in/vikram-chatterji/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email hosts@themachinelearningpodcast.com) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.rungalileo.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Galileo</a></li><li><a href="https://www.educative.io/edpresso/what-is-the-f1-score?utm_source=rss&amp;utm_medium=rss" target="_blank">F1 Score</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://keras.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Keras</a></li><li><a href="https://spacy.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">SpaCy</a><ul><li><a href="https://www.pythonpodcast.com/episode-87-spacy-with-matthew-honnibal/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://pytorch.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Pytorch</a><ul><li><a href="https://www.pythonpodcast.com/pytorch-deep-learning-epsiode-202/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://mxnet.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">MXNet</a></li><li><a href="https://jax.readthedocs.io/en/latest/?utm_source=rss&amp;utm_medium=rss" target="_blank">Jax</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-07-14t00:52:42+00:00-37211df4d5c5ae2</guid>
      <link>https://www.aiengineeringpodcast.com/galileo-machine-learning-data-management-episode-3</link>
      <pubDate>Thu, 14 Jul 2022 00:00:00 +0000</pubDate>
      <podcast:soundbite startTime="327.71" duration="25.51">So we decided to start this company with the idea that let's build out a way such that people can short circuit this entire process of working with the right kind of data. And can we do this in a way such that we can provide a really intelligent system, an intelligent bench on top of which they can bring their data, analyze it, fix it, and store it, and keep track of it? We call this the ML data intelligence platform, and that's where we just recently launched with Galileo.</podcast:soundbite>
      <podcast:soundbite startTime="400.50" duration="29.75">That's a great question. I think the issues that we've noticed users have vary based on where in the ML process they are at that point in time for a particular model. What I mean by that is so we've spoken to hundreds of ML teams in the course of the last year to kind of figure out what their issues are and what tools they're using. Turns out that if you look at the 1, 000 foot view of of unstructured data ML, you can have 3 different parts to this. There's a pretraining, posttraining, and postproduction phase.</podcast:soundbite>
      <podcast:soundbite startTime="1947.89" duration="28.77">Like, 50% of our team is ML research, which is notice it it's very different from most other ML companies, especially in this field. And the reason for that is because we realized that there's a lot that you can do from all of the different signals that the model is giving you and then provide that back to the user and kind of, like, almost like a superpower. And 1 aspect of that is, you're right, it's around ethics and how you can figure out is there a certain kind of bias? Then biases can come in and creep in in many different ways. Can you kind of automate that?</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:47:04</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Stop Feeding Garbage Data To Your ML Models, Clean It Up With Galileo</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305387154586297c3fd3ee-5349-4bfe-890e-63de281940c8v1.mp3" length="39270280" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/6385305387154586297c3fd3ee-5349-4bfe-890e-63de281940c8v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_7c3fd3ee-5349-4bfe-890e-63de281940c8638557221712720420.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7c3fd3ee-5349-4bfe-890e-63de281940c8638557221709404521.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/7c3fd3ee-5349-4bfe-890e-63de281940c8638557221706336472.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Build Better Machine Learning Models With Confidence By Adding Validation With Deepchecks</title>
      <description><![CDATA[Summary<br />Machine learning has the potential to transform industries and revolutionize business capabilities, but only if the models are reliable and robust. Because of the fundamental probabilistic nature of machine learning techniques it can be challenging to test and validate the generated models. The team at Deepchecks understands the widespread need to easily and repeatably check and verify the outputs of machine learning models and the complexity involved in making it a reality. In this episode Shir Chorev and Philip Tannor explain how they are addressing the problem with their open source deepchecks library and how you can start using it today to build trust in your machine learning applications.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Your host is Tobias Macey and today I’m interviewing Shir Chorev and Philip Tannor about Deepchecks, a Python package for comprehensively validating your machine learning models and data with minimal effort.</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Deepchecks is and the story behind it?</li><li>Who is the target audience for the project?&nbsp;<ul><li>What are the biggest challenges that these users face in bringing ML models from concept to production and how does DeepChecks address those problems?</li></ul></li><li>In the absence of DeepChecks how are practitioners solving the problems of model validation and comparison across iteratiosn?&nbsp;<ul><li>What are some of the other tools in this ecosystem and what are the differentiating features of DeepChecks?</li></ul></li><li>What are some examples of the kinds of tests that are useful for understanding the "correctness" of models?&nbsp;<ul><li>What are the methods by which ML engineers/data scientists/domain experts can define what "correctness" means in a given model or subject area?</li></ul></li><li>In software engineering the categories of tests are tiered as unit -&gt; integration -&gt; end-to-end. What are the relevant categories of tests that need to be built for validating the behavior of machine learning models?</li><li>How do model monitoring utilities overlap with the kinds of tests that you are building with deepchecks?</li><li>Can you describe how the DeepChecks package is implemented?&nbsp;<ul><li>How have the design and goals of the project changed or evolved from when you started working on it?</li><li>What are the assumptions that you have built up from your own experiences that have been challenged by your early users and design partners?</li></ul></li><li>Can you describe the workflow for an individual or team using DeepChecks as part of their model training and deployment lifecycle?</li><li>Test engineering is a deep discipline in its own right. How have you approached the user experience and API design to reduce the overhead for ML practitioners to adopt good practices?</li><li>What are the interfaces available for creating reusable tests and composing test suites together?</li><li>What are the additional services/capabilities that you are providing in your commercial offering?&nbsp;<ul><li>How are you managing the governance and sustainability of the OSS project and balancing that against the needs/priorities of the business?</li></ul></li><li>What are the most interesting, innovative, or unexpected ways that you have seen DeepChecks used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on DeepChecks?</li><li>When is DeepChecks the wrong choice?</li><li>What do you have planned for the future of DeepChecks?</li></ul>Contact Info<br /><ul><li>Shir&nbsp;<ul><li><a href="https://www.linkedin.com/in/shirchorev/?originalSubdomain=il&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://github.com/shir22?utm_source=rss&amp;utm_medium=rss" target="_blank">shir22</a> on GitHub</li></ul></li><li>Philip&nbsp;<ul><li><a href="https://www.linkedin.com/in/philip-tannor-a6a910b7?originalSubdomain=il&amp;utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li><li><a href="https://twitter.com/philiptannor?utm_source=rss&amp;utm_medium=rss" target="_blank">@philiptannor</a> on Twitter</li></ul></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email hosts@themachinelearningpodcast.com) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://github.com/deepchecks/deepchecks?utm_source=rss&amp;utm_medium=rss" target="_blank">DeepChecks</a></li><li><a href="https://en.wikipedia.org/wiki/Random_forest?utm_source=rss&amp;utm_medium=rss" target="_blank">Random Forest</a></li><li><a href="https://en.wikipedia.org/wiki/Talpiot_program?utm_source=rss&amp;utm_medium=rss" target="_blank">Talpiot Program</a></li><li><a href="https://github.com/slundberg/shap/?utm_source=rss&amp;utm_medium=rss" target="_blank">SHAP</a><ul><li><a href="https://www.pythonpodcast.com/shap-explainable-machine-learning-episode-335/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://airflow.apache.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Airflow</a></li><li><a href="https://greatexpectations.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Great Expectations</a><ul><li><a href="https://www.dataengineeringpodcast.com/great-expectations-technical-debt-data-pipeline-episode-117/?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast Episode</a></li></ul></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-07-06t01:35:41+00:00-e3950a082837335</guid>
      <link>https://www.aiengineeringpodcast.com/deepchecks-open-source-macehine-learning-testing-episode-2</link>
      <pubDate>Wed, 6 Jul 2022 02:00:00 +0000</pubDate>
      <podcast:soundbite startTime="1015.91" duration="57.58">And so I'm curious what you've seen as far as ways the teams might think about building in some of those validations as part of their kind of general test suite for any machine learning model to be able to catch or report on some of these ways that bias might be exhibited? Really important question, bias. And I think to some people, it feels like bias is just, like, another, you know, interesting kind of lecture type thing. And, you know, from some other people, some other populations, sometimes, you know, these types of things even without you knowing about them really have a drastic effect on your life, and it's really facing. The more machine learning is gonna be deployed, the more you might feel. It's been from a, like, engineering or professional point of view, I think I wanna separate, you know, 2 different use cases. 1 of them is structured data, the other is unstructured data. When you have structured data, then, you know, there are some challenges. No 1 just look at, I don't know, gender or, you know, a ZIP code or something like that and compare it to whatever. You don't want it to be correlated to. You also want to look for hidden features.</podcast:soundbite>
      <podcast:soundbite startTime="213.79" duration="42.33">So what was really interesting about the roles I had in the, like, machinery research group I mentioned was that we got to see a lot of projects, and we got to, like, deal with the interesting parts while collaborating with, like, many different parts within the let's call it the wider kind of defense ecosystem, which was pretty much ahead of most of the civilian world. And I know it's counterintuitive, but there were a lot of things that were pretty new there. So I really felt like a potential customer for what I'm doing now. We just couldn't find any solutions that were kind of making sure that machinery models are behaving as expected. And, you know, there wasn't really anything out there, and that's a big deal because, you know, we kind of felt that what we're what we're seeing in our domain, it was probably what's gonna happen in a lot of different companies in a few years.</podcast:soundbite>
      <podcast:soundbite startTime="2186.54" duration="110.51">speaking to the open commercial aspect of what you're building, with speaking to the open source project, I'm wondering what are some of the additional capabilities and services that you're layering on top of the open source project and how you think about the governance and sustainability aspects of the deep checks, the package, and balance that against the business needs of DeepChex, the business. In general, we're an open core company. That means, you know, our focus is definitely the open source. And what we really care about is giving a quality product to the community. And we realized most people using DeepChex won't pay, and we're completely fine with that. That's the way we're aiming. We're building community and the user base in a way that the sheer numbers are enough that even if, you know, some of the users, hey, then that's enough for us. So typically, it makes sense for some of these companies to engage with us either, you know, whether a company that needs more governance and, you know, features that have to do with the governance for the models themselves. So that could mean, you know, if you're doing monitoring and you're not just monitoring only be able to, like, the scientific aspect, but you wanna be able to have control over, you know, who's in charge of which model and so forth. The other side is companies that are, you know, in production, not just in training phase. So they have typically, you know, companies will start and have between 1 5 models in production depending on a few different characteristics. For those types of companies, then, you know, it's performance monitoring, drift, things like that. But while we're integrating with the different types of databases, have a few different deployment options, it's built in a way that they would expect to use us as an enterprise offering. So it's interesting because it's the same algorithms, the same look and feel, the same API that users are using when they use the open source package. But then typically with our requirements from other stakeholders or other users, when you need more UI type features and so forth, then we think it made sense to move. So it's a pretty clear motion.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:48:40</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build Better Machine Learning Models With Confidence By Adding Validation With Deepchecks</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>2</itunes:episode>
      <podcast:episode>2</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539141904146aaa856cd-3111-45af-ae0d-cbeda156ec02v1.mp3" length="38547030" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539141904146aaa856cd-3111-45af-ae0d-cbeda156ec02v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_aaa856cd-3111-45af-ae0d-cbeda156ec02638557222631098529.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/aaa856cd-3111-45af-ae0d-cbeda156ec02638557222625276638.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/aaa856cd-3111-45af-ae0d-cbeda156ec02638557222621254725.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Build A Full Stack ML Powered App In An Afternoon With Baseten</title>
      <description><![CDATA[Summary<br />Building an ML model is getting easier than ever, but it is still a challenge to get that model in front of the people that you built it for. Baseten is a platform that helps you quickly generate a full stack application powered by your model. You can easily create a web interface and APIs powered by the model you created, or a pre-trained model from their library. In this episode Tuhin Srivastava, co-founder of Basten, explains how the platform empowers data scientists and ML engineers to get their work in production without having to negotiate for help from their application development colleagues.<br />Announcements<br /><ul><li>Hello and welcome to the Machine Learning Podcast, the podcast about machine learning and how to bring it from idea to delivery.</li><li>Data powers machine learning, but poor data quality is the largest impediment to effective ML today. Galileo is a collaborative data bench for data scientists building Natural Language Processing (NLP) models to programmatically inspect, fix and track their data across the ML workflow (pre-training, post-training and post-production) – no more excel sheets or ad-hoc python scripts. Get meaningful gains in your model performance fast, dramatically reduce data labeling and procurement costs, while seeing 10x faster ML iterations. Galileo is offering listeners a free 30 day trial and a 30% discount on the product there after. This offer is available until Aug 31, so go to <a href="https://www.themachinelearningpodcast.com/galileo?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/galileo</a> and request a demo today!</li><li>Do you wish you could use artificial intelligence to drive your business the way Big Tech does, but don’t have a money printer? Graft is a cloud-native platform that aims to make the AI of the 1% accessible to the 99%. Wield the most advanced techniques for unlocking the value of data, including text, images, video, audio, and graphs. No machine learning skills required, no team to hire, and no infrastructure to build or maintain. For more information on Graft or to schedule a demo, visit <a href="https://www.themachinelearningpodcast.com/graft?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/graft</a> today and tell them Tobias sent you.</li><li>Predibase is a low-code ML platform without low-code limits. Built on top of our open source foundations of Ludwig and Horovod, our platform allows you to train state-of-the-art ML and deep learning models on your datasets at scale. Our platform works on text, images, tabular, audio and multi-modal data using our novel compositional model architecture. We allow users to operationalize models on top of the modern data stack, through REST and PQL – an extension of SQL that puts predictive power in the hands of data practitioners. Go to <a href="https://www.themachinelearningpodcast.com/predibase?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com/predibase</a> today to learn more and try it out!</li><li>Your host is Tobias Macey and today I’m interviewing Tuhin Srivastava about Baseten, an ML Application Builder for data science and machine learning teams</li></ul>Interview<br /><ul><li>Introduction</li><li>How did you get involved in machine learning?</li><li>Can you describe what Baseten is and the story behind it?</li><li>Who are the target users for Baseten and what problems are you solving for them?</li><li>What are some of the typical technical requirements for an application that is powered by a machine learning model?&nbsp;<ul><li>In the absence of Baseten, what are some of the common utilities/patterns that teams might rely on?</li></ul></li><li>What kinds of challenges do teams run into when serving a model in the context of an application?</li><li>There are a number of projects that aim to reduce the overhead of turning a model into a usable product (e.g. Streamlit, Hex, etc.). What is your assessment of the current ecosystem for lowering the barrier to product development for ML and data science teams?</li><li>Can you describe how the Baseten platform is designed?&nbsp;<ul><li>How have the design and goals of the project changed or evolved since you started working on it?</li><li>How do you handle sandboxing of arbitrary user-managed code to ensure security and stability of the platform?</li></ul></li><li>How did you approach the system design to allow for mapping application development paradigms into a structure that was accessible to ML professionals?</li><li>Can you describe the workflow for building an ML powered application?</li><li>What types of models do you support? (e.g. NLP, computer vision, timeseries, deep neural nets vs. linear regression, etc.)&nbsp;<ul><li>How do the monitoring requirements shift for these different model types?</li><li>What other challenges are presented by these different model types?</li></ul></li><li>What are the limitations in size/complexity/operational requirements that you have to impose to ensure a stable platform?</li><li>What is the process for deploying model updates?</li><li>For organizations that are relying on Baseten as a prototyping platform, what are the options for taking a successful application and handing it off to a product team for further customization?</li><li>What are the most interesting, innovative, or unexpected ways that you have seen Baseten used?</li><li>What are the most interesting, unexpected, or challenging lessons that you have learned while working on Baseten?</li><li>When is Baseten the wrong choice?</li><li>What do you have planned for the future of Baseten?</li></ul>Contact Info<br /><ul><li><a href="https://twitter.com/tuhinone?utm_source=rss&amp;utm_medium=rss" target="_blank">@tuhinone</a> on Twitter</li><li><a href="https://www.linkedin.com/in/tuhin-srivastava-60601114/?utm_source=rss&amp;utm_medium=rss" target="_blank">LinkedIn</a></li></ul>Parting Question<br /><ul><li>From your perspective, what is the biggest barrier to adoption of machine learning today?</li></ul>Closing Announcements<br /><ul><li>Thank you for listening! Don’t forget to check out our other shows. The <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> covers the latest on modern data management. Podcast.__init__ covers the Python language, its community, and the innovative ways it is being used.</li><li>Visit the <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">site</a> to subscribe to the show, sign up for the mailing list, and read the show notes.</li><li>If you’ve learned something or tried out a project from the show then tell us about it! Email <a target="_blank">hosts@themachinelearningpodcast.com</a>) with your story.</li><li>To help other people find the show please leave a review on <a href="https://podcasts.apple.com/us/podcast/the-machine-learning-podcast/id1626358243?utm_source=rss&amp;utm_medium=rss" target="_blank">iTunes</a> and tell your friends and co-workers</li></ul>Links<br /><ul><li><a href="https://www.baseten.co/?utm_source=rss&amp;utm_medium=rss" target="_blank">Baseten</a></li><li><a href="https://www.baseten.co/?utm_source=rss&amp;utm_medium=rss" target="_blank">Gumroad</a></li><li><a href="https://scikit-learn.org/stable/?utm_source=rss&amp;utm_medium=rss" target="_blank">scikit-learn</a></li><li><a href="https://www.tensorflow.org/?utm_source=rss&amp;utm_medium=rss" target="_blank">Tensorflow</a></li><li><a href="https://keras.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Keras</a></li><li><a href="https://streamlit.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Streamlit</a><ul><li><a href="https://www.pythonpodcast.com/streamlit-web-application-episode-238/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://retool.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Retool</a></li><li><a href="https://hex.tech/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hex</a><ul><li><a href="https://www.pythonpodcast.com/hex-collaborative-notebooks-episode-294/?utm_source=rss&amp;utm_medium=rss" target="_blank">Podcast.__init__ Episode</a></li></ul></li><li><a href="https://kubernetes.io/?utm_source=rss&amp;utm_medium=rss" target="_blank">Kubernetes</a></li><li><a href="https://github.com/react-monaco-editor/react-monaco-editor?utm_source=rss&amp;utm_medium=rss" target="_blank">React Monaco</a></li><li><a href="https://huggingface.co/?utm_source=rss&amp;utm_medium=rss" target="_blank">Huggingface</a></li><li><a href="https://www.airtable.com/?utm_source=rss&amp;utm_medium=rss" target="_blank">Airtable</a></li><li><a href="https://openai.com/dall-e-2/?utm_source=rss&amp;utm_medium=rss" target="_blank">Dall-E 2</a></li><li><a href="https://en.wikipedia.org/wiki/GPT-3?utm_source=rss&amp;utm_medium=rss" target="_blank">GPT-3</a></li><li><a href="https://wandb.ai/site?utm_source=rss&amp;utm_medium=rss" target="_blank">Weights and Biases</a></li></ul>The intro and outro music is from <a href="https://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/Tales_Of_A_Dead_Fish/Hitmans_Lovesong/?utm_source=rss&amp;utm_medium=rss" target="_blank">Hitman’s Lovesong feat. Paola Graziano</a> by <a href="http://freemusicarchive.org/music/The_Freak_Fandango_Orchestra/?utm_source=rss&amp;utm_medium=rss" target="_blank">The Freak Fandango Orchestra</a>/<a href="https://creativecommons.org/licenses/by-sa/3.0/?utm_source=rss&amp;utm_medium=rss" target="_blank">CC BY-SA 3.0</a>]]></description>
      <guid isPermaLink="false">podlove-2022-06-28t00:36:46+00:00-6e6defdac20d145</guid>
      <link>https://www.aiengineeringpodcast.com/wrap-your-model-in-a-full-stack-application-in-an-afternoon-with-baseten</link>
      <pubDate>Wed, 29 Jun 2022 01:00:00 +0000</pubDate>
      <podcast:soundbite startTime="700.32" duration="42.98">In terms of the actual process of running a model in the context of an application beyond just being able to wire together the UI or build the API, what are some of the sort of core technical requirements that are needed to be able to actually support that model as it's operating and ensure that you're able to scale it as usage grows or ensure that you're able to monitor it or manage the integration of the API endpoints into the actual model execution and any sort of, you know, supporting storage or the other sort of technical components that are required just to be able to say, I have a model, I have an application, and everything is running and happy.</podcast:soundbite>
      <podcast:soundbite startTime="319.83" duration="44.49">In terms of the problems that you're solving, you made it pretty clear that, you know, there's the initial step of, I've got a model and I can put an API in front of it, but then how do you actually build the whole application around it? And so in terms of the solution for that problem, I'm wondering if you can speak to the type of user that you're focused on addressing to fill that requirement and some of the types of organizations that might rely on that capability rather than maybe having their own in house team to productionize these applications around these models or sort of what the typical flow is from, I've got a model and I've got a prototype built with this, you know, full stack app builder in the form of base 10. And then now I actually want to, you know, bring the feature set even further.</podcast:soundbite>
      <podcast:soundbite startTime="106.98" duration="13.50">So, Tuheen, can you start by introducing yourself? Yeah. Hey. I'm Tuheen. I'm the CEO and 1 of the cofounders of Base 10. I I have a background in machine learning, have been founded a couple of companies. I've been working on Base 10 since 2019.</podcast:soundbite>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:46:26</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Build A Full Stack ML Powered App In An Afternoon With Baseten</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:episodeType>Full</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539420862439cb6342ed-8f7e-4f10-ac57-fa43594c5455v1.mp3" length="34164566" type="audio/mpeg" />
      <podcast:chapters url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530539420862439cb6342ed-8f7e-4f10-ac57-fa43594c5455v1.chapters.json" type="application/json" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/transcript_cb6342ed-8f7e-4f10-ac57-fa43594c5455638557220343225082.html" type="text/html" language="en" rel="transcript" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/cb6342ed-8f7e-4f10-ac57-fa43594c5455638557220340083932.srt" type="application/x-subrip" language="en" rel="captions" />
      <podcast:transcript url="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/cb6342ed-8f7e-4f10-ac57-fa43594c5455638557220334857956.vtt" type="text/vtt" language="en" rel="captions" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
    <item>
      <title>Introducing The Show</title>
      <description><![CDATA[Hello, and welcome to the Machine Learning Podcast. I’m your host, Tobias Macey. You might know me from the <a href="https://www.dataengineeringpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Data Engineering Podcast</a> or the <a href="https://www.pythonpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">Python Podcast.__init__</a>. If you work with machine learning and AI, or you’re curious about it and want to learn more, then this show is for you. We’ll go beyond the esoteric research and flashy headlines and find out how machine learning is making an impact on the world and creating value for business. Along the way we’ll be joined by the researchers, engineers, and entrepreneurs who are shaping the industry. So go to <a href="https://www.themachinelearningpodcast.com?utm_source=rss&amp;utm_medium=rss" target="_blank">themachinelearningpodcast.com</a> today to subscribe and stay informed on how ML/AI are being used, how it works, and how to go from idea to production.<br /><figure><img src="https://analytics.boundlessnotions.com/piwik.php?idsite=3&amp;rec=1&amp;url=https%3A%2F%2Fwww.themachinelearningpodcast.com%2Fintroducing-the-show-episode-0%2F&amp;action_name=Introducing+The+Show&amp;urlref=https%3A%2F%2Fwww.themachinelearningpodcast.com%2Ffeed%2F&amp;utm_source=rss&amp;utm_medium=rss" width="0" height="0"><figcaption></figcaption></figure><br /><a href="https://machinelearning.supercast.com/" target="_blank">Support The Machine Learning Podcast</a>]]></description>
      <guid isPermaLink="false">podlove-2022-06-03t12:12:04+00:00-486b841f7253ee2</guid>
      <link>https://www.themachinelearningpodcast.com/introducing-the-show-episode-0</link>
      <pubDate>Fri, 3 Jun 2022 12:00:00 +0000</pubDate>
      <itunes:image href="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg" />
      <podcast:images srcset="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557211890591941ai_engineering_podcast_logo.jpg 1500w" />
      <itunes:duration>00:01:12</itunes:duration>
      <itunes:explicit>false</itunes:explicit>
      <itunes:title>Introducing The Show</itunes:title>
      <itunes:author>Tobias Macey</itunes:author>
      <itunes:episodeType>Trailer</itunes:episodeType>
      <enclosure url="https://op3.dev/e/dts.podtrac.com/redirect.mp3/serve.podhome.fm/episode/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638530538342328863734a1e90-cdeb-4cc8-8d3f-33473c81129e.mp3" length="977060" type="audio/mpeg" />
      <podcast:person role="Host" group="Cast" href="https://www.boundlessnotions.com" img="https://assets.podhome.fm/f6ff0caa-931b-4c08-bfdd-08dc7f5cd336/638557955481531561square.jpg">Tobias Macey</podcast:person>
    </item>
  </channel>
</rss>