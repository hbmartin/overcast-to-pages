<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <atom:link href="https://feeds.megaphone.fm/nvidiaaipodcast" rel="self" type="application/rss+xml"/>
    <title>NVIDIA AI Podcast</title>
    <link>https://ai-podcast.nvidia.com</link>
    <language>en</language>
    <copyright>All rights reserved e203f610-4315-11f0-9656-27588e6ca9e9</copyright>
    <description>Explore how the latest technologies are shaping our world, from groundbreaking discoveries to transformative sustainability efforts. The NVIDIA AI Podcast shines a light on the stories and solutions behind the most innovative changes, helping to inspire and educate listeners. Every week, we’ll bring you another tale, another 30-minute interview, as we build a real-time oral history of AI that’s already garnered nearly 6.5 million listens and been acclaimed as one of the best AI and machine learning podcasts. Listen in and get inspired. More information: https://ai-podcast.nvidia.com/</description>
    <image>
      <url>https://megaphone.imgix.net/podcasts/b569e226-f45b-11ef-8eab-87014600b959/image/930a52dc0716b826d78f94be0e1a163c.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress</url>
      <title>NVIDIA AI Podcast</title>
      <link>https://ai-podcast.nvidia.com</link>
    </image>
    <itunes:explicit>no</itunes:explicit>
    <itunes:type>episodic</itunes:type>
    <itunes:subtitle>Exploring AI one person, one interview, one story at a time. </itunes:subtitle>
    <itunes:author>NVIDIA</itunes:author>
    <itunes:summary>Explore how the latest technologies are shaping our world, from groundbreaking discoveries to transformative sustainability efforts. The NVIDIA AI Podcast shines a light on the stories and solutions behind the most innovative changes, helping to inspire and educate listeners. Every week, we’ll bring you another tale, another 30-minute interview, as we build a real-time oral history of AI that’s already garnered nearly 6.5 million listens and been acclaimed as one of the best AI and machine learning podcasts. Listen in and get inspired. More information: https://ai-podcast.nvidia.com/</itunes:summary>
    <content:encoded>
      <![CDATA[<p>Explore how the latest technologies are shaping our world, from groundbreaking discoveries to transformative sustainability efforts. The <em>NVIDIA AI Podcast</em> shines a light on the stories and solutions behind the most innovative changes, helping to inspire and educate listeners. Every week, we’ll bring you another tale, another 30-minute interview, as we build a real-time oral history of AI that’s already garnered nearly 6.5 million listens and been acclaimed as one of the best AI and machine learning podcasts. Listen in and get inspired. <strong>More information: </strong><a href="https://ai-podcast.nvidia.com/"><strong>https://ai-podcast.nvidia.com/</strong></a></p>]]>
    </content:encoded>
    <itunes:owner>
      <itunes:name>The AI Podcast</itunes:name>
      <itunes:email>aipodcast@nvidia.com</itunes:email>
    </itunes:owner>
    <itunes:image href="https://megaphone.imgix.net/podcasts/b569e226-f45b-11ef-8eab-87014600b959/image/930a52dc0716b826d78f94be0e1a163c.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
    <itunes:category text="Technology">
    </itunes:category>
    <item>
      <title>CVS Health and Aible are Delivering Enterprise AI with Rapid Prototyping, Agents, and Reasoning Models - Ep. 261</title>
      <description>Tony Ambrozie from CVS Health and Arijit Sengupta from Aible share how their partnership is transforming enterprise AI development through rapid prototyping and human-centered design. Discover their proven methodology for moving from concept to production in just 30 days, why they treat AI agents like interns who need training and feedback, and how reasoning models are creating more reliable and trustworthy AI systems. They also explore the future of autonomous agents, the importance of responsible AI in healthcare, and why the next wave of AI will focus on empowering humans rather than replacing them.


Learn more at: ⁠ai-podcast.nvidia.com</description>
      <pubDate>Wed, 18 Jun 2025 15:45:00 -0000</pubDate>
      <itunes:title>CVS Health and Abile are Delivering Enterprise AI with Rapid Prototyping, Agents, and Reasoning Models</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>261</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/feefe422-42fd-11f0-ac75-af90761dfddf/image/74b77dad19d202920999e585b1ac7ce6.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Tony Ambrozie from CVS Health and Arijit Sengupta from Aible share how their partnership is transforming enterprise AI development through rapid prototyping and human-centered design. Discover their proven methodology for moving from concept to production in just 30 days, why they treat AI agents like interns who need training and feedback, and how reasoning models are creating more reliable and trustworthy AI systems. They also explore the future of autonomous agents, the importance of responsible AI in healthcare, and why the next wave of AI will focus on empowering humans rather than replacing them.


Learn more at: ⁠ai-podcast.nvidia.com</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Tony Ambrozie from CVS Health and Arijit Sengupta from Aible share how their partnership is transforming enterprise AI development through rapid prototyping and human-centered design. Discover their proven methodology for moving from concept to production in just 30 days, why they treat AI agents like interns who need training and feedback, and how reasoning models are creating more reliable and trustworthy AI systems. They also explore the future of autonomous agents, the importance of responsible AI in healthcare, and why the next wave of AI will focus on empowering humans rather than replacing them.</p>
<p>
Learn more at: ⁠<a href="https://nvda.ws/4n79196">ai-podcast.nvidia.com</a></p>]]>
      </content:encoded>
      <itunes:duration>2374</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[feefe422-42fd-11f0-ac75-af90761dfddf]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4792321922.mp3?updated=1750194480" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Marco Pavone on AI Simulation, Safety, and the Road to Autonomous Vehicles - Ep. 260</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>In this episode of the NVIDIA AI Podcast, Dr. Marco Pavone, Director of Autonomous Vehicle Research at NVIDIA and Professor at Stanford University, joins us to discuss the cutting-edge technologies making autonomous vehicles safer than ever. Learn how digital twins and high-fidelity simulation are improving vehicle testing, accelerating development, and reducing real-world risks. Dr. Pavone also shares insights on the latest advances in generative AI and foundation models, and its impact on autonomous vehicle innovation—from city streets to aerospace.



Learn more at: ai-podcast.nvidia.com</description>
      <pubDate>Wed, 11 Jun 2025 07:00:00 -0000</pubDate>
      <itunes:title>NVIDIA’s Marco Pavone on AI Simulation, Safety, and the Road to Autonomous Vehicles</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>260</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f4842126-3fea-11f0-bb30-e3883493f933/image/f15c474a09d35f3e7dad385465af5661.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, Dr. Marco Pavone, Director of Autonomous Vehicle Research at NVIDIA and Professor at Stanford University, joins us to discuss the cutting-edge technologies making autonomous vehicles safer than ever. Learn how digital twins and high-fidelity simulation are improving vehicle testing, accelerating development, and reducing real-world risks. Dr. Pavone also shares insights on the latest advances in generative AI and foundation models, and its impact on autonomous vehicle innovation—from city streets to aerospace.



Learn more at: ai-podcast.nvidia.com</itunes:summary>
      <content:encoded>
        <![CDATA[<p>In this episode of the NVIDIA AI Podcast, Dr. Marco Pavone, Director of Autonomous Vehicle Research at NVIDIA and Professor at Stanford University, joins us to discuss the cutting-edge technologies making autonomous vehicles safer than ever. Learn how digital twins and high-fidelity simulation are improving vehicle testing, accelerating development, and reducing real-world risks. Dr. Pavone also shares insights on the latest advances in generative AI and foundation models, and its impact on autonomous vehicle innovation—from city streets to aerospace.</p>
<p><br></p>
<p>Learn more at: <a href="https://nvda.ws/3HxWaMY">ai-podcast.nvidia.com</a></p>]]>
      </content:encoded>
      <itunes:duration>2144</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[f4842126-3fea-11f0-bb30-e3883493f933]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2797470744.mp3?updated=1749658963" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>The Future of Humanoid Robots With 1X's Bernt Bornich - Ep. 259</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Bernt Børnich, founder and CEO of 1X Technologies, shares his vision for the future of humanoid robotics. Hear how the company is building fully autonomous robots that can learn and adapt in real-world environments.



Learn more at ai-podcast.nvidia.com</description>
      <pubDate>Wed, 04 Jun 2025 15:45:00 -0000</pubDate>
      <itunes:title>The Future of Humanoid Robots With 1X's Bernt Bornich</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>259</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0205bfc8-34e5-11f0-a0e7-d7ea75d154a8/image/88084b09a2aafa2eb9e69be25b9b33a6.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Bernt Børnich, founder and CEO of 1X Technologies, shares his vision for the future of humanoid robotics. Hear how the company is building fully autonomous robots that can learn and adapt in real-world environments.



Learn more at ai-podcast.nvidia.com</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Bernt Børnich, founder and CEO of 1X Technologies, shares his vision for the future of humanoid robotics. Hear how the company is building fully autonomous robots that can learn and adapt in real-world environments.</p>
<p><br></p>
<p>Learn more at <a href="https://nvda.ws/43t2ZIr">ai-podcast.nvidia.com</a> </p>
<p><br></p>]]>
      </content:encoded>
      <itunes:duration>1885</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[0205bfc8-34e5-11f0-a0e7-d7ea75d154a8]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2289926480.mp3?updated=1749572759" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Bartley Richardson on Why ‘Agentic AI Is Next-Level Automation’ - Ep. 258</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Bartley Richardson, senior director of engineering and AI infrastructure at NVIDIA, discusses the transformative potential of agentic AI as the next level of automation and introduces the NVIDIA Agent Intelligence toolkit, which ensures seamless integration and observability across multi-vendor agent systems.</description>
      <pubDate>Wed, 28 May 2025 15:45:00 -0000</pubDate>
      <itunes:title>NVIDIA’s Bartley Richardson on Why ‘Agentic AI Is Next-Level Automation’</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>258</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/7fac56f8-34e5-11f0-b6ad-73975b0ff918/image/006ab45ac814d71587bd41de02533042.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Bartley Richardson, senior director of engineering and AI infrastructure at NVIDIA, discusses the transformative potential of agentic AI as the next level of automation and introduces the NVIDIA Agent Intelligence toolkit, which ensures seamless integration and observability across multi-vendor agent systems.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Bartley Richardson, senior director of engineering and AI infrastructure at NVIDIA, discusses the transformative potential of agentic AI as the next level of automation and introduces the NVIDIA Agent Intelligence toolkit, which ensures seamless integration and observability across multi-vendor agent systems.</p>]]>
      </content:encoded>
      <itunes:duration>1712</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[7fac56f8-34e5-11f0-b6ad-73975b0ff918]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5557359354.mp3?updated=1747682375" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Siemens Is Bringing AI to Factory Floors - Ep. 257</title>
      <description>Matthias Loskyll, head of virtual control and industrial AI at Siemens Factory Automation, joins the NVIDIA AI Podcast to discuss how AI, simulation and digital twins are making significant impacts in manufacturing. From automating defect detection with Siemens Inspekto to enhancing production efficiency, NVIDIA’s collaboration with Siemens is making advanced automation accessible and secure for manufacturers.</description>
      <pubDate>Tue, 20 May 2025 15:45:00 -0000</pubDate>
      <itunes:title>How Siemens Is Bringing AI to Factory Floors</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>257</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f4dc9a52-31b9-11f0-99d3-7bcd4cdc2ed1/image/243c09cead558b41da18290912f58efd.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Matthias Loskyll, head of virtual control and industrial AI at Siemens Factory Automation, joins the NVIDIA AI Podcast to discuss how AI, simulation and digital twins are making significant impacts in manufacturing. From automating defect detection with Siemens Inspekto to enhancing production efficiency, NVIDIA’s collaboration with Siemens is making advanced automation accessible and secure for manufacturers.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Matthias Loskyll, head of virtual control and industrial AI at Siemens Factory Automation, joins the NVIDIA AI Podcast to discuss how AI, simulation and digital twins are making significant impacts in manufacturing. From automating defect detection with Siemens Inspekto to enhancing production efficiency, NVIDIA’s collaboration with Siemens is making advanced automation accessible and secure for manufacturers.</p>]]>
      </content:encoded>
      <itunes:duration>2238</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[f4dc9a52-31b9-11f0-99d3-7bcd4cdc2ed1]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2321858142.mp3?updated=1747333820" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Visa Is Making Payments Safer and Smarter with AI - Ep. 256</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Visa processes an astounding number of transactions each year, which means even small improvements in its systems can have a significant impact. Sarah Laszlo, senior director of Visa’s machine learning platform, joins the AI Podcast to discuss how AI is transforming the way the company serves its global customer base, from advancing fraud prevention to enhancing personalization. She also shares valuable insights for enterprises looking to adopt generative AI, emphasizing the importance of using open-source models and fostering strong relationships between governance and technical teams.</description>
      <pubDate>Wed, 14 May 2025 15:45:00 -0000</pubDate>
      <itunes:title>How Visa Is Making Payments Safer and Smarter with AI</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>256</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/1fcc7290-2b80-11f0-b76f-6388555b4b30/image/7d3cea82e4dd0cbbd2fc843adc4f09be.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Visa processes an astounding number of transactions each year, which means even small improvements in its systems can have a significant impact. Sarah Laszlo, senior director of Visa’s machine learning platform, joins the AI Podcast to discuss how AI is transforming the way the company serves its global customer base, from advancing fraud prevention to enhancing personalization. She also shares valuable insights for enterprises looking to adopt generative AI, emphasizing the importance of using open-source models and fostering strong relationships between governance and technical teams.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Visa processes an astounding number of transactions each year, which means even small improvements in its systems can have a significant impact. Sarah Laszlo, senior director of Visa’s machine learning platform, joins the AI Podcast to discuss how AI is transforming the way the company serves its global customer base, from advancing fraud prevention to enhancing personalization. She also shares valuable insights for enterprises looking to adopt generative AI, emphasizing the importance of using open-source models and fostering strong relationships between governance and technical teams.</p>]]>
      </content:encoded>
      <itunes:duration>1333</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[1fcc7290-2b80-11f0-b76f-6388555b4b30]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1767769652.mp3?updated=1746649274" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Rama Akkiraju on Building the Right AI Infrastructure for Enterprise Success - Ep. 255</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Rama Akkiraju, VP of IT for AI and ML at NVIDIA, discusses the transformative power of AI in enterprises. Akkiraju highlights the rapid evolution from perception AI to agentic AI and emphasizes the importance of treating AI as a new layer in the development stack. She also shares insights on the role of AI platform architects and key trends shaping the future of AI infrastructure.</description>
      <pubDate>Wed, 07 May 2025 15:45:00 -0000</pubDate>
      <itunes:title>NVIDIA’s Rama Akkiraju on Building the Right AI Infrastructure for Enterprise Success</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>255</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/a62e261c-2603-11f0-b8f0-37da2ab35d1e/image/bbded485e9f6eda52164ce5571a83cef.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Rama Akkiraju, VP of IT for AI and ML at NVIDIA, discusses the transformative power of AI in enterprises. Akkiraju highlights the rapid evolution from perception AI to agentic AI and emphasizes the importance of treating AI as a new layer in the development stack. She also shares insights on the role of AI platform architects and key trends shaping the future of AI infrastructure.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Rama Akkiraju, VP of IT for AI and ML at NVIDIA, discusses the transformative power of AI in enterprises. Akkiraju highlights the rapid evolution from perception AI to agentic AI and emphasizes the importance of treating AI as a new layer in the development stack. She also shares insights on the role of AI platform architects and key trends shaping the future of AI infrastructure.</p>]]>
      </content:encoded>
      <itunes:duration>2092</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[a62e261c-2603-11f0-b8f0-37da2ab35d1e]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7570149000.mp3?updated=1746046057" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Yum! Brands, the World’s Largest Restaurant Company, Advances AI Adoption - Ep. 254</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Yum! Brands, the parent company of KFC, Taco Bell, Pizza Hut and Habit Burger &amp; Grill, is partnering with NVIDIA to streamline order taking, optimize operations and enhance service across its restaurants. Joe Park, Chief Digital and Technology Officer at Yum! Brands, Inc. and President of Byte by Yum!, shares how the company is further accelerating AI deployment.</description>
      <pubDate>Wed, 30 Apr 2025 15:45:00 -0000</pubDate>
      <itunes:title>Yum! Brands, the World’s Largest Restaurant Company, Advances AI Adoption</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>254</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/8169d3d2-1eea-11f0-9729-03fd4a54bb97/image/a2819e0f223cbd22dcb8bd20379db325.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Yum! Brands, the parent company of KFC, Taco Bell, Pizza Hut and Habit Burger &amp; Grill, is partnering with NVIDIA to streamline order taking, optimize operations and enhance service across its restaurants. Joe Park, Chief Digital and Technology Officer at Yum! Brands, Inc. and President of Byte by Yum!, shares how the company is further accelerating AI deployment.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Yum! Brands, the parent company of KFC, Taco Bell, Pizza Hut and Habit Burger &amp; Grill, is partnering with NVIDIA to streamline order taking, optimize operations and enhance service across its restaurants. Joe Park, Chief Digital and Technology Officer at Yum! Brands, Inc. and President of Byte by Yum!, shares how the company is further accelerating AI deployment.</p>]]>
      </content:encoded>
      <itunes:duration>1446</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[8169d3d2-1eea-11f0-9729-03fd4a54bb97]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2416455099.mp3?updated=1745265769" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Capital One’s Prem Natarajan Shares How AI Can Enhance Financial Services and Customer Experiences - Ep. 253</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Prem Natarajan, the executive vice president, chief scientist and head of AI at Capital One, discusses how AI is enhancing financial services by transforming customer experiences and internal operations. He shares how advanced AI models and agentic workflows are accelerating the delivery of personalized services and improving efficiency — paving the way for enhanced security and streamlined financial processes.</description>
      <pubDate>Wed, 23 Apr 2025 16:00:00 -0000</pubDate>
      <itunes:title>Capital One’s Prem Natarajan Shares How AI Can Enhance Financial Services and Customer Experiences</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>253</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c5baab3a-194d-11f0-9277-a3410fb0923e/image/2970b8106375fa567ef808bb64a95d0e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Prem Natarajan, the executive vice president, chief scientist and head of AI at Capital One, discusses how AI is enhancing financial services by transforming customer experiences and internal operations. He shares how advanced AI models and agentic workflows are accelerating the delivery of personalized services and improving efficiency — paving the way for enhanced security and streamlined financial processes.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Prem Natarajan, the executive vice president, chief scientist and head of AI at Capital One, discusses how AI is enhancing financial services by transforming customer experiences and internal operations. He shares how advanced AI models and agentic workflows are accelerating the delivery of personalized services and improving efficiency — paving the way for enhanced security and streamlined financial processes.</p>]]>
      </content:encoded>
      <itunes:duration>1904</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[c5baab3a-194d-11f0-9277-a3410fb0923e]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7586743955.mp3?updated=1744648527" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Isomorphic Labs Discusses AI-Driven Drug Discovery and the Future of Medicine - Ep. 252</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Max Jaderberg and Sergei Yakneen from Isomorphic Labs discuss how AI is enhancing drug discovery by treating biology as an information processing system. They share how advanced AI models like AlphaFold 3 are accelerating the pipeline and paving the way for a future of precision medicine.</description>
      <pubDate>Wed, 16 Apr 2025 16:00:00 -0000</pubDate>
      <itunes:title>Isomorphic Labs Discusses AI-Driven Drug Discovery and the Future of Medicine</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>252</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dab3e144-194a-11f0-a4a8-97551b790455/image/7300e7d93f3bf54b0201a30d0c434508.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Max Jaderberg and Sergei Yakneen from Isomorphic Labs discuss how AI is enhancing drug discovery by treating biology as an information processing system. They share how advanced AI models like AlphaFold 3 are accelerating the pipeline and paving the way for a future of precision medicine.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Max Jaderberg and Sergei Yakneen from Isomorphic Labs discuss how AI is enhancing drug discovery by treating biology as an information processing system. They share how advanced AI models like AlphaFold 3 are accelerating the pipeline and paving the way for a future of precision medicine. </p>]]>
      </content:encoded>
      <itunes:duration>2365</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[dab3e144-194a-11f0-a4a8-97551b790455]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2151852467.mp3?updated=1744647274" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>‘Black Women in Artificial Intelligence’ Founder Talks AI Education and Empowerment - Ep. 251</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Angle Bush, founder and CEO of Black Women in Artificial Intelligence (BWIAI), discusses her mission to foster a more inclusive and diverse AI community. Learn how BWIAI is building a supportive network and providing resources to empower Black women in the tech industry.</description>
      <pubDate>Wed, 09 Apr 2025 16:00:00 -0000</pubDate>
      <itunes:title>‘Black Women in Artificial Intelligence’ Founder Talks AI Education and Empowerment</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>250</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/2b5b5238-148e-11f0-ab0c-b7e7a7987c5b/image/e24c7e08cde1ec4578a922eb44d19462.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Angle Bush, founder and CEO of Black Women in Artificial Intelligence (BWIAI), discusses her mission to foster a more inclusive and diverse AI community. Learn how BWIAI is building a supportive network and providing resources to empower Black women in the tech industry.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Angle Bush, founder and CEO of Black Women in Artificial Intelligence (BWIAI), discusses her mission to foster a more inclusive and diverse AI community. Learn how BWIAI is building a supportive network and providing resources to empower Black women in the tech industry.</p>]]>
      </content:encoded>
      <itunes:duration>1279</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[2b5b5238-148e-11f0-ab0c-b7e7a7987c5b]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5831197517.mp3?updated=1744126430" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Jacob Liberman on the Power of Agentic AI in the Enterprise - Ep. 250</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Jacob Liberman, Director of Product Management at NVIDIA, discusses how agentic AI is transforming enterprises by automating complex tasks and enhancing human capabilities. Learn how NVIDIA Blueprints are making it easier for developers to deploy these intelligent agents and drive real business value.</description>
      <pubDate>Wed, 02 Apr 2025 16:00:00 -0000</pubDate>
      <itunes:title>NVIDIA’s Jacob Liberman on the Power of Agentic AI in the Enterprise</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>249</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dca8389c-0f27-11f0-8da7-87d9daeaf3b1/image/552214156fe6a1620cbb4941b3b2900d.jpeg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Jacob Liberman, Director of Product Management at NVIDIA, discusses how agentic AI is transforming enterprises by automating complex tasks and enhancing human capabilities. Learn how NVIDIA Blueprints are making it easier for developers to deploy these intelligent agents and drive real business value.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Jacob Liberman, Director of Product Management at NVIDIA, discusses how agentic AI is transforming enterprises by automating complex tasks and enhancing human capabilities. Learn how NVIDIA Blueprints are making it easier for developers to deploy these intelligent agents and drive real business value.</p>]]>
      </content:encoded>
      <itunes:duration>1782</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[dca8389c-0f27-11f0-8da7-87d9daeaf3b1]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1684874550.mp3?updated=1743532733" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Enhancing Grid Reliability: How Buzz Solutions Uses Vision AI to Prevent Outages and Wildfires - Ep. 249</title>
      <link>https://ai-podcast.nvidia.com/</link>
      <description>Kaitlyn Albertoli, CEO and cofounder of Buzz Solutions, discusses how the company uses vision AI to enhance the reliability of the electric grid by quickly identifying potential issues such as broken components, encroaching vegetation, and wildlife interference from inspection data collected by drones and helicopters. This technology helps prevent outages and wildfires, ensuring the grid remains robust and safe.</description>
      <pubDate>Wed, 26 Mar 2025 13:00:00 -0000</pubDate>
      <itunes:title>Enhancing Grid Reliability: How Buzz Solutions Uses Vision AI to Prevent Outages and Wildfires</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>249</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/9cce3e40-0998-11f0-b033-f337ffa422a0/image/e284f8325e0da1aa44bcea1a4e38301a.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Kaitlyn Albertoli, CEO and cofounder of Buzz Solutions, discusses how the company uses vision AI to enhance the reliability of the electric grid by quickly identifying potential issues such as broken components, encroaching vegetation, and wildlife interference from inspection data collected by drones and helicopters. This technology helps prevent outages and wildfires, ensuring the grid remains robust and safe.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Kaitlyn Albertoli, CEO and cofounder of Buzz Solutions, discusses how the company uses vision AI to enhance the reliability of the electric grid by quickly identifying potential issues such as broken components, encroaching vegetation, and wildlife interference from inspection data collected by drones and helicopters. This technology helps prevent outages and wildfires, ensuring the grid remains robust and safe.</p>]]>
      </content:encoded>
      <itunes:duration>2180</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[9cce3e40-0998-11f0-b033-f337ffa422a0]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4254475272.mp3?updated=1743619807" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Roboflow Simplifies Computer Vision for Developers and the Enterprise - Ep. 248</title>
      <link>https://blogs.nvidia.com/blog/roboflow-computer-vision/</link>
      <description>Joseph Nelson, co-founder and CEO of Roboflow, discusses how the company is making computer vision accessible to millions of developers and industries, from manufacturing to healthcare and more. </description>
      <pubDate>Wed, 05 Mar 2025 16:00:00 -0000</pubDate>
      <itunes:title>Roboflow Simplifies Computer Vision for Developers and the Enterprise</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>247</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/446d9d80-f922-11ef-826d-93763a168a12/image/305d78e349606fd514242e1021b30b49.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Joseph Nelson, co-founder and CEO of Roboflow, discusses how the company is making computer vision accessible to millions of developers and industries, from manufacturing to healthcare and more. </itunes:summary>
      <content:encoded>
        <![CDATA[<p>Joseph Nelson, co-founder and CEO of Roboflow, discusses how the company is making computer vision accessible to millions of developers and industries, from manufacturing to healthcare and more. </p>]]>
      </content:encoded>
      <itunes:duration>2320</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[446d9d80-f922-11ef-826d-93763a168a12]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6283742998.mp3?updated=1741127809" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Telenor's Kaaren Hilsen on Launching Norway’s First AI Factory - Ep. 247</title>
      <description>Telenor’s Chief Innovation Officer and Head of the AI Factory, Kaaren Hilsen, discusses Norway’s first AI factory. Opened in November, the facility processes sensitive data securely within Norway, ensuring data sovereignty and environmental sustainability. Learn how Telenor’s green computing initiatives, including a renewable energy-powered data center in Oslo, are advancing responsible and sustainable AI.</description>
      <pubDate>Thu, 27 Feb 2025 16:00:00 -0000</pubDate>
      <itunes:title>Telenor's Kaaren Hilsen on Launching Norway’s First AI Factory</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>247</itunes:episode>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f6227b84-f460-11ef-abfa-bfb1e0ee066d/image/55b08a0d8315b68507e5325087c37a7c.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle></itunes:subtitle>
      <itunes:summary>Telenor’s Chief Innovation Officer and Head of the AI Factory, Kaaren Hilsen, discusses Norway’s first AI factory. Opened in November, the facility processes sensitive data securely within Norway, ensuring data sovereignty and environmental sustainability. Learn how Telenor’s green computing initiatives, including a renewable energy-powered data center in Oslo, are advancing responsible and sustainable AI.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Telenor’s Chief Innovation Officer and Head of the AI Factory, Kaaren Hilsen, discusses Norway’s first AI factory. Opened in November, the facility processes sensitive data securely within Norway, ensuring data sovereignty and environmental sustainability. Learn how Telenor’s green computing initiatives, including a renewable energy-powered data center in Oslo, are advancing responsible and sustainable AI.</p>]]>
      </content:encoded>
      <itunes:duration>1385</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[f6227b84-f460-11ef-abfa-bfb1e0ee066d]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8727670438.mp3?updated=1741121462" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Temenos’ Barb Morgan Shares How AI Is Reshaping Banking - Ep. 246</title>
      <link>https://soundcloud.com/theaipodcast/barb-morgan-temenos</link>
      <description>AI is transforming banking by providing hyper-personalized services and real-time insights, enhancing customer experiences and ensuring robust data security. Barb Morgan, chief product and technology officer at Temenos, shares her expertise on how AI is transforming the banking landscape.</description>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b60b43aa-f45b-11ef-8be6-c750ec83cb42/image/44324527e248a48b833215cf81524f19.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is transforming banking by providing hyper-per…</itunes:subtitle>
      <itunes:summary>AI is transforming banking by providing hyper-personalized services and real-time insights, enhancing customer experiences and ensuring robust data security. Barb Morgan, chief product and technology officer at Temenos, shares her expertise on how AI is transforming the banking landscape.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>AI is transforming banking by providing hyper-personalized services and real-time insights, enhancing customer experiences and ensuring robust data security. Barb Morgan, chief product and technology officer at Temenos, shares her expertise on how AI is transforming the banking landscape.</p>]]>
      </content:encoded>
      <itunes:duration>1843</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2037536680]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5407555760.mp3?updated=1741121445" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Tara Chklovksi, Anshita Saini on Technovation Pioneering AI Education for Innovation - Ep. 245</title>
      <link>https://soundcloud.com/theaipodcast/tara-chklovski-anshita-saini</link>
      <description>In this episode of the NVIDIA AI Podcast, Tara Chklovski, founder and CEO of Technovation, returns to discuss the importance of inclusive AI. With Anshita Saini, a Technovation alumna and OpenAI staff member, Chklovski explores how Technovation empowers girls through AI education and enhances real-world problem-solving skills. Saini shares her journey from creating an app that helped combat a vaping crisis at her high school to taking on her current role at OpenAI. She also introduces Wiser AI, an initiative she founded to support women and underrepresented voices in AI.</description>
      <pubDate>Sat, 08 Feb 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b6b44afe-f45b-11ef-8be6-8be0cfee0890/image/6120c8965b228677b76adb299edb050a.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA AI Podcast, Tara Ch…</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, Tara Chklovski, founder and CEO of Technovation, returns to discuss the importance of inclusive AI. With Anshita Saini, a Technovation alumna and OpenAI staff member, Chklovski explores how Technovation empowers girls through AI education and enhances real-world problem-solving skills. Saini shares her journey from creating an app that helped combat a vaping crisis at her high school to taking on her current role at OpenAI. She also introduces Wiser AI, an initiative she founded to support women and underrepresented voices in AI.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>In this episode of the NVIDIA AI Podcast, Tara Chklovski, founder and CEO of Technovation, returns to discuss the importance of inclusive AI. With Anshita Saini, a Technovation alumna and OpenAI staff member, Chklovski explores how Technovation empowers girls through AI education and enhances real-world problem-solving skills. Saini shares her journey from creating an app that helped combat a vaping crisis at her high school to taking on her current role at OpenAI. She also introduces Wiser AI, an initiative she founded to support women and underrepresented voices in AI.</p>]]>
      </content:encoded>
      <itunes:duration>2045</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2030812652]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3155865046.mp3?updated=1741121417" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI for Everyone: How Gooey.AI Empowers Global Frontline Workers with Low Code Workflows - Ep. 244</title>
      <link>https://soundcloud.com/theaipodcast/gooey-ai</link>
      <description>Co-founders Sean Blagsvedt and Archana Prasad of Gooey.AI discuss how their platform is making AI more accessible across communities. The platform enables teams to leverage multiple AI tools, enhancing productivity in sectors like agriculture, healthcare, and frontline services. Key applications include multilingual chatbots that support African farmers through WhatsApp and AI assistants that help HVAC technicians access technical documentation.</description>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b70e59cc-f45b-11ef-8be6-1f62abd4ddf7/image/8e7659f0243e3a1fff096092307bf94e.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Co-founders Sean Blagsvedt and Archana Prasad of …</itunes:subtitle>
      <itunes:summary>Co-founders Sean Blagsvedt and Archana Prasad of Gooey.AI discuss how their platform is making AI more accessible across communities. The platform enables teams to leverage multiple AI tools, enhancing productivity in sectors like agriculture, healthcare, and frontline services. Key applications include multilingual chatbots that support African farmers through WhatsApp and AI assistants that help HVAC technicians access technical documentation.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Co-founders Sean Blagsvedt and Archana Prasad of Gooey.AI discuss how their platform is making AI more accessible across communities. The platform enables teams to leverage multiple AI tools, enhancing productivity in sectors like agriculture, healthcare, and frontline services. Key applications include multilingual chatbots that support African farmers through WhatsApp and AI assistants that help HVAC technicians access technical documentation.</p>]]>
      </content:encoded>
      <itunes:duration>2436</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2025039724]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2573962144.mp3?updated=1741121399" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI Agents Take Digital Experiences to the Next Level in Gaming and Beyond, Featuring Chris Covert from Inworld AI - Ep. 243</title>
      <link>https://soundcloud.com/theaipodcast/chris-covert-inworld</link>
      <description>AI agents with advanced perception and cognition capabilities are making digital experiences more dynamic and personalized across industries. In this episode of the NVIDIA AI Podcast, Inworld AI’s Chris Covert discusses how intelligent digital humans are reshaping interactive experiences, from gaming to healthcare, and emphasizes that the key to meaningful AI experiences lies in focusing on user value rather than just technology.</description>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b76e6cae-f45b-11ef-8be6-ab9547d2904a/image/3a7b1a6b062c31a7499190eadb9f541c.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI agents with advanced perception and cognition …</itunes:subtitle>
      <itunes:summary>AI agents with advanced perception and cognition capabilities are making digital experiences more dynamic and personalized across industries. In this episode of the NVIDIA AI Podcast, Inworld AI’s Chris Covert discusses how intelligent digital humans are reshaping interactive experiences, from gaming to healthcare, and emphasizes that the key to meaningful AI experiences lies in focusing on user value rather than just technology.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>AI agents with advanced perception and cognition capabilities are making digital experiences more dynamic and personalized across industries. In this episode of the NVIDIA AI Podcast, Inworld AI’s Chris Covert discusses how intelligent digital humans are reshaping interactive experiences, from gaming to healthcare, and emphasizes that the key to meaningful AI experiences lies in focusing on user value rather than just technology.</p>]]>
      </content:encoded>
      <itunes:duration>1592</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2021182833]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6624782194.mp3?updated=1741121387" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Firsthand's Jon Heller Shares How AI Agents Enhance Consumer Journeys in Retail - Ep. 242</title>
      <link>https://soundcloud.com/theaipodcast/jon-heller-firsthand</link>
      <description>With AI agents, organizations can reshape the landscape in retail and beyond. In this episode of the NVIDIA AI Podcast, Jon Heller of Firsthand discusses how AI Brand Agents are transforming online shopping and digital marketing by personalizing customer journeys and turning marketing interactions into valuable research data.</description>
      <pubDate>Tue, 21 Jan 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b7ce845e-f45b-11ef-8be6-b7f78c6175a8/image/dbb9050254c673615b8192a7af007116.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>With AI agents, organizations can reshape the lan…</itunes:subtitle>
      <itunes:summary>With AI agents, organizations can reshape the landscape in retail and beyond. In this episode of the NVIDIA AI Podcast, Jon Heller of Firsthand discusses how AI Brand Agents are transforming online shopping and digital marketing by personalizing customer journeys and turning marketing interactions into valuable research data.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>With AI agents, organizations can reshape the landscape in retail and beyond. In this episode of the NVIDIA AI Podcast, Jon Heller of Firsthand discusses how AI Brand Agents are transforming online shopping and digital marketing by personalizing customer journeys and turning marketing interactions into valuable research data.</p>]]>
      </content:encoded>
      <itunes:duration>2117</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2014776835]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5937093417.mp3?updated=1741121375" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How SDSC Uses AI to Transform Surgical Training and Practice - Ep. 241</title>
      <link>https://soundcloud.com/theaipodcast/margaux-masson-forsythe-sdsc</link>
      <description>Margaux Masson-Forsythe, director of machine learning at the Surgical Data Science Collective (SDSC), discusses how AI-driven video analysis is transforming surgical training and practice, making surgery safer and more accessible to billions of people worldwide.</description>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b82b180e-f45b-11ef-8be6-931980e4dbe1/image/0a6c6e5862008c77825296b6dc9ef35a.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Margaux Masson-Forsythe, director of machine lear…</itunes:subtitle>
      <itunes:summary>Margaux Masson-Forsythe, director of machine learning at the Surgical Data Science Collective (SDSC), discusses how AI-driven video analysis is transforming surgical training and practice, making surgery safer and more accessible to billions of people worldwide.</itunes:summary>
      <content:encoded>
        <![CDATA[<p>Margaux Masson-Forsythe, director of machine learning at the Surgical Data Science Collective (SDSC), discusses how AI-driven video analysis is transforming surgical training and practice, making surgery safer and more accessible to billions of people worldwide.</p>]]>
      </content:encoded>
      <itunes:duration>1568</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2009018743]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8311576906.mp3?updated=1741121363" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How World Foundation Models Will Advance Physical AI With NVIDIA’s Ming-Yu Liu - Ep. 240</title>
      <link>https://soundcloud.com/theaipodcast/world-foundation-models</link>
      <description>As AI continues to evolve rapidly, it is becoming more important to create models that can effectively simulate and predict outcomes in real-world environments. World foundation models are powerful neural networks that can simulate physical environments, enabling teams to enhance AI workflows and development. Ming-Yu Liu, vice president of research at NVIDIA and an IEEE Fellow, joined the NVIDIA AI Podcast to talk about world foundation models and how it will impact various industries. https://blogs.nvidia.com/blog/world-foundation-models-advance-physical-ai/ https://www.nvidia.com/cosmos/</description>
      <pubDate>Tue, 07 Jan 2025 16:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b88a5562-f45b-11ef-8be6-5354948de59e/image/00a85cdea93de2bc9734a9a01db06b09.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>As AI continues to evolve rapidly, it is becoming…</itunes:subtitle>
      <itunes:summary>As AI continues to evolve rapidly, it is becoming more important to create models that can effectively simulate and predict outcomes in real-world environments. World foundation models are powerful neural networks that can simulate physical environments, enabling teams to enhance AI workflows and development. Ming-Yu Liu, vice president of research at NVIDIA and an IEEE Fellow, joined the NVIDIA AI Podcast to talk about world foundation models and how it will impact various industries. https://blogs.nvidia.com/blog/world-foundation-models-advance-physical-ai/ https://www.nvidia.com/cosmos/</itunes:summary>
      <content:encoded>
        <![CDATA[<p>As AI continues to evolve rapidly, it is becoming more important to create models that can effectively simulate and predict outcomes in real-world environments. World foundation models are powerful neural networks that can simulate physical environments, enabling teams to enhance AI workflows and development. Ming-Yu Liu, vice president of research at NVIDIA and an IEEE Fellow, joined the NVIDIA AI Podcast to talk about world foundation models and how it will impact various industries. https://blogs.nvidia.com/blog/world-foundation-models-advance-physical-ai/ https://www.nvidia.com/cosmos/</p>]]>
      </content:encoded>
      <itunes:duration>1231</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/2000119463]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7271089150.mp3?updated=1741121351" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Imbue CEO Kanjun Qiu on Transforming AI Agents Into Personal Collaborators - Ep. 239</title>
      <link>https://soundcloud.com/theaipodcast/ai-agents-kanjun-qiu</link>
      <description>In this episode of the NVIDIA AI Podcast, Kanjun Qiu, CEO of Imbue, explores the emerging era where individuals can create and utilize their own AI agents. Drawing a parallel to the personal computer revolution of the late 1970s and 80s, Qiu discusses how modern AI systems are evolving to work collaboratively with users, enhancing their capabilities rather than just automating tasks.</description>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b8e8e758-f45b-11ef-8be6-4b3ced62af7b/image/680d022b7e1de438304d3bba4d129663.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA AI Podcast, Kanjun …</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, Kanjun Qiu, CEO of Imbue, explores the emerging era where individuals can create and utilize their own AI agents. Drawing a parallel to the personal computer revolution of the late 1970s and 80s, Qiu discusses how modern AI systems are evolving to work collaboratively with users, enhancing their capabilities rather than just automating tasks.</itunes:summary>
      <content:encoded>
        <![CDATA[In this episode of the NVIDIA AI Podcast, Kanjun Qiu, CEO of Imbue, explores the emerging era where individuals can create and utilize their own AI agents. Drawing a parallel to the personal computer revolution of the late 1970s and 80s, Qiu discusses how modern AI systems are evolving to work collaboratively with users, enhancing their capabilities rather than just automating tasks. ]]>
      </content:encoded>
      <itunes:duration>2016</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1983647039]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5047734177.mp3?updated=1740586325" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How AI Can Help Boost Disability Inclusion - Ep. 238</title>
      <link>https://soundcloud.com/theaipodcast/sara-minkara-tim-shriver</link>
      <description>In this episode of the NVIDIA AI Podcast, Sara Minkara, U.S. Special Advisor on International Disability Rights, and Timothy Shriver, Chairman of Special Olympics, discuss AI's potential to enhance education and disability inclusion. They emphasize the importance of including disability communities in AI development, as well as the cultural and social benefits of building an inclusive future.

Read the transcript:
https://blogs.nvidia.com/wp-content/uploads/2024/12/AI-Podcast_Disability-Inclusion-and-Education_Transcript.pdf</description>
      <pubDate>Sat, 30 Nov 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b944a2c8-f45b-11ef-8be6-ab167d4ce764/image/b75499a38efea2e1154b39f50c78def4.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA AI Podcast, Sara Mi…</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, Sara Minkara, U.S. Special Advisor on International Disability Rights, and Timothy Shriver, Chairman of Special Olympics, discuss AI's potential to enhance education and disability inclusion. They emphasize the importance of including disability communities in AI development, as well as the cultural and social benefits of building an inclusive future.

Read the transcript:
https://blogs.nvidia.com/wp-content/uploads/2024/12/AI-Podcast_Disability-Inclusion-and-Education_Transcript.pdf</itunes:summary>
      <content:encoded>
        <![CDATA[In this episode of the NVIDIA AI Podcast, Sara Minkara, U.S. Special Advisor on International Disability Rights, and Timothy Shriver, Chairman of Special Olympics, discuss AI's potential to enhance education and disability inclusion. They emphasize the importance of including disability communities in AI development, as well as the cultural and social benefits of building an inclusive future.

Read the transcript:
https://blogs.nvidia.com/wp-content/uploads/2024/12/AI-Podcast_Disability-Inclusion-and-Education_Transcript.pdf]]>
      </content:encoded>
      <itunes:duration>2147</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1972135971]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2442740634.mp3?updated=1740586326" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA's Louis Stewart on How AI Is Shaping Workforce Development - Ep. 237</title>
      <link>https://soundcloud.com/theaipodcast/ai-workforce-development</link>
      <description>In this episode of the NVIDIA's AI Podcast, Louis Stewart, head of strategic initiatives for NVIDIA’s global developer ecosystem, discusses why workforce development is crucial for maximizing AI benefits. He emphasizes the importance of AI education, inclusivity, and public-private partnerships in preparing the global workforce for the future. Engaging with AI tools and understanding their impact on the workforce landscape is vital for ensuring these changes benefit everyone.

https://blogs.nvidia.com/blog/workforce-development-ai/</description>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b99fd47c-f45b-11ef-8be6-ff01e340f109/image/6ecd47293a9fe74542497850e8bda9d7.png?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA's AI Podcast, Louis…</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA's AI Podcast, Louis Stewart, head of strategic initiatives for NVIDIA’s global developer ecosystem, discusses why workforce development is crucial for maximizing AI benefits. He emphasizes the importance of AI education, inclusivity, and public-private partnerships in preparing the global workforce for the future. Engaging with AI tools and understanding their impact on the workforce landscape is vital for ensuring these changes benefit everyone.

https://blogs.nvidia.com/blog/workforce-development-ai/</itunes:summary>
      <content:encoded>
        <![CDATA[In this episode of the NVIDIA's AI Podcast, Louis Stewart, head of strategic initiatives for NVIDIA’s global developer ecosystem, discusses why workforce development is crucial for maximizing AI benefits. He emphasizes the importance of AI education, inclusivity, and public-private partnerships in preparing the global workforce for the future. Engaging with AI tools and understanding their impact on the workforce landscape is vital for ensuring these changes benefit everyone.

https://blogs.nvidia.com/blog/workforce-development-ai/]]>
      </content:encoded>
      <itunes:duration>1874</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1957516771]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1559648366.mp3?updated=1740586327" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How the Department of Energy Is Tapping AI to Transform Science, Industry and Government - Ep. 236</title>
      <link>https://soundcloud.com/theaipodcast/helena-fu-department-of-energy</link>
      <description>Helena Fu, director of the DOE’s Office of Critical and Emerging Technologies (CET) and DOE’s chief AI officer, discusses the latest groundbreaking efforts with AI that are transforming national security, infrastructure, and scientific discovery. With oversight of 17 national labs and 34 facilities, the DOE is at the forefront of AI research and development.</description>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/b9fd01c4-f45b-11ef-8be6-1384fe6504da/image/a39bbf36a7ad84291c0ea8333c83fc0d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Helena Fu, director of the DOE’s Office of Critic…</itunes:subtitle>
      <itunes:summary>Helena Fu, director of the DOE’s Office of Critical and Emerging Technologies (CET) and DOE’s chief AI officer, discusses the latest groundbreaking efforts with AI that are transforming national security, infrastructure, and scientific discovery. With oversight of 17 national labs and 34 facilities, the DOE is at the forefront of AI research and development.</itunes:summary>
      <content:encoded>
        <![CDATA[Helena Fu, director of the DOE’s Office of Critical and Emerging Technologies (CET) and DOE’s chief AI officer, discusses the latest groundbreaking efforts with AI that are transforming national security, infrastructure, and scientific discovery. With oversight of 17 national labs and 34 facilities, the DOE is at the forefront of AI research and development.]]>
      </content:encoded>
      <itunes:duration>1491</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1957585027]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9427831936.mp3?updated=1740586327" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Zoom CTO Xuedong "XD" Huang on How AI Revolutionizes Productivity - Ep. 235</title>
      <link>https://soundcloud.com/theaipodcast/zoom-xuedong-huang</link>
      <description>Zoom, a company that helped change the way people work during the COVID-19 pandemic, is continuing to reimagine the future of work by transforming itself into an AI-first communications and productivity platform. 

In this episode of NVIDIA’s AI Podcast, Zoom CTO Xuedong (XD) Huang shares how the company is reshaping productivity with AI, including through its Zoom AI Companion 2.0, unveiled recently at the Zoomtopia conference. 

Designed to be a productivity partner, the AI companion is central to Zoom’s “federated AI” strategy, which focuses on integrating multiple large language models. 

Huang also introduces the concept of “AUI,” combining conversational AI and graphical user interfaces (GUIs) to streamline collaboration and supercharge business performance.</description>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ba5bb048-f45b-11ef-8be6-639c5d001933/image/c18ea36e0b5d3b5653efea7dfff1d341.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Zoom, a company that helped change the way people…</itunes:subtitle>
      <itunes:summary>Zoom, a company that helped change the way people work during the COVID-19 pandemic, is continuing to reimagine the future of work by transforming itself into an AI-first communications and productivity platform. 

In this episode of NVIDIA’s AI Podcast, Zoom CTO Xuedong (XD) Huang shares how the company is reshaping productivity with AI, including through its Zoom AI Companion 2.0, unveiled recently at the Zoomtopia conference. 

Designed to be a productivity partner, the AI companion is central to Zoom’s “federated AI” strategy, which focuses on integrating multiple large language models. 

Huang also introduces the concept of “AUI,” combining conversational AI and graphical user interfaces (GUIs) to streamline collaboration and supercharge business performance.</itunes:summary>
      <content:encoded>
        <![CDATA[Zoom, a company that helped change the way people work during the COVID-19 pandemic, is continuing to reimagine the future of work by transforming itself into an AI-first communications and productivity platform. 

In this episode of NVIDIA’s AI Podcast, Zoom CTO Xuedong (XD) Huang shares how the company is reshaping productivity with AI, including through its Zoom AI Companion 2.0, unveiled recently at the Zoomtopia conference. 

Designed to be a productivity partner, the AI companion is central to Zoom’s “federated AI” strategy, which focuses on integrating multiple large language models. 

Huang also introduces the concept of “AUI,” combining conversational AI and graphical user interfaces (GUIs) to streamline collaboration and supercharge business performance.]]>
      </content:encoded>
      <itunes:duration>2195</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1940222278]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2686827061.mp3?updated=1740586328" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA's Josh Parker on How AI and Accelerated Computing Drive Sustainability - Ep. 234</title>
      <link>https://soundcloud.com/theaipodcast/ai-accelerated-computing-sustainability</link>
      <description>From improving energy efficiency to helping address climate challenges, AI and accelerated computing are becoming key tools in the push for sustainability. In this episode of NVIDIA’s AI Podcast, Joshua Parker, senior director of corporate sustainability, shared his perspective on how these technologies are contributing to a more sustainable future.

https://blogs.nvidia.com/blog/ai-energy-efficiency/</description>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bab975b6-f45b-11ef-8be6-7bb34a1d09e0/image/fa56abdc43fe281adcde35e4cba11848.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>From improving energy efficiency to helping addre…</itunes:subtitle>
      <itunes:summary>From improving energy efficiency to helping address climate challenges, AI and accelerated computing are becoming key tools in the push for sustainability. In this episode of NVIDIA’s AI Podcast, Joshua Parker, senior director of corporate sustainability, shared his perspective on how these technologies are contributing to a more sustainable future.

https://blogs.nvidia.com/blog/ai-energy-efficiency/</itunes:summary>
      <content:encoded>
        <![CDATA[From improving energy efficiency to helping address climate challenges, AI and accelerated computing are becoming key tools in the push for sustainability. In this episode of NVIDIA’s AI Podcast, Joshua Parker, senior director of corporate sustainability, shared his perspective on how these technologies are contributing to a more sustainable future.

https://blogs.nvidia.com/blog/ai-energy-efficiency/]]>
      </content:encoded>
      <itunes:duration>2101</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1924472510]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7696903686.mp3?updated=1740586328" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>SonicJobs CEO Mikhil Raja on Using AI Agents to Connect the Internet, starting with Jobs - Ep. 233</title>
      <link>https://soundcloud.com/theaipodcast/ai-sonicjobs</link>
      <description>Companies in the US spend $15bn annually on talent acquisition. The most important metric in recruitment advertising is the conversion from the paid click on the job platform to the application the employer receives. Industry-wide, apply conversion is just 5%. Redirection of the candidate from the job platform to the company site is the biggest cause of abandonment; this step has a 70% bounce rate. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mikhil Raja, Cofounder and CEO of SonicJobs, about how they have built AI Agents to enable candidates to complete applications directly on job platforms, without redirection, boosting completion rates to 26% from 5%. Raja delves deep into SonicJobs’ cutting-edge technology, which merges traditional AI with large language models (LLMs) to understand and interact with job application web flows. He also emphasizes the importance of fine-tuning foundational models to achieve more impactful and scalable innovations.

SonicJobs is a member of the NVIDIA Inception program for startups.</description>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bb152500-f45b-11ef-8be6-ff31896de23f/image/33912448016a510bc4a9a5009cca6c46.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Companies in the US spend $15bn annually on talen…</itunes:subtitle>
      <itunes:summary>Companies in the US spend $15bn annually on talent acquisition. The most important metric in recruitment advertising is the conversion from the paid click on the job platform to the application the employer receives. Industry-wide, apply conversion is just 5%. Redirection of the candidate from the job platform to the company site is the biggest cause of abandonment; this step has a 70% bounce rate. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mikhil Raja, Cofounder and CEO of SonicJobs, about how they have built AI Agents to enable candidates to complete applications directly on job platforms, without redirection, boosting completion rates to 26% from 5%. Raja delves deep into SonicJobs’ cutting-edge technology, which merges traditional AI with large language models (LLMs) to understand and interact with job application web flows. He also emphasizes the importance of fine-tuning foundational models to achieve more impactful and scalable innovations.

SonicJobs is a member of the NVIDIA Inception program for startups.</itunes:summary>
      <content:encoded>
        <![CDATA[Companies in the US spend $15bn annually on talent acquisition. The most important metric in recruitment advertising is the conversion from the paid click on the job platform to the application the employer receives. Industry-wide, apply conversion is just 5%. Redirection of the candidate from the job platform to the company site is the biggest cause of abandonment; this step has a 70% bounce rate. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mikhil Raja, Cofounder and CEO of SonicJobs, about how they have built AI Agents to enable candidates to complete applications directly on job platforms, without redirection, boosting completion rates to 26% from 5%. Raja delves deep into SonicJobs’ cutting-edge technology, which merges traditional AI with large language models (LLMs) to understand and interact with job application web flows. He also emphasizes the importance of fine-tuning foundational models to achieve more impactful and scalable innovations.

SonicJobs is a member of the NVIDIA Inception program for startups.]]>
      </content:encoded>
      <itunes:duration>1653</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1914925946]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6937118061.mp3?updated=1740586329" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Machina Labs’ Edward Mehr on Autonomous Blacksmith Bots and More - Ep. 232</title>
      <link>https://soundcloud.com/theaipodcast/machina-labs-edward-mehr-on-autonomous-blacksmith-bots-and-more</link>
      <description>Edward Mehr works where AI meets the anvil.  The company he cofounded, Machina Labs, blends the latest advancements in robotics and AI to form metal into countless shapes for use in defense, aerospace, and more. The company’s applications accelerate design and innovation, enabling rapid iteration and production in days instead of the months required by conventional processes. NVIDIA AI Podcast host Noah Kravitz speaks with Mehr, CEO of Machina Labs, on how the company uses AI to develop the first-ever robotic blacksmith. Its Robotic Craftsman platform integrates seven-axis robots that can shape, scan, trim and drill a wide range of materials — all capabilities made possible through AI.</description>
      <pubDate>Tue, 03 Sep 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bb6e79de-f45b-11ef-8be6-c3cf2efda7fd/image/ff9a81bd441c0c3c1ea5f910d6125a1b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Edward Mehr works where AI meets the anvil.  The …</itunes:subtitle>
      <itunes:summary>Edward Mehr works where AI meets the anvil.  The company he cofounded, Machina Labs, blends the latest advancements in robotics and AI to form metal into countless shapes for use in defense, aerospace, and more. The company’s applications accelerate design and innovation, enabling rapid iteration and production in days instead of the months required by conventional processes. NVIDIA AI Podcast host Noah Kravitz speaks with Mehr, CEO of Machina Labs, on how the company uses AI to develop the first-ever robotic blacksmith. Its Robotic Craftsman platform integrates seven-axis robots that can shape, scan, trim and drill a wide range of materials — all capabilities made possible through AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Edward Mehr works where AI meets the anvil.  The company he cofounded, Machina Labs, blends the latest advancements in robotics and AI to form metal into countless shapes for use in defense, aerospace, and more. The company’s applications accelerate design and innovation, enabling rapid iteration and production in days instead of the months required by conventional processes. NVIDIA AI Podcast host Noah Kravitz speaks with Mehr, CEO of Machina Labs, on how the company uses AI to develop the first-ever robotic blacksmith. Its Robotic Craftsman platform integrates seven-axis robots that can shape, scan, trim and drill a wide range of materials — all capabilities made possible through AI.]]>
      </content:encoded>
      <itunes:duration>2245</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1906641035]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7088039115.mp3?updated=1740586330" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Snowflake's Baris Gultekin on Unlocking the Value of Data With Large Language Models - Ep. 231</title>
      <link>https://soundcloud.com/theaipodcast/snowflake-ai</link>
      <description>Snowflake is using AI to help enterprises transform data into insights and applications. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz and Baris Gultekin, head of AI at Snowflake, discuss how the company’s AI Data Cloud platform enables customers to access and manage data at scale. By separating the storage of data from compute, Snowflake has allowed organizations across the world to connect via cloud technology and work on a unified platform — eliminating data silos and streamlining collaborative workflows.</description>
      <pubDate>Wed, 21 Aug 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bbced090-f45b-11ef-8be6-5784d71176ad/image/336878d0c1bc70763ea943fd9831f021.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Snowflake is using AI to help enterprises transfo…</itunes:subtitle>
      <itunes:summary>Snowflake is using AI to help enterprises transform data into insights and applications. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz and Baris Gultekin, head of AI at Snowflake, discuss how the company’s AI Data Cloud platform enables customers to access and manage data at scale. By separating the storage of data from compute, Snowflake has allowed organizations across the world to connect via cloud technology and work on a unified platform — eliminating data silos and streamlining collaborative workflows.</itunes:summary>
      <content:encoded>
        <![CDATA[Snowflake is using AI to help enterprises transform data into insights and applications. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz and Baris Gultekin, head of AI at Snowflake, discuss how the company’s AI Data Cloud platform enables customers to access and manage data at scale. By separating the storage of data from compute, Snowflake has allowed organizations across the world to connect via cloud technology and work on a unified platform — eliminating data silos and streamlining collaborative workflows.]]>
      </content:encoded>
      <itunes:duration>1930</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1900414140]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1168756815.mp3?updated=1740586330" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Recursion CEO Chris Gibson on Accelerating the Biopharmaceutical Industry With AI - Ep. 230</title>
      <link>https://soundcloud.com/theaipodcast/recursion-ceo-chris-gibson</link>
      <description>Techbio is a field combining data, technology and biology to enhance scientific processes — and AI has the potential to supercharge the biopharmaceutical industry further.  In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Chris Gibson, cofounder and CEO of Recursion, about how the company uses AI and machine learning to accelerate drug discovery and development at scale. Tune in to hear Gibson discuss how AI is transforming the biopharmaceutical industry by increasing efficiency and lowering discovery costs.</description>
      <pubDate>Wed, 07 Aug 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bc2aea06-f45b-11ef-8be6-070ddc8922c5/image/bf6635b90e416e58756c0a5e46da16b7.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Techbio is a field combining data, technology and…</itunes:subtitle>
      <itunes:summary>Techbio is a field combining data, technology and biology to enhance scientific processes — and AI has the potential to supercharge the biopharmaceutical industry further.  In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Chris Gibson, cofounder and CEO of Recursion, about how the company uses AI and machine learning to accelerate drug discovery and development at scale. Tune in to hear Gibson discuss how AI is transforming the biopharmaceutical industry by increasing efficiency and lowering discovery costs.</itunes:summary>
      <content:encoded>
        <![CDATA[Techbio is a field combining data, technology and biology to enhance scientific processes — and AI has the potential to supercharge the biopharmaceutical industry further.  In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Chris Gibson, cofounder and CEO of Recursion, about how the company uses AI and machine learning to accelerate drug discovery and development at scale. Tune in to hear Gibson discuss how AI is transforming the biopharmaceutical industry by increasing efficiency and lowering discovery costs.]]>
      </content:encoded>
      <itunes:duration>2275</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1879973706]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9356389112.mp3?updated=1740586331" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Georgia Tech’s AI Makerspace Is Preparing the Future Workforce for AI - Ep. 229</title>
      <link>https://soundcloud.com/theaipodcast/georgia-tech</link>
      <description>AI is set to transform the workforce — and the Georgia Institute of Technology’s new AI Makerspace is helping tens of thousands of students get ahead of the curve. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Arijit Raychowdhury, a professor and Steve W. Cedex school chair of electrical engineering at Georgia Tech’s college of engineering, about the supercomputer hub, which provides students with the computing resources to reinforce their coursework and gain hands-on experience with AI. Built in collaboration with NVIDIA, the AI Makerspace underscores Georgia Tech’s commitment to preparing students for an AI-driven future, while fostering collaboration with local schools and universities.</description>
      <pubDate>Wed, 24 Jul 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bc8669a8-f45b-11ef-8be6-631f07ccf170/image/60fde98ea9dd6d058de9c89a489183e9.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is set to transform the workforce — and the Ge…</itunes:subtitle>
      <itunes:summary>AI is set to transform the workforce — and the Georgia Institute of Technology’s new AI Makerspace is helping tens of thousands of students get ahead of the curve. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Arijit Raychowdhury, a professor and Steve W. Cedex school chair of electrical engineering at Georgia Tech’s college of engineering, about the supercomputer hub, which provides students with the computing resources to reinforce their coursework and gain hands-on experience with AI. Built in collaboration with NVIDIA, the AI Makerspace underscores Georgia Tech’s commitment to preparing students for an AI-driven future, while fostering collaboration with local schools and universities.</itunes:summary>
      <content:encoded>
        <![CDATA[AI is set to transform the workforce — and the Georgia Institute of Technology’s new AI Makerspace is helping tens of thousands of students get ahead of the curve. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Arijit Raychowdhury, a professor and Steve W. Cedex school chair of electrical engineering at Georgia Tech’s college of engineering, about the supercomputer hub, which provides students with the computing resources to reinforce their coursework and gain hands-on experience with AI. Built in collaboration with NVIDIA, the AI Makerspace underscores Georgia Tech’s commitment to preparing students for an AI-driven future, while fostering collaboration with local schools and universities.]]>
      </content:encoded>
      <itunes:duration>1920</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1868252172]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3425820980.mp3?updated=1740586331" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Paige Cofounder Thomas Fuchs’ Diagnosis on Improving Cancer Patient Outcomes With AI - Ep. 228</title>
      <link>https://soundcloud.com/theaipodcast/paige-thomas-fuchs</link>
      <description>Improved cancer diagnostics — and improved patient outcomes — could be among the changes generative AI will bring to the healthcare industry, thanks to Paige, the first company with an FDA-approved tool for cancer diagnosis. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Paige cofounder and Chief Scientific Officer Thomas Fuchs. He’s also dean of artificial intelligence and human health at the Icahn School of Medicine at Mount Sinai. 

Tune in to hear Fuchs on machine learning and AI applications and how technology brings better precision and care to the medical industry.</description>
      <pubDate>Wed, 10 Jul 2024 18:19:59 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bce0f40e-f45b-11ef-8be6-d388dc84843e/image/3901aaf7b32b9b038a53a5405ffff3be.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Improved cancer diagnostics — and improved patien…</itunes:subtitle>
      <itunes:summary>Improved cancer diagnostics — and improved patient outcomes — could be among the changes generative AI will bring to the healthcare industry, thanks to Paige, the first company with an FDA-approved tool for cancer diagnosis. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Paige cofounder and Chief Scientific Officer Thomas Fuchs. He’s also dean of artificial intelligence and human health at the Icahn School of Medicine at Mount Sinai. 

Tune in to hear Fuchs on machine learning and AI applications and how technology brings better precision and care to the medical industry.</itunes:summary>
      <content:encoded>
        <![CDATA[Improved cancer diagnostics — and improved patient outcomes — could be among the changes generative AI will bring to the healthcare industry, thanks to Paige, the first company with an FDA-approved tool for cancer diagnosis. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Paige cofounder and Chief Scientific Officer Thomas Fuchs. He’s also dean of artificial intelligence and human health at the Icahn School of Medicine at Mount Sinai. 

Tune in to hear Fuchs on machine learning and AI applications and how technology brings better precision and care to the medical industry.]]>
      </content:encoded>
      <itunes:duration>1991</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1864135386]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2028628801.mp3?updated=1740586332" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Roblox Uses Generative AI to Enhance User Experiences - Ep. 227</title>
      <link>https://soundcloud.com/theaipodcast/anumpam-singh-roblox</link>
      <description>Roblox is a colorful online platform that aims to reimagine the way that people come together — now that vision is being augmented by generative AI. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Anupam Singh, vice president of AI and growth engineering at Roblox, on how the company is using the technology to enhance virtual experiences with features such as automated chat filters and real-time text translation, which help build inclusivity and user safety. Singh also discusses how generative AI can be used to power coding assistants that help creators focus more on creative expression, rather than spending time manually scripting world-building features.</description>
      <pubDate>Wed, 26 Jun 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bd3bd306-f45b-11ef-8be6-27a1cb5b6811/image/20071b87ee5e876f3cad2175ce5914ac.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Roblox is a colorful online platform that aims to…</itunes:subtitle>
      <itunes:summary>Roblox is a colorful online platform that aims to reimagine the way that people come together — now that vision is being augmented by generative AI. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Anupam Singh, vice president of AI and growth engineering at Roblox, on how the company is using the technology to enhance virtual experiences with features such as automated chat filters and real-time text translation, which help build inclusivity and user safety. Singh also discusses how generative AI can be used to power coding assistants that help creators focus more on creative expression, rather than spending time manually scripting world-building features.</itunes:summary>
      <content:encoded>
        <![CDATA[Roblox is a colorful online platform that aims to reimagine the way that people come together — now that vision is being augmented by generative AI. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Anupam Singh, vice president of AI and growth engineering at Roblox, on how the company is using the technology to enhance virtual experiences with features such as automated chat filters and real-time text translation, which help build inclusivity and user safety. Singh also discusses how generative AI can be used to power coding assistants that help creators focus more on creative expression, rather than spending time manually scripting world-building features.]]>
      </content:encoded>
      <itunes:duration>1742</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1851430170]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6337007007.mp3?updated=1740586333" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Michael Rubloff Explains How Neural Radiance Fields Turn 2D Images Into 3D Models - Ep. 226</title>
      <link>https://soundcloud.com/theaipodcast/nerf</link>
      <description>Let’s talk about NeRFs — no, not the neon-colored foam dart blasters, but neural radiance fields, a technology that might just change the nature of images forever. In this episode of NVIDIA’s AI Podcast recorded live at GTC, host Noah Kravitz speaks with Michael Rubloff, founder and managing editor of radiancefields.com, about radiance field-based technologies. NeRFs allow users to take a series of 2D images or video to create a hyperrealistic 3D model — something like a photograph of a scene, but that can be looked at from multiple angles. Tune in to learn more about the technology’s creative and commercial applications and how it might transform the way people capture and experience the world.</description>
      <pubDate>Wed, 12 Jun 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bd9497f2-f45b-11ef-8be6-63d1cba53ead/image/2e97eeeea57dbcee00fece53bb3ce1a2.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Let’s talk about NeRFs — no, not the neon-colored…</itunes:subtitle>
      <itunes:summary>Let’s talk about NeRFs — no, not the neon-colored foam dart blasters, but neural radiance fields, a technology that might just change the nature of images forever. In this episode of NVIDIA’s AI Podcast recorded live at GTC, host Noah Kravitz speaks with Michael Rubloff, founder and managing editor of radiancefields.com, about radiance field-based technologies. NeRFs allow users to take a series of 2D images or video to create a hyperrealistic 3D model — something like a photograph of a scene, but that can be looked at from multiple angles. Tune in to learn more about the technology’s creative and commercial applications and how it might transform the way people capture and experience the world.</itunes:summary>
      <content:encoded>
        <![CDATA[Let’s talk about NeRFs — no, not the neon-colored foam dart blasters, but neural radiance fields, a technology that might just change the nature of images forever. In this episode of NVIDIA’s AI Podcast recorded live at GTC, host Noah Kravitz speaks with Michael Rubloff, founder and managing editor of radiancefields.com, about radiance field-based technologies. NeRFs allow users to take a series of 2D images or video to create a hyperrealistic 3D model — something like a photograph of a scene, but that can be looked at from multiple angles. Tune in to learn more about the technology’s creative and commercial applications and how it might transform the way people capture and experience the world.]]>
      </content:encoded>
      <itunes:duration>1490</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1844347677]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6388661675.mp3?updated=1740586333" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Yotta CEO Sunil Gupta on Supercharging India’s Fast-Growing AI Market - Ep. 225</title>
      <link>https://soundcloud.com/theaipodcast/yotta-ceo-sunil-gupta</link>
      <description>India’s AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA’s AI Podcast, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company’s Shakti Cloud offering, which provides scalable GPU services for enterprises of all sizes. Yotta is the first Indian cloud services provider in the NVIDIA Partner Network, and its Shakti Cloud is India’s fastest AI supercomputing infrastructure, with 16 exaflops of compute capacity supported by over 16,000 NVIDIA H100 Tensor Core GPUs. Tune in to hear Gupta’s insights on India’s potential as a major AI market and how to balance data center growth with sustainability and energy efficiency.</description>
      <pubDate>Mon, 03 Jun 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bdede618-f45b-11ef-8be6-8f62971defbe/image/67cc3c751cb50b2639e8c77f1a001e0a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>India’s AI market is expected to be massive. Yott…</itunes:subtitle>
      <itunes:summary>India’s AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA’s AI Podcast, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company’s Shakti Cloud offering, which provides scalable GPU services for enterprises of all sizes. Yotta is the first Indian cloud services provider in the NVIDIA Partner Network, and its Shakti Cloud is India’s fastest AI supercomputing infrastructure, with 16 exaflops of compute capacity supported by over 16,000 NVIDIA H100 Tensor Core GPUs. Tune in to hear Gupta’s insights on India’s potential as a major AI market and how to balance data center growth with sustainability and energy efficiency.</itunes:summary>
      <content:encoded>
        <![CDATA[India’s AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA’s AI Podcast, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company’s Shakti Cloud offering, which provides scalable GPU services for enterprises of all sizes. Yotta is the first Indian cloud services provider in the NVIDIA Partner Network, and its Shakti Cloud is India’s fastest AI supercomputing infrastructure, with 16 exaflops of compute capacity supported by over 16,000 NVIDIA H100 Tensor Core GPUs. Tune in to hear Gupta’s insights on India’s potential as a major AI market and how to balance data center growth with sustainability and energy efficiency.]]>
      </content:encoded>
      <itunes:duration>2000</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1837778895]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6972219091.mp3?updated=1740586334" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Two Stanford Students Are Building Robots for Handling Household Chores - Ep. 224</title>
      <link>https://soundcloud.com/theaipodcast/household-robots</link>
      <description>Imagine having a robot that could help you clean up after a party — or fold heaps of laundry. Chengshu Eric Li and Josiah David Wong, two Stanford University Ph.D. students advised by renowned American computer scientist Professor Fei-Fei Li, are making that a ‌dream come true. In this episode of the AI Podcast, host Noah Kravitz spoke with the two about their project, BEHAVIOR-1K, which aims to enable robots to perform 1,000 household chores, including picking up fallen objects or cooking. To train the robots, they’re using the NVIDIA Omniverse platform, as well as reinforcement and imitation learning techniques. Listen to hear more about the breakthroughs and challenges Li and Wong experienced along the way.</description>
      <pubDate>Mon, 27 May 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/be48b4a8-f45b-11ef-8be6-43871aa545b8/image/892948b62104ec7e4422522b042baae1.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Imagine having a robot that could help you clean …</itunes:subtitle>
      <itunes:summary>Imagine having a robot that could help you clean up after a party — or fold heaps of laundry. Chengshu Eric Li and Josiah David Wong, two Stanford University Ph.D. students advised by renowned American computer scientist Professor Fei-Fei Li, are making that a ‌dream come true. In this episode of the AI Podcast, host Noah Kravitz spoke with the two about their project, BEHAVIOR-1K, which aims to enable robots to perform 1,000 household chores, including picking up fallen objects or cooking. To train the robots, they’re using the NVIDIA Omniverse platform, as well as reinforcement and imitation learning techniques. Listen to hear more about the breakthroughs and challenges Li and Wong experienced along the way.</itunes:summary>
      <content:encoded>
        <![CDATA[Imagine having a robot that could help you clean up after a party — or fold heaps of laundry. Chengshu Eric Li and Josiah David Wong, two Stanford University Ph.D. students advised by renowned American computer scientist Professor Fei-Fei Li, are making that a ‌dream come true. In this episode of the AI Podcast, host Noah Kravitz spoke with the two about their project, BEHAVIOR-1K, which aims to enable robots to perform 1,000 household chores, including picking up fallen objects or cooking. To train the robots, they’re using the NVIDIA Omniverse platform, as well as reinforcement and imitation learning techniques. Listen to hear more about the breakthroughs and challenges Li and Wong experienced along the way.]]>
      </content:encoded>
      <itunes:duration>1840</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1832461098]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2941900425.mp3?updated=1740586334" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Basecamp's Phil Lorenz on Combining AI With Biodiversity Data  - Ep. 223</title>
      <link>https://soundcloud.com/theaipodcast/basecamp-phil-lorenz</link>
      <description>Basecamp Research is on a mission to capture the vastness of life on Earth at an unprecedented scale. Phil Lorenz, chief technology officer at Basecamp Research, discusses using AI and biodiversity data to advance fields like medicine and environmental conservation with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Lorenz explains Basecamp’s systematic collection of biodiversity data in partnership with nature parks worldwide and its use of deep learning to analyze and apply it for use cases such as protein structure prediction and gene editing. He also emphasizes the importance of ethical data governance and touches on technological advancements that will help drive the future of AI in biology.</description>
      <pubDate>Wed, 15 May 2024 13:00:02 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bea36b28-f45b-11ef-8be6-439e229f074f/image/c94d2a537c24c0f2dc0b26ed5a23387a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Basecamp Research is on a mission to capture the …</itunes:subtitle>
      <itunes:summary>Basecamp Research is on a mission to capture the vastness of life on Earth at an unprecedented scale. Phil Lorenz, chief technology officer at Basecamp Research, discusses using AI and biodiversity data to advance fields like medicine and environmental conservation with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Lorenz explains Basecamp’s systematic collection of biodiversity data in partnership with nature parks worldwide and its use of deep learning to analyze and apply it for use cases such as protein structure prediction and gene editing. He also emphasizes the importance of ethical data governance and touches on technological advancements that will help drive the future of AI in biology.</itunes:summary>
      <content:encoded>
        <![CDATA[Basecamp Research is on a mission to capture the vastness of life on Earth at an unprecedented scale. Phil Lorenz, chief technology officer at Basecamp Research, discusses using AI and biodiversity data to advance fields like medicine and environmental conservation with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Lorenz explains Basecamp’s systematic collection of biodiversity data in partnership with nature parks worldwide and its use of deep learning to analyze and apply it for use cases such as protein structure prediction and gene editing. He also emphasizes the importance of ethical data governance and touches on technological advancements that will help drive the future of AI in biology.]]>
      </content:encoded>
      <itunes:duration>1763</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1821274848]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8121030595.mp3?updated=1740586335" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Media.Monks’ Lewis Smithingham on Enhancing Media and Marketing With AI - Ep. 222</title>
      <link>https://soundcloud.com/theaipodcast/mediamonks-lewis-smithingham</link>
      <description>Meet Media.Monks’ Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI’s potential to enhance media and entertainment with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Wormhole was designed to showcase Monks.Flow, an AI-powered platform that streamlines marketing and content creation workflows. Smithingham delves into Media.Monks’ platforms for media, entertainment and advertising and speaks to its vision for a future where AI enhances creativity and allows for more personalized, scalable content creation.

 https://blogs.nvidia.com/blog/media-monks-ai-podcast/</description>
      <pubDate>Thu, 09 May 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/befc6228-f45b-11ef-8be6-379ff9f2daa6/image/b63c93bbfe83ca5302618eded8bb5b18.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Meet Media.Monks’ Wormhole, an alien-like, conver…</itunes:subtitle>
      <itunes:summary>Meet Media.Monks’ Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI’s potential to enhance media and entertainment with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Wormhole was designed to showcase Monks.Flow, an AI-powered platform that streamlines marketing and content creation workflows. Smithingham delves into Media.Monks’ platforms for media, entertainment and advertising and speaks to its vision for a future where AI enhances creativity and allows for more personalized, scalable content creation.

 https://blogs.nvidia.com/blog/media-monks-ai-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[Meet Media.Monks’ Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI’s potential to enhance media and entertainment with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI conference. Wormhole was designed to showcase Monks.Flow, an AI-powered platform that streamlines marketing and content creation workflows. Smithingham delves into Media.Monks’ platforms for media, entertainment and advertising and speaks to its vision for a future where AI enhances creativity and allows for more personalized, scalable content creation.

 https://blogs.nvidia.com/blog/media-monks-ai-podcast/]]>
      </content:encoded>
      <itunes:duration>2554</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1816942410]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7739159415.mp3?updated=1740586335" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Performance AI: Insights from Arthur's Adam Wenchel – Ep. 221</title>
      <link>https://soundcloud.com/theaipodcast/arthur-adam-wenchel</link>
      <description>In this episode of the NVIDIA AI Podcast, recorded live at the GTC 2024, host Noah Kravitz sits down with Adam Wenchel, co-founder and CEO of Arthur. Arthur enhances the performance of AI systems across various metrics like accuracy, explainability, and fairness. Wenchel shares insights into the challenges and opportunities of deploying generative AI. The discussion spans a range of topics, including AI bias, the observability of AI systems, and the practical implications of AI in business. For more on Arthur, visit arthur.ai.</description>
      <pubDate>Tue, 30 Apr 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bf58b3fc-f45b-11ef-8be6-27d4a3e0e588/image/98a8773f8cd9a3907600d4f0a51de19b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA AI Podcast, recorde…</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, recorded live at the GTC 2024, host Noah Kravitz sits down with Adam Wenchel, co-founder and CEO of Arthur. Arthur enhances the performance of AI systems across various metrics like accuracy, explainability, and fairness. Wenchel shares insights into the challenges and opportunities of deploying generative AI. The discussion spans a range of topics, including AI bias, the observability of AI systems, and the practical implications of AI in business. For more on Arthur, visit arthur.ai.</itunes:summary>
      <content:encoded>
        <![CDATA[In this episode of the NVIDIA AI Podcast, recorded live at the GTC 2024, host Noah Kravitz sits down with Adam Wenchel, co-founder and CEO of Arthur. Arthur enhances the performance of AI systems across various metrics like accuracy, explainability, and fairness. Wenchel shares insights into the challenges and opportunities of deploying generative AI. The discussion spans a range of topics, including AI bias, the observability of AI systems, and the practical implications of AI in business. For more on Arthur, visit arthur.ai.]]>
      </content:encoded>
      <itunes:duration>1608</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1811598663]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9904238366.mp3?updated=1740586336" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI2’s Christopher Bretherton Discusses Using Machine Learning for Climate Modeling - Ep. 220</title>
      <link>https://soundcloud.com/theaipodcast/christopher-bretherton</link>
      <description>Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology’s potential to enhance climate modeling with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Bretherton explains how machine learning helps overcome the limitations of traditional climate models and underscores the role of localized predictions in empowering communities to prepare for climate-related risks. Through ongoing research and collaboration, Bretherton and his team aim to improve climate modeling and enable society to better mitigate and adapt to the impacts of climate change.</description>
      <pubDate>Wed, 24 Apr 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/bfb44d84-f45b-11ef-8be6-7b6cf4e28a55/image/cfb0d5389b0f4d7af6a2e04d1fb0fe66.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Can machine learning help predict extreme weather…</itunes:subtitle>
      <itunes:summary>Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology’s potential to enhance climate modeling with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Bretherton explains how machine learning helps overcome the limitations of traditional climate models and underscores the role of localized predictions in empowering communities to prepare for climate-related risks. Through ongoing research and collaboration, Bretherton and his team aim to improve climate modeling and enable society to better mitigate and adapt to the impacts of climate change.</itunes:summary>
      <content:encoded>
        <![CDATA[Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology’s potential to enhance climate modeling with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Bretherton explains how machine learning helps overcome the limitations of traditional climate models and underscores the role of localized predictions in empowering communities to prepare for climate-related risks. Through ongoing research and collaboration, Bretherton and his team aim to improve climate modeling and enable society to better mitigate and adapt to the impacts of climate change.]]>
      </content:encoded>
      <itunes:duration>1949</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1806553098]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2607576157.mp3?updated=1740586337" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Living Optics CEO Robin Wang on Democratizing Hyperspectral Imaging - Ep. 219</title>
      <link>https://soundcloud.com/theaipodcast/robin-wang</link>
      <description>Step into the realm of the unseen with Robin Wang, CEO of Living Optics. The startup cofounder discusses the power of hyperspectral imaging with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Living Optics’ hyperspectral imaging camera, which can capture visual data across 96 colors, reveals details invisible to the human eye. Potential applications are as diverse as monitoring plant health to detecting cracks in bridges. The startup aims to empower users across industries to gain new insights from richer, more informative datasets fueled by hyperspectral imaging technology. 

Living Optics is a member of the NVIDIA Inception program for cutting-edge startups.

Stay tuned for more episodes recorded live from GTC.</description>
      <pubDate>Tue, 23 Apr 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c00f132c-f45b-11ef-8be6-cb69d69025f4/image/2e0d006badf092615ef248ff64e7a1cb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Step into the realm of the unseen with Robin Wang…</itunes:subtitle>
      <itunes:summary>Step into the realm of the unseen with Robin Wang, CEO of Living Optics. The startup cofounder discusses the power of hyperspectral imaging with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Living Optics’ hyperspectral imaging camera, which can capture visual data across 96 colors, reveals details invisible to the human eye. Potential applications are as diverse as monitoring plant health to detecting cracks in bridges. The startup aims to empower users across industries to gain new insights from richer, more informative datasets fueled by hyperspectral imaging technology. 

Living Optics is a member of the NVIDIA Inception program for cutting-edge startups.

Stay tuned for more episodes recorded live from GTC.</itunes:summary>
      <content:encoded>
        <![CDATA[Step into the realm of the unseen with Robin Wang, CEO of Living Optics. The startup cofounder discusses the power of hyperspectral imaging with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Living Optics’ hyperspectral imaging camera, which can capture visual data across 96 colors, reveals details invisible to the human eye. Potential applications are as diverse as monitoring plant health to detecting cracks in bridges. The startup aims to empower users across industries to gain new insights from richer, more informative datasets fueled by hyperspectral imaging technology. 

Living Optics is a member of the NVIDIA Inception program for cutting-edge startups.

Stay tuned for more episodes recorded live from GTC.]]>
      </content:encoded>
      <itunes:duration>1594</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1802251500]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7278146921.mp3?updated=1740586337" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Cleanlab's Curtis Northcutt and Berkeley Research Group's Steven Gawthorpe on AI for Fighting Crime</title>
      <link>https://soundcloud.com/theaipodcast/cleanlabs-ai</link>
      <description>Talk about scrubbing data. Curtis Northcutt, cofounder and CEO of Cleanlab, and Steven Gawthorpe, senior data scientist at Berkeley Research Group, speak about Cleanlab’s groundbreaking approach to data curation with Noah Kravitz, host of NVIDIA’s AI Podcast, in an episode recorded live at the NVIDIA GTC global AI conference. The startup’s tools enhance data reliability and trustworthiness through sophisticated error identification and correction algorithms. Northcutt and Gawthorpe provide insights into how AI-powered data analytics can help combat economic crimes and corruption and discuss the intersection of AI, data science and ethical governance in fostering a more just society. 

Cleanlab is a member of the NVIDIA Inception program for cutting-edge startups.

 https://blogs.nvidia.com/blog/cleanlab-podcast/</description>
      <pubDate>Wed, 10 Apr 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c06f33c4-f45b-11ef-8be6-cbbecd6df556/image/26050db5f2231e833ff143ba04e35481.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Talk about scrubbing data. Curtis Northcutt, cofo…</itunes:subtitle>
      <itunes:summary>Talk about scrubbing data. Curtis Northcutt, cofounder and CEO of Cleanlab, and Steven Gawthorpe, senior data scientist at Berkeley Research Group, speak about Cleanlab’s groundbreaking approach to data curation with Noah Kravitz, host of NVIDIA’s AI Podcast, in an episode recorded live at the NVIDIA GTC global AI conference. The startup’s tools enhance data reliability and trustworthiness through sophisticated error identification and correction algorithms. Northcutt and Gawthorpe provide insights into how AI-powered data analytics can help combat economic crimes and corruption and discuss the intersection of AI, data science and ethical governance in fostering a more just society. 

Cleanlab is a member of the NVIDIA Inception program for cutting-edge startups.

 https://blogs.nvidia.com/blog/cleanlab-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[Talk about scrubbing data. Curtis Northcutt, cofounder and CEO of Cleanlab, and Steven Gawthorpe, senior data scientist at Berkeley Research Group, speak about Cleanlab’s groundbreaking approach to data curation with Noah Kravitz, host of NVIDIA’s AI Podcast, in an episode recorded live at the NVIDIA GTC global AI conference. The startup’s tools enhance data reliability and trustworthiness through sophisticated error identification and correction algorithms. Northcutt and Gawthorpe provide insights into how AI-powered data analytics can help combat economic crimes and corruption and discuss the intersection of AI, data science and ethical governance in fostering a more just society. 

Cleanlab is a member of the NVIDIA Inception program for cutting-edge startups.

 https://blogs.nvidia.com/blog/cleanlab-podcast/]]>
      </content:encoded>
      <itunes:duration>1968</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1797413893]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2521763222.mp3?updated=1740586338" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Dotlumen CEO Cornel Amariei on Assistive Technology for the Visually Impaired - Ep. 217</title>
      <link>https://soundcloud.com/theaipodcast/gtc24-cornel-amariei-inception</link>
      <description>Dotlumen is illuminating a new technology to help persons who are blind or low vision navigate the world. 

In this episode of NVIDIA’s AI Podcast, recorded live at the NVIDIA GTC global AI conference, host Noah Kravitz spoke with the Romanian startup’s founder and CEO, Cornel Amariei, about developing its flagship Dotlumen Glasses. 

Dotlumen is a member of the NVIDIA Inception program for cutting-edge startups. 

Equipped with sensors and powered by AI, the glasses compute a safely walkable path for persons who are blind or low vision, and offer haptic — or tactile — feedback on how to proceed via corresponding vibrations. Amariei further discusses the process and challenges of developing assistive technology and its potential for enhancing accessibility. 

Stay tuned for more episodes recorded live from GTC.</description>
      <pubDate>Tue, 09 Apr 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c0cb09f6-f45b-11ef-8be6-f71f83963fd6/image/bf0631642ec8edb6854716860646d7a4.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Dotlumen is illuminating a new technology to help…</itunes:subtitle>
      <itunes:summary>Dotlumen is illuminating a new technology to help persons who are blind or low vision navigate the world. 

In this episode of NVIDIA’s AI Podcast, recorded live at the NVIDIA GTC global AI conference, host Noah Kravitz spoke with the Romanian startup’s founder and CEO, Cornel Amariei, about developing its flagship Dotlumen Glasses. 

Dotlumen is a member of the NVIDIA Inception program for cutting-edge startups. 

Equipped with sensors and powered by AI, the glasses compute a safely walkable path for persons who are blind or low vision, and offer haptic — or tactile — feedback on how to proceed via corresponding vibrations. Amariei further discusses the process and challenges of developing assistive technology and its potential for enhancing accessibility. 

Stay tuned for more episodes recorded live from GTC.</itunes:summary>
      <content:encoded>
        <![CDATA[Dotlumen is illuminating a new technology to help persons who are blind or low vision navigate the world. 

In this episode of NVIDIA’s AI Podcast, recorded live at the NVIDIA GTC global AI conference, host Noah Kravitz spoke with the Romanian startup’s founder and CEO, Cornel Amariei, about developing its flagship Dotlumen Glasses. 

Dotlumen is a member of the NVIDIA Inception program for cutting-edge startups. 

Equipped with sensors and powered by AI, the glasses compute a safely walkable path for persons who are blind or low vision, and offer haptic — or tactile — feedback on how to proceed via corresponding vibrations. Amariei further discusses the process and challenges of developing assistive technology and its potential for enhancing accessibility. 

Stay tuned for more episodes recorded live from GTC.]]>
      </content:encoded>
      <itunes:duration>2133</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1791227923]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7122446127.mp3?updated=1740586339" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Personalized Health: Viome's Guru Banavar Discusses Startup’s AI-Driven Approach - Ep. 216</title>
      <link>https://soundcloud.com/theaipodcast/viome-guru-banavar</link>
      <description>Viome CTO Guru Banavar discusses how the startup’s innovations in AI and genomics advance personalized health and wellness.</description>
      <pubDate>Wed, 27 Mar 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c127835c-f45b-11ef-8be6-57fb829cddca/image/ea034f0d8afbee146bc654ec8a1ac614.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Viome CTO Guru Banavar discusses how the startup’…</itunes:subtitle>
      <itunes:summary>Viome CTO Guru Banavar discusses how the startup’s innovations in AI and genomics advance personalized health and wellness.</itunes:summary>
      <content:encoded>
        <![CDATA[Viome CTO Guru Banavar discusses how the startup’s innovations in AI and genomics advance personalized health and wellness.]]>
      </content:encoded>
      <itunes:duration>3146</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1785368577]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3995782121.mp3?updated=1740586339" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>ITIF's Daniel Castro on Energy-Efficient AI and Climate Change - Ep. 215</title>
      <link>https://soundcloud.com/theaipodcast/ai-daniel-castro-itif</link>
      <description>AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology’s energy consumption. Castro also touches on the need for policies and frameworks that encourage the development of energy-efficient technology. Tune in to discover the crucial role of GPU acceleration in enhancing sustainability and how AI can help address climate change challenges.</description>
      <pubDate>Mon, 11 Mar 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c183cd4c-f45b-11ef-8be6-1f0531513e04/image/473cbe8f7308a3548f4f3da627b9f361.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI-driven change is in the air, as are concerns a…</itunes:subtitle>
      <itunes:summary>AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology’s energy consumption. Castro also touches on the need for policies and frameworks that encourage the development of energy-efficient technology. Tune in to discover the crucial role of GPU acceleration in enhancing sustainability and how AI can help address climate change challenges.</itunes:summary>
      <content:encoded>
        <![CDATA[AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology’s energy consumption. Castro also touches on the need for policies and frameworks that encourage the development of energy-efficient technology. Tune in to discover the crucial role of GPU acceleration in enhancing sustainability and how AI can help address climate change challenges.]]>
      </content:encoded>
      <itunes:duration>1993</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1772793834]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2574294771.mp3?updated=1740586340" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Exploring Filmmaking with Cuebric's AI: Insights from Pinar Seyhan Demirdag - Ep. 214</title>
      <link>https://soundcloud.com/theaipodcast/pinar-demirdag-cuebric</link>
      <description>In today’s episode of NVIDIA’s AI Podcast, host Noah Kravitz talks with Pinar Seyhan Demirdag, co-founder and CEO of Cuebric. Cuebric is on a mission to offer new solutions in filmmaking and content creation through immersive, two-and-a-half-dimensional cinematic environments. Their AI-powered application aims to help creators quickly bring their ideas to life, making high-quality production more accessible. Demirdag discusses how Cuebric uses generative AI to enable the creation of engaging environments affordably. Listen in to find out about the current landscape of content creation, the role of AI in simplifying the creative process, and Cuebric's participation in NVIDIA's GTC technology conference.

https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/</description>
      <pubDate>Tue, 27 Feb 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c1ddfa4c-f45b-11ef-8be6-efc3d8b6a2db/image/d29dc2254c7e42378928a53e3f5563f0.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In today’s episode of NVIDIA’s AI Podcast, host N…</itunes:subtitle>
      <itunes:summary>In today’s episode of NVIDIA’s AI Podcast, host Noah Kravitz talks with Pinar Seyhan Demirdag, co-founder and CEO of Cuebric. Cuebric is on a mission to offer new solutions in filmmaking and content creation through immersive, two-and-a-half-dimensional cinematic environments. Their AI-powered application aims to help creators quickly bring their ideas to life, making high-quality production more accessible. Demirdag discusses how Cuebric uses generative AI to enable the creation of engaging environments affordably. Listen in to find out about the current landscape of content creation, the role of AI in simplifying the creative process, and Cuebric's participation in NVIDIA's GTC technology conference.

https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/</itunes:summary>
      <content:encoded>
        <![CDATA[In today’s episode of NVIDIA’s AI Podcast, host Noah Kravitz talks with Pinar Seyhan Demirdag, co-founder and CEO of Cuebric. Cuebric is on a mission to offer new solutions in filmmaking and content creation through immersive, two-and-a-half-dimensional cinematic environments. Their AI-powered application aims to help creators quickly bring their ideas to life, making high-quality production more accessible. Demirdag discusses how Cuebric uses generative AI to enable the creation of engaging environments affordably. Listen in to find out about the current landscape of content creation, the role of AI in simplifying the creative process, and Cuebric's participation in NVIDIA's GTC technology conference.

https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/]]>
      </content:encoded>
      <itunes:duration>2007</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1759544883]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2736711034.mp3?updated=1740586340" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How the Ohio Supercomputer Center Drives the Future of Computing - Ep. 213</title>
      <link>https://soundcloud.com/theaipodcast/ai-alan-chalker</link>
      <description>NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things supercomputing. The center’s Open OnDemand program, which takes the form of a web-based interface, empowers Ohio higher education institutions and industries with accessible, reliable and secure computational services and training and educational programs. Chalker dives into the history and evolution of the OSC, and explains how it’s working with client companies like NASCAR, which is simulating race car designs virtually. Tune in to learn more about Chalker’s outlook on the future of supercomputing and OSC’s role in realizing it.</description>
      <pubDate>Wed, 21 Feb 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c23bba92-f45b-11ef-8be6-afde40d107de/image/a68d55f2c2f2db07c52f48f214c2abda.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>NASCAR races are all about speed, but even the fa…</itunes:subtitle>
      <itunes:summary>NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things supercomputing. The center’s Open OnDemand program, which takes the form of a web-based interface, empowers Ohio higher education institutions and industries with accessible, reliable and secure computational services and training and educational programs. Chalker dives into the history and evolution of the OSC, and explains how it’s working with client companies like NASCAR, which is simulating race car designs virtually. Tune in to learn more about Chalker’s outlook on the future of supercomputing and OSC’s role in realizing it.</itunes:summary>
      <content:encoded>
        <![CDATA[NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things supercomputing. The center’s Open OnDemand program, which takes the form of a web-based interface, empowers Ohio higher education institutions and industries with accessible, reliable and secure computational services and training and educational programs. Chalker dives into the history and evolution of the OSC, and explains how it’s working with client companies like NASCAR, which is simulating race car designs virtually. Tune in to learn more about Chalker’s outlook on the future of supercomputing and OSC’s role in realizing it.]]>
      </content:encoded>
      <itunes:duration>2095</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1746649332]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4583154680.mp3?updated=1740586341" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Cardiac Clarity: Dr. Keith Channon Talks Revolutionizing Heart Health With AI - Ep. 212</title>
      <link>https://soundcloud.com/theaipodcast/cardiac-caristo-dr-keith-channon</link>
      <description>Here’s some news to still beating hearts: AI is helping bring some clarity to cardiology. Caristo Diagnostics has developed an AI-powered solution for detecting coronary inflammation in cardiac CT scans. In this episode of NVIDIA’s AI Podcast, Dr. Keith Channon, cofounder and chief medical officer at the startup, speaks with host Noah Kravtiz about the technology. Called Caristo, it analyzes radiometric features in CT scan data to identify inflammation in the fat tissue surrounding coronary arteries, a key indicator of heart disease. Tune in to learn more about how Caristo uses AI to improve treatment plans and risk predictions by providing physicians with a patient-specific readout of inflammation levels.</description>
      <pubDate>Wed, 31 Jan 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c297e696-f45b-11ef-8be6-9389245a8d98/image/310282eced52bc8be23c13e8a6ec1ace.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Here’s some news to still beating hearts: AI is h…</itunes:subtitle>
      <itunes:summary>Here’s some news to still beating hearts: AI is helping bring some clarity to cardiology. Caristo Diagnostics has developed an AI-powered solution for detecting coronary inflammation in cardiac CT scans. In this episode of NVIDIA’s AI Podcast, Dr. Keith Channon, cofounder and chief medical officer at the startup, speaks with host Noah Kravtiz about the technology. Called Caristo, it analyzes radiometric features in CT scan data to identify inflammation in the fat tissue surrounding coronary arteries, a key indicator of heart disease. Tune in to learn more about how Caristo uses AI to improve treatment plans and risk predictions by providing physicians with a patient-specific readout of inflammation levels.</itunes:summary>
      <content:encoded>
        <![CDATA[Here’s some news to still beating hearts: AI is helping bring some clarity to cardiology. Caristo Diagnostics has developed an AI-powered solution for detecting coronary inflammation in cardiac CT scans. In this episode of NVIDIA’s AI Podcast, Dr. Keith Channon, cofounder and chief medical officer at the startup, speaks with host Noah Kravtiz about the technology. Called Caristo, it analyzes radiometric features in CT scan data to identify inflammation in the fat tissue surrounding coronary arteries, a key indicator of heart disease. Tune in to learn more about how Caristo uses AI to improve treatment plans and risk predictions by providing physicians with a patient-specific readout of inflammation levels.]]>
      </content:encoded>
      <itunes:duration>2024</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1731441726]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8696540596.mp3?updated=1740586342" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>DigitalPath's Ethan Higgins On Using AI to Fight Wildfires - Ep. 211</title>
      <link>https://soundcloud.com/theaipodcast/ai-wildfire</link>
      <description>DigitalPath is igniting change in the golden state — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real time.  

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company’s role in the ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and the University of California, San Diego. 

DigitalPath built computer vision models to process images collected from network cameras — anywhere from eight to 16 million a day — intelligently identifying signs of fire like smoke.

“One of the things we realized early on, though, is that it’s not necessarily a problem about just detecting a fire in a picture,” Higgins said. “It’s a process of making a manageable amount of data to handle.”

That’s because, he explained, it’s unlikely that humans will be entirely out of the loop in the detection process for the foreseeable future. 

The company uses various AI algorithms to classify images based on whether they should be reviewed or acted upon — if so, an alert is sent out to a CAL FIRE command centers. 

There are some downsides to using computer vision to detect wildfires — namely, that extinguishing more fires means a greater buildup of natural fuel and the potential for larger wildfires in the long term. DigitalPath, along with UCSD, are exploring using high-resolution LIDAR data to identify where those fuels can be let out in the form of prescribed burns. 

Looking ahead, Higgins foresees the field tapping generative AI to accelerate new simulation tools — as well as using AI models to analyze the output of other models to doubly improve wildfire prediction and detection.

“AI is not perfect, but when you couple multiple models together, it can get really close,” he said.</description>
      <pubDate>Wed, 17 Jan 2024 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c2f50cf4-f45b-11ef-8be6-9b5db262140f/image/bd2497d21024600adabf661e03c01347.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>DigitalPath is igniting change in the golden stat…</itunes:subtitle>
      <itunes:summary>DigitalPath is igniting change in the golden state — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real time.  

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company’s role in the ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and the University of California, San Diego. 

DigitalPath built computer vision models to process images collected from network cameras — anywhere from eight to 16 million a day — intelligently identifying signs of fire like smoke.

“One of the things we realized early on, though, is that it’s not necessarily a problem about just detecting a fire in a picture,” Higgins said. “It’s a process of making a manageable amount of data to handle.”

That’s because, he explained, it’s unlikely that humans will be entirely out of the loop in the detection process for the foreseeable future. 

The company uses various AI algorithms to classify images based on whether they should be reviewed or acted upon — if so, an alert is sent out to a CAL FIRE command centers. 

There are some downsides to using computer vision to detect wildfires — namely, that extinguishing more fires means a greater buildup of natural fuel and the potential for larger wildfires in the long term. DigitalPath, along with UCSD, are exploring using high-resolution LIDAR data to identify where those fuels can be let out in the form of prescribed burns. 

Looking ahead, Higgins foresees the field tapping generative AI to accelerate new simulation tools — as well as using AI models to analyze the output of other models to doubly improve wildfire prediction and detection.

“AI is not perfect, but when you couple multiple models together, it can get really close,” he said.</itunes:summary>
      <content:encoded>
        <![CDATA[DigitalPath is igniting change in the golden state — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real time.  

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company’s role in the ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and the University of California, San Diego. 

DigitalPath built computer vision models to process images collected from network cameras — anywhere from eight to 16 million a day — intelligently identifying signs of fire like smoke.

“One of the things we realized early on, though, is that it’s not necessarily a problem about just detecting a fire in a picture,” Higgins said. “It’s a process of making a manageable amount of data to handle.”

That’s because, he explained, it’s unlikely that humans will be entirely out of the loop in the detection process for the foreseeable future. 

The company uses various AI algorithms to classify images based on whether they should be reviewed or acted upon — if so, an alert is sent out to a CAL FIRE command centers. 

There are some downsides to using computer vision to detect wildfires — namely, that extinguishing more fires means a greater buildup of natural fuel and the potential for larger wildfires in the long term. DigitalPath, along with UCSD, are exploring using high-resolution LIDAR data to identify where those fuels can be let out in the form of prescribed burns. 

Looking ahead, Higgins foresees the field tapping generative AI to accelerate new simulation tools — as well as using AI models to analyze the output of other models to doubly improve wildfire prediction and detection.

“AI is not perfect, but when you couple multiple models together, it can get really close,” he said.]]>
      </content:encoded>
      <itunes:duration>1341</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1713097308]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5540889943.mp3?updated=1740586342" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>The Case for Generative AI in the Legal Field - Ep. 210</title>
      <link>https://soundcloud.com/theaipodcast/legal</link>
      <description>Thomson Reuters, the global content and technology company, is transforming the legal industry with generative AI.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Thomson Reuters’ Chief Product Officer David Wong about its potential — and implications.

Many of Thomson Reuters offerings for the legal industry either address an information retrieval problem or help generate written content.

It has a AI-driven digital solution that enables law practitioners to search laws and cases intelligently within different jurisdictions. It also provides AI-powered tools that are set to be integrated with commonly used products like Microsoft 365 to automate the time-consuming processes of drafting and analyzing legal documents.


These technologies increase the productivity of legal professionals, enabling them to focus their time on higher value work. According to Wong, ultimately these tools also have the potential to help deliver better access to justice. 

To address ethical concerns, the company has created publicly available AI development guidelines, as well as privacy and data protection policies. And it’s participating in the drafting of ethical guidelines for the industries it serves. 

There’s still a wide range of reactions surrounding AI use in the legal field, from optimism about its potential to fears of job replacement. But Wong underscored that no matter what the outlook, “it is very likely that professionals that use AI are going to replace professionals that don’t use AI.” 

Looking ahead, Thomson Reuters aims to further integrate generative AI, as well as retrieval-augmented generation techniques into its flagship research products to help lawyers synthesize, read and respond to complicated technical and legal questions. Recently, Thomson Reuters acquired Casetext, which developed the first AI legal assistant, CoCounsel. In 2024 Thomson Reuters is building on this with the launch of an AI assistant that will be the interface across Thomson Reuters products with GenAI capabilities, including those in other fields such as tax and accounting.</description>
      <pubDate>Wed, 20 Dec 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c350e81c-f45b-11ef-8be6-df27d4a706f7/image/ba5af51d67c29dc4bb9fb5c3a8c76841.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Thomson Reuters, the global content and technolog…</itunes:subtitle>
      <itunes:summary>Thomson Reuters, the global content and technology company, is transforming the legal industry with generative AI.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Thomson Reuters’ Chief Product Officer David Wong about its potential — and implications.

Many of Thomson Reuters offerings for the legal industry either address an information retrieval problem or help generate written content.

It has a AI-driven digital solution that enables law practitioners to search laws and cases intelligently within different jurisdictions. It also provides AI-powered tools that are set to be integrated with commonly used products like Microsoft 365 to automate the time-consuming processes of drafting and analyzing legal documents.


These technologies increase the productivity of legal professionals, enabling them to focus their time on higher value work. According to Wong, ultimately these tools also have the potential to help deliver better access to justice. 

To address ethical concerns, the company has created publicly available AI development guidelines, as well as privacy and data protection policies. And it’s participating in the drafting of ethical guidelines for the industries it serves. 

There’s still a wide range of reactions surrounding AI use in the legal field, from optimism about its potential to fears of job replacement. But Wong underscored that no matter what the outlook, “it is very likely that professionals that use AI are going to replace professionals that don’t use AI.” 

Looking ahead, Thomson Reuters aims to further integrate generative AI, as well as retrieval-augmented generation techniques into its flagship research products to help lawyers synthesize, read and respond to complicated technical and legal questions. Recently, Thomson Reuters acquired Casetext, which developed the first AI legal assistant, CoCounsel. In 2024 Thomson Reuters is building on this with the launch of an AI assistant that will be the interface across Thomson Reuters products with GenAI capabilities, including those in other fields such as tax and accounting.</itunes:summary>
      <content:encoded>
        <![CDATA[Thomson Reuters, the global content and technology company, is transforming the legal industry with generative AI.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Thomson Reuters’ Chief Product Officer David Wong about its potential — and implications.

Many of Thomson Reuters offerings for the legal industry either address an information retrieval problem or help generate written content.

It has a AI-driven digital solution that enables law practitioners to search laws and cases intelligently within different jurisdictions. It also provides AI-powered tools that are set to be integrated with commonly used products like Microsoft 365 to automate the time-consuming processes of drafting and analyzing legal documents.


These technologies increase the productivity of legal professionals, enabling them to focus their time on higher value work. According to Wong, ultimately these tools also have the potential to help deliver better access to justice. 

To address ethical concerns, the company has created publicly available AI development guidelines, as well as privacy and data protection policies. And it’s participating in the drafting of ethical guidelines for the industries it serves. 

There’s still a wide range of reactions surrounding AI use in the legal field, from optimism about its potential to fears of job replacement. But Wong underscored that no matter what the outlook, “it is very likely that professionals that use AI are going to replace professionals that don’t use AI.” 

Looking ahead, Thomson Reuters aims to further integrate generative AI, as well as retrieval-augmented generation techniques into its flagship research products to help lawyers synthesize, read and respond to complicated technical and legal questions. Recently, Thomson Reuters acquired Casetext, which developed the first AI legal assistant, CoCounsel. In 2024 Thomson Reuters is building on this with the launch of an AI assistant that will be the interface across Thomson Reuters products with GenAI capabilities, including those in other fields such as tax and accounting.]]>
      </content:encoded>
      <itunes:duration>1783</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1694640141]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6140298575.mp3?updated=1740586343" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Wayve CEO Alex Kendall on Making a Splash in Autonomous Vehicles - Ep. 209</title>
      <link>https://soundcloud.com/theaipodcast/ai-wayve</link>
      <description>A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control. 

Wayve, a London-based autonomous driving technology company, and a member of NVIDIA's startup accelerator program, is leading the surf.

In the latest episode of NVIDIA’s AI Podcast, host Katie Burke Washabaugh spoke with the company’s cofounder and CEO, Alex Kendall, about what AV 2.0 means for the future of self-driving cars. 

Unlike AV 1.0’s focus on perfecting a vehicle’s perception capabilities using multiple deep neural networks, AV 2.0 calls for comprehensive in-vehicle intelligence to drive decision-making in real-world, dynamic environments. 

Embodied AI — the concept of giving AI a physical interface to interact with the world — is the basis of this new AV wave. 

Kendall pointed out that it’s a “hardware/software problem — you need to consider these things separately,” even as they work together. For example, a vehicle can have the highest-quality sensors, but without the right software, the system can’t use them to execute the right decisions. 

Generative AI plays a key role, enabling synthetic data generation so AV makers can use a model’s previous experiences to create and simulate novel driving scenarios. 

It can “take crowds of pedestrians and snow and bring them together” to “create a snowy, crowded pedestrian scene” that the vehicle has never experienced before. 

According to Kendall, that will “play a huge role in both learning and validating the level of performance that we need to deploy these vehicles safely” — all while saving time and costs.

In June, Wayve unveiled GAIA-1, a generative world model for developing autonomous vehicles. 

The company also recently announced LINGO-1, an AI model that allows passengers to use natural language to enhance the learning and explainability of AI driving models. 

Looking ahead, the company hopes to scale and further develop its solutions, improving the safety of AVs to deliver value, build public trust and meet customer expectations. 

Kendall views embodied AI as playing a definitive role in the future of the AI landscape, pushing pioneers to “build better” and “build further” to achieve the “next big breakthroughs.”

For more on NVIDIA's Inception startup accelerator program, visit https://www.nvidia.com/en-us/startups/</description>
      <pubDate>Wed, 06 Dec 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c3ac7f6a-f45b-11ef-8be6-17fc3d9132b3/image/10119f7a38a5afa474685a2baf388e32.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>A new era of autonomous vehicle technology, known…</itunes:subtitle>
      <itunes:summary>A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control. 

Wayve, a London-based autonomous driving technology company, and a member of NVIDIA's startup accelerator program, is leading the surf.

In the latest episode of NVIDIA’s AI Podcast, host Katie Burke Washabaugh spoke with the company’s cofounder and CEO, Alex Kendall, about what AV 2.0 means for the future of self-driving cars. 

Unlike AV 1.0’s focus on perfecting a vehicle’s perception capabilities using multiple deep neural networks, AV 2.0 calls for comprehensive in-vehicle intelligence to drive decision-making in real-world, dynamic environments. 

Embodied AI — the concept of giving AI a physical interface to interact with the world — is the basis of this new AV wave. 

Kendall pointed out that it’s a “hardware/software problem — you need to consider these things separately,” even as they work together. For example, a vehicle can have the highest-quality sensors, but without the right software, the system can’t use them to execute the right decisions. 

Generative AI plays a key role, enabling synthetic data generation so AV makers can use a model’s previous experiences to create and simulate novel driving scenarios. 

It can “take crowds of pedestrians and snow and bring them together” to “create a snowy, crowded pedestrian scene” that the vehicle has never experienced before. 

According to Kendall, that will “play a huge role in both learning and validating the level of performance that we need to deploy these vehicles safely” — all while saving time and costs.

In June, Wayve unveiled GAIA-1, a generative world model for developing autonomous vehicles. 

The company also recently announced LINGO-1, an AI model that allows passengers to use natural language to enhance the learning and explainability of AI driving models. 

Looking ahead, the company hopes to scale and further develop its solutions, improving the safety of AVs to deliver value, build public trust and meet customer expectations. 

Kendall views embodied AI as playing a definitive role in the future of the AI landscape, pushing pioneers to “build better” and “build further” to achieve the “next big breakthroughs.”

For more on NVIDIA's Inception startup accelerator program, visit https://www.nvidia.com/en-us/startups/</itunes:summary>
      <content:encoded>
        <![CDATA[A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control. 

Wayve, a London-based autonomous driving technology company, and a member of NVIDIA's startup accelerator program, is leading the surf.

In the latest episode of NVIDIA’s AI Podcast, host Katie Burke Washabaugh spoke with the company’s cofounder and CEO, Alex Kendall, about what AV 2.0 means for the future of self-driving cars. 

Unlike AV 1.0’s focus on perfecting a vehicle’s perception capabilities using multiple deep neural networks, AV 2.0 calls for comprehensive in-vehicle intelligence to drive decision-making in real-world, dynamic environments. 

Embodied AI — the concept of giving AI a physical interface to interact with the world — is the basis of this new AV wave. 

Kendall pointed out that it’s a “hardware/software problem — you need to consider these things separately,” even as they work together. For example, a vehicle can have the highest-quality sensors, but without the right software, the system can’t use them to execute the right decisions. 

Generative AI plays a key role, enabling synthetic data generation so AV makers can use a model’s previous experiences to create and simulate novel driving scenarios. 

It can “take crowds of pedestrians and snow and bring them together” to “create a snowy, crowded pedestrian scene” that the vehicle has never experienced before. 

According to Kendall, that will “play a huge role in both learning and validating the level of performance that we need to deploy these vehicles safely” — all while saving time and costs.

In June, Wayve unveiled GAIA-1, a generative world model for developing autonomous vehicles. 

The company also recently announced LINGO-1, an AI model that allows passengers to use natural language to enhance the learning and explainability of AI driving models. 

Looking ahead, the company hopes to scale and further develop its solutions, improving the safety of AVs to deliver value, build public trust and meet customer expectations. 

Kendall views embodied AI as playing a definitive role in the future of the AI landscape, pushing pioneers to “build better” and “build further” to achieve the “next big breakthroughs.”

For more on NVIDIA's Inception startup accelerator program, visit https://www.nvidia.com/en-us/startups/]]>
      </content:encoded>
      <itunes:duration>1905</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1683154701]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1595215679.mp3?updated=1740586343" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Annamalai Chockalingam on the Rise of LLMs - Ep. 206</title>
      <link>https://soundcloud.com/theaipodcast/ai-llm</link>
      <description>Generative AI and large language models (LLMs) are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.” 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future potential.

LLMs are a “subset of the larger generative AI movement” that deals with language. They’re deep learning algorithms that can recognize, summarize, translate, predict and generate language. 

AI has been around for a while, but according to Chockalingam, three key factors enabled LLMs. 

One is the availability of large-scale data sets to train models with. As more people used the internet, more data became available for use. The second is the development of computer infrastructure, which has become advanced enough to handle “mountains of data” in a “reasonable timeframe.” And the third is advancements in AI algorithms, allowing for non-sequential or parallel processing of large data pools. 

LLMs can do five things with language: generate, summarize, translate, instruct or chat. With a combination of “these modalities and actions, you can build applications” to solve any problem, Chockalingam said. 

Enterprises are tapping LLMs to “drive innovation,” “develop new customer experiences,” and gain a “competitive advantage.” They’re also exploring what safe deployment of those models looks like, aiming to achieve responsible development, trustworthiness and repeatability.

New techniques like retrieval augmented generation (RAG) could boost LLM development. RAG involves feeding models with up-to-date “data sources or third-party APIs” to achieve “more appropriate responses” — granting them current context so that they can “generate better” answers.

Chockalingam encourages those interested in LLMs to “get your hands dirty and get started” — whether that means using popular applications like ChatGPT or playing with pretrained models in the NVIDIA NGC catalog.

NVIDIA offers a full-stack computing platform for developers and enterprises experimenting with LLMs, with an ecosystem of over 4 million developers and 1,600 generative AI organizations. To learn more, register for LLM Developer Day on Nov. 17 to hear from NVIDIA experts about how best to develop applications.</description>
      <pubDate>Thu, 23 Nov 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c40b5256-f45b-11ef-8be6-fb2878007937/image/3242629dd44f2498971037c440fe5e43.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Generative AI and large language models (LLMs) ar…</itunes:subtitle>
      <itunes:summary>Generative AI and large language models (LLMs) are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.” 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future potential.

LLMs are a “subset of the larger generative AI movement” that deals with language. They’re deep learning algorithms that can recognize, summarize, translate, predict and generate language. 

AI has been around for a while, but according to Chockalingam, three key factors enabled LLMs. 

One is the availability of large-scale data sets to train models with. As more people used the internet, more data became available for use. The second is the development of computer infrastructure, which has become advanced enough to handle “mountains of data” in a “reasonable timeframe.” And the third is advancements in AI algorithms, allowing for non-sequential or parallel processing of large data pools. 

LLMs can do five things with language: generate, summarize, translate, instruct or chat. With a combination of “these modalities and actions, you can build applications” to solve any problem, Chockalingam said. 

Enterprises are tapping LLMs to “drive innovation,” “develop new customer experiences,” and gain a “competitive advantage.” They’re also exploring what safe deployment of those models looks like, aiming to achieve responsible development, trustworthiness and repeatability.

New techniques like retrieval augmented generation (RAG) could boost LLM development. RAG involves feeding models with up-to-date “data sources or third-party APIs” to achieve “more appropriate responses” — granting them current context so that they can “generate better” answers.

Chockalingam encourages those interested in LLMs to “get your hands dirty and get started” — whether that means using popular applications like ChatGPT or playing with pretrained models in the NVIDIA NGC catalog.

NVIDIA offers a full-stack computing platform for developers and enterprises experimenting with LLMs, with an ecosystem of over 4 million developers and 1,600 generative AI organizations. To learn more, register for LLM Developer Day on Nov. 17 to hear from NVIDIA experts about how best to develop applications.</itunes:summary>
      <content:encoded>
        <![CDATA[Generative AI and large language models (LLMs) are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.” 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future potential.

LLMs are a “subset of the larger generative AI movement” that deals with language. They’re deep learning algorithms that can recognize, summarize, translate, predict and generate language. 

AI has been around for a while, but according to Chockalingam, three key factors enabled LLMs. 

One is the availability of large-scale data sets to train models with. As more people used the internet, more data became available for use. The second is the development of computer infrastructure, which has become advanced enough to handle “mountains of data” in a “reasonable timeframe.” And the third is advancements in AI algorithms, allowing for non-sequential or parallel processing of large data pools. 

LLMs can do five things with language: generate, summarize, translate, instruct or chat. With a combination of “these modalities and actions, you can build applications” to solve any problem, Chockalingam said. 

Enterprises are tapping LLMs to “drive innovation,” “develop new customer experiences,” and gain a “competitive advantage.” They’re also exploring what safe deployment of those models looks like, aiming to achieve responsible development, trustworthiness and repeatability.

New techniques like retrieval augmented generation (RAG) could boost LLM development. RAG involves feeding models with up-to-date “data sources or third-party APIs” to achieve “more appropriate responses” — granting them current context so that they can “generate better” answers.

Chockalingam encourages those interested in LLMs to “get your hands dirty and get started” — whether that means using popular applications like ChatGPT or playing with pretrained models in the NVIDIA NGC catalog.

NVIDIA offers a full-stack computing platform for developers and enterprises experimenting with LLMs, with an ecosystem of over 4 million developers and 1,600 generative AI organizations. To learn more, register for LLM Developer Day on Nov. 17 to hear from NVIDIA experts about how best to develop applications.]]>
      </content:encoded>
      <itunes:duration>2312</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1651053912]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7219344189.mp3?updated=1740586344" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Afresh Co-Founder Nathan Fenner On How AI Can Help Grocers Manage Supply Chains - Ep. 208</title>
      <link>https://soundcloud.com/theaipodcast/nathan-fenner-afresh</link>
      <description>Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient. 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of eliminating food waste. 

Most supply chain and inventory management offerings targeting grocers and retailers are outdated. Fenner and his team noticed those solutions, built for the nonperishable side of the business, didn’t work as well on the fresh side — creating enormous amounts of food waste and causing billions in lost profits. 

The team first sought to solve the store-replenishment challenge by developing a platform to help grocers decide how much fresh produce to order to optimize costs while meeting demand. 

They created machine learning and AI models that could effectively use the data generated by fresh produce, which is messier than data generated by nonperishable goods because of factors like time to decay, greater demand fluctuation and unreliability caused by lack of barcodes, leading to incorrect scans at self-checkout registers. 

The result was a fully integrated, machine learning-based platform that helps grocers make informed decisions at each node of the operations process. 

The company also recently launched inventory management software that allows grocers to save time and increase data accuracy by intelligently tracking inventory. That information can be inputted back into the platform’s ordering solution, further refining the accuracy of inventory data. 

It’s all part of Afresh’s greater mission to tackle climate change.

“The most impactful thing we can do is reduce food waste to mitigate climate change,” Fenner said. “It’s really one of the key things that brought me into the business: I think I’ve always had a keen eye to work in the climate space. It’s really motivating for a lot of our team, and it’s a key part of our mission.”</description>
      <pubDate>Tue, 21 Nov 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c499a7d6-f45b-11ef-8be6-6f022d842162/image/551051d8bc3e86cbdb43d417686df430.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Talk about going after low-hanging fruit. Afresh …</itunes:subtitle>
      <itunes:summary>Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient. 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of eliminating food waste. 

Most supply chain and inventory management offerings targeting grocers and retailers are outdated. Fenner and his team noticed those solutions, built for the nonperishable side of the business, didn’t work as well on the fresh side — creating enormous amounts of food waste and causing billions in lost profits. 

The team first sought to solve the store-replenishment challenge by developing a platform to help grocers decide how much fresh produce to order to optimize costs while meeting demand. 

They created machine learning and AI models that could effectively use the data generated by fresh produce, which is messier than data generated by nonperishable goods because of factors like time to decay, greater demand fluctuation and unreliability caused by lack of barcodes, leading to incorrect scans at self-checkout registers. 

The result was a fully integrated, machine learning-based platform that helps grocers make informed decisions at each node of the operations process. 

The company also recently launched inventory management software that allows grocers to save time and increase data accuracy by intelligently tracking inventory. That information can be inputted back into the platform’s ordering solution, further refining the accuracy of inventory data. 

It’s all part of Afresh’s greater mission to tackle climate change.

“The most impactful thing we can do is reduce food waste to mitigate climate change,” Fenner said. “It’s really one of the key things that brought me into the business: I think I’ve always had a keen eye to work in the climate space. It’s really motivating for a lot of our team, and it’s a key part of our mission.”</itunes:summary>
      <content:encoded>
        <![CDATA[Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient. 

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of eliminating food waste. 

Most supply chain and inventory management offerings targeting grocers and retailers are outdated. Fenner and his team noticed those solutions, built for the nonperishable side of the business, didn’t work as well on the fresh side — creating enormous amounts of food waste and causing billions in lost profits. 

The team first sought to solve the store-replenishment challenge by developing a platform to help grocers decide how much fresh produce to order to optimize costs while meeting demand. 

They created machine learning and AI models that could effectively use the data generated by fresh produce, which is messier than data generated by nonperishable goods because of factors like time to decay, greater demand fluctuation and unreliability caused by lack of barcodes, leading to incorrect scans at self-checkout registers. 

The result was a fully integrated, machine learning-based platform that helps grocers make informed decisions at each node of the operations process. 

The company also recently launched inventory management software that allows grocers to save time and increase data accuracy by intelligently tracking inventory. That information can be inputted back into the platform’s ordering solution, further refining the accuracy of inventory data. 

It’s all part of Afresh’s greater mission to tackle climate change.

“The most impactful thing we can do is reduce food waste to mitigate climate change,” Fenner said. “It’s really one of the key things that brought me into the business: I think I’ve always had a keen eye to work in the climate space. It’s really motivating for a lot of our team, and it’s a key part of our mission.”]]>
      </content:encoded>
      <itunes:duration>1980</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1671268662]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1265458091.mp3?updated=1740586345" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Co-Founder of Annalise.ai Aengus Tran on Using AI as a Spell Check for Health Checks - Ep. 207</title>
      <link>https://soundcloud.com/theaipodcast/harrisonai-ceo-aengus-tran</link>
      <description>Clinician-led healthcare AI company Harrison.ai has built an AI system that serves as “spell checker” for radiologists — flagging critical findings to improve the speed and accuracy of radiology image analysis, reducing misdiagnoses.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Harrison.ai CEO and cofounder Aengus Tran about the company’s mission to scale global healthcare capacity with autonomous AI systems. 

Harrison.ai’s initial product, annalise.ai, is an AI tool that automates radiology image analysis to enable faster, more accurate diagnoses. It can produce 124-130 different possible diagnoses and flag key findings to aid radiologists in their final diagnosis. Currently, annalise.ai works for chest X-rays and brain CT scans. 

While an AI designed for categorizing traffic lights, for example, doesn’t need perfection,  medical tools must be highly accurate — any oversight could be fatal. To overcome this challenge, annalise.ai was trained on millions of meticulously annotated images — some were annotated three to five times over before being used for training.

Harrison.ai is also developing Franklin.ai, a sibling AI tool aimed to accelerate and improve the accuracy of histopathology diagnosis — in which a clinician performs a biopsy and inspects the tissue for the presence of cancerous cells. Similarly to annalise.ai, Franklin.ai flags critical findings to assist pathologists in speeding and increasing the accuracy of diagnoses.

Ethical concerns about AI use are ever-rising, but for Tran, the concern is less about whether it’s ethical to use AI for medical diagnosis but “actually the converse: Is it ethical to not use AI for medical diagnosis,” especially if “humans using those AI systems simply pick up more misdiagnosis, pick up more cancer and conditions?” 

Tran also talked about the future of AI systems and suggested that the focus is dual: first, focus on improving preexisting systems and then think of new cutting-edge solutions. 

And for those looking to break into careers in AI and healthcare, Tran says that the “first step is to decide upfront what problems you’re willing to spend a huge part of your time solving first, before the AI part,” emphasizing that the “first thing is actually to fall in love with some problem.”</description>
      <pubDate>Mon, 06 Nov 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c4f95320-f45b-11ef-8be6-234c8b2424e1/image/7221ee94d0f76e5d765306ca17fd56a9.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Clinician-led healthcare AI company Harrison.ai h…</itunes:subtitle>
      <itunes:summary>Clinician-led healthcare AI company Harrison.ai has built an AI system that serves as “spell checker” for radiologists — flagging critical findings to improve the speed and accuracy of radiology image analysis, reducing misdiagnoses.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Harrison.ai CEO and cofounder Aengus Tran about the company’s mission to scale global healthcare capacity with autonomous AI systems. 

Harrison.ai’s initial product, annalise.ai, is an AI tool that automates radiology image analysis to enable faster, more accurate diagnoses. It can produce 124-130 different possible diagnoses and flag key findings to aid radiologists in their final diagnosis. Currently, annalise.ai works for chest X-rays and brain CT scans. 

While an AI designed for categorizing traffic lights, for example, doesn’t need perfection,  medical tools must be highly accurate — any oversight could be fatal. To overcome this challenge, annalise.ai was trained on millions of meticulously annotated images — some were annotated three to five times over before being used for training.

Harrison.ai is also developing Franklin.ai, a sibling AI tool aimed to accelerate and improve the accuracy of histopathology diagnosis — in which a clinician performs a biopsy and inspects the tissue for the presence of cancerous cells. Similarly to annalise.ai, Franklin.ai flags critical findings to assist pathologists in speeding and increasing the accuracy of diagnoses.

Ethical concerns about AI use are ever-rising, but for Tran, the concern is less about whether it’s ethical to use AI for medical diagnosis but “actually the converse: Is it ethical to not use AI for medical diagnosis,” especially if “humans using those AI systems simply pick up more misdiagnosis, pick up more cancer and conditions?” 

Tran also talked about the future of AI systems and suggested that the focus is dual: first, focus on improving preexisting systems and then think of new cutting-edge solutions. 

And for those looking to break into careers in AI and healthcare, Tran says that the “first step is to decide upfront what problems you’re willing to spend a huge part of your time solving first, before the AI part,” emphasizing that the “first thing is actually to fall in love with some problem.”</itunes:summary>
      <content:encoded>
        <![CDATA[Clinician-led healthcare AI company Harrison.ai has built an AI system that serves as “spell checker” for radiologists — flagging critical findings to improve the speed and accuracy of radiology image analysis, reducing misdiagnoses.

In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Harrison.ai CEO and cofounder Aengus Tran about the company’s mission to scale global healthcare capacity with autonomous AI systems. 

Harrison.ai’s initial product, annalise.ai, is an AI tool that automates radiology image analysis to enable faster, more accurate diagnoses. It can produce 124-130 different possible diagnoses and flag key findings to aid radiologists in their final diagnosis. Currently, annalise.ai works for chest X-rays and brain CT scans. 

While an AI designed for categorizing traffic lights, for example, doesn’t need perfection,  medical tools must be highly accurate — any oversight could be fatal. To overcome this challenge, annalise.ai was trained on millions of meticulously annotated images — some were annotated three to five times over before being used for training.

Harrison.ai is also developing Franklin.ai, a sibling AI tool aimed to accelerate and improve the accuracy of histopathology diagnosis — in which a clinician performs a biopsy and inspects the tissue for the presence of cancerous cells. Similarly to annalise.ai, Franklin.ai flags critical findings to assist pathologists in speeding and increasing the accuracy of diagnoses.

Ethical concerns about AI use are ever-rising, but for Tran, the concern is less about whether it’s ethical to use AI for medical diagnosis but “actually the converse: Is it ethical to not use AI for medical diagnosis,” especially if “humans using those AI systems simply pick up more misdiagnosis, pick up more cancer and conditions?” 

Tran also talked about the future of AI systems and suggested that the focus is dual: first, focus on improving preexisting systems and then think of new cutting-edge solutions. 

And for those looking to break into careers in AI and healthcare, Tran says that the “first step is to decide upfront what problems you’re willing to spend a huge part of your time solving first, before the AI part,” emphasizing that the “first thing is actually to fall in love with some problem.”]]>
      </content:encoded>
      <itunes:duration>1876</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1658401437]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8575652623.mp3?updated=1740586346" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Making Machines Mindful: NYU Professor Talks Responsible AI - Ep. 205</title>
      <link>https://soundcloud.com/theaipodcast/making-machines-mindful</link>
      <description>Artificial intelligence is now a household term. Responsible AI is hot on its heels.

Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, wants to make the terms “AI” and “responsible AI” synonymous. 

In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz ‌spoke with Stoyanovich about responsible AI, her advocacy efforts and how people can help.</description>
      <pubDate>Wed, 18 Oct 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c559676a-f45b-11ef-8be6-c7a352523675/image/606b42281dcb47b854b914d67146403c.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Artificial intelligence is now a household term. …</itunes:subtitle>
      <itunes:summary>Artificial intelligence is now a household term. Responsible AI is hot on its heels.

Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, wants to make the terms “AI” and “responsible AI” synonymous. 

In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz ‌spoke with Stoyanovich about responsible AI, her advocacy efforts and how people can help.</itunes:summary>
      <content:encoded>
        <![CDATA[Artificial intelligence is now a household term. Responsible AI is hot on its heels.

Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, wants to make the terms “AI” and “responsible AI” synonymous. 

In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz ‌spoke with Stoyanovich about responsible AI, her advocacy efforts and how people can help.]]>
      </content:encoded>
      <itunes:duration>2150</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1643145072]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6206788715.mp3?updated=1740586346" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Jim Fan Delves Into Large Language Models and Their Industry Impact - Ep. 204</title>
      <link>https://soundcloud.com/theaipodcast/ai-jim-fan</link>
      <description>For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents.

In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with Chat GPT-4 that can autonomously play Minecraft.

AI agents are models that “can proactively take actions and then perceive the world, see the consequences of its actions, and then improve itself,” Fan said. Many current AI agents are programmed to achieve specific objectives, such as beating a game as quickly as possible or answering a question. They can work autonomously toward a particular output but lack a broader decision-making agency.

Fan wondered if it was possible to have a “truly open-ended agent that can be prompted by arbitrary natural language to do open-ended, even creative things.” 

But he needed a flexible playground in which to test that possibility. 
 
“And that’s why we found Minecraft to be almost a perfect primordial soup for open-ended agents to emerge, because it sets up the environment so well,” he said. Minecraft at its core, after all, doesn’t set a specific key objective for players other than to survive and freely explore the open world.

That became the springboard for Fan’s project, MineDojo, which eventually led to the creation of the AI bot Voyager. 

“Voyager leverages the power of Chat GPT-4 to write code in Javascript to execute in the game,” Fan explained. “GPT-4 then looks at the output, and if there’s an error from JavaScript or some feedback from the environment, GPT-4 does a self-reflection and tries to debug the code.”

The bot learns from its mistakes and stores the correctly implemented programs in a skill library for future use, allowing for “lifelong learning.” 

In-game, Voyager can autonomously explore for hours, adapting its decisions based on its environment and developing skills to combat monsters and find food when needed. 

“We see all these behaviors come from the Voyager setup, the skill library and also the coding mechanism,” Fan explained. “We did not preprogram any of these behaviors.” 

He then spoke more generally about the rise and trajectory of LLMs. He foresees strong applications in software, gaming and robotics and increasingly pressing conversations surrounding AI safety. 

Fan encourages those looking to get involved and work with LLMs to “just do something,” whether that means using online resources or experimenting with beginner-friendly, CPU-based AI models.</description>
      <pubDate>Tue, 03 Oct 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c5b61a46-f45b-11ef-8be6-eb5616168dc9/image/4ab23925aa57b3a5c32e02bd766bc8d5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>For NVIDIA Senior AI Scientist Jim Fan, the video…</itunes:subtitle>
      <itunes:summary>For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents.

In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with Chat GPT-4 that can autonomously play Minecraft.

AI agents are models that “can proactively take actions and then perceive the world, see the consequences of its actions, and then improve itself,” Fan said. Many current AI agents are programmed to achieve specific objectives, such as beating a game as quickly as possible or answering a question. They can work autonomously toward a particular output but lack a broader decision-making agency.

Fan wondered if it was possible to have a “truly open-ended agent that can be prompted by arbitrary natural language to do open-ended, even creative things.” 

But he needed a flexible playground in which to test that possibility. 
 
“And that’s why we found Minecraft to be almost a perfect primordial soup for open-ended agents to emerge, because it sets up the environment so well,” he said. Minecraft at its core, after all, doesn’t set a specific key objective for players other than to survive and freely explore the open world.

That became the springboard for Fan’s project, MineDojo, which eventually led to the creation of the AI bot Voyager. 

“Voyager leverages the power of Chat GPT-4 to write code in Javascript to execute in the game,” Fan explained. “GPT-4 then looks at the output, and if there’s an error from JavaScript or some feedback from the environment, GPT-4 does a self-reflection and tries to debug the code.”

The bot learns from its mistakes and stores the correctly implemented programs in a skill library for future use, allowing for “lifelong learning.” 

In-game, Voyager can autonomously explore for hours, adapting its decisions based on its environment and developing skills to combat monsters and find food when needed. 

“We see all these behaviors come from the Voyager setup, the skill library and also the coding mechanism,” Fan explained. “We did not preprogram any of these behaviors.” 

He then spoke more generally about the rise and trajectory of LLMs. He foresees strong applications in software, gaming and robotics and increasingly pressing conversations surrounding AI safety. 

Fan encourages those looking to get involved and work with LLMs to “just do something,” whether that means using online resources or experimenting with beginner-friendly, CPU-based AI models.</itunes:summary>
      <content:encoded>
        <![CDATA[For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents.

In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with Chat GPT-4 that can autonomously play Minecraft.

AI agents are models that “can proactively take actions and then perceive the world, see the consequences of its actions, and then improve itself,” Fan said. Many current AI agents are programmed to achieve specific objectives, such as beating a game as quickly as possible or answering a question. They can work autonomously toward a particular output but lack a broader decision-making agency.

Fan wondered if it was possible to have a “truly open-ended agent that can be prompted by arbitrary natural language to do open-ended, even creative things.” 

But he needed a flexible playground in which to test that possibility. 
 
“And that’s why we found Minecraft to be almost a perfect primordial soup for open-ended agents to emerge, because it sets up the environment so well,” he said. Minecraft at its core, after all, doesn’t set a specific key objective for players other than to survive and freely explore the open world.

That became the springboard for Fan’s project, MineDojo, which eventually led to the creation of the AI bot Voyager. 

“Voyager leverages the power of Chat GPT-4 to write code in Javascript to execute in the game,” Fan explained. “GPT-4 then looks at the output, and if there’s an error from JavaScript or some feedback from the environment, GPT-4 does a self-reflection and tries to debug the code.”

The bot learns from its mistakes and stores the correctly implemented programs in a skill library for future use, allowing for “lifelong learning.” 

In-game, Voyager can autonomously explore for hours, adapting its decisions based on its environment and developing skills to combat monsters and find food when needed. 

“We see all these behaviors come from the Voyager setup, the skill library and also the coding mechanism,” Fan explained. “We did not preprogram any of these behaviors.” 

He then spoke more generally about the rise and trajectory of LLMs. He foresees strong applications in software, gaming and robotics and increasingly pressing conversations surrounding AI safety. 

Fan encourages those looking to get involved and work with LLMs to “just do something,” whether that means using online resources or experimenting with beginner-friendly, CPU-based AI models.]]>
      </content:encoded>
      <itunes:duration>2258</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1627125918]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3996919971.mp3?updated=1740586347" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Anima Anandkumar on Using Generative AI to Tackle Global Challenges - Ep. 203</title>
      <link>https://soundcloud.com/theaipodcast/anima-anandkumar</link>
      <description>Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research.

Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and Technology. 

At the talk, Anandkumar says that generative AI was described as “an inflection point in our lives,” with discussions swirling around how to “harness it to benefit society and humanity through scientific applications.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI’s potential to make splashes in the scientific community. 

It can, for example, be fed DNA, RNA, viral and bacterial data to craft a model that understands the language of genomes. That model can help predict dangerous coronavirus variants to accelerate drug and vaccine research. 

Generative AI can also predict extreme weather events like hurricanes or heat waves. Even with an AI boost, trying to predict natural events is challenging because of the sheer number of variables and unknowns. 

However, Anandkumar explains that it’s not just a matter of upsizing language models or adding compute power — it’s also about fine-tuning and setting the right parameters.

“Those are the aspects we’re working on at NVIDIA and Caltech, in collaboration with many other organizations, to say, ‘How do we capture the multitude of scales present in the natural world?’” she said. “With the limited data we have, can we hope to extrapolate to finer scales? Can we hope to embed the right constraints and come up with physically valid predictions that make a big impact?” 

Anandkumar adds that to ensure AI models are responsibly and safely used, existing laws must be strengthened to prevent dangerous downstream applications.

She also talks about the AI boom, which is transforming the role of humans across industries, and problems yet to be solved. 

“This is the research advice I give to everyone: the most important thing is the question, not the answer,” she said.</description>
      <pubDate>Mon, 11 Sep 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c613504e-f45b-11ef-8be6-43eb6e15be35/image/87204b9eb6c015b19b1d447e2152fa1b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Generative AI-based models can not only learn and…</itunes:subtitle>
      <itunes:summary>Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research.

Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and Technology. 

At the talk, Anandkumar says that generative AI was described as “an inflection point in our lives,” with discussions swirling around how to “harness it to benefit society and humanity through scientific applications.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI’s potential to make splashes in the scientific community. 

It can, for example, be fed DNA, RNA, viral and bacterial data to craft a model that understands the language of genomes. That model can help predict dangerous coronavirus variants to accelerate drug and vaccine research. 

Generative AI can also predict extreme weather events like hurricanes or heat waves. Even with an AI boost, trying to predict natural events is challenging because of the sheer number of variables and unknowns. 

However, Anandkumar explains that it’s not just a matter of upsizing language models or adding compute power — it’s also about fine-tuning and setting the right parameters.

“Those are the aspects we’re working on at NVIDIA and Caltech, in collaboration with many other organizations, to say, ‘How do we capture the multitude of scales present in the natural world?’” she said. “With the limited data we have, can we hope to extrapolate to finer scales? Can we hope to embed the right constraints and come up with physically valid predictions that make a big impact?” 

Anandkumar adds that to ensure AI models are responsibly and safely used, existing laws must be strengthened to prevent dangerous downstream applications.

She also talks about the AI boom, which is transforming the role of humans across industries, and problems yet to be solved. 

“This is the research advice I give to everyone: the most important thing is the question, not the answer,” she said.</itunes:summary>
      <content:encoded>
        <![CDATA[Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research.

Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and Technology. 

At the talk, Anandkumar says that generative AI was described as “an inflection point in our lives,” with discussions swirling around how to “harness it to benefit society and humanity through scientific applications.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI’s potential to make splashes in the scientific community. 

It can, for example, be fed DNA, RNA, viral and bacterial data to craft a model that understands the language of genomes. That model can help predict dangerous coronavirus variants to accelerate drug and vaccine research. 

Generative AI can also predict extreme weather events like hurricanes or heat waves. Even with an AI boost, trying to predict natural events is challenging because of the sheer number of variables and unknowns. 

However, Anandkumar explains that it’s not just a matter of upsizing language models or adding compute power — it’s also about fine-tuning and setting the right parameters.

“Those are the aspects we’re working on at NVIDIA and Caltech, in collaboration with many other organizations, to say, ‘How do we capture the multitude of scales present in the natural world?’” she said. “With the limited data we have, can we hope to extrapolate to finer scales? Can we hope to embed the right constraints and come up with physically valid predictions that make a big impact?” 

Anandkumar adds that to ensure AI models are responsibly and safely used, existing laws must be strengthened to prevent dangerous downstream applications.

She also talks about the AI boom, which is transforming the role of humans across industries, and problems yet to be solved. 

“This is the research advice I give to everyone: the most important thing is the question, not the answer,” she said.]]>
      </content:encoded>
      <itunes:duration>2408</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1613940966]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1131830366.mp3?updated=1740586347" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Deepdub’s Ofir Krakowski on Redefining Dubbing from Hollywood to Bollywood - Ep. 202</title>
      <link>https://soundcloud.com/theaipodcast/ai-deepdub</link>
      <description>In the global entertainment landscape, TV show and film production stretches far beyond Hollywood or Bollywood — it's a worldwide phenomenon. 

However, while streaming platforms have broadened the reach of content, dubbing and translation technology still has plenty of room for growth.

Deepdub acts as a digital bridge, providing access to content by using generative AI to break down language and cultural barriers.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the Israel-based startup’s co-founder and CEO, Ofir Krakowski. Deepdub uses AI-driven dubbing to help entertainment companies boost efficiency and cut costs while increasing accessibility. 

The company is a member of NVIDIA Inception, a free program that offers startups go-to-market support, expertise and technological assistance. 

Traditional dubbing is slow, costly and often missing the mark, Krakowski says. Current technology struggles with the subtleties of language, leaving jokes, idioms or jargon lost in translation. 

Deepdub offers a web-based platform that enables people to interact with sophisticated AI models to handle each part of the translation and dubbing process efficiently. It translates the text, generates a voice and mixes it into the original music and audio effects. 

But as Krakowkski points out, even the best AI models make mistakes, so the platform involves a human touchpoint to verify translations and ensure that generated voices sound natural and capture the right emotion. 

Deepdub is also working on matching lip movements to dubbed voices. 

Ultimately, Krakowski hopes to free the world from the restrictions placed by language barriers. 

“I believe that the technology will enable people to enjoy the content that is created around the world,” he said. “It will globalize storytelling and knowledge, which are currently bound by language barriers.”

https://blogs.nvidia.com/blog/2023/08/30/deepdub/</description>
      <pubDate>Wed, 30 Aug 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c66fe12e-f45b-11ef-8be6-a3ae842be450/image/dbcb1dcd025114ebe051de5b25d0da34.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the global entertainment landscape, TV show an…</itunes:subtitle>
      <itunes:summary>In the global entertainment landscape, TV show and film production stretches far beyond Hollywood or Bollywood — it's a worldwide phenomenon. 

However, while streaming platforms have broadened the reach of content, dubbing and translation technology still has plenty of room for growth.

Deepdub acts as a digital bridge, providing access to content by using generative AI to break down language and cultural barriers.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the Israel-based startup’s co-founder and CEO, Ofir Krakowski. Deepdub uses AI-driven dubbing to help entertainment companies boost efficiency and cut costs while increasing accessibility. 

The company is a member of NVIDIA Inception, a free program that offers startups go-to-market support, expertise and technological assistance. 

Traditional dubbing is slow, costly and often missing the mark, Krakowski says. Current technology struggles with the subtleties of language, leaving jokes, idioms or jargon lost in translation. 

Deepdub offers a web-based platform that enables people to interact with sophisticated AI models to handle each part of the translation and dubbing process efficiently. It translates the text, generates a voice and mixes it into the original music and audio effects. 

But as Krakowkski points out, even the best AI models make mistakes, so the platform involves a human touchpoint to verify translations and ensure that generated voices sound natural and capture the right emotion. 

Deepdub is also working on matching lip movements to dubbed voices. 

Ultimately, Krakowski hopes to free the world from the restrictions placed by language barriers. 

“I believe that the technology will enable people to enjoy the content that is created around the world,” he said. “It will globalize storytelling and knowledge, which are currently bound by language barriers.”

https://blogs.nvidia.com/blog/2023/08/30/deepdub/</itunes:summary>
      <content:encoded>
        <![CDATA[In the global entertainment landscape, TV show and film production stretches far beyond Hollywood or Bollywood — it's a worldwide phenomenon. 

However, while streaming platforms have broadened the reach of content, dubbing and translation technology still has plenty of room for growth.

Deepdub acts as a digital bridge, providing access to content by using generative AI to break down language and cultural barriers.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the Israel-based startup’s co-founder and CEO, Ofir Krakowski. Deepdub uses AI-driven dubbing to help entertainment companies boost efficiency and cut costs while increasing accessibility. 

The company is a member of NVIDIA Inception, a free program that offers startups go-to-market support, expertise and technological assistance. 

Traditional dubbing is slow, costly and often missing the mark, Krakowski says. Current technology struggles with the subtleties of language, leaving jokes, idioms or jargon lost in translation. 

Deepdub offers a web-based platform that enables people to interact with sophisticated AI models to handle each part of the translation and dubbing process efficiently. It translates the text, generates a voice and mixes it into the original music and audio effects. 

But as Krakowkski points out, even the best AI models make mistakes, so the platform involves a human touchpoint to verify translations and ensure that generated voices sound natural and capture the right emotion. 

Deepdub is also working on matching lip movements to dubbed voices. 

Ultimately, Krakowski hopes to free the world from the restrictions placed by language barriers. 

“I believe that the technology will enable people to enjoy the content that is created around the world,” he said. “It will globalize storytelling and knowledge, which are currently bound by language barriers.”

https://blogs.nvidia.com/blog/2023/08/30/deepdub/]]>
      </content:encoded>
      <itunes:duration>1957</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1601292126]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5744793810.mp3?updated=1740586348" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Replit CEO Amjad Masad on Empowering the Next Billion Software Creators - Ep. 201</title>
      <link>https://soundcloud.com/theaipodcast/replit-ceo-amjad-masad</link>
      <description>Replit aims to empower the next billion software creators. 

In this week’s episode of NVIDIA’s AI Podcast, host Noah Kraviz dives into a conversation with Replit CEO Amjad Masad. Masad says the San Francisco-based maker of a software development platform, which came up as a member of NVIDIA’s startup accelerator program, wants to bridge the gap between ideas and software, a task simplified by advances in generative AI. 

“Replit is fundamentally about reducing the friction between an idea and a software product,” Masad said. 

The company’s Ghostwriter coding AI has two main features: a code completion model and a chat model. These features not only make suggestions as users type their code, but also provide intelligent explanations of what a piece of code is doing, tracing dependencies and context. The model can even flag errors and offers solutions — like a full collaborator in a Google Docs for code. 

The company is also developing “make me an app” functionality. This tool allows users to provide high-level instructions to an Artificial Developer Intelligence, which then builds, tests and iterates the requested software. 

The aim is to make software creation accessible to all, even those with no coding experience. While this feature is still under development, Masad said the company plans to improve it over the next year, potentially having it ready for developers in the next 6 to 8 months. 

Going forward, Masad envisions a future where AI functions as a collaborator, able to conduct high-level tasks and even manage resources. “We're entering a period where software is going to feel more alive,” Masad said. “And so I think computing is becoming more humane, more accessible, more exciting, more natural.”

For more on NVIDIA’s startup accelerator program, visit https://www.nvidia.com/en-us/startups/</description>
      <pubDate>Mon, 14 Aug 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c6cc5df0-f45b-11ef-8be6-b34190bd117f/image/25cf0b821142cbbe803d7441e914189e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Replit aims to empower the next billion software …</itunes:subtitle>
      <itunes:summary>Replit aims to empower the next billion software creators. 

In this week’s episode of NVIDIA’s AI Podcast, host Noah Kraviz dives into a conversation with Replit CEO Amjad Masad. Masad says the San Francisco-based maker of a software development platform, which came up as a member of NVIDIA’s startup accelerator program, wants to bridge the gap between ideas and software, a task simplified by advances in generative AI. 

“Replit is fundamentally about reducing the friction between an idea and a software product,” Masad said. 

The company’s Ghostwriter coding AI has two main features: a code completion model and a chat model. These features not only make suggestions as users type their code, but also provide intelligent explanations of what a piece of code is doing, tracing dependencies and context. The model can even flag errors and offers solutions — like a full collaborator in a Google Docs for code. 

The company is also developing “make me an app” functionality. This tool allows users to provide high-level instructions to an Artificial Developer Intelligence, which then builds, tests and iterates the requested software. 

The aim is to make software creation accessible to all, even those with no coding experience. While this feature is still under development, Masad said the company plans to improve it over the next year, potentially having it ready for developers in the next 6 to 8 months. 

Going forward, Masad envisions a future where AI functions as a collaborator, able to conduct high-level tasks and even manage resources. “We're entering a period where software is going to feel more alive,” Masad said. “And so I think computing is becoming more humane, more accessible, more exciting, more natural.”

For more on NVIDIA’s startup accelerator program, visit https://www.nvidia.com/en-us/startups/</itunes:summary>
      <content:encoded>
        <![CDATA[Replit aims to empower the next billion software creators. 

In this week’s episode of NVIDIA’s AI Podcast, host Noah Kraviz dives into a conversation with Replit CEO Amjad Masad. Masad says the San Francisco-based maker of a software development platform, which came up as a member of NVIDIA’s startup accelerator program, wants to bridge the gap between ideas and software, a task simplified by advances in generative AI. 

“Replit is fundamentally about reducing the friction between an idea and a software product,” Masad said. 

The company’s Ghostwriter coding AI has two main features: a code completion model and a chat model. These features not only make suggestions as users type their code, but also provide intelligent explanations of what a piece of code is doing, tracing dependencies and context. The model can even flag errors and offers solutions — like a full collaborator in a Google Docs for code. 

The company is also developing “make me an app” functionality. This tool allows users to provide high-level instructions to an Artificial Developer Intelligence, which then builds, tests and iterates the requested software. 

The aim is to make software creation accessible to all, even those with no coding experience. While this feature is still under development, Masad said the company plans to improve it over the next year, potentially having it ready for developers in the next 6 to 8 months. 

Going forward, Masad envisions a future where AI functions as a collaborator, able to conduct high-level tasks and even manage resources. “We're entering a period where software is going to feel more alive,” Masad said. “And so I think computing is becoming more humane, more accessible, more exciting, more natural.”

For more on NVIDIA’s startup accelerator program, visit https://www.nvidia.com/en-us/startups/]]>
      </content:encoded>
      <itunes:duration>2549</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1590910059]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2842799795.mp3?updated=1740586349" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Codeium’s Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development - Ep. 200</title>
      <link>https://soundcloud.com/theaipodcast/codeiums</link>
      <description>The world increasingly runs on code. 

Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of NVIDIA’s Inception program for startups, aims to do. 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun Mohan and Jeff Wang, the company’s head of business, about the company's business, about how AI is transforming software.

Codeium's AI-powered code acceleration toolkit boasts three core features: autocomplete, chat and search. 

Autocomplete intelligently suggests code segments, saving developers time by minimizing the need for writing boilerplate or unit tests. 

At the same time the chat function empowers developers to rework or even create code with natural language queries, enhancing their coding efficiency while providing searchable context on the entire code base.

Noah spoke with Mohan and Wang about the future of software development with AI, and the continued, essential role of humans in the process.</description>
      <pubDate>Wed, 26 Jul 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c727b84e-f45b-11ef-8be6-37a248182669/image/1e4540180a81a725b06aa99307ed0959.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The world increasingly runs on code. 

Accelerati…</itunes:subtitle>
      <itunes:summary>The world increasingly runs on code. 

Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of NVIDIA’s Inception program for startups, aims to do. 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun Mohan and Jeff Wang, the company’s head of business, about the company's business, about how AI is transforming software.

Codeium's AI-powered code acceleration toolkit boasts three core features: autocomplete, chat and search. 

Autocomplete intelligently suggests code segments, saving developers time by minimizing the need for writing boilerplate or unit tests. 

At the same time the chat function empowers developers to rework or even create code with natural language queries, enhancing their coding efficiency while providing searchable context on the entire code base.

Noah spoke with Mohan and Wang about the future of software development with AI, and the continued, essential role of humans in the process.</itunes:summary>
      <content:encoded>
        <![CDATA[The world increasingly runs on code. 

Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of NVIDIA’s Inception program for startups, aims to do. 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun Mohan and Jeff Wang, the company’s head of business, about the company's business, about how AI is transforming software.

Codeium's AI-powered code acceleration toolkit boasts three core features: autocomplete, chat and search. 

Autocomplete intelligently suggests code segments, saving developers time by minimizing the need for writing boilerplate or unit tests. 

At the same time the chat function empowers developers to rework or even create code with natural language queries, enhancing their coding efficiency while providing searchable context on the entire code base.

Noah spoke with Mohan and Wang about the future of software development with AI, and the continued, essential role of humans in the process.]]>
      </content:encoded>
      <itunes:duration>2342</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1574497063]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4310650478.mp3?updated=1740586349" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>MosaicML's Naveen Rao on Making Custom LLMs More Accessible - Ep. 199</title>
      <link>https://soundcloud.com/theaipodcast/mosaicml-naveen-rao</link>
      <description>Startup MosaicML is on a mission to help the AI community enhance prediction accuracy, decrease costs, and save time by providing tools for easy training and deployment of large AI models.

In this episode of NVIDIA's AI Podcast, host Noah Kravitz speaks with MosaicML CEO and co-founder Naveen Rao, about how the company aims to democratize access to large language models.

MosaicML, a member of NVIDIA's Inception program, has identified two key barriers to widespread adoption: the difficulty of coordinating a large number of GPUs to train a model and the costs associated with this process.

Making training of models accessible is key for many companies who need to control over model behavior, respect data privacy, and iterate fast to develop new products based on AI.</description>
      <pubDate>Wed, 12 Jul 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c785180e-f45b-11ef-8be6-37ba5b6f977d/image/ac065564f933aa1ab4f833f167c3e554.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Startup MosaicML is on a mission to help the AI c…</itunes:subtitle>
      <itunes:summary>Startup MosaicML is on a mission to help the AI community enhance prediction accuracy, decrease costs, and save time by providing tools for easy training and deployment of large AI models.

In this episode of NVIDIA's AI Podcast, host Noah Kravitz speaks with MosaicML CEO and co-founder Naveen Rao, about how the company aims to democratize access to large language models.

MosaicML, a member of NVIDIA's Inception program, has identified two key barriers to widespread adoption: the difficulty of coordinating a large number of GPUs to train a model and the costs associated with this process.

Making training of models accessible is key for many companies who need to control over model behavior, respect data privacy, and iterate fast to develop new products based on AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Startup MosaicML is on a mission to help the AI community enhance prediction accuracy, decrease costs, and save time by providing tools for easy training and deployment of large AI models.

In this episode of NVIDIA's AI Podcast, host Noah Kravitz speaks with MosaicML CEO and co-founder Naveen Rao, about how the company aims to democratize access to large language models.

MosaicML, a member of NVIDIA's Inception program, has identified two key barriers to widespread adoption: the difficulty of coordinating a large number of GPUs to train a model and the costs associated with this process.

Making training of models accessible is key for many companies who need to control over model behavior, respect data privacy, and iterate fast to develop new products based on AI.]]>
      </content:encoded>
      <itunes:duration>1886</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1558919602]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3831162358.mp3?updated=1740586350" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Matice Founder Jessica Whited on Harnessing Regenerative Species for Medical Breakthroughs - Ep. 198</title>
      <link>https://soundcloud.com/theaipodcast/matice</link>
      <description>Scientists at Matice Biosciences are using AI to study the regeneration of tissues in animals known as super-regenerators, such as salamanders and planarians. 

The goal of the research is to develop new treatments that will help humans heal from injuries without scarring.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with Jessica Whited, a regenerative biologist at Harvard University and co-founder of Matice Biosciences.

https://blogs.nvidia.com/blog/2023/06/21/matice/</description>
      <pubDate>Wed, 28 Jun 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c7e046a2-f45b-11ef-8be6-0f9422746b5c/image/aeee8c0bc8a7302354b730d88b5e46b7.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Scientists at Matice Biosciences are using AI to …</itunes:subtitle>
      <itunes:summary>Scientists at Matice Biosciences are using AI to study the regeneration of tissues in animals known as super-regenerators, such as salamanders and planarians. 

The goal of the research is to develop new treatments that will help humans heal from injuries without scarring.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with Jessica Whited, a regenerative biologist at Harvard University and co-founder of Matice Biosciences.

https://blogs.nvidia.com/blog/2023/06/21/matice/</itunes:summary>
      <content:encoded>
        <![CDATA[Scientists at Matice Biosciences are using AI to study the regeneration of tissues in animals known as super-regenerators, such as salamanders and planarians. 

The goal of the research is to develop new treatments that will help humans heal from injuries without scarring.

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with Jessica Whited, a regenerative biologist at Harvard University and co-founder of Matice Biosciences.

https://blogs.nvidia.com/blog/2023/06/21/matice/]]>
      </content:encoded>
      <itunes:duration>2348</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1550643253]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7590452540.mp3?updated=1740586350" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>MIT's Anant Agarwal on AI in Education - Ep. 197</title>
      <link>https://soundcloud.com/theaipodcast/edtech</link>
      <description>In the latest episode of NVIDIA's AI Podcast, Anant Agarwal, founder of edX and Chief Platform Officer at 2U, shared his vision for the future of online education and the impact of artificial intelligence in revolutionizing the learning experience.

Agarwal, a strong advocate for Massive Open Online Courses MOOCs, discussed the importance of accessibility and quality in education. The MIT professor and renowned edtech pioneer also highlighted the implementation of AI-powered features in the edX platform, including the ChatGPT plugin and edX Xpert, an AI-powered learning assistant.</description>
      <pubDate>Wed, 07 Jun 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c83ed366-f45b-11ef-8be6-d71880c52701/image/6cbdbfcf04cce1831f44730e1294b838.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the latest episode of NVIDIA's AI Podcast, Ana…</itunes:subtitle>
      <itunes:summary>In the latest episode of NVIDIA's AI Podcast, Anant Agarwal, founder of edX and Chief Platform Officer at 2U, shared his vision for the future of online education and the impact of artificial intelligence in revolutionizing the learning experience.

Agarwal, a strong advocate for Massive Open Online Courses MOOCs, discussed the importance of accessibility and quality in education. The MIT professor and renowned edtech pioneer also highlighted the implementation of AI-powered features in the edX platform, including the ChatGPT plugin and edX Xpert, an AI-powered learning assistant.</itunes:summary>
      <content:encoded>
        <![CDATA[In the latest episode of NVIDIA's AI Podcast, Anant Agarwal, founder of edX and Chief Platform Officer at 2U, shared his vision for the future of online education and the impact of artificial intelligence in revolutionizing the learning experience.

Agarwal, a strong advocate for Massive Open Online Courses MOOCs, discussed the importance of accessibility and quality in education. The MIT professor and renowned edtech pioneer also highlighted the implementation of AI-powered features in the edX platform, including the ChatGPT plugin and edX Xpert, an AI-powered learning assistant.]]>
      </content:encoded>
      <itunes:duration>2325</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1532657599]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3638376296.mp3?updated=1740586351" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Alex Fielding and Privateer Space Are Taking on Space Debris - Ep. 196</title>
      <link>https://soundcloud.com/theaipodcast/ai-alex-fielding</link>
      <description>In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. 

Fielding is a tech industry veteran, having previously worked alongside Apple co-founder Steve Wozniak on several projects, and holds a deep expertise in engineering, robotics, machine learning and AI.

Privateer Space, Fielding’s latest venture, aims to address one of the most daunting challenges facing our world today: space debris. 

The company is creating a data infrastructure to monitor and clean up space debris, ensuring sustainable growth for the budding space economy. In essence, they’re the sanitation engineers of the cosmos. 

Privateer is also focused on bolstering space accessibility. All of the company’s datasets and those of its partners are being made available through APIs, so users can more easily build space applications related to Earth observation, climate science and more.

Privateer Space is a part of NVIDIA Inception, a free program that offers go-to-market support, expertise and technology for AI startups.

During the podcast, Fielding shares the genesis of Privateer Space, his journey from Apple to the space industry, and his subsequent work on communication between satellites at different altitudes. 

He also addresses the severity of space debris, explaining how every launch adds more debris, including minute yet potentially dangerous fragments like frozen propellant and paint chips.

https://blogs.nvidia.com/blog/2023/05/23/privateer-space</description>
      <pubDate>Thu, 18 May 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c89b7dbe-f45b-11ef-8be6-e715482c7c84/image/947672833e075253ec4d08b14f3700d3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In this episode of the NVIDIA AI Podcast, host No…</itunes:subtitle>
      <itunes:summary>In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. 

Fielding is a tech industry veteran, having previously worked alongside Apple co-founder Steve Wozniak on several projects, and holds a deep expertise in engineering, robotics, machine learning and AI.

Privateer Space, Fielding’s latest venture, aims to address one of the most daunting challenges facing our world today: space debris. 

The company is creating a data infrastructure to monitor and clean up space debris, ensuring sustainable growth for the budding space economy. In essence, they’re the sanitation engineers of the cosmos. 

Privateer is also focused on bolstering space accessibility. All of the company’s datasets and those of its partners are being made available through APIs, so users can more easily build space applications related to Earth observation, climate science and more.

Privateer Space is a part of NVIDIA Inception, a free program that offers go-to-market support, expertise and technology for AI startups.

During the podcast, Fielding shares the genesis of Privateer Space, his journey from Apple to the space industry, and his subsequent work on communication between satellites at different altitudes. 

He also addresses the severity of space debris, explaining how every launch adds more debris, including minute yet potentially dangerous fragments like frozen propellant and paint chips.

https://blogs.nvidia.com/blog/2023/05/23/privateer-space</itunes:summary>
      <content:encoded>
        <![CDATA[In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. 

Fielding is a tech industry veteran, having previously worked alongside Apple co-founder Steve Wozniak on several projects, and holds a deep expertise in engineering, robotics, machine learning and AI.

Privateer Space, Fielding’s latest venture, aims to address one of the most daunting challenges facing our world today: space debris. 

The company is creating a data infrastructure to monitor and clean up space debris, ensuring sustainable growth for the budding space economy. In essence, they’re the sanitation engineers of the cosmos. 

Privateer is also focused on bolstering space accessibility. All of the company’s datasets and those of its partners are being made available through APIs, so users can more easily build space applications related to Earth observation, climate science and more.

Privateer Space is a part of NVIDIA Inception, a free program that offers go-to-market support, expertise and technology for AI startups.

During the podcast, Fielding shares the genesis of Privateer Space, his journey from Apple to the space industry, and his subsequent work on communication between satellites at different altitudes. 

He also addresses the severity of space debris, explaining how every launch adds more debris, including minute yet potentially dangerous fragments like frozen propellant and paint chips.

https://blogs.nvidia.com/blog/2023/05/23/privateer-space]]>
      </content:encoded>
      <itunes:duration>2400</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1518052162]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6651023419.mp3?updated=1740586352" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Bojan Tunguz, Johnny Israeli on How AI and Crowdsourcing Can Advance Vaccine Distribution - Ep. 195</title>
      <link>https://soundcloud.com/theaipodcast/crowdsource</link>
      <description>Artificial intelligence is teaming up with crowdsourcing to improve the thermo-stability of mRNA vaccines, making distribution more accessible worldwide.

In this episode of NVIDIA's AI podcast, host Noah Kravitz interviewed Bojan Tunguz, a physicist and senior system software engineer at NVIDIA, and Johnny Israeli, senior manager of AI and cloud software at NVIDIA. 

The guests delved into AI's potential in drug discovery and the Stanford Open Vaccine competition, a machine-learning contest using crowdsourcing to tackle the thermo-stability challenges of mRNA vaccines.

Kaggle, the online machine learning competition platform, hosted the Stanford Open Vaccine competition. Tunguz, a quadruple Kaggle grandmaster, shared how Kaggle has grown to encompass not just competitions, but also datasets, code, and discussions. Competitors can earn points, rankings, and status achievements across these four areas.

The fusion of artificial intelligence, crowdsourcing, and machine learning competitions is opening new possibilities in drug discovery and vaccine distribution. By tapping into the collective wisdom and skills of participants worldwide, it becomes possible to solve pressing global problems, such as enhancing the thermo-stability of mRNA vaccines, allowing for a more efficient and widely accessible distribution process.

Don't miss this enlightening conversation on the transformative power of AI and crowdsourcing in mRNA vaccine distribution.</description>
      <pubDate>Mon, 01 May 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c8f71840-f45b-11ef-8be6-871d2733ee3f/image/03ef943c3b6d856a50f439f455b39497.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Artificial intelligence is teaming up with crowds…</itunes:subtitle>
      <itunes:summary>Artificial intelligence is teaming up with crowdsourcing to improve the thermo-stability of mRNA vaccines, making distribution more accessible worldwide.

In this episode of NVIDIA's AI podcast, host Noah Kravitz interviewed Bojan Tunguz, a physicist and senior system software engineer at NVIDIA, and Johnny Israeli, senior manager of AI and cloud software at NVIDIA. 

The guests delved into AI's potential in drug discovery and the Stanford Open Vaccine competition, a machine-learning contest using crowdsourcing to tackle the thermo-stability challenges of mRNA vaccines.

Kaggle, the online machine learning competition platform, hosted the Stanford Open Vaccine competition. Tunguz, a quadruple Kaggle grandmaster, shared how Kaggle has grown to encompass not just competitions, but also datasets, code, and discussions. Competitors can earn points, rankings, and status achievements across these four areas.

The fusion of artificial intelligence, crowdsourcing, and machine learning competitions is opening new possibilities in drug discovery and vaccine distribution. By tapping into the collective wisdom and skills of participants worldwide, it becomes possible to solve pressing global problems, such as enhancing the thermo-stability of mRNA vaccines, allowing for a more efficient and widely accessible distribution process.

Don't miss this enlightening conversation on the transformative power of AI and crowdsourcing in mRNA vaccine distribution.</itunes:summary>
      <content:encoded>
        <![CDATA[Artificial intelligence is teaming up with crowdsourcing to improve the thermo-stability of mRNA vaccines, making distribution more accessible worldwide.

In this episode of NVIDIA's AI podcast, host Noah Kravitz interviewed Bojan Tunguz, a physicist and senior system software engineer at NVIDIA, and Johnny Israeli, senior manager of AI and cloud software at NVIDIA. 

The guests delved into AI's potential in drug discovery and the Stanford Open Vaccine competition, a machine-learning contest using crowdsourcing to tackle the thermo-stability challenges of mRNA vaccines.

Kaggle, the online machine learning competition platform, hosted the Stanford Open Vaccine competition. Tunguz, a quadruple Kaggle grandmaster, shared how Kaggle has grown to encompass not just competitions, but also datasets, code, and discussions. Competitors can earn points, rankings, and status achievements across these four areas.

The fusion of artificial intelligence, crowdsourcing, and machine learning competitions is opening new possibilities in drug discovery and vaccine distribution. By tapping into the collective wisdom and skills of participants worldwide, it becomes possible to solve pressing global problems, such as enhancing the thermo-stability of mRNA vaccines, allowing for a more efficient and widely accessible distribution process.

Don't miss this enlightening conversation on the transformative power of AI and crowdsourcing in mRNA vaccine distribution.]]>
      </content:encoded>
      <itunes:duration>1985</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1502486944]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7551446723.mp3?updated=1740586352" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>The Future of Intelligent Vehicle Interiors: Building Trust With HMI &amp; AI - Ep. 194</title>
      <link>https://soundcloud.com/theaipodcast/ai-rightware</link>
      <description>Imagine a future where your vehicle's interior offers personalized experiences and builds trust through human-machine interfaces and artificial intelligence. In this episode of the NVIDIA AI Podcast, host Katie Burke Washabaugh and guest Andreas Binner, Chief Technology Officer at Rightware, delve into this fascinating topic.

Rightware is a company at the forefront of developing in-vehicle HMI. Their platform, Kanzi, works in tandem with NVIDIA DRIVE IX to provide a complete toolchain for designing personalized vehicle interiors for the next generation of transportation, including detailed visualizations of the car's AI.

Andreas touches on his journey into automotive technology and HMI, the evolution of infotainment in the automotive industry over the past decade, and surprising trends in HMI. They explore the influence of AI on HMI, novel AI-enabled features, and the importance of trust in new technologies.

Other topics include the role of HMI in fostering trust between vehicle occupants and the vehicle, the implications of autonomous vehicle visualization, balancing larger in-vehicle screens with driver distraction risks, additional features for trust-building between autonomous vehicles and passengers, and predictions for intelligent cockpits in the next decade.

Learn about the innovations that Rightware's Kanzi platform and NVIDIA DRIVE IX bring to the automotive industry and how they contribute to the development of intelligent vehicle interiors. Tune in.</description>
      <pubDate>Tue, 25 Apr 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c953da26-f45b-11ef-8be6-db0caa50f808/image/534c70521dda471ca900242c1ab5c6b3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Imagine a future where your vehicle's interior of…</itunes:subtitle>
      <itunes:summary>Imagine a future where your vehicle's interior offers personalized experiences and builds trust through human-machine interfaces and artificial intelligence. In this episode of the NVIDIA AI Podcast, host Katie Burke Washabaugh and guest Andreas Binner, Chief Technology Officer at Rightware, delve into this fascinating topic.

Rightware is a company at the forefront of developing in-vehicle HMI. Their platform, Kanzi, works in tandem with NVIDIA DRIVE IX to provide a complete toolchain for designing personalized vehicle interiors for the next generation of transportation, including detailed visualizations of the car's AI.

Andreas touches on his journey into automotive technology and HMI, the evolution of infotainment in the automotive industry over the past decade, and surprising trends in HMI. They explore the influence of AI on HMI, novel AI-enabled features, and the importance of trust in new technologies.

Other topics include the role of HMI in fostering trust between vehicle occupants and the vehicle, the implications of autonomous vehicle visualization, balancing larger in-vehicle screens with driver distraction risks, additional features for trust-building between autonomous vehicles and passengers, and predictions for intelligent cockpits in the next decade.

Learn about the innovations that Rightware's Kanzi platform and NVIDIA DRIVE IX bring to the automotive industry and how they contribute to the development of intelligent vehicle interiors. Tune in.</itunes:summary>
      <content:encoded>
        <![CDATA[Imagine a future where your vehicle's interior offers personalized experiences and builds trust through human-machine interfaces and artificial intelligence. In this episode of the NVIDIA AI Podcast, host Katie Burke Washabaugh and guest Andreas Binner, Chief Technology Officer at Rightware, delve into this fascinating topic.

Rightware is a company at the forefront of developing in-vehicle HMI. Their platform, Kanzi, works in tandem with NVIDIA DRIVE IX to provide a complete toolchain for designing personalized vehicle interiors for the next generation of transportation, including detailed visualizations of the car's AI.

Andreas touches on his journey into automotive technology and HMI, the evolution of infotainment in the automotive industry over the past decade, and surprising trends in HMI. They explore the influence of AI on HMI, novel AI-enabled features, and the importance of trust in new technologies.

Other topics include the role of HMI in fostering trust between vehicle occupants and the vehicle, the implications of autonomous vehicle visualization, balancing larger in-vehicle screens with driver distraction risks, additional features for trust-building between autonomous vehicles and passengers, and predictions for intelligent cockpits in the next decade.

Learn about the innovations that Rightware's Kanzi platform and NVIDIA DRIVE IX bring to the automotive industry and how they contribute to the development of intelligent vehicle interiors. Tune in.]]>
      </content:encoded>
      <itunes:duration>1254</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1497818689]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3721111282.mp3?updated=1740586353" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How GlüxKind Created Ella, the AI-Powered Smart Stroller - Ep. 193</title>
      <link>https://soundcloud.com/theaipodcast/ai-stroller</link>
      <description>Imagine a stroller that can drive itself, help users up hills, brake on slopes and provide alerts of potential hazards. That’s what GlüxKind has done with Ella, an award-winning smart stroller that uses the NVIDIA Jetson edge AI and robotics platform to power its AI features. 

Kevin Huang and Anne Hunger are the co-founders of GlüxKind, a Vancouver-based startup that aims to make parenting easier with AI. They’re also married and have a child together who inspired them to create Ella. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Huang and Hunger about their journey from being consumers looking for a better stroller to becoming entrepreneurs who built one. 

They discuss how NVIDIA Jetson enables Ella’s self-driving capabilities, object detection, voice control and other features that make it stand out from other strollers. 

The pair also share their vision for the future of smart baby gear and how they hope to improve the lives of parents and caregivers around the world.</description>
      <pubDate>Mon, 10 Apr 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/c9af8e66-f45b-11ef-8be6-1b7ef11d4423/image/524dd2350cce354429c30024a19d3cce.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Imagine a stroller that can drive itself, help us…</itunes:subtitle>
      <itunes:summary>Imagine a stroller that can drive itself, help users up hills, brake on slopes and provide alerts of potential hazards. That’s what GlüxKind has done with Ella, an award-winning smart stroller that uses the NVIDIA Jetson edge AI and robotics platform to power its AI features. 

Kevin Huang and Anne Hunger are the co-founders of GlüxKind, a Vancouver-based startup that aims to make parenting easier with AI. They’re also married and have a child together who inspired them to create Ella. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Huang and Hunger about their journey from being consumers looking for a better stroller to becoming entrepreneurs who built one. 

They discuss how NVIDIA Jetson enables Ella’s self-driving capabilities, object detection, voice control and other features that make it stand out from other strollers. 

The pair also share their vision for the future of smart baby gear and how they hope to improve the lives of parents and caregivers around the world.</itunes:summary>
      <content:encoded>
        <![CDATA[Imagine a stroller that can drive itself, help users up hills, brake on slopes and provide alerts of potential hazards. That’s what GlüxKind has done with Ella, an award-winning smart stroller that uses the NVIDIA Jetson edge AI and robotics platform to power its AI features. 

Kevin Huang and Anne Hunger are the co-founders of GlüxKind, a Vancouver-based startup that aims to make parenting easier with AI. They’re also married and have a child together who inspired them to create Ella. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Huang and Hunger about their journey from being consumers looking for a better stroller to becoming entrepreneurs who built one. 

They discuss how NVIDIA Jetson enables Ella’s self-driving capabilities, object detection, voice control and other features that make it stand out from other strollers. 

The pair also share their vision for the future of smart baby gear and how they hope to improve the lives of parents and caregivers around the world.]]>
      </content:encoded>
      <itunes:duration>1584</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1490530207]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2248006908.mp3?updated=1740586353" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ubisoft’s Yves Jacquier on How Generative AI Will Revolutionize Gaming - Ep. 192</title>
      <link>https://soundcloud.com/theaipodcast/ai-ubisoft</link>
      <description>Tools like ChatGPT have awakened the world to the potential of generative AI. Now, much more is coming.

On the latest episode of NVIDIA’s AI Podcast, Yves Jacquier, executive director of Ubisoft La Forge, shares valuable insights into the transformative potential of generative AI in the gaming industry. With over two decades of experience in technology innovation, science and R&amp;D management across various sectors, Jacquier’s comprehensive expertise makes him a true visionary in the field.

During his conversation with podcast host Noah Kravitz, Jacquier highlighted how generative AI, which enables computers to create unique content such as images, text and music, is already revolutionizing the gaming sector. By designing new levels, characters and items, and generating realistic graphics and soundscapes, this cutting-edge technology offers countless opportunities for more immersive and engaging experiences.

As the driving force behind Ubisoft La Forge, Jacquier plays a crucial role in shaping the company’s academic R&amp;D strategy. Key milestones include establishing a chair in AI deep learning in 2011 and founding Ubisoft La Forge, the first lab in the gaming industry dedicated to applied academic research — research that’s being translated into state-of-the-art gaming experiences.</description>
      <pubDate>Mon, 27 Mar 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ca10246a-f45b-11ef-8be6-834c586d2cce/image/f2139307bcf264f24e18f08d1f1b0ac1.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Tools like ChatGPT have awakened the world to the…</itunes:subtitle>
      <itunes:summary>Tools like ChatGPT have awakened the world to the potential of generative AI. Now, much more is coming.

On the latest episode of NVIDIA’s AI Podcast, Yves Jacquier, executive director of Ubisoft La Forge, shares valuable insights into the transformative potential of generative AI in the gaming industry. With over two decades of experience in technology innovation, science and R&amp;D management across various sectors, Jacquier’s comprehensive expertise makes him a true visionary in the field.

During his conversation with podcast host Noah Kravitz, Jacquier highlighted how generative AI, which enables computers to create unique content such as images, text and music, is already revolutionizing the gaming sector. By designing new levels, characters and items, and generating realistic graphics and soundscapes, this cutting-edge technology offers countless opportunities for more immersive and engaging experiences.

As the driving force behind Ubisoft La Forge, Jacquier plays a crucial role in shaping the company’s academic R&amp;D strategy. Key milestones include establishing a chair in AI deep learning in 2011 and founding Ubisoft La Forge, the first lab in the gaming industry dedicated to applied academic research — research that’s being translated into state-of-the-art gaming experiences.</itunes:summary>
      <content:encoded>
        <![CDATA[Tools like ChatGPT have awakened the world to the potential of generative AI. Now, much more is coming.

On the latest episode of NVIDIA’s AI Podcast, Yves Jacquier, executive director of Ubisoft La Forge, shares valuable insights into the transformative potential of generative AI in the gaming industry. With over two decades of experience in technology innovation, science and R&amp;D management across various sectors, Jacquier’s comprehensive expertise makes him a true visionary in the field.

During his conversation with podcast host Noah Kravitz, Jacquier highlighted how generative AI, which enables computers to create unique content such as images, text and music, is already revolutionizing the gaming sector. By designing new levels, characters and items, and generating realistic graphics and soundscapes, this cutting-edge technology offers countless opportunities for more immersive and engaging experiences.

As the driving force behind Ubisoft La Forge, Jacquier plays a crucial role in shaping the company’s academic R&amp;D strategy. Key milestones include establishing a chair in AI deep learning in 2011 and founding Ubisoft La Forge, the first lab in the gaming industry dedicated to applied academic research — research that’s being translated into state-of-the-art gaming experiences.]]>
      </content:encoded>
      <itunes:duration>2126</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1475533357]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3249357315.mp3?updated=1740586354" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Peter Ma on Using AI to Find Promising Signals for Alien Life - Ep. 191</title>
      <link>https://soundcloud.com/theaipodcast/peter-ma-ai-technosignatures</link>
      <description>Peter Ma was bored in his high school computer science class. So he decided to teach himself something new: how to use artificial intelligence to find alien life.

That’s how he eventually became the lead author of a groundbreaking study published in Nature Astronomy. 

The study reveals how Ma and his co-authors used AI to analyze a massive dataset of radio signals collected by the SETI Breakthrough Listen project. 

They found eight signals that might just be technosignatures, or signs of alien technology. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz interviews Ma, who is now an undergraduate student at the University of Toronto. 

Ma tells Kravitz how he stumbled upon this problem and how he developed an AI algorithm that outperformed traditional methods in the search for extraterrestrial intelligence.

You can read more about Ma’s research on NVIDIA’s blog: https://blogs.nvidia.com/blog/2023/02/06/ai-potential-alien-signals/</description>
      <pubDate>Wed, 15 Mar 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ca6ab11e-f45b-11ef-8be6-8bddbddd9881/image/824c740ef5be7a2d0650b42f9aa76c43.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Peter Ma was bored in his high school computer sc…</itunes:subtitle>
      <itunes:summary>Peter Ma was bored in his high school computer science class. So he decided to teach himself something new: how to use artificial intelligence to find alien life.

That’s how he eventually became the lead author of a groundbreaking study published in Nature Astronomy. 

The study reveals how Ma and his co-authors used AI to analyze a massive dataset of radio signals collected by the SETI Breakthrough Listen project. 

They found eight signals that might just be technosignatures, or signs of alien technology. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz interviews Ma, who is now an undergraduate student at the University of Toronto. 

Ma tells Kravitz how he stumbled upon this problem and how he developed an AI algorithm that outperformed traditional methods in the search for extraterrestrial intelligence.

You can read more about Ma’s research on NVIDIA’s blog: https://blogs.nvidia.com/blog/2023/02/06/ai-potential-alien-signals/</itunes:summary>
      <content:encoded>
        <![CDATA[Peter Ma was bored in his high school computer science class. So he decided to teach himself something new: how to use artificial intelligence to find alien life.

That’s how he eventually became the lead author of a groundbreaking study published in Nature Astronomy. 

The study reveals how Ma and his co-authors used AI to analyze a massive dataset of radio signals collected by the SETI Breakthrough Listen project. 

They found eight signals that might just be technosignatures, or signs of alien technology. 

In this episode of the NVIDIA AI Podcast, host Noah Kravitz interviews Ma, who is now an undergraduate student at the University of Toronto. 

Ma tells Kravitz how he stumbled upon this problem and how he developed an AI algorithm that outperformed traditional methods in the search for extraterrestrial intelligence.

You can read more about Ma’s research on NVIDIA’s blog: https://blogs.nvidia.com/blog/2023/02/06/ai-potential-alien-signals/]]>
      </content:encoded>
      <itunes:duration>2050</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1469975854]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1810219958.mp3?updated=1740586355" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Glean Founders Talk AI-Powered Enterprise Search on NVIDIA Podcast - Ep. 190</title>
      <link>https://soundcloud.com/theaipodcast/glean-enterprise-search-llm</link>
      <description>In the quest for knowledge at work, it can be tempting to think that finding what you need is like a needle in a haystack. But what if the haystack itself could show you where the needle is?

That's the promise of large language models, or LLMs as they’re known, and it's the subject of a this week’s episode of NVIDIA’s AI Podcast featuring Deedy Das and Eddie Zhou, founding engineers at Glean, in conversation with our host, Noah Kravitz.  

With large-language models, the haystack can become a source of intelligence, helping guide knowledge workers on what they need to know. 

Glean is a Silicon Valley startup focused on providing better tools for enterprise search by indexing everything employees have access to in the company, including Slack, Dropbox, and email. The company raised a Series C financing round last year, valuing the company at $1 billion. 

By indexing everything employees have access to in the company, LLMs can provide a comprehensive view of the enterprise and its data, making it easier to find the information needed to get work done. 

In the podcast, Das and Zhou discuss the challenges and opportunities of bringing LLMs into the enterprise, and how this technology can help people spend less time searching and more time working.

https://blogs.nvidia.com/blog/2023/03/01/glean-llm-enterprise-search/</description>
      <pubDate>Wed, 01 Mar 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cac56e42-f45b-11ef-8be6-7769dc2037c6/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the quest for knowledge at work, it can be tem…</itunes:subtitle>
      <itunes:summary>In the quest for knowledge at work, it can be tempting to think that finding what you need is like a needle in a haystack. But what if the haystack itself could show you where the needle is?

That's the promise of large language models, or LLMs as they’re known, and it's the subject of a this week’s episode of NVIDIA’s AI Podcast featuring Deedy Das and Eddie Zhou, founding engineers at Glean, in conversation with our host, Noah Kravitz.  

With large-language models, the haystack can become a source of intelligence, helping guide knowledge workers on what they need to know. 

Glean is a Silicon Valley startup focused on providing better tools for enterprise search by indexing everything employees have access to in the company, including Slack, Dropbox, and email. The company raised a Series C financing round last year, valuing the company at $1 billion. 

By indexing everything employees have access to in the company, LLMs can provide a comprehensive view of the enterprise and its data, making it easier to find the information needed to get work done. 

In the podcast, Das and Zhou discuss the challenges and opportunities of bringing LLMs into the enterprise, and how this technology can help people spend less time searching and more time working.

https://blogs.nvidia.com/blog/2023/03/01/glean-llm-enterprise-search/</itunes:summary>
      <content:encoded>
        <![CDATA[In the quest for knowledge at work, it can be tempting to think that finding what you need is like a needle in a haystack. But what if the haystack itself could show you where the needle is?

That's the promise of large language models, or LLMs as they’re known, and it's the subject of a this week’s episode of NVIDIA’s AI Podcast featuring Deedy Das and Eddie Zhou, founding engineers at Glean, in conversation with our host, Noah Kravitz.  

With large-language models, the haystack can become a source of intelligence, helping guide knowledge workers on what they need to know. 

Glean is a Silicon Valley startup focused on providing better tools for enterprise search by indexing everything employees have access to in the company, including Slack, Dropbox, and email. The company raised a Series C financing round last year, valuing the company at $1 billion. 

By indexing everything employees have access to in the company, LLMs can provide a comprehensive view of the enterprise and its data, making it easier to find the information needed to get work done. 

In the podcast, Das and Zhou discuss the challenges and opportunities of bringing LLMs into the enterprise, and how this technology can help people spend less time searching and more time working.

https://blogs.nvidia.com/blog/2023/03/01/glean-llm-enterprise-search/]]>
      </content:encoded>
      <itunes:duration>1979</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1455306718]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7975910330.mp3?updated=1740586355" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Making a Splash: AI Can Help Protect Ocean Goers from Deadly Rips - Ep. 189</title>
      <link>https://soundcloud.com/theaipodcast/ai-christo-rautenbach</link>
      <description>Surfers, swimmers, and beachgoers face a hidden danger in the ocean: rip currents. These narrow channels of water can flow away from the shore at speeds up to 2.5 meters per second, making them one of the biggest safety risks for those enjoying the ocean. 

To help keep beachgoers safe, Dr. Christo Rautenbach, a coastal and estuarine physical processes scientist, has teamed up with the National Institute of Water and Atmospheric Research in New Zealand to develop a real-time rip current identification tool using deep learning.

On this episode of the NVIDIA AI podcast, host Noah Kravitz interviews Dr. Rautenbach about the technology behind the rip current detection tool. The tool was developed by Dr. Rautenbach and NIWA in collaboration with Surf Lifesaving New Zealand and achieved a detection rate of roughly 90% in trials. The research behind the technology was published in the November 22nd edition of the journal Remote Sensing.

Dr. Rautenbach explains how AI can be used to identify rip currents, a critical step in keeping beachgoers safe. He shares the research behind the technology and the results of the trials, as well as the potential for this tool to be used globally to help reduce the number of fatalities caused by rip currents. Tune in.

https://blogs.nvidia.com/blog/2023/02/15/rip</description>
      <pubDate>Wed, 15 Feb 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cb2396ac-f45b-11ef-8be6-b783a11ecdbe/image/e61ce305a835466a0259666d5550c38d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Surfers, swimmers, and beachgoers face a hidden d…</itunes:subtitle>
      <itunes:summary>Surfers, swimmers, and beachgoers face a hidden danger in the ocean: rip currents. These narrow channels of water can flow away from the shore at speeds up to 2.5 meters per second, making them one of the biggest safety risks for those enjoying the ocean. 

To help keep beachgoers safe, Dr. Christo Rautenbach, a coastal and estuarine physical processes scientist, has teamed up with the National Institute of Water and Atmospheric Research in New Zealand to develop a real-time rip current identification tool using deep learning.

On this episode of the NVIDIA AI podcast, host Noah Kravitz interviews Dr. Rautenbach about the technology behind the rip current detection tool. The tool was developed by Dr. Rautenbach and NIWA in collaboration with Surf Lifesaving New Zealand and achieved a detection rate of roughly 90% in trials. The research behind the technology was published in the November 22nd edition of the journal Remote Sensing.

Dr. Rautenbach explains how AI can be used to identify rip currents, a critical step in keeping beachgoers safe. He shares the research behind the technology and the results of the trials, as well as the potential for this tool to be used globally to help reduce the number of fatalities caused by rip currents. Tune in.

https://blogs.nvidia.com/blog/2023/02/15/rip</itunes:summary>
      <content:encoded>
        <![CDATA[Surfers, swimmers, and beachgoers face a hidden danger in the ocean: rip currents. These narrow channels of water can flow away from the shore at speeds up to 2.5 meters per second, making them one of the biggest safety risks for those enjoying the ocean. 

To help keep beachgoers safe, Dr. Christo Rautenbach, a coastal and estuarine physical processes scientist, has teamed up with the National Institute of Water and Atmospheric Research in New Zealand to develop a real-time rip current identification tool using deep learning.

On this episode of the NVIDIA AI podcast, host Noah Kravitz interviews Dr. Rautenbach about the technology behind the rip current detection tool. The tool was developed by Dr. Rautenbach and NIWA in collaboration with Surf Lifesaving New Zealand and achieved a detection rate of roughly 90% in trials. The research behind the technology was published in the November 22nd edition of the journal Remote Sensing.

Dr. Rautenbach explains how AI can be used to identify rip currents, a critical step in keeping beachgoers safe. He shares the research behind the technology and the results of the trials, as well as the potential for this tool to be used globally to help reduce the number of fatalities caused by rip currents. Tune in.

https://blogs.nvidia.com/blog/2023/02/15/rip]]>
      </content:encoded>
      <itunes:duration>2207</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1435966984]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7005396227.mp3?updated=1740586356" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Deloitte’s Nitin Mittal on the Secrets of 'All-In' AI Success - Ep. 188</title>
      <link>https://soundcloud.com/theaipodcast/ai-deloitte</link>
      <description>Artificial intelligence is the new electricity. The fifth industrial revolution. And companies that go all-in on AI are reaping the rewards. So how do you make that happen? 

That big question — how? — is explored by Nitin Mittal, Principal at Deloitte, one of the world’s largest professional services organizations, and co-author Thomas Davenport in their new book "All-In On AI: How Smart Companies Win Big with Artificial Intelligence.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mittal, who leads Deloitte's artificial intelligence growth platform spoke about how companies across a wide variety of industries used AI to radically transform their organizations and achieve competitive advantage. 

The book, from the Harvard Business Review Press, explores the importance of a company-wide commitment to AI and the role of leadership in driving the adoption and implementation of AI. Mittal emphasizes that companies must have a clear strategy and plan, and invest in the necessary technology and talent to make the most of AI.</description>
      <pubDate>Wed, 01 Feb 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cb80a34c-f45b-11ef-8be6-37ac44ea85c6/image/e99c8b06ae392a2ba51fb883cfae3bf2.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Artificial intelligence is the new electricity. T…</itunes:subtitle>
      <itunes:summary>Artificial intelligence is the new electricity. The fifth industrial revolution. And companies that go all-in on AI are reaping the rewards. So how do you make that happen? 

That big question — how? — is explored by Nitin Mittal, Principal at Deloitte, one of the world’s largest professional services organizations, and co-author Thomas Davenport in their new book "All-In On AI: How Smart Companies Win Big with Artificial Intelligence.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mittal, who leads Deloitte's artificial intelligence growth platform spoke about how companies across a wide variety of industries used AI to radically transform their organizations and achieve competitive advantage. 

The book, from the Harvard Business Review Press, explores the importance of a company-wide commitment to AI and the role of leadership in driving the adoption and implementation of AI. Mittal emphasizes that companies must have a clear strategy and plan, and invest in the necessary technology and talent to make the most of AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Artificial intelligence is the new electricity. The fifth industrial revolution. And companies that go all-in on AI are reaping the rewards. So how do you make that happen? 

That big question — how? — is explored by Nitin Mittal, Principal at Deloitte, one of the world’s largest professional services organizations, and co-author Thomas Davenport in their new book "All-In On AI: How Smart Companies Win Big with Artificial Intelligence.” 

On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Mittal, who leads Deloitte's artificial intelligence growth platform spoke about how companies across a wide variety of industries used AI to radically transform their organizations and achieve competitive advantage. 

The book, from the Harvard Business Review Press, explores the importance of a company-wide commitment to AI and the role of leadership in driving the adoption and implementation of AI. Mittal emphasizes that companies must have a clear strategy and plan, and invest in the necessary technology and talent to make the most of AI.]]>
      </content:encoded>
      <itunes:duration>2318</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1435453027]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8963207151.mp3?updated=1740586357" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Sequoia Capital’s Pat Grady and Sonya Huang on Generative AI - Ep. 187</title>
      <link>https://soundcloud.com/theaipodcast/sequoia-capitals-pat-grady-and-sonya-huang-on-generative-ai-ep-187</link>
      <description>In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz is joined by Pat Grady and Sonya Huang, partners at Sequoia Capital, to discuss their recent essay, “Generative AI: A Creative New World.”

The authors delve into the potential of generative AI to enable new forms of creativity and expression, as well as the challenges and ethical considerations of this technology. They also offer insights into the future of generative AI.

Grady and Huang emphasize the potential of generative AI to revolutionize industries such as art, design and media by allowing for the creation of unique, personalized content on a scale that would be impossible for humans to achieve alone. 

They also address the importance of considering the ethical implications of the technology, including the potential for biased or harmful outputs and the need for responsible use and regulation.

Listen to the full episode to hear more about the possibilities of generative AI and the considerations to be made as this technology moves forward.</description>
      <pubDate>Wed, 18 Jan 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cbd8cc8e-f45b-11ef-8be6-1fc2c716665b/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the latest episode of the NVIDIA AI Podcast, h…</itunes:subtitle>
      <itunes:summary>In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz is joined by Pat Grady and Sonya Huang, partners at Sequoia Capital, to discuss their recent essay, “Generative AI: A Creative New World.”

The authors delve into the potential of generative AI to enable new forms of creativity and expression, as well as the challenges and ethical considerations of this technology. They also offer insights into the future of generative AI.

Grady and Huang emphasize the potential of generative AI to revolutionize industries such as art, design and media by allowing for the creation of unique, personalized content on a scale that would be impossible for humans to achieve alone. 

They also address the importance of considering the ethical implications of the technology, including the potential for biased or harmful outputs and the need for responsible use and regulation.

Listen to the full episode to hear more about the possibilities of generative AI and the considerations to be made as this technology moves forward.</itunes:summary>
      <content:encoded>
        <![CDATA[In the latest episode of the NVIDIA AI Podcast, host Noah Kravitz is joined by Pat Grady and Sonya Huang, partners at Sequoia Capital, to discuss their recent essay, “Generative AI: A Creative New World.”

The authors delve into the potential of generative AI to enable new forms of creativity and expression, as well as the challenges and ethical considerations of this technology. They also offer insights into the future of generative AI.

Grady and Huang emphasize the potential of generative AI to revolutionize industries such as art, design and media by allowing for the creation of unique, personalized content on a scale that would be impossible for humans to achieve alone. 

They also address the importance of considering the ethical implications of the technology, including the potential for biased or harmful outputs and the need for responsible use and regulation.

Listen to the full episode to hear more about the possibilities of generative AI and the considerations to be made as this technology moves forward.]]>
      </content:encoded>
      <itunes:duration>2564</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1416677611]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3320310554.mp3?updated=1740586357" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>UF Provost Joe Glover on Building a Leading AI University - Ep. 186</title>
      <link>https://soundcloud.com/theaipodcast/university-of-florida-ai</link>
      <description>When NVIDIA co-founder Chris Malachowsky approached University of Florida Provost Joe Glover with the offer of an AI supercomputer, he couldn't have predicted the transformative impact it would have on the university. 

In just a short time, UF has become one of the top public colleges in the US and developed a groundbreaking neural network for healthcare research.

In a recent episode of NVIDIA’s AI Podcast, host Noah Kravitz sat down with Joe Glover, provost and senior vice president of academic affairs at the University of Florida. 

The two discussed the university’s efforts to put AI to work across all aspects of higher education, including a public-private partnership with NVIDIA that has helped transform UF into one of the leading AI universities in the country.

Just a year after the partnership was unveiled in July 2020, UF rose to number five on the US News and World Report’s list of the best public colleges in the US. The ranking was, in part a recognition of UF’s vision for infusing AI into its teaching and research.

https://blogs.nvidia.com/blog/2023/01/04/university-of-florida-ai/</description>
      <pubDate>Wed, 04 Jan 2023 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cc360962-f45b-11ef-8be6-471590f718d6/image/f11d93785916297122466c228fb8f16f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>When NVIDIA co-founder Chris Malachowsky approach…</itunes:subtitle>
      <itunes:summary>When NVIDIA co-founder Chris Malachowsky approached University of Florida Provost Joe Glover with the offer of an AI supercomputer, he couldn't have predicted the transformative impact it would have on the university. 

In just a short time, UF has become one of the top public colleges in the US and developed a groundbreaking neural network for healthcare research.

In a recent episode of NVIDIA’s AI Podcast, host Noah Kravitz sat down with Joe Glover, provost and senior vice president of academic affairs at the University of Florida. 

The two discussed the university’s efforts to put AI to work across all aspects of higher education, including a public-private partnership with NVIDIA that has helped transform UF into one of the leading AI universities in the country.

Just a year after the partnership was unveiled in July 2020, UF rose to number five on the US News and World Report’s list of the best public colleges in the US. The ranking was, in part a recognition of UF’s vision for infusing AI into its teaching and research.

https://blogs.nvidia.com/blog/2023/01/04/university-of-florida-ai/</itunes:summary>
      <content:encoded>
        <![CDATA[When NVIDIA co-founder Chris Malachowsky approached University of Florida Provost Joe Glover with the offer of an AI supercomputer, he couldn't have predicted the transformative impact it would have on the university. 

In just a short time, UF has become one of the top public colleges in the US and developed a groundbreaking neural network for healthcare research.

In a recent episode of NVIDIA’s AI Podcast, host Noah Kravitz sat down with Joe Glover, provost and senior vice president of academic affairs at the University of Florida. 

The two discussed the university’s efforts to put AI to work across all aspects of higher education, including a public-private partnership with NVIDIA that has helped transform UF into one of the leading AI universities in the country.

Just a year after the partnership was unveiled in July 2020, UF rose to number five on the US News and World Report’s list of the best public colleges in the US. The ranking was, in part a recognition of UF’s vision for infusing AI into its teaching and research.

https://blogs.nvidia.com/blog/2023/01/04/university-of-florida-ai/]]>
      </content:encoded>
      <itunes:duration>1674</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1412938858]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1190617787.mp3?updated=1740586358" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Doing the Best They Can: EverestLabs Ensures Fewer Recyclables Go to Landfills - Ep. 184</title>
      <link>https://soundcloud.com/theaipodcast/everestlabs</link>
      <description>All of us recycle. Or, at least, all of us should. Now, AI is joining the effort. 

On the latest episode of the NVIDIA AI Podcast, host Noah Kravitz spoke with JD Ambati, founder and CEO of EverestLabs, developer of RecycleOS, the first AI-enabled operating system for recycling. 

The company reports that an average of 25-40% more waste is being recovered in recycling facilities around the world that use its tech.</description>
      <pubDate>Mon, 19 Dec 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cc9605ce-f45b-11ef-8be6-0f500bb3d75e/image/cf5334283d309219a9ea358bced23cb1.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>All of us recycle. Or, at least, all of us should…</itunes:subtitle>
      <itunes:summary>All of us recycle. Or, at least, all of us should. Now, AI is joining the effort. 

On the latest episode of the NVIDIA AI Podcast, host Noah Kravitz spoke with JD Ambati, founder and CEO of EverestLabs, developer of RecycleOS, the first AI-enabled operating system for recycling. 

The company reports that an average of 25-40% more waste is being recovered in recycling facilities around the world that use its tech.</itunes:summary>
      <content:encoded>
        <![CDATA[All of us recycle. Or, at least, all of us should. Now, AI is joining the effort. 

On the latest episode of the NVIDIA AI Podcast, host Noah Kravitz spoke with JD Ambati, founder and CEO of EverestLabs, developer of RecycleOS, the first AI-enabled operating system for recycling. 

The company reports that an average of 25-40% more waste is being recovered in recycling facilities around the world that use its tech.]]>
      </content:encoded>
      <itunes:duration>2252</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1397620591]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7557883582.mp3?updated=1740586359" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Hittin’ the Sim: NVIDIA’s Matt Cragun on Conditioning Autonomous Vehicles in Simulation - Ep. 185</title>
      <link>https://soundcloud.com/theaipodcast/autonomous-vehicles-simulation</link>
      <description>Training, testing and validating autonomous vehicles requires a continuous pipeline — or data factory — to introduce new scenarios and refine deep neural networks.

A key component of this process is simulation. AV developers can test a virtually limitless number of scenarios, repeatably and at scale, with high-fidelity, physically based simulation. And like much of the technology related to AI, simulation is constantly evolving and improving, getting ever nearer to closing the gap between the real and virtual worlds.

NVIDIA DRIVE Sim, built on Omniverse, provides a virtual proving ground for AV testing and validation. It’s a highly accurate simulation platform with the ability to enable groundbreaking tools, including synthetic data generation and neural reconstruction, to build digital twins of driving environments and scenarios.

Matt Cragun, senior product manager for AV simulation at NVIDIA, joined the AI Podcast to discuss the development of simulation for self-driving technology, detailing the origins and inner workings of DRIVE Sim.

He also provided a sneak peek into the frontiers researchers are exploring for this critical testing and validation technology.

https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/</description>
      <pubDate>Tue, 06 Dec 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cd1f5c2a-f45b-11ef-8be6-c7e86e15316c/image/83ee133f6ad3367b297498139d8c7134.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Training, testing and validating autonomous vehic…</itunes:subtitle>
      <itunes:summary>Training, testing and validating autonomous vehicles requires a continuous pipeline — or data factory — to introduce new scenarios and refine deep neural networks.

A key component of this process is simulation. AV developers can test a virtually limitless number of scenarios, repeatably and at scale, with high-fidelity, physically based simulation. And like much of the technology related to AI, simulation is constantly evolving and improving, getting ever nearer to closing the gap between the real and virtual worlds.

NVIDIA DRIVE Sim, built on Omniverse, provides a virtual proving ground for AV testing and validation. It’s a highly accurate simulation platform with the ability to enable groundbreaking tools, including synthetic data generation and neural reconstruction, to build digital twins of driving environments and scenarios.

Matt Cragun, senior product manager for AV simulation at NVIDIA, joined the AI Podcast to discuss the development of simulation for self-driving technology, detailing the origins and inner workings of DRIVE Sim.

He also provided a sneak peek into the frontiers researchers are exploring for this critical testing and validation technology.

https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/</itunes:summary>
      <content:encoded>
        <![CDATA[Training, testing and validating autonomous vehicles requires a continuous pipeline — or data factory — to introduce new scenarios and refine deep neural networks.

A key component of this process is simulation. AV developers can test a virtually limitless number of scenarios, repeatably and at scale, with high-fidelity, physically based simulation. And like much of the technology related to AI, simulation is constantly evolving and improving, getting ever nearer to closing the gap between the real and virtual worlds.

NVIDIA DRIVE Sim, built on Omniverse, provides a virtual proving ground for AV testing and validation. It’s a highly accurate simulation platform with the ability to enable groundbreaking tools, including synthetic data generation and neural reconstruction, to build digital twins of driving environments and scenarios.

Matt Cragun, senior product manager for AV simulation at NVIDIA, joined the AI Podcast to discuss the development of simulation for self-driving technology, detailing the origins and inner workings of DRIVE Sim.

He also provided a sneak peek into the frontiers researchers are exploring for this critical testing and validation technology.

https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/]]>
      </content:encoded>
      <itunes:duration>1753</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1392173029]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4167200124.mp3?updated=1740586359" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>WSC Sports’ Amos Bercovich on How AI Keeps the Sports Highlights Coming - Ep. 183</title>
      <link>https://soundcloud.com/theaipodcast/wsc-sports</link>
      <description>Doesn’t matter if you love hockey, basketball, or soccer. Thanks to the Internet, there's never been a better time to be a sports fan.

But how are all of these craveable video packages made? Editing together so many social media clips, long-form YouTube highlights and other videos from global sporting events is no easy feat.

That's where auto-magical video solutions help. And by auto-magical, of course, we mean AI-powered.

On this episode of the AI Podcast, host Noah Kravitz spoke with Amos Bercovich, algorithm group leader at WSC Sports, makers of an AI cloud platform that enables over 200 sports organizations worldwide to generate personalized and customized sports videos automatically and in real time.

Bercovich spoke about the technological highlights behind your favorite highlight reels.

https://blogs.nvidia.com/blog/2022/11/15/sports-highlights/</description>
      <pubDate>Tue, 15 Nov 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cd7fc7e0-f45b-11ef-8be6-9bd111d59254/image/665d7701da70f4d14ff8693763929dc7.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Doesn’t matter if you love hockey, basketball, or…</itunes:subtitle>
      <itunes:summary>Doesn’t matter if you love hockey, basketball, or soccer. Thanks to the Internet, there's never been a better time to be a sports fan.

But how are all of these craveable video packages made? Editing together so many social media clips, long-form YouTube highlights and other videos from global sporting events is no easy feat.

That's where auto-magical video solutions help. And by auto-magical, of course, we mean AI-powered.

On this episode of the AI Podcast, host Noah Kravitz spoke with Amos Bercovich, algorithm group leader at WSC Sports, makers of an AI cloud platform that enables over 200 sports organizations worldwide to generate personalized and customized sports videos automatically and in real time.

Bercovich spoke about the technological highlights behind your favorite highlight reels.

https://blogs.nvidia.com/blog/2022/11/15/sports-highlights/</itunes:summary>
      <content:encoded>
        <![CDATA[Doesn’t matter if you love hockey, basketball, or soccer. Thanks to the Internet, there's never been a better time to be a sports fan.

But how are all of these craveable video packages made? Editing together so many social media clips, long-form YouTube highlights and other videos from global sporting events is no easy feat.

That's where auto-magical video solutions help. And by auto-magical, of course, we mean AI-powered.

On this episode of the AI Podcast, host Noah Kravitz spoke with Amos Bercovich, algorithm group leader at WSC Sports, makers of an AI cloud platform that enables over 200 sports organizations worldwide to generate personalized and customized sports videos automatically and in real time.

Bercovich spoke about the technological highlights behind your favorite highlight reels.

https://blogs.nvidia.com/blog/2022/11/15/sports-highlights/]]>
      </content:encoded>
      <itunes:duration>1575</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1383245527]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9594156376.mp3?updated=1740586360" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI-Equipped Drones Could Offer Real-Time Updates on Endangered African Black Rhinos - Ep. 182</title>
      <link>https://soundcloud.com/theaipodcast/ai-zoe-jewell-alice-hua</link>
      <description>In the latest example of how researchers are using the latest technologies to track animals less invasively, a team of researchers has proposed harnessing high-flying AI-equipped drones powered to track the endangered black rhino through the wilds of Namibia.

In a paper published earlier this year in the journal PeerJ, the researchers show the potential of drone-based AI to identify animals in even the remotest areas and provide real-time updates on their status from the air.

While drones — and technology of just about every kind — have been harnessed to track African wildlife, the proposal promises to help gamekeepers move faster to protect rhinos and other megafauna from poachers.

AI Podcast host Noah Kravitz spoke to two of the authors of the paper. 

Zoey Jewel is co founder and president of wild track.org, a global network of biologists and conservationists dedicated to non invasive wildlife monitoring techniques. And Alice Hua is a recent graduate of the School of Information at UC Berkeley in California, and an ML platform engineer at CrowdStrike. 

And for more, read the full paper at https://peerj.com/articles/13779/.</description>
      <pubDate>Sat, 05 Nov 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cddc64d2-f45b-11ef-8be6-8fa274392987/image/801637e863e38b6b06eaa4a77e931503.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the latest example of how researchers are usin…</itunes:subtitle>
      <itunes:summary>In the latest example of how researchers are using the latest technologies to track animals less invasively, a team of researchers has proposed harnessing high-flying AI-equipped drones powered to track the endangered black rhino through the wilds of Namibia.

In a paper published earlier this year in the journal PeerJ, the researchers show the potential of drone-based AI to identify animals in even the remotest areas and provide real-time updates on their status from the air.

While drones — and technology of just about every kind — have been harnessed to track African wildlife, the proposal promises to help gamekeepers move faster to protect rhinos and other megafauna from poachers.

AI Podcast host Noah Kravitz spoke to two of the authors of the paper. 

Zoey Jewel is co founder and president of wild track.org, a global network of biologists and conservationists dedicated to non invasive wildlife monitoring techniques. And Alice Hua is a recent graduate of the School of Information at UC Berkeley in California, and an ML platform engineer at CrowdStrike. 

And for more, read the full paper at https://peerj.com/articles/13779/.</itunes:summary>
      <content:encoded>
        <![CDATA[In the latest example of how researchers are using the latest technologies to track animals less invasively, a team of researchers has proposed harnessing high-flying AI-equipped drones powered to track the endangered black rhino through the wilds of Namibia.

In a paper published earlier this year in the journal PeerJ, the researchers show the potential of drone-based AI to identify animals in even the remotest areas and provide real-time updates on their status from the air.

While drones — and technology of just about every kind — have been harnessed to track African wildlife, the proposal promises to help gamekeepers move faster to protect rhinos and other megafauna from poachers.

AI Podcast host Noah Kravitz spoke to two of the authors of the paper. 

Zoey Jewel is co founder and president of wild track.org, a global network of biologists and conservationists dedicated to non invasive wildlife monitoring techniques. And Alice Hua is a recent graduate of the School of Information at UC Berkeley in California, and an ML platform engineer at CrowdStrike. 

And for more, read the full paper at https://peerj.com/articles/13779/.]]>
      </content:encoded>
      <itunes:duration>1634</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1373296717]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1762810954.mp3?updated=1740586360" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Tarteel Uses AI to Help Arabic Learners Perfect Their Pronunciation - Ep. 181</title>
      <link>https://soundcloud.com/theaipodcast/tarteel-ai</link>
      <description>There are some 1.8 billion Muslims, but only 16% or so of them speak Arabic, the language of the Quran. 

This is in part due to the fact that many Muslims struggle to find qualified instructors to give them feedback on their Quran recitation.
Enter today’s guest and his company Tarteel, a member of the NVIDIA Inception program for startups. 

Tarteel was founded with the mission of strengthening the relationship Muslims have with the Quran. 

The company is accomplishing this with a fusion of Islamic principles and cutting-edge technology. 

AI Podcast host Noah Kravitz spoke with Tarteel CEO Anas Abou Allaban, to learn more.</description>
      <pubDate>Thu, 20 Oct 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ce3909f8-f45b-11ef-8be6-5ba6494047a1/image/cb36c6233c03ffcdf1a69c4d27a5c667.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>There are some 1.8 billion Muslims, but only 16% …</itunes:subtitle>
      <itunes:summary>There are some 1.8 billion Muslims, but only 16% or so of them speak Arabic, the language of the Quran. 

This is in part due to the fact that many Muslims struggle to find qualified instructors to give them feedback on their Quran recitation.
Enter today’s guest and his company Tarteel, a member of the NVIDIA Inception program for startups. 

Tarteel was founded with the mission of strengthening the relationship Muslims have with the Quran. 

The company is accomplishing this with a fusion of Islamic principles and cutting-edge technology. 

AI Podcast host Noah Kravitz spoke with Tarteel CEO Anas Abou Allaban, to learn more.</itunes:summary>
      <content:encoded>
        <![CDATA[There are some 1.8 billion Muslims, but only 16% or so of them speak Arabic, the language of the Quran. 

This is in part due to the fact that many Muslims struggle to find qualified instructors to give them feedback on their Quran recitation.
Enter today’s guest and his company Tarteel, a member of the NVIDIA Inception program for startups. 

Tarteel was founded with the mission of strengthening the relationship Muslims have with the Quran. 

The company is accomplishing this with a fusion of Islamic principles and cutting-edge technology. 

AI Podcast host Noah Kravitz spoke with Tarteel CEO Anas Abou Allaban, to learn more.]]>
      </content:encoded>
      <itunes:duration>1778</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1365975223]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2918733966.mp3?updated=1740586361" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Researchers Use AI to Help Earbud Users Mute Background Noise - Ep. 180</title>
      <link>https://soundcloud.com/theaipodcast/ai-clearbuds</link>
      <description>Thanks to earbuds, people can take calls anywhere, while doing anything. The problem: those on the other end of the call can hear all the background noise, too, whether it’s the roommate’s vacuum cleaner or neighboring conversations at a café.

Now, work by a trio of graduate students at the University of Washington, who spent the pandemic cooped up together in a noisy apartment, lets those on the other end of the call hear just the speaker — rather than all the surrounding sounds.

Users found that the system, dubbed “ClearBuds” — presented last month at the ACM International Conference on Mobile Systems, Applications and Services — improved background noise suppression much better than a commercially available alternative.

AI Podcast host Noah Kravitz caught up with the team at ClearBuds to discuss the unlikely pandemic-time origin story behind a technology that promises to make calls clearer and easier, wherever we go.</description>
      <pubDate>Sun, 02 Oct 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ce9414b0-f45b-11ef-8be6-9b333f45e67f/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Thanks to earbuds, people can take calls anywhere…</itunes:subtitle>
      <itunes:summary>Thanks to earbuds, people can take calls anywhere, while doing anything. The problem: those on the other end of the call can hear all the background noise, too, whether it’s the roommate’s vacuum cleaner or neighboring conversations at a café.

Now, work by a trio of graduate students at the University of Washington, who spent the pandemic cooped up together in a noisy apartment, lets those on the other end of the call hear just the speaker — rather than all the surrounding sounds.

Users found that the system, dubbed “ClearBuds” — presented last month at the ACM International Conference on Mobile Systems, Applications and Services — improved background noise suppression much better than a commercially available alternative.

AI Podcast host Noah Kravitz caught up with the team at ClearBuds to discuss the unlikely pandemic-time origin story behind a technology that promises to make calls clearer and easier, wherever we go.</itunes:summary>
      <content:encoded>
        <![CDATA[Thanks to earbuds, people can take calls anywhere, while doing anything. The problem: those on the other end of the call can hear all the background noise, too, whether it’s the roommate’s vacuum cleaner or neighboring conversations at a café.

Now, work by a trio of graduate students at the University of Washington, who spent the pandemic cooped up together in a noisy apartment, lets those on the other end of the call hear just the speaker — rather than all the surrounding sounds.

Users found that the system, dubbed “ClearBuds” — presented last month at the ACM International Conference on Mobile Systems, Applications and Services — improved background noise suppression much better than a commercially available alternative.

AI Podcast host Noah Kravitz caught up with the team at ClearBuds to discuss the unlikely pandemic-time origin story behind a technology that promises to make calls clearer and easier, wherever we go.]]>
      </content:encoded>
      <itunes:duration>1901</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1356146131]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9816455771.mp3?updated=1740586362" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Overjet's Ai Wardah Inam on Bringing AI to Dentistry - Ep. 179</title>
      <link>https://soundcloud.com/theaipodcast/ai-overjet</link>
      <description>Dentists get a bad rap. Dentists also get more people out of more aggravating pain than just about anyone.

Which is why the more technology dentists have, the better. 

Overjet, a member of the NVIDIA Inception program for startups, is moving fast to bring AI to dentists’ offices. 

On this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Dr. Wardah Inam, CEO of Overjet, about how her company uses AI to improve patient care. 

Overjet’s AI-powered technology analyzes and annotates X-rays for dentists and insurance providers. 

It’s a step that promises to take the subjectivity out of X-ray interpretations, boosting medical services.</description>
      <pubDate>Tue, 20 Sep 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cef0f5ea-f45b-11ef-8be6-93ed9380194b/image/93897b8f58cdfc1f889b4bda46a0d84b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Dentists get a bad rap. Dentists also get more pe…</itunes:subtitle>
      <itunes:summary>Dentists get a bad rap. Dentists also get more people out of more aggravating pain than just about anyone.

Which is why the more technology dentists have, the better. 

Overjet, a member of the NVIDIA Inception program for startups, is moving fast to bring AI to dentists’ offices. 

On this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Dr. Wardah Inam, CEO of Overjet, about how her company uses AI to improve patient care. 

Overjet’s AI-powered technology analyzes and annotates X-rays for dentists and insurance providers. 

It’s a step that promises to take the subjectivity out of X-ray interpretations, boosting medical services.</itunes:summary>
      <content:encoded>
        <![CDATA[Dentists get a bad rap. Dentists also get more people out of more aggravating pain than just about anyone.

Which is why the more technology dentists have, the better. 

Overjet, a member of the NVIDIA Inception program for startups, is moving fast to bring AI to dentists’ offices. 

On this episode of the NVIDIA AI Podcast, host Noah Kravitz talks to Dr. Wardah Inam, CEO of Overjet, about how her company uses AI to improve patient care. 

Overjet’s AI-powered technology analyzes and annotates X-rays for dentists and insurance providers. 

It’s a step that promises to take the subjectivity out of X-ray interpretations, boosting medical services.]]>
      </content:encoded>
      <itunes:duration>1693</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1336626109]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7559783465.mp3?updated=1740586362" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Reinventing the Wheel: Gatik’s Apeksha Kumavat Accelerates Autonomous Delivery - Ep. 178</title>
      <link>https://soundcloud.com/theaipodcast/ai-gatik</link>
      <description>As consumers expect faster, cheaper deliveries, companies are turning to AI to rethink how they move goods. 

Foremost among these new systems are “hub-and-spoke,” or middle-mile, operations, where companies place distribution centers closer to retail operations for quicker access to inventory. However, faster delivery is just part of the equation. These systems must also be low cost for consumers.

Autonomous delivery company Gatik seeks to provide lasting solutions for faster and cheaper shipping. By automating the routes between the hub — the distribution center — and the spokes — retail stores — these operations can run around the clock efficiently and with minimal investment.

Gatik co-founder and Chief Engineer Apeksha Kumavat joined NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to walk through how the company is developing autonomous trucks for middle-mile delivery.

https://blogs.nvidia.com/blog/2022/09/14/gatik-podcast/</description>
      <pubDate>Wed, 14 Sep 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cf4b3334-f45b-11ef-8be6-379ff731c1d0/image/14a928d2dafdaf0b5e830b7e0c2afc8f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>As consumers expect faster, cheaper deliveries, c…</itunes:subtitle>
      <itunes:summary>As consumers expect faster, cheaper deliveries, companies are turning to AI to rethink how they move goods. 

Foremost among these new systems are “hub-and-spoke,” or middle-mile, operations, where companies place distribution centers closer to retail operations for quicker access to inventory. However, faster delivery is just part of the equation. These systems must also be low cost for consumers.

Autonomous delivery company Gatik seeks to provide lasting solutions for faster and cheaper shipping. By automating the routes between the hub — the distribution center — and the spokes — retail stores — these operations can run around the clock efficiently and with minimal investment.

Gatik co-founder and Chief Engineer Apeksha Kumavat joined NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to walk through how the company is developing autonomous trucks for middle-mile delivery.

https://blogs.nvidia.com/blog/2022/09/14/gatik-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[As consumers expect faster, cheaper deliveries, companies are turning to AI to rethink how they move goods. 

Foremost among these new systems are “hub-and-spoke,” or middle-mile, operations, where companies place distribution centers closer to retail operations for quicker access to inventory. However, faster delivery is just part of the equation. These systems must also be low cost for consumers.

Autonomous delivery company Gatik seeks to provide lasting solutions for faster and cheaper shipping. By automating the routes between the hub — the distribution center — and the spokes — retail stores — these operations can run around the clock efficiently and with minimal investment.

Gatik co-founder and Chief Engineer Apeksha Kumavat joined NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to walk through how the company is developing autonomous trucks for middle-mile delivery.

https://blogs.nvidia.com/blog/2022/09/14/gatik-podcast/]]>
      </content:encoded>
      <itunes:duration>1950</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1342943932]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4076789545.mp3?updated=1740586363" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Rendered.ai CEO Nathan Kundtz on Using AI to Build Better AI - Ep. 177</title>
      <link>https://soundcloud.com/theaipodcast/renderedai</link>
      <description>Data is the fuel that makes artificial intelligence run. 

Training machine learning and AI systems requires data. And the quality of datasets has a big impact on the systems’ results. 

But compiling quality real-world data for AI and ML can be difficult and expensive. 

That’s where synthetic data comes in. 

The guest for this week’s AI Podcast episode, Nathan Kundtz, is founder and CEO of Rendered.ai, a platform as a service for creating synthetic data to train AI models. The company is also a member of NVIDIA Inception, a free, global program that nurtures cutting-edge startups.

https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/</description>
      <pubDate>Wed, 31 Aug 2022 13:00:09 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/cfa58f78-f45b-11ef-8be6-af5c129d076e/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Data is the fuel that makes artificial intelligen…</itunes:subtitle>
      <itunes:summary>Data is the fuel that makes artificial intelligence run. 

Training machine learning and AI systems requires data. And the quality of datasets has a big impact on the systems’ results. 

But compiling quality real-world data for AI and ML can be difficult and expensive. 

That’s where synthetic data comes in. 

The guest for this week’s AI Podcast episode, Nathan Kundtz, is founder and CEO of Rendered.ai, a platform as a service for creating synthetic data to train AI models. The company is also a member of NVIDIA Inception, a free, global program that nurtures cutting-edge startups.

https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/</itunes:summary>
      <content:encoded>
        <![CDATA[Data is the fuel that makes artificial intelligence run. 

Training machine learning and AI systems requires data. And the quality of datasets has a big impact on the systems’ results. 

But compiling quality real-world data for AI and ML can be difficult and expensive. 

That’s where synthetic data comes in. 

The guest for this week’s AI Podcast episode, Nathan Kundtz, is founder and CEO of Rendered.ai, a platform as a service for creating synthetic data to train AI models. The company is also a member of NVIDIA Inception, a free, global program that nurtures cutting-edge startups.

https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/]]>
      </content:encoded>
      <itunes:duration>1878</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1326089404]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6102804457.mp3?updated=1740586363" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Clément Farabet on Orchestrating AI Training for Autonomous Vehicles - Ep. 175</title>
      <link>https://soundcloud.com/theaipodcast/nvidia-clement-farabet-ai-training-av</link>
      <description>Autonomous vehicles are one of the most complex AI challenges of our time. The networks running in the car must act as an intricate symphony, requiring intensive training, testing and validation on massive amounts of data to operate safely in the real world.

Clément Farabet is the Vice President of AI Infrastructure at NVIDIA, and is the proverbial maestro behind the AV development orchestra. He’s applying nearly 15 years of experience in deep learning — including building Twitter’s AI machine — to teach neural networks how to perceive and react to the world around them.

Farabet sat down with NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to discuss how the early days of deep learning led to today’s flourishing AV industry, and how he’s approaching DNN development.

Tapping into the performance of the NVIDIA SaturnV supercomputer, Farabet is designing a highly scalable data factory to deliver intelligent transportation in the near term, and is looking ahead to the next frontiers in AI.</description>
      <pubDate>Tue, 02 Aug 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d000af8e-f45b-11ef-8be6-4b2d7ce77b8b/image/b1def6bb945d944bb8cf9881b15f8beb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Autonomous vehicles are one of the most complex A…</itunes:subtitle>
      <itunes:summary>Autonomous vehicles are one of the most complex AI challenges of our time. The networks running in the car must act as an intricate symphony, requiring intensive training, testing and validation on massive amounts of data to operate safely in the real world.

Clément Farabet is the Vice President of AI Infrastructure at NVIDIA, and is the proverbial maestro behind the AV development orchestra. He’s applying nearly 15 years of experience in deep learning — including building Twitter’s AI machine — to teach neural networks how to perceive and react to the world around them.

Farabet sat down with NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to discuss how the early days of deep learning led to today’s flourishing AV industry, and how he’s approaching DNN development.

Tapping into the performance of the NVIDIA SaturnV supercomputer, Farabet is designing a highly scalable data factory to deliver intelligent transportation in the near term, and is looking ahead to the next frontiers in AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Autonomous vehicles are one of the most complex AI challenges of our time. The networks running in the car must act as an intricate symphony, requiring intensive training, testing and validation on massive amounts of data to operate safely in the real world.

Clément Farabet is the Vice President of AI Infrastructure at NVIDIA, and is the proverbial maestro behind the AV development orchestra. He’s applying nearly 15 years of experience in deep learning — including building Twitter’s AI machine — to teach neural networks how to perceive and react to the world around them.

Farabet sat down with NVIDIA’s Katie Burke Washabaugh on the latest episode of the AI Podcast to discuss how the early days of deep learning led to today’s flourishing AV industry, and how he’s approaching DNN development.

Tapping into the performance of the NVIDIA SaturnV supercomputer, Farabet is designing a highly scalable data factory to deliver intelligent transportation in the near term, and is looking ahead to the next frontiers in AI.]]>
      </content:encoded>
      <itunes:duration>1776</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1316650894]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9404582027.mp3?updated=1740586364" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Immunai CTO and Co-Founder Luis Voloch on Using Deep Learning to Develop New Drugs - Ep. 176</title>
      <link>https://soundcloud.com/theaipodcast/ai-luis-voloch</link>
      <description>What if we could map our immune system to create drugs that can help our bodies win the fight against cancer and other diseases? That’s the big idea behind immunotherapy. The problem: the immune system is incredibly complex. 

Enter Immunai, a biotechnology company that’s using AI technology to map the human immune system and speed the development of new immunotherapies against cancer and autoimmune diseases.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Luis Voloch, CTO and Co-Founder of Immunai, about tackling the challenges of the immune system with a machine learning and data science mindset.</description>
      <pubDate>Sun, 31 Jul 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d05b18e8-f45b-11ef-8be6-7b1a6fc2f43a/image/6780266ed30b66cf4e8ef3b4ad8eb538.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>What if we could map our immune system to create …</itunes:subtitle>
      <itunes:summary>What if we could map our immune system to create drugs that can help our bodies win the fight against cancer and other diseases? That’s the big idea behind immunotherapy. The problem: the immune system is incredibly complex. 

Enter Immunai, a biotechnology company that’s using AI technology to map the human immune system and speed the development of new immunotherapies against cancer and autoimmune diseases.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Luis Voloch, CTO and Co-Founder of Immunai, about tackling the challenges of the immune system with a machine learning and data science mindset.</itunes:summary>
      <content:encoded>
        <![CDATA[What if we could map our immune system to create drugs that can help our bodies win the fight against cancer and other diseases? That’s the big idea behind immunotherapy. The problem: the immune system is incredibly complex. 

Enter Immunai, a biotechnology company that’s using AI technology to map the human immune system and speed the development of new immunotherapies against cancer and autoimmune diseases.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Luis Voloch, CTO and Co-Founder of Immunai, about tackling the challenges of the immune system with a machine learning and data science mindset.]]>
      </content:encoded>
      <itunes:duration>1672</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1310110849]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2880380085.mp3?updated=1740586365" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Lucid Motors’ Mike Bell on Software-Defined Innovation - Ep. 174</title>
      <link>https://soundcloud.com/theaipodcast/lucid-motors-mike-bell-on-software-defined-innovation-ep-173</link>
      <description>AI and electric vehicle technology breakthroughs are transforming the automotive industry. These developments pave the way for new innovators, attracting technical prowess and design philosophies from Silicon Valley.

Mike Bell, senior vice president of digital at Lucid Motors, sees continuous innovation coupled with over-the-air updates as key to designing sustainable, award-winning intelligent vehicles that provide seamless automated driving experiences.

NVIDIA’s Katie Burke Washabaugh spoke with Bell on the latest AI Podcast episode, covering what it takes to stay ahead in the software-defined vehicle space.

Bell touched on future technology and its implications for the mass adoption of sustainable, AI-powered EVs — as well as what Lucid’s Silicon Valley roots bring to the intersection of innovation and transportation.

https://blogs.nvidia.com/blog/2022/07/06/lucid-motors-podcast/</description>
      <pubDate>Wed, 20 Jul 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d0b5ce00-f45b-11ef-8be6-03210c726d0d/image/38dab8b818598e3e1655fe0c98722bfb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI and electric vehicle technology breakthroughs …</itunes:subtitle>
      <itunes:summary>AI and electric vehicle technology breakthroughs are transforming the automotive industry. These developments pave the way for new innovators, attracting technical prowess and design philosophies from Silicon Valley.

Mike Bell, senior vice president of digital at Lucid Motors, sees continuous innovation coupled with over-the-air updates as key to designing sustainable, award-winning intelligent vehicles that provide seamless automated driving experiences.

NVIDIA’s Katie Burke Washabaugh spoke with Bell on the latest AI Podcast episode, covering what it takes to stay ahead in the software-defined vehicle space.

Bell touched on future technology and its implications for the mass adoption of sustainable, AI-powered EVs — as well as what Lucid’s Silicon Valley roots bring to the intersection of innovation and transportation.

https://blogs.nvidia.com/blog/2022/07/06/lucid-motors-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[AI and electric vehicle technology breakthroughs are transforming the automotive industry. These developments pave the way for new innovators, attracting technical prowess and design philosophies from Silicon Valley.

Mike Bell, senior vice president of digital at Lucid Motors, sees continuous innovation coupled with over-the-air updates as key to designing sustainable, award-winning intelligent vehicles that provide seamless automated driving experiences.

NVIDIA’s Katie Burke Washabaugh spoke with Bell on the latest AI Podcast episode, covering what it takes to stay ahead in the software-defined vehicle space.

Bell touched on future technology and its implications for the mass adoption of sustainable, AI-powered EVs — as well as what Lucid’s Silicon Valley roots bring to the intersection of innovation and transportation.

https://blogs.nvidia.com/blog/2022/07/06/lucid-motors-podcast/]]>
      </content:encoded>
      <itunes:duration>1093</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1300294819]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3155946696.mp3?updated=1740586365" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Santiago Valderrama on Getting Smarter on Machine Learning, One Problem at a Time - Ep. 173</title>
      <link>https://soundcloud.com/theaipodcast/ai-santiago-valdarrama</link>
      <description>Want to learn about AI and machine learning? There are plenty of resources out there to help — blogs, podcasts, YouTube tutorials — perhaps too many. Machine learning engineer Santiago Valdarrama has taken a far more focused approach to helping us all get smarter about the field. He’s created a following by posing one machine learning question every day on his website bnomial.com. Think of it as Wordle for those who want to learn more about machine learning.</description>
      <pubDate>Wed, 06 Jul 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d110c0d0-f45b-11ef-8be6-5f24f2ac2feb/image/1a20aad6460ae854c9ef270020bd0bc5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Want to learn about AI and machine learning? Ther…</itunes:subtitle>
      <itunes:summary>Want to learn about AI and machine learning? There are plenty of resources out there to help — blogs, podcasts, YouTube tutorials — perhaps too many. Machine learning engineer Santiago Valdarrama has taken a far more focused approach to helping us all get smarter about the field. He’s created a following by posing one machine learning question every day on his website bnomial.com. Think of it as Wordle for those who want to learn more about machine learning.</itunes:summary>
      <content:encoded>
        <![CDATA[Want to learn about AI and machine learning? There are plenty of resources out there to help — blogs, podcasts, YouTube tutorials — perhaps too many. Machine learning engineer Santiago Valdarrama has taken a far more focused approach to helping us all get smarter about the field. He’s created a following by posing one machine learning question every day on his website bnomial.com. Think of it as Wordle for those who want to learn more about machine learning.]]>
      </content:encoded>
      <itunes:duration>1635</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1300758916]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6869490475.mp3?updated=1740586366" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Artem Cherkasov and Olexandr Isayev on Democratizing Drug Discovery with Deep Learning - Ep. 172</title>
      <link>https://soundcloud.com/theaipodcast/ai-drug-discovery</link>
      <description>It may seem intuitive that AI and deep learning can speed up workflows — including novel drug discovery, a typically years-long and several-billion-dollar endeavor.

But professors Artem Cherkasov and Olexandr Isayev were surprised to find that no recent academic papers provided a comprehensive, global research review of how deep learning and GPU-accelerated computing impact drug discovery.

In March, they published a paper in Nature to fill this gap, presenting an up-to-date review of the state of the art for GPU-accelerated drug discovery techniques. 

Cherkasov, a professor in the department of urologic sciences at the University of British Columbia, and Isayev, an assistant professor of chemistry at Carnegie Mellon University, join NVIDIA AI Podcast host Noah Kravitz this week to discuss how GPUs can help democratize drug discovery.

In addition, the guests cover their inspiration and process for writing the paper, talk about NVIDIA technologies that are transforming the role of AI in drug discovery, and give tips for adopting new approaches to research.</description>
      <pubDate>Wed, 22 Jun 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d16da6c4-f45b-11ef-8be6-6b6e1642eb39/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>It may seem intuitive that AI and deep learning c…</itunes:subtitle>
      <itunes:summary>It may seem intuitive that AI and deep learning can speed up workflows — including novel drug discovery, a typically years-long and several-billion-dollar endeavor.

But professors Artem Cherkasov and Olexandr Isayev were surprised to find that no recent academic papers provided a comprehensive, global research review of how deep learning and GPU-accelerated computing impact drug discovery.

In March, they published a paper in Nature to fill this gap, presenting an up-to-date review of the state of the art for GPU-accelerated drug discovery techniques. 

Cherkasov, a professor in the department of urologic sciences at the University of British Columbia, and Isayev, an assistant professor of chemistry at Carnegie Mellon University, join NVIDIA AI Podcast host Noah Kravitz this week to discuss how GPUs can help democratize drug discovery.

In addition, the guests cover their inspiration and process for writing the paper, talk about NVIDIA technologies that are transforming the role of AI in drug discovery, and give tips for adopting new approaches to research.</itunes:summary>
      <content:encoded>
        <![CDATA[It may seem intuitive that AI and deep learning can speed up workflows — including novel drug discovery, a typically years-long and several-billion-dollar endeavor.

But professors Artem Cherkasov and Olexandr Isayev were surprised to find that no recent academic papers provided a comprehensive, global research review of how deep learning and GPU-accelerated computing impact drug discovery.

In March, they published a paper in Nature to fill this gap, presenting an up-to-date review of the state of the art for GPU-accelerated drug discovery techniques. 

Cherkasov, a professor in the department of urologic sciences at the University of British Columbia, and Isayev, an assistant professor of chemistry at Carnegie Mellon University, join NVIDIA AI Podcast host Noah Kravitz this week to discuss how GPUs can help democratize drug discovery.

In addition, the guests cover their inspiration and process for writing the paper, talk about NVIDIA technologies that are transforming the role of AI in drug discovery, and give tips for adopting new approaches to research.]]>
      </content:encoded>
      <itunes:duration>1685</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1291324111]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5816241500.mp3?updated=1740586366" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Astrophysicist Brant Robertson Using AI to Glean Insights from James Webb Space Telescope - Ep. 171</title>
      <link>https://soundcloud.com/theaipodcast/scientists-turn-to-ai-to-glean-insights-from-nasas-james-webb-space-telescope</link>
      <description>On July 12 NASA will release the first science data – including the first science-quality images - from the $10 billion James Webb Space Telescope. The images are sure to be stunning, and guaranteed to make headlines around the world. AI Podcast Host Noah Kravitz spoke with UC Santa Cruz's Brant Robertson, a professor of astrophysics and astronomy, about the data science behind one of the biggest science stories of our time. 

https://blogs.nvidia.com/blog/2022/06/08/deep-learning-james-webb-space-telescope/</description>
      <pubDate>Wed, 08 Jun 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d1cbec2a-f45b-11ef-8be6-4b6d90ba5404/image/18b803e2bcafbb68971ec096bd245ab2.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>On July 12 NASA will release the first science da…</itunes:subtitle>
      <itunes:summary>On July 12 NASA will release the first science data – including the first science-quality images - from the $10 billion James Webb Space Telescope. The images are sure to be stunning, and guaranteed to make headlines around the world. AI Podcast Host Noah Kravitz spoke with UC Santa Cruz's Brant Robertson, a professor of astrophysics and astronomy, about the data science behind one of the biggest science stories of our time. 

https://blogs.nvidia.com/blog/2022/06/08/deep-learning-james-webb-space-telescope/</itunes:summary>
      <content:encoded>
        <![CDATA[On July 12 NASA will release the first science data – including the first science-quality images - from the $10 billion James Webb Space Telescope. The images are sure to be stunning, and guaranteed to make headlines around the world. AI Podcast Host Noah Kravitz spoke with UC Santa Cruz's Brant Robertson, a professor of astrophysics and astronomy, about the data science behind one of the biggest science stories of our time. 

https://blogs.nvidia.com/blog/2022/06/08/deep-learning-james-webb-space-telescope/]]>
      </content:encoded>
      <itunes:duration>2151</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1280705689]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2140945088.mp3?updated=1740586367" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Hume AI’s Alan Cowen on Building AIs With a Devotion to Emotion - Ep. 170</title>
      <link>https://soundcloud.com/theaipodcast/alan-cowen</link>
      <description>Can machines experience emotions? They might, according to Hume AI, an AI research lab and technology company that aims to “ensure artificial intelligence is built to serve human goals and emotional well-being.” 

So how can AI genuinely understand how we are feeling, and respond appropriately?

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Alan Cowen, founder of Hume AI and The Hume Initiative. Cowen — a former researcher at Google who holds a Ph.D. in Psychology from UC Berkeley — talks about the latest work at the intersection of computing and human emotion.</description>
      <pubDate>Thu, 26 May 2022 13:00:20 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d227ef98-f45b-11ef-8be6-8763e798cff2/image/9060940b1ef9d8cd3c1b59cf128f16ec.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Can machines experience emotions? They might, acc…</itunes:subtitle>
      <itunes:summary>Can machines experience emotions? They might, according to Hume AI, an AI research lab and technology company that aims to “ensure artificial intelligence is built to serve human goals and emotional well-being.” 

So how can AI genuinely understand how we are feeling, and respond appropriately?

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Alan Cowen, founder of Hume AI and The Hume Initiative. Cowen — a former researcher at Google who holds a Ph.D. in Psychology from UC Berkeley — talks about the latest work at the intersection of computing and human emotion.</itunes:summary>
      <content:encoded>
        <![CDATA[Can machines experience emotions? They might, according to Hume AI, an AI research lab and technology company that aims to “ensure artificial intelligence is built to serve human goals and emotional well-being.” 

So how can AI genuinely understand how we are feeling, and respond appropriately?

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Alan Cowen, founder of Hume AI and The Hume Initiative. Cowen — a former researcher at Google who holds a Ph.D. in Psychology from UC Berkeley — talks about the latest work at the intersection of computing and human emotion.]]>
      </content:encoded>
      <itunes:duration>2849</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1275209080]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7231365087.mp3?updated=1740586368" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Waabi CEO Raquel Urtasun on Using AI, Simulation to Teach Autonomous Vehicles to Drive - Ep. 169</title>
      <link>https://soundcloud.com/theaipodcast/ai-raquel-urtasun</link>
      <description>Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience. The road to achieving this astronomical level of driving leads to the virtual world.

On the latest episode of the AI Podcast, Waabi CEO and founder Raquel Urtasun joins NVIDIA’s Katie Burke Washabaugh to talk about the role simulation technology plays in developing production-level autonomous vehicles. 

Waabi is an autonomous-vehicle system startup that uses powerful, high-fidelity simulation to run multiple scenarios simultaneously and tailor training to rare and dangerous situations that are difficult to encounter in the real world.

Urtasun is also a professor of Computer Science at the University of Toronto. Before starting Waabi, she led the Uber Advanced Technologies Group as chief scientist and head of research and development.</description>
      <pubDate>Thu, 05 May 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d283208e-f45b-11ef-8be6-6f2f22cb48b2/image/3aa95c1e9abc5f925a23163969a20ba5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Teaching the AI brains of autonomous vehicles to …</itunes:subtitle>
      <itunes:summary>Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience. The road to achieving this astronomical level of driving leads to the virtual world.

On the latest episode of the AI Podcast, Waabi CEO and founder Raquel Urtasun joins NVIDIA’s Katie Burke Washabaugh to talk about the role simulation technology plays in developing production-level autonomous vehicles. 

Waabi is an autonomous-vehicle system startup that uses powerful, high-fidelity simulation to run multiple scenarios simultaneously and tailor training to rare and dangerous situations that are difficult to encounter in the real world.

Urtasun is also a professor of Computer Science at the University of Toronto. Before starting Waabi, she led the Uber Advanced Technologies Group as chief scientist and head of research and development.</itunes:summary>
      <content:encoded>
        <![CDATA[Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience. The road to achieving this astronomical level of driving leads to the virtual world.

On the latest episode of the AI Podcast, Waabi CEO and founder Raquel Urtasun joins NVIDIA’s Katie Burke Washabaugh to talk about the role simulation technology plays in developing production-level autonomous vehicles. 

Waabi is an autonomous-vehicle system startup that uses powerful, high-fidelity simulation to run multiple scenarios simultaneously and tailor training to rare and dangerous situations that are difficult to encounter in the real world.

Urtasun is also a professor of Computer Science at the University of Toronto. Before starting Waabi, she led the Uber Advanced Technologies Group as chief scientist and head of research and development.]]>
      </content:encoded>
      <itunes:duration>1339</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1262573350]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2259175973.mp3?updated=1740586368" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>What Is Conversational AI? ZeroShot Bot CEO Jason Mars Explains - Ep. 168</title>
      <link>https://soundcloud.com/theaipodcast/what-is-conversational-ai-zeroshot-bot-ceo-jason-mars-explains</link>
      <description>Entrepreneur Jason Mars calls conversation our “first technology.” 

Before humans invented the wheel, crafted a spear or tamed fire, we mastered the superpower of talking to one another. 

That makes conversation an incredibly important tool. 

But if you’ve dealt with the automated chatbots deployed by the customer service arms of just about any big organization lately — whether banks or airlines — you also know how hard it can be to get it right. 

Deep learning AI and new techniques such as zero-shot learning promise to change that. 

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz — whose intelligence is anything but artificial — spoke with Mars about how the latest AI techniques intersect with the very ancient art of conversation. 

In addition to being an entrepreneur and CEO of several startups, including Zero Shot Bot, Mars is an associate professor of computer science at the University of Michigan and the author of “Breaking Bots: Inventing a New Voice in the AI Revolution” (ForbesBooks, 2021).</description>
      <pubDate>Wed, 27 Apr 2022 13:00:11 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d2df9de6-f45b-11ef-8be6-dbb0682b7920/image/bb13825dc550f1de84e1a0e50cf7847a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Entrepreneur Jason Mars calls conversation our “f…</itunes:subtitle>
      <itunes:summary>Entrepreneur Jason Mars calls conversation our “first technology.” 

Before humans invented the wheel, crafted a spear or tamed fire, we mastered the superpower of talking to one another. 

That makes conversation an incredibly important tool. 

But if you’ve dealt with the automated chatbots deployed by the customer service arms of just about any big organization lately — whether banks or airlines — you also know how hard it can be to get it right. 

Deep learning AI and new techniques such as zero-shot learning promise to change that. 

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz — whose intelligence is anything but artificial — spoke with Mars about how the latest AI techniques intersect with the very ancient art of conversation. 

In addition to being an entrepreneur and CEO of several startups, including Zero Shot Bot, Mars is an associate professor of computer science at the University of Michigan and the author of “Breaking Bots: Inventing a New Voice in the AI Revolution” (ForbesBooks, 2021).</itunes:summary>
      <content:encoded>
        <![CDATA[Entrepreneur Jason Mars calls conversation our “first technology.” 

Before humans invented the wheel, crafted a spear or tamed fire, we mastered the superpower of talking to one another. 

That makes conversation an incredibly important tool. 

But if you’ve dealt with the automated chatbots deployed by the customer service arms of just about any big organization lately — whether banks or airlines — you also know how hard it can be to get it right. 

Deep learning AI and new techniques such as zero-shot learning promise to change that. 

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz — whose intelligence is anything but artificial — spoke with Mars about how the latest AI techniques intersect with the very ancient art of conversation. 

In addition to being an entrepreneur and CEO of several startups, including Zero Shot Bot, Mars is an associate professor of computer science at the University of Michigan and the author of “Breaking Bots: Inventing a New Voice in the AI Revolution” (ForbesBooks, 2021).]]>
      </content:encoded>
      <itunes:duration>2305</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1256968012]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4864275038.mp3?updated=1740586369" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>MLCommons’ David Kanter, NVIDIA’s Daniel Galvez on Publicly Accessible Datasets - Ep. 167</title>
      <link>https://soundcloud.com/theaipodcast/mlcommons</link>
      <description>In deep learning and machine learning, having a large enough dataset is key to training a system and getting it to produce results.

So what does a ML researcher do when there just isn’t enough publicly accessible data?

Enter the MLCommons Association, a global engineering consortium with the aim of making ML better for everyone.

MLCommons recently announced the general availability of the People’s Speech Dataset, a 30,000 hour English-language conversational speech dataset, and the Multilingual Spoken Words Corpus, an audio speech dataset with over 340,000 keywords in 50 languages, to help advance ML research.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with David Kanter, founder and executive director of MLCommons, and NVIDIA senior AI developer technology engineer Daniel Galvez, about the democratization of access to speech technology and how ML Commons is helping advance the research and development of machine learning for everyone.

https://blogs.nvidia.com/blog/2022/04/13/mlcommons/</description>
      <pubDate>Tue, 12 Apr 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d33ec01e-f45b-11ef-8be6-ffe16d593009/image/c55849849087426d78fa4acf264553ad.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In deep learning and machine learning, having a l…</itunes:subtitle>
      <itunes:summary>In deep learning and machine learning, having a large enough dataset is key to training a system and getting it to produce results.

So what does a ML researcher do when there just isn’t enough publicly accessible data?

Enter the MLCommons Association, a global engineering consortium with the aim of making ML better for everyone.

MLCommons recently announced the general availability of the People’s Speech Dataset, a 30,000 hour English-language conversational speech dataset, and the Multilingual Spoken Words Corpus, an audio speech dataset with over 340,000 keywords in 50 languages, to help advance ML research.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with David Kanter, founder and executive director of MLCommons, and NVIDIA senior AI developer technology engineer Daniel Galvez, about the democratization of access to speech technology and how ML Commons is helping advance the research and development of machine learning for everyone.

https://blogs.nvidia.com/blog/2022/04/13/mlcommons/</itunes:summary>
      <content:encoded>
        <![CDATA[In deep learning and machine learning, having a large enough dataset is key to training a system and getting it to produce results.

So what does a ML researcher do when there just isn’t enough publicly accessible data?

Enter the MLCommons Association, a global engineering consortium with the aim of making ML better for everyone.

MLCommons recently announced the general availability of the People’s Speech Dataset, a 30,000 hour English-language conversational speech dataset, and the Multilingual Spoken Words Corpus, an audio speech dataset with over 340,000 keywords in 50 languages, to help advance ML research.

On this episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with David Kanter, founder and executive director of MLCommons, and NVIDIA senior AI developer technology engineer Daniel Galvez, about the democratization of access to speech technology and how ML Commons is helping advance the research and development of machine learning for everyone.

https://blogs.nvidia.com/blog/2022/04/13/mlcommons/]]>
      </content:encoded>
      <itunes:duration>2111</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1247044111]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8273333074.mp3?updated=1740586369" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans - Ep. 166</title>
      <link>https://soundcloud.com/theaipodcast/ai-polestar</link>
      <description>Polestar Chief Operating Officer Dennis Nobelius sees driving enjoyment and autonomous-driving capabilities complementing one another in sustainable vehicles that keep driving — and the driver — front and center. 

NVIDIA’s Katie Washabaugh spoke with Nobelius for the latest episode of the AI Podcast about the role the performance brand will play as vehicles become greener and more autonomous.

Nobelius touched on the sustainable automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.</description>
      <pubDate>Wed, 30 Mar 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d3996a28-f45b-11ef-8be6-2ff74c25c5a7/image/a3975a1c95ce0887dcd3845577bf712c.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Polestar Chief Operating Officer Dennis Nobelius …</itunes:subtitle>
      <itunes:summary>Polestar Chief Operating Officer Dennis Nobelius sees driving enjoyment and autonomous-driving capabilities complementing one another in sustainable vehicles that keep driving — and the driver — front and center. 

NVIDIA’s Katie Washabaugh spoke with Nobelius for the latest episode of the AI Podcast about the role the performance brand will play as vehicles become greener and more autonomous.

Nobelius touched on the sustainable automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.</itunes:summary>
      <content:encoded>
        <![CDATA[Polestar Chief Operating Officer Dennis Nobelius sees driving enjoyment and autonomous-driving capabilities complementing one another in sustainable vehicles that keep driving — and the driver — front and center. 

NVIDIA’s Katie Washabaugh spoke with Nobelius for the latest episode of the AI Podcast about the role the performance brand will play as vehicles become greener and more autonomous.

Nobelius touched on the sustainable automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.]]>
      </content:encoded>
      <itunes:duration>1045</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1240933747]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6828649317.mp3?updated=1740586370" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Robust Intelligence CEO Yaron Singer on How to Prevent AI Failures - Ep. 165</title>
      <link>https://soundcloud.com/theaipodcast/robust-intelligence-ceo-yaron-singer-on-how-to-prevent-ai-failures-ep-170</link>
      <description>Sometimes AI models fail, just like everything else in the world fails sometimes. That's where today's guest comes in. Yaron Singer is co- founder and CEO of Robust Intelligence, a company founded in 2019, out of research Singer was doing in his other job, as the Gordon McKay Professor of Computer Science and Applied Mathematics at Harvard University. Robust Intelligence, RI, for short, has developed a sort of AI firewall that wraps around a company's AI models to protects them from making mistakes, by constantly stress=testing these models. If you're not familiar with AI, stress walls and are wondering how an AI firewall can be a thing Yaron is here to tell us all about it.</description>
      <pubDate>Thu, 17 Mar 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d3f41e78-f45b-11ef-8be6-0b01e712c5b7/image/16fd7b584dc9ce0c7937a24998f865f4.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Sometimes AI models fail, just like everything el…</itunes:subtitle>
      <itunes:summary>Sometimes AI models fail, just like everything else in the world fails sometimes. That's where today's guest comes in. Yaron Singer is co- founder and CEO of Robust Intelligence, a company founded in 2019, out of research Singer was doing in his other job, as the Gordon McKay Professor of Computer Science and Applied Mathematics at Harvard University. Robust Intelligence, RI, for short, has developed a sort of AI firewall that wraps around a company's AI models to protects them from making mistakes, by constantly stress=testing these models. If you're not familiar with AI, stress walls and are wondering how an AI firewall can be a thing Yaron is here to tell us all about it.</itunes:summary>
      <content:encoded>
        <![CDATA[Sometimes AI models fail, just like everything else in the world fails sometimes. That's where today's guest comes in. Yaron Singer is co- founder and CEO of Robust Intelligence, a company founded in 2019, out of research Singer was doing in his other job, as the Gordon McKay Professor of Computer Science and Applied Mathematics at Harvard University. Robust Intelligence, RI, for short, has developed a sort of AI firewall that wraps around a company's AI models to protects them from making mistakes, by constantly stress=testing these models. If you're not familiar with AI, stress walls and are wondering how an AI firewall can be a thing Yaron is here to tell us all about it.]]>
      </content:encoded>
      <itunes:duration>1405</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1232997337]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7329381887.mp3?updated=1740586371" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Recommender Systems 101: NVIDIA’s Even Oldridge Breaks It Down - Ep. 164</title>
      <link>https://soundcloud.com/theaipodcast/recommender-system</link>
      <description>The very thing that makes the internet so useful to so many people — the vast quantity of information that’s out there — can also make going online frustrating.

There’s so much available that the sheer volume of choices can be overwhelming. That’s where recommender systems come in, explains NVIDIA AI Podcast host Noah Kravitz.

To dig into how recommender systems work — and why these systems are being harnessed by companies in industries around the globe — Kravitz spoke to Even Oldridge, senior manager for the Merlin team at NVIDIA.

https://blogs.nvidia.com/blog/2022/03/02/whats-a-recommender-system-2/</description>
      <pubDate>Wed, 02 Mar 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d450333e-f45b-11ef-8be6-0b6d0cac758b/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The very thing that makes the internet so useful …</itunes:subtitle>
      <itunes:summary>The very thing that makes the internet so useful to so many people — the vast quantity of information that’s out there — can also make going online frustrating.

There’s so much available that the sheer volume of choices can be overwhelming. That’s where recommender systems come in, explains NVIDIA AI Podcast host Noah Kravitz.

To dig into how recommender systems work — and why these systems are being harnessed by companies in industries around the globe — Kravitz spoke to Even Oldridge, senior manager for the Merlin team at NVIDIA.

https://blogs.nvidia.com/blog/2022/03/02/whats-a-recommender-system-2/</itunes:summary>
      <content:encoded>
        <![CDATA[The very thing that makes the internet so useful to so many people — the vast quantity of information that’s out there — can also make going online frustrating.

There’s so much available that the sheer volume of choices can be overwhelming. That’s where recommender systems come in, explains NVIDIA AI Podcast host Noah Kravitz.

To dig into how recommender systems work — and why these systems are being harnessed by companies in industries around the globe — Kravitz spoke to Even Oldridge, senior manager for the Merlin team at NVIDIA.

https://blogs.nvidia.com/blog/2022/03/02/whats-a-recommender-system-2/]]>
      </content:encoded>
      <itunes:duration>2295</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1224771802]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3082775359.mp3?updated=1740586371" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Exaggeration Detector Could Lead to More Accurate Health Science Journalism - Ep. 163</title>
      <link>https://soundcloud.com/theaipodcast/exaggeration-detector</link>
      <description>It would be an exaggeration to say you’ll never again read a news article overhyping a medical breakthrough. But, thanks to researchers at the University of Copenhagen, spotting hyperbole may one day get more manageable.

In a paper, Dustin Wright and Isabelle Augenstein explain how they used NVIDIA GPUs to train an “exaggeration detection system” to identify overenthusiastic claims in health science reporting.

The paper comes amid a pandemic that has fueled demand for understandable, accurate information. And social media has made health misinformation more widespread.

Research like Wright and Augenstein’s could speed more precise health sciences news to more people. We spoke with Wright about his work.

https://blogs.nvidia.com/blog/2022/2/16/exaggeration-detector-podcast/</description>
      <pubDate>Wed, 16 Feb 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d4adc1b6-f45b-11ef-8be6-4b539288df86/image/7cfc7eaccc0b808c38a7eb165e8c0f67.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>It would be an exaggeration to say you’ll never a…</itunes:subtitle>
      <itunes:summary>It would be an exaggeration to say you’ll never again read a news article overhyping a medical breakthrough. But, thanks to researchers at the University of Copenhagen, spotting hyperbole may one day get more manageable.

In a paper, Dustin Wright and Isabelle Augenstein explain how they used NVIDIA GPUs to train an “exaggeration detection system” to identify overenthusiastic claims in health science reporting.

The paper comes amid a pandemic that has fueled demand for understandable, accurate information. And social media has made health misinformation more widespread.

Research like Wright and Augenstein’s could speed more precise health sciences news to more people. We spoke with Wright about his work.

https://blogs.nvidia.com/blog/2022/2/16/exaggeration-detector-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[It would be an exaggeration to say you’ll never again read a news article overhyping a medical breakthrough. But, thanks to researchers at the University of Copenhagen, spotting hyperbole may one day get more manageable.

In a paper, Dustin Wright and Isabelle Augenstein explain how they used NVIDIA GPUs to train an “exaggeration detection system” to identify overenthusiastic claims in health science reporting.

The paper comes amid a pandemic that has fueled demand for understandable, accurate information. And social media has made health misinformation more widespread.

Research like Wright and Augenstein’s could speed more precise health sciences news to more people. We spoke with Wright about his work.

https://blogs.nvidia.com/blog/2022/2/16/exaggeration-detector-podcast/]]>
      </content:encoded>
      <itunes:duration>1787</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1215858001]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8725424622.mp3?updated=1740586372" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Sarah Tariq Turning Cars into Software-Defined Vehicles - Ep. 162</title>
      <link>https://soundcloud.com/theaipodcast/nvidias-sarah-tariq-turning-cars-into-software-defined-vehicles-ep-162</link>
      <description>Autonomous driving has evolved from science fiction to technology that is actively deployed on roads today.

Sarah Tariq, vice president of autonomous driving software at NVIDIA, has been a key player in this transition. She worked on the ground floor of autonomous vehicle development at both NVIDIA and robotaxi company Zoox, and is now developing solutions for the coming generation of software-defined vehicles.

Tariq is working to redefine how the world views personal transportation, transforming it into an experience that surprises and delights. She spoke with NVIDIA AI Podcast host Katie Washabaugh about her decade in AV development, the many ways in which software can improve mobility and what’s on the road ahead for intelligent transportation.

https://blogs.nvidia.com/blog/2022/02/09/sarah-tariq-software-defined-vehicles</description>
      <pubDate>Wed, 09 Feb 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d50ae332-f45b-11ef-8be6-dbfc11098ce8/image/52d31d0217d1ae2a5300896a7ccb265b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Autonomous driving has evolved from science ficti…</itunes:subtitle>
      <itunes:summary>Autonomous driving has evolved from science fiction to technology that is actively deployed on roads today.

Sarah Tariq, vice president of autonomous driving software at NVIDIA, has been a key player in this transition. She worked on the ground floor of autonomous vehicle development at both NVIDIA and robotaxi company Zoox, and is now developing solutions for the coming generation of software-defined vehicles.

Tariq is working to redefine how the world views personal transportation, transforming it into an experience that surprises and delights. She spoke with NVIDIA AI Podcast host Katie Washabaugh about her decade in AV development, the many ways in which software can improve mobility and what’s on the road ahead for intelligent transportation.

https://blogs.nvidia.com/blog/2022/02/09/sarah-tariq-software-defined-vehicles</itunes:summary>
      <content:encoded>
        <![CDATA[Autonomous driving has evolved from science fiction to technology that is actively deployed on roads today.

Sarah Tariq, vice president of autonomous driving software at NVIDIA, has been a key player in this transition. She worked on the ground floor of autonomous vehicle development at both NVIDIA and robotaxi company Zoox, and is now developing solutions for the coming generation of software-defined vehicles.

Tariq is working to redefine how the world views personal transportation, transforming it into an experience that surprises and delights. She spoke with NVIDIA AI Podcast host Katie Washabaugh about her decade in AV development, the many ways in which software can improve mobility and what’s on the road ahead for intelligent transportation.

https://blogs.nvidia.com/blog/2022/02/09/sarah-tariq-software-defined-vehicles]]>
      </content:encoded>
      <itunes:duration>1092</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1212343507]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5217264172.mp3?updated=1740586372" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Listen Up: How Audio Analytic Is Teaching Machines to Listen - Ep. 161</title>
      <link>https://soundcloud.com/theaipodcast/ai-chris-mitchell</link>
      <description>From active noise cancellation to digital assistants that are always listening for your commands, audio is perhaps one of the most important but often overlooked aspects of modern technology in our daily lives. 

Audio Analytic has been using machine learning that enables a vast array of devices to make sense of the world of sound. 

We spoke with Dr. Chris Mitchell, CEO and founder of Audio Analytic about the challenges, and the fun, involved in teaching machines to listen.</description>
      <pubDate>Wed, 02 Feb 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d5675c84-f45b-11ef-8be6-bbd37f3f644d/image/ab0d67a9fef00e51b4a2b34030e5ebc8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>From active noise cancellation to digital assista…</itunes:subtitle>
      <itunes:summary>From active noise cancellation to digital assistants that are always listening for your commands, audio is perhaps one of the most important but often overlooked aspects of modern technology in our daily lives. 

Audio Analytic has been using machine learning that enables a vast array of devices to make sense of the world of sound. 

We spoke with Dr. Chris Mitchell, CEO and founder of Audio Analytic about the challenges, and the fun, involved in teaching machines to listen.</itunes:summary>
      <content:encoded>
        <![CDATA[From active noise cancellation to digital assistants that are always listening for your commands, audio is perhaps one of the most important but often overlooked aspects of modern technology in our daily lives. 

Audio Analytic has been using machine learning that enables a vast array of devices to make sense of the world of sound. 

We spoke with Dr. Chris Mitchell, CEO and founder of Audio Analytic about the challenges, and the fun, involved in teaching machines to listen.]]>
      </content:encoded>
      <itunes:duration>1891</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1205786227]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9273534095.mp3?updated=1740586373" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Fusing Art and Tech: MORF Gallery CEO Scott Birnbaum on Digital Paintings, NFTs and More - Ep. 160</title>
      <link>https://soundcloud.com/theaipodcast/ai-scott-birnbaum-morf</link>
      <description>Browse through MORF Gallery — virtually or at an in-person exhibition — and you’ll find robots that paint, digital dreamscape experiences, and fine art brought to life by visual effects.

The gallery showcases cutting-edge, one-of-a-kind artwork from award-winning artists who fuse their creative skills with AI, machine learning, robotics and neuroscience.

Scott Birnbaum, CEO and co-founder of MORF Gallery, a Silicon Valley startup, spoke with NVIDIA AI Podcast host Noah Kravitz about digital art, non-fungible tokens, as well as ArtStick, a plug-in device that turns any TV into a premium digital art gallery.

https://blogs.nvidia.com/blog/2022/01/19/morf-gallery-ceo-scott-birnbaum/</description>
      <pubDate>Wed, 19 Jan 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d5c3d9fa-f45b-11ef-8be6-e3de33179aff/image/98c1d5aec349427e85f1dd27b53b409e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Browse through MORF Gallery — virtually or at an …</itunes:subtitle>
      <itunes:summary>Browse through MORF Gallery — virtually or at an in-person exhibition — and you’ll find robots that paint, digital dreamscape experiences, and fine art brought to life by visual effects.

The gallery showcases cutting-edge, one-of-a-kind artwork from award-winning artists who fuse their creative skills with AI, machine learning, robotics and neuroscience.

Scott Birnbaum, CEO and co-founder of MORF Gallery, a Silicon Valley startup, spoke with NVIDIA AI Podcast host Noah Kravitz about digital art, non-fungible tokens, as well as ArtStick, a plug-in device that turns any TV into a premium digital art gallery.

https://blogs.nvidia.com/blog/2022/01/19/morf-gallery-ceo-scott-birnbaum/</itunes:summary>
      <content:encoded>
        <![CDATA[Browse through MORF Gallery — virtually or at an in-person exhibition — and you’ll find robots that paint, digital dreamscape experiences, and fine art brought to life by visual effects.

The gallery showcases cutting-edge, one-of-a-kind artwork from award-winning artists who fuse their creative skills with AI, machine learning, robotics and neuroscience.

Scott Birnbaum, CEO and co-founder of MORF Gallery, a Silicon Valley startup, spoke with NVIDIA AI Podcast host Noah Kravitz about digital art, non-fungible tokens, as well as ArtStick, a plug-in device that turns any TV into a premium digital art gallery.

https://blogs.nvidia.com/blog/2022/01/19/morf-gallery-ceo-scott-birnbaum/]]>
      </content:encoded>
      <itunes:duration>1854</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1195372741]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5361239659.mp3?updated=1740586374" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>‘AI Dungeon’ Creator Nick Walton Uses AI to Generate Infinite Gaming Storylines - Ep. 159</title>
      <link>https://soundcloud.com/theaipodcast/ai-dungeon</link>
      <description>What started as Nick Walton’s college hackathon project grew into AI Dungeon, a popular text adventure game with over 1.5 million users. 

Walton is the co-founder and CEO of Latitude, a Utah-based startup that uses AI to create unique gaming storylines. 

He spoke with NVIDIA AI Podcast host Noah Kravitz about how natural language processing methods can generate infinite open-ended adventure plots for interactive games like AI Dungeon, which draws an average of 150,000 new players each month.

https://blogs.nvidia.com/blog/2021/01/05/nick-walton-ai-podcast/</description>
      <pubDate>Wed, 05 Jan 2022 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d624109a-f45b-11ef-8be6-63fd0437ccc2/image/74c462bc75fe4e3e936a75d334da873f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>What started as Nick Walton’s college hackathon p…</itunes:subtitle>
      <itunes:summary>What started as Nick Walton’s college hackathon project grew into AI Dungeon, a popular text adventure game with over 1.5 million users. 

Walton is the co-founder and CEO of Latitude, a Utah-based startup that uses AI to create unique gaming storylines. 

He spoke with NVIDIA AI Podcast host Noah Kravitz about how natural language processing methods can generate infinite open-ended adventure plots for interactive games like AI Dungeon, which draws an average of 150,000 new players each month.

https://blogs.nvidia.com/blog/2021/01/05/nick-walton-ai-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[What started as Nick Walton’s college hackathon project grew into AI Dungeon, a popular text adventure game with over 1.5 million users. 

Walton is the co-founder and CEO of Latitude, a Utah-based startup that uses AI to create unique gaming storylines. 

He spoke with NVIDIA AI Podcast host Noah Kravitz about how natural language processing methods can generate infinite open-ended adventure plots for interactive games like AI Dungeon, which draws an average of 150,000 new players each month.

https://blogs.nvidia.com/blog/2021/01/05/nick-walton-ai-podcast/]]>
      </content:encoded>
      <itunes:duration>1557</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1190646844]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4574387667.mp3?updated=1740586374" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI Pioneer Kai-Fu Lee Discusses His New Work of Fiction - Ep. 158</title>
      <link>https://soundcloud.com/theaipodcast/ai-kaifu-lee</link>
      <description>One of AI’s greatest champions has turned to fiction to answer the question: how will technology shape our world in the next 20 years?

Kai-Fu Lee, CEO of Sinovation Ventures and a former president of Google China, spoke with NVIDIA AI Podcast host Noah Kravitz about AI 2041: Ten Visions for Our Future. The book, his fourth available in the U.S. and first work of fiction, was in collaboration with Chinese sci-fi writer Chen Qiufan, also known as Stanley Chan.

Lee and Chan blend their expertise in scientific forecasting and speculative fiction in this collection of short stories, which was published in September.

Among Lee’s books is the New York Times bestseller AI Superpowers: China, Silicon Valley, and the New World Order, which he spoke about on a 2018 episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/12/15/kai-fu-lee-ai-2041/</description>
      <pubDate>Wed, 15 Dec 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d683ad52-f45b-11ef-8be6-070b9cec03fa/image/b7335e6f491f3cc58304d67dc012f6e0.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>One of AI’s greatest champions has turned to fict…</itunes:subtitle>
      <itunes:summary>One of AI’s greatest champions has turned to fiction to answer the question: how will technology shape our world in the next 20 years?

Kai-Fu Lee, CEO of Sinovation Ventures and a former president of Google China, spoke with NVIDIA AI Podcast host Noah Kravitz about AI 2041: Ten Visions for Our Future. The book, his fourth available in the U.S. and first work of fiction, was in collaboration with Chinese sci-fi writer Chen Qiufan, also known as Stanley Chan.

Lee and Chan blend their expertise in scientific forecasting and speculative fiction in this collection of short stories, which was published in September.

Among Lee’s books is the New York Times bestseller AI Superpowers: China, Silicon Valley, and the New World Order, which he spoke about on a 2018 episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/12/15/kai-fu-lee-ai-2041/</itunes:summary>
      <content:encoded>
        <![CDATA[One of AI’s greatest champions has turned to fiction to answer the question: how will technology shape our world in the next 20 years?

Kai-Fu Lee, CEO of Sinovation Ventures and a former president of Google China, spoke with NVIDIA AI Podcast host Noah Kravitz about AI 2041: Ten Visions for Our Future. The book, his fourth available in the U.S. and first work of fiction, was in collaboration with Chinese sci-fi writer Chen Qiufan, also known as Stanley Chan.

Lee and Chan blend their expertise in scientific forecasting and speculative fiction in this collection of short stories, which was published in September.

Among Lee’s books is the New York Times bestseller AI Superpowers: China, Silicon Valley, and the New World Order, which he spoke about on a 2018 episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/12/15/kai-fu-lee-ai-2041/]]>
      </content:encoded>
      <itunes:duration>1819</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1178242306]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9361611653.mp3?updated=1740586375" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Real or Not Real? Attorney Steven Frank Uses Deep Learning to Authenticate Art - Ep. 157</title>
      <link>https://soundcloud.com/theaipodcast/real-or-not-real-attorney-steven-frank-uses-deep-learning-to-authenticate-art</link>
      <description>Leonardo da Vinci’s portrait of Jesus, known as Salvator Mundi, was sold at a British auction for nearly half a billion dollars in 2017, making it the most expensive painting ever to change hands.

However, even art history experts were skeptical about whether the work was an original of the master rather than one of his many protégés. 

Steven Frank is a partner at the law firm Morgan Lewis, specializing in intellectual property and commercial technology law. He’s also half of the husband-wife team that used convolutional neural networks to determine that this painting was likely an authentic da Vinci.

He spoke with NVIDIA AI Podcast host Noah Kravitz about working with his wife, Andrea Frank, a professional curator of art images, to authenticate artistic masterpieces with AI’s help.

https://blogs.nvidia.com/blog/2021/12/01/steven-frank-ai-art/</description>
      <pubDate>Tue, 30 Nov 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d6e1f10a-f45b-11ef-8be6-9bf68f49bf20/image/844fd20a5a9ca0acfd6e66fdc9693da2.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Leonardo da Vinci’s portrait of Jesus, known as S…</itunes:subtitle>
      <itunes:summary>Leonardo da Vinci’s portrait of Jesus, known as Salvator Mundi, was sold at a British auction for nearly half a billion dollars in 2017, making it the most expensive painting ever to change hands.

However, even art history experts were skeptical about whether the work was an original of the master rather than one of his many protégés. 

Steven Frank is a partner at the law firm Morgan Lewis, specializing in intellectual property and commercial technology law. He’s also half of the husband-wife team that used convolutional neural networks to determine that this painting was likely an authentic da Vinci.

He spoke with NVIDIA AI Podcast host Noah Kravitz about working with his wife, Andrea Frank, a professional curator of art images, to authenticate artistic masterpieces with AI’s help.

https://blogs.nvidia.com/blog/2021/12/01/steven-frank-ai-art/</itunes:summary>
      <content:encoded>
        <![CDATA[Leonardo da Vinci’s portrait of Jesus, known as Salvator Mundi, was sold at a British auction for nearly half a billion dollars in 2017, making it the most expensive painting ever to change hands.

However, even art history experts were skeptical about whether the work was an original of the master rather than one of his many protégés. 

Steven Frank is a partner at the law firm Morgan Lewis, specializing in intellectual property and commercial technology law. He’s also half of the husband-wife team that used convolutional neural networks to determine that this painting was likely an authentic da Vinci.

He spoke with NVIDIA AI Podcast host Noah Kravitz about working with his wife, Andrea Frank, a professional curator of art images, to authenticate artistic masterpieces with AI’s help.

https://blogs.nvidia.com/blog/2021/12/01/steven-frank-ai-art/]]>
      </content:encoded>
      <itunes:duration>2486</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1169788282]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7062782662.mp3?updated=1740586376" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI of the Tiger: Conservation Biologist Jeremy Dertien - Ep. 156</title>
      <link>https://soundcloud.com/theaipodcast/ai-jeremy-dertien</link>
      <description>Fewer than 4,000 tigers remain worldwide, according to Tigers United, a university consortium that recently began using AI to help save the species.

Jeremy Dertien is a conservation biologist with Tigers United and a Ph.D. candidate in wildlife biology and conservation planning at Clemson University.

He spoke with NVIDIA AI Podcast host Noah Kravitz about a project deploying AI-equipped cameras to monitor poaching in central India, where more than 70 percent of the remaining tiger populations reside.

 https://blogs.nvidia.com/blog/2021/11/18/jeremy-dertien-tigers-united/</description>
      <pubDate>Wed, 17 Nov 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d796c260-f45b-11ef-8be6-a35e719a366b/image/5ec31051943ed8d2ad4224607a11f9c2.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Fewer than 4,000 tigers remain worldwide, accordi…</itunes:subtitle>
      <itunes:summary>Fewer than 4,000 tigers remain worldwide, according to Tigers United, a university consortium that recently began using AI to help save the species.

Jeremy Dertien is a conservation biologist with Tigers United and a Ph.D. candidate in wildlife biology and conservation planning at Clemson University.

He spoke with NVIDIA AI Podcast host Noah Kravitz about a project deploying AI-equipped cameras to monitor poaching in central India, where more than 70 percent of the remaining tiger populations reside.

 https://blogs.nvidia.com/blog/2021/11/18/jeremy-dertien-tigers-united/</itunes:summary>
      <content:encoded>
        <![CDATA[Fewer than 4,000 tigers remain worldwide, according to Tigers United, a university consortium that recently began using AI to help save the species.

Jeremy Dertien is a conservation biologist with Tigers United and a Ph.D. candidate in wildlife biology and conservation planning at Clemson University.

He spoke with NVIDIA AI Podcast host Noah Kravitz about a project deploying AI-equipped cameras to monitor poaching in central India, where more than 70 percent of the remaining tiger populations reside.

 https://blogs.nvidia.com/blog/2021/11/18/jeremy-dertien-tigers-united/]]>
      </content:encoded>
      <itunes:duration>1885</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1162090666]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5986161941.mp3?updated=1740586377" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Metaspectral’s‌ ‌Migel‌ ‌Tissera‌ ‌on‌ ‌AI-Based‌ ‌Data‌ ‌Management‌ ‌ - Ep. 155</title>
      <link>https://soundcloud.com/theaipodcast/ai-migel-tissera</link>
      <description>‌Moondust‌,‌ ‌minerals‌ ‌and‌ ‌soil‌ ‌types‌ ‌are‌ ‌just‌ ‌some‌ ‌of‌ ‌the‌ ‌materials‌ ‌that‌ ‌can‌ ‌be‌ ‌quickly‌ ‌identified‌ ‌and‌ ‌analyzed‌ ‌with‌ ‌AI‌,‌‌ ‌based‌ ‌on‌ ‌images‌ ‌of‌ ‌them.‌ ‌ ‌
 ‌
Migel‌ ‌Tissera‌ ‌is‌ ‌co-founder‌ ‌and‌ ‌CTO‌ ‌of‌ ‌Metaspectral,‌ ‌a‌ ‌Vancouver-based‌ ‌startup‌ ‌that‌ ‌provides‌ ‌an‌ ‌AI-based‌ ‌data‌ ‌management‌ ‌and‌ ‌analysis‌ ‌platform‌ ‌for‌ ‌ultra-high-resolution‌ ‌images.‌ ‌
 ‌
He‌ ‌spoke‌ ‌with‌ ‌‌NVIDIA‌ ‌AI‌ ‌Podcast‌‌ ‌host‌ ‌Noah‌ ‌Kravitz‌ ‌about‌ ‌how‌ ‌Metaspectral’s‌ ‌technologies‌ ‌help‌ ‌space‌ ‌explorers‌ ‌make‌ ‌quicker‌ ‌and‌ ‌better‌ ‌use‌ ‌of‌ ‌the‌ ‌massive‌ ‌amounts‌ ‌of‌ ‌image‌ ‌data‌ ‌they‌ ‌collect‌ ‌out‌ ‌in‌ ‌the‌ ‌cosmos.‌ ‌
 ‌
In‌ ‌addition‌ ‌to‌ ‌space,‌ ‌the‌ ‌startup’s‌ ‌platform‌ ‌is‌ ‌used‌ ‌across‌ ‌industries‌ ‌such‌ ‌as‌ ‌agriculture,‌ ‌forensics‌ ‌and‌ ‌recycling.‌ ‌

Show notes: https://blogs.nvidia.com/blog/2021/11/03/migel-tissera/</description>
      <pubDate>Wed, 03 Nov 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d8003d94-f45b-11ef-8be6-878d75346ff6/image/de24f167fae24d71a54563b43c91b775.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>‌Moondust‌,‌ ‌minerals‌ ‌and‌ ‌soil‌ ‌types‌ ‌are…</itunes:subtitle>
      <itunes:summary>‌Moondust‌,‌ ‌minerals‌ ‌and‌ ‌soil‌ ‌types‌ ‌are‌ ‌just‌ ‌some‌ ‌of‌ ‌the‌ ‌materials‌ ‌that‌ ‌can‌ ‌be‌ ‌quickly‌ ‌identified‌ ‌and‌ ‌analyzed‌ ‌with‌ ‌AI‌,‌‌ ‌based‌ ‌on‌ ‌images‌ ‌of‌ ‌them.‌ ‌ ‌
 ‌
Migel‌ ‌Tissera‌ ‌is‌ ‌co-founder‌ ‌and‌ ‌CTO‌ ‌of‌ ‌Metaspectral,‌ ‌a‌ ‌Vancouver-based‌ ‌startup‌ ‌that‌ ‌provides‌ ‌an‌ ‌AI-based‌ ‌data‌ ‌management‌ ‌and‌ ‌analysis‌ ‌platform‌ ‌for‌ ‌ultra-high-resolution‌ ‌images.‌ ‌
 ‌
He‌ ‌spoke‌ ‌with‌ ‌‌NVIDIA‌ ‌AI‌ ‌Podcast‌‌ ‌host‌ ‌Noah‌ ‌Kravitz‌ ‌about‌ ‌how‌ ‌Metaspectral’s‌ ‌technologies‌ ‌help‌ ‌space‌ ‌explorers‌ ‌make‌ ‌quicker‌ ‌and‌ ‌better‌ ‌use‌ ‌of‌ ‌the‌ ‌massive‌ ‌amounts‌ ‌of‌ ‌image‌ ‌data‌ ‌they‌ ‌collect‌ ‌out‌ ‌in‌ ‌the‌ ‌cosmos.‌ ‌
 ‌
In‌ ‌addition‌ ‌to‌ ‌space,‌ ‌the‌ ‌startup’s‌ ‌platform‌ ‌is‌ ‌used‌ ‌across‌ ‌industries‌ ‌such‌ ‌as‌ ‌agriculture,‌ ‌forensics‌ ‌and‌ ‌recycling.‌ ‌

Show notes: https://blogs.nvidia.com/blog/2021/11/03/migel-tissera/</itunes:summary>
      <content:encoded>
        <![CDATA[‌Moondust‌,‌ ‌minerals‌ ‌and‌ ‌soil‌ ‌types‌ ‌are‌ ‌just‌ ‌some‌ ‌of‌ ‌the‌ ‌materials‌ ‌that‌ ‌can‌ ‌be‌ ‌quickly‌ ‌identified‌ ‌and‌ ‌analyzed‌ ‌with‌ ‌AI‌,‌‌ ‌based‌ ‌on‌ ‌images‌ ‌of‌ ‌them.‌ ‌ ‌
 ‌
Migel‌ ‌Tissera‌ ‌is‌ ‌co-founder‌ ‌and‌ ‌CTO‌ ‌of‌ ‌Metaspectral,‌ ‌a‌ ‌Vancouver-based‌ ‌startup‌ ‌that‌ ‌provides‌ ‌an‌ ‌AI-based‌ ‌data‌ ‌management‌ ‌and‌ ‌analysis‌ ‌platform‌ ‌for‌ ‌ultra-high-resolution‌ ‌images.‌ ‌
 ‌
He‌ ‌spoke‌ ‌with‌ ‌‌NVIDIA‌ ‌AI‌ ‌Podcast‌‌ ‌host‌ ‌Noah‌ ‌Kravitz‌ ‌about‌ ‌how‌ ‌Metaspectral’s‌ ‌technologies‌ ‌help‌ ‌space‌ ‌explorers‌ ‌make‌ ‌quicker‌ ‌and‌ ‌better‌ ‌use‌ ‌of‌ ‌the‌ ‌massive‌ ‌amounts‌ ‌of‌ ‌image‌ ‌data‌ ‌they‌ ‌collect‌ ‌out‌ ‌in‌ ‌the‌ ‌cosmos.‌ ‌
 ‌
In‌ ‌addition‌ ‌to‌ ‌space,‌ ‌the‌ ‌startup’s‌ ‌platform‌ ‌is‌ ‌used‌ ‌across‌ ‌industries‌ ‌such‌ ‌as‌ ‌agriculture,‌ ‌forensics‌ ‌and‌ ‌recycling.‌ ‌

Show notes: https://blogs.nvidia.com/blog/2021/11/03/migel-tissera/]]>
      </content:encoded>
      <itunes:duration>1909</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1150589371]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4644884241.mp3?updated=1740586377" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Researchers Chris Downum and Leszek Pawlowicz Use Deep Learning to Accelerate Archaeology - Ep. 154</title>
      <link>https://soundcloud.com/theaipodcast/ai-sherd</link>
      <description>The more advanced modern technologies become, the more they can help us understand the past.

Chris Downum and Leszek Pawlowicz, researchers in the Department of Anthropology at Northern Arizona University, are using GPU-based deep learning algorithms to categorize sherds — tiny fragments of ancient pottery.

They spoke with NVIDIA AI Podcast host Noah Kravitz about analyzing sherds to learn more about American Southwest culture, circa 825 to 1300 A.D.

https://blogs.nvidia.com/blog/2021/10/20/ai-pottery-anthropology/</description>
      <pubDate>Wed, 20 Oct 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d85fa28e-f45b-11ef-8be6-3f55d4803c38/image/265d26da2a69156cf8e41b8b3897759e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The more advanced modern technologies become, the…</itunes:subtitle>
      <itunes:summary>The more advanced modern technologies become, the more they can help us understand the past.

Chris Downum and Leszek Pawlowicz, researchers in the Department of Anthropology at Northern Arizona University, are using GPU-based deep learning algorithms to categorize sherds — tiny fragments of ancient pottery.

They spoke with NVIDIA AI Podcast host Noah Kravitz about analyzing sherds to learn more about American Southwest culture, circa 825 to 1300 A.D.

https://blogs.nvidia.com/blog/2021/10/20/ai-pottery-anthropology/</itunes:summary>
      <content:encoded>
        <![CDATA[The more advanced modern technologies become, the more they can help us understand the past.

Chris Downum and Leszek Pawlowicz, researchers in the Department of Anthropology at Northern Arizona University, are using GPU-based deep learning algorithms to categorize sherds — tiny fragments of ancient pottery.

They spoke with NVIDIA AI Podcast host Noah Kravitz about analyzing sherds to learn more about American Southwest culture, circa 825 to 1300 A.D.

https://blogs.nvidia.com/blog/2021/10/20/ai-pottery-anthropology/]]>
      </content:encoded>
      <itunes:duration>1588</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1142735335]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9111753962.mp3?updated=1740586378" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Maya Ackerman on LyricStudio, an AI-Based Writing Songwriting Assistant - Ep. 153</title>
      <link>https://soundcloud.com/theaipodcast/maya-ackerman</link>
      <description>Lennon and McCartney. Ashford and Simpson. Many of our all-time favorite tunes have come from songwriting duos. Now, anyone can find a snazzy compositional partner in AI.

Maya Ackerman is the CEO of WaveAI, a Silicon Valley startup using AI and machine learning to, as the company motto puts it, “unlock new heights of human creative expression.”

She spoke with NVIDIA AI Podcast host Noah Kravitz about WaveAI’s LyricStudio software, an AI-based lyric and poetry writing assistant.

https://blogs.nvidia.com/blog/2021/10/06/lyricstudio-ai-podcast/</description>
      <pubDate>Fri, 01 Oct 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d8bd55c8-f45b-11ef-8be6-bbea68840445/image/f97b4eb310e8728760efca295341ee45.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Lennon and McCartney. Ashford and Simpson. Many o…</itunes:subtitle>
      <itunes:summary>Lennon and McCartney. Ashford and Simpson. Many of our all-time favorite tunes have come from songwriting duos. Now, anyone can find a snazzy compositional partner in AI.

Maya Ackerman is the CEO of WaveAI, a Silicon Valley startup using AI and machine learning to, as the company motto puts it, “unlock new heights of human creative expression.”

She spoke with NVIDIA AI Podcast host Noah Kravitz about WaveAI’s LyricStudio software, an AI-based lyric and poetry writing assistant.

https://blogs.nvidia.com/blog/2021/10/06/lyricstudio-ai-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[Lennon and McCartney. Ashford and Simpson. Many of our all-time favorite tunes have come from songwriting duos. Now, anyone can find a snazzy compositional partner in AI.

Maya Ackerman is the CEO of WaveAI, a Silicon Valley startup using AI and machine learning to, as the company motto puts it, “unlock new heights of human creative expression.”

She spoke with NVIDIA AI Podcast host Noah Kravitz about WaveAI’s LyricStudio software, an AI-based lyric and poetry writing assistant.

https://blogs.nvidia.com/blog/2021/10/06/lyricstudio-ai-podcast/]]>
      </content:encoded>
      <itunes:duration>1394</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1134648463]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7512369271.mp3?updated=1740586379" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Wild Things: NVIDIA’s Sifei Liu Talks 3D Reconstructions of Endangered Species - Ep. 152</title>
      <link>https://soundcloud.com/theaipodcast/nvidia-sifei-liu-3d-reconstructions-endangered-species</link>
      <description>Endangered species can be difficult to study, as they are elusive, and the very act of observing them can disrupt their lives. Now, scientists can take a closer look at endangered species by studying AI-generated 3D representations of them.

Sifei Liu, a senior research scientist at NVIDIA, has worked with her team to create an algorithm that can reconstruct 3D meshes — graphics models used to display the edges, vertices and overall shape of an object — from 2D inputs like images and videos.

Liu spoke with NVIDIA AI Podcast host Noah Kravitz about her team’s project, called Online Adaptation for Consistent Mesh Reconstruction in the Wild. Liu and her team have presented the project at various prominent conferences, including NeurIPS 2020.</description>
      <pubDate>Mon, 20 Sep 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d918a9e6-f45b-11ef-8be6-6b672c0f19d6/image/e5db94b012a3acd1ee139df998aba850.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Endangered species can be difficult to study, as …</itunes:subtitle>
      <itunes:summary>Endangered species can be difficult to study, as they are elusive, and the very act of observing them can disrupt their lives. Now, scientists can take a closer look at endangered species by studying AI-generated 3D representations of them.

Sifei Liu, a senior research scientist at NVIDIA, has worked with her team to create an algorithm that can reconstruct 3D meshes — graphics models used to display the edges, vertices and overall shape of an object — from 2D inputs like images and videos.

Liu spoke with NVIDIA AI Podcast host Noah Kravitz about her team’s project, called Online Adaptation for Consistent Mesh Reconstruction in the Wild. Liu and her team have presented the project at various prominent conferences, including NeurIPS 2020.</itunes:summary>
      <content:encoded>
        <![CDATA[Endangered species can be difficult to study, as they are elusive, and the very act of observing them can disrupt their lives. Now, scientists can take a closer look at endangered species by studying AI-generated 3D representations of them.

Sifei Liu, a senior research scientist at NVIDIA, has worked with her team to create an algorithm that can reconstruct 3D meshes — graphics models used to display the edges, vertices and overall shape of an object — from 2D inputs like images and videos.

Liu spoke with NVIDIA AI Podcast host Noah Kravitz about her team’s project, called Online Adaptation for Consistent Mesh Reconstruction in the Wild. Liu and her team have presented the project at various prominent conferences, including NeurIPS 2020.]]>
      </content:encoded>
      <itunes:duration>1268</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1126687156]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5408764746.mp3?updated=1740586380" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>GANTheftAuto: Harrison Kinsley on AI-Generated Gaming Environments - Ep. 151</title>
      <link>https://soundcloud.com/theaipodcast/gantheftauto-harrison-kinsley-on-ai-generated-gaming-environments</link>
      <description>Machines have long played games - think of Deep Blue or AlphaGo. Now they're building them. GANTheftAuto creator Harrison Kinsley talks about his creation on the latest episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/09/08/gantheftauto/</description>
      <pubDate>Wed, 08 Sep 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d9a12780-f45b-11ef-8be6-a33ced3bebb2/image/2f887304ab2a69d885fee6e48496341d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Machines have long played games - think of Deep B…</itunes:subtitle>
      <itunes:summary>Machines have long played games - think of Deep Blue or AlphaGo. Now they're building them. GANTheftAuto creator Harrison Kinsley talks about his creation on the latest episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/09/08/gantheftauto/</itunes:summary>
      <content:encoded>
        <![CDATA[Machines have long played games - think of Deep Blue or AlphaGo. Now they're building them. GANTheftAuto creator Harrison Kinsley talks about his creation on the latest episode of the AI Podcast.

https://blogs.nvidia.com/blog/2021/09/08/gantheftauto/]]>
      </content:encoded>
      <itunes:duration>1786</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1118476090]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2010160389.mp3?updated=1740586380" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>GE's Danielle Merfeld and Arvind Rangarajan on AI and Renewable Energy - Ep. 150</title>
      <link>https://soundcloud.com/theaipodcast/ai-ge-renewable-energy</link>
      <description>At GE Renewable Energy, CTO Danielle Merfeld and technical leader Arvind Rangarajan are among those making advances throughout renewable energy.

Merfeld and Rangarajan spoke with NVIDIA AI Podcast host Noah Kravitz about how the company uses AI and a human-in-the-loop process to make renewable energy more widespread.

The International Energy Agency has set a goal to reach a net zero energy sector by 2050. To reach this goal, 88 percent of electricity needs to come from renewable sources.

Wind energy will account for 40 percent of that, but today only makes up 8 percent of renewable energy.

https://blogs.nvidia.com/blog/2021/08/25/ge-ai-energy/</description>
      <pubDate>Fri, 20 Aug 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/d9fd7ad0-f45b-11ef-8be6-0b7694c36f69/image/7b29d748922a701a170d2aaf5adb6b5a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>At GE Renewable Energy, CTO Danielle Merfeld and …</itunes:subtitle>
      <itunes:summary>At GE Renewable Energy, CTO Danielle Merfeld and technical leader Arvind Rangarajan are among those making advances throughout renewable energy.

Merfeld and Rangarajan spoke with NVIDIA AI Podcast host Noah Kravitz about how the company uses AI and a human-in-the-loop process to make renewable energy more widespread.

The International Energy Agency has set a goal to reach a net zero energy sector by 2050. To reach this goal, 88 percent of electricity needs to come from renewable sources.

Wind energy will account for 40 percent of that, but today only makes up 8 percent of renewable energy.

https://blogs.nvidia.com/blog/2021/08/25/ge-ai-energy/</itunes:summary>
      <content:encoded>
        <![CDATA[At GE Renewable Energy, CTO Danielle Merfeld and technical leader Arvind Rangarajan are among those making advances throughout renewable energy.

Merfeld and Rangarajan spoke with NVIDIA AI Podcast host Noah Kravitz about how the company uses AI and a human-in-the-loop process to make renewable energy more widespread.

The International Energy Agency has set a goal to reach a net zero energy sector by 2050. To reach this goal, 88 percent of electricity needs to come from renewable sources.

Wind energy will account for 40 percent of that, but today only makes up 8 percent of renewable energy.

https://blogs.nvidia.com/blog/2021/08/25/ge-ai-energy/]]>
      </content:encoded>
      <itunes:duration>1872</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1108428379]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6083519599.mp3?updated=1740586381" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Jules Anh Tuan Nguyen Explains How AI Lets Amputee Control Prosthetic Hand, Video Games - Ep. 149</title>
      <link>https://soundcloud.com/theaipodcast/jules-anh-tuan-nguyen-explains-how-ai-lets-amputee-control-prosthetic-hand-video-games-ep-149</link>
      <description>Path-breaking work that translates an amputee’s thoughts into finger motions, and even commands in video games, holds open the possibility of humans controlling just about anything digital with their minds.

Using GPUs, a group of researchers trained an AI neural decoder able to run on a compact, power-efficient NVIDIA Jetson Nano system on module (SOM) to translate 46-year-old Shawn Findley’s thoughts into individual finger motions.

And if that breakthrough weren’t enough, the team then plugged Findley into a PC running Far Cry 5 and Raiden IV, where he had his game avatar move, jump — even fly a virtual helicopter — using his mind.

It’s a demonstration that not only promises to give amputees more natural and responsive control over their prosthetics. It could one day give users almost superhuman capabilities.

The effort is detailed in a draft paper, or pre-print, titled “A Portable, Self-Contained Neuroprosthetic Hand with Deep Learning-Based Finger Control.” It details an extraordinary cross-disciplinary collaboration behind a system that, in effect, allows humans to control just about anything digital with thoughts.

Jules Anh Tuan Nguyen,  the paper’s lead author and now a postdoctoral researcher at the University of Minnesota, spoke with NVIDIA AI Podcast host Noah Kravitz about his efforts to allow amputees to control their prosthetic limb — right down to the finger motions — with their minds.

blogs.nvidia.com/blog/2021/08/10/lending-a-helping-hand-jules-anh-tuan-nguyen-on-building-a-neuroprosthetic</description>
      <pubDate>Wed, 11 Aug 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/da5ce268-f45b-11ef-8be6-8b68cb9e5725/image/0cc693daf23a903119e1399a64c1a4d9.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Path-breaking work that translates an amputee’s t…</itunes:subtitle>
      <itunes:summary>Path-breaking work that translates an amputee’s thoughts into finger motions, and even commands in video games, holds open the possibility of humans controlling just about anything digital with their minds.

Using GPUs, a group of researchers trained an AI neural decoder able to run on a compact, power-efficient NVIDIA Jetson Nano system on module (SOM) to translate 46-year-old Shawn Findley’s thoughts into individual finger motions.

And if that breakthrough weren’t enough, the team then plugged Findley into a PC running Far Cry 5 and Raiden IV, where he had his game avatar move, jump — even fly a virtual helicopter — using his mind.

It’s a demonstration that not only promises to give amputees more natural and responsive control over their prosthetics. It could one day give users almost superhuman capabilities.

The effort is detailed in a draft paper, or pre-print, titled “A Portable, Self-Contained Neuroprosthetic Hand with Deep Learning-Based Finger Control.” It details an extraordinary cross-disciplinary collaboration behind a system that, in effect, allows humans to control just about anything digital with thoughts.

Jules Anh Tuan Nguyen,  the paper’s lead author and now a postdoctoral researcher at the University of Minnesota, spoke with NVIDIA AI Podcast host Noah Kravitz about his efforts to allow amputees to control their prosthetic limb — right down to the finger motions — with their minds.

blogs.nvidia.com/blog/2021/08/10/lending-a-helping-hand-jules-anh-tuan-nguyen-on-building-a-neuroprosthetic</itunes:summary>
      <content:encoded>
        <![CDATA[Path-breaking work that translates an amputee’s thoughts into finger motions, and even commands in video games, holds open the possibility of humans controlling just about anything digital with their minds.

Using GPUs, a group of researchers trained an AI neural decoder able to run on a compact, power-efficient NVIDIA Jetson Nano system on module (SOM) to translate 46-year-old Shawn Findley’s thoughts into individual finger motions.

And if that breakthrough weren’t enough, the team then plugged Findley into a PC running Far Cry 5 and Raiden IV, where he had his game avatar move, jump — even fly a virtual helicopter — using his mind.

It’s a demonstration that not only promises to give amputees more natural and responsive control over their prosthetics. It could one day give users almost superhuman capabilities.

The effort is detailed in a draft paper, or pre-print, titled “A Portable, Self-Contained Neuroprosthetic Hand with Deep Learning-Based Finger Control.” It details an extraordinary cross-disciplinary collaboration behind a system that, in effect, allows humans to control just about anything digital with thoughts.

Jules Anh Tuan Nguyen,  the paper’s lead author and now a postdoctoral researcher at the University of Minnesota, spoke with NVIDIA AI Podcast host Noah Kravitz about his efforts to allow amputees to control their prosthetic limb — right down to the finger motions — with their minds.

blogs.nvidia.com/blog/2021/08/10/lending-a-helping-hand-jules-anh-tuan-nguyen-on-building-a-neuroprosthetic]]>
      </content:encoded>
      <itunes:duration>2203</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1103963611]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8313735235.mp3?updated=1740586381" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Matt Ginsberg Built a GPU-Powered Crossword Solver to Take on Top Word Nerds - Ep. 148</title>
      <link>https://soundcloud.com/theaipodcast/ai-matt-ginsberg</link>
      <description>Following a long string of victories for computers in other games — chess in 1997, go in 2016 and Texas hold’em poker in 2019 — a GPU-powered AI has beaten some of the world’s most competitive word nerds at the crossword puzzles that are a staple of every Sunday paper.

Dr.Fill, the crossword puzzle-playing AI created by Matt Ginsberg — a serial entrepreneur, pioneering AI researcher and former research professor — scored higher than any humans earlier this year at the American Crossword Puzzle Tournament.

Ginsberg spoke with NVIDIA AI Podcast host Noah Kravitz about his decade-long journey creating Dr.Fill and where he envisions it going in the future.

https://blogs.nvidia.com/blog/2021/07/28/matt-ginsberg-ai-podcast/</description>
      <pubDate>Wed, 28 Jul 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/daba4d36-f45b-11ef-8be6-bfe935291fe6/image/ded662cc50ec44f424dbb9537aa0e8e8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Following a long string of victories for computer…</itunes:subtitle>
      <itunes:summary>Following a long string of victories for computers in other games — chess in 1997, go in 2016 and Texas hold’em poker in 2019 — a GPU-powered AI has beaten some of the world’s most competitive word nerds at the crossword puzzles that are a staple of every Sunday paper.

Dr.Fill, the crossword puzzle-playing AI created by Matt Ginsberg — a serial entrepreneur, pioneering AI researcher and former research professor — scored higher than any humans earlier this year at the American Crossword Puzzle Tournament.

Ginsberg spoke with NVIDIA AI Podcast host Noah Kravitz about his decade-long journey creating Dr.Fill and where he envisions it going in the future.

https://blogs.nvidia.com/blog/2021/07/28/matt-ginsberg-ai-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[Following a long string of victories for computers in other games — chess in 1997, go in 2016 and Texas hold’em poker in 2019 — a GPU-powered AI has beaten some of the world’s most competitive word nerds at the crossword puzzles that are a staple of every Sunday paper.

Dr.Fill, the crossword puzzle-playing AI created by Matt Ginsberg — a serial entrepreneur, pioneering AI researcher and former research professor — scored higher than any humans earlier this year at the American Crossword Puzzle Tournament.

Ginsberg spoke with NVIDIA AI Podcast host Noah Kravitz about his decade-long journey creating Dr.Fill and where he envisions it going in the future.

https://blogs.nvidia.com/blog/2021/07/28/matt-ginsberg-ai-podcast/]]>
      </content:encoded>
      <itunes:duration>1675</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1095310237]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7969103431.mp3?updated=1740586382" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Liila Torabi Talks the New Era of Robotics Through Isaac Sim - Ep. 147</title>
      <link>https://soundcloud.com/theaipodcast/nvidia-liila-torabi</link>
      <description>Robots are not just limited to the assembly line. At NVIDIA, Liila Torabi works on making the next generation of robotics possible. Torabi is the senior product manager for Isaac Sim, a robotics and AI simulation platform powered by NVIDIA Omniverse. Torabi spoke with NVIDIA AI Podcast host Noah Kravitz about the new era of robotics, one driven by making robots smarter through AI.

https://blogs.nvidia.com/blog/2021/07/14/liila-isaac-sim/</description>
      <pubDate>Tue, 13 Jul 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/db1748c4-f45b-11ef-8be6-bf78c5241def/image/510f2c71caa0777d8560b0f0ed1ec49d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Robots are not just limited to the assembly line.…</itunes:subtitle>
      <itunes:summary>Robots are not just limited to the assembly line. At NVIDIA, Liila Torabi works on making the next generation of robotics possible. Torabi is the senior product manager for Isaac Sim, a robotics and AI simulation platform powered by NVIDIA Omniverse. Torabi spoke with NVIDIA AI Podcast host Noah Kravitz about the new era of robotics, one driven by making robots smarter through AI.

https://blogs.nvidia.com/blog/2021/07/14/liila-isaac-sim/</itunes:summary>
      <content:encoded>
        <![CDATA[Robots are not just limited to the assembly line. At NVIDIA, Liila Torabi works on making the next generation of robotics possible. Torabi is the senior product manager for Isaac Sim, a robotics and AI simulation platform powered by NVIDIA Omniverse. Torabi spoke with NVIDIA AI Podcast host Noah Kravitz about the new era of robotics, one driven by making robots smarter through AI.

https://blogs.nvidia.com/blog/2021/07/14/liila-isaac-sim/]]>
      </content:encoded>
      <itunes:duration>1663</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1083569986]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4381359861.mp3?updated=1740586383" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA's Simon Yuen Talks About the Future Horizon of Digital Humans - Ep. 146</title>
      <link>https://soundcloud.com/theaipodcast/audio2face-simon-yuen</link>
      <description>We all know about the applications for digital humans for films and video games, but at NVIDIA, Simon Yuen has discovered the vast need and potential for digital humans beyond the entertainment industry.

Yuen spoke with NVIDIA AI Podcast host Noah Kravitz about how we’re getting to a point where the simulation of digital humans is possible as opposed to just the visual representation.

Yuen leads the Digital Human project at NVIDIA. One of the first products the team is developing is Audio2Face, an AI-based solution that automates high-quality facial animation in real-time, based only on audio as input.

https://blogs.nvidia.com/blog/2021/06/28/simon-audio2face/</description>
      <pubDate>Tue, 29 Jun 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/db73d7e2-f45b-11ef-8be6-c3cfc779c02b/image/52aa31f796798965466ea842b153f504.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We all know about the applications for digital hu…</itunes:subtitle>
      <itunes:summary>We all know about the applications for digital humans for films and video games, but at NVIDIA, Simon Yuen has discovered the vast need and potential for digital humans beyond the entertainment industry.

Yuen spoke with NVIDIA AI Podcast host Noah Kravitz about how we’re getting to a point where the simulation of digital humans is possible as opposed to just the visual representation.

Yuen leads the Digital Human project at NVIDIA. One of the first products the team is developing is Audio2Face, an AI-based solution that automates high-quality facial animation in real-time, based only on audio as input.

https://blogs.nvidia.com/blog/2021/06/28/simon-audio2face/</itunes:summary>
      <content:encoded>
        <![CDATA[We all know about the applications for digital humans for films and video games, but at NVIDIA, Simon Yuen has discovered the vast need and potential for digital humans beyond the entertainment industry.

Yuen spoke with NVIDIA AI Podcast host Noah Kravitz about how we’re getting to a point where the simulation of digital humans is possible as opposed to just the visual representation.

Yuen leads the Digital Human project at NVIDIA. One of the first products the team is developing is Audio2Face, an AI-based solution that automates high-quality facial animation in real-time, based only on audio as input.

https://blogs.nvidia.com/blog/2021/06/28/simon-audio2face/]]>
      </content:encoded>
      <itunes:duration>2061</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1078364350]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2158711731.mp3?updated=1740586383" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Waste Not, Want Not: AI Startup Opseyes Revolutionizes Wastewater Analysis - Ep. 145</title>
      <link>https://soundcloud.com/theaipodcast/ai-opseyes</link>
      <description>What do radiology and wastewater have in common? Hopefully, not much. 

But at startup Opseyes, founder Bryan Arndt and data scientist Robin Schlenga are putting the AI that’s revolutionizing medical imaging to work on analyzing wastewater samples.

Arndt and Schlenga spoke with NVIDIA AI Podcast host Noah Kravitz about the inspiration for Opseyes, which began with Arndt’s career at wastewater industry leader Ramboll. Effluent has typically been analyzed by sending tightly sealed samples through the mail to experts.

While speaking with his brother, a radiologist using deep learning, Arndt realized that AI could do something similar for wastewater samples.

Schlenga then led the creation of Opseyes’ convolutional neural network, which allows customers to upload a photo of a sample taken through a microscope. With Opseyes already in use at several wastewater plants, Arndt and Schlenga anticipate much more bacterial analysis in their future.

https://blogs.nvidia.com/blog/2021/06/16/ai-opseyes-wastewater-analysis/</description>
      <pubDate>Wed, 16 Jun 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dbd09950-f45b-11ef-8be6-47af8bff267a/image/8ce59514e66c6812903e97321266ed80.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>What do radiology and wastewater have in common? …</itunes:subtitle>
      <itunes:summary>What do radiology and wastewater have in common? Hopefully, not much. 

But at startup Opseyes, founder Bryan Arndt and data scientist Robin Schlenga are putting the AI that’s revolutionizing medical imaging to work on analyzing wastewater samples.

Arndt and Schlenga spoke with NVIDIA AI Podcast host Noah Kravitz about the inspiration for Opseyes, which began with Arndt’s career at wastewater industry leader Ramboll. Effluent has typically been analyzed by sending tightly sealed samples through the mail to experts.

While speaking with his brother, a radiologist using deep learning, Arndt realized that AI could do something similar for wastewater samples.

Schlenga then led the creation of Opseyes’ convolutional neural network, which allows customers to upload a photo of a sample taken through a microscope. With Opseyes already in use at several wastewater plants, Arndt and Schlenga anticipate much more bacterial analysis in their future.

https://blogs.nvidia.com/blog/2021/06/16/ai-opseyes-wastewater-analysis/</itunes:summary>
      <content:encoded>
        <![CDATA[What do radiology and wastewater have in common? Hopefully, not much. 

But at startup Opseyes, founder Bryan Arndt and data scientist Robin Schlenga are putting the AI that’s revolutionizing medical imaging to work on analyzing wastewater samples.

Arndt and Schlenga spoke with NVIDIA AI Podcast host Noah Kravitz about the inspiration for Opseyes, which began with Arndt’s career at wastewater industry leader Ramboll. Effluent has typically been analyzed by sending tightly sealed samples through the mail to experts.

While speaking with his brother, a radiologist using deep learning, Arndt realized that AI could do something similar for wastewater samples.

Schlenga then led the creation of Opseyes’ convolutional neural network, which allows customers to upload a photo of a sample taken through a microscope. With Opseyes already in use at several wastewater plants, Arndt and Schlenga anticipate much more bacterial analysis in their future.

https://blogs.nvidia.com/blog/2021/06/16/ai-opseyes-wastewater-analysis/]]>
      </content:encoded>
      <itunes:duration>1955</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1069450864]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7151807959.mp3?updated=1740586384" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Getting Clever with Kaolin: Researchers Accelerate 3D Deep Learning with New Tools - Ep. 144</title>
      <link>https://soundcloud.com/theaipodcast/kaolin</link>
      <description>3D deep learning holds the potential to accelerate progress in everything from robotics to medical imaging. But until now, researchers haven’t had the right tools to easily manage and visualize different types of 3D data.

NVIDIA Kaolin is a collection of tools within the NVIDIA Omniverse simulation and collaboration platform that allows researchers to visualize and generate datasets, move between 3D tools and retain basic functions for other users.

NVIDIA AI Podcast host Noah Kravitz spoke with four NVIDIANs about their work on the platform, including Richard Kerris, industry general manager for Omniverse; Jean-Francois Lafleche, a deep learning engineer; Senior Research Scientist Masha Shugrina; and Research Scientist Clement Fuji Tsang.

Kaolin includes both a library, which contains a growing number of GPU-optimized operations, and an app within NVIDIA Omniverse for interactive 3D data visualizations. The long-term goal is to make both facets so robust that users could import a photo that generates a highly developed 3D model without spending time on recreating the scene within a 3D platform.

https://blogs.nvidia.com/blog/2021/06/02/kaolin-podcast/</description>
      <pubDate>Tue, 01 Jun 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dc30247e-f45b-11ef-8be6-ab510a3f668a/image/b0ebcc2c2fd775810ea8299763d24203.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>3D deep learning holds the potential to accelerat…</itunes:subtitle>
      <itunes:summary>3D deep learning holds the potential to accelerate progress in everything from robotics to medical imaging. But until now, researchers haven’t had the right tools to easily manage and visualize different types of 3D data.

NVIDIA Kaolin is a collection of tools within the NVIDIA Omniverse simulation and collaboration platform that allows researchers to visualize and generate datasets, move between 3D tools and retain basic functions for other users.

NVIDIA AI Podcast host Noah Kravitz spoke with four NVIDIANs about their work on the platform, including Richard Kerris, industry general manager for Omniverse; Jean-Francois Lafleche, a deep learning engineer; Senior Research Scientist Masha Shugrina; and Research Scientist Clement Fuji Tsang.

Kaolin includes both a library, which contains a growing number of GPU-optimized operations, and an app within NVIDIA Omniverse for interactive 3D data visualizations. The long-term goal is to make both facets so robust that users could import a photo that generates a highly developed 3D model without spending time on recreating the scene within a 3D platform.

https://blogs.nvidia.com/blog/2021/06/02/kaolin-podcast/</itunes:summary>
      <content:encoded>
        <![CDATA[3D deep learning holds the potential to accelerate progress in everything from robotics to medical imaging. But until now, researchers haven’t had the right tools to easily manage and visualize different types of 3D data.

NVIDIA Kaolin is a collection of tools within the NVIDIA Omniverse simulation and collaboration platform that allows researchers to visualize and generate datasets, move between 3D tools and retain basic functions for other users.

NVIDIA AI Podcast host Noah Kravitz spoke with four NVIDIANs about their work on the platform, including Richard Kerris, industry general manager for Omniverse; Jean-Francois Lafleche, a deep learning engineer; Senior Research Scientist Masha Shugrina; and Research Scientist Clement Fuji Tsang.

Kaolin includes both a library, which contains a growing number of GPU-optimized operations, and an app within NVIDIA Omniverse for interactive 3D data visualizations. The long-term goal is to make both facets so robust that users could import a photo that generates a highly developed 3D model without spending time on recreating the scene within a 3D platform.

https://blogs.nvidia.com/blog/2021/06/02/kaolin-podcast/]]>
      </content:encoded>
      <itunes:duration>1413</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1060251388]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3654541804.mp3?updated=1740586384" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI Researcher James Kahn Explains Deep Learning’s Collision Course with Particle Physics - Ep. 143</title>
      <link>https://soundcloud.com/theaipodcast/ai-researcher-james-kahn-deep-learnings-particle-physics</link>
      <description>For a particle physicist, the world’s biggest questions — how did the universe originate and what’s beyond it — can only be answered with help from the world’s smallest building blocks.

James Kahn, a consultant with German research platform Helmholtz AI and a collaborator on the global Belle II particle physics experiment, uses deep learning to understand the fundamental rules governing particle decay.

Kahn spoke with AI Podcast host Noah Kravitz about the specifics of how AI is accelerating particle physics. 

He also touched on his work at Helmholtz AI. Khan helps researchers in fields spanning medicine to earth sciences apply AI to the problems they’re solving. His wide-ranging career — from particle physicist to computer scientist — shows how AI accelerates every industry.

https://blogs.nvidia.com/blog/2021/05/19/ai-particle-physics/</description>
      <pubDate>Wed, 19 May 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dc8c9fc4-f45b-11ef-8be6-a772e056dfcd/image/832e6dd8823865f90de9bdc3e57d8074.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>For a particle physicist, the world’s biggest que…</itunes:subtitle>
      <itunes:summary>For a particle physicist, the world’s biggest questions — how did the universe originate and what’s beyond it — can only be answered with help from the world’s smallest building blocks.

James Kahn, a consultant with German research platform Helmholtz AI and a collaborator on the global Belle II particle physics experiment, uses deep learning to understand the fundamental rules governing particle decay.

Kahn spoke with AI Podcast host Noah Kravitz about the specifics of how AI is accelerating particle physics. 

He also touched on his work at Helmholtz AI. Khan helps researchers in fields spanning medicine to earth sciences apply AI to the problems they’re solving. His wide-ranging career — from particle physicist to computer scientist — shows how AI accelerates every industry.

https://blogs.nvidia.com/blog/2021/05/19/ai-particle-physics/</itunes:summary>
      <content:encoded>
        <![CDATA[For a particle physicist, the world’s biggest questions — how did the universe originate and what’s beyond it — can only be answered with help from the world’s smallest building blocks.

James Kahn, a consultant with German research platform Helmholtz AI and a collaborator on the global Belle II particle physics experiment, uses deep learning to understand the fundamental rules governing particle decay.

Kahn spoke with AI Podcast host Noah Kravitz about the specifics of how AI is accelerating particle physics. 

He also touched on his work at Helmholtz AI. Khan helps researchers in fields spanning medicine to earth sciences apply AI to the problems they’re solving. His wide-ranging career — from particle physicist to computer scientist — shows how AI accelerates every industry.

https://blogs.nvidia.com/blog/2021/05/19/ai-particle-physics/]]>
      </content:encoded>
      <itunes:duration>1375</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1051541071]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1560138828.mp3?updated=1740586385" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Walmart’s Grant Gelvin on Prediction Analytics at Supercenter Scale - Ep. 142</title>
      <link>https://soundcloud.com/theaipodcast/walmarts-prediction-analytics</link>
      <description>With only one U.S. state without a Walmart supercenter — and over 4,600 stores across the country — the retail giant’s prediction analytics work with data on an enormous scale.

Grant Gelven, a machine learning engineer at Walmart Global Tech, joined NVIDIA AI Podcast host Noah Kravitz for the latest episode of the AI Podcast. 

Gelven spoke about the big data and machine learning methods making it possible to improve everything from the customer experience to stocking to item pricing.

https://blogs.nvidia.com/blog/2021/05/05/ai-walmart/</description>
      <pubDate>Wed, 05 May 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dce9cdca-f45b-11ef-8be6-fbc351ea8094/image/37bd731c45e201799753a761c008ab6c.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>With only one U.S. state without a Walmart superc…</itunes:subtitle>
      <itunes:summary>With only one U.S. state without a Walmart supercenter — and over 4,600 stores across the country — the retail giant’s prediction analytics work with data on an enormous scale.

Grant Gelven, a machine learning engineer at Walmart Global Tech, joined NVIDIA AI Podcast host Noah Kravitz for the latest episode of the AI Podcast. 

Gelven spoke about the big data and machine learning methods making it possible to improve everything from the customer experience to stocking to item pricing.

https://blogs.nvidia.com/blog/2021/05/05/ai-walmart/</itunes:summary>
      <content:encoded>
        <![CDATA[With only one U.S. state without a Walmart supercenter — and over 4,600 stores across the country — the retail giant’s prediction analytics work with data on an enormous scale.

Grant Gelven, a machine learning engineer at Walmart Global Tech, joined NVIDIA AI Podcast host Noah Kravitz for the latest episode of the AI Podcast. 

Gelven spoke about the big data and machine learning methods making it possible to improve everything from the customer experience to stocking to item pricing.

https://blogs.nvidia.com/blog/2021/05/05/ai-walmart/]]>
      </content:encoded>
      <itunes:duration>1374</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1042831483]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9841835320.mp3?updated=1740586386" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Julie Bernauer Talks Setting Up One of World’s Fastest Supercomputers - Ep. 141</title>
      <link>https://soundcloud.com/theaipodcast/nvidias-julie-bernauer-ep-141</link>
      <description>Julie Bernauer — senior solutions architect for machine learning and deep learning at NVIDIA — led the small team that successfully built Selene, the world’s fifth-fastest supercomputer.

Adding to an already impressive feat, Bernauer’s team brought up Selene as the world went into lockdown in early 2020. They used skeleton crews, social distancing protocols, and remote cable validation to achieve what typically takes months with a larger install team in a few weeks.

Bernauer told NVIDIA AI Podcast host Noah Kravitz about the goal in creating Selene, which was primarily to support NVIDIA’s researchers. Referencing her time as a doctoral student, Bernauer explains how researchers are often prevented from working on larger models due to expense and infrastructure.

With Selene, the infrastructure is modular and can be scaled up or down depending on what users require, and allows for different types of research to be performed simultaneously. Bernauer said that Selene is proving most useful to autonomous vehicle and language modeling research at the moment.

Going forward, Bernauer envisions some of the power and efficiency of systems like Selene becoming more available on widely accessible devices, such as laptops or edge products such as cars.</description>
      <pubDate>Wed, 21 Apr 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dd47652a-f45b-11ef-8be6-3b3a0a31e053/image/c3e8a1c1e70781ea89075b834112e705.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Julie Bernauer — senior solutions architect for m…</itunes:subtitle>
      <itunes:summary>Julie Bernauer — senior solutions architect for machine learning and deep learning at NVIDIA — led the small team that successfully built Selene, the world’s fifth-fastest supercomputer.

Adding to an already impressive feat, Bernauer’s team brought up Selene as the world went into lockdown in early 2020. They used skeleton crews, social distancing protocols, and remote cable validation to achieve what typically takes months with a larger install team in a few weeks.

Bernauer told NVIDIA AI Podcast host Noah Kravitz about the goal in creating Selene, which was primarily to support NVIDIA’s researchers. Referencing her time as a doctoral student, Bernauer explains how researchers are often prevented from working on larger models due to expense and infrastructure.

With Selene, the infrastructure is modular and can be scaled up or down depending on what users require, and allows for different types of research to be performed simultaneously. Bernauer said that Selene is proving most useful to autonomous vehicle and language modeling research at the moment.

Going forward, Bernauer envisions some of the power and efficiency of systems like Selene becoming more available on widely accessible devices, such as laptops or edge products such as cars.</itunes:summary>
      <content:encoded>
        <![CDATA[Julie Bernauer — senior solutions architect for machine learning and deep learning at NVIDIA — led the small team that successfully built Selene, the world’s fifth-fastest supercomputer.

Adding to an already impressive feat, Bernauer’s team brought up Selene as the world went into lockdown in early 2020. They used skeleton crews, social distancing protocols, and remote cable validation to achieve what typically takes months with a larger install team in a few weeks.

Bernauer told NVIDIA AI Podcast host Noah Kravitz about the goal in creating Selene, which was primarily to support NVIDIA’s researchers. Referencing her time as a doctoral student, Bernauer explains how researchers are often prevented from working on larger models due to expense and infrastructure.

With Selene, the infrastructure is modular and can be scaled up or down depending on what users require, and allows for different types of research to be performed simultaneously. Bernauer said that Selene is proving most useful to autonomous vehicle and language modeling research at the moment.

Going forward, Bernauer envisions some of the power and efficiency of systems like Selene becoming more available on widely accessible devices, such as laptops or edge products such as cars.]]>
      </content:encoded>
      <itunes:duration>1783</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1033656982]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2792257173.mp3?updated=1740586386" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Shalini De Mello Talks Self-Supervised AI, NeurIPS Successes - Ep. 140</title>
      <link>https://soundcloud.com/theaipodcast/nvidias-shalini-de-mello-talks-self-supervised-ai-neurips-successes-ep-xxx</link>
      <description>Shalini De Mello, a principal research scientist at NVIDIA who’s made her mark inventing computer vision technology that contributes to driver safety, finished 2020 with a bang — presenting two posters at the prestigious NeurIPS conference in December.

A 10-year NVIDIA veteran, De Mello works on self-supervised and few-shot learning, 3D reconstruction, viewpoint estimation and human-computer interaction. 

She told NVIDIA AI Podcast host Noah Kravitz about her NeurIPS submissions on reconstructing 3D meshes and self-learning transformations for improving head and gaze redirection — both significant challenges for computer vision.

https://blogs.nvidia.com/blog/2021/04/07/nvidia-research-shalini-de-mello/</description>
      <pubDate>Wed, 07 Apr 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dda3f7f4-f45b-11ef-8be6-7be4c45d608e/image/dfc7e4d3255a94169dd8f11543343677.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Shalini De Mello, a principal research scientist …</itunes:subtitle>
      <itunes:summary>Shalini De Mello, a principal research scientist at NVIDIA who’s made her mark inventing computer vision technology that contributes to driver safety, finished 2020 with a bang — presenting two posters at the prestigious NeurIPS conference in December.

A 10-year NVIDIA veteran, De Mello works on self-supervised and few-shot learning, 3D reconstruction, viewpoint estimation and human-computer interaction. 

She told NVIDIA AI Podcast host Noah Kravitz about her NeurIPS submissions on reconstructing 3D meshes and self-learning transformations for improving head and gaze redirection — both significant challenges for computer vision.

https://blogs.nvidia.com/blog/2021/04/07/nvidia-research-shalini-de-mello/</itunes:summary>
      <content:encoded>
        <![CDATA[Shalini De Mello, a principal research scientist at NVIDIA who’s made her mark inventing computer vision technology that contributes to driver safety, finished 2020 with a bang — presenting two posters at the prestigious NeurIPS conference in December.

A 10-year NVIDIA veteran, De Mello works on self-supervised and few-shot learning, 3D reconstruction, viewpoint estimation and human-computer interaction. 

She told NVIDIA AI Podcast host Noah Kravitz about her NeurIPS submissions on reconstructing 3D meshes and self-learning transformations for improving head and gaze redirection — both significant challenges for computer vision.

https://blogs.nvidia.com/blog/2021/04/07/nvidia-research-shalini-de-mello/]]>
      </content:encoded>
      <itunes:duration>2132</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1024629535]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4925855361.mp3?updated=1740586387" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Drum Roll, Please: AI Startup Sunhouse Founder Tlacael Esparza Finds His Rhythm - Ep. 139</title>
      <link>https://soundcloud.com/theaipodcast/ai-tlacael-esparza</link>
      <description>Drawing on his trifecta of degrees in math, music and music technology, Tlacael Esparza, co-founder and CTO of Sunhouse, is revolutionizing electronic drumming.

Esparza has created Sensory Percussion, a combination of hardware and software that uses sensors and AI to allow a single drum to produce a complex range of sounds depending on where and how the musician hits it.

In the latest installment of the NVIDIA AI Podcast, Esparza spoke with host Noah Kravitz about the tech behind the tool, and what inspired him to create Sunhouse. Esparza has been doing drumstick tricks of his own for many years — prior to founding Sunhouse, he toured with a variety of bands and recorded drums for many albums.

Esparza’s musical skill and programming knowledge formed the basis for Sensory Percussion. Partnering with his brother, Tenoch, and with support from a New York University startup accelerator, Sunhouse was born in 2014.

Since then, it’s become successful with live performers. Esparza is especially proud of its popularity in the New York jazz community and among drumming legends like Marcus Gilmore and Wilco’s Glenn Kotche.

https://blogs.nvidia.com/blog/2021/03/31/sunhouse-tlacael-esparza/</description>
      <pubDate>Wed, 31 Mar 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/de042c82-f45b-11ef-8be6-03c1b1dd60a9/image/063ae34b585ab913978b69b42e08c5f8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Drawing on his trifecta of degrees in math, music…</itunes:subtitle>
      <itunes:summary>Drawing on his trifecta of degrees in math, music and music technology, Tlacael Esparza, co-founder and CTO of Sunhouse, is revolutionizing electronic drumming.

Esparza has created Sensory Percussion, a combination of hardware and software that uses sensors and AI to allow a single drum to produce a complex range of sounds depending on where and how the musician hits it.

In the latest installment of the NVIDIA AI Podcast, Esparza spoke with host Noah Kravitz about the tech behind the tool, and what inspired him to create Sunhouse. Esparza has been doing drumstick tricks of his own for many years — prior to founding Sunhouse, he toured with a variety of bands and recorded drums for many albums.

Esparza’s musical skill and programming knowledge formed the basis for Sensory Percussion. Partnering with his brother, Tenoch, and with support from a New York University startup accelerator, Sunhouse was born in 2014.

Since then, it’s become successful with live performers. Esparza is especially proud of its popularity in the New York jazz community and among drumming legends like Marcus Gilmore and Wilco’s Glenn Kotche.

https://blogs.nvidia.com/blog/2021/03/31/sunhouse-tlacael-esparza/</itunes:summary>
      <content:encoded>
        <![CDATA[Drawing on his trifecta of degrees in math, music and music technology, Tlacael Esparza, co-founder and CTO of Sunhouse, is revolutionizing electronic drumming.

Esparza has created Sensory Percussion, a combination of hardware and software that uses sensors and AI to allow a single drum to produce a complex range of sounds depending on where and how the musician hits it.

In the latest installment of the NVIDIA AI Podcast, Esparza spoke with host Noah Kravitz about the tech behind the tool, and what inspired him to create Sunhouse. Esparza has been doing drumstick tricks of his own for many years — prior to founding Sunhouse, he toured with a variety of bands and recorded drums for many albums.

Esparza’s musical skill and programming knowledge formed the basis for Sensory Percussion. Partnering with his brother, Tenoch, and with support from a New York University startup accelerator, Sunhouse was born in 2014.

Since then, it’s become successful with live performers. Esparza is especially proud of its popularity in the New York jazz community and among drumming legends like Marcus Gilmore and Wilco’s Glenn Kotche.

https://blogs.nvidia.com/blog/2021/03/31/sunhouse-tlacael-esparza/]]>
      </content:encoded>
      <itunes:duration>1923</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1019600446]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9695537518.mp3?updated=1740586388" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Author Cade Metz Talks About His New Book "Genius Makers" - Ep. 138</title>
      <link>https://soundcloud.com/theaipodcast/ai-cade-metz-ep-138</link>
      <description>Call it Moneyball for AI.

In his just released book, "Genius Makers," New York Times writer Cade Metz tells the funny, inspiring — and ultimately triumphant — tale of how a dogged group of AI researchers bet their careers on the long-dismissed technology of deep learning.

https://blogs.nvidia.com/blog/2021/03/17/ai-cade-metz</description>
      <pubDate>Tue, 16 Mar 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/de620514-f45b-11ef-8be6-1fd496ac18ce/image/fc6d5e30a2af205f87ecdb5c22ad5cea.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Call it Moneyball for AI.

In his just released b…</itunes:subtitle>
      <itunes:summary>Call it Moneyball for AI.

In his just released book, "Genius Makers," New York Times writer Cade Metz tells the funny, inspiring — and ultimately triumphant — tale of how a dogged group of AI researchers bet their careers on the long-dismissed technology of deep learning.

https://blogs.nvidia.com/blog/2021/03/17/ai-cade-metz</itunes:summary>
      <content:encoded>
        <![CDATA[Call it Moneyball for AI.

In his just released book, "Genius Makers," New York Times writer Cade Metz tells the funny, inspiring — and ultimately triumphant — tale of how a dogged group of AI researchers bet their careers on the long-dismissed technology of deep learning.

https://blogs.nvidia.com/blog/2021/03/17/ai-cade-metz]]>
      </content:encoded>
      <itunes:duration>2036</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/1004404831]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5421447117.mp3?updated=1740586388" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Marc Hamilton on Building the Cambridge-1 Supercomputer During a Pandemic - Ep. 137</title>
      <link>https://soundcloud.com/theaipodcast/nvidias-marc-hamilton-on-building-the-cambridge-1-supercomputer-during-a-pandemic</link>
      <description>Since NVIDIA announced construction of the U.K.’s most powerful supercomputer — Cambridge-1 — Marc Hamilton, vice president of solutions architecture and engineering, has been (remotely) overseeing its building across the pond.

Cambridge-1, which will be available for U.K. healthcare researchers to work on pressing problems, is being built on NVIDIA DGX SuperPOD architecture for a whopping 400 petaflops of AI performance. Located at KAO Data, a data center using 100% renewable energy, Cambridge-1 will rank among the world’s top 3 most energy-efficient supercomputers on the current Green500 list.

Hamilton points to the concentration of leading healthcare companies in the U.K. as a primary reason for Cambridge-1’s location. AstraZeneca, GSK, Oxford Nanopore and more have already announced their intent to harness the supercomputer for research in the coming months.</description>
      <pubDate>Tue, 02 Mar 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/debf0804-f45b-11ef-8be6-b79c59c35bd7/image/c2b68b1cafffd5f678fceaf7125ced63.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Since NVIDIA announced construction of the U.K.’s…</itunes:subtitle>
      <itunes:summary>Since NVIDIA announced construction of the U.K.’s most powerful supercomputer — Cambridge-1 — Marc Hamilton, vice president of solutions architecture and engineering, has been (remotely) overseeing its building across the pond.

Cambridge-1, which will be available for U.K. healthcare researchers to work on pressing problems, is being built on NVIDIA DGX SuperPOD architecture for a whopping 400 petaflops of AI performance. Located at KAO Data, a data center using 100% renewable energy, Cambridge-1 will rank among the world’s top 3 most energy-efficient supercomputers on the current Green500 list.

Hamilton points to the concentration of leading healthcare companies in the U.K. as a primary reason for Cambridge-1’s location. AstraZeneca, GSK, Oxford Nanopore and more have already announced their intent to harness the supercomputer for research in the coming months.</itunes:summary>
      <content:encoded>
        <![CDATA[Since NVIDIA announced construction of the U.K.’s most powerful supercomputer — Cambridge-1 — Marc Hamilton, vice president of solutions architecture and engineering, has been (remotely) overseeing its building across the pond.

Cambridge-1, which will be available for U.K. healthcare researchers to work on pressing problems, is being built on NVIDIA DGX SuperPOD architecture for a whopping 400 petaflops of AI performance. Located at KAO Data, a data center using 100% renewable energy, Cambridge-1 will rank among the world’s top 3 most energy-efficient supercomputers on the current Green500 list.

Hamilton points to the concentration of leading healthcare companies in the U.K. as a primary reason for Cambridge-1’s location. AstraZeneca, GSK, Oxford Nanopore and more have already announced their intent to harness the supercomputer for research in the coming months.]]>
      </content:encoded>
      <itunes:duration>1623</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/990956506]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2217956075.mp3?updated=1740586389" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Miracle Qure: Founder Pooja Rao Talks Medical Technology at Qure.ai - Ep. 136</title>
      <link>https://soundcloud.com/theaipodcast/qure-pooja-rao</link>
      <description>Pooja Rao, a doctor, data scientist and entrepreneur, wants to make cutting-edge medical care available to communities around the world, regardless of their resources. Her startup, Qure.ai, is doing exactly that, with technology that’s used in 150+ healthcare facilities in 27 countries.

Rao is the cofounder and head of research and development at the Mumbai-based company, which started in 2016. The company develops AI technology that interprets medical images, with a focus on pulmonary and neurological scans.

https://blogs.nvidia.com/blog/2021/02/18/pooja-rao-qure-ai/</description>
      <pubDate>Thu, 18 Feb 2021 14:00:25 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/df1dc024-f45b-11ef-8be6-031a7944165b/image/2fa84608e41abd9f4f49f3c31d512e37.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Pooja Rao, a doctor, data scientist and entrepren…</itunes:subtitle>
      <itunes:summary>Pooja Rao, a doctor, data scientist and entrepreneur, wants to make cutting-edge medical care available to communities around the world, regardless of their resources. Her startup, Qure.ai, is doing exactly that, with technology that’s used in 150+ healthcare facilities in 27 countries.

Rao is the cofounder and head of research and development at the Mumbai-based company, which started in 2016. The company develops AI technology that interprets medical images, with a focus on pulmonary and neurological scans.

https://blogs.nvidia.com/blog/2021/02/18/pooja-rao-qure-ai/</itunes:summary>
      <content:encoded>
        <![CDATA[Pooja Rao, a doctor, data scientist and entrepreneur, wants to make cutting-edge medical care available to communities around the world, regardless of their resources. Her startup, Qure.ai, is doing exactly that, with technology that’s used in 150+ healthcare facilities in 27 countries.

Rao is the cofounder and head of research and development at the Mumbai-based company, which started in 2016. The company develops AI technology that interprets medical images, with a focus on pulmonary and neurological scans.

https://blogs.nvidia.com/blog/2021/02/18/pooja-rao-qure-ai/]]>
      </content:encoded>
      <itunes:duration>1722</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/987707857]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1562002325.mp3?updated=1740586389" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Making Machines More Human: Best-Selling Author Brian Christian on the Alignment Problem - Ep. 135</title>
      <link>https://soundcloud.com/theaipodcast/making-machines-more-human-author-brian-christian-talks-the-alignment-problem</link>
      <description>Not many can claim to be a computer programmer, nonfiction author and poet, but Brian Christian has established himself as all three.

Christian has just released his newest book, The Alignment Problem, which delves into the disparity that occurs when AI models don’t do exactly what they’re intended to do. 

The book follows on the success of Christian’s previous work, "The Most Human Human and Algorithms to Live By." Now a visiting scholar at UC Berkeley, Christian joined AI Podcast host Noah Kravitz to talk about the alignment problem and some new techniques being used to address the issue.

The alignment problem can be caused by a range of reasons — such as data bias, or datasets used incorrectly and out of context. As AI takes on a variety of tasks, from medical diagnostics to parole sentencing decisions, machine learning researchers are expressing concern over the problem.

Listen to the full podcast to hear about this and more — including Christian’s book club experience with Elon Musk and why he chose to double major in philosophy and computer science.</description>
      <pubDate>Mon, 01 Feb 2021 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/df79f7c2-f45b-11ef-8be6-0b4128da6313/image/fa0299d4ba0d65c8179d97b63c825c34.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Not many can claim to be a computer programmer, n…</itunes:subtitle>
      <itunes:summary>Not many can claim to be a computer programmer, nonfiction author and poet, but Brian Christian has established himself as all three.

Christian has just released his newest book, The Alignment Problem, which delves into the disparity that occurs when AI models don’t do exactly what they’re intended to do. 

The book follows on the success of Christian’s previous work, "The Most Human Human and Algorithms to Live By." Now a visiting scholar at UC Berkeley, Christian joined AI Podcast host Noah Kravitz to talk about the alignment problem and some new techniques being used to address the issue.

The alignment problem can be caused by a range of reasons — such as data bias, or datasets used incorrectly and out of context. As AI takes on a variety of tasks, from medical diagnostics to parole sentencing decisions, machine learning researchers are expressing concern over the problem.

Listen to the full podcast to hear about this and more — including Christian’s book club experience with Elon Musk and why he chose to double major in philosophy and computer science.</itunes:summary>
      <content:encoded>
        <![CDATA[Not many can claim to be a computer programmer, nonfiction author and poet, but Brian Christian has established himself as all three.

Christian has just released his newest book, The Alignment Problem, which delves into the disparity that occurs when AI models don’t do exactly what they’re intended to do. 

The book follows on the success of Christian’s previous work, "The Most Human Human and Algorithms to Live By." Now a visiting scholar at UC Berkeley, Christian joined AI Podcast host Noah Kravitz to talk about the alignment problem and some new techniques being used to address the issue.

The alignment problem can be caused by a range of reasons — such as data bias, or datasets used incorrectly and out of context. As AI takes on a variety of tasks, from medical diagnostics to parole sentencing decisions, machine learning researchers are expressing concern over the problem.

Listen to the full podcast to hear about this and more — including Christian’s book club experience with Elon Musk and why he chose to double major in philosophy and computer science.]]>
      </content:encoded>
      <itunes:duration>2107</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/977995255]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6697057652.mp3?updated=1740586390" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Otter.ai CEO Sam Liang on Bringing Live Captions to a Meeting Near You - Ep. 134</title>
      <link>https://soundcloud.com/theaipodcast/ai-sam-liang-otter-ai</link>
      <description>Sam Liang is making things easier for the creators of the NVIDIA AI Podcast — and just about every remote worker.

He’s the CEO and co-founder of Otter.ai, which uses AI to produce speech-to-text transcriptions in real time or from recording uploads. The platform has a range of capabilities, from differentiating between multiple people, to understanding accents, to parsing through various background noises.

And now, Otter.ai is making live captioning possible on a variety of platforms, including Zoom, Skype and Microsoft Teams. Even Liang’s conversation with AI Podcast host Noah Kravitz was captioned in real time over Skype.

This new capability has been enthusiastically received by remote workers — Liang says that Otter.ai has already transcribed tens of millions of meetings.

Liang envisions even more practical effects of Otter.ai’s live captions. The platform can already identify keywords. Soon he thinks it’ll be recognizing action items, helping manage agendas and providing notifications.

https://blogs.nvidia.com/blog/2021/01/21/otter-ai-sam-liang/</description>
      <pubDate>Thu, 21 Jan 2021 14:00:29 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/dfd9899e-f45b-11ef-8be6-979a6ff5f08b/image/a6e907500dce99f53b1efbe8178c5ffc.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Sam Liang is making things easier for the creator…</itunes:subtitle>
      <itunes:summary>Sam Liang is making things easier for the creators of the NVIDIA AI Podcast — and just about every remote worker.

He’s the CEO and co-founder of Otter.ai, which uses AI to produce speech-to-text transcriptions in real time or from recording uploads. The platform has a range of capabilities, from differentiating between multiple people, to understanding accents, to parsing through various background noises.

And now, Otter.ai is making live captioning possible on a variety of platforms, including Zoom, Skype and Microsoft Teams. Even Liang’s conversation with AI Podcast host Noah Kravitz was captioned in real time over Skype.

This new capability has been enthusiastically received by remote workers — Liang says that Otter.ai has already transcribed tens of millions of meetings.

Liang envisions even more practical effects of Otter.ai’s live captions. The platform can already identify keywords. Soon he thinks it’ll be recognizing action items, helping manage agendas and providing notifications.

https://blogs.nvidia.com/blog/2021/01/21/otter-ai-sam-liang/</itunes:summary>
      <content:encoded>
        <![CDATA[Sam Liang is making things easier for the creators of the NVIDIA AI Podcast — and just about every remote worker.

He’s the CEO and co-founder of Otter.ai, which uses AI to produce speech-to-text transcriptions in real time or from recording uploads. The platform has a range of capabilities, from differentiating between multiple people, to understanding accents, to parsing through various background noises.

And now, Otter.ai is making live captioning possible on a variety of platforms, including Zoom, Skype and Microsoft Teams. Even Liang’s conversation with AI Podcast host Noah Kravitz was captioned in real time over Skype.

This new capability has been enthusiastically received by remote workers — Liang says that Otter.ai has already transcribed tens of millions of meetings.

Liang envisions even more practical effects of Otter.ai’s live captions. The platform can already identify keywords. Soon he thinks it’ll be recognizing action items, helping manage agendas and providing notifications.

https://blogs.nvidia.com/blog/2021/01/21/otter-ai-sam-liang/]]>
      </content:encoded>
      <itunes:duration>1451</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/969753745]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1958434634.mp3?updated=1740586391" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>On the Clock: High School Junior Ana DuCristea Creates Timely AI-based Reminder App - Ep. 133</title>
      <link>https://soundcloud.com/theaipodcast/on-the-clock-high-school-junior-ana-ducristea-creates-timely-ai-based-reminder-app-ep-133</link>
      <description>Canadian high schooler Ana DuCristea has a clever solution for the quarantine blues, as days blur into weeks. Using AI and natural language processing, she programmed an app capable of setting customizable reminders so you won’t miss any important activities, like baking banana bread or whipping up Dalgona coffee.

DuCristea, who’s familiar with Python and has taken a variety of online AI courses, set to work on the app after winning a Jetson Nano Developer Kit this summer at AI4ALL, an AI summer camp. She’d long been frustrated with the simplicity of current reminder apps and decided to create her own solution.

Using Python and the Nano, DuCristea developed an app in just two months that integrates with mobile and PC messaging program Discord. With the app, users can message a bot on Discord requesting a reminder for a specific task, date and time.</description>
      <pubDate>Wed, 06 Jan 2021 14:00:24 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e0364706-f45b-11ef-8be6-2fa35b9bd341/image/2b9c095f6937b605aa850659689a6f53.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Canadian high schooler Ana DuCristea has a clever…</itunes:subtitle>
      <itunes:summary>Canadian high schooler Ana DuCristea has a clever solution for the quarantine blues, as days blur into weeks. Using AI and natural language processing, she programmed an app capable of setting customizable reminders so you won’t miss any important activities, like baking banana bread or whipping up Dalgona coffee.

DuCristea, who’s familiar with Python and has taken a variety of online AI courses, set to work on the app after winning a Jetson Nano Developer Kit this summer at AI4ALL, an AI summer camp. She’d long been frustrated with the simplicity of current reminder apps and decided to create her own solution.

Using Python and the Nano, DuCristea developed an app in just two months that integrates with mobile and PC messaging program Discord. With the app, users can message a bot on Discord requesting a reminder for a specific task, date and time.</itunes:summary>
      <content:encoded>
        <![CDATA[Canadian high schooler Ana DuCristea has a clever solution for the quarantine blues, as days blur into weeks. Using AI and natural language processing, she programmed an app capable of setting customizable reminders so you won’t miss any important activities, like baking banana bread or whipping up Dalgona coffee.

DuCristea, who’s familiar with Python and has taken a variety of online AI courses, set to work on the app after winning a Jetson Nano Developer Kit this summer at AI4ALL, an AI summer camp. She’d long been frustrated with the simplicity of current reminder apps and decided to create her own solution.

Using Python and the Nano, DuCristea developed an app in just two months that integrates with mobile and PC messaging program Discord. With the app, users can message a bot on Discord requesting a reminder for a specific task, date and time.]]>
      </content:encoded>
      <itunes:duration>1333</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/960284578]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8291532447.mp3?updated=1740586391" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Hey, Mr. DJ: Super Hi-Fi’s AI Applies Smarts to Sound - Ep. 132</title>
      <link>https://soundcloud.com/theaipodcast/ai-brendon-cassidy-super-hifi</link>
      <description>Brendon Cassidy, CTO and chief scientist at Super Hi-Fi, uses AI to give everyone the experience of a radio station tailored to their unique tastes.

Super Hi-Fi, an AI startup and member of the NVIDIA Inception program, develops technology that produces smooth transitions, intersperses content meaningfully and adjusts volume and crossfade. Started three years ago, Super Hi-Fi first partnered with iHeartRadio and is now also used by companies such as Peloton and Sonos.

Results are showing that users like this personalized approach. Cassidy notes that they tested MagicStitch, one of their tools that eliminates the gap between songs, and found that customers listening with MagicStitch turned on spent 10 percent more time streaming music.

 https://blogs.nvidia.com/blog/2020/12/23/super-hifi-ai/</description>
      <pubDate>Wed, 23 Dec 2020 14:00:18 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e095e0b2-f45b-11ef-8be6-0be3b0b11413/image/a5a0a743d266d7d45bb4ad75b0433dd5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Brendon Cassidy, CTO and chief scientist at Super…</itunes:subtitle>
      <itunes:summary>Brendon Cassidy, CTO and chief scientist at Super Hi-Fi, uses AI to give everyone the experience of a radio station tailored to their unique tastes.

Super Hi-Fi, an AI startup and member of the NVIDIA Inception program, develops technology that produces smooth transitions, intersperses content meaningfully and adjusts volume and crossfade. Started three years ago, Super Hi-Fi first partnered with iHeartRadio and is now also used by companies such as Peloton and Sonos.

Results are showing that users like this personalized approach. Cassidy notes that they tested MagicStitch, one of their tools that eliminates the gap between songs, and found that customers listening with MagicStitch turned on spent 10 percent more time streaming music.

 https://blogs.nvidia.com/blog/2020/12/23/super-hifi-ai/</itunes:summary>
      <content:encoded>
        <![CDATA[Brendon Cassidy, CTO and chief scientist at Super Hi-Fi, uses AI to give everyone the experience of a radio station tailored to their unique tastes.

Super Hi-Fi, an AI startup and member of the NVIDIA Inception program, develops technology that produces smooth transitions, intersperses content meaningfully and adjusts volume and crossfade. Started three years ago, Super Hi-Fi first partnered with iHeartRadio and is now also used by companies such as Peloton and Sonos.

Results are showing that users like this personalized approach. Cassidy notes that they tested MagicStitch, one of their tools that eliminates the gap between songs, and found that customers listening with MagicStitch turned on spent 10 percent more time streaming music.

 https://blogs.nvidia.com/blog/2020/12/23/super-hifi-ai/]]>
      </content:encoded>
      <itunes:duration>2163</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/949832608]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2049389098.mp3?updated=1740586392" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Behind the Scenes at NeurIPS with NVIDIA and CalTech’s Anima Anandkumar - Ep. 131</title>
      <link>https://soundcloud.com/theaipodcast/ai-anima-anandkumar</link>
      <description>Anima Anandkumar is setting a personal record this week with seven of her team’s research papers accepted to NeurIPS 2020.

The 34th annual Neural Information Processing Systems conference is taking place virtually from Dec. 6-12. The premier event on neural networks, NeurIPS draws thousands of the world’s best researchers every year.

Anandkumar, NVIDIA’s director of machine learning research and Bren professor at CalTech’s CMS Department, joined AI Podcast host Noah Kravitz to talk about what to expect at the conference, and to explain what she sees as the future of AI.

https://blogs.nvidia.com/blog/2020/12/09/neurips-nvidia-caltech-anima-anandkumar/</description>
      <pubDate>Mon, 07 Dec 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e0f22bce-f45b-11ef-8be6-afa0b413c89e/image/245b60a05b5cfb1bf020f30aeb525cd9.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Anima Anandkumar is setting a personal record thi…</itunes:subtitle>
      <itunes:summary>Anima Anandkumar is setting a personal record this week with seven of her team’s research papers accepted to NeurIPS 2020.

The 34th annual Neural Information Processing Systems conference is taking place virtually from Dec. 6-12. The premier event on neural networks, NeurIPS draws thousands of the world’s best researchers every year.

Anandkumar, NVIDIA’s director of machine learning research and Bren professor at CalTech’s CMS Department, joined AI Podcast host Noah Kravitz to talk about what to expect at the conference, and to explain what she sees as the future of AI.

https://blogs.nvidia.com/blog/2020/12/09/neurips-nvidia-caltech-anima-anandkumar/</itunes:summary>
      <content:encoded>
        <![CDATA[Anima Anandkumar is setting a personal record this week with seven of her team’s research papers accepted to NeurIPS 2020.

The 34th annual Neural Information Processing Systems conference is taking place virtually from Dec. 6-12. The premier event on neural networks, NeurIPS draws thousands of the world’s best researchers every year.

Anandkumar, NVIDIA’s director of machine learning research and Bren professor at CalTech’s CMS Department, joined AI Podcast host Noah Kravitz to talk about what to expect at the conference, and to explain what she sees as the future of AI.

https://blogs.nvidia.com/blog/2020/12/09/neurips-nvidia-caltech-anima-anandkumar/]]>
      </content:encoded>
      <itunes:duration>1820</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/943475032]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3042726412.mp3?updated=1740586392" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Lilt CEO AI Spence Green Is Making More Information Accessible to More People - Ep. 130</title>
      <link>https://soundcloud.com/theaipodcast/ai-lilt-translation-spence-green</link>
      <description>We've got an expert on AI powered translation joining us on the show today. Spence Green is CEO at Lilt, a Silicon Valley based AI-powered enterprise translation software and services company.  Lilt's mission is to make more of the world's information accessible to more of the world's people, regardless of where they were born and what language they speak. Spence is here to talk to us about how they're doing it.</description>
      <pubDate>Tue, 06 Oct 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e14e1a92-f45b-11ef-8be6-4f3e66bb60d0/image/47e95a7c5365aa98a63d109b2116c8d3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We've got an expert on AI powered translation joi…</itunes:subtitle>
      <itunes:summary>We've got an expert on AI powered translation joining us on the show today. Spence Green is CEO at Lilt, a Silicon Valley based AI-powered enterprise translation software and services company.  Lilt's mission is to make more of the world's information accessible to more of the world's people, regardless of where they were born and what language they speak. Spence is here to talk to us about how they're doing it.</itunes:summary>
      <content:encoded>
        <![CDATA[We've got an expert on AI powered translation joining us on the show today. Spence Green is CEO at Lilt, a Silicon Valley based AI-powered enterprise translation software and services company.  Lilt's mission is to make more of the world's information accessible to more of the world's people, regardless of where they were born and what language they speak. Spence is here to talk to us about how they're doing it.]]>
      </content:encoded>
      <itunes:duration>1640</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/907983682]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9403352755.mp3?updated=1740586393" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Art(ificial) Intelligence: Pindar Van Arman Builds Robots that Paint - Ep. 129</title>
      <link>https://soundcloud.com/theaipodcast/pindar-van-arman-ai-robots</link>
      <description>Pindar Van Arman, an American artist and roboticist, designs painting robots that explore the differences between human and computational creativity. Since his first system in 2005 he has built multiple artificially-creative robots. The most famous, Cloud Painter, was awarded first place at Robotart 2018. PIndar, his robots, and their work have been featured all over the media, including on NPR, BBC, HBO, Vice, and the documentary "Machine" a film about artificial intelligence. You can see and learn more about Pindar on his website, cloudpainter.com. In fact, unless you're driving, you should go ahead and load it into your browser right now, so you can look at the art you listen to him talk.

For more from Pindar Van Arman, check out:

http://www.cloudpainter.com
http://www.artonomo.us

And explore his work on NVIDIA's AI Art Gallery:

https://www.nvidia.com/ai-art-gallery/pindar-van-arman</description>
      <pubDate>Thu, 01 Oct 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e1aaeec0-f45b-11ef-8be6-eba789ed6503/image/29a8ddcf1580c77fbce3b968a371bd2f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Pindar Van Arman, an American artist and robotici…</itunes:subtitle>
      <itunes:summary>Pindar Van Arman, an American artist and roboticist, designs painting robots that explore the differences between human and computational creativity. Since his first system in 2005 he has built multiple artificially-creative robots. The most famous, Cloud Painter, was awarded first place at Robotart 2018. PIndar, his robots, and their work have been featured all over the media, including on NPR, BBC, HBO, Vice, and the documentary "Machine" a film about artificial intelligence. You can see and learn more about Pindar on his website, cloudpainter.com. In fact, unless you're driving, you should go ahead and load it into your browser right now, so you can look at the art you listen to him talk.

For more from Pindar Van Arman, check out:

http://www.cloudpainter.com
http://www.artonomo.us

And explore his work on NVIDIA's AI Art Gallery:

https://www.nvidia.com/ai-art-gallery/pindar-van-arman</itunes:summary>
      <content:encoded>
        <![CDATA[Pindar Van Arman, an American artist and roboticist, designs painting robots that explore the differences between human and computational creativity. Since his first system in 2005 he has built multiple artificially-creative robots. The most famous, Cloud Painter, was awarded first place at Robotart 2018. PIndar, his robots, and their work have been featured all over the media, including on NPR, BBC, HBO, Vice, and the documentary "Machine" a film about artificial intelligence. You can see and learn more about Pindar on his website, cloudpainter.com. In fact, unless you're driving, you should go ahead and load it into your browser right now, so you can look at the art you listen to him talk.

For more from Pindar Van Arman, check out:

http://www.cloudpainter.com
http://www.artonomo.us

And explore his work on NVIDIA's AI Art Gallery:

https://www.nvidia.com/ai-art-gallery/pindar-van-arman]]>
      </content:encoded>
      <itunes:duration>2059</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/905915449]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9635493773.mp3?updated=1740586394" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Exploring the AI Startup Ecosystem with NVIDIA Inception’s Jeff Herbst - Ep. 128</title>
      <link>https://soundcloud.com/theaipodcast/ai-nvidia-jeff-herbst</link>
      <description>Jeff Herbst is a fixture of the AI startup ecosystem. Which makes sense since he’s the VP of business development at NVIDIA and head of NVIDIA Inception, a virtual accelerator that currently has over 6,000 members in a wide range of industries.

Ahead of the GPU Technology Conference, taking place Oct. 5-9, Herbst joined AI Podcast host Noah Kravitz to talk about what opportunities are available to startups at the conference, and how NVIDIA Inception is accelerating startups in every industry.

Learn more about NVIDIA Inception at https://www.nvidia.com/en-us/deep-learning-ai/startups/

Follow Jeff Herbst at @jeffatNvdia</description>
      <pubDate>Wed, 23 Sep 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e206dd3e-f45b-11ef-8be6-a73c767e614a/image/1568ab6be6791427380077172c56c918.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Jeff Herbst is a fixture of the AI startup ecosys…</itunes:subtitle>
      <itunes:summary>Jeff Herbst is a fixture of the AI startup ecosystem. Which makes sense since he’s the VP of business development at NVIDIA and head of NVIDIA Inception, a virtual accelerator that currently has over 6,000 members in a wide range of industries.

Ahead of the GPU Technology Conference, taking place Oct. 5-9, Herbst joined AI Podcast host Noah Kravitz to talk about what opportunities are available to startups at the conference, and how NVIDIA Inception is accelerating startups in every industry.

Learn more about NVIDIA Inception at https://www.nvidia.com/en-us/deep-learning-ai/startups/

Follow Jeff Herbst at @jeffatNvdia</itunes:summary>
      <content:encoded>
        <![CDATA[Jeff Herbst is a fixture of the AI startup ecosystem. Which makes sense since he’s the VP of business development at NVIDIA and head of NVIDIA Inception, a virtual accelerator that currently has over 6,000 members in a wide range of industries.

Ahead of the GPU Technology Conference, taking place Oct. 5-9, Herbst joined AI Podcast host Noah Kravitz to talk about what opportunities are available to startups at the conference, and how NVIDIA Inception is accelerating startups in every industry.

Learn more about NVIDIA Inception at https://www.nvidia.com/en-us/deep-learning-ai/startups/

Follow Jeff Herbst at @jeffatNvdia]]>
      </content:encoded>
      <itunes:duration>2034</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/898549855]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8081913555.mp3?updated=1740586394" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA Research's David Luebke on Intersection of Graphics, AI - Ep. 127</title>
      <link>https://soundcloud.com/theaipodcast/nvidia-research-david-luebke</link>
      <description>Today we're talking graphics, the intersection of AI and graphics specifically. There may be no better guest to talk AI and graphics than our guest today, David Luebke. David is vice president of graphics research at NVIDIA. He co-founded NVIDIA Research in 2006, after eight years on the faculty of the University of Virginia.</description>
      <pubDate>Wed, 09 Sep 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e263d822-f45b-11ef-8be6-cf52ccc49670/image/e2e2d9eb359d740e4115b0d4d9b8f273.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Today we're talking graphics, the intersection of…</itunes:subtitle>
      <itunes:summary>Today we're talking graphics, the intersection of AI and graphics specifically. There may be no better guest to talk AI and graphics than our guest today, David Luebke. David is vice president of graphics research at NVIDIA. He co-founded NVIDIA Research in 2006, after eight years on the faculty of the University of Virginia.</itunes:summary>
      <content:encoded>
        <![CDATA[Today we're talking graphics, the intersection of AI and graphics specifically. There may be no better guest to talk AI and graphics than our guest today, David Luebke. David is vice president of graphics research at NVIDIA. He co-founded NVIDIA Research in 2006, after eight years on the faculty of the University of Virginia.]]>
      </content:encoded>
      <itunes:duration>2605</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/891262237]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2878923624.mp3?updated=1740586395" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Picture Perfection: Topaz Labs CTO Albert Yang Will Take Your Snapshots to the Next Level - Ep. 126</title>
      <link>https://soundcloud.com/theaipodcast/ai-albert-yang</link>
      <description>It’s a modern television trope – detectives trying to solve a case “enhance” a blurry image, digitally, giving them a crystal clear image of their suspect. Until recently, this was little more than science fiction. Now, however, it’s a key tool for photographers around the world. Topaz Labs pioneered the intersection of deep learning and photo noise reduction. Their sprawling suite of image editing plugins are relied by pro and amateur photographers alike. We spoke with Topaz founder and CTO, Feng “Albert” Yang, to learn where AI and photography are going next.</description>
      <pubDate>Mon, 31 Aug 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e2ecb67e-f45b-11ef-8be6-738fac1ac6b5/image/791398e77318271235e2d774a1816f21.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>It’s a modern television trope – detectives tryin…</itunes:subtitle>
      <itunes:summary>It’s a modern television trope – detectives trying to solve a case “enhance” a blurry image, digitally, giving them a crystal clear image of their suspect. Until recently, this was little more than science fiction. Now, however, it’s a key tool for photographers around the world. Topaz Labs pioneered the intersection of deep learning and photo noise reduction. Their sprawling suite of image editing plugins are relied by pro and amateur photographers alike. We spoke with Topaz founder and CTO, Feng “Albert” Yang, to learn where AI and photography are going next.</itunes:summary>
      <content:encoded>
        <![CDATA[It’s a modern television trope – detectives trying to solve a case “enhance” a blurry image, digitally, giving them a crystal clear image of their suspect. Until recently, this was little more than science fiction. Now, however, it’s a key tool for photographers around the world. Topaz Labs pioneered the intersection of deep learning and photo noise reduction. Their sprawling suite of image editing plugins are relied by pro and amateur photographers alike. We spoke with Topaz founder and CTO, Feng “Albert” Yang, to learn where AI and photography are going next.]]>
      </content:encoded>
      <itunes:duration>1719</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/886706377]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5398920967.mp3?updated=1740586396" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA Research's Aaron Lefohn on What's Next at Intersection of AI and Computer Graphics – Ep. 125</title>
      <link>https://soundcloud.com/theaipodcast/nvidia-researchs-aaron-lefohn-on-whats-next-at-intersection-of-ai-computer-graphics-ep-125</link>
      <description>It's all come full circle. Real-time graphics technology, namely, GPUs, sparked the modern AI boom. Now modern AI, driven by GPUs, is remaking graphics. This episodes guest is Aaron Lefohn, senior director of realtime rendering research at NVIDIA. Aaron's international team of scientists played a key role in founding the field of AI computer graphics. They were the first to bring AI to real-time computer graphics. They invented key technologies that brought ray tracing to real time computer graphics. Now they're at the forefront of combining AI and ray tracing to rapidly increase the realism of real-time graphics.</description>
      <pubDate>Mon, 24 Aug 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e34a63e6-f45b-11ef-8be6-9b4d6a228484/image/2aba56efeb978472117d35fb6b5f0e7d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>It's all come full circle. Real-time graphics tec…</itunes:subtitle>
      <itunes:summary>It's all come full circle. Real-time graphics technology, namely, GPUs, sparked the modern AI boom. Now modern AI, driven by GPUs, is remaking graphics. This episodes guest is Aaron Lefohn, senior director of realtime rendering research at NVIDIA. Aaron's international team of scientists played a key role in founding the field of AI computer graphics. They were the first to bring AI to real-time computer graphics. They invented key technologies that brought ray tracing to real time computer graphics. Now they're at the forefront of combining AI and ray tracing to rapidly increase the realism of real-time graphics.</itunes:summary>
      <content:encoded>
        <![CDATA[It's all come full circle. Real-time graphics technology, namely, GPUs, sparked the modern AI boom. Now modern AI, driven by GPUs, is remaking graphics. This episodes guest is Aaron Lefohn, senior director of realtime rendering research at NVIDIA. Aaron's international team of scientists played a key role in founding the field of AI computer graphics. They were the first to bring AI to real-time computer graphics. They invented key technologies that brought ray tracing to real time computer graphics. Now they're at the forefront of combining AI and ray tracing to rapidly increase the realism of real-time graphics.]]>
      </content:encoded>
      <itunes:duration>2045</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/880567855]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7841321196.mp3?updated=1740586396" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Hugging Face’s Sam Shleifer Talks Natural Language Processing - Ep. 124</title>
      <link>https://soundcloud.com/theaipodcast/huggingface</link>
      <description>Hugging Face is more than just an adorable emoji — it’s a company that’s demystifying AI by transforming the latest developments in deep learning into usable code for businesses and researchers.

Research engineer Sam Shleifer spoke with AI Podcast host Noah Kravitz about Hugging Face NLP technology, which is in use at over 1,000 companies, including Apple, Bing and Grammarly, across fields ranging from finance to medical technology. 

Hugging Face’s models serve a variety of purposes for their customers, including autocompletion, customer service automation and translation. Their popular web application, Write with Transformer, can even take half-formed thoughts and suggest options for completion.

Shleifer is currently at work developing models that are accessible to everyone, whether they are proficient coders or not. 

In the next few years, Shleifer envisions the continued growth of smaller NLP models that power a wave of chat apps with state-of-the-art translation capabilities.</description>
      <pubDate>Thu, 20 Aug 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e3a5ac4c-f45b-11ef-8be6-cf557bcb5e52/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Hugging Face is more than just an adorable emoji …</itunes:subtitle>
      <itunes:summary>Hugging Face is more than just an adorable emoji — it’s a company that’s demystifying AI by transforming the latest developments in deep learning into usable code for businesses and researchers.

Research engineer Sam Shleifer spoke with AI Podcast host Noah Kravitz about Hugging Face NLP technology, which is in use at over 1,000 companies, including Apple, Bing and Grammarly, across fields ranging from finance to medical technology. 

Hugging Face’s models serve a variety of purposes for their customers, including autocompletion, customer service automation and translation. Their popular web application, Write with Transformer, can even take half-formed thoughts and suggest options for completion.

Shleifer is currently at work developing models that are accessible to everyone, whether they are proficient coders or not. 

In the next few years, Shleifer envisions the continued growth of smaller NLP models that power a wave of chat apps with state-of-the-art translation capabilities.</itunes:summary>
      <content:encoded>
        <![CDATA[Hugging Face is more than just an adorable emoji — it’s a company that’s demystifying AI by transforming the latest developments in deep learning into usable code for businesses and researchers.

Research engineer Sam Shleifer spoke with AI Podcast host Noah Kravitz about Hugging Face NLP technology, which is in use at over 1,000 companies, including Apple, Bing and Grammarly, across fields ranging from finance to medical technology. 

Hugging Face’s models serve a variety of purposes for their customers, including autocompletion, customer service automation and translation. Their popular web application, Write with Transformer, can even take half-formed thoughts and suggest options for completion.

Shleifer is currently at work developing models that are accessible to everyone, whether they are proficient coders or not. 

In the next few years, Shleifer envisions the continued growth of smaller NLP models that power a wave of chat apps with state-of-the-art translation capabilities.]]>
      </content:encoded>
      <itunes:duration>1964</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/879536599]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5483950787.mp3?updated=1740586397" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Here Comes the Sun: NASA Scientists Talk Solar Physics - Ep. 123</title>
      <link>https://soundcloud.com/theaipodcast/deep-learning-key-to-understanding-data-from-latest-scientific-instruments</link>
      <description>Michael Kirk and Raphael Attie, scientists at NASA’s Goddard Space Flight Center, regularly face terabytes of data in their quest to analyze images of the sun. 

This computational challenge, which could take a year or more on a CPU, has been reduced to less than a week on Quadro RTX data science workstations. Kirk and Attie spoke to AI Podcast host Noah Kravitz about the workflow they follow to study these images, and what they hope to find.

The lessons they’ve learned are useful for those in both science and industry grappling with how to best put torrents of data to work.</description>
      <pubDate>Tue, 11 Aug 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e42c0d50-f45b-11ef-8be6-2f3a22aeed3a/image/f83b28ccb92037e1b916c5843145b2ac.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Michael Kirk and Raphael Attie, scientists at NAS…</itunes:subtitle>
      <itunes:summary>Michael Kirk and Raphael Attie, scientists at NASA’s Goddard Space Flight Center, regularly face terabytes of data in their quest to analyze images of the sun. 

This computational challenge, which could take a year or more on a CPU, has been reduced to less than a week on Quadro RTX data science workstations. Kirk and Attie spoke to AI Podcast host Noah Kravitz about the workflow they follow to study these images, and what they hope to find.

The lessons they’ve learned are useful for those in both science and industry grappling with how to best put torrents of data to work.</itunes:summary>
      <content:encoded>
        <![CDATA[Michael Kirk and Raphael Attie, scientists at NASA’s Goddard Space Flight Center, regularly face terabytes of data in their quest to analyze images of the sun. 

This computational challenge, which could take a year or more on a CPU, has been reduced to less than a week on Quadro RTX data science workstations. Kirk and Attie spoke to AI Podcast host Noah Kravitz about the workflow they follow to study these images, and what they hope to find.

The lessons they’ve learned are useful for those in both science and industry grappling with how to best put torrents of data to work.]]>
      </content:encoded>
      <itunes:duration>2609</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/874386253]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9299163360.mp3?updated=1740586398" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>HP’s Jared Dame on How AI, Data Science Driving Demand for Powerful New Workstations - Ep. 122</title>
      <link>https://soundcloud.com/theaipodcast/hpe-jared-dame-ai-data-science</link>
      <description>Jared Dame, Z by HP's director of business development and strategy for AI, data science and edge technologies, spoke to AI Podcast host Noah Kravitz about the role HP’s workstations play in cutting-edge AI and data science.</description>
      <pubDate>Mon, 27 Jul 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e4885470-f45b-11ef-8be6-07f0d580c58a/image/0600e1cd8dd5af1a244fde31cf6663b4.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Jared Dame, Z by HP's director of business develo…</itunes:subtitle>
      <itunes:summary>Jared Dame, Z by HP's director of business development and strategy for AI, data science and edge technologies, spoke to AI Podcast host Noah Kravitz about the role HP’s workstations play in cutting-edge AI and data science.</itunes:summary>
      <content:encoded>
        <![CDATA[Jared Dame, Z by HP's director of business development and strategy for AI, data science and edge technologies, spoke to AI Podcast host Noah Kravitz about the role HP’s workstations play in cutting-edge AI and data science.]]>
      </content:encoded>
      <itunes:duration>1715</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/867395356]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6167523331.mp3?updated=1740586398" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Not So Taxing: How Intuit Uses AI to Make Tax Day Easier - Ep. 121</title>
      <link>https://soundcloud.com/theaipodcast/not-so-taxing-how-intuit-uses-ai-to-make-tax-day-easier-ep-121</link>
      <description>Understanding the U.S. tax code can take years of study — it’s 80,000 pages long. Software company Intuit has decided that it’s a job for AI. Ashok Srivastava, its senior vice president and chief data officer, spoke to AI Podcast host Noah Kravitz about how the company is utilizing machine learning to help customers with taxes and aid small businesses through the financial effects of COVID-19.</description>
      <pubDate>Wed, 08 Jul 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e4e56c50-f45b-11ef-8be6-e73e9c8a173f/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Understanding the U.S. tax code can take years of…</itunes:subtitle>
      <itunes:summary>Understanding the U.S. tax code can take years of study — it’s 80,000 pages long. Software company Intuit has decided that it’s a job for AI. Ashok Srivastava, its senior vice president and chief data officer, spoke to AI Podcast host Noah Kravitz about how the company is utilizing machine learning to help customers with taxes and aid small businesses through the financial effects of COVID-19.</itunes:summary>
      <content:encoded>
        <![CDATA[Understanding the U.S. tax code can take years of study — it’s 80,000 pages long. Software company Intuit has decided that it’s a job for AI. Ashok Srivastava, its senior vice president and chief data officer, spoke to AI Podcast host Noah Kravitz about how the company is utilizing machine learning to help customers with taxes and aid small businesses through the financial effects of COVID-19.]]>
      </content:encoded>
      <itunes:duration>1801</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/854731171]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5136526263.mp3?updated=1740586399" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Jonah Alben Talks AI - Ep. 120</title>
      <link>https://soundcloud.com/theaipodcast/ai-jonah-alben</link>
      <description>Imagine building an engine with 54 billion parts. Now imagine each piece is the size of a gnat’s eyelash. That gives you some idea of the scale Jonah Alben works at. Jonah is the co-leader of GPU engineering at Nvidia. The engines he builds are GPUs. Without these chips your favorite computer games and special-effects movies would look pretty lame. GPUs also power scientific simulations of everything from a Mars lander to a protein spike on the coronavirus… and, oh yes, these days they do much of the heavy lifting for the latest and greatest form of computing: AI.</description>
      <pubDate>Wed, 27 May 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e5435018-f45b-11ef-8be6-b39dba86b4cd/image/5927b03ca4529adcae5619024544db85.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Imagine building an engine with 54 billion parts.…</itunes:subtitle>
      <itunes:summary>Imagine building an engine with 54 billion parts. Now imagine each piece is the size of a gnat’s eyelash. That gives you some idea of the scale Jonah Alben works at. Jonah is the co-leader of GPU engineering at Nvidia. The engines he builds are GPUs. Without these chips your favorite computer games and special-effects movies would look pretty lame. GPUs also power scientific simulations of everything from a Mars lander to a protein spike on the coronavirus… and, oh yes, these days they do much of the heavy lifting for the latest and greatest form of computing: AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Imagine building an engine with 54 billion parts. Now imagine each piece is the size of a gnat’s eyelash. That gives you some idea of the scale Jonah Alben works at. Jonah is the co-leader of GPU engineering at Nvidia. The engines he builds are GPUs. Without these chips your favorite computer games and special-effects movies would look pretty lame. GPUs also power scientific simulations of everything from a Mars lander to a protein spike on the coronavirus… and, oh yes, these days they do much of the heavy lifting for the latest and greatest form of computing: AI.]]>
      </content:encoded>
      <itunes:duration>1328</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/829476304]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3780132679.mp3?updated=1740586400" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Keith Strier Talks AI Nations - Ep. 119</title>
      <link>https://soundcloud.com/theaipodcast/ai-keith-strier</link>
      <description>As NVIDIA’s vice president of worldwide AI initiatives, Keith Strier is thinking on a global scale.

He leads an initiative called AI Nations, a worldwide program that helps government leaders and stakeholders develop plans to implement AI to advance national priorities and drive economic growth.

Strier spoke to AI Podcast host Noah Kravitz about AI Nations, and how NVIDIA helps countries harness all the capabilities of AI — from enhancing their local startup ecosystems to developing autonomous public transportation systems.</description>
      <pubDate>Thu, 30 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e59f9954-f45b-11ef-8be6-9bdff8a5222e/image/956114d7aebc2586458f1ec59d2337fd.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>As NVIDIA’s vice president of worldwide AI initia…</itunes:subtitle>
      <itunes:summary>As NVIDIA’s vice president of worldwide AI initiatives, Keith Strier is thinking on a global scale.

He leads an initiative called AI Nations, a worldwide program that helps government leaders and stakeholders develop plans to implement AI to advance national priorities and drive economic growth.

Strier spoke to AI Podcast host Noah Kravitz about AI Nations, and how NVIDIA helps countries harness all the capabilities of AI — from enhancing their local startup ecosystems to developing autonomous public transportation systems.</itunes:summary>
      <content:encoded>
        <![CDATA[As NVIDIA’s vice president of worldwide AI initiatives, Keith Strier is thinking on a global scale.

He leads an initiative called AI Nations, a worldwide program that helps government leaders and stakeholders develop plans to implement AI to advance national priorities and drive economic growth.

Strier spoke to AI Podcast host Noah Kravitz about AI Nations, and how NVIDIA helps countries harness all the capabilities of AI — from enhancing their local startup ecosystems to developing autonomous public transportation systems.]]>
      </content:encoded>
      <itunes:duration>1749</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/815607637]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3530776342.mp3?updated=1740586400" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Lenovo's Mike Leach on the Role of the Workstation in Modern AI - Ep. 118</title>
      <link>https://soundcloud.com/theaipodcast/lenovo</link>
      <description>Whether you're using the latest generation of AI enabled mobile apps or robust business systems powered on banks of powerful servers, chances are your technology was built, first, on a workstation. We spoke with Lenovo’s Mike Leach about how these workhorses are adapting to support a plethora of new kinds of AI applications.</description>
      <pubDate>Wed, 22 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e5fe36d0-f45b-11ef-8be6-b3326637bc69/image/063a468d881b1f718b440fc7968df3e3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Whether you're using the latest generation of AI …</itunes:subtitle>
      <itunes:summary>Whether you're using the latest generation of AI enabled mobile apps or robust business systems powered on banks of powerful servers, chances are your technology was built, first, on a workstation. We spoke with Lenovo’s Mike Leach about how these workhorses are adapting to support a plethora of new kinds of AI applications.</itunes:summary>
      <content:encoded>
        <![CDATA[Whether you're using the latest generation of AI enabled mobile apps or robust business systems powered on banks of powerful servers, chances are your technology was built, first, on a workstation. We spoke with Lenovo’s Mike Leach about how these workhorses are adapting to support a plethora of new kinds of AI applications.]]>
      </content:encoded>
      <itunes:duration>1736</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/805409266]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8840281462.mp3?updated=1740586401" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ford’s Nikita Jaipuria and Rohan Bhasin on Generating Synthetic Data - Ep. 117</title>
      <link>https://soundcloud.com/theaipodcast/ford-generating-synthetic-data</link>
      <description>Autonomous vehicles require a massive amount of data and computing power. Teaching a vehicle to see what’s on the road in front of it is a big part of the puzzle. Our guests today, Ford’s Nikita Jaipuria and Rohan Bhasin, are using Generative Adversarial Networks to help autonomous vehicle systems see as well in rain and snowy conditions as they do when it’s clear out.</description>
      <pubDate>Tue, 21 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e65d633a-f45b-11ef-8be6-df09a94cc151/image/0b1717e84fab017a8907c40afe57bce6.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Autonomous vehicles require a massive amount of d…</itunes:subtitle>
      <itunes:summary>Autonomous vehicles require a massive amount of data and computing power. Teaching a vehicle to see what’s on the road in front of it is a big part of the puzzle. Our guests today, Ford’s Nikita Jaipuria and Rohan Bhasin, are using Generative Adversarial Networks to help autonomous vehicle systems see as well in rain and snowy conditions as they do when it’s clear out.</itunes:summary>
      <content:encoded>
        <![CDATA[Autonomous vehicles require a massive amount of data and computing power. Teaching a vehicle to see what’s on the road in front of it is a big part of the puzzle. Our guests today, Ford’s Nikita Jaipuria and Rohan Bhasin, are using Generative Adversarial Networks to help autonomous vehicle systems see as well in rain and snowy conditions as they do when it’s clear out.]]>
      </content:encoded>
      <itunes:duration>1400</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/803738632]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7285580902.mp3?updated=1740586402" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Finding Trash in Sensitive Waterways with AI - Ep. 116</title>
      <link>https://soundcloud.com/theaipodcast/ai-waterways</link>
      <description>Cleaning up our oceans, rivers, and waterways have become a major environmental issue. Leaders in the field are now looking to begin harnessing modern AI and machine learning techniques to help tackle this immense challenge. We spoke with the San Francisco Estuary Institute’s Lorenzo Flores on using machine learning to find trash in environmentally sensitive waterways.</description>
      <pubDate>Thu, 16 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e6ba52b6-f45b-11ef-8be6-3f2b5624427f/image/d27c343fac0bb56832f9e2af3dd0093a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Cleaning up our oceans, rivers, and waterways hav…</itunes:subtitle>
      <itunes:summary>Cleaning up our oceans, rivers, and waterways have become a major environmental issue. Leaders in the field are now looking to begin harnessing modern AI and machine learning techniques to help tackle this immense challenge. We spoke with the San Francisco Estuary Institute’s Lorenzo Flores on using machine learning to find trash in environmentally sensitive waterways.</itunes:summary>
      <content:encoded>
        <![CDATA[Cleaning up our oceans, rivers, and waterways have become a major environmental issue. Leaders in the field are now looking to begin harnessing modern AI and machine learning techniques to help tackle this immense challenge. We spoke with the San Francisco Estuary Institute’s Lorenzo Flores on using machine learning to find trash in environmentally sensitive waterways.]]>
      </content:encoded>
      <itunes:duration>1530</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/801031951]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7298454199.mp3?updated=1740586402" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>MIT’s Jonathan Frankle on “The Lottery Hypothesis” - Ep. 115</title>
      <link>https://soundcloud.com/theaipodcast/mit-the-lottery-hypothesis</link>
      <description>We spoke with Jonathan Frankle, a PhD student at MIT and coauthor of a seminal paper outlining a technique, known as the “The Lottery Ticket,” hypothesis that promises to help advance our understanding of why neural networks, and deep learning, works so well.</description>
      <pubDate>Tue, 14 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e7164ff8-f45b-11ef-8be6-13dcde892e83/image/6e5c98976bf76c2b0cbfd3b4792b0936.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Jonathan Frankle, a PhD student at …</itunes:subtitle>
      <itunes:summary>We spoke with Jonathan Frankle, a PhD student at MIT and coauthor of a seminal paper outlining a technique, known as the “The Lottery Ticket,” hypothesis that promises to help advance our understanding of why neural networks, and deep learning, works so well.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Jonathan Frankle, a PhD student at MIT and coauthor of a seminal paper outlining a technique, known as the “The Lottery Ticket,” hypothesis that promises to help advance our understanding of why neural networks, and deep learning, works so well.]]>
      </content:encoded>
      <itunes:duration>1457</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/797956489]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9071990085.mp3?updated=1740586403" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Credit Check: Capital One’s Kyle Nicholson on Modern Machine Learning in Finance - Ep. 114</title>
      <link>https://soundcloud.com/theaipodcast/capital-one</link>
      <description>We spoke with Capital One Senior Software Engineer Kyle Nicholson on how modern machine learning techniques have become a key tool for financial and credit analysis.</description>
      <pubDate>Thu, 09 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e77391ea-f45b-11ef-8be6-473a1aa8e48b/image/6582a34107c4eb40d39467f39b623ae3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Capital One Senior Software Enginee…</itunes:subtitle>
      <itunes:summary>We spoke with Capital One Senior Software Engineer Kyle Nicholson on how modern machine learning techniques have become a key tool for financial and credit analysis.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Capital One Senior Software Engineer Kyle Nicholson on how modern machine learning techniques have become a key tool for financial and credit analysis.]]>
      </content:encoded>
      <itunes:duration>1147</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/793374328]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1136278267.mp3?updated=1740586403" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Speed of Light: SLAC’s Ryan Coffee Talks Ultrafast Science - Ep. 112</title>
      <link>https://soundcloud.com/theaipodcast/slac-ryan-coffee</link>
      <description>We spoke with a particle physicist Ryan Coffee, senior staff scientist at the SLAC National Accelerator Laboratory on how he — and others in his field — are putting deep learning to work. We include questions from friends, family and acquaintances in a wide-ranging conversation complementing a deep-dive session led by Ryan Coffee as part of GTC Digital.</description>
      <pubDate>Fri, 03 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e82ce924-f45b-11ef-8be6-0f2633f4bd02/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with a particle physicist Ryan Coffee, s…</itunes:subtitle>
      <itunes:summary>We spoke with a particle physicist Ryan Coffee, senior staff scientist at the SLAC National Accelerator Laboratory on how he — and others in his field — are putting deep learning to work. We include questions from friends, family and acquaintances in a wide-ranging conversation complementing a deep-dive session led by Ryan Coffee as part of GTC Digital.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with a particle physicist Ryan Coffee, senior staff scientist at the SLAC National Accelerator Laboratory on how he — and others in his field — are putting deep learning to work. We include questions from friends, family and acquaintances in a wide-ranging conversation complementing a deep-dive session led by Ryan Coffee as part of GTC Digital.]]>
      </content:encoded>
      <itunes:duration>2212</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/788200978]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4449147487.mp3?updated=1740586405" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Demystifying AI with NVIDIA’s Will Ramey - Ep. 113</title>
      <link>https://soundcloud.com/theaipodcast/deep-learning-demystified</link>
      <description>We brought back one of NVIDIA’s best explainers, Will Ramey, to provide an introduction to today’s AI boom and the key concepts behind it. Ramey, senior director and global head of developer programs at NVIDIA, led a webinar, "Deep Learning Demystified," as part of this year's GTC Digital online conference. https://developer.nvidia.com/gtc/2020/video/s22555</description>
      <pubDate>Fri, 03 Apr 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e7cf5b9c-f45b-11ef-8be6-c32edbf49391/image/86f2212e6117a6496864087647449881.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We brought back one of NVIDIA’s best explainers, …</itunes:subtitle>
      <itunes:summary>We brought back one of NVIDIA’s best explainers, Will Ramey, to provide an introduction to today’s AI boom and the key concepts behind it. Ramey, senior director and global head of developer programs at NVIDIA, led a webinar, "Deep Learning Demystified," as part of this year's GTC Digital online conference. https://developer.nvidia.com/gtc/2020/video/s22555</itunes:summary>
      <content:encoded>
        <![CDATA[We brought back one of NVIDIA’s best explainers, Will Ramey, to provide an introduction to today’s AI boom and the key concepts behind it. Ramey, senior director and global head of developer programs at NVIDIA, led a webinar, "Deep Learning Demystified," as part of this year's GTC Digital online conference. https://developer.nvidia.com/gtc/2020/video/s22555]]>
      </content:encoded>
      <itunes:duration>2838</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/789512254]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4992366460.mp3?updated=1740586404" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Stanford's Margot Gerritsen on Data Science and Women in Tech - Ep. 111</title>
      <link>https://soundcloud.com/theaipodcast/stanfords-margot-gerritsen</link>
      <description>On this episode of the NVIDIA AI Podcast, we interview Stanford Professor Margot Gerritsen about what’s next in data science, the growing role of women in data science, and how data science intersects with modern AI. For more, tune into Professor Gerritsen's Women in Data Science podcast https://www.widsconference.org/podcast.html</description>
      <pubDate>Sat, 28 Mar 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e88949b2-f45b-11ef-8be6-3fd815b6f6d2/image/66a14fe825c2eae657c33fc3d3ef62f8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>On this episode of the NVIDIA AI Podcast, we inte…</itunes:subtitle>
      <itunes:summary>On this episode of the NVIDIA AI Podcast, we interview Stanford Professor Margot Gerritsen about what’s next in data science, the growing role of women in data science, and how data science intersects with modern AI. For more, tune into Professor Gerritsen's Women in Data Science podcast https://www.widsconference.org/podcast.html</itunes:summary>
      <content:encoded>
        <![CDATA[On this episode of the NVIDIA AI Podcast, we interview Stanford Professor Margot Gerritsen about what’s next in data science, the growing role of women in data science, and how data science intersects with modern AI. For more, tune into Professor Gerritsen's Women in Data Science podcast https://www.widsconference.org/podcast.html]]>
      </content:encoded>
      <itunes:duration>2050</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/783605716]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1237387148.mp3?updated=1740586405" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Keeping an Eye on AI: Building Ethical Technology at Salesforce - Ep. 110</title>
      <link>https://soundcloud.com/theaipodcast/ethical-ai</link>
      <description>Kathy Baxter, the architect of ethical AI practice at Salesforce, is helping her team and clients create more responsible technology. To do so, she supports employee education, the inclusion of safeguards in Salesforce technology, and collaboration with other companies to improve ethical AI across industries.</description>
      <pubDate>Tue, 24 Mar 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e8e465fe-f45b-11ef-8be6-0bbfa55e0143/image/7a41d0e65895c2d84460ea55bb37f0d9.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Kathy Baxter, the architect of ethical AI practic…</itunes:subtitle>
      <itunes:summary>Kathy Baxter, the architect of ethical AI practice at Salesforce, is helping her team and clients create more responsible technology. To do so, she supports employee education, the inclusion of safeguards in Salesforce technology, and collaboration with other companies to improve ethical AI across industries.</itunes:summary>
      <content:encoded>
        <![CDATA[Kathy Baxter, the architect of ethical AI practice at Salesforce, is helping her team and clients create more responsible technology. To do so, she supports employee education, the inclusion of safeguards in Salesforce technology, and collaboration with other companies to improve ethical AI across industries.]]>
      </content:encoded>
      <itunes:duration>2014</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/782872945]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3860948829.mp3?updated=1740586406" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Nanotronics Brings Deep Learning to Precision Manufacturing - Ep. 109</title>
      <link>https://soundcloud.com/theaipodcast/ai-nanotronics-matthew-putman-3</link>
      <description>Matthew Putman, this week’s guest on the AI Podcast, knows that the devil is in the details. That’s why he’s the co-founder and CEO of Nanotronics, a Brooklyn-based company providing precision manufacturing enhanced by AI, automation and 3D imaging.</description>
      <pubDate>Mon, 17 Feb 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e9408a3c-f45b-11ef-8be6-33a309deb615/image/00bc7d35ea923f414964f4403dad7610.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Matthew Putman, this week’s guest on the AI Podca…</itunes:subtitle>
      <itunes:summary>Matthew Putman, this week’s guest on the AI Podcast, knows that the devil is in the details. That’s why he’s the co-founder and CEO of Nanotronics, a Brooklyn-based company providing precision manufacturing enhanced by AI, automation and 3D imaging.</itunes:summary>
      <content:encoded>
        <![CDATA[Matthew Putman, this week’s guest on the AI Podcast, knows that the devil is in the details. That’s why he’s the co-founder and CEO of Nanotronics, a Brooklyn-based company providing precision manufacturing enhanced by AI, automation and 3D imaging.]]>
      </content:encoded>
      <itunes:duration>1404</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/762906757]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1505451092.mp3?updated=1740586406" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA’s Neda Cvijetic Explains the Science Behind Self-Driving Cars - Ep. 108</title>
      <link>https://soundcloud.com/theaipodcast/nvidias-neda-cvijetic-explains-the-science-behind-self-driving-cars-ep-108</link>
      <description>What John Madden was to pro football, Neda Cvijetic is to autonomous vehicles. No one’s better at explaining the action, in real time, than Cvijetic. Cvijetic, senior manager of autonomous vehicles at NVIDIA, drives our NVIDIA DRIVE Labs series of videos and blogs breaking down the science behind autonomous vehicles.</description>
      <pubDate>Tue, 04 Feb 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e99f0eae-f45b-11ef-8be6-3f01065bc35f/image/ecb066ecc557285fdd31c82a0b585be8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>What John Madden was to pro football, Neda Cvijet…</itunes:subtitle>
      <itunes:summary>What John Madden was to pro football, Neda Cvijetic is to autonomous vehicles. No one’s better at explaining the action, in real time, than Cvijetic. Cvijetic, senior manager of autonomous vehicles at NVIDIA, drives our NVIDIA DRIVE Labs series of videos and blogs breaking down the science behind autonomous vehicles.</itunes:summary>
      <content:encoded>
        <![CDATA[What John Madden was to pro football, Neda Cvijetic is to autonomous vehicles. No one’s better at explaining the action, in real time, than Cvijetic. Cvijetic, senior manager of autonomous vehicles at NVIDIA, drives our NVIDIA DRIVE Labs series of videos and blogs breaking down the science behind autonomous vehicles.]]>
      </content:encoded>
      <itunes:duration>1488</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/755381191]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2911676460.mp3?updated=1740586407" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI’s Mild Ride: RoadBotics Puts AI on Pothole Patrol - Ep. 107</title>
      <link>https://soundcloud.com/theaipodcast/ai-ben-schmidt-roadbotics-podcast</link>
      <description>National Pothole Day is Jan. 15. Its timing is no accident. All over the Northern hemisphere, potholes are at their suspension-wrecking, spine-shaking worst this month. Thanks to AI, one startup is working all year long to alleviate this menace. Benjamin Schmidt, president and co-founder of RoadBotics, is using the tech to pave the way to better roads.</description>
      <pubDate>Thu, 09 Jan 2020 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/e9fb52c2-f45b-11ef-8be6-bb43e3f11e8f/image/94e4ca52908cb8b04fe027be6cfb4c02.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>National Pothole Day is Jan. 15. Its timing is no…</itunes:subtitle>
      <itunes:summary>National Pothole Day is Jan. 15. Its timing is no accident. All over the Northern hemisphere, potholes are at their suspension-wrecking, spine-shaking worst this month. Thanks to AI, one startup is working all year long to alleviate this menace. Benjamin Schmidt, president and co-founder of RoadBotics, is using the tech to pave the way to better roads.</itunes:summary>
      <content:encoded>
        <![CDATA[National Pothole Day is Jan. 15. Its timing is no accident. All over the Northern hemisphere, potholes are at their suspension-wrecking, spine-shaking worst this month. Thanks to AI, one startup is working all year long to alleviate this menace. Benjamin Schmidt, president and co-founder of RoadBotics, is using the tech to pave the way to better roads.]]>
      </content:encoded>
      <itunes:duration>1510</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/740460151]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8271112415.mp3?updated=1740586408" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Serkan Piantino’s Company Makes AI for Everyone - Ep. 106</title>
      <link>https://soundcloud.com/theaipodcast/serkan-piantino-spell</link>
      <description>Spell, founded by Serkan Piantino, is making machine learning as easy as ABC. Piantino, CEO of the New York-based startup and former director of engineering for Facebook AI Research, explained to AI Podcast host Noah Kravitz how he’s bringing compute power to those that don’t have easy access to GPU clusters.</description>
      <pubDate>Wed, 18 Dec 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ea573434-f45b-11ef-8be6-3b8f84159b34/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Spell, founded by Serkan Piantino, is making mach…</itunes:subtitle>
      <itunes:summary>Spell, founded by Serkan Piantino, is making machine learning as easy as ABC. Piantino, CEO of the New York-based startup and former director of engineering for Facebook AI Research, explained to AI Podcast host Noah Kravitz how he’s bringing compute power to those that don’t have easy access to GPU clusters.</itunes:summary>
      <content:encoded>
        <![CDATA[Spell, founded by Serkan Piantino, is making machine learning as easy as ABC. Piantino, CEO of the New York-based startup and former director of engineering for Facebook AI Research, explained to AI Podcast host Noah Kravitz how he’s bringing compute power to those that don’t have easy access to GPU clusters.]]>
      </content:encoded>
      <itunes:duration>1397</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/731092522]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7849067564.mp3?updated=1740586408" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Pod Squad: Descript Uses AI to Make Managing Podcasts Quicker, Easier - Ep. 105</title>
      <link>https://soundcloud.com/theaipodcast/descript-ai-podcast-andrew-mason</link>
      <description>You can’t have an AI podcast and not interview someone using AI to make podcasts better. That’s why we reached out to serial entrepreneur Andrew Mason to talk to him about what he’s doing now. His company, Descript Podcast Studio, uses AI, natural language processing and automatic speech synthesis to make podcast editing easier and more collaborative.</description>
      <pubDate>Wed, 04 Dec 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/eaba69f0-f45b-11ef-8be6-1fd6af6344ab/image/fd763272307c47bb80b37f983149320b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>You can’t have an AI podcast and not interview so…</itunes:subtitle>
      <itunes:summary>You can’t have an AI podcast and not interview someone using AI to make podcasts better. That’s why we reached out to serial entrepreneur Andrew Mason to talk to him about what he’s doing now. His company, Descript Podcast Studio, uses AI, natural language processing and automatic speech synthesis to make podcast editing easier and more collaborative.</itunes:summary>
      <content:encoded>
        <![CDATA[You can’t have an AI podcast and not interview someone using AI to make podcasts better. That’s why we reached out to serial entrepreneur Andrew Mason to talk to him about what he’s doing now. His company, Descript Podcast Studio, uses AI, natural language processing and automatic speech synthesis to make podcast editing easier and more collaborative.]]>
      </content:encoded>
      <itunes:duration>1539</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/723283363]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8729540932.mp3?updated=1740586409" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Speaking the Same Language: How Oracle’s Conversational AI Serves Customers - Ep. 104</title>
      <link>https://soundcloud.com/theaipodcast/speaking-the-same-language-how-oracles-conversational-ai-serves-customers-ep-103</link>
      <description>At Oracle, customer service chatbots use conversational AI to respond to consumers with more speed and complexity. Suhas Uliyar, vice president of bots, AI and mobile product management at Oracle, stopped by to talk to AI Podcast host Noah Kravitz about how the newest wave of conversational AI can keep up with the nuances of human conversation.</description>
      <pubDate>Thu, 21 Nov 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/eb167182-f45b-11ef-8be6-f75635988f18/image/bead4928e2554ace6842eb948527fb12.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>At Oracle, customer service chatbots use conversa…</itunes:subtitle>
      <itunes:summary>At Oracle, customer service chatbots use conversational AI to respond to consumers with more speed and complexity. Suhas Uliyar, vice president of bots, AI and mobile product management at Oracle, stopped by to talk to AI Podcast host Noah Kravitz about how the newest wave of conversational AI can keep up with the nuances of human conversation.</itunes:summary>
      <content:encoded>
        <![CDATA[At Oracle, customer service chatbots use conversational AI to respond to consumers with more speed and complexity. Suhas Uliyar, vice president of bots, AI and mobile product management at Oracle, stopped by to talk to AI Podcast host Noah Kravitz about how the newest wave of conversational AI can keep up with the nuances of human conversation.]]>
      </content:encoded>
      <itunes:duration>1955</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/716059609]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9220630566.mp3?updated=1740586410" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI4Good: Canadian Lab Empowers Women in Computer Science - Ep. 103</title>
      <link>https://soundcloud.com/theaipodcast/ai4good-canadian-lab-empowers-women-in-computer-science-ep-102</link>
      <description>Doina Precup is applying Romanian wisdom to the gender gap in the fields of AI and computer science.

The associate professor at McGill University and research team lead at AI startup DeepMind spoke with AI Podcast host Noah Kravitz about her personal experiences, along with the AI4Good Lab she co-founded to give women more access to machine learning training.

Growing up in Romania, Precup attended a high school that specialized in computer science and a technical university. She didn’t experience gender disparity in these learning environments. 

“If anything, programming was considered a very good job for women, because you did not need to be working in the fields,” she explained.

It made the gap in Canadian universities and companies even more noticeable. At McGill, Precup saw that female students were hesitant to speak up or pursue graduate studies.

Together with Angelique Mannella, CEO of AM Consulting and an Amazon employee, Precup was inspired to start the AI4Good Lab in 2017.</description>
      <pubDate>Wed, 13 Nov 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/eb9dc218-f45b-11ef-8be6-8f38885567d7/image/47d869152016b5e44ea18cb3a6fab978.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Doina Precup is applying Romanian wisdom to the g…</itunes:subtitle>
      <itunes:summary>Doina Precup is applying Romanian wisdom to the gender gap in the fields of AI and computer science.

The associate professor at McGill University and research team lead at AI startup DeepMind spoke with AI Podcast host Noah Kravitz about her personal experiences, along with the AI4Good Lab she co-founded to give women more access to machine learning training.

Growing up in Romania, Precup attended a high school that specialized in computer science and a technical university. She didn’t experience gender disparity in these learning environments. 

“If anything, programming was considered a very good job for women, because you did not need to be working in the fields,” she explained.

It made the gap in Canadian universities and companies even more noticeable. At McGill, Precup saw that female students were hesitant to speak up or pursue graduate studies.

Together with Angelique Mannella, CEO of AM Consulting and an Amazon employee, Precup was inspired to start the AI4Good Lab in 2017.</itunes:summary>
      <content:encoded>
        <![CDATA[Doina Precup is applying Romanian wisdom to the gender gap in the fields of AI and computer science.

The associate professor at McGill University and research team lead at AI startup DeepMind spoke with AI Podcast host Noah Kravitz about her personal experiences, along with the AI4Good Lab she co-founded to give women more access to machine learning training.

Growing up in Romania, Precup attended a high school that specialized in computer science and a technical university. She didn’t experience gender disparity in these learning environments. 

“If anything, programming was considered a very good job for women, because you did not need to be working in the fields,” she explained.

It made the gap in Canadian universities and companies even more noticeable. At McGill, Precup saw that female students were hesitant to speak up or pursue graduate studies.

Together with Angelique Mannella, CEO of AM Consulting and an Amazon employee, Precup was inspired to start the AI4Good Lab in 2017.]]>
      </content:encoded>
      <itunes:duration>1708</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/706098688]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7816522955.mp3?updated=1740586410" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AI Startup Brings Computer Vision to Customer Service - Ep. 102</title>
      <link>https://soundcloud.com/theaipodcast/satish-mandalika-drishyam-ai</link>
      <description>When your appliances break, the last thing you want to do is spend an hour on the phone trying to reach a customer service representative. 

Using computer vision, Drishyam.AI is eliminating service lines to help consumers more quickly.

Satish Mandalika, the CEO and founder of the deep learning-based image recognition platform, spoke with AI Podcast host Noah Kravitz about the company. 

“Customer support is ripe for disruption,” Mandalika said. Drishyam.AI is changing the game by giving customers an app that they use to take a picture of the product they need help with at any time of day or night, rather than calling a help line.

Using computer vision, Drishyam.AI analyzes the issue and communicates directly with manufacturers, rather than going through retail outlets. This is more efficient because a product’s lifetime warranty is usually held by the company that made it, rather than the stores selling it like Home Depot and Lowe’s.</description>
      <pubDate>Wed, 30 Oct 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ebfd0fac-f45b-11ef-8be6-97d9d291fa09/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>When your appliances break, the last thing you wa…</itunes:subtitle>
      <itunes:summary>When your appliances break, the last thing you want to do is spend an hour on the phone trying to reach a customer service representative. 

Using computer vision, Drishyam.AI is eliminating service lines to help consumers more quickly.

Satish Mandalika, the CEO and founder of the deep learning-based image recognition platform, spoke with AI Podcast host Noah Kravitz about the company. 

“Customer support is ripe for disruption,” Mandalika said. Drishyam.AI is changing the game by giving customers an app that they use to take a picture of the product they need help with at any time of day or night, rather than calling a help line.

Using computer vision, Drishyam.AI analyzes the issue and communicates directly with manufacturers, rather than going through retail outlets. This is more efficient because a product’s lifetime warranty is usually held by the company that made it, rather than the stores selling it like Home Depot and Lowe’s.</itunes:summary>
      <content:encoded>
        <![CDATA[When your appliances break, the last thing you want to do is spend an hour on the phone trying to reach a customer service representative. 

Using computer vision, Drishyam.AI is eliminating service lines to help consumers more quickly.

Satish Mandalika, the CEO and founder of the deep learning-based image recognition platform, spoke with AI Podcast host Noah Kravitz about the company. 

“Customer support is ripe for disruption,” Mandalika said. Drishyam.AI is changing the game by giving customers an app that they use to take a picture of the product they need help with at any time of day or night, rather than calling a help line.

Using computer vision, Drishyam.AI analyzes the issue and communicates directly with manufacturers, rather than going through retail outlets. This is more efficient because a product’s lifetime warranty is usually held by the company that made it, rather than the stores selling it like Home Depot and Lowe’s.]]>
      </content:encoded>
      <itunes:duration>1161</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/705238864]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2722886199.mp3?updated=1740586411" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Clean Sweep: Tokyo Robotics Company Builds Tidying Robots - Ep. 101</title>
      <link>https://soundcloud.com/theaipodcast/jun-hatori-preferred-networks-ep-101</link>
      <description>Though creating an autonomous robot that can tidy a room seems like enough of an achievement, Tokyo-based Preferred Networks goes one step further. By integrating natural language processing (NLP) into their technology, their robots respond to commands and adjust their actions. Jun Hatori, a software engineer at Preferred Networks, stopped to talk with AI Podcast host Noah Kravitz about the company’s latest developments.</description>
      <pubDate>Mon, 21 Oct 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ec5ac67e-f45b-11ef-8be6-8bc679794942/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Though creating an autonomous robot that can tidy…</itunes:subtitle>
      <itunes:summary>Though creating an autonomous robot that can tidy a room seems like enough of an achievement, Tokyo-based Preferred Networks goes one step further. By integrating natural language processing (NLP) into their technology, their robots respond to commands and adjust their actions. Jun Hatori, a software engineer at Preferred Networks, stopped to talk with AI Podcast host Noah Kravitz about the company’s latest developments.</itunes:summary>
      <content:encoded>
        <![CDATA[Though creating an autonomous robot that can tidy a room seems like enough of an achievement, Tokyo-based Preferred Networks goes one step further. By integrating natural language processing (NLP) into their technology, their robots respond to commands and adjust their actions. Jun Hatori, a software engineer at Preferred Networks, stopped to talk with AI Podcast host Noah Kravitz about the company’s latest developments.]]>
      </content:encoded>
      <itunes:duration>1089</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/701332282]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7532740076.mp3?updated=1740586412" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>The Buck Starts Here: NVIDIA’s Ian Buck on What’s Next for AI - Ep. 100</title>
      <link>https://soundcloud.com/theaipodcast/ian-buck</link>
      <description>AI is still young, but software is available to help even relatively unsophisticated users harness it. That’s according to Ian Buck, general manager of NVIDIA’s accelerated computing group, who shared his views in our latest AI Podcast. Buck, who helped lay the foundation for GPU computing as a Stanford doctoral candidate, will deliver the keynote address at GTC DC on Nov. 5. To sign up for GTC DC, visit https://nvda.ws/2Jzg7T1 and use the 'GMPOD' promo code for a 20% discount.</description>
      <pubDate>Wed, 16 Oct 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ecbb3478-f45b-11ef-8be6-2b66495f41be/image/0ce28cbee8064caf9df022b7201f7b5e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is still young, but software is available to h…</itunes:subtitle>
      <itunes:summary>AI is still young, but software is available to help even relatively unsophisticated users harness it. That’s according to Ian Buck, general manager of NVIDIA’s accelerated computing group, who shared his views in our latest AI Podcast. Buck, who helped lay the foundation for GPU computing as a Stanford doctoral candidate, will deliver the keynote address at GTC DC on Nov. 5. To sign up for GTC DC, visit https://nvda.ws/2Jzg7T1 and use the 'GMPOD' promo code for a 20% discount.</itunes:summary>
      <content:encoded>
        <![CDATA[AI is still young, but software is available to help even relatively unsophisticated users harness it. That’s according to Ian Buck, general manager of NVIDIA’s accelerated computing group, who shared his views in our latest AI Podcast. Buck, who helped lay the foundation for GPU computing as a Stanford doctoral candidate, will deliver the keynote address at GTC DC on Nov. 5. To sign up for GTC DC, visit https://nvda.ws/2Jzg7T1 and use the 'GMPOD' promo code for a 20% discount.]]>
      </content:encoded>
      <itunes:duration>1694</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/697367537]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9234469927.mp3?updated=1740586412" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>GauGAN Rocket Man: Conceptual Artist Uses AI Tools for Sci-Fi Modeling - Ep. 99</title>
      <link>https://soundcloud.com/theaipodcast/gaugan-rocket-man-conceptual-artist-uses-ai-tools-for-sci-fi-modeling-ep-99</link>
      <description>Have you ever wondered what it takes to produce the complex imagery in films like Star Wars or Transformers? The man behind the magic, Colie Wertz, is here to explain.

Wertz is a conceptual artist and modeler who works on film, television and video games. He sat down with AI Podcast host Noah Kravitz to explain his specialty in hard modeling, in which he produces digital models of objects with hard surfaces like vehicles, robots and computers.

To make these images, Wertz has taken to using AI art tools such as GauGAN, a real-time painting web app that allows users to create realistic landscapes using generative adversarial networks.</description>
      <pubDate>Tue, 01 Oct 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ed175c1c-f45b-11ef-8be6-43f016175835/image/0b484e551f706fb5f0f01bb13604fecb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Have you ever wondered what it takes to produce t…</itunes:subtitle>
      <itunes:summary>Have you ever wondered what it takes to produce the complex imagery in films like Star Wars or Transformers? The man behind the magic, Colie Wertz, is here to explain.

Wertz is a conceptual artist and modeler who works on film, television and video games. He sat down with AI Podcast host Noah Kravitz to explain his specialty in hard modeling, in which he produces digital models of objects with hard surfaces like vehicles, robots and computers.

To make these images, Wertz has taken to using AI art tools such as GauGAN, a real-time painting web app that allows users to create realistic landscapes using generative adversarial networks.</itunes:summary>
      <content:encoded>
        <![CDATA[Have you ever wondered what it takes to produce the complex imagery in films like Star Wars or Transformers? The man behind the magic, Colie Wertz, is here to explain.

Wertz is a conceptual artist and modeler who works on film, television and video games. He sat down with AI Podcast host Noah Kravitz to explain his specialty in hard modeling, in which he produces digital models of objects with hard surfaces like vehicles, robots and computers.

To make these images, Wertz has taken to using AI art tools such as GauGAN, a real-time painting web app that allows users to create realistic landscapes using generative adversarial networks.]]>
      </content:encoded>
      <itunes:duration>1976</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/690065029]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8328451853.mp3?updated=1740586413" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Say Yes to the AI Dress: Entrepreneur Brings GPUs to Fashion - Ep. 98</title>
      <link>https://soundcloud.com/theaipodcast/entrepreneur-brings-gpus-to-fashion</link>
      <description>In the future imagined by Pinar Yanardag, a postdoctoral research associate at MIT Media Lab, AI will collaborate with humans, not replace them. This is the concept behind her project, “How to Generate (Almost) Anything,” which she created with other students from the MIT Media Lab and professionals in the Boston area. Yanardag sat down with AI Podcast host Noah Kravitz to talk about this project, along with her other new creations.</description>
      <pubDate>Sat, 21 Sep 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ed782362-f45b-11ef-8be6-0b5fb1691243/image/2cd62bf38b16b9c06789e31202e9f959.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In the future imagined by Pinar Yanardag, a postd…</itunes:subtitle>
      <itunes:summary>In the future imagined by Pinar Yanardag, a postdoctoral research associate at MIT Media Lab, AI will collaborate with humans, not replace them. This is the concept behind her project, “How to Generate (Almost) Anything,” which she created with other students from the MIT Media Lab and professionals in the Boston area. Yanardag sat down with AI Podcast host Noah Kravitz to talk about this project, along with her other new creations.</itunes:summary>
      <content:encoded>
        <![CDATA[In the future imagined by Pinar Yanardag, a postdoctoral research associate at MIT Media Lab, AI will collaborate with humans, not replace them. This is the concept behind her project, “How to Generate (Almost) Anything,” which she created with other students from the MIT Media Lab and professionals in the Boston area. Yanardag sat down with AI Podcast host Noah Kravitz to talk about this project, along with her other new creations.]]>
      </content:encoded>
      <itunes:duration>1325</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/686738683]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6796988146.mp3?updated=1740586413" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Focal Systems Brings AI to Grocery Stores - Ep. 97</title>
      <link>https://soundcloud.com/theaipodcast/focal-systems-grocery</link>
      <description>We’ve all chosen the self-checkout stand over the human cashier, thinking it’ll take less time.

But somehow, things take a terrible turn. The barcodes aren’t scanning, there’s a pop-up scolding you for not placing the product in the bagging area (though you did, of course), and an employee is coming over to fix the chaos.

It would’ve taken less time to go to the cashier.

Focal Systems is applying deep learning and computer vision to automate portions of retail stores in order to streamline store operations and get customers in and out more efficiently, without the pitfalls of the traditional self-checkout.

CEO Francois Chaubard sat down with AI Podcast host Noah Kravitz to talk about how the company is changing retailers.</description>
      <pubDate>Sun, 15 Sep 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/edd6eafa-f45b-11ef-8be6-cb12b40a1029/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We’ve all chosen the self-checkout stand over the…</itunes:subtitle>
      <itunes:summary>We’ve all chosen the self-checkout stand over the human cashier, thinking it’ll take less time.

But somehow, things take a terrible turn. The barcodes aren’t scanning, there’s a pop-up scolding you for not placing the product in the bagging area (though you did, of course), and an employee is coming over to fix the chaos.

It would’ve taken less time to go to the cashier.

Focal Systems is applying deep learning and computer vision to automate portions of retail stores in order to streamline store operations and get customers in and out more efficiently, without the pitfalls of the traditional self-checkout.

CEO Francois Chaubard sat down with AI Podcast host Noah Kravitz to talk about how the company is changing retailers.</itunes:summary>
      <content:encoded>
        <![CDATA[We’ve all chosen the self-checkout stand over the human cashier, thinking it’ll take less time.

But somehow, things take a terrible turn. The barcodes aren’t scanning, there’s a pop-up scolding you for not placing the product in the bagging area (though you did, of course), and an employee is coming over to fix the chaos.

It would’ve taken less time to go to the cashier.

Focal Systems is applying deep learning and computer vision to automate portions of retail stores in order to streamline store operations and get customers in and out more efficiently, without the pitfalls of the traditional self-checkout.

CEO Francois Chaubard sat down with AI Podcast host Noah Kravitz to talk about how the company is changing retailers.]]>
      </content:encoded>
      <itunes:duration>1512</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/682966523]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8052692872.mp3?updated=1740586414" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Kiwibots Bring Sustenance to Students - Ep. 96</title>
      <link>https://soundcloud.com/theaipodcast/kiwibot-felipe-chavez</link>
      <description>College students are many things — sleepy, overly caffeinated, stressed — but above all, they are hungry. Kiwi Campus is here to help. Co-founder and CEO of Kiwi Campus, Felipe Chávez, joined AI Podcast host Noah Kravitz to talk about Kiwi and its delivery service.

Based in Berkeley, Calif., the company specializes in creating a robotic ecosystem for last mile delivery. Its solution is the Kiwibot. The small autonomous robot delivers orders seven days a week from 10 AM to 8 PM. Its coverage area includes UC Berkeley and the surrounding streets.</description>
      <pubDate>Tue, 10 Sep 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ee33c63a-f45b-11ef-8be6-c72f31c0ed97/image/316ab4f2d7c822641e60dc4e6511c5cc.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>College students are many things — sleepy, overly…</itunes:subtitle>
      <itunes:summary>College students are many things — sleepy, overly caffeinated, stressed — but above all, they are hungry. Kiwi Campus is here to help. Co-founder and CEO of Kiwi Campus, Felipe Chávez, joined AI Podcast host Noah Kravitz to talk about Kiwi and its delivery service.

Based in Berkeley, Calif., the company specializes in creating a robotic ecosystem for last mile delivery. Its solution is the Kiwibot. The small autonomous robot delivers orders seven days a week from 10 AM to 8 PM. Its coverage area includes UC Berkeley and the surrounding streets.</itunes:summary>
      <content:encoded>
        <![CDATA[College students are many things — sleepy, overly caffeinated, stressed — but above all, they are hungry. Kiwi Campus is here to help. Co-founder and CEO of Kiwi Campus, Felipe Chávez, joined AI Podcast host Noah Kravitz to talk about Kiwi and its delivery service.

Based in Berkeley, Calif., the company specializes in creating a robotic ecosystem for last mile delivery. Its solution is the Kiwibot. The small autonomous robot delivers orders seven days a week from 10 AM to 8 PM. Its coverage area includes UC Berkeley and the surrounding streets.]]>
      </content:encoded>
      <itunes:duration>1316</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/679291599]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2214417849.mp3?updated=1740586415" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Dial A for AI: Charter Boosts Customer Service with AI - Ep. 95</title>
      <link>https://soundcloud.com/theaipodcast/charter-ai</link>
      <description>Charter Communications is working to make customer service smarter even before an operator picks up the phone. Charter Communications, also known as Spectrum, is using AI to improve their customer service and process data more intelligently. Senior Director of Wireless Engineering Jared Ritter took a break from his presentations at GTC Santa Clara to talk to AI Podcast host Noah Kravitz about Charter’s perspective on customer relations.</description>
      <pubDate>Tue, 03 Sep 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ee8f5900-f45b-11ef-8be6-5b60f9f610eb/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Charter Communications is working to make custome…</itunes:subtitle>
      <itunes:summary>Charter Communications is working to make customer service smarter even before an operator picks up the phone. Charter Communications, also known as Spectrum, is using AI to improve their customer service and process data more intelligently. Senior Director of Wireless Engineering Jared Ritter took a break from his presentations at GTC Santa Clara to talk to AI Podcast host Noah Kravitz about Charter’s perspective on customer relations.</itunes:summary>
      <content:encoded>
        <![CDATA[Charter Communications is working to make customer service smarter even before an operator picks up the phone. Charter Communications, also known as Spectrum, is using AI to improve their customer service and process data more intelligently. Senior Director of Wireless Engineering Jared Ritter took a break from his presentations at GTC Santa Clara to talk to AI Podcast host Noah Kravitz about Charter’s perspective on customer relations.]]>
      </content:encoded>
      <itunes:duration>1163</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/676638071]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9679863416.mp3?updated=1740586415" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Doc.ai CEO Walter De Brouwer on How Federated Learning Can Help Keep Data Private- Ep. 94</title>
      <link>https://soundcloud.com/theaipodcast/docai-ceo-walter-de-brouwer-ep-92</link>
      <description>Artificial intelligence thrives on data, the more the better. But when we’re talking about putting data in many industries, such as health care, to work, things can get very complicated, very quickly. Walter De Brouwer is CEO of Doc.ai, a Silicon Valley based company that’s building a medical research platform that can address this issue with federated learning.</description>
      <pubDate>Sun, 18 Aug 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/eeeb087c-f45b-11ef-8be6-1bda88745392/image/3adff3313617e562e5106ef1c8e678b4.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Artificial intelligence thrives on data, the more…</itunes:subtitle>
      <itunes:summary>Artificial intelligence thrives on data, the more the better. But when we’re talking about putting data in many industries, such as health care, to work, things can get very complicated, very quickly. Walter De Brouwer is CEO of Doc.ai, a Silicon Valley based company that’s building a medical research platform that can address this issue with federated learning.</itunes:summary>
      <content:encoded>
        <![CDATA[Artificial intelligence thrives on data, the more the better. But when we’re talking about putting data in many industries, such as health care, to work, things can get very complicated, very quickly. Walter De Brouwer is CEO of Doc.ai, a Silicon Valley based company that’s building a medical research platform that can address this issue with federated learning.]]>
      </content:encoded>
      <itunes:duration>1799</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/655486025]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4986753122.mp3?updated=1740586416" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Forget Storming Area 51, AI’s Helping Astronomers Scour the Skies for Habitable Planets - Ep. 93</title>
      <link>https://soundcloud.com/theaipodcast/guyon-gratadour</link>
      <description>Imagine staring into the high-beams of an oncoming car. Now imagine trying to pick out a speck of dust in the glare of the headlights. That’s the challenge Olivier Guyon and Damien Gratadour face as they try to find the dull glint of an exoplanet — a planet orbiting a star outside our solar system — beside the bright light of its star.

The pair -- Guyon is an instrument developer for Japan’s Subaru Telescope, and an astronomer at the University of Arizona; and Gratadour is an associate professor at the Observatoire de Paris and an instrument scientist at the Australian National University -- spoke with AI Podcast host Noah Kravitz about how they’re using GPU-powered extreme adaptive optics in very large telescopes to image nearby habitable planets.</description>
      <pubDate>Wed, 07 Aug 2019 13:00:25 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ef47a35c-f45b-11ef-8be6-fb8741eeb513/image/bd026c34104fc5f78ecff1b18d20f130.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Imagine staring into the high-beams of an oncomin…</itunes:subtitle>
      <itunes:summary>Imagine staring into the high-beams of an oncoming car. Now imagine trying to pick out a speck of dust in the glare of the headlights. That’s the challenge Olivier Guyon and Damien Gratadour face as they try to find the dull glint of an exoplanet — a planet orbiting a star outside our solar system — beside the bright light of its star.

The pair -- Guyon is an instrument developer for Japan’s Subaru Telescope, and an astronomer at the University of Arizona; and Gratadour is an associate professor at the Observatoire de Paris and an instrument scientist at the Australian National University -- spoke with AI Podcast host Noah Kravitz about how they’re using GPU-powered extreme adaptive optics in very large telescopes to image nearby habitable planets.</itunes:summary>
      <content:encoded>
        <![CDATA[Imagine staring into the high-beams of an oncoming car. Now imagine trying to pick out a speck of dust in the glare of the headlights. That’s the challenge Olivier Guyon and Damien Gratadour face as they try to find the dull glint of an exoplanet — a planet orbiting a star outside our solar system — beside the bright light of its star.

The pair -- Guyon is an instrument developer for Japan’s Subaru Telescope, and an astronomer at the University of Arizona; and Gratadour is an associate professor at the Observatoire de Paris and an instrument scientist at the Australian National University -- spoke with AI Podcast host Noah Kravitz about how they’re using GPU-powered extreme adaptive optics in very large telescopes to image nearby habitable planets.]]>
      </content:encoded>
      <itunes:duration>1472</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/662196161]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1700691861.mp3?updated=1740586417" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Making "Iron Man" Interface Real: AI-Based Virtualitics Demystifies Data Science with VR - Ep. 92</title>
      <link>https://soundcloud.com/theaipodcast/aakash-virtualitics</link>
      <description>The words “data science” often inspire feelings of dread or confusion. But Virtualitics, an AI-based analytics platform, is bringing creativity and excitement to the field through machine learning and immersive virtualization. In our latest episode of the AI Podcast, Virtualitics Machine Learning Projects Head Aakash Indurkhya spoke with AI Podcast host Noah Kravitz about why VR can now be so useful.</description>
      <pubDate>Sun, 28 Jul 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/efa3c2ea-f45b-11ef-8be6-d306b018ea9e/image/5e1c9afb5537cf7f7f11d626d8574479.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The words “data science” often inspire feelings o…</itunes:subtitle>
      <itunes:summary>The words “data science” often inspire feelings of dread or confusion. But Virtualitics, an AI-based analytics platform, is bringing creativity and excitement to the field through machine learning and immersive virtualization. In our latest episode of the AI Podcast, Virtualitics Machine Learning Projects Head Aakash Indurkhya spoke with AI Podcast host Noah Kravitz about why VR can now be so useful.</itunes:summary>
      <content:encoded>
        <![CDATA[The words “data science” often inspire feelings of dread or confusion. But Virtualitics, an AI-based analytics platform, is bringing creativity and excitement to the field through machine learning and immersive virtualization. In our latest episode of the AI Podcast, Virtualitics Machine Learning Projects Head Aakash Indurkhya spoke with AI Podcast host Noah Kravitz about why VR can now be so useful.]]>
      </content:encoded>
      <itunes:duration>1646</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/658647725]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2356061868.mp3?updated=1740586417" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Get Your Fashion Fix: Stitch Fix Adds AI Flair to Your Closet - Ep. 91</title>
      <link>https://soundcloud.com/theaipodcast/stitch-fix-ai</link>
      <description>Some say style never fades, and now with the help of AI, finding one’s fashion sense is about to get a whole lot easier. Fashion ecommerce startup Stitch Fix is piecing together a seamless balance between AI-powered decision making and human judgement. We spoke with Stitch Fix Chief Algorithms Officer Brad Klingenberg about how the company is using AI to help us all dress better.</description>
      <pubDate>Tue, 09 Jul 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f001ac48-f45b-11ef-8be6-d7b771aee9d6/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Some say style never fades, and now with the help…</itunes:subtitle>
      <itunes:summary>Some say style never fades, and now with the help of AI, finding one’s fashion sense is about to get a whole lot easier. Fashion ecommerce startup Stitch Fix is piecing together a seamless balance between AI-powered decision making and human judgement. We spoke with Stitch Fix Chief Algorithms Officer Brad Klingenberg about how the company is using AI to help us all dress better.</itunes:summary>
      <content:encoded>
        <![CDATA[Some say style never fades, and now with the help of AI, finding one’s fashion sense is about to get a whole lot easier. Fashion ecommerce startup Stitch Fix is piecing together a seamless balance between AI-powered decision making and human judgement. We spoke with Stitch Fix Chief Algorithms Officer Brad Klingenberg about how the company is using AI to help us all dress better.]]>
      </content:encoded>
      <itunes:duration>1461</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/645582363]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8252029858.mp3?updated=1740586418" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Talking Trucks with TuSimple's Chuck Price - Ep. 90</title>
      <link>https://soundcloud.com/theaipodcast/chuck-price-tusimple</link>
      <description>We’re all aware of the race to deliver self driving cars that will allow consumers to sit back and be chauffeured wherever they wish. But the implications of self-driving trucks might actually be bigger, in the short term. Our guest today is Chuck Price, Chief Product Officer of TuSimple, which is developing commercially ready level four fully autonomous driving solutions for the logistics industry: self-driving trucks. So let’s talk trucks.</description>
      <pubDate>Tue, 02 Jul 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f05fdd22-f45b-11ef-8be6-c3358ed90756/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We’re all aware of the race to deliver self drivi…</itunes:subtitle>
      <itunes:summary>We’re all aware of the race to deliver self driving cars that will allow consumers to sit back and be chauffeured wherever they wish. But the implications of self-driving trucks might actually be bigger, in the short term. Our guest today is Chuck Price, Chief Product Officer of TuSimple, which is developing commercially ready level four fully autonomous driving solutions for the logistics industry: self-driving trucks. So let’s talk trucks.</itunes:summary>
      <content:encoded>
        <![CDATA[We’re all aware of the race to deliver self driving cars that will allow consumers to sit back and be chauffeured wherever they wish. But the implications of self-driving trucks might actually be bigger, in the short term. Our guest today is Chuck Price, Chief Product Officer of TuSimple, which is developing commercially ready level four fully autonomous driving solutions for the logistics industry: self-driving trucks. So let’s talk trucks.]]>
      </content:encoded>
      <itunes:duration>1448</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/645901110]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9457357354.mp3?updated=1740586418" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Anthem Could Have Healthcare Industry Singing a New Tune - Ep. 89</title>
      <link>https://soundcloud.com/theaipodcast/anthem-could-have-healthcare-industry-singing-a-new-tune-ep-89</link>
      <description>AI is bringing convenience to your healthcare experience. Health insurance company Anthem helps patients personalize and better understand their healthcare information through AI. We spoke with 
Rajeev Ronanki, senior vice president and chief digital officer at Anthem, about how AI makes data "meaningful and useful," for the healthcare giant.</description>
      <pubDate>Wed, 26 Jun 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f0bc5bf6-f45b-11ef-8be6-ff283a72ef5b/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is bringing convenience to your healthcare exp…</itunes:subtitle>
      <itunes:summary>AI is bringing convenience to your healthcare experience. Health insurance company Anthem helps patients personalize and better understand their healthcare information through AI. We spoke with 
Rajeev Ronanki, senior vice president and chief digital officer at Anthem, about how AI makes data "meaningful and useful," for the healthcare giant.</itunes:summary>
      <content:encoded>
        <![CDATA[AI is bringing convenience to your healthcare experience. Health insurance company Anthem helps patients personalize and better understand their healthcare information through AI. We spoke with 
Rajeev Ronanki, senior vice president and chief digital officer at Anthem, about how AI makes data "meaningful and useful," for the healthcare giant.]]>
      </content:encoded>
      <itunes:duration>1273</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/642179742]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2087865091.mp3?updated=1740586419" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>SAS Chief Operating Officer Oliver Schabenberger - Ep. 88</title>
      <link>https://soundcloud.com/theaipodcast/sas-chief-operating-officer-oliver-schabenberger-ep-88</link>
      <description>SAS Chief Operating Officer Oliver Schabenberger spoke with us about how organizations can use AI and related technologies.</description>
      <pubDate>Tue, 04 Jun 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f119e186-f45b-11ef-8be6-8f0b8325d384/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>SAS Chief Operating Officer Oliver Schabenberger …</itunes:subtitle>
      <itunes:summary>SAS Chief Operating Officer Oliver Schabenberger spoke with us about how organizations can use AI and related technologies.</itunes:summary>
      <content:encoded>
        <![CDATA[SAS Chief Operating Officer Oliver Schabenberger spoke with us about how organizations can use AI and related technologies.]]>
      </content:encoded>
      <itunes:duration>1001</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/631121661]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4231198610.mp3?updated=1740586420" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>AutoX's Professor X on the State of Automotive Autonomy - Ep. 87</title>
      <link>https://soundcloud.com/theaipodcast/autox-jianxiong-xiao</link>
      <description>The path to self driving vehicles is usually marked by six milestones, or levels, from level 0, or no automation, to level 5, or full autonomy. Jianxiong Xiao, CEO of of startup  AutoX, has his sights set on level 4, defined by the National Highway Traffic Administration as “a car capable of performing all driving functions under certain conditions."</description>
      <pubDate>Wed, 29 May 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f179081e-f45b-11ef-8be6-4beda49119c7/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The path to self driving vehicles is usually mark…</itunes:subtitle>
      <itunes:summary>The path to self driving vehicles is usually marked by six milestones, or levels, from level 0, or no automation, to level 5, or full autonomy. Jianxiong Xiao, CEO of of startup  AutoX, has his sights set on level 4, defined by the National Highway Traffic Administration as “a car capable of performing all driving functions under certain conditions."</itunes:summary>
      <content:encoded>
        <![CDATA[The path to self driving vehicles is usually marked by six milestones, or levels, from level 0, or no automation, to level 5, or full autonomy. Jianxiong Xiao, CEO of of startup  AutoX, has his sights set on level 4, defined by the National Highway Traffic Administration as “a car capable of performing all driving functions under certain conditions."]]>
      </content:encoded>
      <itunes:duration>1280</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/624446466]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9292831699.mp3?updated=1740586420" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>A-High: How Grownetics Automates Cannabis Cultivation with Deep Learning - Ep. 86</title>
      <link>https://soundcloud.com/theaipodcast/ai-cannabis-grownetics</link>
      <description>Sticky. Kind. Chronic. Reefer. Forget the dated slang. These days the word is ‘opportunity.’ The market for legal cannabis in the United States was estimated at $12 billion last year, up 30% year over year from 2017, and it’s projected to grow to $44 billion by 2020. Our guests this episode is Vincent Harkiewicz, is CEO and co-founder of Boulder, Colorado-based Grownetics, a startup that sits at the intersection of agtech, marjijuana, data analytics and artificial intelligence.</description>
      <pubDate>Tue, 21 May 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f1d601cc-f45b-11ef-8be6-bb75fd00e862/image/c6b46bd5bb7d7d70efcd6e1ed70b1bc5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Sticky. Kind. Chronic. Reefer. Forget the dated s…</itunes:subtitle>
      <itunes:summary>Sticky. Kind. Chronic. Reefer. Forget the dated slang. These days the word is ‘opportunity.’ The market for legal cannabis in the United States was estimated at $12 billion last year, up 30% year over year from 2017, and it’s projected to grow to $44 billion by 2020. Our guests this episode is Vincent Harkiewicz, is CEO and co-founder of Boulder, Colorado-based Grownetics, a startup that sits at the intersection of agtech, marjijuana, data analytics and artificial intelligence.</itunes:summary>
      <content:encoded>
        <![CDATA[Sticky. Kind. Chronic. Reefer. Forget the dated slang. These days the word is ‘opportunity.’ The market for legal cannabis in the United States was estimated at $12 billion last year, up 30% year over year from 2017, and it’s projected to grow to $44 billion by 2020. Our guests this episode is Vincent Harkiewicz, is CEO and co-founder of Boulder, Colorado-based Grownetics, a startup that sits at the intersection of agtech, marjijuana, data analytics and artificial intelligence.]]>
      </content:encoded>
      <itunes:duration>1663</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/624422646]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3584520080.mp3?updated=1740586421" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Teaching Families to Embrace AI - Ep. 85</title>
      <link>https://soundcloud.com/theaipodcast/teaching-families-to-embrace-ai-ep-84</link>
      <description>Tara Chklovski is CEO and founder of Iridescent, a non-profit that provides access to hands on learning opportunities to prepare underrepresented children and adults for the future of work. She’s been called everything from the “pioneer empowering the incredible tech girls of the future,” to a “CEO science superstar hero.” Tara is here to talk about a bunch of things, including the UN’s AI for Good Global Summit this May in Geneva, and the AI World Championship, part of the AI Family Challenge, May 18 in Silicon Valley.</description>
      <pubDate>Thu, 16 May 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f23427b6-f45b-11ef-8be6-7ff6c2030a5c/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Tara Chklovski is CEO and founder of Iridescent, …</itunes:subtitle>
      <itunes:summary>Tara Chklovski is CEO and founder of Iridescent, a non-profit that provides access to hands on learning opportunities to prepare underrepresented children and adults for the future of work. She’s been called everything from the “pioneer empowering the incredible tech girls of the future,” to a “CEO science superstar hero.” Tara is here to talk about a bunch of things, including the UN’s AI for Good Global Summit this May in Geneva, and the AI World Championship, part of the AI Family Challenge, May 18 in Silicon Valley.</itunes:summary>
      <content:encoded>
        <![CDATA[Tara Chklovski is CEO and founder of Iridescent, a non-profit that provides access to hands on learning opportunities to prepare underrepresented children and adults for the future of work. She’s been called everything from the “pioneer empowering the incredible tech girls of the future,” to a “CEO science superstar hero.” Tara is here to talk about a bunch of things, including the UN’s AI for Good Global Summit this May in Geneva, and the AI World Championship, part of the AI Family Challenge, May 18 in Silicon Valley.]]>
      </content:encoded>
      <itunes:duration>1802</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/621751281]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3836838437.mp3?updated=1740586421" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Astronomers Turn to AI as New Telescopes Come Online - Ep. 84</title>
      <link>https://soundcloud.com/theaipodcast/brant-robertson-astronomy</link>
      <description>Good news: astronomers are getting new tools to let them see further, better than ever before. The bad news: they’ll soon be getting more data than humans can handle. To turn the vast quantities of data that will be pouring out of these instruments into world-changing scientific discoveries, Brant Robertson, a visiting professor at the Institute for Advanced Study in Princeton and an associate professor of astronomy at UC Santa Cruz, is turning to AI.</description>
      <pubDate>Wed, 01 May 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f2909960-f45b-11ef-8be6-eb9eaa1e0369/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Good news: astronomers are getting new tools to l…</itunes:subtitle>
      <itunes:summary>Good news: astronomers are getting new tools to let them see further, better than ever before. The bad news: they’ll soon be getting more data than humans can handle. To turn the vast quantities of data that will be pouring out of these instruments into world-changing scientific discoveries, Brant Robertson, a visiting professor at the Institute for Advanced Study in Princeton and an associate professor of astronomy at UC Santa Cruz, is turning to AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Good news: astronomers are getting new tools to let them see further, better than ever before. The bad news: they’ll soon be getting more data than humans can handle. To turn the vast quantities of data that will be pouring out of these instruments into world-changing scientific discoveries, Brant Robertson, a visiting professor at the Institute for Advanced Study in Princeton and an associate professor of astronomy at UC Santa Cruz, is turning to AI.]]>
      </content:encoded>
      <itunes:duration>1340</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/614526855]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2461053044.mp3?updated=1740586422" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Primer's Sean Gourley on Bots, Propaganda and Fake News - Ep. 83</title>
      <link>https://soundcloud.com/theaipodcast/primer-sean-gourley</link>
      <description>In 2015 today's guest penned an article called "Robot Propaganda" for Wired magazine. It contained this then bold prediction: "we are likely to see versions of these bots deployed on U.S. audiences as part of the 2016 presidential election campaigns." Well we all know how that turned out. Sean Gourley, founder and CEO of Primer, joined us to talk about bots, propaganda and fake news and how they relate to the work his own company is doing in natural language understanding and generation.</description>
      <pubDate>Sun, 21 Apr 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f2ebf580-f45b-11ef-8be6-3b893120485b/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In 2015 today's guest penned an article called "R…</itunes:subtitle>
      <itunes:summary>In 2015 today's guest penned an article called "Robot Propaganda" for Wired magazine. It contained this then bold prediction: "we are likely to see versions of these bots deployed on U.S. audiences as part of the 2016 presidential election campaigns." Well we all know how that turned out. Sean Gourley, founder and CEO of Primer, joined us to talk about bots, propaganda and fake news and how they relate to the work his own company is doing in natural language understanding and generation.</itunes:summary>
      <content:encoded>
        <![CDATA[In 2015 today's guest penned an article called "Robot Propaganda" for Wired magazine. It contained this then bold prediction: "we are likely to see versions of these bots deployed on U.S. audiences as part of the 2016 presidential election campaigns." Well we all know how that turned out. Sean Gourley, founder and CEO of Primer, joined us to talk about bots, propaganda and fake news and how they relate to the work his own company is doing in natural language understanding and generation.]]>
      </content:encoded>
      <itunes:duration>1831</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/610888797]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4008692438.mp3?updated=1740586423" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>UC Berkeley’s Pieter Abbeel on How Deep Learning Will Help Robots Learn - Ep. 82</title>
      <link>https://soundcloud.com/theaipodcast/pieter-abbeel-ep-82</link>
      <description>Robots can do amazing things. Compare even the most advanced robots to a three-year old, however, and they can come up short. UC Berkeley Professor Pieter Abbeel has pioneered the idea that deep learning could be the key to bridging that gap: creating robots that can learn how move through the world more fluidly and naturally. We caught up with Abbeel, who is director of the Berkeley Robot Learning Lab and cofounder of Covariant AI, a Bay Area company developing AI software that makes it easy to teach robots new and complex skills, at GTC 2019.</description>
      <pubDate>Thu, 11 Apr 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f346282a-f45b-11ef-8be6-bb70ce43a957/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Robots can do amazing things. Compare even the mo…</itunes:subtitle>
      <itunes:summary>Robots can do amazing things. Compare even the most advanced robots to a three-year old, however, and they can come up short. UC Berkeley Professor Pieter Abbeel has pioneered the idea that deep learning could be the key to bridging that gap: creating robots that can learn how move through the world more fluidly and naturally. We caught up with Abbeel, who is director of the Berkeley Robot Learning Lab and cofounder of Covariant AI, a Bay Area company developing AI software that makes it easy to teach robots new and complex skills, at GTC 2019.</itunes:summary>
      <content:encoded>
        <![CDATA[Robots can do amazing things. Compare even the most advanced robots to a three-year old, however, and they can come up short. UC Berkeley Professor Pieter Abbeel has pioneered the idea that deep learning could be the key to bridging that gap: creating robots that can learn how move through the world more fluidly and naturally. We caught up with Abbeel, who is director of the Berkeley Robot Learning Lab and cofounder of Covariant AI, a Bay Area company developing AI software that makes it easy to teach robots new and complex skills, at GTC 2019.]]>
      </content:encoded>
      <itunes:duration>1418</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/604056732]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3505226585.mp3?updated=1740586423" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How the Breakthrough Listen Harnessed AI in the Search for Aliens - Ep. 81</title>
      <link>https://soundcloud.com/theaipodcast/gerry-zhang-ai-seti-institute</link>
      <description>UC Berkeley's Gerry Zhang talks about his work using deep learning to analyze signals from space for signs of intelligent extraterrestrial civilizations. And while we haven't found aliens, yet, the doctoral student has already made some extraordinary discoveries.</description>
      <pubDate>Wed, 27 Mar 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f3a372c8-f45b-11ef-8be6-df0e67dacd2f/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>UC Berkeley's Gerry Zhang talks about his work us…</itunes:subtitle>
      <itunes:summary>UC Berkeley's Gerry Zhang talks about his work using deep learning to analyze signals from space for signs of intelligent extraterrestrial civilizations. And while we haven't found aliens, yet, the doctoral student has already made some extraordinary discoveries.</itunes:summary>
      <content:encoded>
        <![CDATA[UC Berkeley's Gerry Zhang talks about his work using deep learning to analyze signals from space for signs of intelligent extraterrestrial civilizations. And while we haven't found aliens, yet, the doctoral student has already made some extraordinary discoveries.]]>
      </content:encoded>
      <itunes:duration>1121</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/598105551]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6569504264.mp3?updated=1740586424" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ready for the Playoffs? Swish Analytics Can Help You Clean Up - Ep. 80</title>
      <link>https://soundcloud.com/theaipodcast/march-madness-swish-analytics</link>
      <description>Not sure who will win the NBA playoffs? Looking for coaching when putting together your fantasy football team? Swish Analytics uses AI to help you pick winners. Corey Beaumont, co-founder and head of engineering at the startup, explains how Swish Analytics takes the same kind of mathematical models lenders use to assess whether a borrower is a good risk and applies them to the $1 trillion sports betting market.</description>
      <pubDate>Thu, 14 Mar 2019 20:51:14 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f400d080-f45b-11ef-8be6-27178bbf552b/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Not sure who will win the NBA playoffs? Looking f…</itunes:subtitle>
      <itunes:summary>Not sure who will win the NBA playoffs? Looking for coaching when putting together your fantasy football team? Swish Analytics uses AI to help you pick winners. Corey Beaumont, co-founder and head of engineering at the startup, explains how Swish Analytics takes the same kind of mathematical models lenders use to assess whether a borrower is a good risk and applies them to the $1 trillion sports betting market.</itunes:summary>
      <content:encoded>
        <![CDATA[Not sure who will win the NBA playoffs? Looking for coaching when putting together your fantasy football team? Swish Analytics uses AI to help you pick winners. Corey Beaumont, co-founder and head of engineering at the startup, explains how Swish Analytics takes the same kind of mathematical models lenders use to assess whether a borrower is a good risk and applies them to the $1 trillion sports betting market.]]>
      </content:encoded>
      <itunes:duration>1551</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/589251633]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9315597192.mp3?updated=1740586424" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How AI Helps GOAT Keep Sneakerheads a Step Ahead - Ep. 79</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-goat-gtc</link>
      <description>GOAT Group helps sneaker enthusiasts get their hands on authentic Air Jordans, Yeezys and a variety of old-school kicks with the help of AI. Michael Hall, director of data at GOAT Group explains how in a conversation with AI Podcast host Noah Kravitz.</description>
      <pubDate>Tue, 26 Feb 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f45da5a8-f45b-11ef-8be6-b375826a286e/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>GOAT Group helps sneaker enthusiasts get their ha…</itunes:subtitle>
      <itunes:summary>GOAT Group helps sneaker enthusiasts get their hands on authentic Air Jordans, Yeezys and a variety of old-school kicks with the help of AI. Michael Hall, director of data at GOAT Group explains how in a conversation with AI Podcast host Noah Kravitz.</itunes:summary>
      <content:encoded>
        <![CDATA[GOAT Group helps sneaker enthusiasts get their hands on authentic Air Jordans, Yeezys and a variety of old-school kicks with the help of AI. Michael Hall, director of data at GOAT Group explains how in a conversation with AI Podcast host Noah Kravitz.]]>
      </content:encoded>
      <itunes:duration>1940</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/581410521]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6764186881.mp3?updated=1740586425" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Nuance Brings AI to Healthcare - Ep. 78</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-karen-holzberger-nuance-f2</link>
      <description>You probably recognize the name Nuance from their work with speech recognition and virtual assistant technology. They’re one of the pioneers of voice recognition technology. Of course Nuance Communications has gotten into AI, but what you might not know is they’ve also gotten into using AI to chart the course of the healthcare industry and how physicians can use artificial intelligence to make people healthier and make their work better, Karen Holzberger is the vice president and general manager of Nuance’s Healthcare diagnostic solutions business.</description>
      <pubDate>Mon, 11 Feb 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f4bc4ca2-f45b-11ef-8be6-bf1794a27d56/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>You probably recognize the name Nuance from their…</itunes:subtitle>
      <itunes:summary>You probably recognize the name Nuance from their work with speech recognition and virtual assistant technology. They’re one of the pioneers of voice recognition technology. Of course Nuance Communications has gotten into AI, but what you might not know is they’ve also gotten into using AI to chart the course of the healthcare industry and how physicians can use artificial intelligence to make people healthier and make their work better, Karen Holzberger is the vice president and general manager of Nuance’s Healthcare diagnostic solutions business.</itunes:summary>
      <content:encoded>
        <![CDATA[You probably recognize the name Nuance from their work with speech recognition and virtual assistant technology. They’re one of the pioneers of voice recognition technology. Of course Nuance Communications has gotten into AI, but what you might not know is they’ve also gotten into using AI to chart the course of the healthcare industry and how physicians can use artificial intelligence to make people healthier and make their work better, Karen Holzberger is the vice president and general manager of Nuance’s Healthcare diagnostic solutions business.]]>
      </content:encoded>
      <itunes:duration>1396</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/575356416]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5998113412.mp3?updated=1740586426" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Sort Circuit: How GPUs Helped One Man Conquer His Lego Pile - Ep. 77</title>
      <link>https://soundcloud.com/theaipodcast/sort-circuit-how-gpus-helped-one-man-conquer-his-lego-pile-ep-77</link>
      <description>At some point in life, every man faces the same great challenge: sorting out his children's Lego pile. Thanks to GPU-driven deep learning, Francisco "Paco" Garcia is one of the few men who can say they've conquered it. Here's how.</description>
      <pubDate>Wed, 23 Jan 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f51b3f1e-f45b-11ef-8be6-cfcbe3e76661/image/1d0fb4d501df54a10d5571ceb8280a44.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>At some point in life, every man faces the same g…</itunes:subtitle>
      <itunes:summary>At some point in life, every man faces the same great challenge: sorting out his children's Lego pile. Thanks to GPU-driven deep learning, Francisco "Paco" Garcia is one of the few men who can say they've conquered it. Here's how.</itunes:summary>
      <content:encoded>
        <![CDATA[At some point in life, every man faces the same great challenge: sorting out his children's Lego pile. Thanks to GPU-driven deep learning, Francisco "Paco" Garcia is one of the few men who can say they've conquered it. Here's how.]]>
      </content:encoded>
      <itunes:duration>1810</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/561225171]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3684649324.mp3?updated=1740586426" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>A Man, a GAN, and a 1080 Ti: How Jason Antic Created 'De-Oldify'  - Ep. 76</title>
      <link>https://soundcloud.com/theaipodcast/how-jason-antic-used-deep-learning-to-make-old-photos-look-new-ep-73</link>
      <description>You don't need to be an an academic or to work for a big company to get into deep learning. You can just be a guy with a NVIDIA GeForce 1080 Ti and a Generative Adversarial network. Jason Antic, who describes himself as "a software guy," began digging deep into GANS. Next thing you know: he’s created an increasingly popular tool that colors old black-and-white shots to make them look good. Interested in digging into AI for yourself? Listen and get inspired.</description>
      <pubDate>Wed, 09 Jan 2019 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f589fea4-f45b-11ef-8be6-33092b72ea3f/image/8bb4089f566189f201a14098c3412c62.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>You don't need to be an an academic or to work fo…</itunes:subtitle>
      <itunes:summary>You don't need to be an an academic or to work for a big company to get into deep learning. You can just be a guy with a NVIDIA GeForce 1080 Ti and a Generative Adversarial network. Jason Antic, who describes himself as "a software guy," began digging deep into GANS. Next thing you know: he’s created an increasingly popular tool that colors old black-and-white shots to make them look good. Interested in digging into AI for yourself? Listen and get inspired.</itunes:summary>
      <content:encoded>
        <![CDATA[You don't need to be an an academic or to work for a big company to get into deep learning. You can just be a guy with a NVIDIA GeForce 1080 Ti and a Generative Adversarial network. Jason Antic, who describes himself as "a software guy," began digging deep into GANS. Next thing you know: he’s created an increasingly popular tool that colors old black-and-white shots to make them look good. Interested in digging into AI for yourself? Listen and get inspired.]]>
      </content:encoded>
      <itunes:duration>1726</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/556350426]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2648904227.mp3?updated=1740586427" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How SoundHound Uses AI to Bring Voice and Music Recognition to Any Platform - Ep. 75</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-soundhound</link>
      <description>SoundHound made its name as music identification service. Since then, SoundHound has become much more. It's leveraged its 10 plus years in data analytics to create a voice recognition tool companies can bake into any product. Here to tell us how SoundHound has grown into a major player in voice driven Ai is SoundHoud VP of Product Marketing Mike Zagorsek.</description>
      <pubDate>Wed, 19 Dec 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f5e4c168-f45b-11ef-8be6-83018e607c94/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>SoundHound made its name as music identification …</itunes:subtitle>
      <itunes:summary>SoundHound made its name as music identification service. Since then, SoundHound has become much more. It's leveraged its 10 plus years in data analytics to create a voice recognition tool companies can bake into any product. Here to tell us how SoundHound has grown into a major player in voice driven Ai is SoundHoud VP of Product Marketing Mike Zagorsek.</itunes:summary>
      <content:encoded>
        <![CDATA[SoundHound made its name as music identification service. Since then, SoundHound has become much more. It's leveraged its 10 plus years in data analytics to create a voice recognition tool companies can bake into any product. Here to tell us how SoundHound has grown into a major player in voice driven Ai is SoundHoud VP of Product Marketing Mike Zagorsek.]]>
      </content:encoded>
      <itunes:duration>1713</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/548027694]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5445071380.mp3?updated=1740586428" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Good News About Fake News: AI Can Now Help Detect False Information - Ep. 74</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-vagelis-papalexakis-fake-news</link>
      <description>With “Fake News” embedding itself into, well, our news, it’s become more important than ever to distinguish between content that is fake or authentic. That’s why Vagelis Papalexakis, a professor of computer science at the University of California, Riverside, developed an algorithm that detects fake news with 75 percent accuracy.</description>
      <pubDate>Thu, 06 Dec 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f6422f1a-f45b-11ef-8be6-a3a3d12a28c4/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>With “Fake News” embedding itself into, well, our…</itunes:subtitle>
      <itunes:summary>With “Fake News” embedding itself into, well, our news, it’s become more important than ever to distinguish between content that is fake or authentic. That’s why Vagelis Papalexakis, a professor of computer science at the University of California, Riverside, developed an algorithm that detects fake news with 75 percent accuracy.</itunes:summary>
      <content:encoded>
        <![CDATA[With “Fake News” embedding itself into, well, our news, it’s become more important than ever to distinguish between content that is fake or authentic. That’s why Vagelis Papalexakis, a professor of computer science at the University of California, Riverside, developed an algorithm that detects fake news with 75 percent accuracy.]]>
      </content:encoded>
      <itunes:duration>1605</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/539956314]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6425976454.mp3?updated=1740586428" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>A Conversation with the Entrepreneur Behind the World's Most Realistic Artificial Voices - Ep. 73</title>
      <link>https://soundcloud.com/theaipodcast/a-conversation-with-the-entrepreneur-behind-the-worlds-most-realistic-artificial-voices-ep-73</link>
      <description>Voice recognition is one thing, creating natural sounding artificial voices is quite another. Lyrebird - a member of NVIDIA’s Inception startup program - uses deep learning to take this a step further, with a system that's able to listen to a human voices and generate speech that mimics the sound of the original, human, speaker. We spoke with Lyrebird co-founder Jose Solero about the benefits of this technology, and why he feels the need to educate the public about what's possible.</description>
      <pubDate>Wed, 21 Nov 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f69e16fe-f45b-11ef-8be6-6b3df2ab8757/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Voice recognition is one thing, creating natural …</itunes:subtitle>
      <itunes:summary>Voice recognition is one thing, creating natural sounding artificial voices is quite another. Lyrebird - a member of NVIDIA’s Inception startup program - uses deep learning to take this a step further, with a system that's able to listen to a human voices and generate speech that mimics the sound of the original, human, speaker. We spoke with Lyrebird co-founder Jose Solero about the benefits of this technology, and why he feels the need to educate the public about what's possible.</itunes:summary>
      <content:encoded>
        <![CDATA[Voice recognition is one thing, creating natural sounding artificial voices is quite another. Lyrebird - a member of NVIDIA’s Inception startup program - uses deep learning to take this a step further, with a system that's able to listen to a human voices and generate speech that mimics the sound of the original, human, speaker. We spoke with Lyrebird co-founder Jose Solero about the benefits of this technology, and why he feels the need to educate the public about what's possible.]]>
      </content:encoded>
      <itunes:duration>2168</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/533486289]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3478222809.mp3?updated=1740586429" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Investor, AI Pioneer Kai-Fu Lee on the Future of AI in the US, China - Ep. 72</title>
      <link>https://soundcloud.com/theaipodcast/kai-fu-lee-ai</link>
      <description>Dr. Kai-Fu Lee has been at the center of artificial intelligence for decades. 

dr. Lee developed the world's first speaker independent continuous speech recognition system, selected as the most important innovation of the year by BusinessWeek, and that was back in 1988. 

In the three decades since, Dr. Lee has led teams at Apple, Silicon Graphics, Microsoft and Google. 

In 2009 Dr. Lee left Google to start Sinovation Ventures, which now manages a $2 billion fund focusing on technology startups in China and the United States. 

His latest book, "AI Superpowers: China, Silicon Valley, and the New World Order," ranks number six on the New York Times Business Books best sellers list.</description>
      <pubDate>Wed, 07 Nov 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f6f9f712-f45b-11ef-8be6-f37d67a39c93/image/0df32a0dee423ff800b30b555ef75d6e.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Dr. Kai-Fu Lee has been at the center of artifici…</itunes:subtitle>
      <itunes:summary>Dr. Kai-Fu Lee has been at the center of artificial intelligence for decades. 

dr. Lee developed the world's first speaker independent continuous speech recognition system, selected as the most important innovation of the year by BusinessWeek, and that was back in 1988. 

In the three decades since, Dr. Lee has led teams at Apple, Silicon Graphics, Microsoft and Google. 

In 2009 Dr. Lee left Google to start Sinovation Ventures, which now manages a $2 billion fund focusing on technology startups in China and the United States. 

His latest book, "AI Superpowers: China, Silicon Valley, and the New World Order," ranks number six on the New York Times Business Books best sellers list.</itunes:summary>
      <content:encoded>
        <![CDATA[Dr. Kai-Fu Lee has been at the center of artificial intelligence for decades. 

dr. Lee developed the world's first speaker independent continuous speech recognition system, selected as the most important innovation of the year by BusinessWeek, and that was back in 1988. 

In the three decades since, Dr. Lee has led teams at Apple, Silicon Graphics, Microsoft and Google. 

In 2009 Dr. Lee left Google to start Sinovation Ventures, which now manages a $2 billion fund focusing on technology startups in China and the United States. 

His latest book, "AI Superpowers: China, Silicon Valley, and the New World Order," ranks number six on the New York Times Business Books best sellers list.]]>
      </content:encoded>
      <itunes:duration>2033</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/525762432]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2221055844.mp3?updated=1740586429" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Intuit Uses Deep Learning to Help You with Your Taxes - Ep. 71</title>
      <link>https://soundcloud.com/theaipodcast/ep-71</link>
      <description>Intuit Senior Vice President and Chief Data Officer Ashok Srivastava on how the personal finance giant is using AI to help make us all smarter about our finances.</description>
      <pubDate>Wed, 24 Oct 2018 14:47:41 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f756d734-f45b-11ef-8be6-f32c9f2ad5fa/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Intuit Senior Vice President and Chief Data Offic…</itunes:subtitle>
      <itunes:summary>Intuit Senior Vice President and Chief Data Officer Ashok Srivastava on how the personal finance giant is using AI to help make us all smarter about our finances.</itunes:summary>
      <content:encoded>
        <![CDATA[Intuit Senior Vice President and Chief Data Officer Ashok Srivastava on how the personal finance giant is using AI to help make us all smarter about our finances.]]>
      </content:encoded>
      <itunes:duration>1922</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/519141165]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9660697367.mp3?updated=1740586430" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>What's in Your Wallet? For Capital One, the Answer Is AI - Ep. 70</title>
      <link>https://soundcloud.com/theaipodcast/whats-in-your-wallet-for-capital-one-the-answer-is-ai-ep-70</link>
      <description>When you hear of AI and machine learning, it’s easy to think of technology companies leading the charge. Capital One is determined to change that. In a conversation with AI Podcast host Noah Kravitz, Nitzan Mekel, managing vice president of machine learning at Capital One, explained how the banking giant is integrating AI and machine learning into customer-facing applications such as fraud-monitoring and detection, call center operations and customer experience.</description>
      <pubDate>Wed, 10 Oct 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f7b50ade-f45b-11ef-8be6-a3cd09e1d831/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>When you hear of AI and machine learning, it’s ea…</itunes:subtitle>
      <itunes:summary>When you hear of AI and machine learning, it’s easy to think of technology companies leading the charge. Capital One is determined to change that. In a conversation with AI Podcast host Noah Kravitz, Nitzan Mekel, managing vice president of machine learning at Capital One, explained how the banking giant is integrating AI and machine learning into customer-facing applications such as fraud-monitoring and detection, call center operations and customer experience.</itunes:summary>
      <content:encoded>
        <![CDATA[When you hear of AI and machine learning, it’s easy to think of technology companies leading the charge. Capital One is determined to change that. In a conversation with AI Podcast host Noah Kravitz, Nitzan Mekel, managing vice president of machine learning at Capital One, explained how the banking giant is integrating AI and machine learning into customer-facing applications such as fraud-monitoring and detection, call center operations and customer experience.]]>
      </content:encoded>
      <itunes:duration>1476</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/512168646]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8364631719.mp3?updated=1740586431" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Cycle of DOOM Now Complete: Researchers Use AI to Generate New Levels for Seminal Videogame - Ep. 69</title>
      <link>https://soundcloud.com/theaipodcast/the-cycle-of-doom-now-complete-researchers-use-ai-to-generate-new-levels-for-seminal-videogame-ep-69</link>
      <description>DOOM, of course, is foundational to 3D gaming. 3D gaming, of course, is foundational to GPUs. GPUs, of course, are foundational to deep learning, which is, now, thanks to a team of Italian researchers, two of whom we're bringing to you with this podcast, being used to make new levels for... DOOM.</description>
      <pubDate>Mon, 17 Sep 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f83c237a-f45b-11ef-8be6-9ff61dc08a18/image/90fafa651a91fe342661b5b3a1973f6a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>DOOM, of course, is foundational to 3D gaming. 3D…</itunes:subtitle>
      <itunes:summary>DOOM, of course, is foundational to 3D gaming. 3D gaming, of course, is foundational to GPUs. GPUs, of course, are foundational to deep learning, which is, now, thanks to a team of Italian researchers, two of whom we're bringing to you with this podcast, being used to make new levels for... DOOM.</itunes:summary>
      <content:encoded>
        <![CDATA[DOOM, of course, is foundational to 3D gaming. 3D gaming, of course, is foundational to GPUs. GPUs, of course, are foundational to deep learning, which is, now, thanks to a team of Italian researchers, two of whom we're bringing to you with this podcast, being used to make new levels for... DOOM.]]>
      </content:encoded>
      <itunes:duration>1374</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/502348308]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2284249463.mp3?updated=1740586432" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>This Astrophysics Grad Student Doesn't Always Make Memes... But When He Does, He Uses Deep Learning</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-dank-memes-lawrence-pierson</link>
      <description>What's a meme? And what makes a meme, dank? Today's guest is Lawrence Pierson, a PhD student in theoretical astrophysics at Stanford University, will answer these questions, and more. He's the author a paper detailing how he and a classmate built a neural network to generate memes. Some of them are even funny.</description>
      <pubDate>Wed, 29 Aug 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f89ed844-f45b-11ef-8be6-338901c5574e/image/40a036637353f2f356876e97c7694316.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>What's a meme? And what makes a meme, dank? Today…</itunes:subtitle>
      <itunes:summary>What's a meme? And what makes a meme, dank? Today's guest is Lawrence Pierson, a PhD student in theoretical astrophysics at Stanford University, will answer these questions, and more. He's the author a paper detailing how he and a classmate built a neural network to generate memes. Some of them are even funny.</itunes:summary>
      <content:encoded>
        <![CDATA[What's a meme? And what makes a meme, dank? Today's guest is Lawrence Pierson, a PhD student in theoretical astrophysics at Stanford University, will answer these questions, and more. He's the author a paper detailing how he and a classmate built a neural network to generate memes. Some of them are even funny.]]>
      </content:encoded>
      <itunes:duration>1630</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/495430923]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6909660121.mp3?updated=1740586432" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Teaching Bots Learn by Watching Human Behavior - Ep. 67</title>
      <link>https://soundcloud.com/theaipodcast/ai-stanford-svl-ep-67</link>
      <description>Robots following coded instructions to complete a task? Old school. Robots learning to do things by watching how humans do it? That’s the future. Earlier this year, Stanford’s Animesh Garg and Marynel Vázquez shared their research in a talk on “Generalizable Autonomy for Robotic Mobility and Manipulation” at the GPU Technology Conference last week.  We caught up with them to learn more about generalizable autonomy - the idea that a robot should be able to observe human behavior, and learn to imitate it in a way that’s applicable to a variety of tasks and situations. Like learning to cook by watching YouTube videos, or figuring out how to cross a crowded room for another.</description>
      <pubDate>Wed, 22 Aug 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f8fba344-f45b-11ef-8be6-1f424b454e32/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Robots following coded instructions to complete a…</itunes:subtitle>
      <itunes:summary>Robots following coded instructions to complete a task? Old school. Robots learning to do things by watching how humans do it? That’s the future. Earlier this year, Stanford’s Animesh Garg and Marynel Vázquez shared their research in a talk on “Generalizable Autonomy for Robotic Mobility and Manipulation” at the GPU Technology Conference last week.  We caught up with them to learn more about generalizable autonomy - the idea that a robot should be able to observe human behavior, and learn to imitate it in a way that’s applicable to a variety of tasks and situations. Like learning to cook by watching YouTube videos, or figuring out how to cross a crowded room for another.</itunes:summary>
      <content:encoded>
        <![CDATA[Robots following coded instructions to complete a task? Old school. Robots learning to do things by watching how humans do it? That’s the future. Earlier this year, Stanford’s Animesh Garg and Marynel Vázquez shared their research in a talk on “Generalizable Autonomy for Robotic Mobility and Manipulation” at the GPU Technology Conference last week.  We caught up with them to learn more about generalizable autonomy - the idea that a robot should be able to observe human behavior, and learn to imitate it in a way that’s applicable to a variety of tasks and situations. Like learning to cook by watching YouTube videos, or figuring out how to cross a crowded room for another.]]>
      </content:encoded>
      <itunes:duration>2231</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/489011793]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6113615083.mp3?updated=1740586433" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Startup Uses Deep Learning to Understand Voice - Ep. 66</title>
      <link>https://soundcloud.com/theaipodcast/ep-70</link>
      <description>Any sufficiently advanced technology is indistinguishable from magic. As the years have passed  what passed since the invention of the personal computer, what passes in the world of technology has changed dramatically. So what’s next? Voice computing is once answer. Voice computing is one of the hottest and most fascinating areas of today’s’ technology landscape. Peter Cahill is the CEO of Voysis, an Irish startup using AI to make voice computing more realistic, and a part of more online retail experiences everywhere.</description>
      <pubDate>Wed, 08 Aug 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f9598130-f45b-11ef-8be6-83373a6b09c8/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Any sufficiently advanced technology is indisting…</itunes:subtitle>
      <itunes:summary>Any sufficiently advanced technology is indistinguishable from magic. As the years have passed  what passed since the invention of the personal computer, what passes in the world of technology has changed dramatically. So what’s next? Voice computing is once answer. Voice computing is one of the hottest and most fascinating areas of today’s’ technology landscape. Peter Cahill is the CEO of Voysis, an Irish startup using AI to make voice computing more realistic, and a part of more online retail experiences everywhere.</itunes:summary>
      <content:encoded>
        <![CDATA[Any sufficiently advanced technology is indistinguishable from magic. As the years have passed  what passed since the invention of the personal computer, what passes in the world of technology has changed dramatically. So what’s next? Voice computing is once answer. Voice computing is one of the hottest and most fascinating areas of today’s’ technology landscape. Peter Cahill is the CEO of Voysis, an Irish startup using AI to make voice computing more realistic, and a part of more online retail experiences everywhere.]]>
      </content:encoded>
      <itunes:duration>1595</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/479848629]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3875361470.mp3?updated=1740586433" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Startup Uses AI to Help Airports Work More Smoothly  - Ep. 65</title>
      <link>https://soundcloud.com/theaipodcast/ai-searidge</link>
      <description>Airport control towers are icons of the aviation industry. But a Canadian startup 
wants to use artificial intelligence to make them a relic of the past. Searidge Technologies believes AI powered video systems can do a better job.</description>
      <pubDate>Wed, 18 Jul 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/f9b7515c-f45b-11ef-8be6-dfb751f377a1/image/98016587a2ca4051cd2be023bc906cd7.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Airport control towers are icons of the aviation …</itunes:subtitle>
      <itunes:summary>Airport control towers are icons of the aviation industry. But a Canadian startup 
wants to use artificial intelligence to make them a relic of the past. Searidge Technologies believes AI powered video systems can do a better job.</itunes:summary>
      <content:encoded>
        <![CDATA[Airport control towers are icons of the aviation industry. But a Canadian startup 
wants to use artificial intelligence to make them a relic of the past. Searidge Technologies believes AI powered video systems can do a better job.]]>
      </content:encoded>
      <itunes:duration>1454</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/471208941]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5970996672.mp3?updated=1740586434" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Startup Uses AI to Give Consumers the Credit They Deserve - Ep. 64</title>
      <link>https://soundcloud.com/theaipodcast/startup-uses-ai-to-give-millennials-the-credit-they-deserve</link>
      <description>Credit scores are a funny thing. Funny might not be the right word, but you know what we mean. You can't have a credit score unless you have a credit history. You have to use your credit to keep your score up, but if your score's not good enough, you can't get credit. But never fear, AI and machine learning are here to help. Our guest on this episode is Ajay Gopal, he's with Deserve, a startup that's using machine learning to extend credit to people who may not have a typical credit history.</description>
      <pubDate>Tue, 03 Jul 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fa1420f8-f45b-11ef-8be6-43e441cf5ec7/image/fe6272fecdc728b1676a451991b85c3f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Credit scores are a funny thing. Funny might not …</itunes:subtitle>
      <itunes:summary>Credit scores are a funny thing. Funny might not be the right word, but you know what we mean. You can't have a credit score unless you have a credit history. You have to use your credit to keep your score up, but if your score's not good enough, you can't get credit. But never fear, AI and machine learning are here to help. Our guest on this episode is Ajay Gopal, he's with Deserve, a startup that's using machine learning to extend credit to people who may not have a typical credit history.</itunes:summary>
      <content:encoded>
        <![CDATA[Credit scores are a funny thing. Funny might not be the right word, but you know what we mean. You can't have a credit score unless you have a credit history. You have to use your credit to keep your score up, but if your score's not good enough, you can't get credit. But never fear, AI and machine learning are here to help. Our guest on this episode is Ajay Gopal, he's with Deserve, a startup that's using machine learning to extend credit to people who may not have a typical credit history.]]>
      </content:encoded>
      <itunes:duration>1246</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/466429455]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6264898665.mp3?updated=1740586435" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA Chief Scientist Bill Dally on Where AI Goes Next - Ep. 62</title>
      <link>https://soundcloud.com/theaipodcast/ai-bill-dally-nvidia-research</link>
      <description>NVIDIA researchers are gearing up to present 19 accepted papers and posters, seven of them during speaking sessions, at the annual Computer Vision and Pattern Recognition conference next week in Salt Lake City, Utah. Joining us to discuss some of what's being presented at CVPR, and to share his perspective on the world of deep learning and AI in general is one of the pillars of the computer science world, Bill Dally, chief scientist at NVIDIA.</description>
      <pubDate>Wed, 13 Jun 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fa6f636e-f45b-11ef-8be6-8f9c265eed96/image/7e36d6e784354d75122db1dd91ce4731.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>NVIDIA researchers are gearing up to present 19 a…</itunes:subtitle>
      <itunes:summary>NVIDIA researchers are gearing up to present 19 accepted papers and posters, seven of them during speaking sessions, at the annual Computer Vision and Pattern Recognition conference next week in Salt Lake City, Utah. Joining us to discuss some of what's being presented at CVPR, and to share his perspective on the world of deep learning and AI in general is one of the pillars of the computer science world, Bill Dally, chief scientist at NVIDIA.</itunes:summary>
      <content:encoded>
        <![CDATA[NVIDIA researchers are gearing up to present 19 accepted papers and posters, seven of them during speaking sessions, at the annual Computer Vision and Pattern Recognition conference next week in Salt Lake City, Utah. Joining us to discuss some of what's being presented at CVPR, and to share his perspective on the world of deep learning and AI in general is one of the pillars of the computer science world, Bill Dally, chief scientist at NVIDIA.]]>
      </content:encoded>
      <itunes:duration>1596</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/458477529]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2851161724.mp3?updated=1740586435" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How AI's Storming the Fashion Industry - Ep. 61</title>
      <link>https://soundcloud.com/theaipodcast/gtc-fashion</link>
      <description>Smarts are always in fashion, and our next guest has that in spades. Costa Colbert has been chasing down how brains — both real and artificial — work for 30 years. Dr. Colbert — who holds degrees in fields ranging from neural science to electrical engineering — is known for his studies of information transmission in pyramidal neurons of the mammalian hippocampus and neocortex. At MAD Street Den his team is putting modern deep learning techniques to work for retailers in a wide variety of ways — including using Generative Adversarial Networks to create images of models wearing clothes.</description>
      <pubDate>Thu, 07 Jun 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fac7bf46-f45b-11ef-8be6-7f263a07c634/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Smarts are always in fashion, and our next guest …</itunes:subtitle>
      <itunes:summary>Smarts are always in fashion, and our next guest has that in spades. Costa Colbert has been chasing down how brains — both real and artificial — work for 30 years. Dr. Colbert — who holds degrees in fields ranging from neural science to electrical engineering — is known for his studies of information transmission in pyramidal neurons of the mammalian hippocampus and neocortex. At MAD Street Den his team is putting modern deep learning techniques to work for retailers in a wide variety of ways — including using Generative Adversarial Networks to create images of models wearing clothes.</itunes:summary>
      <content:encoded>
        <![CDATA[Smarts are always in fashion, and our next guest has that in spades. Costa Colbert has been chasing down how brains — both real and artificial — work for 30 years. Dr. Colbert — who holds degrees in fields ranging from neural science to electrical engineering — is known for his studies of information transmission in pyramidal neurons of the mammalian hippocampus and neocortex. At MAD Street Den his team is putting modern deep learning techniques to work for retailers in a wide variety of ways — including using Generative Adversarial Networks to create images of models wearing clothes.]]>
      </content:encoded>
      <itunes:duration>1542</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/454828680]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1914254897.mp3?updated=1740586436" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Netflix's Justin Basilico on How Entertainment and AI Intersect - Ep. 60</title>
      <link>https://soundcloud.com/theaipodcast/netflixs-justin-basilico-on-how-entertainment-and-ai-intersect-ep-60</link>
      <description>NetFlix has changed the way we watch television for the better. The streaming video pioneer is much more than just an entertainment giant for the 21st century — it’s also a pioneer when it comes to using machine learning. While Justin Basilico, a research director with NetFlix, can’t share all the spoilers, he knows better than anyone how entertainment and machine learning intersect.</description>
      <pubDate>Tue, 29 May 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fb20618c-f45b-11ef-8be6-5b8a4f4a4d79/image/d924a1a9838a23d9db82233ccc5dfb6f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>NetFlix has changed the way we watch television f…</itunes:subtitle>
      <itunes:summary>NetFlix has changed the way we watch television for the better. The streaming video pioneer is much more than just an entertainment giant for the 21st century — it’s also a pioneer when it comes to using machine learning. While Justin Basilico, a research director with NetFlix, can’t share all the spoilers, he knows better than anyone how entertainment and machine learning intersect.</itunes:summary>
      <content:encoded>
        <![CDATA[NetFlix has changed the way we watch television for the better. The streaming video pioneer is much more than just an entertainment giant for the 21st century — it’s also a pioneer when it comes to using machine learning. While Justin Basilico, a research director with NetFlix, can’t share all the spoilers, he knows better than anyone how entertainment and machine learning intersect.]]>
      </content:encoded>
      <itunes:duration>1155</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/447646695]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1252394337.mp3?updated=1740586436" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>A USB Port for Your Body? Startup Uses AI to Connect Medical Devices to Nervous System - Ep. 59</title>
      <link>https://soundcloud.com/theaipodcast/cambridge-bio-augmentation-systems</link>
      <description>Think of it as like a USB port for your body. Emil Hewage is the co-founder and CEO at Cambridge Bio-Augmentation Systems, a neural engineering startup. They UK startup is building interfaces that use AI to help plug medical devices int our nervous systems.  CBAS was named one of the top startups at Y Combinator’s Winter ‘17 cohort by TechCrunch and won the top prize with accelerator MassChallenge UK 2015.</description>
      <pubDate>Tue, 22 May 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fb8099da-f45b-11ef-8be6-8fb0cd2fef90/image/797cb5dcd363f46da94c0f2ef2c0107b.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Think of it as like a USB port for your body. Emi…</itunes:subtitle>
      <itunes:summary>Think of it as like a USB port for your body. Emil Hewage is the co-founder and CEO at Cambridge Bio-Augmentation Systems, a neural engineering startup. They UK startup is building interfaces that use AI to help plug medical devices int our nervous systems.  CBAS was named one of the top startups at Y Combinator’s Winter ‘17 cohort by TechCrunch and won the top prize with accelerator MassChallenge UK 2015.</itunes:summary>
      <content:encoded>
        <![CDATA[Think of it as like a USB port for your body. Emil Hewage is the co-founder and CEO at Cambridge Bio-Augmentation Systems, a neural engineering startup. They UK startup is building interfaces that use AI to help plug medical devices int our nervous systems.  CBAS was named one of the top startups at Y Combinator’s Winter ‘17 cohort by TechCrunch and won the top prize with accelerator MassChallenge UK 2015.]]>
      </content:encoded>
      <itunes:duration>1212</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/444474210]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3661130168.mp3?updated=1740586437" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>The Long View on Big Data: Wayne Thompson, Chief Data Scientist, SAS Data Science Institute - Ep. 58</title>
      <link>https://soundcloud.com/theaipodcast/wayne-thompson-chief-data-scientist-sas-data-science-institute-ep-58</link>
      <description>Wayne Thompson was into big data, before big data was cool. Now the world — even much of our GPU Technology Conference — revolves around the kinds of challenges the 25-year veteran of analytics software developer SAS Institute has made a career of helping enterprises master. How did that happen? We asked Thomson, Chief Data Scientist of SAS Data Science Technologies to talk about the big data, big models, and big computations driving deep learning, and to give us some perspective about what makes today’s deep learning technologies different.</description>
      <pubDate>Thu, 17 May 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fbe0238c-f45b-11ef-8be6-af398c9ff40e/image/d924a1a9838a23d9db82233ccc5dfb6f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Wayne Thompson was into big data, before big data…</itunes:subtitle>
      <itunes:summary>Wayne Thompson was into big data, before big data was cool. Now the world — even much of our GPU Technology Conference — revolves around the kinds of challenges the 25-year veteran of analytics software developer SAS Institute has made a career of helping enterprises master. How did that happen? We asked Thomson, Chief Data Scientist of SAS Data Science Technologies to talk about the big data, big models, and big computations driving deep learning, and to give us some perspective about what makes today’s deep learning technologies different.</itunes:summary>
      <content:encoded>
        <![CDATA[Wayne Thompson was into big data, before big data was cool. Now the world — even much of our GPU Technology Conference — revolves around the kinds of challenges the 25-year veteran of analytics software developer SAS Institute has made a career of helping enterprises master. How did that happen? We asked Thomson, Chief Data Scientist of SAS Data Science Technologies to talk about the big data, big models, and big computations driving deep learning, and to give us some perspective about what makes today’s deep learning technologies different.]]>
      </content:encoded>
      <itunes:duration>1128</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/445529436]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6612664183.mp3?updated=1740586438" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>NVIDIA's Bryan Catanzaro on the Latest from NVIDIA Research - Ep. 57</title>
      <link>https://soundcloud.com/theaipodcast/research</link>
      <description>This week's episode features Bryan Catanzaro, vice president of applied deep learning research at NVIDIA, and if you've been following the podcast for a while, you know that an earlier episode featuring Bryan is one of the most popular podcasts we've done. Bryan is going to walk us through some of the latest developments at NVIDIA research... as well as share a story that involves Andrew Ng and cats.</description>
      <pubDate>Thu, 10 May 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fc3aea6a-f45b-11ef-8be6-0fbe17b841e6/image/203cf9ee3cb96e3e9cf54f9382b99b33.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>This week's episode features Bryan Catanzaro, vic…</itunes:subtitle>
      <itunes:summary>This week's episode features Bryan Catanzaro, vice president of applied deep learning research at NVIDIA, and if you've been following the podcast for a while, you know that an earlier episode featuring Bryan is one of the most popular podcasts we've done. Bryan is going to walk us through some of the latest developments at NVIDIA research... as well as share a story that involves Andrew Ng and cats.</itunes:summary>
      <content:encoded>
        <![CDATA[This week's episode features Bryan Catanzaro, vice president of applied deep learning research at NVIDIA, and if you've been following the podcast for a while, you know that an earlier episode featuring Bryan is one of the most popular podcasts we've done. Bryan is going to walk us through some of the latest developments at NVIDIA research... as well as share a story that involves Andrew Ng and cats.]]>
      </content:encoded>
      <itunes:duration>1180</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/442297113]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5948825411.mp3?updated=1740586438" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Grab and Go: Startup AiFi Using Deep Learning to Make Every Store Smarter - Ep. 56</title>
      <link>https://soundcloud.com/theaipodcast/grab-and-go-store-retail-aifi</link>
      <description>Grab the goods and go. AiFi co-founder and CEO Steve Gu wants to give every store — from Mom and Pop bodegas to supermarket chains — the ability to let customers saunter out of the door without so much as a wave at a checker. The benefits involve more than just convenience: stores will have a better idea of how their customers behave and get a real-time bead on their inventory. To do that, our latest guests and his team at startup AiFi rely on advanced sensor fusion, simulation, and deep learning.</description>
      <pubDate>Wed, 02 May 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fc94b48c-f45b-11ef-8be6-77063898a24d/image/44f8609b9364e562b3221dce5785262f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Grab the goods and go. AiFi co-founder and CEO St…</itunes:subtitle>
      <itunes:summary>Grab the goods and go. AiFi co-founder and CEO Steve Gu wants to give every store — from Mom and Pop bodegas to supermarket chains — the ability to let customers saunter out of the door without so much as a wave at a checker. The benefits involve more than just convenience: stores will have a better idea of how their customers behave and get a real-time bead on their inventory. To do that, our latest guests and his team at startup AiFi rely on advanced sensor fusion, simulation, and deep learning.</itunes:summary>
      <content:encoded>
        <![CDATA[Grab the goods and go. AiFi co-founder and CEO Steve Gu wants to give every store — from Mom and Pop bodegas to supermarket chains — the ability to let customers saunter out of the door without so much as a wave at a checker. The benefits involve more than just convenience: stores will have a better idea of how their customers behave and get a real-time bead on their inventory. To do that, our latest guests and his team at startup AiFi rely on advanced sensor fusion, simulation, and deep learning.]]>
      </content:encoded>
      <itunes:duration>1131</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/438683346]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5476528038.mp3?updated=1740586439" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Deep Learning Can Accelerate the Quest for Cheap, Clean Fusion Energy - Ep. 55</title>
      <link>https://soundcloud.com/theaipodcast/fusion</link>
      <description>Clean, cheap fusion energy would change everything for the better. Our next guest, William Tang, has spent a career at the forefront of that field, currently as principal research physicist at the Princeton Plasma Physics Laboratory. He’s also one of the world’s foremost experts on how the science of fusion energy, and high-performance computing intersect. Now, he sees new tools — deep learning and artificial intelligence — being put to work to enable big-data-driven discovery in key scientific endeavors, such a the quest to deliver Fusion energy.</description>
      <pubDate>Wed, 25 Apr 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fcedf4b6-f45b-11ef-8be6-07b04d909829/image/532cebc3f6448801aade2899e7a53acf.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Clean, cheap fusion energy would change everythin…</itunes:subtitle>
      <itunes:summary>Clean, cheap fusion energy would change everything for the better. Our next guest, William Tang, has spent a career at the forefront of that field, currently as principal research physicist at the Princeton Plasma Physics Laboratory. He’s also one of the world’s foremost experts on how the science of fusion energy, and high-performance computing intersect. Now, he sees new tools — deep learning and artificial intelligence — being put to work to enable big-data-driven discovery in key scientific endeavors, such a the quest to deliver Fusion energy.</itunes:summary>
      <content:encoded>
        <![CDATA[Clean, cheap fusion energy would change everything for the better. Our next guest, William Tang, has spent a career at the forefront of that field, currently as principal research physicist at the Princeton Plasma Physics Laboratory. He’s also one of the world’s foremost experts on how the science of fusion energy, and high-performance computing intersect. Now, he sees new tools — deep learning and artificial intelligence — being put to work to enable big-data-driven discovery in key scientific endeavors, such a the quest to deliver Fusion energy.]]>
      </content:encoded>
      <itunes:duration>1644</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/435221490]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8090404719.mp3?updated=1740586439" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>A Conversation About Go, Sci-Fi, Deep Learning and Computational Chemistry - Ep. 54</title>
      <link>https://soundcloud.com/theaipodcast/deep-learning-computational-chemistry</link>
      <description>Deep learning has helped machines understand how to move pieces around a board to master, and win, Go, the most complicated game mankind has ever invented. Now it's helping a new generation of chemists better understand how to move molecules around to model new kinds of materials. Our guest, Olexandr Isayev, an assistant professor at the UNC Eshelman School of Pharmacy, at the University of North Carolina at Chapel Hill, joined our show to explain how deep learning, Go, sci-fi, and computational chemistry intersect.</description>
      <pubDate>Fri, 20 Apr 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fd46b3f8-f45b-11ef-8be6-17612ab74fa9/image/6453dec79f68cf238b59fc9a53874cd3.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Deep learning has helped machines understand how …</itunes:subtitle>
      <itunes:summary>Deep learning has helped machines understand how to move pieces around a board to master, and win, Go, the most complicated game mankind has ever invented. Now it's helping a new generation of chemists better understand how to move molecules around to model new kinds of materials. Our guest, Olexandr Isayev, an assistant professor at the UNC Eshelman School of Pharmacy, at the University of North Carolina at Chapel Hill, joined our show to explain how deep learning, Go, sci-fi, and computational chemistry intersect.</itunes:summary>
      <content:encoded>
        <![CDATA[Deep learning has helped machines understand how to move pieces around a board to master, and win, Go, the most complicated game mankind has ever invented. Now it's helping a new generation of chemists better understand how to move molecules around to model new kinds of materials. Our guest, Olexandr Isayev, an assistant professor at the UNC Eshelman School of Pharmacy, at the University of North Carolina at Chapel Hill, joined our show to explain how deep learning, Go, sci-fi, and computational chemistry intersect.]]>
      </content:encoded>
      <itunes:duration>1584</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/432240651]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7830852892.mp3?updated=1740586441" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>How Deep Learning Powered Cartman to Victory in the 2017 Amazon Robotics Challenge - Ep. 53</title>
      <link>https://soundcloud.com/theaipodcast/gtc-robots</link>
      <description>How do you win a fast-paced first-person shooter? Answer: it helps to have a good GPU, of course. How do you win one of the world’s most high profile robotics competitions? You guessed it, it helps to have a good GPU. Doug Morrison of the Australian Center for Robotic Vision helped lead the team that developed Cartman, a custom-built, cost-effective robotic system that picked and placed its way to victory in the 2017 Amazon Robotics Challenge global finals in Nagoya Japan last year.</description>
      <pubDate>Thu, 12 Apr 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fd9ffa30-f45b-11ef-8be6-af54dff84edd/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>How do you win a fast-paced first-person shooter?…</itunes:subtitle>
      <itunes:summary>How do you win a fast-paced first-person shooter? Answer: it helps to have a good GPU, of course. How do you win one of the world’s most high profile robotics competitions? You guessed it, it helps to have a good GPU. Doug Morrison of the Australian Center for Robotic Vision helped lead the team that developed Cartman, a custom-built, cost-effective robotic system that picked and placed its way to victory in the 2017 Amazon Robotics Challenge global finals in Nagoya Japan last year.</itunes:summary>
      <content:encoded>
        <![CDATA[How do you win a fast-paced first-person shooter? Answer: it helps to have a good GPU, of course. How do you win one of the world’s most high profile robotics competitions? You guessed it, it helps to have a good GPU. Doug Morrison of the Australian Center for Robotic Vision helped lead the team that developed Cartman, a custom-built, cost-effective robotic system that picked and placed its way to victory in the 2017 Amazon Robotics Challenge global finals in Nagoya Japan last year.]]>
      </content:encoded>
      <itunes:duration>1244</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/428376591]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6613935301.mp3?updated=1740586441" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 52: Live at GTC - How Deep Learning Can Fight Cancer</title>
      <link>https://soundcloud.com/theaipodcast/gtc-deep-learning-cancer</link>
      <description>We talk a lot about technology, and data, specifically, impacting all facets of modern life. In this episode we're going to look at data's role in addressing one of the biggest threats to life as we know it: cancer. We'll talk to Dr. Richard Wender, chief cancer control officer at the American Cancer Society about how technology is key to redefining how we look at, and fight, cancer.</description>
      <pubDate>Wed, 04 Apr 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fdfa8220-f45b-11ef-8be6-b75f406f612b/image/18643e9f04ee1917e6bd9de52845a909.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We talk a lot about technology, and data, specifi…</itunes:subtitle>
      <itunes:summary>We talk a lot about technology, and data, specifically, impacting all facets of modern life. In this episode we're going to look at data's role in addressing one of the biggest threats to life as we know it: cancer. We'll talk to Dr. Richard Wender, chief cancer control officer at the American Cancer Society about how technology is key to redefining how we look at, and fight, cancer.</itunes:summary>
      <content:encoded>
        <![CDATA[We talk a lot about technology, and data, specifically, impacting all facets of modern life. In this episode we're going to look at data's role in addressing one of the biggest threats to life as we know it: cancer. We'll talk to Dr. Richard Wender, chief cancer control officer at the American Cancer Society about how technology is key to redefining how we look at, and fight, cancer.]]>
      </content:encoded>
      <itunes:duration>1664</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/423857382]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8726962139.mp3?updated=1740586441" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 51: Live at GTC - Deep Learning Can Save Lives by Predicting Severe Weather</title>
      <link>https://soundcloud.com/theaipodcast/gtc-weather</link>
      <description>One of the things that makes the weather so dangerous is that it's so hard to predict. Tornadoes, hail, high winds and flash floods cause billions of dollars worth of property damage, and injure or kill hundreds of people in the United States each year. Knowing when storms may strike can save lives, and property. Our guest is part of a team at the National Center for Atmospheric Research that's doing just that. We spoke with David John Gagne, a postdoctoral fellow at the National Center for Atmospheric Research about his work with deep learning at the GPU Technology Conference in Silicon Valley this week.</description>
      <pubDate>Tue, 27 Mar 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/fe5595b6-f45b-11ef-8be6-970a5726ca36/image/e355f78a10f9e90d84c2c1854f24f002.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>One of the things that makes the weather so dange…</itunes:subtitle>
      <itunes:summary>One of the things that makes the weather so dangerous is that it's so hard to predict. Tornadoes, hail, high winds and flash floods cause billions of dollars worth of property damage, and injure or kill hundreds of people in the United States each year. Knowing when storms may strike can save lives, and property. Our guest is part of a team at the National Center for Atmospheric Research that's doing just that. We spoke with David John Gagne, a postdoctoral fellow at the National Center for Atmospheric Research about his work with deep learning at the GPU Technology Conference in Silicon Valley this week.</itunes:summary>
      <content:encoded>
        <![CDATA[One of the things that makes the weather so dangerous is that it's so hard to predict. Tornadoes, hail, high winds and flash floods cause billions of dollars worth of property damage, and injure or kill hundreds of people in the United States each year. Knowing when storms may strike can save lives, and property. Our guest is part of a team at the National Center for Atmospheric Research that's doing just that. We spoke with David John Gagne, a postdoctoral fellow at the National Center for Atmospheric Research about his work with deep learning at the GPU Technology Conference in Silicon Valley this week.]]>
      </content:encoded>
      <itunes:duration>1441</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/421630005]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3076013341.mp3?updated=1740586442" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 50: How Deep Learning Can Make Your Lawyer More Productive</title>
      <link>https://soundcloud.com/theaipodcast/lawyers-ai-legal-lawgeex</link>
      <description>Accountants have spreadsheets. Novelists have word processors. Now, deep learning promises to help take some of the grunt out of legal grunt work. Here's how one startup is using deep learning to help lawyers get legal work done faster and more accurately.</description>
      <pubDate>Wed, 21 Mar 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/feafc6a8-f45b-11ef-8be6-6bd1baa3b4f4/image/4f54d979e3cfbed91fc5d40df39f172d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Accountants have spreadsheets. Novelists have wor…</itunes:subtitle>
      <itunes:summary>Accountants have spreadsheets. Novelists have word processors. Now, deep learning promises to help take some of the grunt out of legal grunt work. Here's how one startup is using deep learning to help lawyers get legal work done faster and more accurately.</itunes:summary>
      <content:encoded>
        <![CDATA[Accountants have spreadsheets. Novelists have word processors. Now, deep learning promises to help take some of the grunt out of legal grunt work. Here's how one startup is using deep learning to help lawyers get legal work done faster and more accurately.]]>
      </content:encoded>
      <itunes:duration>2125</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/418755300]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8026865252.mp3?updated=1740586442" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 49: How GoDaddy Uses AI to Help You Master the Value of Your Domain Name</title>
      <link>https://soundcloud.com/theaipodcast/domain-names-godaddy</link>
      <description>Ever since the internet went mainstream people have been struggling with perhaps the ultimate question: what do I call my web site? What domain name do I register? But almost as quickly as that became a question in people's mind, a secondary question came up: what's my domain name going to be worth? Well thanks to AI we have a better answer to that than ever. Joining us for this episode: Jason Ansel, senior principal engineer with GoDaddy, which is using AI to help you better understand the value of your domain name.</description>
      <pubDate>Thu, 08 Mar 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ff0c1ea8-f45b-11ef-8be6-3333f5a92801/image/eced61902fa1bde9b8cd088b216be542.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Ever since the internet went mainstream people ha…</itunes:subtitle>
      <itunes:summary>Ever since the internet went mainstream people have been struggling with perhaps the ultimate question: what do I call my web site? What domain name do I register? But almost as quickly as that became a question in people's mind, a secondary question came up: what's my domain name going to be worth? Well thanks to AI we have a better answer to that than ever. Joining us for this episode: Jason Ansel, senior principal engineer with GoDaddy, which is using AI to help you better understand the value of your domain name.</itunes:summary>
      <content:encoded>
        <![CDATA[Ever since the internet went mainstream people have been struggling with perhaps the ultimate question: what do I call my web site? What domain name do I register? But almost as quickly as that became a question in people's mind, a secondary question came up: what's my domain name going to be worth? Well thanks to AI we have a better answer to that than ever. Joining us for this episode: Jason Ansel, senior principal engineer with GoDaddy, which is using AI to help you better understand the value of your domain name.]]>
      </content:encoded>
      <itunes:duration>1490</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/392018058]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8957278035.mp3?updated=1740586443" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 48: Sarcasm Detector Uses AI to Understand People at Their Funniest, Meanest</title>
      <link>https://soundcloud.com/theaipodcast/ai-sarcasm</link>
      <description>Sarcasm? On the Internet? You're kidding. But sarcasm is no joke. Long before today's sentiment analysis systems struggled to accurately understand human communication, people struggled to understand one another's sarcasm. Now, thanks to the work of Dr. Pushpak Bhattacharyya and his team computers are beginning to understand one of humanity's most challenging, and amusing, modes of communication. Dr. Bhattacharyya, director of IIT Patna, and a professor at the Computer Science and Engineering Department at IIT Bombay has spent the past few years using GPU-powered deep learning to detect sarcasm.</description>
      <pubDate>Wed, 14 Feb 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/ffa288de-f45b-11ef-8be6-bb667838c4e0/image/c372d0f497d34b0cacad198b099a76c8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Sarcasm? On the Internet? You're kidding. But sar…</itunes:subtitle>
      <itunes:summary>Sarcasm? On the Internet? You're kidding. But sarcasm is no joke. Long before today's sentiment analysis systems struggled to accurately understand human communication, people struggled to understand one another's sarcasm. Now, thanks to the work of Dr. Pushpak Bhattacharyya and his team computers are beginning to understand one of humanity's most challenging, and amusing, modes of communication. Dr. Bhattacharyya, director of IIT Patna, and a professor at the Computer Science and Engineering Department at IIT Bombay has spent the past few years using GPU-powered deep learning to detect sarcasm.</itunes:summary>
      <content:encoded>
        <![CDATA[Sarcasm? On the Internet? You're kidding. But sarcasm is no joke. Long before today's sentiment analysis systems struggled to accurately understand human communication, people struggled to understand one another's sarcasm. Now, thanks to the work of Dr. Pushpak Bhattacharyya and his team computers are beginning to understand one of humanity's most challenging, and amusing, modes of communication. Dr. Bhattacharyya, director of IIT Patna, and a professor at the Computer Science and Engineering Department at IIT Bombay has spent the past few years using GPU-powered deep learning to detect sarcasm.]]>
      </content:encoded>
      <itunes:duration>2376</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/399792828]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2885571062.mp3?updated=1740586444" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 47: How AI Can Improve Access to Palliative Care</title>
      <link>https://soundcloud.com/theaipodcast/ep-47-how-ai-can-improve-access-to-palliative-care</link>
      <description>AI is being used to enhance and improve life in varied and often incredible ways. But what if we could use AI to improve the end of our lives, too? Our guest today is Anand Avati, a graduate student in the Artificial Intelligence Lab at Stanford University's Computer Science Department. Anand is co-author of a research paper entitled "Improving Palliative Care with Deep Learning" which details his team's use of a deep learning system to predict patient mortality with the aim of improving access to palliative care for critically-ill patients.</description>
      <pubDate>Wed, 31 Jan 2018 15:23:45 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/001efe1e-f45c-11ef-8be6-dbfe3b846da6/image/c0480d36292b539f84885ebda823ec32.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is being used to enhance and improve life in v…</itunes:subtitle>
      <itunes:summary>AI is being used to enhance and improve life in varied and often incredible ways. But what if we could use AI to improve the end of our lives, too? Our guest today is Anand Avati, a graduate student in the Artificial Intelligence Lab at Stanford University's Computer Science Department. Anand is co-author of a research paper entitled "Improving Palliative Care with Deep Learning" which details his team's use of a deep learning system to predict patient mortality with the aim of improving access to palliative care for critically-ill patients.</itunes:summary>
      <content:encoded>
        <![CDATA[AI is being used to enhance and improve life in varied and often incredible ways. But what if we could use AI to improve the end of our lives, too? Our guest today is Anand Avati, a graduate student in the Artificial Intelligence Lab at Stanford University's Computer Science Department. Anand is co-author of a research paper entitled "Improving Palliative Care with Deep Learning" which details his team's use of a deep learning system to predict patient mortality with the aim of improving access to palliative care for critically-ill patients.]]>
      </content:encoded>
      <itunes:duration>1648</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/392003178]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5023687864.mp3?updated=1740586445" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 46: When AI Meets Sci-Fi - A Talk with Award-Winning Author Ken MacLeod</title>
      <link>https://soundcloud.com/theaipodcast/science-fiction-ai-ken-macleod-corporation-wars</link>
      <description>AI is getting better, and it's finding its way into more parts of our lives with each passing day. And talking about the future artificial intelligence has become a surefire way to spawn a thousand debates about the future, and nature, of humankind ourselves. Our guest today, Ken McLeod, is an award winning science fiction author whose work dives deep into the relationship between man and machine. His latest book, "The Corporation Wars: Emergence" is the final volume in an acclaimed trilogy whose cast of characters includes sentient robots, computer AIs that oversee Earth from afar, and, of course, emulated human minds running in digital simulations.</description>
      <pubDate>Sun, 07 Jan 2018 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/00a5c7b4-f45c-11ef-8be6-673bf1525f81/image/945ecc737a63c92c8df151d0f02585b5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI is getting better, and it's finding its way in…</itunes:subtitle>
      <itunes:summary>AI is getting better, and it's finding its way into more parts of our lives with each passing day. And talking about the future artificial intelligence has become a surefire way to spawn a thousand debates about the future, and nature, of humankind ourselves. Our guest today, Ken McLeod, is an award winning science fiction author whose work dives deep into the relationship between man and machine. His latest book, "The Corporation Wars: Emergence" is the final volume in an acclaimed trilogy whose cast of characters includes sentient robots, computer AIs that oversee Earth from afar, and, of course, emulated human minds running in digital simulations.</itunes:summary>
      <content:encoded>
        <![CDATA[AI is getting better, and it's finding its way into more parts of our lives with each passing day. And talking about the future artificial intelligence has become a surefire way to spawn a thousand debates about the future, and nature, of humankind ourselves. Our guest today, Ken McLeod, is an award winning science fiction author whose work dives deep into the relationship between man and machine. His latest book, "The Corporation Wars: Emergence" is the final volume in an acclaimed trilogy whose cast of characters includes sentient robots, computer AIs that oversee Earth from afar, and, of course, emulated human minds running in digital simulations.]]>
      </content:encoded>
      <itunes:duration>1885</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/382280039]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8798655660.mp3?updated=1740586446" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 45: How to Use AI, and Tinder, to Hack the Dating Scene</title>
      <link>https://soundcloud.com/theaipodcast/ai-tinder-dating</link>
      <description>Love. The search for love. The search even for someone you just kind of like. It's been the subject of poems, novels, songs, you name it. For as long as humans have been around, they've been looking for love. But what if you could use AI to automate the process? To help you with everything from finding your true match, to swiping through all those not quite true matches. Oscar Alsing, our guest on this episode, will talk about how he's used AI, and Tinder, to do just that.</description>
      <pubDate>Tue, 26 Dec 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/01012a0a-f45c-11ef-8be6-d388fd340183/image/ebe114d0b863cdcd01e51581e56d54d8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Love. The search for love. The search even for so…</itunes:subtitle>
      <itunes:summary>Love. The search for love. The search even for someone you just kind of like. It's been the subject of poems, novels, songs, you name it. For as long as humans have been around, they've been looking for love. But what if you could use AI to automate the process? To help you with everything from finding your true match, to swiping through all those not quite true matches. Oscar Alsing, our guest on this episode, will talk about how he's used AI, and Tinder, to do just that.</itunes:summary>
      <content:encoded>
        <![CDATA[Love. The search for love. The search even for someone you just kind of like. It's been the subject of poems, novels, songs, you name it. For as long as humans have been around, they've been looking for love. But what if you could use AI to automate the process? To help you with everything from finding your true match, to swiping through all those not quite true matches. Oscar Alsing, our guest on this episode, will talk about how he's used AI, and Tinder, to do just that.]]>
      </content:encoded>
      <itunes:duration>1267</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/375473585]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9353414579.mp3?updated=1740586446" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 44: Forget Polls, Here's What Street View, and AI, Can Tell You About How People Will Vote</title>
      <link>https://soundcloud.com/theaipodcast/ep-44-what-street-view-can-tell-you-about-how-people-will-vote</link>
      <description>Election polling is an inexact science. If you've been paying attention to American politics at all over the past year or two, you don't need us to tell you that. But what if instead of asking voters their opinions on the candidates or the issues you took a different approach, one that involves artificial intelligence... and cars. Joining us for this edition of the AI podcast is Timnit Gebru, a post-doctoral researcher at Microsoft Research in New York and a newly minted PhD from the Stanford Artificial Intelligence Laboratory. Timnit is co-author of a paper titled "Using Deep learning and Street View to Estimate the Demographic Makeup of Neighborhoods Across the United States."</description>
      <pubDate>Wed, 20 Dec 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/015cb0d2-f45c-11ef-8be6-77fe57168876/image/dd59bdb67d2a5ec889e6604576176f18.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Election polling is an inexact science. If you've…</itunes:subtitle>
      <itunes:summary>Election polling is an inexact science. If you've been paying attention to American politics at all over the past year or two, you don't need us to tell you that. But what if instead of asking voters their opinions on the candidates or the issues you took a different approach, one that involves artificial intelligence... and cars. Joining us for this edition of the AI podcast is Timnit Gebru, a post-doctoral researcher at Microsoft Research in New York and a newly minted PhD from the Stanford Artificial Intelligence Laboratory. Timnit is co-author of a paper titled "Using Deep learning and Street View to Estimate the Demographic Makeup of Neighborhoods Across the United States."</itunes:summary>
      <content:encoded>
        <![CDATA[Election polling is an inexact science. If you've been paying attention to American politics at all over the past year or two, you don't need us to tell you that. But what if instead of asking voters their opinions on the candidates or the issues you took a different approach, one that involves artificial intelligence... and cars. Joining us for this edition of the AI podcast is Timnit Gebru, a post-doctoral researcher at Microsoft Research in New York and a newly minted PhD from the Stanford Artificial Intelligence Laboratory. Timnit is co-author of a paper titled "Using Deep learning and Street View to Estimate the Demographic Makeup of Neighborhoods Across the United States."]]>
      </content:encoded>
      <itunes:duration>1832</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/372522038]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3821215665.mp3?updated=1740586447" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 43: How Vincent AI Uses a Generative Adversarial Network to Let You  Sketch Like Picasso</title>
      <link>https://soundcloud.com/theaipodcast/vincent-ai</link>
      <description>Think you've got no artistic talent? You do now. Vincent AI is an application that lets you pick up a stylus, sketch out a few lines on a screen, and watch as your scribbles are turned into a work of art inspired by one of seven artistic masters. We speak with Monty Barlow, machine learning director for Cambridge Consultants, the technology development house behind this amazing demo.</description>
      <pubDate>Wed, 06 Dec 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/01ba2a1e-f45c-11ef-8be6-8352afafeae9/image/6cd73b662278978ec5f67f6d13641445.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Think you've got no artistic talent? You do now. …</itunes:subtitle>
      <itunes:summary>Think you've got no artistic talent? You do now. Vincent AI is an application that lets you pick up a stylus, sketch out a few lines on a screen, and watch as your scribbles are turned into a work of art inspired by one of seven artistic masters. We speak with Monty Barlow, machine learning director for Cambridge Consultants, the technology development house behind this amazing demo.</itunes:summary>
      <content:encoded>
        <![CDATA[Think you've got no artistic talent? You do now. Vincent AI is an application that lets you pick up a stylus, sketch out a few lines on a screen, and watch as your scribbles are turned into a work of art inspired by one of seven artistic masters. We speak with Monty Barlow, machine learning director for Cambridge Consultants, the technology development house behind this amazing demo.]]>
      </content:encoded>
      <itunes:duration>1254</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/366364940]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8584718888.mp3?updated=1740586448" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 42: AI Serves Up Feast of Recipes for Thanksgiving (and Beyond)</title>
      <link>https://soundcloud.com/theaipodcast/ai-recipes-thanksgiving</link>
      <description>Ever see a photo of an amazing looking meal, maybe in a food magazine or an Instagram feed, and wish you had the recipe to make it yourself? Thanks to a project born out of MIT's Computer Science and Artificial Intelligence Laboratory we're a step closer to being able to do that. We talk with Nick Hynes, one of the minds and stomachs behind this effort just in time for Thanksgiving and the holiday food season.</description>
      <pubDate>Thu, 23 Nov 2017 06:58:15 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/021e2654-f45c-11ef-8be6-6f1413c67062/image/77238cf378689ee5ec8833b9c2bcc01c.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Ever see a photo of an amazing looking meal, mayb…</itunes:subtitle>
      <itunes:summary>Ever see a photo of an amazing looking meal, maybe in a food magazine or an Instagram feed, and wish you had the recipe to make it yourself? Thanks to a project born out of MIT's Computer Science and Artificial Intelligence Laboratory we're a step closer to being able to do that. We talk with Nick Hynes, one of the minds and stomachs behind this effort just in time for Thanksgiving and the holiday food season.</itunes:summary>
      <content:encoded>
        <![CDATA[Ever see a photo of an amazing looking meal, maybe in a food magazine or an Instagram feed, and wish you had the recipe to make it yourself? Thanks to a project born out of MIT's Computer Science and Artificial Intelligence Laboratory we're a step closer to being able to do that. We talk with Nick Hynes, one of the minds and stomachs behind this effort just in time for Thanksgiving and the holiday food season.]]>
      </content:encoded>
      <itunes:duration>1144</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/359727662]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5692845117.mp3?updated=1740586448" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 41: How Artomatix Uses AI to Generate Infinite Zombie Armies</title>
      <link>https://soundcloud.com/theaipodcast/ep-42-how-artomatix-uses-ai-to-generate-infinite-zombie-armies</link>
      <description>Whether you're wandering through the sprawling virtual worlds of Grand Theft Auto... or just trying out a new couch in Ikea's virtual living room, virtual worlds are everywhere. But there's as problem. There just aren't enough artists to build all these virtual worlds and populate them with foes... or furniture. We spoke with Artomatix co-founder Eric Risser about how deep learning can help artists fill such burgeoning virtual worlds.</description>
      <pubDate>Sun, 05 Nov 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/027d256e-f45c-11ef-8be6-bf3e048e0b36/image/73ae0f5d57e8047d10d1aedbc210e86a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Whether you're wandering through the sprawling vi…</itunes:subtitle>
      <itunes:summary>Whether you're wandering through the sprawling virtual worlds of Grand Theft Auto... or just trying out a new couch in Ikea's virtual living room, virtual worlds are everywhere. But there's as problem. There just aren't enough artists to build all these virtual worlds and populate them with foes... or furniture. We spoke with Artomatix co-founder Eric Risser about how deep learning can help artists fill such burgeoning virtual worlds.</itunes:summary>
      <content:encoded>
        <![CDATA[Whether you're wandering through the sprawling virtual worlds of Grand Theft Auto... or just trying out a new couch in Ikea's virtual living room, virtual worlds are everywhere. But there's as problem. There just aren't enough artists to build all these virtual worlds and populate them with foes... or furniture. We spoke with Artomatix co-founder Eric Risser about how deep learning can help artists fill such burgeoning virtual worlds.]]>
      </content:encoded>
      <itunes:duration>1566</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/353224490]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3410869106.mp3?updated=1740586449" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 40: Using Deep Learning to Scan Your Shopping Basket</title>
      <link>https://soundcloud.com/theaipodcast/malong-technologies</link>
      <description>Tired of waiting in checkout lines? Malong Technologies offers technology that may one day let you grab what you want and go. We spoke to this startup about how it's turning its prowess in some of the world's top image recognition contests into a service businesses can use to put image recognition to work.</description>
      <pubDate>Wed, 25 Oct 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/02da331c-f45c-11ef-8be6-a3de62f5feaa/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Tired of waiting in checkout lines? Malong Techno…</itunes:subtitle>
      <itunes:summary>Tired of waiting in checkout lines? Malong Technologies offers technology that may one day let you grab what you want and go. We spoke to this startup about how it's turning its prowess in some of the world's top image recognition contests into a service businesses can use to put image recognition to work.</itunes:summary>
      <content:encoded>
        <![CDATA[Tired of waiting in checkout lines? Malong Technologies offers technology that may one day let you grab what you want and go. We spoke to this startup about how it's turning its prowess in some of the world's top image recognition contests into a service businesses can use to put image recognition to work.]]>
      </content:encoded>
      <itunes:duration>1573</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/348569200]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8381802148.mp3?updated=1740586449" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 39: How Tattoodo Uses AI to Help You Find Your Next Tattoo</title>
      <link>https://soundcloud.com/theaipodcast/ep-39-using-ai-to-classify-tattoos</link>
      <description>Picture this, you find yourself in a tattoo parlor. But none of the dragons, flaming skulls, or gothic font lifestyle mottos you see on the wall seem like something you want on your body. So what do you do? You turn to AI, of course. We spoke to two members of the development team at Tattoodo.com, who created an app that uses deep learning to help you create the tattoo of your dreams.</description>
      <pubDate>Thu, 28 Sep 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0337cebe-f45c-11ef-8be6-c36722ffdbfb/image/6c6d850959e4e4e6a99d2442d6dfd81a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Picture this, you find yourself in a tattoo parlo…</itunes:subtitle>
      <itunes:summary>Picture this, you find yourself in a tattoo parlor. But none of the dragons, flaming skulls, or gothic font lifestyle mottos you see on the wall seem like something you want on your body. So what do you do? You turn to AI, of course. We spoke to two members of the development team at Tattoodo.com, who created an app that uses deep learning to help you create the tattoo of your dreams.</itunes:summary>
      <content:encoded>
        <![CDATA[Picture this, you find yourself in a tattoo parlor. But none of the dragons, flaming skulls, or gothic font lifestyle mottos you see on the wall seem like something you want on your body. So what do you do? You turn to AI, of course. We spoke to two members of the development team at Tattoodo.com, who created an app that uses deep learning to help you create the tattoo of your dreams.]]>
      </content:encoded>
      <itunes:duration>1257</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/344389413]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2071202592.mp3?updated=1740586450" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 38: Spoiler Alert! AI Predicts Next Chapter in Game of Thrones Saga</title>
      <link>https://soundcloud.com/theaipodcast/spoiler-alert-ai-predicts-next-chapter-in-game-of-thrones-saga</link>
      <description>This might be the first time we've been able to say this, but we might have spoilers ahead on this episode. Joining us we have Zack Thoutt, a data scientist and a developer from Boulder, Colorado. Zack has done something we've all wanted to have done: he's working on finishing the books behind HBO's Game of Thrones - a Song of Ice and Fire - by putting an AI system to work with sometimes comical results.</description>
      <pubDate>Thu, 14 Sep 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0393d556-f45c-11ef-8be6-cbc5d4d4dd02/image/865bccaee9e8bd0bdf86defaecec41d5.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>This might be the first time we've been able to s…</itunes:subtitle>
      <itunes:summary>This might be the first time we've been able to say this, but we might have spoilers ahead on this episode. Joining us we have Zack Thoutt, a data scientist and a developer from Boulder, Colorado. Zack has done something we've all wanted to have done: he's working on finishing the books behind HBO's Game of Thrones - a Song of Ice and Fire - by putting an AI system to work with sometimes comical results.</itunes:summary>
      <content:encoded>
        <![CDATA[This might be the first time we've been able to say this, but we might have spoilers ahead on this episode. Joining us we have Zack Thoutt, a data scientist and a developer from Boulder, Colorado. Zack has done something we've all wanted to have done: he's working on finishing the books behind HBO's Game of Thrones - a Song of Ice and Fire - by putting an AI system to work with sometimes comical results.]]>
      </content:encoded>
      <itunes:duration>1080</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/342299720]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3181716833.mp3?updated=1740586451" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 37: Sergey Levine on How Deep Learning Will Unleash a Robotics Revolution</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-sergey-levine</link>
      <description>The robots that have taken on tasks in the real world - which is to say the world where physics apply - are primarily programmed to do a specific job, such as welding a joint in a car or sweeping up cat hair. So what if robots could learn, and take it a step further - what if they could teach themselves, and pass on their knowledge to other robots? Where could that take machines, and the notion of machine intelligence? And how fast could we get there? Those are the questions our guest Sergey Levine,  an assistant professor at UC Berkeley's department of Electrical Engineering and Computer Sciences, is finding answers to.</description>
      <pubDate>Wed, 30 Aug 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/03f080ee-f45c-11ef-8be6-eb94310a42f3/image/947b6b669bc939018087bc59988bbc26.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The robots that have taken on tasks in the real w…</itunes:subtitle>
      <itunes:summary>The robots that have taken on tasks in the real world - which is to say the world where physics apply - are primarily programmed to do a specific job, such as welding a joint in a car or sweeping up cat hair. So what if robots could learn, and take it a step further - what if they could teach themselves, and pass on their knowledge to other robots? Where could that take machines, and the notion of machine intelligence? And how fast could we get there? Those are the questions our guest Sergey Levine,  an assistant professor at UC Berkeley's department of Electrical Engineering and Computer Sciences, is finding answers to.</itunes:summary>
      <content:encoded>
        <![CDATA[The robots that have taken on tasks in the real world - which is to say the world where physics apply - are primarily programmed to do a specific job, such as welding a joint in a car or sweeping up cat hair. So what if robots could learn, and take it a step further - what if they could teach themselves, and pass on their knowledge to other robots? Where could that take machines, and the notion of machine intelligence? And how fast could we get there? Those are the questions our guest Sergey Levine,  an assistant professor at UC Berkeley's department of Electrical Engineering and Computer Sciences, is finding answers to.]]>
      </content:encoded>
      <itunes:duration>1447</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/340089852]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5365834136.mp3?updated=1740586451" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 36: How AI Is Reshaping the Payments Industry</title>
      <link>https://soundcloud.com/theaipodcast/ep-36-how-ai-is-reshaping-the-payments-industry</link>
      <description>The next time you don’t recognize a transaction listed on your monthly Paypal statement, rest assured: AI will likely identify the culprit and help ensure it won’t happen again. With advances in machine learning and the deployments of neural networks, logistic regression-powered models are expanding their uses throughout PayPal, Vadim Kutsyy, a data scientist at the online payments company, told host Michael Copeland on this week’s edition of the AI Podcast.</description>
      <pubDate>Wed, 23 Aug 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/044de626-f45c-11ef-8be6-d36e8aceca38/image/8dd36681c3f60d436b7d49f357d3c73f.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>The next time you don’t recognize a transaction l…</itunes:subtitle>
      <itunes:summary>The next time you don’t recognize a transaction listed on your monthly Paypal statement, rest assured: AI will likely identify the culprit and help ensure it won’t happen again. With advances in machine learning and the deployments of neural networks, logistic regression-powered models are expanding their uses throughout PayPal, Vadim Kutsyy, a data scientist at the online payments company, told host Michael Copeland on this week’s edition of the AI Podcast.</itunes:summary>
      <content:encoded>
        <![CDATA[The next time you don’t recognize a transaction listed on your monthly Paypal statement, rest assured: AI will likely identify the culprit and help ensure it won’t happen again. With advances in machine learning and the deployments of neural networks, logistic regression-powered models are expanding their uses throughout PayPal, Vadim Kutsyy, a data scientist at the online payments company, told host Michael Copeland on this week’s edition of the AI Podcast.]]>
      </content:encoded>
      <itunes:duration>1363</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/339231366]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC2052944299.mp3?updated=1740586452" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 35: Jetson Interns Assemble! Interns Discuss Amazing AI Robots They're Building</title>
      <link>https://soundcloud.com/theaipodcast/ai-jetson-interns</link>
      <description>We are here at the mothership of NVIDIA with this summer's Jetson interns. And Mokshith Voodarla, Mark Thies, Isaac Wilcove -- all recruited at top robotics competitions -- are building some amazing things with our Jetson embedded computing platform and deep learning, including a delivery robot, a robot that recognizes and disposes of trash, and a remote control car that can find people who are trapped in a building during a fire or earthquake.</description>
      <pubDate>Thu, 17 Aug 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/04aa9fd8-f45c-11ef-8be6-57ac66fa607c/image/c1793dd4ff359607b01fa0cdbd0fae0a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We are here at the mothership of NVIDIA with this…</itunes:subtitle>
      <itunes:summary>We are here at the mothership of NVIDIA with this summer's Jetson interns. And Mokshith Voodarla, Mark Thies, Isaac Wilcove -- all recruited at top robotics competitions -- are building some amazing things with our Jetson embedded computing platform and deep learning, including a delivery robot, a robot that recognizes and disposes of trash, and a remote control car that can find people who are trapped in a building during a fire or earthquake.</itunes:summary>
      <content:encoded>
        <![CDATA[We are here at the mothership of NVIDIA with this summer's Jetson interns. And Mokshith Voodarla, Mark Thies, Isaac Wilcove -- all recruited at top robotics competitions -- are building some amazing things with our Jetson embedded computing platform and deep learning, including a delivery robot, a robot that recognizes and disposes of trash, and a remote control car that can find people who are trapped in a building during a fire or earthquake.]]>
      </content:encoded>
      <itunes:duration>1531</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/338247148]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4204921753.mp3?updated=1740586452" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 34: Pierre Barreau Explains How Aiva Uses Deep Learning to Make Music</title>
      <link>https://soundcloud.com/theaipodcast/ep-34</link>
      <description>AI systems have been trained to take photos and transform them into the style of great artists like Van Gogh, Picasso, or J.M.W. Turner. Take a photo, pick a style, and what emerges looks kind of like the lost work of an artistic master. Now, AI is heading in a different artistic direction: music. The soaring music featured on today's podcast, which made its debut at our GPU Technology Conference, was composed by an AI system developed by our guest, Pierre Barreau, head of Luxembourg-based startup Aiva Technologies.</description>
      <pubDate>Tue, 08 Aug 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0505ad4c-f45c-11ef-8be6-6bed75f84b05/image/77f3eacaa965abdc510a4a09c2478a55.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>AI systems have been trained to take photos and t…</itunes:subtitle>
      <itunes:summary>AI systems have been trained to take photos and transform them into the style of great artists like Van Gogh, Picasso, or J.M.W. Turner. Take a photo, pick a style, and what emerges looks kind of like the lost work of an artistic master. Now, AI is heading in a different artistic direction: music. The soaring music featured on today's podcast, which made its debut at our GPU Technology Conference, was composed by an AI system developed by our guest, Pierre Barreau, head of Luxembourg-based startup Aiva Technologies.</itunes:summary>
      <content:encoded>
        <![CDATA[AI systems have been trained to take photos and transform them into the style of great artists like Van Gogh, Picasso, or J.M.W. Turner. Take a photo, pick a style, and what emerges looks kind of like the lost work of an artistic master. Now, AI is heading in a different artistic direction: music. The soaring music featured on today's podcast, which made its debut at our GPU Technology Conference, was composed by an AI system developed by our guest, Pierre Barreau, head of Luxembourg-based startup Aiva Technologies.]]>
      </content:encoded>
      <itunes:duration>1273</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/337176178]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7861463948.mp3?updated=1740586453" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 33: Why Warehouses Could Be the Sweet Spot for Flying Robots</title>
      <link>https://soundcloud.com/theaipodcast/ep-33-in-the-drone-why-warehouses-could-be-the-sweet-spot-for-flying-robots</link>
      <description>We’ve heard of robots working in warehouses, picking the right windshield or a box of wiring harnesses from shevles. But what about making sure those shelves are stocked with the right stuff, in the right place, at the right time? Marc Gyongosi thinks that flying robots – better known as drones – are right for the job. Marc is the CEO founder of IFM, or Intelligent Flying Machines, which is pretty much what IFM does.</description>
      <pubDate>Wed, 02 Aug 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0562507e-f45c-11ef-8be6-474806529c9f/image/77ed7369a5cb9b226301867ff6512081.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We’ve heard of robots working in warehouses, pick…</itunes:subtitle>
      <itunes:summary>We’ve heard of robots working in warehouses, picking the right windshield or a box of wiring harnesses from shevles. But what about making sure those shelves are stocked with the right stuff, in the right place, at the right time? Marc Gyongosi thinks that flying robots – better known as drones – are right for the job. Marc is the CEO founder of IFM, or Intelligent Flying Machines, which is pretty much what IFM does.</itunes:summary>
      <content:encoded>
        <![CDATA[We’ve heard of robots working in warehouses, picking the right windshield or a box of wiring harnesses from shevles. But what about making sure those shelves are stocked with the right stuff, in the right place, at the right time? Marc Gyongosi thinks that flying robots – better known as drones – are right for the job. Marc is the CEO founder of IFM, or Intelligent Flying Machines, which is pretty much what IFM does.]]>
      </content:encoded>
      <itunes:duration>1146</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/336050592]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8245887836.mp3?updated=1740586454" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 32: Deep Learning Pioneer Andrew Ng on AI as the New Electricity</title>
      <link>https://soundcloud.com/theaipodcast/andrew-ng-ai-new-electricity</link>
      <description>Purple shirts, haircuts, and cats. How are these three all related? According to deep learning pioneer Andrew Ng, they all played a part in AI’s growing presence in our lives. Ng, formerly of Google and Baidu, and the founder of his new company, Deeplearning.ai, joined this week’s episode of the AI Podcast to share his thoughts on AI being the new electricity.</description>
      <pubDate>Wed, 26 Jul 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/05bb197a-f45c-11ef-8be6-d3bb9431abe1/image/318b09b0a8b6f26e6088f45c9abbcb21.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Purple shirts, haircuts, and cats. How are these …</itunes:subtitle>
      <itunes:summary>Purple shirts, haircuts, and cats. How are these three all related? According to deep learning pioneer Andrew Ng, they all played a part in AI’s growing presence in our lives. Ng, formerly of Google and Baidu, and the founder of his new company, Deeplearning.ai, joined this week’s episode of the AI Podcast to share his thoughts on AI being the new electricity.</itunes:summary>
      <content:encoded>
        <![CDATA[Purple shirts, haircuts, and cats. How are these three all related? According to deep learning pioneer Andrew Ng, they all played a part in AI’s growing presence in our lives. Ng, formerly of Google and Baidu, and the founder of his new company, Deeplearning.ai, joined this week’s episode of the AI Podcast to share his thoughts on AI being the new electricity.]]>
      </content:encoded>
      <itunes:duration>1883</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/334829522]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6899461779.mp3?updated=1740586454" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 31: Could an AI Win the Nobel Prize?</title>
      <link>https://soundcloud.com/theaipodcast/ai-nobel-gtc</link>
      <description>Our guest on this segment, Paul Wigley, of the Australian National University, was part of a team of scientists who applied AI to an experiment to create a Bose-Einstein condensate. And in doing so they had a question: if we can use AI as a tool in this experiment, can we use AI as its own novel, scientist, to explore different parts of physics and different parts of science?</description>
      <pubDate>Tue, 18 Jul 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/06181d5a-f45c-11ef-8be6-cbeae4729c58/image/b22c571cae199c01de93c3c74739c185.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Our guest on this segment, Paul Wigley, of the Au…</itunes:subtitle>
      <itunes:summary>Our guest on this segment, Paul Wigley, of the Australian National University, was part of a team of scientists who applied AI to an experiment to create a Bose-Einstein condensate. And in doing so they had a question: if we can use AI as a tool in this experiment, can we use AI as its own novel, scientist, to explore different parts of physics and different parts of science?</itunes:summary>
      <content:encoded>
        <![CDATA[Our guest on this segment, Paul Wigley, of the Australian National University, was part of a team of scientists who applied AI to an experiment to create a Bose-Einstein condensate. And in doing so they had a question: if we can use AI as a tool in this experiment, can we use AI as its own novel, scientist, to explore different parts of physics and different parts of science?]]>
      </content:encoded>
      <itunes:duration>1164</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/333918963]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5763073191.mp3?updated=1740586455" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 30: Not Hotdog, When Ridiculous AI Fiction Becomes Hilarious Reality</title>
      <link>https://soundcloud.com/theaipodcast/ep-30-nothotdog-the-inside-story-of-how-ai-came-to-hbos-silicon-valley</link>
      <description>Tim Anglade, a consultant with HBO's "Silicon Valley," has engineered an app that solves an important problem for all of us: is that a hot dog... or not? The app was dreamed up by the writers and producers of HBO's hit comedy and brought to the real world by Anglade thanks to deep learning.</description>
      <pubDate>Thu, 13 Jul 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/06730ed6-f45c-11ef-8be6-37e34dd09122/image/8d9aa913dd65fe57c5a78386745e84f0.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Tim Anglade, a consultant with HBO's "Silicon Val…</itunes:subtitle>
      <itunes:summary>Tim Anglade, a consultant with HBO's "Silicon Valley," has engineered an app that solves an important problem for all of us: is that a hot dog... or not? The app was dreamed up by the writers and producers of HBO's hit comedy and brought to the real world by Anglade thanks to deep learning.</itunes:summary>
      <content:encoded>
        <![CDATA[Tim Anglade, a consultant with HBO's "Silicon Valley," has engineered an app that solves an important problem for all of us: is that a hot dog... or not? The app was dreamed up by the writers and producers of HBO's hit comedy and brought to the real world by Anglade thanks to deep learning.]]>
      </content:encoded>
      <itunes:duration>1911</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/332832097]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3033053667.mp3?updated=1740586455" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 29: TuSimple's Xiaodi Hou Talks About Bringing Driverless Trucks to Highways</title>
      <link>https://soundcloud.com/theaipodcast/ai-driverless-trucks-tusimple-highway</link>
      <description>We all know about driverless cars, driverless cars get all the love and all the attention, because we don't want to drive. But we're going to talk in this segment about autonomous trucks, how and why we need autonomous trucks in many ways just as much as we need autonomous cars. To do that, we're talking to Xiaodi Hou the CTO and co-founder of TuSimple, a company that is bringing driverless trucks to the road.</description>
      <pubDate>Thu, 06 Jul 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/06d11a3a-f45c-11ef-8be6-af46ff33d8e5/image/ca4734556e7392367393f7c0cf75d9a8.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We all know about driverless cars, driverless car…</itunes:subtitle>
      <itunes:summary>We all know about driverless cars, driverless cars get all the love and all the attention, because we don't want to drive. But we're going to talk in this segment about autonomous trucks, how and why we need autonomous trucks in many ways just as much as we need autonomous cars. To do that, we're talking to Xiaodi Hou the CTO and co-founder of TuSimple, a company that is bringing driverless trucks to the road.</itunes:summary>
      <content:encoded>
        <![CDATA[We all know about driverless cars, driverless cars get all the love and all the attention, because we don't want to drive. But we're going to talk in this segment about autonomous trucks, how and why we need autonomous trucks in many ways just as much as we need autonomous cars. To do that, we're talking to Xiaodi Hou the CTO and co-founder of TuSimple, a company that is bringing driverless trucks to the road.]]>
      </content:encoded>
      <itunes:duration>887</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/332021980]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5909114876.mp3?updated=1740586456" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 28: How Syed Ahmed Taught AI to Translate Sign Language</title>
      <link>https://soundcloud.com/theaipodcast/ep-28-how-a-researcher-taught-ai-to-read-sign-language</link>
      <description>We all know how far AI, and in particular deep learning, have pushed speech recognition, whether that is with Apple Siri, Amazon Alexa, or Google Assistant, Our guest on this segment, Syed Ahmed, is directing the power of AI towards another form of communication, American Sign Language. And what 
Syed has done is set up a deep learning model that translates American Sign Language into the English Language.</description>
      <pubDate>Wed, 28 Jun 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/072f8dea-f45c-11ef-8be6-676dd93b9573/image/19f59790af0eadaaece1223b6a5debbb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We all know how far AI, and in particular deep le…</itunes:subtitle>
      <itunes:summary>We all know how far AI, and in particular deep learning, have pushed speech recognition, whether that is with Apple Siri, Amazon Alexa, or Google Assistant, Our guest on this segment, Syed Ahmed, is directing the power of AI towards another form of communication, American Sign Language. And what 
Syed has done is set up a deep learning model that translates American Sign Language into the English Language.</itunes:summary>
      <content:encoded>
        <![CDATA[We all know how far AI, and in particular deep learning, have pushed speech recognition, whether that is with Apple Siri, Amazon Alexa, or Google Assistant, Our guest on this segment, Syed Ahmed, is directing the power of AI towards another form of communication, American Sign Language. And what 
Syed has done is set up a deep learning model that translates American Sign Language into the English Language.]]>
      </content:encoded>
      <itunes:duration>829</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/330441342]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6223330869.mp3?updated=1740586457" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 27: Danny Lange, of Unity Technologies, on How AI Can Enhance Gaming, and Gaming Can Enhance AI</title>
      <link>https://soundcloud.com/theaipodcast/ai-games-gtc</link>
      <description>Over the last few years data intensive machine learning solutions have supplanted rule-based software systems at many technology-based companies. Think about Amazon, Netflix, and Uber. But the gaming world hasn't exactly followed suit, at least not as quickly. Most games are still a delicate mix of hard-wired behavior in the form of traditional code, and somewhat more responsive behavior in the form of large collections of rules. Our guest, Danny Lange, VP of AI and Machine Learning at Unity Technologies, is taking a different tack, using deep learning to help with game creation, that subtle combination of art, story, and software.</description>
      <pubDate>Wed, 21 Jun 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/078ca7f0-f45c-11ef-8be6-eb1bfe3018b7/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Over the last few years data intensive machine le…</itunes:subtitle>
      <itunes:summary>Over the last few years data intensive machine learning solutions have supplanted rule-based software systems at many technology-based companies. Think about Amazon, Netflix, and Uber. But the gaming world hasn't exactly followed suit, at least not as quickly. Most games are still a delicate mix of hard-wired behavior in the form of traditional code, and somewhat more responsive behavior in the form of large collections of rules. Our guest, Danny Lange, VP of AI and Machine Learning at Unity Technologies, is taking a different tack, using deep learning to help with game creation, that subtle combination of art, story, and software.</itunes:summary>
      <content:encoded>
        <![CDATA[Over the last few years data intensive machine learning solutions have supplanted rule-based software systems at many technology-based companies. Think about Amazon, Netflix, and Uber. But the gaming world hasn't exactly followed suit, at least not as quickly. Most games are still a delicate mix of hard-wired behavior in the form of traditional code, and somewhat more responsive behavior in the form of large collections of rules. Our guest, Danny Lange, VP of AI and Machine Learning at Unity Technologies, is taking a different tack, using deep learning to help with game creation, that subtle combination of art, story, and software.]]>
      </content:encoded>
      <itunes:duration>843</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/329452913]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1775515360.mp3?updated=1740586458" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 26: Deep Learning Promises to Bring Algorithmic Investing Smarts to the Rest of Us</title>
      <link>https://soundcloud.com/theaipodcast/ai-finance</link>
      <description>In recent years hedge funds have taken the lead in algorithmic investing - or robo-trading as it’s sometimes called. But there’s no reason the hedge fund world should have all the good stuff. In this episode of the AI Podcast, we speak with Gaurav Chakravorty, co-founder of qplum, a startup that’s working to bring that same machine learning investing approach to the rest of us.</description>
      <pubDate>Wed, 14 Jun 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/07e89eca-f45c-11ef-8be6-93ea7a80b631/image/634d6f633759cb44dfb57274e0639921.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>In recent years hedge funds have taken the lead i…</itunes:subtitle>
      <itunes:summary>In recent years hedge funds have taken the lead in algorithmic investing - or robo-trading as it’s sometimes called. But there’s no reason the hedge fund world should have all the good stuff. In this episode of the AI Podcast, we speak with Gaurav Chakravorty, co-founder of qplum, a startup that’s working to bring that same machine learning investing approach to the rest of us.</itunes:summary>
      <content:encoded>
        <![CDATA[In recent years hedge funds have taken the lead in algorithmic investing - or robo-trading as it’s sometimes called. But there’s no reason the hedge fund world should have all the good stuff. In this episode of the AI Podcast, we speak with Gaurav Chakravorty, co-founder of qplum, a startup that’s working to bring that same machine learning investing approach to the rest of us.]]>
      </content:encoded>
      <itunes:duration>1320</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/328080023]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3844319292.mp3?updated=1740586458" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 25: Google's Ian Goodfellow on How an Argument in a Bar Led to Generative Adversarial Networks</title>
      <link>https://soundcloud.com/theaipodcast/what-are-generative-adversarial-networks-ian-goodfellow-explains</link>
      <description>How an argument in a bar led Google's Ian Goodfellow to create Generative Adversarial Networks - deep learning systems that argue with each other - an AI breakthrough that promises to help researchers build systems that can learn with less human intervention.</description>
      <pubDate>Wed, 07 Jun 2017 18:57:39 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0843db46-f45c-11ef-8be6-23f3433b268a/image/594692a8fd95410bb75a133263d7f080.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>How an argument in a bar led Google's Ian Goodfel…</itunes:subtitle>
      <itunes:summary>How an argument in a bar led Google's Ian Goodfellow to create Generative Adversarial Networks - deep learning systems that argue with each other - an AI breakthrough that promises to help researchers build systems that can learn with less human intervention.</itunes:summary>
      <content:encoded>
        <![CDATA[How an argument in a bar led Google's Ian Goodfellow to create Generative Adversarial Networks - deep learning systems that argue with each other - an AI breakthrough that promises to help researchers build systems that can learn with less human intervention.]]>
      </content:encoded>
      <itunes:duration>1420</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/326749576]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7440792784.mp3?updated=1740586459" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 24: How Yahoo Uses AI to Create Instant eSports Highlight Reels</title>
      <link>https://soundcloud.com/theaipodcast/ep-23-how-yahoo-uses-ai-to-create-instant-esports-highlight-reels</link>
      <description>Whatever sport we follow, we all love a good highlight reel - and we want those highlights now. And whether they're following StarCraft II, League of Legends, or Heroes of the Storm, eSports fans are no different. To highlight the kills, and thrills, of a great eSports competition, Yale Song, Senior Research Scientist at Yahoo! Research, turned to AI.</description>
      <pubDate>Wed, 31 May 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/08cbf06c-f45c-11ef-8be6-17af1b48c272/image/69f1cb81e21bbefa977f436fa2d7d211.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Whatever sport we follow, we all love a good high…</itunes:subtitle>
      <itunes:summary>Whatever sport we follow, we all love a good highlight reel - and we want those highlights now. And whether they're following StarCraft II, League of Legends, or Heroes of the Storm, eSports fans are no different. To highlight the kills, and thrills, of a great eSports competition, Yale Song, Senior Research Scientist at Yahoo! Research, turned to AI.</itunes:summary>
      <content:encoded>
        <![CDATA[Whatever sport we follow, we all love a good highlight reel - and we want those highlights now. And whether they're following StarCraft II, League of Legends, or Heroes of the Storm, eSports fans are no different. To highlight the kills, and thrills, of a great eSports competition, Yale Song, Senior Research Scientist at Yahoo! Research, turned to AI.]]>
      </content:encoded>
      <itunes:duration>1334</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/325397036]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9569762255.mp3?updated=1740586459" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 23: How Airbus A³ Plans to Bring Autonomous Air Taxis to Urban Skies</title>
      <link>https://soundcloud.com/theaipodcast/ep-23-airbus-incubator-plans-to-bring-autonomous-air-taxis-to-sf-bay-area</link>
      <description>With self-driving cars generating so much buzz, it’s hard to believe that a self-piloting air taxi is, err,  flying under the radar.  But not for long. We spoke with Arne Stoschek, head of autonomous systems at Airbus A3 (pronounced “A-cubed”), the Silicon Valley-based advanced products and partnerships outpost of Airbus Group about a plan to bring a self-piloted air taxi to the Bay Area’s skies.</description>
      <pubDate>Mon, 22 May 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/09295c84-f45c-11ef-8be6-af001a808b5d/image/c0afa77d6964cbeb740c72dd09e532ef.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>With self-driving cars generating so much buzz, i…</itunes:subtitle>
      <itunes:summary>With self-driving cars generating so much buzz, it’s hard to believe that a self-piloting air taxi is, err,  flying under the radar.  But not for long. We spoke with Arne Stoschek, head of autonomous systems at Airbus A3 (pronounced “A-cubed”), the Silicon Valley-based advanced products and partnerships outpost of Airbus Group about a plan to bring a self-piloted air taxi to the Bay Area’s skies.</itunes:summary>
      <content:encoded>
        <![CDATA[With self-driving cars generating so much buzz, it’s hard to believe that a self-piloting air taxi is, err,  flying under the radar.  But not for long. We spoke with Arne Stoschek, head of autonomous systems at Airbus A3 (pronounced “A-cubed”), the Silicon Valley-based advanced products and partnerships outpost of Airbus Group about a plan to bring a self-piloted air taxi to the Bay Area’s skies.]]>
      </content:encoded>
      <itunes:duration>1107</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/324346780]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8981709931.mp3?updated=1740586460" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 22: Kitt.ai Co-Founder on How AI Lets Us Talk with Our Machines</title>
      <link>https://soundcloud.com/theaipodcast/gtc-ai-chat-bots</link>
      <description>We spoke with Xuchen Yao, co-founder of Kitt.ai, a startup using AI to build better chat experiences, about how voice and chat are turning into rich, interactive interfaces for a new generation of AI-powered services.</description>
      <pubDate>Tue, 16 May 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0987ba2c-f45c-11ef-8be6-7fabd4e75c5a/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Xuchen Yao, co-founder of Kitt.ai, …</itunes:subtitle>
      <itunes:summary>We spoke with Xuchen Yao, co-founder of Kitt.ai, a startup using AI to build better chat experiences, about how voice and chat are turning into rich, interactive interfaces for a new generation of AI-powered services.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Xuchen Yao, co-founder of Kitt.ai, a startup using AI to build better chat experiences, about how voice and chat are turning into rich, interactive interfaces for a new generation of AI-powered services.]]>
      </content:encoded>
      <itunes:duration>1413</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/323102639]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5173659951.mp3?updated=1740586461" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 21: Live at GTC - How AI and VR Intersect</title>
      <link>https://soundcloud.com/theaipodcast/ep-21-live-from-gtc-how-ai-and-vr-intersect</link>
      <description>Are AI and VR the peanut butter and chocolate of computing? Are they a match made in heaven? We spoke with Michael Ludden, who heads up IBM Watson's AI and VR labs, about how these two technologies intersect at this week's GPU Technology Conference.</description>
      <pubDate>Fri, 12 May 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/09e32d94-f45c-11ef-8be6-0fa4d0e3d19d/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Are AI and VR the peanut butter and chocolate of …</itunes:subtitle>
      <itunes:summary>Are AI and VR the peanut butter and chocolate of computing? Are they a match made in heaven? We spoke with Michael Ludden, who heads up IBM Watson's AI and VR labs, about how these two technologies intersect at this week's GPU Technology Conference.</itunes:summary>
      <content:encoded>
        <![CDATA[Are AI and VR the peanut butter and chocolate of computing? Are they a match made in heaven? We spoke with Michael Ludden, who heads up IBM Watson's AI and VR labs, about how these two technologies intersect at this week's GPU Technology Conference.]]>
      </content:encoded>
      <itunes:duration>480</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/322365163]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3684845165.mp3?updated=1740586461" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 20: Live at GTC - How AI Will Bring More Joy to Your Cooking</title>
      <link>https://soundcloud.com/theaipodcast/ep-20-live-at-gtc-innit-brings-deep-learning-to-your-kitchen</link>
      <description>We spoke with Innit Chief Technology Officer Hristo Bojinov about all the surprising ways deep learning can help us better manage the very personal relationship we all have with food — from meal planning to kitchen inventory to cooking the perfect roast chicken.</description>
      <pubDate>Thu, 11 May 2017 19:58:59 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0a40b70c-f45c-11ef-8be6-47e6025f18fe/image/6645d8ebcb9c260475ed114c2561ae91.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Innit Chief Technology Officer Hris…</itunes:subtitle>
      <itunes:summary>We spoke with Innit Chief Technology Officer Hristo Bojinov about all the surprising ways deep learning can help us better manage the very personal relationship we all have with food — from meal planning to kitchen inventory to cooking the perfect roast chicken.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Innit Chief Technology Officer Hristo Bojinov about all the surprising ways deep learning can help us better manage the very personal relationship we all have with food — from meal planning to kitchen inventory to cooking the perfect roast chicken.]]>
      </content:encoded>
      <itunes:duration>1272</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/322157062]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9393871467.mp3?updated=1740586462" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 19: AI Food Delivery Bots Rolling Through San Francisco</title>
      <link>https://soundcloud.com/theaipodcast/ep-19-ai-food-delivery-bots-rolling-through-san-francisco</link>
      <description>We spoke with the team at Marble, which has turned AI loose on the streets of San Francisco delivering food in San Francisco's vibrant Mission District.</description>
      <pubDate>Wed, 03 May 2017 23:59:06 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0a9e1a64-f45c-11ef-8be6-031375ac1c4d/image/3430f6f668fadc92739a6a77dadb408d.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with the team at Marble, which has turne…</itunes:subtitle>
      <itunes:summary>We spoke with the team at Marble, which has turned AI loose on the streets of San Francisco delivering food in San Francisco's vibrant Mission District.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with the team at Marble, which has turned AI loose on the streets of San Francisco delivering food in San Francisco's vibrant Mission District.]]>
      </content:encoded>
      <itunes:duration>1367</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/320821045]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8701228592.mp3?updated=1740586462" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 18: How AI Learns Racism, Sexism</title>
      <link>https://soundcloud.com/theaipodcast/ep-18-racism-sexism</link>
      <description>We spoke with Princeton researcher Aylin Caliskan, co-author of a headline-grabbing paper published in Science magazine earlier this month. Her paper details how learning machines can sometimes learn all too well, picking up our biases as well as our brilliance.</description>
      <pubDate>Sun, 23 Apr 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0af9afe6-f45c-11ef-8be6-43d872436f33/image/298cf15c3c068db542a7b009ddbb8788.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Princeton researcher Aylin Caliskan…</itunes:subtitle>
      <itunes:summary>We spoke with Princeton researcher Aylin Caliskan, co-author of a headline-grabbing paper published in Science magazine earlier this month. Her paper details how learning machines can sometimes learn all too well, picking up our biases as well as our brilliance.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Princeton researcher Aylin Caliskan, co-author of a headline-grabbing paper published in Science magazine earlier this month. Her paper details how learning machines can sometimes learn all too well, picking up our biases as well as our brilliance.]]>
      </content:encoded>
      <itunes:duration>1248</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/319471380]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1431350750.mp3?updated=1740586463" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 17: Training an AI to Play Mario Kart 64</title>
      <link>https://soundcloud.com/theaipodcast/ai-mario-cart</link>
      <description>Previous episodes discussed deep learning systems trained to master games like Chess, Go, and even Texas Hold 'Em. But training a deep neural net on a racing game like Mario Kart 64? What can you learn from that? A lot, it turns out, explains Kevin Hughes.</description>
      <pubDate>Fri, 07 Apr 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0b55f56c-f45c-11ef-8be6-433309cf2fb6/image/b17ea59df8c0c118cce1fc4ab8cb9b3a.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Previous episodes discussed deep learning systems…</itunes:subtitle>
      <itunes:summary>Previous episodes discussed deep learning systems trained to master games like Chess, Go, and even Texas Hold 'Em. But training a deep neural net on a racing game like Mario Kart 64? What can you learn from that? A lot, it turns out, explains Kevin Hughes.</itunes:summary>
      <content:encoded>
        <![CDATA[Previous episodes discussed deep learning systems trained to master games like Chess, Go, and even Texas Hold 'Em. But training a deep neural net on a racing game like Mario Kart 64? What can you learn from that? A lot, it turns out, explains Kevin Hughes.]]>
      </content:encoded>
      <itunes:duration>1194</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/317577433]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC4924531906.mp3?updated=1740586464" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 16: Growth Opportunity - How AI Puts Lettuce in Your Salad Bowl</title>
      <link>https://soundcloud.com/theaipodcast/ep-16-growth-opportunity-how-ai-puts-lettuce-in-your-salad-bowl</link>
      <description>If you're looking for the impact of deep learning, look to the end of your fork. We spoke with Blue River Technology co-founder and CTO Lee Redden about how the startup put deep learning to work tending 10% of the lettuce produced in the United States, and how deep learning promises to unleash a new agricultural revolution.</description>
      <pubDate>Tue, 04 Apr 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0bb3a28e-f45c-11ef-8be6-639f354c419c/image/e3cc9d0a40116169b1aea98a13388770.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>If you're looking for the impact of deep learning…</itunes:subtitle>
      <itunes:summary>If you're looking for the impact of deep learning, look to the end of your fork. We spoke with Blue River Technology co-founder and CTO Lee Redden about how the startup put deep learning to work tending 10% of the lettuce produced in the United States, and how deep learning promises to unleash a new agricultural revolution.</itunes:summary>
      <content:encoded>
        <![CDATA[If you're looking for the impact of deep learning, look to the end of your fork. We spoke with Blue River Technology co-founder and CTO Lee Redden about how the startup put deep learning to work tending 10% of the lettuce produced in the United States, and how deep learning promises to unleash a new agricultural revolution.]]>
      </content:encoded>
      <itunes:duration>1433</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/316349625]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5571133262.mp3?updated=1740586464" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 15: How AI Beat the Pros at Texas Hold'em, and Why It Matters</title>
      <link>https://soundcloud.com/theaipodcast/ai-beats-pros-at-texas-hold-em</link>
      <description>We spoke with Michael Bowling,  a professor at the University of Alberta whose team of researchers created a GPU-trained AI that has defeated professional poker players at heads-up no-limit Texas hold’em. The work promises to yield applications in the real world, where — unlike games such as Go and Chess — we often have to make decisions based on incomplete information.</description>
      <pubDate>Sat, 25 Mar 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0c117454-f45c-11ef-8be6-3715055a09de/image/632c7ad5503116520634a216cb0e9536.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We spoke with Michael Bowling,  a professor at th…</itunes:subtitle>
      <itunes:summary>We spoke with Michael Bowling,  a professor at the University of Alberta whose team of researchers created a GPU-trained AI that has defeated professional poker players at heads-up no-limit Texas hold’em. The work promises to yield applications in the real world, where — unlike games such as Go and Chess — we often have to make decisions based on incomplete information.</itunes:summary>
      <content:encoded>
        <![CDATA[We spoke with Michael Bowling,  a professor at the University of Alberta whose team of researchers created a GPU-trained AI that has defeated professional poker players at heads-up no-limit Texas hold’em. The work promises to yield applications in the real world, where — unlike games such as Go and Chess — we often have to make decisions based on incomplete information.]]>
      </content:encoded>
      <itunes:duration>2350</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/315163450]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5799153080.mp3?updated=1740586465" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 14: AI Takes Wing – Deep Learning Hears Once Extinct Bird</title>
      <link>https://soundcloud.com/theaipodcast/ep-14-how-deep-learning-tracks-endangered-critters</link>
      <description>We speak with Matthew McKown, CEO of Conservation Metrics, about how deep learning techniques helped rediscover a bird that was once thought extinct, and how GPU-powered AI now helps biologists crunch vast quantities of data to spot trends that would have been impossible to detect before.</description>
      <pubDate>Mon, 20 Mar 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0c712d72-f45c-11ef-8be6-c34c925fc8b5/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We speak with Matthew McKown, CEO of Conservation…</itunes:subtitle>
      <itunes:summary>We speak with Matthew McKown, CEO of Conservation Metrics, about how deep learning techniques helped rediscover a bird that was once thought extinct, and how GPU-powered AI now helps biologists crunch vast quantities of data to spot trends that would have been impossible to detect before.</itunes:summary>
      <content:encoded>
        <![CDATA[We speak with Matthew McKown, CEO of Conservation Metrics, about how deep learning techniques helped rediscover a bird that was once thought extinct, and how GPU-powered AI now helps biologists crunch vast quantities of data to spot trends that would have been impossible to detect before.]]>
      </content:encoded>
      <itunes:duration>1425</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/314044823]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC8861158459.mp3?updated=1740586465" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 13: How AI Can Improve Brain Tumor Treatment</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-radio-genomics</link>
      <description>We talk with Dr. Bradley Erickson, a Mayo Clinic neuroradiologist, who uses AI to predict tumor genomics using MRIs. His method could give doctors easier access to invaluable genetic information. Information that could predict how quickly a tumor will progress, and if it will respond to specific drugs and other treatments.</description>
      <pubDate>Thu, 16 Mar 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0ccee3a4-f45c-11ef-8be6-47cd00b469f2/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>We talk with Dr. Bradley Erickson, a Mayo Clinic …</itunes:subtitle>
      <itunes:summary>We talk with Dr. Bradley Erickson, a Mayo Clinic neuroradiologist, who uses AI to predict tumor genomics using MRIs. His method could give doctors easier access to invaluable genetic information. Information that could predict how quickly a tumor will progress, and if it will respond to specific drugs and other treatments.</itunes:summary>
      <content:encoded>
        <![CDATA[We talk with Dr. Bradley Erickson, a Mayo Clinic neuroradiologist, who uses AI to predict tumor genomics using MRIs. His method could give doctors easier access to invaluable genetic information. Information that could predict how quickly a tumor will progress, and if it will respond to specific drugs and other treatments.]]>
      </content:encoded>
      <itunes:duration>1604</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/312618360]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5038026745.mp3?updated=1740586466" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 12: How AI Can Improve the Diagnosis and Treatment of Diseases</title>
      <link>https://soundcloud.com/theaipodcast/ep-12-ai-podcast-how-ai-can-improve-the-diagnosis-and-treatment-of-diseases</link>
      <description>Medicine — particularly radiology and pathology — have become more data-driven. The Massachusetts General Hospital Center for Clinical Data Science — led by Mark Michalski — promises to accelerate that, using AI technologies to spot patterns that can improve the detection, diagnosis and treatment of diseases.</description>
      <pubDate>Tue, 07 Mar 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0d2d0182-f45c-11ef-8be6-8f3d8e7646e4/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Medicine — particularly radiology and pathology —…</itunes:subtitle>
      <itunes:summary>Medicine — particularly radiology and pathology — have become more data-driven. The Massachusetts General Hospital Center for Clinical Data Science — led by Mark Michalski — promises to accelerate that, using AI technologies to spot patterns that can improve the detection, diagnosis and treatment of diseases.</itunes:summary>
      <content:encoded>
        <![CDATA[Medicine — particularly radiology and pathology — have become more data-driven. The Massachusetts General Hospital Center for Clinical Data Science — led by Mark Michalski — promises to accelerate that, using AI technologies to spot patterns that can improve the detection, diagnosis and treatment of diseases.]]>
      </content:encoded>
      <itunes:duration>1431</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/311447378]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6342175522.mp3?updated=1740586467" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 11: How a Computer Scientist Uses AI to Read Lost Literature</title>
      <link>https://soundcloud.com/theaipodcast/ep-11-how-a-computer-scientist-uses-ai-to-read-lost-literature</link>
      <description>University of Kentucky Computer Science Professor Brent Seales caused a worldwide sensation when he and his team were able to use non-invasive scans to unlock writings on the ancient En-Gedi scroll to reveal the earliest copy of a Pentateuchal book — Leviticus — ever found in a Holy Ark. Now he’s turning his expertise to more ancient texts, this time from the lost Roman city of Herculaneum.</description>
      <pubDate>Tue, 28 Feb 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0d8bdf86-f45c-11ef-8be6-1b9e1398c52c/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>University of Kentucky Computer Science Professor…</itunes:subtitle>
      <itunes:summary>University of Kentucky Computer Science Professor Brent Seales caused a worldwide sensation when he and his team were able to use non-invasive scans to unlock writings on the ancient En-Gedi scroll to reveal the earliest copy of a Pentateuchal book — Leviticus — ever found in a Holy Ark. Now he’s turning his expertise to more ancient texts, this time from the lost Roman city of Herculaneum.</itunes:summary>
      <content:encoded>
        <![CDATA[University of Kentucky Computer Science Professor Brent Seales caused a worldwide sensation when he and his team were able to use non-invasive scans to unlock writings on the ancient En-Gedi scroll to reveal the earliest copy of a Pentateuchal book — Leviticus — ever found in a Holy Ark. Now he’s turning his expertise to more ancient texts, this time from the lost Roman city of Herculaneum.]]>
      </content:encoded>
      <itunes:duration>1044</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/310246131]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6771816583.mp3?updated=1740586467" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 10: Turning AI Loose on the Track with Roborace</title>
      <link>https://soundcloud.com/theaipodcast/ep-10-turning-ai-loose-on-the-track-with-roborace</link>
      <description>If you want to bring autonomous vehicles to the mainstream, fast, first you’ve got to go fast. We spoke with Jonathan Cooke, chief marketing officer of Roborace, the first ever driverless electric racing championship, who wants to turn autonomous racing into a spectator sport that will spark the creation of more powerful, capable automotive AI.</description>
      <pubDate>Wed, 22 Feb 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0debc66c-f45c-11ef-8be6-e79b4d8e1477/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>If you want to bring autonomous vehicles to the m…</itunes:subtitle>
      <itunes:summary>If you want to bring autonomous vehicles to the mainstream, fast, first you’ve got to go fast. We spoke with Jonathan Cooke, chief marketing officer of Roborace, the first ever driverless electric racing championship, who wants to turn autonomous racing into a spectator sport that will spark the creation of more powerful, capable automotive AI.</itunes:summary>
      <content:encoded>
        <![CDATA[If you want to bring autonomous vehicles to the mainstream, fast, first you’ve got to go fast. We spoke with Jonathan Cooke, chief marketing officer of Roborace, the first ever driverless electric racing championship, who wants to turn autonomous racing into a spectator sport that will spark the creation of more powerful, capable automotive AI.]]>
      </content:encoded>
      <itunes:duration>969</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/309094666]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC1809454347.mp3?updated=1740586468" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 9: Winning the Cybersecurity Cat and Mouse Game with AI</title>
      <link>https://soundcloud.com/theaipodcast/ep-9-winning-the-cybersecurity-cat-and-mouse-game-with-ai</link>
      <description>Cybersecurity is a cat-and-mouse game where the mouse always has long had the upper hand because it’s so easy for new malware to go undetected. Dr. Eli David, an expert in computational intelligence and CTO of Deep Instinct, wants to use AI to change that, bringing the GPU-powered deep learning techniques underpinning modern speech and image recognition to the vexing world of cybersecurity.</description>
      <pubDate>Wed, 08 Feb 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0e4cf914-f45c-11ef-8be6-b71ed2fbf266/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Cybersecurity is a cat-and-mouse game where the m…</itunes:subtitle>
      <itunes:summary>Cybersecurity is a cat-and-mouse game where the mouse always has long had the upper hand because it’s so easy for new malware to go undetected. Dr. Eli David, an expert in computational intelligence and CTO of Deep Instinct, wants to use AI to change that, bringing the GPU-powered deep learning techniques underpinning modern speech and image recognition to the vexing world of cybersecurity.</itunes:summary>
      <content:encoded>
        <![CDATA[Cybersecurity is a cat-and-mouse game where the mouse always has long had the upper hand because it’s so easy for new malware to go undetected. Dr. Eli David, an expert in computational intelligence and CTO of Deep Instinct, wants to use AI to change that, bringing the GPU-powered deep learning techniques underpinning modern speech and image recognition to the vexing world of cybersecurity.]]>
      </content:encoded>
      <itunes:duration>1377</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/306799657]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5980495372.mp3?updated=1740586469" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 8: Better Beer Through AI</title>
      <link>https://soundcloud.com/theaipodcast/ai-beer-gastrograph-jason-cohen</link>
      <description>Whether brewing hearty stouts or crisp lagers, flavor is a fickle thing. Not only is it hard to create consistently good brew, as humans our ability to identify - and remember - flavors is flawed. Yet brands worth billions rely on creating consistent flavors. We talk to Jason Cohen, founder of Gastrograph, who is using AI to help businesses that create beer, chocolate, wine, coffee, and spirits better understand flavor.</description>
      <pubDate>Tue, 31 Jan 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0eb1b462-f45c-11ef-8be6-f3001808ca33/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Whether brewing hearty stouts or crisp lagers, fl…</itunes:subtitle>
      <itunes:summary>Whether brewing hearty stouts or crisp lagers, flavor is a fickle thing. Not only is it hard to create consistently good brew, as humans our ability to identify - and remember - flavors is flawed. Yet brands worth billions rely on creating consistent flavors. We talk to Jason Cohen, founder of Gastrograph, who is using AI to help businesses that create beer, chocolate, wine, coffee, and spirits better understand flavor.</itunes:summary>
      <content:encoded>
        <![CDATA[Whether brewing hearty stouts or crisp lagers, flavor is a fickle thing. Not only is it hard to create consistently good brew, as humans our ability to identify - and remember - flavors is flawed. Yet brands worth billions rely on creating consistent flavors. We talk to Jason Cohen, founder of Gastrograph, who is using AI to help businesses that create beer, chocolate, wine, coffee, and spirits better understand flavor.]]>
      </content:encoded>
      <itunes:duration>1428</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/305680638]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9673115361.mp3?updated=1740586469" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 7: How Humans Bias AI - Narrative Science Chief Scientist Kris Hammond</title>
      <link>https://soundcloud.com/theaipodcast/ep-7-bias-in-ai-narrative-science-chief-scientist-kris-hammond</link>
      <description>It’s easy to think of AI as cold, unbiased, objective. Not quite, suggests Narrative Science Chief Scientist Kris Hammond explains, because we never know when AI will repeat our biases back to us.</description>
      <pubDate>Sun, 22 Jan 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0f0dfd30-f45c-11ef-8be6-2f8e3929bc88/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>It’s easy to think of AI as cold, unbiased, objec…</itunes:subtitle>
      <itunes:summary>It’s easy to think of AI as cold, unbiased, objective. Not quite, suggests Narrative Science Chief Scientist Kris Hammond explains, because we never know when AI will repeat our biases back to us.</itunes:summary>
      <content:encoded>
        <![CDATA[It’s easy to think of AI as cold, unbiased, objective. Not quite, suggests Narrative Science Chief Scientist Kris Hammond explains, because we never know when AI will repeat our biases back to us.]]>
      </content:encoded>
      <itunes:duration>1876</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/304547257]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3557206573.mp3?updated=1740586470" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 6: How AI Turns Kiddie Cars Into Autonomous Racers</title>
      <link>https://soundcloud.com/theaipodcast/how-ai-turns-kiddie-autonomous-racers</link>
      <description>Take brains, a few hundred bones and a pink Barbie jeep. What have you got? For inventive hackers, a new sport filled with f-words -- fast, furious, frugal. Founder of the Power Racing Series Jim Burke talks about why he’s bringing autonomous vehicles to a racing event built on the backs of $500 kiddie cars.</description>
      <pubDate>Wed, 18 Jan 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0f69f2d4-f45c-11ef-8be6-8f56d5c40d3e/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Take brains, a few hundred bones and a pink Barbi…</itunes:subtitle>
      <itunes:summary>Take brains, a few hundred bones and a pink Barbie jeep. What have you got? For inventive hackers, a new sport filled with f-words -- fast, furious, frugal. Founder of the Power Racing Series Jim Burke talks about why he’s bringing autonomous vehicles to a racing event built on the backs of $500 kiddie cars.</itunes:summary>
      <content:encoded>
        <![CDATA[Take brains, a few hundred bones and a pink Barbie jeep. What have you got? For inventive hackers, a new sport filled with f-words -- fast, furious, frugal. Founder of the Power Racing Series Jim Burke talks about why he’s bringing autonomous vehicles to a racing event built on the backs of $500 kiddie cars.]]>
      </content:encoded>
      <itunes:duration>1545</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/303348017]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC3368789593.mp3?updated=1740586470" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 5: How Deep Learning Will Reshape Our Cities</title>
      <link>https://soundcloud.com/theaipodcast/how-deep-learning-will-reshape-our-cities</link>
      <description>Deep learning promises to do more than just reshape city streets. We talked to  Lynn Richards, president and CEO of the Congress for New Urbanism and Charles Marohn, president and co-founder of Strong Towns, about how. AI will do much more than automate driving. It promises to help create more liveable cities. And help put expensive infrastructure where we need it most.</description>
      <pubDate>Sun, 08 Jan 2017 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/0fc57258-f45c-11ef-8be6-97d2d8bb0617/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Deep learning promises to do more than just resha…</itunes:subtitle>
      <itunes:summary>Deep learning promises to do more than just reshape city streets. We talked to  Lynn Richards, president and CEO of the Congress for New Urbanism and Charles Marohn, president and co-founder of Strong Towns, about how. AI will do much more than automate driving. It promises to help create more liveable cities. And help put expensive infrastructure where we need it most.</itunes:summary>
      <content:encoded>
        <![CDATA[Deep learning promises to do more than just reshape city streets. We talked to  Lynn Richards, president and CEO of the Congress for New Urbanism and Charles Marohn, president and co-founder of Strong Towns, about how. AI will do much more than automate driving. It promises to help create more liveable cities. And help put expensive infrastructure where we need it most.]]>
      </content:encoded>
      <itunes:duration>2407</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/302227896]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC5223683417.mp3?updated=1740586471" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 4: How AI Will Revolutionize Driving — Danny Shapiro, NVIDIA</title>
      <link>https://soundcloud.com/theaipodcast/how-ai-will-revolutionize-driving-danny-shapiro-nvidia</link>
      <description>Autonomous vehicles will need to do much more than master object detection. Self-driving vehicles will need technology able to integrate visual computing, artificial intelligence, and high-performance computing, NVIDIA's Danny Shapiro explains.</description>
      <pubDate>Sun, 18 Dec 2016 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/102342ac-f45c-11ef-8be6-936842a0380e/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Autonomous vehicles will need to do much more tha…</itunes:subtitle>
      <itunes:summary>Autonomous vehicles will need to do much more than master object detection. Self-driving vehicles will need technology able to integrate visual computing, artificial intelligence, and high-performance computing, NVIDIA's Danny Shapiro explains.</itunes:summary>
      <content:encoded>
        <![CDATA[Autonomous vehicles will need to do much more than master object detection. Self-driving vehicles will need technology able to integrate visual computing, artificial intelligence, and high-performance computing, NVIDIA's Danny Shapiro explains.]]>
      </content:encoded>
      <itunes:duration>1478</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/299075058]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7684216664.mp3?updated=1740586472" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 3: Deep Learning DIY - NVIDIA Engineer Bob Bond, Make: Magazine Executive Editor Mike Senese</title>
      <link>https://soundcloud.com/theaipodcast/3-deep-learning-diy</link>
      <description>Deep learning isn't just for research scientists anymore. Hobbyists can use consumer grade GPUs and open-source DNN software to tackle common household tasks from ant control to chasing away stray cats.</description>
      <pubDate>Sun, 11 Dec 2016 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/10813ac4-f45c-11ef-8be6-7b76f7409efa/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Deep learning isn't just for research scientists …</itunes:subtitle>
      <itunes:summary>Deep learning isn't just for research scientists anymore. Hobbyists can use consumer grade GPUs and open-source DNN software to tackle common household tasks from ant control to chasing away stray cats.</itunes:summary>
      <content:encoded>
        <![CDATA[Deep learning isn't just for research scientists anymore. Hobbyists can use consumer grade GPUs and open-source DNN software to tackle common household tasks from ant control to chasing away stray cats.]]>
      </content:encoded>
      <itunes:duration>1293</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/296911419]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC9269487262.mp3?updated=1740586472" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 2: Where Deep Learning Goes Next - Bryan Catanzaro, NVIDIA Applied Deep Learning Research</title>
      <link>https://soundcloud.com/theaipodcast/2-where-deep-learning-is-going-next</link>
      <description>Bryan Catanzaro, vice president for applied deep learning research at NVIDIA, talks about how we know an AI technology is working, the potential for AI-powered speech, and where we’ll see the next deep learning breakthroughs.</description>
      <pubDate>Thu, 01 Dec 2016 00:00:00 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/10de932c-f45c-11ef-8be6-67e439c68972/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Bryan Catanzaro, vice president for applied deep …</itunes:subtitle>
      <itunes:summary>Bryan Catanzaro, vice president for applied deep learning research at NVIDIA, talks about how we know an AI technology is working, the potential for AI-powered speech, and where we’ll see the next deep learning breakthroughs.</itunes:summary>
      <content:encoded>
        <![CDATA[Bryan Catanzaro, vice president for applied deep learning research at NVIDIA, talks about how we know an AI technology is working, the potential for AI-powered speech, and where we’ll see the next deep learning breakthroughs.]]>
      </content:encoded>
      <itunes:duration>1972</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/296615435]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC6705937427.mp3?updated=1740586473" length="0" type="audio/mpeg"/>
    </item>
    <item>
      <title>Ep. 1: Deep Learning 101 - Will Ramey, NVIDIA Senior Manager for GPU Computing</title>
      <link>https://soundcloud.com/theaipodcast/ai-podcast-deep-learning-101</link>
      <description>Think of our inaugural episode of The AI Podcast as a guide for the perplexed.  Host Michael Copeland speaks with NVIDIA's Will Ramey about the history behind today's AI boom and the key concepts you need to know to get your head around a technology that's reshaping the world.</description>
      <pubDate>Wed, 30 Nov 2016 22:48:06 -0000</pubDate>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:author>NVIDIA</itunes:author>
      <itunes:image href="https://megaphone.imgix.net/podcasts/113a6882-f45c-11ef-8be6-07468978817a/image/7dcb6f5ee43704e84cdbb1845ad951bb.jpg?ixlib=rails-4.3.1&amp;max-w=3000&amp;max-h=3000&amp;fit=crop&amp;auto=format,compress"/>
      <itunes:subtitle>Think of our inaugural episode of The AI Podcast …</itunes:subtitle>
      <itunes:summary>Think of our inaugural episode of The AI Podcast as a guide for the perplexed.  Host Michael Copeland speaks with NVIDIA's Will Ramey about the history behind today's AI boom and the key concepts you need to know to get your head around a technology that's reshaping the world.</itunes:summary>
      <content:encoded>
        <![CDATA[Think of our inaugural episode of The AI Podcast as a guide for the perplexed.  Host Michael Copeland speaks with NVIDIA's Will Ramey about the history behind today's AI boom and the key concepts you need to know to get your head around a technology that's reshaping the world.]]>
      </content:encoded>
      <itunes:duration>2071</itunes:duration>
      <itunes:explicit>no</itunes:explicit>
      <guid isPermaLink="false"><![CDATA[tag:soundcloud,2010:tracks/295616968]]></guid>
      <enclosure url="https://traffic.megaphone.fm/NVC7385218443.mp3?updated=1740586473" length="0" type="audio/mpeg"/>
    </item>
  </channel>
</rss>
