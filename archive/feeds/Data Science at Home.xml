<?xml version="1.0" encoding="UTF-8"?><!-- generator="podbean/5.5" -->
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
     xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0"
     xmlns:spotify="http://www.spotify.com/ns/rss"
     xmlns:podcast="https://podcastindex.org/namespace/1.0"
    xmlns:media="http://search.yahoo.com/mrss/">

<channel>
    <title>Data Science at Home</title>
    <atom:link href="https://feed.podbean.com/datascienceathome/feed.xml" rel="self" type="application/rss+xml"/>
    <link>https://datascienceathome.podbean.com</link>
    <description>Technology, AI, machine learning and algorithms. Come join the discussion on Discord!  
https://discord.gg/4UNKGf3</description>
    <pubDate>Wed, 18 Jun 2025 16:34:45 +0200</pubDate>
    <generator>https://podbean.com/?v=5.5</generator>
    <language>en</language>
        <copyright>Copyright 2024 datascienceathome.com All rights reserved.</copyright>
    <category>Technology</category>
    <ttl>1440</ttl>
    <itunes:type>episodic</itunes:type>
          <itunes:summary>Artificial Intelligence, algorithms and tech tales that are shaping the world. Hype not included.</itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
<itunes:category text="Technology" />
	<itunes:category text="News">
		<itunes:category text="Tech News" />
	</itunes:category>
    <itunes:owner>
        <itunes:name>Francesco Gadaleta</itunes:name>
            </itunes:owner>
    	<itunes:block>No</itunes:block>
	<itunes:explicit>false</itunes:explicit>
	<itunes:new-feed-url>https://datascienceathome.podbean.com/feed.xml</itunes:new-feed-url>
    <itunes:image href="https://pbcdn1.podbean.com/imglogo/image-logo/1799802/dsh-cover-2.jpg" />
    <image>
        <url>https://pbcdn1.podbean.com/imglogo/image-logo/1799802/dsh-cover-2.jpg</url>
        <title>Data Science at Home</title>
        <link>https://datascienceathome.podbean.com</link>
        <width>144</width>
        <height>144</height>
    </image>
    <item>
        <title>Brains in the Machine: The Rise of Neuromorphic Computing (Ep. 285)</title>
        <itunes:title>Brains in the Machine: The Rise of Neuromorphic Computing (Ep. 285)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/brains-in-the-machine-the-rise-of-neuromorphic-computing-ep-285/</link>
                    <comments>https://datascienceathome.podbean.com/e/brains-in-the-machine-the-rise-of-neuromorphic-computing-ep-285/#comments</comments>        <pubDate>Wed, 18 Jun 2025 16:34:45 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/22e42860-f5d7-30c8-9e0d-423b93068a4e</guid>
                                    <description><![CDATA[







<p>In this episode of Data Science at Home, we explore the fascinating world of neuromorphic computing â€” a brain-inspired approach to computation that could reshape the future of AI and robotics. The episode breaks down how neuromorphic systems differ from conventional AI architectures like transformers and LLMs, diving into spiking neural networks (SNNs), their benefits in energy efficiency and real-time processing, and their limitations in training and scalability. Real-world applications are highlighted, including low-power drones, hearing aids, and event-based cameras. Francesco closes with a vision of hybrid systems where neuromorphic chips and LLMs coexist, blending biological inspiration with modern AI.</p>

<p>ğŸ“š References</p>
<ul>
<li>
<p>SpikingJelly: <a href='https://github.com/fangwei123456/spikingjelly'>https://github.com/fangwei123456/spikingjelly</a></p>
</li>
<li>
<p>Norse: <a href='https://github.com/norse/norse'>https://github.com/norse/norse</a></p>
</li>
<li>
<p>IBM TrueNorth: <a href='https://www.millionairematch.com'>https://www.millionairematch.com</a></p>
</li>
<li>
<p>AGNTCY â€” The open source collective building the Internet of Agents
ğŸŒ <a href='https://www.agntcy.org'>https://www.agntcy.org</a></p>
</li>
</ul>







]]></description>
                                                            <content:encoded><![CDATA[







<p>In this episode of <em>Data Science at Home</em>, we explore the fascinating world of neuromorphic computing â€” a brain-inspired approach to computation that could reshape the future of AI and robotics. The episode breaks down how neuromorphic systems differ from conventional AI architectures like transformers and LLMs, diving into spiking neural networks (SNNs), their benefits in energy efficiency and real-time processing, and their limitations in training and scalability. Real-world applications are highlighted, including low-power drones, hearing aids, and event-based cameras. Francesco closes with a vision of hybrid systems where neuromorphic chips and LLMs coexist, blending biological inspiration with modern AI.</p>

<p>ğŸ“š References</p>
<ul>
<li>
<p>SpikingJelly: <a href='https://github.com/fangwei123456/spikingjelly'>https://github.com/fangwei123456/spikingjelly</a></p>
</li>
<li>
<p>Norse: <a href='https://github.com/norse/norse'>https://github.com/norse/norse</a></p>
</li>
<li>
<p>IBM TrueNorth: <a href='https://www.millionairematch.com'>https://www.millionairematch.com</a></p>
</li>
<li>
<p>AGNTCY â€” The open source collective building the Internet of Agents<br>
ğŸŒ <a href='https://www.agntcy.org'>https://www.agntcy.org</a></p>
</li>
</ul>







]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/upx6u759wjz6cfhm/neuro-compute-audio.mp3" length="58352325" type="audio/mpeg"/>
        <itunes:summary><![CDATA[







In this episode of Data Science at Home, we explore the fascinating world of neuromorphic computing â€” a brain-inspired approach to computation that could reshape the future of AI and robotics. The episode breaks down how neuromorphic systems differ from conventional AI architectures like transformers and LLMs, diving into spiking neural networks (SNNs), their benefits in energy efficiency and real-time processing, and their limitations in training and scalability. Real-world applications are highlighted, including low-power drones, hearing aids, and event-based cameras. Francesco closes with a vision of hybrid systems where neuromorphic chips and LLMs coexist, blending biological inspiration with modern AI.

ğŸ“š References


SpikingJelly: https://github.com/fangwei123456/spikingjelly


Norse: https://github.com/norse/norse


IBM TrueNorth: https://research.ibm.com/blog/brain-inspired-chip


Intel Loihi 2: https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html


SpiNNaker: https://apt.cs.manchester.ac.uk/projects/SpiNNaker/


BioRobotics Institute: https://www.santannapisa.it/en/institute/biorobotics



ğŸ™ï¸ Sponsors


MillionaireMatch â€” The elite platform for high-achieving singlesğŸŒ https://www.millionairematch.com


AGNTCY â€” The open source collective building the Internet of AgentsğŸŒ https://www.agntcy.org









]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:18</itunes:duration>
                <itunes:episode>287</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>DSH/Warcoded - AI in the Invisible Battlespace (Ep. 284)</title>
        <itunes:title>DSH/Warcoded - AI in the Invisible Battlespace (Ep. 284)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ep-284/</link>
                    <comments>https://datascienceathome.podbean.com/e/ep-284/#comments</comments>        <pubDate>Tue, 03 Jun 2025 17:31:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/73a4d646-714a-38af-b066-c0cd0f7e8729</guid>
                                    <description><![CDATA[







<p>This episode explores the invisible battlespace of cyber and electronic warfare, where AI takes center stage. From autonomous hacking bots to smart jamming and adversarial attacks on machine learning models, we uncover how modern conflicts are increasingly fought with code, not bullets â€” and why the future of warfare may be decided by algorithms.</p>









<p>Â </p>
Sponsors









<p>Building multi-agent software is hard â€” agent-to-agent and agent-to-tool communication is still the wild west. Thatâ€™s where the AGNTCY, comes in. Itâ€™s an open source collective building the Internet of Agents â€” a global collaboration layer where AI agents can discover each other, communicate, and work across frameworks. For developers, this means cleaner protocols, standard discovery tools, and modular components to scale multi-agent workflows. Build with others who care about robust multi-agent software. Visit <a href='http://AGNTCY.org'>AGNTCY.org</a></p>









<p>Â </p>
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>
]]></description>
                                                            <content:encoded><![CDATA[







<p>This episode explores the invisible battlespace of cyber and electronic warfare, where AI takes center stage. From autonomous hacking bots to smart jamming and adversarial attacks on machine learning models, we uncover how modern conflicts are increasingly fought with code, not bullets â€” and why the future of warfare may be decided by algorithms.</p>









<p>Â </p>
Sponsors









<p>Building multi-agent software is hard â€” agent-to-agent and agent-to-tool communication is still the wild west. Thatâ€™s where the AGNTCY, comes in. Itâ€™s an open source collective building the Internet of Agents â€” a global collaboration layer where AI agents can discover each other, communicate, and work across frameworks. For developers, this means cleaner protocols, standard discovery tools, and modular components to scale multi-agent workflows. Build with others who care about robust multi-agent software. Visit <a href='http://AGNTCY.org'>AGNTCY.org</a></p>









<p>Â </p>
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/muafsmc52tm37qhe/dsh-warcoded-part-4-final.mp3" length="51314937" type="audio/mpeg"/>
        <itunes:summary><![CDATA[







This episode explores the invisible battlespace of cyber and electronic warfare, where AI takes center stage. From autonomous hacking bots to smart jamming and adversarial attacks on machine learning models, we uncover how modern conflicts are increasingly fought with code, not bullets â€” and why the future of warfare may be decided by algorithms.









Â 
Sponsors









Building multi-agent software is hard â€” agent-to-agent and agent-to-tool communication is still the wild west. Thatâ€™s where the AGNTCY, comes in. Itâ€™s an open source collective building the Internet of Agents â€” a global collaboration layer where AI agents can discover each other, communicate, and work across frameworks. For developers, this means cleaner protocols, standard discovery tools, and modular components to scale multi-agent workflows. Build with others who care about robust multi-agent software. Visit AGNTCY.org









Â 
Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at amethix.com
Â 
Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at intrepid.ai
Â 
Â 
#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:22</itunes:duration>
                <itunes:episode>286</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>DSH/Warcoded Swarming the Battlefield (Ep. 283)</title>
        <itunes:title>DSH/Warcoded Swarming the Battlefield (Ep. 283)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/dshwarcoded-swarming-the-battlefield-ep-283/</link>
                    <comments>https://datascienceathome.podbean.com/e/dshwarcoded-swarming-the-battlefield-ep-283/#comments</comments>        <pubDate>Tue, 27 May 2025 16:49:18 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c4c8b305-0903-39b4-b33d-215ddeea47b2</guid>
                                    <description><![CDATA[







<p>Swarming the Battlefield explores how artificial intelligence is revolutionizing combat through coordinated drone swarms. We dive into the algorithms that enable autonomous collaboration, from decentralized decision-making to real-time target allocation, and examine real-world implementations shaping modern battle strategies. 
This episode uncovers how these intelligent agents turn the chaos of the battlefield into a synchronized dance of machine warfare.</p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>







]]></description>
                                                            <content:encoded><![CDATA[







<p><em>Swarming the Battlefield </em>explores how artificial intelligence is revolutionizing combat through coordinated drone swarms. We dive into the algorithms that enable autonomous collaboration, from decentralized decision-making to real-time target allocation, and examine real-world implementations shaping modern battle strategies. <br>
This episode uncovers how these intelligent agents turn the chaos of the battlefield into a synchronized dance of machine warfare.</p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>







]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/23u6kmqyvtvmj8yk/dsh-warcoded-part-3-podcast.mp3" length="62614464" type="audio/mpeg"/>
        <itunes:summary><![CDATA[







Swarming the Battlefield explores how artificial intelligence is revolutionizing combat through coordinated drone swarms. We dive into the algorithms that enable autonomous collaboration, from decentralized decision-making to real-time target allocation, and examine real-world implementations shaping modern battle strategies. This episode uncovers how these intelligent agents turn the chaos of the battlefield into a synchronized dance of machine warfare.
Â 
Sponsors
Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at amethix.com
Â 
Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at intrepid.ai
Â 
Â 
#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast







]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:05</itunes:duration>
                <itunes:episode>285</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>DSH/Warcoded Kill Chains and Algorithmic Warfare â€“ Autonomy in Targeting and Engagement (Ep. 282)</title>
        <itunes:title>DSH/Warcoded Kill Chains and Algorithmic Warfare â€“ Autonomy in Targeting and Engagement (Ep. 282)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/dshwarcoded-kill-chains-and-algorithmic-warfare-%e2%80%93-autonomy-in-targeting-and-engagement-ep-282/</link>
                    <comments>https://datascienceathome.podbean.com/e/dshwarcoded-kill-chains-and-algorithmic-warfare-%e2%80%93-autonomy-in-targeting-and-engagement-ep-282/#comments</comments>        <pubDate>Wed, 14 May 2025 07:33:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c3d2f0b9-65e9-32d7-a40d-303bf9970ee6</guid>
                                    <description><![CDATA[<p>In this gripping follow-up, we dive into how AI is transforming kinetic operationsâ€”from identifying a threat to executing a strike.</p>
<p>ğŸ” Highlights from this episode:</p>
<ul>
<li>
<p>How AI compresses the OODA loop (Observe, Orient, Decide, Act)</p>
</li>
<li>
<p>The spectrum of autonomy: human-on-the-loop vs. human-out-of-the-loop</p>
</li>
<li>
<p>Real-world systems like loitering munitions (Switchblade, Harpy) and Selective Ground Response AI (SGR-AI)</p>
</li>
<li>
<p>The ethical and legal dimensions of delegating lethal decisions to machines</p>
</li>
</ul>
<p>Â </p>
<p>As the lines blur between algorithm and operator, we explore whoâ€”or whatâ€”is pulling the trigger.</p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this gripping follow-up, we dive into how AI is transforming kinetic operationsâ€”from identifying a threat to executing a strike.</p>
<p>ğŸ” <em>Highlights from this episode:</em></p>
<ul>
<li>
<p>How AI compresses the OODA loop (Observe, Orient, Decide, Act)</p>
</li>
<li>
<p>The spectrum of autonomy: human-on-the-loop vs. human-out-of-the-loop</p>
</li>
<li>
<p>Real-world systems like loitering munitions (Switchblade, Harpy) and Selective Ground Response AI (SGR-AI)</p>
</li>
<li>
<p>The ethical and legal dimensions of delegating lethal decisions to machines</p>
</li>
</ul>
<p>Â </p>
<p>As the lines blur between algorithm and operator, we explore whoâ€”or whatâ€”is pulling the trigger.</p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>Â </p>
<p>#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/f7mpdhzvain5tsh8/dsh-warcoded-part-2.mp3" length="63570546" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this gripping follow-up, we dive into how AI is transforming kinetic operationsâ€”from identifying a threat to executing a strike.
ğŸ” Highlights from this episode:


How AI compresses the OODA loop (Observe, Orient, Decide, Act)


The spectrum of autonomy: human-on-the-loop vs. human-out-of-the-loop


Real-world systems like loitering munitions (Switchblade, Harpy) and Selective Ground Response AI (SGR-AI)


The ethical and legal dimensions of delegating lethal decisions to machines


Â 
As the lines blur between algorithm and operator, we explore whoâ€”or whatâ€”is pulling the trigger.
Â 
Â 
Sponsors
Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at amethix.com
Â 
Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at intrepid.ai
Â 
Â 
#Warcoded #DataScienceAtHome #AI #AutonomousWeapons #MilTech #DefenseTech #KillChain #OODAloop #LAWs #EdgeAI #Podcast]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:29</itunes:duration>
                <itunes:episode>284</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>DSH/Warcoded: Eyes and Ears of the Machine â€“ AI Reconnaissance and Surveillance (Ep. 281)</title>
        <itunes:title>DSH/Warcoded: Eyes and Ears of the Machine â€“ AI Reconnaissance and Surveillance (Ep. 281)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/dshwarcoded-eyes-and-ears-of-the-machine-%e2%80%93-ai-reconnaissance-and-surveillance-ep-281/</link>
                    <comments>https://datascienceathome.podbean.com/e/dshwarcoded-eyes-and-ears-of-the-machine-%e2%80%93-ai-reconnaissance-and-surveillance-ep-281/#comments</comments>        <pubDate>Wed, 07 May 2025 21:02:19 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6d55c332-59a6-39f5-bc83-260d9df22711</guid>
                                    <description><![CDATA[<p>Welcome to DSH/Warcoded</p>
<p>We explore how AI is transforming ISR (Intelligence, Surveillance, Reconnaissance)â€”from satellite imagery to drone feeds. 

In this episode:</p>
<p>ğŸ” Computer vision for target ID
ğŸ“¡ Predictive surveillance &amp; pattern-of-life modeling
ğŸ§  LLMs for SIGINT &amp; OSINT intelligence briefings
ğŸŒ Real-world examples: Ukraine, Gaza &amp; more</p>
<p>Listen now and see how machines are learning to see, predict, and inform at the edge of modern conflict.</p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>#AI #defensetech #ISR #LLM #Warcoded #DataScienceAtHome #OSINT #SIGINT #dronewarfare</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Welcome to DSH/Warcoded</p>
<p>We explore how AI is transforming ISR (Intelligence, Surveillance, Reconnaissance)â€”from satellite imagery to drone feeds. <br>
<br>
In this episode:</p>
<p>ğŸ” Computer vision for target ID<br>
ğŸ“¡ Predictive surveillance &amp; pattern-of-life modeling<br>
ğŸ§  LLMs for SIGINT &amp; OSINT intelligence briefings<br>
ğŸŒ Real-world examples: Ukraine, Gaza &amp; more</p>
<p>Listen now and see how machines are learning to see, predict, and inform at the edge of modern conflict.</p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at<a href='https://amethix.com'> amethix.com</a></p>
<p>Â </p>
<p>Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at<a href='https://intrepid.ai'> intrepid.ai</a></p>
<p>Â </p>
<p>#AI #defensetech #ISR #LLM #Warcoded #DataScienceAtHome #OSINT #SIGINT #dronewarfare</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/3eq2utw4yespbyme/warcoded-1-final.mp3" length="46440488" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Welcome to DSH/Warcoded
We explore how AI is transforming ISR (Intelligence, Surveillance, Reconnaissance)â€”from satellite imagery to drone feeds. In this episode:
ğŸ” Computer vision for target IDğŸ“¡ Predictive surveillance &amp; pattern-of-life modelingğŸ§  LLMs for SIGINT &amp; OSINT intelligence briefingsğŸŒ Real-world examples: Ukraine, Gaza &amp; more
Listen now and see how machines are learning to see, predict, and inform at the edge of modern conflict.
Â 
Â 
Sponsors
Warcoded is proudly sponsored by Amethix Technologies. At the intersection of ethics and engineering, Amethix creates AI systems that donâ€™t just functionâ€”they adapt, learn, and serve. With a focus on dual-use innovation, Amethix is shaping a future where intelligent machines extend human capability, not replace it. Discover more at amethix.com
Â 
Warcoded is brought to you by Intrepid AI. From drones to satellites, Intrepid AI gives engineers and defense innovators the tools to prototype, simulate, and deploy autonomous systems with confidence. Whether it's in the sky, on the ground, or in orbitâ€”if it's intelligent and mobile, Intrepid helps you build it. Learn more at intrepid.ai
Â 
#AI #defensetech #ISR #LLM #Warcoded #DataScienceAtHome #OSINT #SIGINT #dronewarfare]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:20</itunes:duration>
                <itunes:episode>283</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI Agents with Atomic Agents ğŸš€ with Kenny Vaneetvelde (Ep. 280)</title>
        <itunes:title>AI Agents with Atomic Agents ğŸš€ with Kenny Vaneetvelde (Ep. 280)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-agents-with-atomic-agents-%f0%9f%9a-with-kenny-vaneetvelde-ep-281/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-agents-with-atomic-agents-%f0%9f%9a-with-kenny-vaneetvelde-ep-281/#comments</comments>        <pubDate>Fri, 11 Apr 2025 05:37:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6cebb617-c05a-3ef9-aa32-a0f843e14658</guid>
                                    <description><![CDATA[<p class="p1">ğŸ™ï¸ In this episode of Data Science at Home, we sit down with Kenny Vaneetvelde, the mastermind behind Atomic Agents, a groundbreaking framework redefining AI development.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ” Discover how atomicity simplifies complex AI systems, why modularity matters more than ever, and how Atomic Agents is eliminating hidden assumptions and redundant complexity in AI workflows.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ’¡ From real-world applications to the tech stack behind the framework, Kenny takes us on a deep dive into this lightweight, powerful tool for creating consistent and brand-aligned AI.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ”¥ Whether youâ€™re a seasoned developer or just AI-curious, this conversation is packed with insights you donâ€™t want to miss.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ“Œ Timestamps:</p>
<p class="p1">0:00 - Intro</p>
<p class="p1">2:30 - Kennyâ€™s journey in AI</p>
<p class="p1">5:00 - What are Atomic Agents?</p>
<p class="p1">10:45 - Why atomicity matters in AI</p>
<p class="p1">18:20 - The tech behind Atomic Agents: Instructor, Pydantic &amp; more</p>
<p class="p1">25:00 - Real-world use cases and future vision</p>
<p class="p1">40:45 - Advice for AI developers and businesses</p>
<p class="p2">Â </p>
<p class="p1">ğŸ“² Check out Atomic Agents on GitHub: https://github.com/BrainBlend-AI/atomic-agents</p>
<p class="p2">Â </p>
<p class="p1">https://brainblendai.com/</p>
<p class="p2">Â </p>
<p class="p1">ğŸ”— Follow Kenny on LinkedIn: https://www.linkedin.com/in/kennyvaneetvelde/</p>
<p class="p2">Â </p>
<p class="p1">ğŸ’¬ Got questions? Drop them in the comments! Donâ€™t forget to like, subscribe, and share this episode with your fellow AI enthusiasts.</p>
<p class="p2">Â </p>
<p class="p1">#AI #AtomicAgents #DataScience #Podcast</p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="p1">ğŸ™ï¸ In this episode of Data Science at Home, we sit down with Kenny Vaneetvelde, the mastermind behind Atomic Agents, a groundbreaking framework redefining AI development.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ” Discover how atomicity simplifies complex AI systems, why modularity matters more than ever, and how Atomic Agents is eliminating hidden assumptions and redundant complexity in AI workflows.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ’¡ From real-world applications to the tech stack behind the framework, Kenny takes us on a deep dive into this lightweight, powerful tool for creating consistent and brand-aligned AI.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ”¥ Whether youâ€™re a seasoned developer or just AI-curious, this conversation is packed with insights you donâ€™t want to miss.</p>
<p class="p2">Â </p>
<p class="p1">ğŸ“Œ Timestamps:</p>
<p class="p1">0:00 - Intro</p>
<p class="p1">2:30 - Kennyâ€™s journey in AI</p>
<p class="p1">5:00 - What are Atomic Agents?</p>
<p class="p1">10:45 - Why atomicity matters in AI</p>
<p class="p1">18:20 - The tech behind Atomic Agents: Instructor, Pydantic &amp; more</p>
<p class="p1">25:00 - Real-world use cases and future vision</p>
<p class="p1">40:45 - Advice for AI developers and businesses</p>
<p class="p2">Â </p>
<p class="p1">ğŸ“² Check out Atomic Agents on GitHub: https://github.com/BrainBlend-AI/atomic-agents</p>
<p class="p2">Â </p>
<p class="p1">https://brainblendai.com/</p>
<p class="p2">Â </p>
<p class="p1">ğŸ”— Follow Kenny on LinkedIn: https://www.linkedin.com/in/kennyvaneetvelde/</p>
<p class="p2">Â </p>
<p class="p1">ğŸ’¬ Got questions? Drop them in the comments! Donâ€™t forget to like, subscribe, and share this episode with your fellow AI enthusiasts.</p>
<p class="p2">Â </p>
<p class="p1">#AI #AtomicAgents #DataScience #Podcast</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2dugmdvr8zkcbvx4/atomic-agents-podcast.mp3" length="133867101" type="audio/mpeg"/>
        <itunes:summary><![CDATA[ğŸ™ï¸ In this episode of Data Science at Home, we sit down with Kenny Vaneetvelde, the mastermind behind Atomic Agents, a groundbreaking framework redefining AI development.
Â 
ğŸ” Discover how atomicity simplifies complex AI systems, why modularity matters more than ever, and how Atomic Agents is eliminating hidden assumptions and redundant complexity in AI workflows.
Â 
ğŸ’¡ From real-world applications to the tech stack behind the framework, Kenny takes us on a deep dive into this lightweight, powerful tool for creating consistent and brand-aligned AI.
Â 
ğŸ”¥ Whether youâ€™re a seasoned developer or just AI-curious, this conversation is packed with insights you donâ€™t want to miss.
Â 
ğŸ“Œ Timestamps:
0:00 - Intro
2:30 - Kennyâ€™s journey in AI
5:00 - What are Atomic Agents?
10:45 - Why atomicity matters in AI
18:20 - The tech behind Atomic Agents: Instructor, Pydantic &amp; more
25:00 - Real-world use cases and future vision
40:45 - Advice for AI developers and businesses
Â 
ğŸ“² Check out Atomic Agents on GitHub: https://github.com/BrainBlend-AI/atomic-agents
Â 
https://brainblendai.com/
Â 
ğŸ”— Follow Kenny on LinkedIn: https://www.linkedin.com/in/kennyvaneetvelde/
Â 
ğŸ’¬ Got questions? Drop them in the comments! Donâ€™t forget to like, subscribe, and share this episode with your fellow AI enthusiasts.
Â 
#AI #AtomicAgents #DataScience #Podcast]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>55:46</itunes:duration>
                <itunes:episode>282</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Run massive models on crappy machines (Ep. 279)</title>
        <itunes:title>Run massive models on crappy machines (Ep. 279)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/run-massive-models-on-crappy-machines-ep-280/</link>
                    <comments>https://datascienceathome.podbean.com/e/run-massive-models-on-crappy-machines-ep-280/#comments</comments>        <pubDate>Fri, 04 Apr 2025 06:29:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d5594610-2a84-366b-bee1-5058c3646e9d</guid>
                                    <description><![CDATA[<p class="p1">AI shouldnâ€™t be limited to those with access to expensive hardware. This episode explores how to break down barriers by running massive AI models on "crappy machines"â€”affordable, low-spec devices. Clever techniques like quantization, pruning, model distillation might not be enough. </p>
<p class="p1">With edge offloading, we can make state-of-the-art AI accessible to hobbyists, researchers, and innovators everywhere. </p>
<p class="p1">By democratizing AI, we can empower individuals and small teams to experiment, create, and solve problems without needing deep pockets or enterprise-grade resources.</p>
<p class="p2">Â </p>
<p class="p1">AI for everyone, on everything. Letâ€™s make it happen.</p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="p1">AI shouldnâ€™t be limited to those with access to expensive hardware. This episode explores how to break down barriers by running massive AI models on "crappy machines"â€”affordable, low-spec devices. Clever techniques like quantization, pruning, model distillation might not be enough. </p>
<p class="p1">With edge offloading, we can make state-of-the-art AI accessible to hobbyists, researchers, and innovators everywhere. </p>
<p class="p1">By democratizing AI, we can empower individuals and small teams to experiment, create, and solve problems without needing deep pockets or enterprise-grade resources.</p>
<p class="p2">Â </p>
<p class="p1">AI for everyone, on everything. Letâ€™s make it happen.</p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/agx89mjyaisu82n4/distributed-ai-podcast.mp3" length="113230366" type="audio/mpeg"/>
        <itunes:summary><![CDATA[AI shouldnâ€™t be limited to those with access to expensive hardware. This episode explores how to break down barriers by running massive AI models on "crappy machines"â€”affordable, low-spec devices. Clever techniques like quantization, pruning, model distillation might not be enough. 
With edge offloading, we can make state-of-the-art AI accessible to hobbyists, researchers, and innovators everywhere. 
By democratizing AI, we can empower individuals and small teams to experiment, create, and solve problems without needing deep pockets or enterprise-grade resources.
Â 
AI for everyone, on everything. Letâ€™s make it happen.
Â 
Â 
âœ¨ Connect with us!
ğŸ“© Newsletter: https://datascienceathome.substack.com
ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.
ğŸ¦ Twitter: @DataScienceAtHome
ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/
Instagram: https://www.instagram.com/datascienceathome/
Facebook: https://www.facebook.com/datascienceAH
LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast
Discord Channel: https://discord.gg/4UNKGf3
Â 
NEW TO DATA SCIENCE AT HOME?
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com
Â 
SEND US MAIL!
We love hearing from you! Send us mail at:
hello@datascienceathome.com
Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>47:10</itunes:duration>
                <itunes:episode>281</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>WeightWatcher: The AI Detective for LLMs (DeepSeek &amp; OpenAI included) (Ep. 278)</title>
        <itunes:title>WeightWatcher: The AI Detective for LLMs (DeepSeek &amp; OpenAI included) (Ep. 278)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/weightwatcher-the-ai-detective-for-llms-deepseek-openai-included-ep-279/</link>
                    <comments>https://datascienceathome.podbean.com/e/weightwatcher-the-ai-detective-for-llms-deepseek-openai-included-ep-279/#comments</comments>        <pubDate>Mon, 31 Mar 2025 06:30:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/87f2fd90-fd45-3090-8939-cb320bfe948b</guid>
                                    <description><![CDATA[<p class="p1">Is DeepSeek the next big thing in AI? Can OpenAI keep up? And how do we truly understand these massive LLMs? </p>
<p class="p1">Enter WeightWatcherâ€”the AI detective tool that peeks inside neural networks without needing their data. </p>
<p class="p2">Â </p>
<p class="p1">In this episode, we chat with its creator, Dr. Charles Martin, to uncover what makes LLMs tick, the hidden patterns inside models like GPT-4 and DeepSeek, and whether AI is headed for a breakthroughâ€”or a bottleneck. </p>
<p class="p1">If youâ€™re into cutting-edge AI, you wonâ€™t want to miss this one!</p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="p1">Is DeepSeek the next big thing in AI? Can OpenAI keep up? And how do we truly understand these massive LLMs? </p>
<p class="p1">Enter WeightWatcherâ€”the AI detective tool that peeks inside neural networks without needing their data. </p>
<p class="p2">Â </p>
<p class="p1">In this episode, we chat with its creator, Dr. Charles Martin, to uncover what makes LLMs tick, the hidden patterns inside models like GPT-4 and DeepSeek, and whether AI is headed for a breakthroughâ€”or a bottleneck. </p>
<p class="p1">If youâ€™re into cutting-edge AI, you wonâ€™t want to miss this one!</p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/bsmynferu6kfgubb/weight-watcher.mp3" length="124285386" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Is DeepSeek the next big thing in AI? Can OpenAI keep up? And how do we truly understand these massive LLMs? 
Enter WeightWatcherâ€”the AI detective tool that peeks inside neural networks without needing their data. 
Â 
In this episode, we chat with its creator, Dr. Charles Martin, to uncover what makes LLMs tick, the hidden patterns inside models like GPT-4 and DeepSeek, and whether AI is headed for a breakthroughâ€”or a bottleneck. 
If youâ€™re into cutting-edge AI, you wonâ€™t want to miss this one!
Â 
Â 
âœ¨ Connect with us!
ğŸ“© Newsletter: https://datascienceathome.substack.com
ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.
ğŸ¦ Twitter: @DataScienceAtHome
ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/
Instagram: https://www.instagram.com/datascienceathome/
Facebook: https://www.facebook.com/datascienceAH
LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast
Discord Channel: https://discord.gg/4UNKGf3
Â 
NEW TO DATA SCIENCE AT HOME?
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com
Â 
SEND US MAIL!
We love hearing from you! Send us mail at:
hello@datascienceathome.com
Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>51:47</itunes:duration>
                <itunes:episode>280</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Tech's Dumbest Mistake: Why Firing Programmers for AI Will Destroy Everything (Ep. 277)</title>
        <itunes:title>Tech's Dumbest Mistake: Why Firing Programmers for AI Will Destroy Everything (Ep. 277)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/techs-dumbest-mistake-why-firing-programmers-for-ai-will-destroy-everything-ep-278/</link>
                    <comments>https://datascienceathome.podbean.com/e/techs-dumbest-mistake-why-firing-programmers-for-ai-will-destroy-everything-ep-278/#comments</comments>        <pubDate>Fri, 28 Mar 2025 12:09:46 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1a3414fe-69bd-3730-b8b7-72c88fe6de09</guid>
                                    <description><![CDATA[<p class="p1">From the viral article "Tech's Dumbest Mistake: Why Firing Programmers for AI Will Destroy Everything" on my newsletter at https://defragzone.substack.com/p/techs-dumbest-mistake-why-firing</p>
<p class="p1">here are my thoughts about AI replacing programmers... </p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="p1">From the viral article "Tech's Dumbest Mistake: Why Firing Programmers for AI Will Destroy Everything" on my newsletter at https://defragzone.substack.com/p/techs-dumbest-mistake-why-firing</p>
<p class="p1">here are my thoughts about AI replacing programmers... </p>
<p class="p2">Â </p>
<p class="p2">Â </p>
<p class="p1">âœ¨ Connect with us!</p>
<p class="p1">ğŸ“© Newsletter: https://datascienceathome.substack.com</p>
<p class="p1">ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.</p>
<p class="p1">ğŸ¦ Twitter: @DataScienceAtHome</p>
<p class="p1">ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/</p>
<p class="p1">Instagram: https://www.instagram.com/datascienceathome/</p>
<p class="p1">Facebook: https://www.facebook.com/datascienceAH</p>
<p class="p1">LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p class="p1">Discord Channel: https://discord.gg/4UNKGf3</p>
<p class="p2">Â </p>
<p class="p1">NEW TO DATA SCIENCE AT HOME?</p>
<p class="p1">Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com</p>
<p class="p2">Â </p>
<p class="p1">SEND US MAIL!</p>
<p class="p1">We love hearing from you! Send us mail at:</p>
<p class="p1">hello@datascienceathome.com</p>
<p class="p1">Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/m9savcxt2kyy3kh3/ai-and-programmers.mp3" length="42130284" type="audio/mpeg"/>
        <itunes:summary><![CDATA[From the viral article "Tech's Dumbest Mistake: Why Firing Programmers for AI Will Destroy Everything" on my newsletter at https://defragzone.substack.com/p/techs-dumbest-mistake-why-firing
here are my thoughts about AI replacing programmers... 
Â 
Â 
âœ¨ Connect with us!
ğŸ“© Newsletter: https://datascienceathome.substack.com
ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.
ğŸ¦ Twitter: @DataScienceAtHome
ğŸ“˜ LinkedIn: https://www.linkedin.com/in/fragadaleta/
Instagram: https://www.instagram.com/datascienceathome/
Facebook: https://www.facebook.com/datascienceAH
LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast
Discord Channel: https://discord.gg/4UNKGf3
Â 
NEW TO DATA SCIENCE AT HOME?
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com
Â 
SEND US MAIL!
We love hearing from you! Send us mail at:
hello@datascienceathome.com
Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:33</itunes:duration>
                <itunes:episode>279</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Scaling Smart: AI, Data, and Building Future-Ready Enterprises with Josh Miramant (Ep. 276)</title>
        <itunes:title>Scaling Smart: AI, Data, and Building Future-Ready Enterprises with Josh Miramant (Ep. 276)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/scaling-smart-ai-data-and-building-future-ready-enterprises-with-josh-miramant-ep-276/</link>
                    <comments>https://datascienceathome.podbean.com/e/scaling-smart-ai-data-and-building-future-ready-enterprises-with-josh-miramant-ep-276/#comments</comments>        <pubDate>Mon, 23 Dec 2024 21:14:30 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/8718d51b-7024-3993-8ce9-6873b5ea7feb</guid>
                                    <description><![CDATA[



<p>In this episode, we dive into the transformative world of AI, data analytics, and cloud infrastructure with Josh Miramant, CEO of Blue Orange Digital. As a seasoned entrepreneur with over $25 million raised across ventures and two successful exits, Josh shares invaluable insights on scaling data-driven businesses, integrating machine learning frameworks, and navigating the rapidly evolving landscape of cloud data architecture. From generative AI to large language models, Josh explores cutting-edge trends shaping financial services, real estate, and consumer goods. </p>
<p>Tune in for a masterclass in leveraging data for impact and innovation!</p>
<p>Â </p>
<p>Links</p>
<p><a href='https://blueorange.digital/'>https://blueorange.digital/</a></p>
<p><a href='https://blueorange.digital/blog/a-data-intelligence-platform-what-is-it/'>https://blueorange.digital/blog/a-data-intelligence-platform-what-is-it/</a></p>
<p><a href='https://blueorange.digital/blog/ai-makes-bi-tools-accessible-to-anyone/'>https://blueorange.digital/blog/ai-makes-bi-tools-accessible-to-anyone/</a></p>
<p>Â </p>
<p>Â </p>



]]></description>
                                                            <content:encoded><![CDATA[



<p>In this episode, we dive into the transformative world of AI, data analytics, and cloud infrastructure with Josh Miramant, CEO of Blue Orange Digital. As a seasoned entrepreneur with over $25 million raised across ventures and two successful exits, Josh shares invaluable insights on scaling data-driven businesses, integrating machine learning frameworks, and navigating the rapidly evolving landscape of cloud data architecture. From generative AI to large language models, Josh explores cutting-edge trends shaping financial services, real estate, and consumer goods. </p>
<p>Tune in for a masterclass in leveraging data for impact and innovation!</p>
<p>Â </p>
<p>Links</p>
<p><a href='https://blueorange.digital/'>https://blueorange.digital/</a></p>
<p><a href='https://blueorange.digital/blog/a-data-intelligence-platform-what-is-it/'>https://blueorange.digital/blog/a-data-intelligence-platform-what-is-it/</a></p>
<p><a href='https://blueorange.digital/blog/ai-makes-bi-tools-accessible-to-anyone/'>https://blueorange.digital/blog/ai-makes-bi-tools-accessible-to-anyone/</a></p>
<p>Â </p>
<p>Â </p>



]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gxjsgyhjx3imjmp8/Blue_Orange_Digital_podcastbpkz4.mp3" length="48471934" type="audio/mpeg"/>
        <itunes:summary><![CDATA[



In this episode, we dive into the transformative world of AI, data analytics, and cloud infrastructure with Josh Miramant, CEO of Blue Orange Digital. As a seasoned entrepreneur with over $25 million raised across ventures and two successful exits, Josh shares invaluable insights on scaling data-driven businesses, integrating machine learning frameworks, and navigating the rapidly evolving landscape of cloud data architecture. From generative AI to large language models, Josh explores cutting-edge trends shaping financial services, real estate, and consumer goods. 
Tune in for a masterclass in leveraging data for impact and innovation!
Â 
Links
https://blueorange.digital/
https://blueorange.digital/blog/a-data-intelligence-platform-what-is-it/
https://blueorange.digital/blog/ai-makes-bi-tools-accessible-to-anyone/
Â 
Â 



]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>48:55</itunes:duration>
                <itunes:episode>278</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Autonomous Weapons and AI Warfare (Ep. 275)</title>
        <itunes:title>Autonomous Weapons and AI Warfare (Ep. 275)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/autonomous-weapons-and-ai-warfare-ep-275/</link>
                    <comments>https://datascienceathome.podbean.com/e/autonomous-weapons-and-ai-warfare-ep-275/#comments</comments>        <pubDate>Mon, 16 Dec 2024 18:21:17 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/63c03b2c-2e3f-339a-928d-f6f71e21a9a3</guid>
                                    <description><![CDATA[<p>Hereâ€™s the updated text with links to the websites included:</p>

<p>AI is revolutionizing the military with autonomous drones, surveillance tech, and decision-making systems. But could these innovations spark the next global conflict? In this episode of Data Science at Home, we expose the cutting-edge tech reshaping defenseâ€”and the chilling ethical questions that follow. Donâ€™t miss this deep dive into the AI arms race!</p>
<p>ğŸ§ LISTEN / SUBSCRIBE TO THE PODCAST</p>
<ul>
<li><a href='https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378'>Apple Podcasts</a></li>
<li><a href='https://datascienceathome.podbean.com/'>Podbean Podcasts</a></li>
<li><a href='https://player.fm/series/data-science-at-home-2600992'>Player FM</a></li>
</ul>

<p>Chapters
00:00 - Intro
01:54 - Autonomous Vehicles
03:11 - Surveillance And Reconnaissance
04:15 - Predictive Analysis
05:57 - Decision Support System
08:24 - Real World Examples
10:42 - Ethical And Strategic Considerations
12:25 - International Regulation
13:21 - Conclusion
14:50 - Outro</p>

<p>âœ¨ Connect with us!</p>
<p>ğŸ¥Youtube: <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a>
ğŸ“© Newsletter: <a href='https://datascienceathome.substack.com/'>https://datascienceathome.substack.com</a>
ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.
ğŸ¦ Twitter: <a href='https://x.com/datascienceAH'>@DataScienceAtHome</a>
ğŸ“˜ LinkedIn: <a href='https://www.linkedin.com/in/fragadaleta/'>Francesco Gad</a>
ğŸ“· Instagram: <a href='https://www.instagram.com/datascienceathome/'>https://www.instagram.com/datascienceathome/</a>
ğŸ“˜ Facebook: <a href='https://www.facebook.com/datascienceAH'>https://www.facebook.com/datascienceAH</a>
ğŸ’¼ LinkedIn: <a href='https://www.linkedin.com/company/data-science-at-home-podcast'>https://www.linkedin.com/company/data-science-at-home-podcast</a>
ğŸ’¬ Discord Channel: <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>

<p>NEW TO DATA SCIENCE AT HOME?
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at <a href='https://datascienceathome.com/'>https://datascienceathome.com</a>.</p>

<p>ğŸ“« SEND US MAIL!
We love hearing from you! Send us mail at:
<a href='mailto:hello@datascienceathome.com'>hello@datascienceathome.com</a></p>
<p>Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>

<p>#DataScienceAtHome #ArtificialIntelligence #AI #MilitaryTechnology #AutonomousDrones #SurveillanceTech #AIArmsRace #DataScience #DefenseInnovation #EthicsInAI #GlobalConflict #PredictiveAnalysis #AIInWarfare #TechnologyAndEthics #AIRevolution #MachineLearning</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Hereâ€™s the updated text with links to the websites included:</p>

<p>AI is revolutionizing the military with autonomous drones, surveillance tech, and decision-making systems. But could these innovations spark the next global conflict? In this episode of Data Science at Home, we expose the cutting-edge tech reshaping defenseâ€”and the chilling ethical questions that follow. Donâ€™t miss this deep dive into the AI arms race!</p>
<p>ğŸ§ LISTEN / SUBSCRIBE TO THE PODCAST</p>
<ul>
<li><a href='https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378'>Apple Podcasts</a></li>
<li><a href='https://datascienceathome.podbean.com/'>Podbean Podcasts</a></li>
<li><a href='https://player.fm/series/data-science-at-home-2600992'>Player FM</a></li>
</ul>

<p>Chapters<br>
00:00 - Intro<br>
01:54 - Autonomous Vehicles<br>
03:11 - Surveillance And Reconnaissance<br>
04:15 - Predictive Analysis<br>
05:57 - Decision Support System<br>
08:24 - Real World Examples<br>
10:42 - Ethical And Strategic Considerations<br>
12:25 - International Regulation<br>
13:21 - Conclusion<br>
14:50 - Outro</p>

<p>âœ¨ Connect with us!</p>
<p>ğŸ¥Youtube: <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a><br>
ğŸ“© Newsletter: <a href='https://datascienceathome.substack.com/'>https://datascienceathome.substack.com</a><br>
ğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.<br>
ğŸ¦ Twitter: <a href='https://x.com/datascienceAH'>@DataScienceAtHome</a><br>
ğŸ“˜ LinkedIn: <a href='https://www.linkedin.com/in/fragadaleta/'>Francesco Gad</a><br>
ğŸ“· Instagram: <a href='https://www.instagram.com/datascienceathome/'>https://www.instagram.com/datascienceathome/</a><br>
ğŸ“˜ Facebook: <a href='https://www.facebook.com/datascienceAH'>https://www.facebook.com/datascienceAH</a><br>
ğŸ’¼ LinkedIn: <a href='https://www.linkedin.com/company/data-science-at-home-podcast'>https://www.linkedin.com/company/data-science-at-home-podcast</a><br>
ğŸ’¬ Discord Channel: <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>

<p>NEW TO DATA SCIENCE AT HOME?<br>
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at <a href='https://datascienceathome.com/'>https://datascienceathome.com</a>.</p>

<p>ğŸ“« SEND US MAIL!<br>
We love hearing from you! Send us mail at:<br>
<a href='mailto:hello@datascienceathome.com'>hello@datascienceathome.com</a></p>
<p>Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!</p>

<p>#DataScienceAtHome #ArtificialIntelligence #AI #MilitaryTechnology #AutonomousDrones #SurveillanceTech #AIArmsRace #DataScience #DefenseInnovation #EthicsInAI #GlobalConflict #PredictiveAnalysis #AIInWarfare #TechnologyAndEthics #AIRevolution #MachineLearning</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/h8y8fqxepwjvixn7/AI-Defense.mp3" length="42531525" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Hereâ€™s the updated text with links to the websites included:

AI is revolutionizing the military with autonomous drones, surveillance tech, and decision-making systems. But could these innovations spark the next global conflict? In this episode of Data Science at Home, we expose the cutting-edge tech reshaping defenseâ€”and the chilling ethical questions that follow. Donâ€™t miss this deep dive into the AI arms race!
ğŸ§ LISTEN / SUBSCRIBE TO THE PODCAST

Apple Podcasts
Podbean Podcasts
Player FM


Chapters00:00 - Intro01:54 - Autonomous Vehicles03:11 - Surveillance And Reconnaissance04:15 - Predictive Analysis05:57 - Decision Support System08:24 - Real World Examples10:42 - Ethical And Strategic Considerations12:25 - International Regulation13:21 - Conclusion14:50 - Outro

âœ¨ Connect with us!
ğŸ¥Youtube: https://www.youtube.com/@DataScienceatHomeğŸ“© Newsletter: https://datascienceathome.substack.comğŸ™ Podcast: Available on Spotify, Apple Podcasts, and more.ğŸ¦ Twitter: @DataScienceAtHomeğŸ“˜ LinkedIn: Francesco GadğŸ“· Instagram: https://www.instagram.com/datascienceathome/ğŸ“˜ Facebook: https://www.facebook.com/datascienceAHğŸ’¼ LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcastğŸ’¬ Discord Channel: https://discord.gg/4UNKGf3

NEW TO DATA SCIENCE AT HOME?Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com.

ğŸ“« SEND US MAIL!We love hearing from you! Send us mail at:hello@datascienceathome.com
Donâ€™t forget to like, subscribe, and hit the ğŸ”” for updates on the latest in AI and data science!

#DataScienceAtHome #ArtificialIntelligence #AI #MilitaryTechnology #AutonomousDrones #SurveillanceTech #AIArmsRace #DataScience #DefenseInnovation #EthicsInAI #GlobalConflict #PredictiveAnalysis #AIInWarfare #TechnologyAndEthics #AIRevolution #MachineLearning
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:43</itunes:duration>
                <itunes:episode>277</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>8 Proven Strategies to Scale Your AI Systems Like OpenAI! ğŸš€  (Ep. 274)</title>
        <itunes:title>8 Proven Strategies to Scale Your AI Systems Like OpenAI! ğŸš€  (Ep. 274)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/8-proven-strategies-to-scale-your-ai-systems-like-openai-%f0%9f%9a-ep-274/</link>
                    <comments>https://datascienceathome.podbean.com/e/8-proven-strategies-to-scale-your-ai-systems-like-openai-%f0%9f%9a-ep-274/#comments</comments>        <pubDate>Fri, 13 Dec 2024 10:25:23 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a08f41ab-0649-3480-b009-1858586026c1</guid>
                                    <description><![CDATA[<p>In this episode of Data Science at Home, weâ€™re diving deep into the powerful strategies that top AI companies, like OpenAI, use to scale their systems to handle millions of requests every minute! From stateless services and caching to the secrets of async processing, discover 8 essential strategies to make your AI and machine learning systems unstoppable. Whether you're working with traditional ML models or large LLMs, these techniques will transform your infrastructure. Hit play to learn how the pros do it and apply it to your own projects!</p>
<p>Â </p>
<p>LISTEN / SUBSCRIBE TO THE PODCAST</p>
<p>YouTube: <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Apple Podcasts: <a href='https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378'>https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378</a></p>
<p>Podbean Podcasts: <a href='https://datascienceathome.podbean.com/'>https://datascienceathome.podbean.com/</a></p>
<p>Player Fm: <a href='https://player.fm/series/data-science-at-home-2600992'>https://player.fm/series/data-science-at-home-2600992</a></p>
<p>Â </p>
<p>Chapters</p>
<p>00:00 Intro</p>
<p>00:34 Scalability Strategies</p>
<p>01:08 Stateless Services</p>
<p>02:47 Horizontal Scaling</p>
<p>04:51 Load Balancing</p>
<p>06:14 Auto Scaling</p>
<p>07:41 Caching</p>
<p>09:27 Database Replication</p>
<p>11:07 Database Sharding</p>
<p>12:54 Async Processing</p>
<p>14:50 Infographics</p>
<p>Â </p>
<p>RESOURCES &amp; LINKS</p>
<p>Data Science at home: <a href='https://datascienceathome.com'>https://datascienceathome.com</a></p>
<p>Amethix Technologies: <a href='https://amethix.com'>https://amethix.com</a></p>
<p>Â </p>
<p>CONNECT WITH US!</p>
<p>Instagram: <a href='https://www.instagram.com/datascienceathome/'>https://www.instagram.com/datascienceathome/</a></p>
<p>Twitter: <a href='https://x.com/datascienceAH'>@datascienceathome</a></p>
<p>Facebook: <a href='https://www.facebook.com/datascienceAH'>https://www.facebook.com/datascienceAH</a></p>
<p>LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p>Discord Channel: <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>
<p>

</p>
<p>NEW TO DATA SCIENCE AT HOME?</p>
<p>Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at <a href='https://datascienceathome.com'>https://datascienceathome.com</a></p>
<p>Â </p>
<p>SEND US MAIL!</p>
<p>We love hearing from you! Send us mail at:Â  hello@datascienceathome.com</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of Data Science at Home, weâ€™re diving deep into the powerful strategies that top AI companies, like OpenAI, use to scale their systems to handle millions of requests every minute! From stateless services and caching to the secrets of async processing, discover 8 essential strategies to make your AI and machine learning systems unstoppable. Whether you're working with traditional ML models or large LLMs, these techniques will transform your infrastructure. Hit play to learn how the pros do it and apply it to your own projects!</p>
<p>Â </p>
<p>LISTEN / SUBSCRIBE TO THE PODCAST</p>
<p>YouTube: <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Apple Podcasts: <a href='https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378'>https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378</a></p>
<p>Podbean Podcasts: <a href='https://datascienceathome.podbean.com/'>https://datascienceathome.podbean.com/</a></p>
<p>Player Fm: <a href='https://player.fm/series/data-science-at-home-2600992'>https://player.fm/series/data-science-at-home-2600992</a></p>
<p>Â </p>
<p>Chapters</p>
<p>00:00 Intro</p>
<p>00:34 Scalability Strategies</p>
<p>01:08 Stateless Services</p>
<p>02:47 Horizontal Scaling</p>
<p>04:51 Load Balancing</p>
<p>06:14 Auto Scaling</p>
<p>07:41 Caching</p>
<p>09:27 Database Replication</p>
<p>11:07 Database Sharding</p>
<p>12:54 Async Processing</p>
<p>14:50 Infographics</p>
<p>Â </p>
<p>RESOURCES &amp; LINKS</p>
<p>Data Science at home: <a href='https://datascienceathome.com'>https://datascienceathome.com</a></p>
<p>Amethix Technologies: <a href='https://amethix.com'>https://amethix.com</a></p>
<p>Â </p>
<p>CONNECT WITH US!</p>
<p>Instagram: <a href='https://www.instagram.com/datascienceathome/'>https://www.instagram.com/datascienceathome/</a></p>
<p>Twitter: <a href='https://x.com/datascienceAH'>@datascienceathome</a></p>
<p>Facebook: <a href='https://www.facebook.com/datascienceAH'>https://www.facebook.com/datascienceAH</a></p>
<p>LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast</p>
<p>Discord Channel: <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>
<p><br>
<br>
</p>
<p>NEW TO DATA SCIENCE AT HOME?</p>
<p>Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at <a href='https://datascienceathome.com'>https://datascienceathome.com</a></p>
<p>Â </p>
<p>SEND US MAIL!</p>
<p>We love hearing from you! Send us mail at:Â  hello@datascienceathome.com</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/admbppn6miqp8k3c/scaling-ml-ai-podcast.mp3" length="41760391" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of Data Science at Home, weâ€™re diving deep into the powerful strategies that top AI companies, like OpenAI, use to scale their systems to handle millions of requests every minute! From stateless services and caching to the secrets of async processing, discover 8 essential strategies to make your AI and machine learning systems unstoppable. Whether you're working with traditional ML models or large LLMs, these techniques will transform your infrastructure. Hit play to learn how the pros do it and apply it to your own projects!
Â 
LISTEN / SUBSCRIBE TO THE PODCAST
YouTube: https://www.youtube.com/@DataScienceatHome
Apple Podcasts: https://podcasts.apple.com/us/podcast/data-science-at-home/id1069871378
Podbean Podcasts: https://datascienceathome.podbean.com/
Player Fm: https://player.fm/series/data-science-at-home-2600992
Â 
Chapters
00:00 Intro
00:34 Scalability Strategies
01:08 Stateless Services
02:47 Horizontal Scaling
04:51 Load Balancing
06:14 Auto Scaling
07:41 Caching
09:27 Database Replication
11:07 Database Sharding
12:54 Async Processing
14:50 Infographics
Â 
RESOURCES &amp; LINKS
Data Science at home: https://datascienceathome.com
Amethix Technologies: https://amethix.com
Â 
CONNECT WITH US!
Instagram: https://www.instagram.com/datascienceathome/
Twitter: @datascienceathome
Facebook: https://www.facebook.com/datascienceAH
LinkedIn: https://www.linkedin.com/company/data-science-at-home-podcast
Discord Channel: https://discord.gg/4UNKGf3

NEW TO DATA SCIENCE AT HOME?
Welcome! Data Science at Home explores the latest in AI, data science, and machine learning. Whether youâ€™re a data professional, tech enthusiast, or just curious about the field, our podcast delivers insights, interviews, and discussions. Learn more at https://datascienceathome.com
Â 
SEND US MAIL!
We love hearing from you! Send us mail at:Â  hello@datascienceathome.com]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:23</itunes:duration>
                <itunes:episode>276</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Humans vs. Bots: Are You Talking to a Machine Right Now? (Ep. 273)</title>
        <itunes:title>Humans vs. Bots: Are You Talking to a Machine Right Now? (Ep. 273)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/humans-vs-bots-are-you-talking-to-a-machine-right-now-ep-273/</link>
                    <comments>https://datascienceathome.podbean.com/e/humans-vs-bots-are-you-talking-to-a-machine-right-now-ep-273/#comments</comments>        <pubDate>Mon, 25 Nov 2024 06:01:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0b29ab5b-bc56-3e9b-94fa-4f152f8ee6c1</guid>
                                    <description><![CDATA[<p>In this episode of Data Science at Home, host Francesco Gadaleta dives deep into the evolving world of AI-generated content detection with experts Souradip Chakraborty, Ph.D. grad student at the University of Maryland, and Amrit Singh Bedi, CS faculty at the University of Central Florida.Â </p>
<p>Together, they explore the growing importance of distinguishing human-written from AI-generated text, discussing real-world examples from social media to news. How reliable are current detection tools like DetectGPT? What are the ethical and technical challenges ahead as AI continues to advance? And is the balance between innovation and regulation tipping in the right direction?Â </p>
<p>Â </p>
<p>Tune in for insights on the future of AI text detection and the broader implications for media, academia, and policy.</p>
<p>Â </p>
<p>ChaptersÂ </p>
<p>Â </p>
<p>00:00 - IntroÂ </p>
<p>00:23 - Guests: Souradip Chakraborty and Amrit Singh BediÂ </p>
<p>01:25 - Distinguish Text Generation By AIÂ </p>
<p>04:33 - Research on Safety and Alignment of Generative ModelÂ </p>
<p>06:01 - Tools to Detect Generated AI TextÂ Â </p>
<p>11:28 - Water Marking</p>
<p>18:27 - Challenges in Detecting Large Documents Generated by AIÂ </p>
<p>23:34 - Number of TokensÂ </p>
<p>26:22 - Adversarial Attack</p>
<p>29:01 - True Positive and False Positive of DetectorsÂ </p>
<p>31:01 - Limit of TechnologiesÂ </p>
<p>41:01 - Future of AI Detection TechniquesÂ </p>
<p>46:04 - Closing Thought</p>
<p>Â </p>
<p>Subscribe to our new YouTube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of Data Science at Home, host Francesco Gadaleta dives deep into the evolving world of AI-generated content detection with experts Souradip Chakraborty, Ph.D. grad student at the University of Maryland, and Amrit Singh Bedi, CS faculty at the University of Central Florida.Â </p>
<p>Together, they explore the growing importance of distinguishing human-written from AI-generated text, discussing real-world examples from social media to news. How reliable are current detection tools like DetectGPT? What are the ethical and technical challenges ahead as AI continues to advance? And is the balance between innovation and regulation tipping in the right direction?Â </p>
<p>Â </p>
<p>Tune in for insights on the future of AI text detection and the broader implications for media, academia, and policy.</p>
<p>Â </p>
<p>ChaptersÂ </p>
<p>Â </p>
<p>00:00 - IntroÂ </p>
<p>00:23 - Guests: Souradip Chakraborty and Amrit Singh BediÂ </p>
<p>01:25 - Distinguish Text Generation By AIÂ </p>
<p>04:33 - Research on Safety and Alignment of Generative ModelÂ </p>
<p>06:01 - Tools to Detect Generated AI TextÂ Â </p>
<p>11:28 - Water Marking</p>
<p>18:27 - Challenges in Detecting Large Documents Generated by AIÂ </p>
<p>23:34 - Number of TokensÂ </p>
<p>26:22 - Adversarial Attack</p>
<p>29:01 - True Positive and False Positive of DetectorsÂ </p>
<p>31:01 - Limit of TechnologiesÂ </p>
<p>41:01 - Future of AI Detection TechniquesÂ </p>
<p>46:04 - Closing Thought</p>
<p>Â </p>
<p>Subscribe to our new YouTube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wt2aa8chqidu28bf/detecting-AI-podcast.mp3" length="46801491" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of Data Science at Home, host Francesco Gadaleta dives deep into the evolving world of AI-generated content detection with experts Souradip Chakraborty, Ph.D. grad student at the University of Maryland, and Amrit Singh Bedi, CS faculty at the University of Central Florida.Â 
Together, they explore the growing importance of distinguishing human-written from AI-generated text, discussing real-world examples from social media to news. How reliable are current detection tools like DetectGPT? What are the ethical and technical challenges ahead as AI continues to advance? And is the balance between innovation and regulation tipping in the right direction?Â 
Â 
Tune in for insights on the future of AI text detection and the broader implications for media, academia, and policy.
Â 
ChaptersÂ 
Â 
00:00 - IntroÂ 
00:23 - Guests: Souradip Chakraborty and Amrit Singh BediÂ 
01:25 - Distinguish Text Generation By AIÂ 
04:33 - Research on Safety and Alignment of Generative ModelÂ 
06:01 - Tools to Detect Generated AI TextÂ Â 
11:28 - Water Marking
18:27 - Challenges in Detecting Large Documents Generated by AIÂ 
23:34 - Number of TokensÂ 
26:22 - Adversarial Attack
29:01 - True Positive and False Positive of DetectorsÂ 
31:01 - Limit of TechnologiesÂ 
41:01 - Future of AI Detection TechniquesÂ 
46:04 - Closing Thought
Â 
Subscribe to our new YouTube channel https://www.youtube.com/@DataScienceatHome
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>49:33</itunes:duration>
                <itunes:episode>275</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI bubble, Sam Altmanâ€™s Manifesto and other fairy tales for billionaires (Ep. 272)</title>
        <itunes:title>AI bubble, Sam Altmanâ€™s Manifesto and other fairy tales for billionaires (Ep. 272)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-bubble-sam-altman-s-manifesto-and-other-fairy-tales-for-billionaires-ep-272/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-bubble-sam-altman-s-manifesto-and-other-fairy-tales-for-billionaires-ep-272/#comments</comments>        <pubDate>Wed, 20 Nov 2024 11:52:58 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d3cf0b56-ca93-38cb-a571-6b0ab7c2d51b</guid>
                                    <description><![CDATA[<p>Welcome to Data Science at Home, where we donâ€™t just drink the AI Kool-Aid. Today, weâ€™re dissecting Sam Altmanâ€™s â€œAI manifestoâ€â€”a magical journey where, apparently, AI will fix everything from climate change to your grandma's back pain. Superintelligence is â€œjust a few thousand days away,â€ right? Sure, Sam, and my catâ€™s about to become a calculus tutor.</p>
<p>Â </p>
<p>In this episode, Iâ€™ll break down the bold (and often bizarre) claims in Altmanâ€™s grand speech for the Intelligence Age. Iâ€™ll give you the real scoop on whatâ€™s realistic, whatâ€™s nonsense, and why some tech billionaires just canâ€™t resist overselling. Think AIâ€™s all-knowing, all-powerful future is just around the corner? Letâ€™s see if we can spot the fairy dust.</p>
<p>Â </p>
<p>Strap in, grab some popcorn, and get ready to see past the hype!</p>
<p>Â </p>
<p>Chapters</p>
<p>Â </p>
<p>00:00 - Intro</p>
<p>00:18 - CEO of Baidu Statement on AI Bubble</p>
<p>03:47 - News On Sam Altman Open AI</p>
<p>06:43 - Online Manifesto "The Intelleigent Age"</p>
<p>13:14 - Deep Learning</p>
<p>16:26 - AI gets Better With Scale</p>
<p>17:45 - Conclusion On Manifesto</p>
<p>Â </p>
<p>Still have popcorns?Â 
Get some laughs at <a href='https://ia.samaltman.com/'>https://ia.samaltman.com/</a>Â </p>
<p>Â </p>
<p>#AIRealTalk #NoHypeZone #InvestorBaitAlert</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Welcome to Data Science at Home, where we donâ€™t just drink the AI Kool-Aid. Today, weâ€™re dissecting Sam Altmanâ€™s â€œAI manifestoâ€â€”a magical journey where, apparently, AI will fix everything from climate change to your grandma's back pain. Superintelligence is â€œjust a few thousand days away,â€ right? Sure, Sam, and my catâ€™s about to become a calculus tutor.</p>
<p>Â </p>
<p>In this episode, Iâ€™ll break down the bold (and often bizarre) claims in Altmanâ€™s grand speech for the Intelligence Age. Iâ€™ll give you the real scoop on whatâ€™s realistic, whatâ€™s nonsense, and why some tech billionaires just canâ€™t resist overselling. Think AIâ€™s all-knowing, all-powerful future is just around the corner? Letâ€™s see if we can spot the fairy dust.</p>
<p>Â </p>
<p>Strap in, grab some popcorn, and get ready to see past the hype!</p>
<p>Â </p>
<p>Chapters</p>
<p>Â </p>
<p>00:00 - Intro</p>
<p>00:18 - CEO of Baidu Statement on AI Bubble</p>
<p>03:47 - News On Sam Altman Open AI</p>
<p>06:43 - Online Manifesto "The Intelleigent Age"</p>
<p>13:14 - Deep Learning</p>
<p>16:26 - AI gets Better With Scale</p>
<p>17:45 - Conclusion On Manifesto</p>
<p>Â </p>
<p>Still have popcorns?Â <br>
Get some laughs at <a href='https://ia.samaltman.com/'>https://ia.samaltman.com/</a>Â </p>
<p>Â </p>
<p>#AIRealTalk #NoHypeZone #InvestorBaitAlert</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gserni2uyeyd5wzs/AI-Bubble-Manifesto.mp3" length="45450970" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Welcome to Data Science at Home, where we donâ€™t just drink the AI Kool-Aid. Today, weâ€™re dissecting Sam Altmanâ€™s â€œAI manifestoâ€â€”a magical journey where, apparently, AI will fix everything from climate change to your grandma's back pain. Superintelligence is â€œjust a few thousand days away,â€ right? Sure, Sam, and my catâ€™s about to become a calculus tutor.
Â 
In this episode, Iâ€™ll break down the bold (and often bizarre) claims in Altmanâ€™s grand speech for the Intelligence Age. Iâ€™ll give you the real scoop on whatâ€™s realistic, whatâ€™s nonsense, and why some tech billionaires just canâ€™t resist overselling. Think AIâ€™s all-knowing, all-powerful future is just around the corner? Letâ€™s see if we can spot the fairy dust.
Â 
Strap in, grab some popcorn, and get ready to see past the hype!
Â 
Chapters
Â 
00:00 - Intro
00:18 - CEO of Baidu Statement on AI Bubble
03:47 - News On Sam Altman Open AI
06:43 - Online Manifesto "The Intelleigent Age"
13:14 - Deep Learning
16:26 - AI gets Better With Scale
17:45 - Conclusion On Manifesto
Â 
Still have popcorns?Â Get some laughs at https://ia.samaltman.com/Â 
Â 
#AIRealTalk #NoHypeZone #InvestorBaitAlert]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:56</itunes:duration>
                <itunes:episode>274</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI vs. The Planet: The Energy Crisis Behind the Chatbot Boom (Ep. 271)</title>
        <itunes:title>AI vs. The Planet: The Energy Crisis Behind the Chatbot Boom (Ep. 271)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-vs-the-planet-the-energy-crisis-behind-the-chatbot-boom-ep-271/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-vs-the-planet-the-energy-crisis-behind-the-chatbot-boom-ep-271/#comments</comments>        <pubDate>Wed, 13 Nov 2024 08:30:08 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7cbbd13c-b33f-357f-8449-f285cced05ba</guid>
                                    <description><![CDATA[<p>In this episode of Data Science at Home, we dive into the hidden costs of AIâ€™s rapid growth â€” specifically, its massive energy consumption. With tools like ChatGPT reaching 200 million weekly active users, the environmental impact of AI is becoming impossible to ignore. Each query, every training session, and every breakthrough come with a price in kilowatt-hours, raising questions about AIâ€™s sustainability.</p>
<p>Â </p>
<p>Join us, as we uncovers the staggering figures behind AI's energy demands and explores practical solutions for the future. From efficiency-focused algorithms and specialized hardware to decentralized learning, this episode examines how we can balance AIâ€™s advancements with our planet's limits. Discover what steps we can take to harness the power of AI responsibly!</p>
<p>Â </p>
<p>Check our new YouTube channel at <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>Chapters</p>
<p>00:00 - Intro</p>
<p>01:25 - Findings on Summary Statics</p>
<p>05:15 - Energy Required To Querry On GPT</p>
<p>07:20 - Energy Efficiency In BlockChain</p>
<p>10:41 - Efficicy Focused Algorithm</p>
<p>14:02 - Hardware Optimization</p>
<p>17:31 - Decentralized Learning</p>
<p>18:38 - Edge Computing with Local Inference</p>
<p>19:46 - Distributed Architectures</p>
<p>21:46 - Outro</p>
<p>Â </p>
<p>Â </p>
<p>#AIandEnergy #AIEnergyConsumption #SustainableAI #AIandEnvironment #DataScience #EfficientAI #DecentralizedLearning #GreenTech #EnergyEfficiency #MachineLearning #FutureOfAI #EcoFriendlyAI #FrancescoFrag #DataScienceAtHome #ResponsibleAI #EnvironmentalImpact</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of Data Science at Home, we dive into the hidden costs of AIâ€™s rapid growth â€” specifically, its massive energy consumption. With tools like ChatGPT reaching 200 million weekly active users, the environmental impact of AI is becoming impossible to ignore. Each query, every training session, and every breakthrough come with a price in kilowatt-hours, raising questions about AIâ€™s sustainability.</p>
<p>Â </p>
<p>Join us, as we uncovers the staggering figures behind AI's energy demands and explores practical solutions for the future. From efficiency-focused algorithms and specialized hardware to decentralized learning, this episode examines how we can balance AIâ€™s advancements with our planet's limits. Discover what steps we can take to harness the power of AI responsibly!</p>
<p>Â </p>
<p>Check our new YouTube channel at <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>Chapters</p>
<p>00:00 - Intro</p>
<p>01:25 - Findings on Summary Statics</p>
<p>05:15 - Energy Required To Querry On GPT</p>
<p>07:20 - Energy Efficiency In BlockChain</p>
<p>10:41 - Efficicy Focused Algorithm</p>
<p>14:02 - Hardware Optimization</p>
<p>17:31 - Decentralized Learning</p>
<p>18:38 - Edge Computing with Local Inference</p>
<p>19:46 - Distributed Architectures</p>
<p>21:46 - Outro</p>
<p>Â </p>
<p>Â </p>
<p>#AIandEnergy #AIEnergyConsumption #SustainableAI #AIandEnvironment #DataScience #EfficientAI #DecentralizedLearning #GreenTech #EnergyEfficiency #MachineLearning #FutureOfAI #EcoFriendlyAI #FrancescoFrag #DataScienceAtHome #ResponsibleAI #EnvironmentalImpact</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6vqyrfab625e4k2q/ai-energy.mp3" length="53952260" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of Data Science at Home, we dive into the hidden costs of AIâ€™s rapid growth â€” specifically, its massive energy consumption. With tools like ChatGPT reaching 200 million weekly active users, the environmental impact of AI is becoming impossible to ignore. Each query, every training session, and every breakthrough come with a price in kilowatt-hours, raising questions about AIâ€™s sustainability.
Â 
Join us, as we uncovers the staggering figures behind AI's energy demands and explores practical solutions for the future. From efficiency-focused algorithms and specialized hardware to decentralized learning, this episode examines how we can balance AIâ€™s advancements with our planet's limits. Discover what steps we can take to harness the power of AI responsibly!
Â 
Check our new YouTube channel at https://www.youtube.com/@DataScienceatHome
Â 
Chapters
00:00 - Intro
01:25 - Findings on Summary Statics
05:15 - Energy Required To Querry On GPT
07:20 - Energy Efficiency In BlockChain
10:41 - Efficicy Focused Algorithm
14:02 - Hardware Optimization
17:31 - Decentralized Learning
18:38 - Edge Computing with Local Inference
19:46 - Distributed Architectures
21:46 - Outro
Â 
Â 
#AIandEnergy #AIEnergyConsumption #SustainableAI #AIandEnvironment #DataScience #EfficientAI #DecentralizedLearning #GreenTech #EnergyEfficiency #MachineLearning #FutureOfAI #EcoFriendlyAI #FrancescoFrag #DataScienceAtHome #ResponsibleAI #EnvironmentalImpact]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:28</itunes:duration>
                <itunes:episode>273</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Love, Loss, and Algorithms: The Dangerous Realism of AI (Ep. 270)</title>
        <itunes:title>Love, Loss, and Algorithms: The Dangerous Realism of AI (Ep. 270)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/love-loss-and-algorithms-the-dangerous-realism-of-ai-ep-270/</link>
                    <comments>https://datascienceathome.podbean.com/e/love-loss-and-algorithms-the-dangerous-realism-of-ai-ep-270/#comments</comments>        <pubDate>Wed, 06 Nov 2024 14:03:05 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c559a26b-8936-33de-b37c-4ac9d94f9763</guid>
                                    <description><![CDATA[<p>Subscribe to our new channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>In this episode of Data Science at Home, we confront a tragic story highlighting the ethical and emotional complexities of AI technology. A U.S. teenager recently took his own life after developing a deep emotional attachment to an AI chatbot emulating a character from Game of Thrones. This devastating event has sparked urgent discussions on the mental health risks, ethical responsibilities, and potential regulations surrounding AI chatbots, especially as they become increasingly lifelike.</p>
<p>Â </p>
<p>ğŸ™ï¸ Topics Covered: </p>
<p>AI &amp; Emotional Attachment: How hyper-realistic AI chatbots can foster intense emotional bonds with users, especially vulnerable groups like adolescents.</p>
<p>Mental Health Risks: The potential for AI to unintentionally contribute to mental health issues, and the challenges of diagnosing such impacts. Ethical &amp; Legal Accountability: How companies like Character AI are being held accountable and the ethical questions raised by emotionally persuasive AI.</p>
<p>Â </p>
<p>ğŸš¨ Analogies Explored: </p>
<p>From VR to CGI and deepfakes, we discuss how hyper-realism in AI parallels other immersive technologies and why its emotional impact can be particularly disorienting and even harmful.</p>
<p>Â </p>
<p>ğŸ› ï¸ Possible Mitigations: </p>
<p>We cover potential solutions like age verification, content monitoring, transparency in AI design, and ethical audits that could mitigate some of the risks involved with hyper-realistic AI interactions. ğŸ‘€ Key Takeaways: As AI becomes more realistic, it brings both immense potential and serious responsibility. Join us as we dive into the ethical landscape of AIâ€”analyzing how we can ensure this technology enriches human lives without crossing lines that could harm us emotionally and psychologically. Stay curious, stay critical, and make sure to subscribe for more no-nonsense tech talk!</p>
<p>Â </p>
<p>Chapters </p>
<p>00:00 - Intro</p>
<p>02:21 - Emotions In Artificial Intelligence</p>
<p>04:00 - Unregulated Influence and Misleading Interaction</p>
<p>06:32 - Overwhelming Realism In AI</p>
<p>10:54 - Virtual Reality</p>
<p>13:25 - Hyper-Realistic CGI Movies</p>
<p>15:38 - Deep Fake Technology</p>
<p>18:11 - Regulations To Mitigate AI Risks</p>
<p>22:50 - Conclusion</p>
<p>Â </p>
<p>#AI#ArtificialIntelligence#MentalHealth#AIEthics#podcast#AIRegulation#EmotionalAI#HyperRealisticAI#TechTalk#AIChatbots#Deepfakes#VirtualReality#TechEthics#DataScience#AIDiscussion #StayCuriousStayCritical</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Subscribe to our new channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>In this episode of Data Science at Home, we confront a tragic story highlighting the ethical and emotional complexities of AI technology. A U.S. teenager recently took his own life after developing a deep emotional attachment to an AI chatbot emulating a character from Game of Thrones. This devastating event has sparked urgent discussions on the mental health risks, ethical responsibilities, and potential regulations surrounding AI chatbots, especially as they become increasingly lifelike.</p>
<p>Â </p>
<p>ğŸ™ï¸ Topics Covered: </p>
<p>AI &amp; Emotional Attachment: How hyper-realistic AI chatbots can foster intense emotional bonds with users, especially vulnerable groups like adolescents.</p>
<p>Mental Health Risks: The potential for AI to unintentionally contribute to mental health issues, and the challenges of diagnosing such impacts. Ethical &amp; Legal Accountability: How companies like Character AI are being held accountable and the ethical questions raised by emotionally persuasive AI.</p>
<p>Â </p>
<p>ğŸš¨ Analogies Explored: </p>
<p>From VR to CGI and deepfakes, we discuss how hyper-realism in AI parallels other immersive technologies and why its emotional impact can be particularly disorienting and even harmful.</p>
<p>Â </p>
<p>ğŸ› ï¸ Possible Mitigations: </p>
<p>We cover potential solutions like age verification, content monitoring, transparency in AI design, and ethical audits that could mitigate some of the risks involved with hyper-realistic AI interactions. ğŸ‘€ Key Takeaways: As AI becomes more realistic, it brings both immense potential and serious responsibility. Join us as we dive into the ethical landscape of AIâ€”analyzing how we can ensure this technology enriches human lives without crossing lines that could harm us emotionally and psychologically. Stay curious, stay critical, and make sure to subscribe for more no-nonsense tech talk!</p>
<p>Â </p>
<p>Chapters </p>
<p>00:00 - Intro</p>
<p>02:21 - Emotions In Artificial Intelligence</p>
<p>04:00 - Unregulated Influence and Misleading Interaction</p>
<p>06:32 - Overwhelming Realism In AI</p>
<p>10:54 - Virtual Reality</p>
<p>13:25 - Hyper-Realistic CGI Movies</p>
<p>15:38 - Deep Fake Technology</p>
<p>18:11 - Regulations To Mitigate AI Risks</p>
<p>22:50 - Conclusion</p>
<p>Â </p>
<p>#AI#ArtificialIntelligence#MentalHealth#AIEthics#podcast#AIRegulation#EmotionalAI#HyperRealisticAI#TechTalk#AIChatbots#Deepfakes#VirtualReality#TechEthics#DataScience#AIDiscussion #StayCuriousStayCritical</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6b5hvuzfrr3cpqvj/love-loss-algorithms.mp3" length="46894183" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Subscribe to our new channel https://www.youtube.com/@DataScienceatHome
Â 
In this episode of Data Science at Home, we confront a tragic story highlighting the ethical and emotional complexities of AI technology. A U.S. teenager recently took his own life after developing a deep emotional attachment to an AI chatbot emulating a character from Game of Thrones. This devastating event has sparked urgent discussions on the mental health risks, ethical responsibilities, and potential regulations surrounding AI chatbots, especially as they become increasingly lifelike.
Â 
ğŸ™ï¸ Topics Covered: 
AI &amp; Emotional Attachment: How hyper-realistic AI chatbots can foster intense emotional bonds with users, especially vulnerable groups like adolescents.
Mental Health Risks: The potential for AI to unintentionally contribute to mental health issues, and the challenges of diagnosing such impacts. Ethical &amp; Legal Accountability: How companies like Character AI are being held accountable and the ethical questions raised by emotionally persuasive AI.
Â 
ğŸš¨ Analogies Explored: 
From VR to CGI and deepfakes, we discuss how hyper-realism in AI parallels other immersive technologies and why its emotional impact can be particularly disorienting and even harmful.
Â 
ğŸ› ï¸ Possible Mitigations: 
We cover potential solutions like age verification, content monitoring, transparency in AI design, and ethical audits that could mitigate some of the risks involved with hyper-realistic AI interactions. ğŸ‘€ Key Takeaways: As AI becomes more realistic, it brings both immense potential and serious responsibility. Join us as we dive into the ethical landscape of AIâ€”analyzing how we can ensure this technology enriches human lives without crossing lines that could harm us emotionally and psychologically. Stay curious, stay critical, and make sure to subscribe for more no-nonsense tech talk!
Â 
Chapters 
00:00 - Intro
02:21 - Emotions In Artificial Intelligence
04:00 - Unregulated Influence and Misleading Interaction
06:32 - Overwhelming Realism In AI
10:54 - Virtual Reality
13:25 - Hyper-Realistic CGI Movies
15:38 - Deep Fake Technology
18:11 - Regulations To Mitigate AI Risks
22:50 - Conclusion
Â 
#AI#ArtificialIntelligence#MentalHealth#AIEthics#podcast#AIRegulation#EmotionalAI#HyperRealisticAI#TechTalk#AIChatbots#Deepfakes#VirtualReality#TechEthics#DataScience#AIDiscussion #StayCuriousStayCritical]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:25</itunes:duration>
                <itunes:episode>272</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>VC Advice Exposed: When Investors Donâ€™t Know What They Want (Ep. 269)</title>
        <itunes:title>VC Advice Exposed: When Investors Donâ€™t Know What They Want (Ep. 269)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/vc-advice-exposed-when-investors-don-t-know-what-they-want-ep-269/</link>
                    <comments>https://datascienceathome.podbean.com/e/vc-advice-exposed-when-investors-don-t-know-what-they-want-ep-269/#comments</comments>        <pubDate>Mon, 28 Oct 2024 07:39:12 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d152064a-4cf5-3d02-8508-b78dc4bd6619</guid>
                                    <description><![CDATA[<p>Ever feel like VC advice is all over the place? Thatâ€™s because it is. In this episode, I expose the madness behind the money and how to navigate their confusing advice!</p>
<p>Â </p>
<p>Watch the video at <a href='https://youtu.be/IBrPFyRMG1Q'>https://youtu.be/IBrPFyRMG1Q</a></p>
<p>Subscribe to our new Youtube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a>Â </p>
<p>Â </p>
<p>Â </p>
<p>00:00 - Introduction</p>
<p>00:16 - The Wild World of VC Advice</p>
<p>02:01 - Grow Fast vs. Grow Slow</p>
<p>05:00 - Listen to Customers or Innovate Ahead</p>
<p>09:51 - Raise Big or Stay Lean?</p>
<p>11:32 - Sell Your Vision in Minutes?</p>
<p>14:20 - The Real VC Secret: Focus on Your Team and Vision</p>
<p>17:03 - Outro</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Ever feel like VC advice is all over the place? Thatâ€™s because it is. In this episode, I expose the madness behind the money and how to navigate their confusing advice!</p>
<p>Â </p>
<p>Watch the video at <a href='https://youtu.be/IBrPFyRMG1Q'>https://youtu.be/IBrPFyRMG1Q</a></p>
<p>Subscribe to our new Youtube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a>Â </p>
<p>Â </p>
<p>Â </p>
<p>00:00 - Introduction</p>
<p>00:16 - The Wild World of VC Advice</p>
<p>02:01 - Grow Fast vs. Grow Slow</p>
<p>05:00 - Listen to Customers or Innovate Ahead</p>
<p>09:51 - Raise Big or Stay Lean?</p>
<p>11:32 - Sell Your Vision in Minutes?</p>
<p>14:20 - The Real VC Secret: Focus on Your Team and Vision</p>
<p>17:03 - Outro</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xr8nfuhbnp33ktew/vc-nonsense.mp3" length="43105174" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Ever feel like VC advice is all over the place? Thatâ€™s because it is. In this episode, I expose the madness behind the money and how to navigate their confusing advice!
Â 
Watch the video at https://youtu.be/IBrPFyRMG1Q
Subscribe to our new Youtube channel https://www.youtube.com/@DataScienceatHomeÂ 
Â 
Â 
00:00 - Introduction
00:16 - The Wild World of VC Advice
02:01 - Grow Fast vs. Grow Slow
05:00 - Listen to Customers or Innovate Ahead
09:51 - Raise Big or Stay Lean?
11:32 - Sell Your Vision in Minutes?
14:20 - The Real VC Secret: Focus on Your Team and Vision
17:03 - Outro]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:57</itunes:duration>
                <itunes:episode>271</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI Says It Can Compress Better Than FLAC?! Hold My Entropy ğŸ¿ (Ep. 268)</title>
        <itunes:title>AI Says It Can Compress Better Than FLAC?! Hold My Entropy ğŸ¿ (Ep. 268)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-says-it-can-compress-better-than-flac-hold-my-entropy-%f0%9f%8d-ep-268/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-says-it-can-compress-better-than-flac-hold-my-entropy-%f0%9f%8d-ep-268/#comments</comments>        <pubDate>Mon, 21 Oct 2024 15:31:47 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/60ae4071-7ef4-32ca-9310-4bd077d919b9</guid>
                                    <description><![CDATA[<p>Can AI really out-compress PNG and FLAC? ğŸ¤” Or is it just another overhyped tech myth? In this episode of Data Science at Home, Frag dives deep into the wild claims that Large Language Models (LLMs) like Chinchilla 70B are beating traditional lossless compression algorithms. ğŸ§ ğŸ’¥</p>
<p>But before you toss out your FLAC collection, let's break down Shannon's Source Coding Theorem and why entropy sets the ultimate limit on lossless compression.</p>
<p>We explore: âš™ï¸ How LLMs leverage probabilistic patterns for compression ğŸ“‰ Why compression efficiency doesnâ€™t equal general intelligence ğŸš€ The practical (and ridiculous) challenges of using AI for compression ğŸ’¡ Can AI actually BREAK Shannonâ€™s limitâ€”or is it just an illusion? </p>
<p>If you love AI, algorithms, or just enjoy some good old myth-busting, this oneâ€™s for you. Don't forget to hit subscribe for more no-nonsense takes on AI, and join the conversation on Discord!</p>
<p>Letâ€™s decode the truth together. 
Join the discussion on the new Discord channel of the podcast <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>
<p>Â </p>
<p>Don't forget to subscribe to our new YouTube channelÂ </p>
<p><a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>Â </p>
<p>References </p>
<p>Have you met Shannon? <a href='https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/'>https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/ </a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Can AI really out-compress PNG and FLAC? ğŸ¤” Or is it just another overhyped tech myth? In this episode of Data Science at Home, Frag dives deep into the wild claims that Large Language Models (LLMs) like Chinchilla 70B are beating traditional lossless compression algorithms. ğŸ§ ğŸ’¥</p>
<p>But before you toss out your FLAC collection, let's break down Shannon's Source Coding Theorem and why entropy sets the ultimate limit on lossless compression.</p>
<p>We explore: âš™ï¸ How LLMs leverage probabilistic patterns for compression ğŸ“‰ Why compression efficiency doesnâ€™t equal general intelligence ğŸš€ The practical (and ridiculous) challenges of using AI for compression ğŸ’¡ Can AI actually BREAK Shannonâ€™s limitâ€”or is it just an illusion? </p>
<p>If you love AI, algorithms, or just enjoy some good old myth-busting, this oneâ€™s for you. Don't forget to hit subscribe for more no-nonsense takes on AI, and join the conversation on Discord!</p>
<p>Letâ€™s decode the truth together. <br>
Join the discussion on the new Discord channel of the podcast <a href='https://discord.gg/4UNKGf3'>https://discord.gg/4UNKGf3</a></p>
<p>Â </p>
<p>Don't forget to subscribe to our new YouTube channelÂ </p>
<p><a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a></p>
<p>Â </p>
<p>Â </p>
<p>References </p>
<p>Have you met Shannon? <a href='https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/'>https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/ </a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tixcsybsexbnbeqk/ai-compression.mp3" length="40503587" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Can AI really out-compress PNG and FLAC? ğŸ¤” Or is it just another overhyped tech myth? In this episode of Data Science at Home, Frag dives deep into the wild claims that Large Language Models (LLMs) like Chinchilla 70B are beating traditional lossless compression algorithms. ğŸ§ ğŸ’¥
But before you toss out your FLAC collection, let's break down Shannon's Source Coding Theorem and why entropy sets the ultimate limit on lossless compression.
We explore: âš™ï¸ How LLMs leverage probabilistic patterns for compression ğŸ“‰ Why compression efficiency doesnâ€™t equal general intelligence ğŸš€ The practical (and ridiculous) challenges of using AI for compression ğŸ’¡ Can AI actually BREAK Shannonâ€™s limitâ€”or is it just an illusion? 
If you love AI, algorithms, or just enjoy some good old myth-busting, this oneâ€™s for you. Don't forget to hit subscribe for more no-nonsense takes on AI, and join the conversation on Discord!
Letâ€™s decode the truth together. Join the discussion on the new Discord channel of the podcast https://discord.gg/4UNKGf3
Â 
Don't forget to subscribe to our new YouTube channelÂ 
https://www.youtube.com/@DataScienceatHome
Â 
Â 
References 
Have you met Shannon? https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/ 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:05</itunes:duration>
                <itunes:episode>270</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What Big Tech Isnâ€™t Telling You About AI (Ep. 267)</title>
        <itunes:title>What Big Tech Isnâ€™t Telling You About AI (Ep. 267)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-big-tech-isn-t-telling-you-about-ai-ep-267/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-big-tech-isn-t-telling-you-about-ai-ep-267/#comments</comments>        <pubDate>Sat, 12 Oct 2024 05:00:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/27558d96-400a-39b8-8f13-e423734c3cbf</guid>
                                    <description><![CDATA[<p>Are AI giants really building trustworthy systems? A groundbreaking transparency report by Stanford, MIT, and Princeton says no. In this episode, we expose the shocking lack of transparency in AI development and how it impacts bias, safety, and trust in the technology. Weâ€™ll break down Gary Marcusâ€™s demands for more openness and what consumers should know about the AI products shaping their lives.</p>
<p>Â </p>
<p>Check our new YouTube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a> and Subscribe!Â </p>
<p>Â </p>
<p>Cool links</p>
<ol><li><a href='https://mitpress.mit.edu/9780262551069/taming-silicon-valley/'>https://mitpress.mit.edu/9780262551069/taming-silicon-valley/</a></li>
<li><a href='http://garymarcus.com/index.html'>http://garymarcus.com/index.html</a></li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>Are AI giants really building trustworthy systems? A groundbreaking transparency report by Stanford, MIT, and Princeton says no. In this episode, we expose the shocking lack of transparency in AI development and how it impacts bias, safety, and trust in the technology. Weâ€™ll break down Gary Marcusâ€™s demands for more openness and what consumers should know about the AI products shaping their lives.</p>
<p>Â </p>
<p>Check our new YouTube channel <a href='https://www.youtube.com/@DataScienceatHome'>https://www.youtube.com/@DataScienceatHome</a> and Subscribe!Â </p>
<p>Â </p>
<p>Cool links</p>
<ol><li><a href='https://mitpress.mit.edu/9780262551069/taming-silicon-valley/'>https://mitpress.mit.edu/9780262551069/taming-silicon-valley/</a></li>
<li><a href='http://garymarcus.com/index.html'>http://garymarcus.com/index.html</a></li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/npqqipcbthup2qqm/ai-transparency.mp3" length="36979355" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Are AI giants really building trustworthy systems? A groundbreaking transparency report by Stanford, MIT, and Princeton says no. In this episode, we expose the shocking lack of transparency in AI development and how it impacts bias, safety, and trust in the technology. Weâ€™ll break down Gary Marcusâ€™s demands for more openness and what consumers should know about the AI products shaping their lives.
Â 
Check our new YouTube channel https://www.youtube.com/@DataScienceatHome and Subscribe!Â 
Â 
Cool links
https://mitpress.mit.edu/9780262551069/taming-silicon-valley/
http://garymarcus.com/index.html
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:15</itunes:duration>
                <itunes:episode>269</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner [RB] (Ep. 266)</title>
        <itunes:title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner [RB] (Ep. 266)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-rb-ep-266/</link>
                    <comments>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-rb-ep-266/#comments</comments>        <pubDate>Tue, 08 Oct 2024 07:54:23 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/fcab93ca-a26a-3ce2-a825-bcfcfc6ce8b9</guid>
                                    <description><![CDATA[<p>We're revisiting one of our most popular episodes from last year, where renowned financial expert Chris Skinner explores the future of money. In this fascinating discussion, Skinner dives deep into cryptocurrencies, digital currencies, AI, and even the metaverse. He touches on government regulations, the role of tech in finance, and what these innovations mean for humanity.</p>
<p>Now, one year later, we encourage you to listen again and reflectâ€”how much has changed? Are Chris Skinner's predictions still holding up, or has the financial landscape evolved in unexpected ways? Tune in and find out!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>We're revisiting one of our most popular episodes from last year, where renowned financial expert Chris Skinner explores the future of money. In this fascinating discussion, Skinner dives deep into cryptocurrencies, digital currencies, AI, and even the metaverse. He touches on government regulations, the role of tech in finance, and what these innovations mean for humanity.</p>
<p>Now, one year later, we encourage you to listen again and reflectâ€”how much has changed? Are Chris Skinner's predictions still holding up, or has the financial landscape evolved in unexpected ways? Tune in and find out!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ix9vfu/ai-crypto-future-finance.mp3" length="53324649" type="audio/mpeg"/>
        <itunes:summary><![CDATA[We're revisiting one of our most popular episodes from last year, where renowned financial expert Chris Skinner explores the future of money. In this fascinating discussion, Skinner dives deep into cryptocurrencies, digital currencies, AI, and even the metaverse. He touches on government regulations, the role of tech in finance, and what these innovations mean for humanity.
Now, one year later, we encourage you to listen again and reflectâ€”how much has changed? Are Chris Skinner's predictions still holding up, or has the financial landscape evolved in unexpected ways? Tune in and find out!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>41:21</itunes:duration>
                <itunes:episode>268</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Kaggle Kommandoâ€™s Data Disco: Laughing our Way Through AI Trends (Ep. 265) [RB]</title>
        <itunes:title>Kaggle Kommandoâ€™s Data Disco: Laughing our Way Through AI Trends (Ep. 265) [RB]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/kaggle-kommando-s-data-disco-laughing-our-way-through-ai-trends-ep-265-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/kaggle-kommando-s-data-disco-laughing-our-way-through-ai-trends-ep-265-rb/#comments</comments>        <pubDate>Tue, 01 Oct 2024 11:25:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b7796286-dd62-3e5a-9afc-665e5dc8ba4f</guid>
                                    <description><![CDATA[
<p>In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
<p>Â </p>
<p>ğŸ”— Links Mentioned in the Episode:</p>
<ol><li>Generative AI for time series: TimeGPT <a href='https://docs.nixtla.io/docs/timegpt_quickstart'>Documentation</a></li>
<li>Lag-llama: <a href='https://github.com/time-series-foundation-models/lag-llama'>GitHub</a> (Note: The benchmark results on this one are pretty horrible)</li>
<li>Open source LLM: Olmo <a href='https://blog.allenai.org/olmo-open-language-model-87ccfc95f580'>Blog Post</a></li>
<li>Quantization for LLM: <a href='https://huggingface.co/docs/optimum/concept_guides/quantization'>Hugging Face Guide</a></li>
</ol><p>And finally, don't miss Konrad's <a href='https://konradb.substack.com/'>Substack</a> for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)</p>
]]></description>
                                                            <content:encoded><![CDATA[
<p>In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
<p>Â </p>
<p>ğŸ”— Links Mentioned in the Episode:</p>
<ol><li>Generative AI for time series: TimeGPT <a href='https://docs.nixtla.io/docs/timegpt_quickstart'>Documentation</a></li>
<li>Lag-llama: <a href='https://github.com/time-series-foundation-models/lag-llama'>GitHub</a> (Note: The benchmark results on this one are pretty horrible)</li>
<li>Open source LLM: Olmo <a href='https://blog.allenai.org/olmo-open-language-model-87ccfc95f580'>Blog Post</a></li>
<li>Quantization for LLM: <a href='https://huggingface.co/docs/optimum/concept_guides/quantization'>Hugging Face Guide</a></li>
</ol><p>And finally, don't miss Konrad's <a href='https://konradb.substack.com/'>Substack</a> for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/px724w/kaggle-kommando-data-disco.mp3" length="82133158" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!
Â 
Sponsors
Intrepid AI is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Â 
ğŸ”— Links Mentioned in the Episode:
Generative AI for time series: TimeGPT Documentation
Lag-llama: GitHub (Note: The benchmark results on this one are pretty horrible)
Open source LLM: Olmo Blog Post
Quantization for LLM: Hugging Face Guide
And finally, don't miss Konrad's Substack for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>42:46</itunes:duration>
                <itunes:episode>267</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI and Video Game Development: Navigating the Future Frontier (Ep. 264) [RB]</title>
        <itunes:title>AI and Video Game Development: Navigating the Future Frontier (Ep. 264) [RB]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-and-video-game-development-navigating-the-future-frontier-ep-264-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-and-video-game-development-navigating-the-future-frontier-ep-264-rb/#comments</comments>        <pubDate>Mon, 30 Sep 2024 11:12:50 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d664a4fe-9323-3300-b479-9979fc5fcff3</guid>
                                    <description><![CDATA[<p>In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). 
Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. 
With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. </p>
<p>From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://mikeyoung44.itch.io/spacefreighter'>https://mikeyoung44.itch.io/spacefreighter</a> - Itch.io link to play the game</li>
<li style="font-weight:400;"><a href='https://discord.gg/yaXgYZ5Ymn'>https://discord.gg/yaXgYZ5Ymn</a> - Discord server for the game</li>
<li style="font-weight:400;"><a href='https://aimodels.substack.com/'>https://aimodels.substack.com/</a> - Mikeâ€™s newsletter (links to website too)</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). <br>
Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. <br>
With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. </p>
<p>From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://mikeyoung44.itch.io/spacefreighter'>https://mikeyoung44.itch.io/spacefreighter</a> - Itch.io link to play the game</li>
<li style="font-weight:400;"><a href='https://discord.gg/yaXgYZ5Ymn'>https://discord.gg/yaXgYZ5Ymn</a> - Discord server for the game</li>
<li style="font-weight:400;"><a href='https://aimodels.substack.com/'>https://aimodels.substack.com/</a> - Mikeâ€™s newsletter (links to website too)</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6gu8h2/ai-and-videogames.mp3" length="46017305" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. 
From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!
Â 
Sponsors
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
Â 
References
https://mikeyoung44.itch.io/spacefreighter - Itch.io link to play the game
https://discord.gg/yaXgYZ5Ymn - Discord server for the game
https://aimodels.substack.com/ - Mikeâ€™s newsletter (links to website too)
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>47:56</itunes:duration>
                <itunes:episode>266</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>LLMs: Totally Not Making Stuff Up (they promise) (Ep. 263)</title>
        <itunes:title>LLMs: Totally Not Making Stuff Up (they promise) (Ep. 263)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/can-we-have-generalisation-without-hallucination/</link>
                    <comments>https://datascienceathome.podbean.com/e/can-we-have-generalisation-without-hallucination/#comments</comments>        <pubDate>Wed, 25 Sep 2024 18:40:15 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b7350c3d-e232-324b-8e5f-354d3db36c73</guid>
                                    <description><![CDATA[<p>In this episode, we dive into the wild world of Large Language Models (LLMs) and their knack forâ€¦ making things up. Can they really generalize without throwing in some fictional facts? Or is hallucination just part of their charm? 
Letâ€™s separate the genius from the guesswork in this insightful breakdown of AIâ€™s creativity problem.</p>
<p>TL;DR;</p>
<p>LLM Generalisation without hallucinations. Is that possible?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.lamini.ai/blog/lamini-memory-tuning'>https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf</a></p>
<p><a href='https://www.lamini.ai/blog/lamini-memory-tuning'>https://www.lamini.ai/blog/lamini-memory-tuning</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, we dive into the wild world of Large Language Models (LLMs) and their knack forâ€¦ making things up. Can they really generalize without throwing in some fictional facts? Or is hallucination just part of their charm? <br>
Letâ€™s separate the genius from the guesswork in this insightful breakdown of AIâ€™s creativity problem.</p>
<p>TL;DR;</p>
<p>LLM Generalisation without hallucinations. Is that possible?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.lamini.ai/blog/lamini-memory-tuning'>https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf</a></p>
<p><a href='https://www.lamini.ai/blog/lamini-memory-tuning'>https://www.lamini.ai/blog/lamini-memory-tuning</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/f6pztqbcus9mi939/zero-hallucinations-llm.mp3" length="53971904" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, we dive into the wild world of Large Language Models (LLMs) and their knack forâ€¦ making things up. Can they really generalize without throwing in some fictional facts? Or is hallucination just part of their charm? Letâ€™s separate the genius from the guesswork in this insightful breakdown of AIâ€™s creativity problem.
TL;DR;
LLM Generalisation without hallucinations. Is that possible?
Â 
References
https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf
https://www.lamini.ai/blog/lamini-memory-tuning
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:06</itunes:duration>
                <itunes:episode>261</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI: The Bubble That Might Popâ€”Whatâ€™s Next? (Ep. 262)</title>
        <itunes:title>AI: The Bubble That Might Popâ€”Whatâ€™s Next? (Ep. 262)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-the-bubble-that-might-pop%e2%80%94what-s-next-ep-262/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-the-bubble-that-might-pop%e2%80%94what-s-next-ep-262/#comments</comments>        <pubDate>Mon, 02 Sep 2024 13:23:57 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/33faa492-b277-3711-83b2-8bfeefb875c6</guid>
                                    <description><![CDATA[<p>The hype around Generative AI is real, but is the bubble about to burst? 
Join me as we dissect the recent downturn in AI investments and what it means for the tech giants like OpenAI and Nvidia. 
Could this be the end of the AI gold rush, or just a bump in the road? </p>
<p>Â </p>
<p>References</p>
<ul><li><a href='http://garymarcus.com/index.html'>http://garymarcus.com/index.html</a></li>
<li><a href='https://garymarcus.substack.com/p/why-the-collapse-of-the-generative?r=8tdk6&amp;utm_source=substack&amp;utm_medium=email'>https://garymarcus.substack.com/p/why-the-collapse-of-the-generative?r=8tdk6&amp;utm_source=substack&amp;utm_medium=email</a></li>
<li><a href='https://www.theinformation.com/articles/openai-makes-a-60-million-hardware-startup-bet?utm_source=substack&amp;utm_medium=email'>https://www.theinformation.com/articles/openai-makes-a-60-million-hardware-startup-bet?utm_source=substack&amp;utm_medium=email</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>The hype around Generative AI is real, but is the bubble about to burst? <br>
Join me as we dissect the recent downturn in AI investments and what it means for the tech giants like OpenAI and Nvidia. <br>
Could this be the end of the AI gold rush, or just a bump in the road? </p>
<p>Â </p>
<p>References</p>
<ul><li><a href='http://garymarcus.com/index.html'>http://garymarcus.com/index.html</a></li>
<li><a href='https://garymarcus.substack.com/p/why-the-collapse-of-the-generative?r=8tdk6&amp;utm_source=substack&amp;utm_medium=email'>https://garymarcus.substack.com/p/why-the-collapse-of-the-generative?r=8tdk6&amp;utm_source=substack&amp;utm_medium=email</a></li>
<li><a href='https://www.theinformation.com/articles/openai-makes-a-60-million-hardware-startup-bet?utm_source=substack&amp;utm_medium=email'>https://www.theinformation.com/articles/openai-makes-a-60-million-hardware-startup-bet?utm_source=substack&amp;utm_medium=email</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/aiud7qk4z3vsrhcp/generative-ai-slowdown.mp3" length="34184555" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The hype around Generative AI is real, but is the bubble about to burst? Join me as we dissect the recent downturn in AI investments and what it means for the tech giants like OpenAI and Nvidia. Could this be the end of the AI gold rush, or just a bump in the road? 
Â 
References
http://garymarcus.com/index.html
https://garymarcus.substack.com/p/why-the-collapse-of-the-generative?r=8tdk6&amp;utm_source=substack&amp;utm_medium=email
https://www.theinformation.com/articles/openai-makes-a-60-million-hardware-startup-bet?utm_source=substack&amp;utm_medium=email
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:04</itunes:duration>
                <itunes:episode>265</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Data Guardians: How Enterprises Can Master Privacy with MetaRouter (Ep. 261)</title>
        <itunes:title>Data Guardians: How Enterprises Can Master Privacy with MetaRouter (Ep. 261)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/data-guardians-how-enterprises-can-master-privacy-with-metarouter-ep-261/</link>
                    <comments>https://datascienceathome.podbean.com/e/data-guardians-how-enterprises-can-master-privacy-with-metarouter-ep-261/#comments</comments>        <pubDate>Thu, 08 Aug 2024 11:05:19 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/32827a07-7237-396a-be6c-490d4242cd25</guid>
                                    <description><![CDATA[<p>In this insightful episode, we dive deep into the pressing issue of data privacy, where 86% of U.S. consumers express growing concerns and 40% don't trust companies to handle their data ethically. 
Join us as we chat with the Vice President of Engineering at MetaRouter, a cutting-edge platform enabling enterprises to regain control over their customer data. We explore how MetaRouter empowers businesses to manage data in a 1st-party context, ensuring ethical, compliant handling while navigating the complexities of privacy regulations.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months</li>
</ul>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;"><a href='https://www.metarouter.io/post/mastering-data-governance-why-governance-at-the-point-of-collection-is-a-must-have'>https://www.metarouter.io/post/mastering-data-governance-why-governance-at-the-point-of-collection-is-a-must-have</a>Â </li>
<li style="font-weight:400;"><a href='https://hubs.ly/Q02HwJly0'>https://hubs.ly/Q02HwJly0</a>Â </li>
<li style="font-weight:400;"><a href='https://www.metarouter.io/post/why-privacy-sandbox-is-a-good-paradigm-shift-for-consumers'>https://www.metarouter.io/post/why-privacy-sandbox-is-a-good-paradigm-shift-for-consumers</a>Â </li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this insightful episode, we dive deep into the pressing issue of data privacy, where 86% of U.S. consumers express growing concerns and 40% don't trust companies to handle their data ethically. <br>
Join us as we chat with the Vice President of Engineering at MetaRouter, a cutting-edge platform enabling enterprises to regain control over their customer data. We explore how MetaRouter empowers businesses to manage data in a 1st-party context, ensuring ethical, compliant handling while navigating the complexities of privacy regulations.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months</li>
</ul>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;"><a href='https://www.metarouter.io/post/mastering-data-governance-why-governance-at-the-point-of-collection-is-a-must-have'>https://www.metarouter.io/post/mastering-data-governance-why-governance-at-the-point-of-collection-is-a-must-have</a>Â </li>
<li style="font-weight:400;"><a href='https://hubs.ly/Q02HwJly0'>https://hubs.ly/Q02HwJly0</a>Â </li>
<li style="font-weight:400;"><a href='https://www.metarouter.io/post/why-privacy-sandbox-is-a-good-paradigm-shift-for-consumers'>https://www.metarouter.io/post/why-privacy-sandbox-is-a-good-paradigm-shift-for-consumers</a>Â </li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gkfwp445wnsgmef5/metarouter-data-platform.mp3" length="38953976" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this insightful episode, we dive deep into the pressing issue of data privacy, where 86% of U.S. consumers express growing concerns and 40% don't trust companies to handle their data ethically. Join us as we chat with the Vice President of Engineering at MetaRouter, a cutting-edge platform enabling enterprises to regain control over their customer data. We explore how MetaRouter empowers businesses to manage data in a 1st-party context, ensuring ethical, compliant handling while navigating the complexities of privacy regulations.
Â 
Sponsors
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months
Â 
References
https://www.metarouter.io/post/mastering-data-governance-why-governance-at-the-point-of-collection-is-a-must-haveÂ 
https://hubs.ly/Q02HwJly0Â 
https://www.metarouter.io/post/why-privacy-sandbox-is-a-good-paradigm-shift-for-consumersÂ 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:27</itunes:duration>
                <itunes:episode>264</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Low-Code Magic: Can It Transform Analytics? (Ep. 260)</title>
        <itunes:title>Low-Code Magic: Can It Transform Analytics? (Ep. 260)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/low-code-magic-can-it-transform-analytics-ep-260/</link>
                    <comments>https://datascienceathome.podbean.com/e/low-code-magic-can-it-transform-analytics-ep-260/#comments</comments>        <pubDate>Mon, 22 Jul 2024 15:26:16 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/786d6586-076b-3dd0-9853-68b6f01283d3</guid>
                                    <description><![CDATA[<p>Join us as David Marom, Head of Panoply Business, explores the benefits of all-in-one data platforms. 
Learn how tech stack consolidation boosts efficiency, improves data accuracy, and cuts costs. 
David shares insights on overcoming common challenges, enhancing data governance, and success stories from organizations thriving with Panoply. 

</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li>Connect and analyze ALL of your data <a href='https://panoply.io/'>https://panoply.io/</a></li>
<li><a href='https://blog.panoply.io/raw-data-to-dashboards-in-just-10-steps'>https://blog.panoply.io/raw-data-to-dashboards-in-just-10-steps</a> 
</li>
<li><a href='https://blog.panoply.io/understanding-etl-extract-transform-and-load-data-to-boost-your-business-intelligence'>https://blog.panoply.io/understanding-etl-extract-transform-and-load-data-to-boost-your-business-intelligence</a></li>
<li>
<p>Blog: <a href='https://blog.panoply.io/the-transformative-power-of-an-all-in-one-data-platform'>The Transformative Power of an All-in-One Data Platform</a></p>
</li>
<li>
<p>Whitepaper: <a href='https://learn.panoply.io/eradicating-inefficiencies'>Eradicating Platform Inefficiencies</a></p>
</li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>Join us as David Marom, Head of Panoply Business, explores the benefits of all-in-one data platforms. <br>
Learn how tech stack consolidation boosts efficiency, improves data accuracy, and cuts costs. <br>
David shares insights on overcoming common challenges, enhancing data governance, and success stories from organizations thriving with Panoply. <br>
<br>
</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li>Connect and analyze ALL of your data <a href='https://panoply.io/'>https://panoply.io/</a></li>
<li><a href='https://blog.panoply.io/raw-data-to-dashboards-in-just-10-steps'>https://blog.panoply.io/raw-data-to-dashboards-in-just-10-steps</a> <br>
</li>
<li><a href='https://blog.panoply.io/understanding-etl-extract-transform-and-load-data-to-boost-your-business-intelligence'>https://blog.panoply.io/understanding-etl-extract-transform-and-load-data-to-boost-your-business-intelligence</a></li>
<li>
<p>Blog: <a href='https://blog.panoply.io/the-transformative-power-of-an-all-in-one-data-platform'>The Transformative Power of an All-in-One Data Platform</a></p>
</li>
<li>
<p>Whitepaper: <a href='https://learn.panoply.io/eradicating-inefficiencies'>Eradicating Platform Inefficiencies</a></p>
</li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8t24vbsm4hyn3e9r/panoply.mp3" length="39488553" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join us as David Marom, Head of Panoply Business, explores the benefits of all-in-one data platforms. Learn how tech stack consolidation boosts efficiency, improves data accuracy, and cuts costs. David shares insights on overcoming common challenges, enhancing data governance, and success stories from organizations thriving with Panoply. 
Â 
Sponsors
Arctic Wolf Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months
Â 
References
Connect and analyze ALL of your data https://panoply.io/
https://blog.panoply.io/raw-data-to-dashboards-in-just-10-steps 
https://blog.panoply.io/understanding-etl-extract-transform-and-load-data-to-boost-your-business-intelligence

Blog: The Transformative Power of an All-in-One Data Platform


Whitepaper: Eradicating Platform Inefficiencies

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:45</itunes:duration>
                <itunes:episode>263</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Do you really know how GPUs work? (Ep. 259)</title>
        <itunes:title>Do you really know how GPUs work? (Ep. 259)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/do-you-really-know-how-gpus-work-ep-259/</link>
                    <comments>https://datascienceathome.podbean.com/e/do-you-really-know-how-gpus-work-ep-259/#comments</comments>        <pubDate>Sat, 22 Jun 2024 10:11:29 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d526d3fc-9591-33cf-8b9b-5930f0f11bca</guid>
                                    <description><![CDATA[<p>Join us in this exciting episode of the Data Science at Home podcast. It's all about GPUs. We'll take you on a journey through the inner workings of these powerful processors, explaining how they handle complex computations and drive everything from gaming graphics to scientific simulations. 
Whether you're a budding programmer or a tech enthusiast, understanding GPUs is key to unlocking new levels of performance and efficiency in your projects. Tune in and get ready to turbocharge your tech knowledge!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join us in this exciting episode of the Data Science at Home podcast. It's all about GPUs. We'll take you on a journey through the inner workings of these powerful processors, explaining how they handle complex computations and drive everything from gaming graphics to scientific simulations. <br>
Whether you're a budding programmer or a tech enthusiast, understanding GPUs is key to unlocking new levels of performance and efficiency in your projects. Tune in and get ready to turbocharge your tech knowledge!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/f4bm2jy4hb2cysvs/how-does-gpu-works.mp3" length="45986644" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join us in this exciting episode of the Data Science at Home podcast. It's all about GPUs. We'll take you on a journey through the inner workings of these powerful processors, explaining how they handle complex computations and drive everything from gaming graphics to scientific simulations. Whether you're a budding programmer or a tech enthusiast, understanding GPUs is key to unlocking new levels of performance and efficiency in your projects. Tune in and get ready to turbocharge your tech knowledge!
Â 
Sponsors
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:17</itunes:duration>
                <itunes:episode>262</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Harnessing AI for Cybersecurity: Expert Tips from QFunction (Ep. 258)</title>
        <itunes:title>Harnessing AI for Cybersecurity: Expert Tips from QFunction (Ep. 258)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/harnessing-ai-for-cybersecurity-expert-tips-from-qfunction-ep-258/</link>
                    <comments>https://datascienceathome.podbean.com/e/harnessing-ai-for-cybersecurity-expert-tips-from-qfunction-ep-258/#comments</comments>        <pubDate>Tue, 11 Jun 2024 08:10:12 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/320b21f2-cf90-39a6-8159-ff125b672e6c</guid>
                                    <description><![CDATA[<p>In this episode, we sit down with Ryan Smith, Founder of <a href='https://qfunction.ai/'>QFunction LLC</a>, to explore how AI and machine learning are revolutionizing cybersecurity. With over 8 years of experience, including work at NASA's Jet Propulsion Laboratory, Ryan shares insights on the future of threat detection and prevention, the challenges businesses face in maintaining effective cybersecurity, and the ethical considerations of AI implementation. 
Learn about cost-effective strategies for small businesses, the importance of collaboration in combating cyber threats, and how QFunction tailors its AI solutions to meet diverse industry needs.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://qfunction.ai/'>QFunction</a>Â  does cybersecurity differently. By relying on scientific breakthroughs in AI and machine learning, QFunction works within your existing security stack to detect anomalies and threats within your data</li>
</ul>
Â 
References
<ul><li><a href='https://qfunction.ai/blog'>QFunction Blog</a></li>
<li><a href='https://qfunction.ai/blog/threat-hunting-network-connections-using-zeek-and-ai'>Threat Hunting Firewall Logs</a></li>
<li><a href='https://qfunction.ai/blog/automated-threat-hunting-within-linux-logs-using-dbscan'>Threat Hunting Linux Logs</a></li>
<li><a href='https://github.com/qfunction-ai/ai-anomaly-detection'>QFunction GitHub</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, we sit down with Ryan Smith, Founder of <a href='https://qfunction.ai/'>QFunction LLC</a>, to explore how AI and machine learning are revolutionizing cybersecurity. With over 8 years of experience, including work at NASA's Jet Propulsion Laboratory, Ryan shares insights on the future of threat detection and prevention, the challenges businesses face in maintaining effective cybersecurity, and the ethical considerations of AI implementation. <br>
Learn about cost-effective strategies for small businesses, the importance of collaboration in combating cyber threats, and how QFunction tailors its AI solutions to meet diverse industry needs.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://qfunction.ai/'>QFunction</a>Â  does cybersecurity differently. By relying on scientific breakthroughs in AI and machine learning, QFunction works within your existing security stack to detect anomalies and threats within your data</li>
</ul>
Â 
References
<ul><li><a href='https://qfunction.ai/blog'>QFunction Blog</a></li>
<li><a href='https://qfunction.ai/blog/threat-hunting-network-connections-using-zeek-and-ai'>Threat Hunting Firewall Logs</a></li>
<li><a href='https://qfunction.ai/blog/automated-threat-hunting-within-linux-logs-using-dbscan'>Threat Hunting Linux Logs</a></li>
<li><a href='https://github.com/qfunction-ai/ai-anomaly-detection'>QFunction GitHub</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/z3tbbtasvggwiyhh/ai-and-cybersecurity-qfunction.mp3" length="33168821" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, we sit down with Ryan Smith, Founder of QFunction LLC, to explore how AI and machine learning are revolutionizing cybersecurity. With over 8 years of experience, including work at NASA's Jet Propulsion Laboratory, Ryan shares insights on the future of threat detection and prevention, the challenges businesses face in maintaining effective cybersecurity, and the ethical considerations of AI implementation. Learn about cost-effective strategies for small businesses, the importance of collaboration in combating cyber threats, and how QFunction tailors its AI solutions to meet diverse industry needs.
Â 
Sponsors
Arctic Wolf Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
QFunctionÂ  does cybersecurity differently. By relying on scientific breakthroughs in AI and machine learning, QFunction works within your existing security stack to detect anomalies and threats within your data
Â 
References
QFunction Blog
Threat Hunting Firewall Logs
Threat Hunting Linux Logs
QFunction GitHub
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>34:33</itunes:duration>
                <itunes:episode>260</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust in the Cosmos Part 4: What happens in space? (Ep. 257)</title>
        <itunes:title>Rust in the Cosmos Part 4: What happens in space? (Ep. 257)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-part-4-what-happens-in-space/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-part-4-what-happens-in-space/#comments</comments>        <pubDate>Sat, 01 Jun 2024 14:14:29 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5300db05-8a5e-3e48-99f6-df80621cc8d2</guid>
                                    <description><![CDATA[<p>In this last episode of the series "Rust in the Cosmos" we speak about what happens in space, what projects are currently active and what happened in the past that we can learn from?</p>
<p>What about Rust and space applications? As always,Â  let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>Intrepid AI, AeroRust, Bytenook</p>
<ul><li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
<li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
</ul>
Â 
References
<ul style="margin:4px 0px 0px 16px;padding:0px;border:0px;font-weight:400;font-style:normal;font-family:'gg sans', 'Noto Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;vertical-align:baseline;list-style:disc outside;color:#dbdee1;letter-spacing:normal;text-align:left;text-indent:0px;text-transform:none;word-spacing:0px;background-color:rgba(2,2,2,.06);"><li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Workshop <a href='https://github.com/AeroRust/nanosat-workshop'>https://github.com/AeroRust/nanosat-workshop</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Embassy - <a href='https://github.com/embassy-rs/embassy'>https://github.com/embassy-rs/embassy</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Software based fault redundancy, (Errata: it's not from NASA) : <a href='https://ieeexplore.ieee.org/document/1402092'>https://ieeexplore.ieee.org/document/1402092</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Whitehouse paper for memory safe languages <a href='https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf'>https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this last episode of the series "Rust in the Cosmos" we speak about what happens in space, what projects are currently active and what happened in the past that we can learn from?</p>
<p>What about Rust and space applications? As always,Â  let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>Intrepid AI, AeroRust, Bytenook</p>
<ul><li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
<li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
</ul>
Â 
References
<ul style="margin:4px 0px 0px 16px;padding:0px;border:0px;font-weight:400;font-style:normal;font-family:'gg sans', 'Noto Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;vertical-align:baseline;list-style:disc outside;color:#dbdee1;letter-spacing:normal;text-align:left;text-indent:0px;text-transform:none;word-spacing:0px;background-color:rgba(2,2,2,.06);"><li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Workshop <a href='https://github.com/AeroRust/nanosat-workshop'>https://github.com/AeroRust/nanosat-workshop</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Embassy - <a href='https://github.com/embassy-rs/embassy'>https://github.com/embassy-rs/embassy</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Software based fault redundancy, (Errata: it's not from NASA) : <a href='https://ieeexplore.ieee.org/document/1402092'>https://ieeexplore.ieee.org/document/1402092</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Whitehouse paper for memory safe languages <a href='https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf'>https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/k77gnr8i43pfwy83/Rust-and-aerospace-applications-4.mp3" length="28232306" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this last episode of the series "Rust in the Cosmos" we speak about what happens in space, what projects are currently active and what happened in the past that we can learn from?
What about Rust and space applications? As always,Â  let's find out ;)
Â 
Sponsors
Arctic Wolf Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
Communities
Intrepid AI, AeroRust, Bytenook
Intrepid AI DiscordÂ https://discord.gg/cSSzche6Ct
Intrepid AI website: https://intrepid.ai
AeroRust Discord invite: https://discord.com/invite/6jJyx5nEUqÂ 
AeroRust website: AeroRust.org
Â 
References
Workshop https://github.com/AeroRust/nanosat-workshop
Embassy - https://github.com/embassy-rs/embassy
Software based fault redundancy, (Errata: it's not from NASA) : https://ieeexplore.ieee.org/document/1402092
Whitehouse paper for memory safe languages https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:24</itunes:duration>
                <itunes:episode>259</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust in the Cosmos Part 3: Embedded programming for space (Ep. 256)</title>
        <itunes:title>Rust in the Cosmos Part 3: Embedded programming for space (Ep. 256)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-part-3/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-part-3/#comments</comments>        <pubDate>Fri, 10 May 2024 11:07:12 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3bacb5a1-a6ce-3ebd-9f1d-ef01b10bf850</guid>
                                    <description><![CDATA[<p>In this episode of "Rust in the Cosmos" we delve into the challenges of building embedded applications for space. 
Did you know that once you ship your app to space... you can't get it back? :P</p>
<p>What role is Rust playing here? Let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>AeroRust, Intrepid, Bytenook</p>
<ul><li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
<li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
</ul>
Â 
References
<ul style="margin:4px 0px 0px 16px;padding:0px;border:0px;font-weight:400;font-style:normal;font-family:'gg sans', 'Noto Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;vertical-align:baseline;list-style:disc outside;color:#dbdee1;letter-spacing:normal;text-align:left;text-indent:0px;text-transform:none;word-spacing:0px;background-color:rgba(2,2,2,.06);"><li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Workshop <a href='https://github.com/AeroRust/nanosat-workshop'>https://github.com/AeroRust/nanosat-workshop</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Embassy - <a href='https://github.com/embassy-rs/embassy'>https://github.com/embassy-rs/embassy</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Software based fault redundancy, (Errata: it's not from NASA) : <a href='https://ieeexplore.ieee.org/document/1402092'>https://ieeexplore.ieee.org/document/1402092</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Whitehouse paper for memory safe languages <a href='https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf'>https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of "Rust in the Cosmos" we delve into the challenges of building embedded applications for space. <br>
Did you know that once you ship your app to space... you can't get it back? :P</p>
<p>What role is Rust playing here? Let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>AeroRust, Intrepid, Bytenook</p>
<ul><li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
<li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
</ul>
Â 
References
<ul style="margin:4px 0px 0px 16px;padding:0px;border:0px;font-weight:400;font-style:normal;font-family:'gg sans', 'Noto Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;vertical-align:baseline;list-style:disc outside;color:#dbdee1;letter-spacing:normal;text-align:left;text-indent:0px;text-transform:none;word-spacing:0px;background-color:rgba(2,2,2,.06);"><li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Workshop <a href='https://github.com/AeroRust/nanosat-workshop'>https://github.com/AeroRust/nanosat-workshop</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Embassy - <a href='https://github.com/embassy-rs/embassy'>https://github.com/embassy-rs/embassy</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Software based fault redundancy, (Errata: it's not from NASA) : <a href='https://ieeexplore.ieee.org/document/1402092'>https://ieeexplore.ieee.org/document/1402092</a></li>
<li style="margin:0px 0px 4px;padding:0px;border:0px;font-weight:inherit;font-style:inherit;font-family:inherit;font-size:16px;vertical-align:baseline;">Whitehouse paper for memory safe languages <a href='https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf'>https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4b4viimicnqppjw9/Rust-and-aerospace-applications-3.mp3" length="42827022" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of "Rust in the Cosmos" we delve into the challenges of building embedded applications for space. Did you know that once you ship your app to space... you can't get it back? :P
What role is Rust playing here? Let's find out ;)
Â 
Sponsors
Arctic Wolf Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
Communities
AeroRust, Intrepid, Bytenook
AeroRust Discord invite: https://discord.com/invite/6jJyx5nEUqÂ 
AeroRust website: AeroRust.org
Intrepid AI DiscordÂ https://discord.gg/cSSzche6Ct
Intrepid AI website: https://intrepid.ai
Â 
References
Workshop https://github.com/AeroRust/nanosat-workshop
Embassy - https://github.com/embassy-rs/embassy
Software based fault redundancy, (Errata: it's not from NASA) : https://ieeexplore.ieee.org/document/1402092
Whitehouse paper for memory safe languages https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>44:36</itunes:duration>
                <itunes:episode>258</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust in the Cosmos Part 2: testing software in space (Ep. 255)</title>
        <itunes:title>Rust in the Cosmos Part 2: testing software in space (Ep. 255)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-decoding-communication-part-2-ep-255/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-decoding-communication-part-2-ep-255/#comments</comments>        <pubDate>Fri, 19 Apr 2024 17:51:46 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/52a2c5be-a7eb-3085-8962-de2f60ac9bea</guid>
                                    <description><![CDATA[<p>In this episode of "Rust in the Cosmos" we delve into the challenge of testing software for... ehm ... space </p>
<p>How can Rust help? Let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>AeroRust, Intrepid, Bytenook</p>
<ul><li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
<li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;">Open-source
<ul><li style="font-weight:400;">GitHub workflows/actions - <a href='https://docs.github.com/en/actions'>https://docs.github.com/en/actions</a>Â </li>
<li style="font-weight:400;">Gitlab CI - <a href='https://docs.gitlab.com/ee/ci/'>https://docs.gitlab.com/ee/ci/</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Alternatives
<ul><li style="font-weight:400;">Circle ci - <a href='https://circleci.com/'>https://circleci.com/</a>Â </li>
<li style="font-weight:400;">Travis <a href='http://travis-ci.com'>http://travis-ci.com</a>Â  </li>
</ul>
</li>
<li style="font-weight:400;">Dagger.io - <a href='https://dagger.io'>https://dagger.io</a> </li>
</ul>
<ul><li style="font-weight:400;">Actions<ul><li style="font-weight:400;"><a href='https://github.com/dtolnay/rust-toolchain'>https://github.com/dtolnay/rust-toolchain</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/taiki-e/install-action'>https://github.com/taiki-e/install-action</a></li>
<li style="font-weight:400;"><a href='https://github.com/marketplace/actions/install-cargo-binstall'>https://github.com/marketplace/actions/install-cargo-binstall</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Additional tools:<ul><li style="font-weight:400;"><a href='https://github.com/nextest-rs/nextest'>https://github.com/nextest-rs/nextest</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/cargo-bins/cargo-binstall'>https://github.com/cargo-bins/cargo-binstall</a></li>
</ul>
</li>
<li style="font-weight:400;"><a href='https://www.youtube.com/watch?v=qfknfCsICUM&amp;ab_channel=RustNationUK'>Jon Gjengset - Towards Impeccable Rust</a>Â </li>
<li>Lechev.space: <a href='http://www.lechev.space'>lechev.space</a></li>
</ul>
<p>


</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of "Rust in the Cosmos" we delve into the challenge of testing software for... ehm ... space </p>
<p>How can Rust help? Let's find out ;)</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
<li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
Â 
Communities
<p>AeroRust, Intrepid, Bytenook</p>
<ul><li style="font-weight:400;">AeroRust Discord invite: <a href='https://discord.com/invite/6jJyx5nEUq'>https://discord.com/invite/6jJyx5nEUq</a>Â </li>
<li style="font-weight:400;">AeroRust website: <a href='http://aerorust.org'>AeroRust.org</a></li>
<li style="font-weight:400;">Intrepid AI DiscordÂ <a href='https://discord.gg/cSSzche6Ct'>https://discord.gg/cSSzche6Ct</a></li>
<li style="font-weight:400;">Intrepid AI website: <a href='https://intrepid.ai'>https://intrepid.ai</a></li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;">Open-source
<ul><li style="font-weight:400;">GitHub workflows/actions - <a href='https://docs.github.com/en/actions'>https://docs.github.com/en/actions</a>Â </li>
<li style="font-weight:400;">Gitlab CI - <a href='https://docs.gitlab.com/ee/ci/'>https://docs.gitlab.com/ee/ci/</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Alternatives
<ul><li style="font-weight:400;">Circle ci - <a href='https://circleci.com/'>https://circleci.com/</a>Â </li>
<li style="font-weight:400;">Travis <a href='http://travis-ci.com'>http://travis-ci.com</a>Â  </li>
</ul>
</li>
<li style="font-weight:400;">Dagger.io - <a href='https://dagger.io'>https://dagger.io</a> </li>
</ul>
<ul><li style="font-weight:400;">Actions<ul><li style="font-weight:400;"><a href='https://github.com/dtolnay/rust-toolchain'>https://github.com/dtolnay/rust-toolchain</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/taiki-e/install-action'>https://github.com/taiki-e/install-action</a></li>
<li style="font-weight:400;"><a href='https://github.com/marketplace/actions/install-cargo-binstall'>https://github.com/marketplace/actions/install-cargo-binstall</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Additional tools:<ul><li style="font-weight:400;"><a href='https://github.com/nextest-rs/nextest'>https://github.com/nextest-rs/nextest</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/cargo-bins/cargo-binstall'>https://github.com/cargo-bins/cargo-binstall</a></li>
</ul>
</li>
<li style="font-weight:400;"><a href='https://www.youtube.com/watch?v=qfknfCsICUM&amp;ab_channel=RustNationUK'>Jon Gjengset - Towards Impeccable Rust</a>Â </li>
<li>Lechev.space: <a href='http://www.lechev.space'>lechev.space</a></li>
</ul>
<p><br>
<br>
<br>
</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vzwnq6ddtmhdsia4/Rust-and-aerospace-applications-2.mp3" length="31535019" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of "Rust in the Cosmos" we delve into the challenge of testing software for... ehm ... space 
How can Rust help? Let's find out ;)
Â 
Sponsors
Arctic Wolf Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
Communities
AeroRust, Intrepid, Bytenook
AeroRust Discord invite: https://discord.com/invite/6jJyx5nEUqÂ 
AeroRust website: AeroRust.org
Intrepid AI DiscordÂ https://discord.gg/cSSzche6Ct
Intrepid AI website: https://intrepid.ai
Â 
References
Open-source
GitHub workflows/actions - https://docs.github.com/en/actionsÂ 
Gitlab CI - https://docs.gitlab.com/ee/ci/Â 

Alternatives
Circle ci - https://circleci.com/Â 
Travis http://travis-ci.comÂ  

Dagger.io - https://dagger.io 
Actionshttps://github.com/dtolnay/rust-toolchainÂ 
https://github.com/taiki-e/install-action
https://github.com/marketplace/actions/install-cargo-binstallÂ 

Additional tools:https://github.com/nextest-rs/nextestÂ 
https://github.com/cargo-bins/cargo-binstall

Jon Gjengset - Towards Impeccable RustÂ 
Lechev.space: lechev.space

Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:50</itunes:duration>
                <itunes:episode>257</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust in the Cosmos Part 1: Decoding Communication (Ep. 254)</title>
        <itunes:title>Rust in the Cosmos Part 1: Decoding Communication (Ep. 254)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-decoding-communication-part-i-ep-254/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-in-the-cosmos-decoding-communication-part-i-ep-254/#comments</comments>        <pubDate>Thu, 11 Apr 2024 08:02:18 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/baa4434f-fd79-3a51-8456-03f1b71778a4</guid>
                                    <description><![CDATA[<p>In this inaugural episode of "Rust in the Cosmos," we delve into the intricacies of communication in space and some of the challenges in space application development.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this inaugural episode of "Rust in the Cosmos," we delve into the intricacies of communication in space and some of the challenges in space application development.</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/m73fehcxn4bcxdgc/Rust-and-aerospace-applications-1.mp3" length="25219656" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this inaugural episode of "Rust in the Cosmos," we delve into the intricacies of communication in space and some of the challenges in space application development.
Â 
Sponsors
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:16</itunes:duration>
                <itunes:episode>256</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI and Video Game Development: Navigating the Future Frontier (Ep. 253)</title>
        <itunes:title>AI and Video Game Development: Navigating the Future Frontier (Ep. 253)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-and-video-game-development-navigating-the-future-frontier-ep-253/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-and-video-game-development-navigating-the-future-frontier-ep-253/#comments</comments>        <pubDate>Sun, 31 Mar 2024 10:22:15 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/bc516046-fe88-3f8f-b896-de0316c0e1fd</guid>
                                    <description><![CDATA[<p>In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. 
From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://mikeyoung44.itch.io/spacefreighter'>https://mikeyoung44.itch.io/spacefreighter</a> - Itch.io link to play the game</li>
<li style="font-weight:400;"><a href='https://discord.gg/yaXgYZ5Ymn'>https://discord.gg/yaXgYZ5Ymn</a> - Discord server for the game</li>
<li style="font-weight:400;"><a href='https://aimodels.substack.com/'>https://aimodels.substack.com/</a> - Mikeâ€™s newsletter (links to website too)</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. <br>
From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> (<a href='https://intrepid.ai'>https://intrepid.ai</a>) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
</ul>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://mikeyoung44.itch.io/spacefreighter'>https://mikeyoung44.itch.io/spacefreighter</a> - Itch.io link to play the game</li>
<li style="font-weight:400;"><a href='https://discord.gg/yaXgYZ5Ymn'>https://discord.gg/yaXgYZ5Ymn</a> - Discord server for the game</li>
<li style="font-weight:400;"><a href='https://aimodels.substack.com/'>https://aimodels.substack.com/</a> - Mikeâ€™s newsletter (links to website too)</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6gu8h2/ai-and-videogames.mp3" length="46017305" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode we delve into the dynamic realm of game development and the transformative role of artificial intelligence (AI). Join Frag, Jim and Mike as they explore the current landscape of game development processes, from initial creative ideation to the integration of AI-driven solutions. With Mike's expertise as a software executive and avid game developer, we uncover the potential of AI to revolutionize game design, streamline development cycles, and enhance player experiences. Discover insights into AI's applications in asset creation, code assistance, and even gameplay itself, as we discuss real-world implementations and cutting-edge research. From the innovative GameGPT framework to the challenges of balancing automation with human creativity, this episode offers valuable perspectives and practical advice for developers looking to harness the power of AI in their game projects. Don't miss out on this insightful exploration at the intersection of technology and entertainment!
Â 
Sponsors
Intrepid AI (https://intrepid.ai) is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
Â 
References
https://mikeyoung44.itch.io/spacefreighter - Itch.io link to play the game
https://discord.gg/yaXgYZ5Ymn - Discord server for the game
https://aimodels.substack.com/ - Mikeâ€™s newsletter (links to website too)
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>47:56</itunes:duration>
                <itunes:episode>255</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Kaggle Kommando's Data Disco: Laughing our Way Through AI Trends (Ep. 252)</title>
        <itunes:title>Kaggle Kommando's Data Disco: Laughing our Way Through AI Trends (Ep. 252)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/kaggle-kommandos-data-disco-laughing-our-way-through-ai-trends-ep-252/</link>
                    <comments>https://datascienceathome.podbean.com/e/kaggle-kommandos-data-disco-laughing-our-way-through-ai-trends-ep-252/#comments</comments>        <pubDate>Thu, 07 Mar 2024 17:22:37 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/497b6b6f-a649-3863-b331-141887147919</guid>
                                    <description><![CDATA[
<p>In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
<p>Â </p>
<p>ğŸ”— Links Mentioned in the Episode:</p>
<ol><li>Generative AI for time series: TimeGPT <a href='https://docs.nixtla.io/docs/timegpt_quickstart'>Documentation</a></li>
<li>Lag-llama: <a href='https://github.com/time-series-foundation-models/lag-llama'>GitHub</a> (Note: The benchmark results on this one are pretty horrible)</li>
<li>Open source LLM: Olmo <a href='https://blog.allenai.org/olmo-open-language-model-87ccfc95f580'>Blog Post</a></li>
<li>Quantization for LLM: <a href='https://huggingface.co/docs/optimum/concept_guides/quantization'>Hugging Face Guide</a></li>
</ol><p>And finally, don't miss Konrad's <a href='https://konradb.substack.com/'>Substack</a> for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)</p>
]]></description>
                                                            <content:encoded><![CDATA[
<p>In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!</p>
<p>Â </p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
<p>Â </p>
<p>ğŸ”— Links Mentioned in the Episode:</p>
<ol><li>Generative AI for time series: TimeGPT <a href='https://docs.nixtla.io/docs/timegpt_quickstart'>Documentation</a></li>
<li>Lag-llama: <a href='https://github.com/time-series-foundation-models/lag-llama'>GitHub</a> (Note: The benchmark results on this one are pretty horrible)</li>
<li>Open source LLM: Olmo <a href='https://blog.allenai.org/olmo-open-language-model-87ccfc95f580'>Blog Post</a></li>
<li>Quantization for LLM: <a href='https://huggingface.co/docs/optimum/concept_guides/quantization'>Hugging Face Guide</a></li>
</ol><p>And finally, don't miss Konrad's <a href='https://konradb.substack.com/'>Substack</a> for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/px724w/kaggle-kommando-data-disco.mp3" length="82133158" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
In this episode, join me and the Kaggle Grand Master, Konrad Banachewicz, for a hilarious journey into the zany world of data science trends. From algorithm acrobatics to AI, creativity, Hollywood movies, and music, we just can't get enough. It's the typical episode with a dose of nerdy comedy you didn't know you needed. Buckle up, it's a data disco, and we're breaking down the binary!
Â 
Sponsors
Intrepid AI is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
Â 
ğŸ”— Links Mentioned in the Episode:
Generative AI for time series: TimeGPT Documentation
Lag-llama: GitHub (Note: The benchmark results on this one are pretty horrible)
Open source LLM: Olmo Blog Post
Quantization for LLM: Hugging Face Guide
And finally, don't miss Konrad's Substack for more nerdy goodness! (If you're there already, be there again! ğŸ˜„)
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>42:46</itunes:duration>
                <itunes:episode>254</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Revolutionizing Robotics: Embracing Low-Code Solutions (Ep. 251)</title>
        <itunes:title>Revolutionizing Robotics: Embracing Low-Code Solutions (Ep. 251)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/revolutionizing-robotics-embracing-low-code-solutions-ep-251/</link>
                    <comments>https://datascienceathome.podbean.com/e/revolutionizing-robotics-embracing-low-code-solutions-ep-251/#comments</comments>        <pubDate>Fri, 16 Feb 2024 09:39:49 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/07de826d-f787-3983-8ae3-5de0e15badc4</guid>
                                    <description><![CDATA[<p>In this episode of Data Science at Home, we explore the game-changing impact of low-code solutions in robotics development. Discover how these tools bridge the coding gap, simplify integration, and enable trial-and-error development. We'll also uncover challenges with traditional coding methods using ROS. Join us for a concise yet insightful discussion on the future of robotics!</p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode of <em>Data Science at Home</em>, we explore the game-changing impact of low-code solutions in robotics development. Discover how these tools bridge the coding gap, simplify integration, and enable trial-and-error development. We'll also uncover challenges with traditional coding methods using ROS. Join us for a concise yet insightful discussion on the future of robotics!</p>
Sponsors
<ul><li><a href='https://intrepid.ai'>Intrepid AI</a> is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.</li>
<li style="line-height:100%;background:#ffffff;">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/392v2n/low-code-robotics-application-development.mp3" length="18508067" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode of Data Science at Home, we explore the game-changing impact of low-code solutions in robotics development. Discover how these tools bridge the coding gap, simplify integration, and enable trial-and-error development. We'll also uncover challenges with traditional coding methods using ROS. Join us for a concise yet insightful discussion on the future of robotics!
Sponsors
Intrepid AI is an AI assisted all-in-one platform for robotics teams. Build robotics applications in minutes, not months.
Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:16</itunes:duration>
                <itunes:episode>253</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Is SQream the fastest big data platform? (Ep. 250)</title>
        <itunes:title>Is SQream the fastest big data platform? (Ep. 250)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/is-this-the-fastest-big-data-platform-ep-250/</link>
                    <comments>https://datascienceathome.podbean.com/e/is-this-the-fastest-big-data-platform-ep-250/#comments</comments>        <pubDate>Tue, 30 Jan 2024 16:42:28 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3bf08235-2c3b-363a-8014-f7a7aafbee0f</guid>
                                    <description><![CDATA[<p>Join us in a dynamic conversation with Yori Lavi, Field CTO at SQream, as we unravel the data analytics landscape. From debunking the data lakehouse hype to SQream's GPU-based magic, discover how extreme data challenges are met with agility. 
Yori shares success stories, insights into SQream's petabyte-scale capabilities, and a roadmap to breaking down organizational bottlenecks in data science. 
Dive into the future of data analytics with SQream's commitment to innovation, leaving legacy formats behind and leading the charge in large-scale, cost-effective data projects. 
Tune in for a dose of GPU-powered revolution!</p>
<p>Â </p>
<p>References</p>
<ul><li><a href='https://sqream.com/'>SQream - GPU-based Big Data PlatformÂ Â </a></li>
<li class="wrapper">
<a href='https://patents.justia.com/assignee/sqream-technologies-ltd'>Patents Assigned to SQREAM TECHNOLOGIES LTD</a>
</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join us in a dynamic conversation with Yori Lavi, Field CTO at SQream, as we unravel the data analytics landscape. From debunking the data lakehouse hype to SQream's GPU-based magic, discover how extreme data challenges are met with agility. <br>
Yori shares success stories, insights into SQream's petabyte-scale capabilities, and a roadmap to breaking down organizational bottlenecks in data science. <br>
Dive into the future of data analytics with SQream's commitment to innovation, leaving legacy formats behind and leading the charge in large-scale, cost-effective data projects. <br>
Tune in for a dose of GPU-powered revolution!</p>
<p>Â </p>
<p>References</p>
<ul><li><a href='https://sqream.com/'>SQream - GPU-based Big Data PlatformÂ Â </a></li>
<li class="wrapper">
<a href='https://patents.justia.com/assignee/sqream-technologies-ltd'>Patents Assigned to SQREAM TECHNOLOGIES LTD</a>
</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/95v5vh/sqream-gpu-data-analytics.mp3" length="54990052" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join us in a dynamic conversation with Yori Lavi, Field CTO at SQream, as we unravel the data analytics landscape. From debunking the data lakehouse hype to SQream's GPU-based magic, discover how extreme data challenges are met with agility. Yori shares success stories, insights into SQream's petabyte-scale capabilities, and a roadmap to breaking down organizational bottlenecks in data science. Dive into the future of data analytics with SQream's commitment to innovation, leaving legacy formats behind and leading the charge in large-scale, cost-effective data projects. Tune in for a dose of GPU-powered revolution!
Â 
References
SQream - GPU-based Big Data PlatformÂ Â 

Patents Assigned to SQREAM TECHNOLOGIES LTD

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>57:16</itunes:duration>
                <itunes:episode>252</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>OpenAI CEO Shake-up: Decoding December 2023 (Ep. 249)</title>
        <itunes:title>OpenAI CEO Shake-up: Decoding December 2023 (Ep. 249)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/openai-ceo-shake-up-decoding-december-2023-ep-249/</link>
                    <comments>https://datascienceathome.podbean.com/e/openai-ceo-shake-up-decoding-december-2023-ep-249/#comments</comments>        <pubDate>Sun, 21 Jan 2024 10:15:57 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/32b121b8-7c85-368c-a86f-709983cc240e</guid>
                                    <description><![CDATA[<p>In this episode from a month ago, join me as we unravel the controversial CEO firing at OpenAI in December 2023. I share my insights on the events, decode the intricacies, and explore what lies ahead for this influential organization. Don't miss this concise yet insightful take on the intersection of leadership and artificial intelligence innovation.</p>
<p>Â </p>
<p>Â </p>
Sponsor
<p style="line-height: 100%; orphans: 2; widows: 2; margin-bottom: 0in; background: #ffffff;" align="left">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a>
</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode from a month ago, join me as we unravel the controversial CEO firing at OpenAI in December 2023. I share my insights on the events, decode the intricacies, and explore what lies ahead for this influential organization. Don't miss this concise yet insightful take on the intersection of leadership and artificial intelligence innovation.</p>
<p>Â </p>
<p>Â </p>
Sponsor
<p style="line-height: 100%; orphans: 2; widows: 2; margin-bottom: 0in; background: #ffffff;" align="left">Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a><br>
</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/zezewe/open-ai-the-real-story.mp3" length="26402480" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode from a month ago, join me as we unravel the controversial CEO firing at OpenAI in December 2023. I share my insights on the events, decode the intricacies, and explore what lies ahead for this influential organization. Don't miss this concise yet insightful take on the intersection of leadership and artificial intelligence innovation.
Â 
Â 
Sponsor
Learn what the new year holds for ransomware as a service, Active Directory, artificial intelligence and more when you download the 2024 Arctic Wolf Labs Predictions Report today at arcticwolf.com/datascience]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>27:30</itunes:duration>
                <itunes:episode>251</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Careers, Skills, and the Evolution of AI (Ep. 248)</title>
        <itunes:title>Careers, Skills, and the Evolution of AI (Ep. 248)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/careers-skills-and-the-evolution-of-ai-ep-248/</link>
                    <comments>https://datascienceathome.podbean.com/e/careers-skills-and-the-evolution-of-ai-ep-248/#comments</comments>        <pubDate>Mon, 08 Jan 2024 06:11:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2ec8edd4-7fa9-33ef-836c-7e1fa5e67f47</guid>
                                    <description><![CDATA[<p>!!WARNING!!</p>
<p>Due to some technical issues the volume is not always constant during the show. I sincerely apologise for any inconvenience
Francesco </p>
<p>Â </p>
<p>Â </p>
<p>In this episode, I speak with Richie Cotton, Data Evangelist at DataCamp, as he delves into the dynamic intersection of AI and education. Richie, a seasoned expert in data science and the host of the podcast, brings together a wealth of knowledge and experience to explore the evolving landscape of AI careers, the skills essential for generative AI technologies, and the symbiosis of domain expertise and technical skills in the industry.</p>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;">Become a generative AI developer in this FREE code-along series. Learn to build a chatbot using the OpenAI API, the Pinecone API, and LangChain, and learn to build NLP and image applications with Hugging Face. <a href='https://www.datacamp.com/ai-code-alongs'>https://www.datacamp.com/ai-code-alongs</a></li>
<li style="font-weight:400;">Learn to use ChatGPT and the OpenAI API in the OpenAI Fundamentals skill track. <a href='https://www.datacamp.com/tracks/openai-fundamentals'>https://www.datacamp.com/tracks/openai-fundamentals</a></li>
<li style="font-weight:400;">Get started with deep learning using PyTorch in the Introduction to Deep Learning with PyTorch course. <a href='https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch'>https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>!!WARNING!!</p>
<p>Due to some technical issues the volume is not always constant during the show. I sincerely apologise for any inconvenience<br>
Francesco </p>
<p>Â </p>
<p>Â </p>
<p>In this episode, I speak with Richie Cotton, Data Evangelist at DataCamp, as he delves into the dynamic intersection of AI and education. Richie, a seasoned expert in data science and the host of the podcast, brings together a wealth of knowledge and experience to explore the evolving landscape of AI careers, the skills essential for generative AI technologies, and the symbiosis of domain expertise and technical skills in the industry.</p>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;">Become a generative AI developer in this FREE code-along series. Learn to build a chatbot using the OpenAI API, the Pinecone API, and LangChain, and learn to build NLP and image applications with Hugging Face. <a href='https://www.datacamp.com/ai-code-alongs'>https://www.datacamp.com/ai-code-alongs</a></li>
<li style="font-weight:400;">Learn to use ChatGPT and the OpenAI API in the OpenAI Fundamentals skill track. <a href='https://www.datacamp.com/tracks/openai-fundamentals'>https://www.datacamp.com/tracks/openai-fundamentals</a></li>
<li style="font-weight:400;">Get started with deep learning using PyTorch in the Introduction to Deep Learning with PyTorch course. <a href='https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch'>https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/e6fbxz/ai-education.mp3" length="31163035" type="audio/mpeg"/>
        <itunes:summary><![CDATA[!!WARNING!!
Due to some technical issues the volume is not always constant during the show. I sincerely apologise for any inconvenienceFrancesco 
Â 
Â 
In this episode, I speak with Richie Cotton, Data Evangelist at DataCamp, as he delves into the dynamic intersection of AI and education. Richie, a seasoned expert in data science and the host of the podcast, brings together a wealth of knowledge and experience to explore the evolving landscape of AI careers, the skills essential for generative AI technologies, and the symbiosis of domain expertise and technical skills in the industry.
Â 
References
Become a generative AI developer in this FREE code-along series. Learn to build a chatbot using the OpenAI API, the Pinecone API, and LangChain, and learn to build NLP and image applications with Hugging Face. https://www.datacamp.com/ai-code-alongs
Learn to use ChatGPT and the OpenAI API in the OpenAI Fundamentals skill track. https://www.datacamp.com/tracks/openai-fundamentals
Get started with deep learning using PyTorch in the Introduction to Deep Learning with PyTorch course. https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:27</itunes:duration>
                <itunes:episode>250</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Open Source Revolution: AIâ€™s Redemption in Data Science (Ep. 247)</title>
        <itunes:title>Open Source Revolution: AIâ€™s Redemption in Data Science (Ep. 247)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/open-source-revolution-ai-s-redemption-in-data-science-ep-247/</link>
                    <comments>https://datascienceathome.podbean.com/e/open-source-revolution-ai-s-redemption-in-data-science-ep-247/#comments</comments>        <pubDate>Tue, 19 Dec 2023 09:59:45 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1de9e059-dfb3-3ae1-9654-deccd79c4997</guid>
                                    <description><![CDATA[<p>Dive into the world of Data Science at Home with our latest episode, where we explore the dynamic relationship between Artificial Intelligence and the redemption of open source software. In this thought-provoking discussion, I share my insights on why now, more than ever, is the opportune moment for open source to leave an indelible mark on the field of AI. Join me as I unpack my opinions and set expectations for the near future, discussing the pivotal role open source is set to play in shaping the landscape of data science and artificial intelligence. Don't miss outâ€”tune in to gain a deeper understanding of this revolutionary intersection!</p>
<p>Â </p>
<p>This episode is available as YouTube stream at <a href='https://www.youtube.com/live/0Enenz1HqIs?si=woyYdjJVz656BneH&amp;t=915'>https://www.youtube.com/live/0Enenz1HqIs?si=woyYdjJVz656BneH&amp;t=915</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Dive into the world of Data Science at Home with our latest episode, where we explore the dynamic relationship between Artificial Intelligence and the redemption of open source software. In this thought-provoking discussion, I share my insights on why now, more than ever, is the opportune moment for open source to leave an indelible mark on the field of AI. Join me as I unpack my opinions and set expectations for the near future, discussing the pivotal role open source is set to play in shaping the landscape of data science and artificial intelligence. Don't miss outâ€”tune in to gain a deeper understanding of this revolutionary intersection!</p>
<p>Â </p>
<p>This episode is available as YouTube stream at <a href='https://www.youtube.com/live/0Enenz1HqIs?si=woyYdjJVz656BneH&amp;t=915'>https://www.youtube.com/live/0Enenz1HqIs?si=woyYdjJVz656BneH&amp;t=915</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/w3ac6e/AI-OSS.mp3" length="35326745" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Dive into the world of Data Science at Home with our latest episode, where we explore the dynamic relationship between Artificial Intelligence and the redemption of open source software. In this thought-provoking discussion, I share my insights on why now, more than ever, is the opportune moment for open source to leave an indelible mark on the field of AI. Join me as I unpack my opinions and set expectations for the near future, discussing the pivotal role open source is set to play in shaping the landscape of data science and artificial intelligence. Don't miss outâ€”tune in to gain a deeper understanding of this revolutionary intersection!
Â 
This episode is available as YouTube stream at https://www.youtube.com/live/0Enenz1HqIs?si=woyYdjJVz656BneH&amp;t=915]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:47</itunes:duration>
                <itunes:episode>249</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner [RB] (Ep. 246)</title>
        <itunes:title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner [RB] (Ep. 246)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-rb-ep-246/</link>
                    <comments>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-rb-ep-246/#comments</comments>        <pubDate>Mon, 11 Dec 2023 06:52:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/263f8d00-6636-34d1-9824-e460f0eebe40</guid>
                                    <description><![CDATA[<p>In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. 
From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. 
Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. 
Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.</p>
<p>Â </p>
<p>You can read about Chris at <a href='https://thefinanser.com/'>https://thefinanser.com/</a></p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps and
tools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use their
Macs as an actual working tool, covering complete use cases like coding, designing, project and time
management and so on. Once subscribed, you get full access to paid features of the apps, as well as to
new apps that are being constantly added.
So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you do
your work more efficiently for just a fraction of the price. Get 7 days for free at <a href='https://stpp.co/dsat'>https://stpp.co/dsat</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. <br>
From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. <br>
Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. <br>
Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.</p>
<p>Â </p>
<p>You can read about Chris at <a href='https://thefinanser.com/'>https://thefinanser.com/</a></p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps and<br>
tools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use their<br>
Macs as an actual working tool, covering complete use cases like coding, designing, project and time<br>
management and so on. Once subscribed, you get full access to paid features of the apps, as well as to<br>
new apps that are being constantly added.<br>
So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you do<br>
your work more efficiently for just a fraction of the price. Get 7 days for free at <a href='https://stpp.co/dsat'>https://stpp.co/dsat</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ix9vfu/ai-crypto-future-finance.mp3" length="53324649" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.
Â 
You can read about Chris at https://thefinanser.com/
Â 
Sponsors
This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps andtools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use theirMacs as an actual working tool, covering complete use cases like coding, designing, project and timemanagement and so on. Once subscribed, you get full access to paid features of the apps, as well as tonew apps that are being constantly added.So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you doyour work more efficiently for just a fraction of the price. Get 7 days for free at https://stpp.co/dsat
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>41:21</itunes:duration>
                <itunes:episode>248</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Debunking AGI Hype and Embracing Reality [RB] (Ep. 245)</title>
        <itunes:title>Debunking AGI Hype and Embracing Reality [RB] (Ep. 245)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/debunking-agi-hype-and-embracing-reality-rb-ep-245/</link>
                    <comments>https://datascienceathome.podbean.com/e/debunking-agi-hype-and-embracing-reality-rb-ep-245/#comments</comments>        <pubDate>Mon, 04 Dec 2023 09:18:14 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ca15c952-1a22-3973-afe6-9681c6014dfd</guid>
                                    <description><![CDATA[<p>In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. 
Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. 

If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.</p>
<p>Â </p>


Filip Piekniewski Bio




<p>Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.</p>




Â 


<p>Sponsors</p>
<ul><li>
<p>Finally, a better way to do B2B research.Â <a href='https://www.newtonx.com/datascience/'>NewtonXÂ </a>The Worldâ€™s Leading B2B Market Research Company</p>
</li>
<li>
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a>Â be your guide.
Check it out atÂ <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://twitter.com/filippie509'>https://twitter.com/filippie509</a></li>
<li><a href='http://blog.piekniewski.info/'>http://blog.piekniewski.info/ (</a>On limits of deep learning and where to go next with AI.)</li>
</ol><p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. <br>
Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. <br>
<br>
If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.</p>
<p>Â </p>


Filip Piekniewski Bio<br>




<p>Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.</p>




Â 


<p>Sponsors</p>
<ul><li>
<p>Finally, a better way to do B2B research.Â <a href='https://www.newtonx.com/datascience/'>NewtonXÂ </a>The Worldâ€™s Leading B2B Market Research Company</p>
</li>
<li>
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a>Â be your guide.<br>
Check it out atÂ <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://twitter.com/filippie509'>https://twitter.com/filippie509</a></li>
<li><a href='http://blog.piekniewski.info/'>http://blog.piekniewski.info/ (</a>On limits of deep learning and where to go next with AI.)</li>
</ol><p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/yuihc5/debunking-agi-hype-reality.mp3" length="74453686" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.
Â 


Filip Piekniewski Bio



Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.




Â 


Sponsors

Finally, a better way to do B2B research.Â NewtonXÂ The Worldâ€™s Leading B2B Market Research Company


Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ Arctic WolfÂ be your guide.Check it out atÂ https://arcticwolf.com/datascience

AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
References
https://twitter.com/filippie509
http://blog.piekniewski.info/ (On limits of deep learning and where to go next with AI.)
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>59:29</itunes:duration>
                <itunes:episode>247</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Destroy your toaster before it kills you. Drama at OpenAI and other stories (Ep. 244)</title>
        <itunes:title>Destroy your toaster before it kills you. Drama at OpenAI and other stories (Ep. 244)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/destroy-your-toaster-before-it-kills-you-drama-at-openai-and-other-stories-ep-244/</link>
                    <comments>https://datascienceathome.podbean.com/e/destroy-your-toaster-before-it-kills-you-drama-at-openai-and-other-stories-ep-244/#comments</comments>        <pubDate>Fri, 01 Dec 2023 19:36:46 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6cfe4407-4702-38fa-bf8f-912866fe6d94</guid>
                                    <description><![CDATA[<p>Brace yourselves, dear friends! 
In this episode, we delve into the earth-shattering revelation that OpenAI might have stumbled upon AGI (lol) and we're all just seconds away from being replaced by highly sophisticated toasters (lol lol). 

Spoiler alert: OpenAI's CEO is just playing 7D chess with the entire human race. So, sit back, relax, and enjoy this totally not ominous exploration into the 'totally not happening' future of AI!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Brace yourselves, dear friends! <br>
In this episode, we delve into the earth-shattering revelation that OpenAI might have stumbled upon AGI (lol) and we're all just seconds away from being replaced by highly sophisticated toasters (lol lol). <br>
<br>
Spoiler alert: OpenAI's CEO is just playing 7D chess with the entire human race. So, sit back, relax, and enjoy this totally not ominous exploration into the 'totally not happening' future of AI!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/52vkby/openai-and-the-doomer-movement.mp3" length="34486572" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Brace yourselves, dear friends! In this episode, we delve into the earth-shattering revelation that OpenAI might have stumbled upon AGI (lol) and we're all just seconds away from being replaced by highly sophisticated toasters (lol lol). Spoiler alert: OpenAI's CEO is just playing 7D chess with the entire human race. So, sit back, relax, and enjoy this totally not ominous exploration into the 'totally not happening' future of AI!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:01</itunes:duration>
                <itunes:episode>246</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The AI Chip Chat ğŸ¤–ğŸ’» (Ep. 243)</title>
        <itunes:title>The AI Chip Chat ğŸ¤–ğŸ’» (Ep. 243)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-ai-chip-chat-%f0%9f%a4%96%f0%9f%92-ep-243/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-ai-chip-chat-%f0%9f%a4%96%f0%9f%92-ep-243/#comments</comments>        <pubDate>Mon, 20 Nov 2023 09:12:38 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/cdc78117-e95b-37aa-bfea-de43b9e6a1e6</guid>
                                    <description><![CDATA[<p>Dive into the cool world of AI chips with us! ğŸš€ We're breaking down how these special computer chips for AI have evolved and what makes them different. Think of them like the superheroes of the tech world!</p>
<p>Don't miss out! ğŸ™ï¸ğŸ” #AIChips #TechTalk #SimpleScience</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Dive into the cool world of AI chips with us! ğŸš€ We're breaking down how these special computer chips for AI have evolved and what makes them different. Think of them like the superheroes of the tech world!</p>
<p>Don't miss out! ğŸ™ï¸ğŸ” #AIChips #TechTalk #SimpleScience</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/y35yei/ai-chips.mp3" length="42557732" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Dive into the cool world of AI chips with us! ğŸš€ We're breaking down how these special computer chips for AI have evolved and what makes them different. Think of them like the superheroes of the tech world!
Don't miss out! ğŸ™ï¸ğŸ” #AIChips #TechTalk #SimpleScience]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:10</itunes:duration>
                <itunes:episode>245</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rolling the Dice: Engineering in an Uncertain World (Ep. 242)</title>
        <itunes:title>Rolling the Dice: Engineering in an Uncertain World (Ep. 242)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rolling-the-dice-engineering-in-an-uncertain-world-ep-242/</link>
                    <comments>https://datascienceathome.podbean.com/e/rolling-the-dice-engineering-in-an-uncertain-world-ep-242/#comments</comments>        <pubDate>Thu, 09 Nov 2023 17:40:38 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/288a9017-12f6-3a73-9254-43e91d0446db</guid>
                                    <description><![CDATA[<p>Hey there, engineering enthusiasts! Ever wondered how engineers deal with the wild, unpredictable twists and turns in their projects? In this episode, we're spilling the beans on uncertainty and why it's the secret sauce in every engineering recipe, not just the fancy stuff like deep learning and neural networks!</p>
<p>Join us for a ride through the world of uncertainty quantification. Tune in and let's demystify the unpredictable together! ğŸ²ğŸ”§ğŸš€</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.osti.gov/servlets/purl/1428000'>https://www.osti.gov/servlets/purl/1428000</a></p>
<p><a href='https://arc.aiaa.org/doi/pdf/10.2514/6.2010-124'>https://arc.aiaa.org/doi/pdf/10.2514/6.2010-124</a></p>
<p><a href='https://arxiv.org/pdf/2001.10411'>https://arxiv.org/pdf/2001.10411</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Hey there, engineering enthusiasts! Ever wondered how engineers deal with the wild, unpredictable twists and turns in their projects? In this episode, we're spilling the beans on uncertainty and why it's the secret sauce in every engineering recipe, not just the fancy stuff like deep learning and neural networks!</p>
<p>Join us for a ride through the world of uncertainty quantification. Tune in and let's demystify the unpredictable together! ğŸ²ğŸ”§ğŸš€</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.osti.gov/servlets/purl/1428000'>https://www.osti.gov/servlets/purl/1428000</a></p>
<p><a href='https://arc.aiaa.org/doi/pdf/10.2514/6.2010-124'>https://arc.aiaa.org/doi/pdf/10.2514/6.2010-124</a></p>
<p><a href='https://arxiv.org/pdf/2001.10411'>https://arxiv.org/pdf/2001.10411</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/bsgcrf/how-to-quantify-uncertainty.mp3" length="31023117" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Hey there, engineering enthusiasts! Ever wondered how engineers deal with the wild, unpredictable twists and turns in their projects? In this episode, we're spilling the beans on uncertainty and why it's the secret sauce in every engineering recipe, not just the fancy stuff like deep learning and neural networks!
Join us for a ride through the world of uncertainty quantification. Tune in and let's demystify the unpredictable together! ğŸ²ğŸ”§ğŸš€
Â 
References
https://www.osti.gov/servlets/purl/1428000
https://arc.aiaa.org/doi/pdf/10.2514/6.2010-124
https://arxiv.org/pdf/2001.10411
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:44</itunes:duration>
                <itunes:episode>244</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>How Language Models Are the Ultimate Database(Ep. 241)</title>
        <itunes:title>How Language Models Are the Ultimate Database(Ep. 241)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-language-models-are-the-ultimate-databaseep-241/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-language-models-are-the-ultimate-databaseep-241/#comments</comments>        <pubDate>Sun, 22 Oct 2023 08:48:02 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/80191a43-ffc6-385a-96e3-c7189002f98b</guid>
                                    <description><![CDATA[<p>In this episode, dive deep into the world of Language Models as we decode their intricate structure, revealing how these powerful algorithms exploit concepts from the past.</p>
<p>But... what if LLMs were just a database?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering'>https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, dive deep into the world of Language Models as we decode their intricate structure, revealing how these powerful algorithms exploit concepts from the past.</p>
<p>But... what if LLMs were just a database?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering'>https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nivv3w/llm-is-a-database.mp3" length="36401828" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, dive deep into the world of Language Models as we decode their intricate structure, revealing how these powerful algorithms exploit concepts from the past.
But... what if LLMs were just a database?
Â 
References
https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:26</itunes:duration>
                <itunes:episode>243</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Elon is right this time: Rust is the language of AI (Ep. 240)</title>
        <itunes:title>Elon is right this time: Rust is the language of AI (Ep. 240)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-is-the-language-of-ai-ep-240/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-is-the-language-of-ai-ep-240/#comments</comments>        <pubDate>Mon, 09 Oct 2023 09:14:13 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2e0ecfd1-a656-351a-814b-8dc4b1e8b1e9</guid>
                                    <description><![CDATA[


<p>In this episode, I delve into Elon Musk's foresight on the future of AI as he champions Rust programming language. 
Here is why Rust stands at the forefront of AI technology and the potential it holds.</p>



<p>References</p>
<p><a href='https://github.com/WasmEdge/mediapipe-rs'>https://github.com/WasmEdge/mediapipe-rs</a></p>
<p><a href='https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341'>https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, I delve into Elon Musk's foresight on the future of AI as he champions Rust programming language. <br>
Here is why Rust stands at the forefront of AI technology and the potential it holds.</p>



<p>References</p>
<p><a href='https://github.com/WasmEdge/mediapipe-rs'>https://github.com/WasmEdge/mediapipe-rs</a></p>
<p><a href='https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341'>https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xiksbh/rust-is-the-future-of-ai.mp3" length="32639103" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, I delve into Elon Musk's foresight on the future of AI as he champions Rust programming language. Here is why Rust stands at the forefront of AI technology and the potential it holds.



References
https://github.com/WasmEdge/mediapipe-rs
https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:05</itunes:duration>
                <itunes:episode>242</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Attacking LLMs for fun and profit (Ep. 239)</title>
        <itunes:title>Attacking LLMs for fun and profit (Ep. 239)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/attacking-llms-for-fun-and-profit-ep-239/</link>
                    <comments>https://datascienceathome.podbean.com/e/attacking-llms-for-fun-and-profit-ep-239/#comments</comments>        <pubDate>Mon, 18 Sep 2023 05:11:25 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/55ae8cc3-6958-3a8e-be5b-dc644eeca5a7</guid>
                                    <description><![CDATA[<p>As a continuation of Episode 238, I explain some effective and fun attacks to conduct against LLMs. Such attacks are even more effective on models served locally, that are hardly controlled by human feedback.</p>
<p>Have great fun and learn them responsibly.</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.jailbreakchat.com/'>https://www.jailbreakchat.com/</a></p>
<p><a href='https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/'>https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/</a></p>
<p><a href='https://arxiv.org/abs/2305.13860'>https://arxiv.org/abs/2305.13860</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>As a continuation of Episode 238, I explain some effective and fun attacks to conduct against LLMs. Such attacks are even more effective on models served locally, that are hardly controlled by human feedback.</p>
<p>Have great fun and learn them responsibly.</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.jailbreakchat.com/'>https://www.jailbreakchat.com/</a></p>
<p><a href='https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/'>https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/</a></p>
<p><a href='https://arxiv.org/abs/2305.13860'>https://arxiv.org/abs/2305.13860</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/eb8vce/attacking-large-language-models.mp3" length="29846167" type="audio/mpeg"/>
        <itunes:summary><![CDATA[As a continuation of Episode 238, I explain some effective and fun attacks to conduct against LLMs. Such attacks are even more effective on models served locally, that are hardly controlled by human feedback.
Have great fun and learn them responsibly.
Â 
References
https://www.jailbreakchat.com/
https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/
https://arxiv.org/abs/2305.13860
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:14</itunes:duration>
                <itunes:episode>241</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Unlocking Language Models: The Power of Prompt Engineering (Ep. 238)</title>
        <itunes:title>Unlocking Language Models: The Power of Prompt Engineering (Ep. 238)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/unlocking-language-models-the-power-of-prompt-engineering-ep-238/</link>
                    <comments>https://datascienceathome.podbean.com/e/unlocking-language-models-the-power-of-prompt-engineering-ep-238/#comments</comments>        <pubDate>Mon, 11 Sep 2023 08:00:14 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/dab686f8-e8b6-356e-991f-e6514c3602ce</guid>
                                    <description><![CDATA[<p>Join me on an enlightening journey through the world of prompt engineering. Explore the multifaceted skills and strategies involved in harnessing the potential of large language models for various applications. From enhancing safety measures to augmenting models with domain knowledge, learn how prompt engineering is shaping the future of AI.</p>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://arxiv.org/pdf/2109.01652.pdf'>https://arxiv.org/pdf/2109.01652.pdf</a></li>
<li><a href='https://arxiv.org/abs/2201.11903'>https://arxiv.org/abs/2201.11903</a></li>
<li><a href='https://arxiv.org/abs/2302.00923'>https://arxiv.org/abs/2302.00923</a></li>
<li><a href='https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering'>https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering</a></li>
<li><a href='https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job'>https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job</a></li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>Join me on an enlightening journey through the world of prompt engineering. Explore the multifaceted skills and strategies involved in harnessing the potential of large language models for various applications. From enhancing safety measures to augmenting models with domain knowledge, learn how prompt engineering is shaping the future of AI.</p>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://arxiv.org/pdf/2109.01652.pdf'>https://arxiv.org/pdf/2109.01652.pdf</a></li>
<li><a href='https://arxiv.org/abs/2201.11903'>https://arxiv.org/abs/2201.11903</a></li>
<li><a href='https://arxiv.org/abs/2302.00923'>https://arxiv.org/abs/2302.00923</a></li>
<li><a href='https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering'>https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering</a></li>
<li><a href='https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job'>https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job</a></li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ais8bm/prompt-engineering-techniques.mp3" length="36439716" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join me on an enlightening journey through the world of prompt engineering. Explore the multifaceted skills and strategies involved in harnessing the potential of large language models for various applications. From enhancing safety measures to augmenting models with domain knowledge, learn how prompt engineering is shaping the future of AI.
Â 
References
https://arxiv.org/pdf/2109.01652.pdf
https://arxiv.org/abs/2201.11903
https://arxiv.org/abs/2302.00923
https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering
https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:08</itunes:duration>
                <itunes:episode>240</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Erosion of Software Architecture Quality in the Age of AI Code Generation (Ep. 237)</title>
        <itunes:title>Erosion of Software Architecture Quality in the Age of AI Code Generation (Ep. 237)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/erosion-of-software-architecture-quality-in-the-age-of-ai-code-generation-ep-237/</link>
                    <comments>https://datascienceathome.podbean.com/e/erosion-of-software-architecture-quality-in-the-age-of-ai-code-generation-ep-237/#comments</comments>        <pubDate>Wed, 30 Aug 2023 08:51:58 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f3f9db8f-fbb1-351a-a664-2d6ef34d5b01</guid>
                                    <description><![CDATA[<p>In this era of AI-powered code generation, software architects are facing a concerning decline in the quality of their creations. The once meticulously crafted software architectures are now being compromised. Should LLMs be responsible?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://harmful.cat-v.org/cat-v/unix_prog_design.pdf'>Program Design in the UNIX Environment</a>
https://harmful.cat-v.org/cat-v/unix_prog_design.pdf</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this era of AI-powered code generation, software architects are facing a concerning decline in the quality of their creations. The once meticulously crafted software architectures are now being compromised. Should LLMs be responsible?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://harmful.cat-v.org/cat-v/unix_prog_design.pdf'>Program Design in the UNIX Environment</a><br>
https://harmful.cat-v.org/cat-v/unix_prog_design.pdf</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/bz3n48/quality-of-software-architectures.mp3" length="31076409" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this era of AI-powered code generation, software architects are facing a concerning decline in the quality of their creations. The once meticulously crafted software architectures are now being compromised. Should LLMs be responsible?
Â 
References
Program Design in the UNIX Environmenthttps://harmful.cat-v.org/cat-v/unix_prog_design.pdf]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:51</itunes:duration>
                <itunes:episode>239</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The new dimension of AI: Vector Databases (Ep. 236)</title>
        <itunes:title>The new dimension of AI: Vector Databases (Ep. 236)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-new-dimension-of-ai-vector-databases-ep-236/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-new-dimension-of-ai-vector-databases-ep-236/#comments</comments>        <pubDate>Thu, 17 Aug 2023 13:06:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/043d23dd-36e0-371b-86bd-4d3f8ddf1bb1</guid>
                                    <description><![CDATA[<p>Let's delve into the emerging trend in database design â€“ or is it really a new trend? 
The realm of vector databases and their revolutionary influence on AI and ML is making headlines. 
Come along as we investigate how these groundbreaking databases are revolutionizing the landscape of data storage, retrieval, and processing, ultimately unlocking the complete potential of artificial intelligence and machine learning. 
But are they genuinely as innovative as they seem?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://partee.io/2022/08/11/vector-embeddings/'>https://partee.io/2022/08/11/vector-embeddings/</a></p>
<p><a href='https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c'>https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c</a></p>
<p><a href='https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3'>https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Let's delve into the emerging trend in database design â€“ or is it really a new trend? <br>
The realm of vector databases and their revolutionary influence on AI and ML is making headlines. <br>
Come along as we investigate how these groundbreaking databases are revolutionizing the landscape of data storage, retrieval, and processing, ultimately unlocking the complete potential of artificial intelligence and machine learning. <br>
But are they genuinely as innovative as they seem?</p>
<p>Â </p>
<p>References</p>
<p><a href='https://partee.io/2022/08/11/vector-embeddings/'>https://partee.io/2022/08/11/vector-embeddings/</a></p>
<p><a href='https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c'>https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c</a></p>
<p><a href='https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3'>https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/3d52pw/vector-databases.mp3" length="34613794" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Let's delve into the emerging trend in database design â€“ or is it really a new trend? The realm of vector databases and their revolutionary influence on AI and ML is making headlines. Come along as we investigate how these groundbreaking databases are revolutionizing the landscape of data storage, retrieval, and processing, ultimately unlocking the complete potential of artificial intelligence and machine learning. But are they genuinely as innovative as they seem?
Â 
References
https://partee.io/2022/08/11/vector-embeddings/
https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c
https://medium.com/@ryanntk/choosing-the-right-embedding-model-a-guide-for-llm-applications-7a60180d28e3
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>27:16</itunes:duration>
                <itunes:episode>238</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Building Self Serve Business Intelligence With AI and LLMs at Zenlytic (Ep. 235)</title>
        <itunes:title>Building Self Serve Business Intelligence With AI and LLMs at Zenlytic (Ep. 235)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/building-self-serve-business-intelligence-with-ai-and-llms-at-zenlytic-ep-235/</link>
                    <comments>https://datascienceathome.podbean.com/e/building-self-serve-business-intelligence-with-ai-and-llms-at-zenlytic-ep-235/#comments</comments>        <pubDate>Fri, 04 Aug 2023 14:02:47 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7d01798b-524b-338a-ae0a-fbcfe3d84f38</guid>
                                    <description><![CDATA[<p>In this episode, we dive into the world of data analytics and artificial intelligence with Ryan, the CEO, and Paul, the CTO of Zenlytic. Having graduated from Harvard and with extensive backgrounds in venture capital, consulting, and data engineering, Ryan and Paul provide valuable insights into their journey of building Zenlytic, a cutting-edge analytics platform. 

Join us as we explore how Zenlytic's natural language interface enhances user experiences, enabling seamless access and analysis of analytics data. Discover how their self-service platform empowers teams to leverage business intelligence effectively, and learn about the unique features that set Zenlytic apart from other analytics platforms in the market. Delve into the crucial aspects of data security and privacy while granting team access, and find out how Zenlytic's analytics capabilities have transformed companies into data-driven decision-makers, ultimately improving their performance. 

</p>
References
<ul><li>Zenlytic Website: <a href='https://www.zenlytic.com/product'>https://www.zenlytic.com/product</a></li>
<li>AI Will Save the World (a16z): <a href='https://a16z.com/2023/06/06/ai-will-save-the-world/'>https://a16z.com/2023/06/06/ai-will-save-the-world/</a></li>
<li>Llama AI (ai.meta.com): <a href='https://ai.meta.com/llama/'>https://ai.meta.com/llama/</a></li>
<li>"Llama 2: Open Foundation and Fine-Tuned Chat Models" (arxiv.org): <a href='https://arxiv.org/abs/2307.09288'>https://arxiv.org/abs/2307.09288</a></li>
<li>"GPT-4 Technical Report" (arxiv.org): <a href='https://arxiv.org/abs/2303.08774'>https://arxiv.org/abs/2303.08774</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, we dive into the world of data analytics and artificial intelligence with Ryan, the CEO, and Paul, the CTO of Zenlytic. Having graduated from Harvard and with extensive backgrounds in venture capital, consulting, and data engineering, Ryan and Paul provide valuable insights into their journey of building Zenlytic, a cutting-edge analytics platform. <br>
<br>
Join us as we explore how Zenlytic's natural language interface enhances user experiences, enabling seamless access and analysis of analytics data. Discover how their self-service platform empowers teams to leverage business intelligence effectively, and learn about the unique features that set Zenlytic apart from other analytics platforms in the market. Delve into the crucial aspects of data security and privacy while granting team access, and find out how Zenlytic's analytics capabilities have transformed companies into data-driven decision-makers, ultimately improving their performance. <br>
<br>
</p>
References
<ul><li>Zenlytic Website: <a href='https://www.zenlytic.com/product'>https://www.zenlytic.com/product</a></li>
<li>AI Will Save the World (a16z): <a href='https://a16z.com/2023/06/06/ai-will-save-the-world/'>https://a16z.com/2023/06/06/ai-will-save-the-world/</a></li>
<li>Llama AI (ai.meta.com): <a href='https://ai.meta.com/llama/'>https://ai.meta.com/llama/</a></li>
<li>"Llama 2: Open Foundation and Fine-Tuned Chat Models" (arxiv.org): <a href='https://arxiv.org/abs/2307.09288'>https://arxiv.org/abs/2307.09288</a></li>
<li>"GPT-4 Technical Report" (arxiv.org): <a href='https://arxiv.org/abs/2303.08774'>https://arxiv.org/abs/2303.08774</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/mjsmdn/zenlytic-llm-analytics.mp3" length="60235812" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, we dive into the world of data analytics and artificial intelligence with Ryan, the CEO, and Paul, the CTO of Zenlytic. Having graduated from Harvard and with extensive backgrounds in venture capital, consulting, and data engineering, Ryan and Paul provide valuable insights into their journey of building Zenlytic, a cutting-edge analytics platform. Join us as we explore how Zenlytic's natural language interface enhances user experiences, enabling seamless access and analysis of analytics data. Discover how their self-service platform empowers teams to leverage business intelligence effectively, and learn about the unique features that set Zenlytic apart from other analytics platforms in the market. Delve into the crucial aspects of data security and privacy while granting team access, and find out how Zenlytic's analytics capabilities have transformed companies into data-driven decision-makers, ultimately improving their performance. 
References
Zenlytic Website: https://www.zenlytic.com/product
AI Will Save the World (a16z): https://a16z.com/2023/06/06/ai-will-save-the-world/
Llama AI (ai.meta.com): https://ai.meta.com/llama/
"Llama 2: Open Foundation and Fine-Tuned Chat Models" (arxiv.org): https://arxiv.org/abs/2307.09288
"GPT-4 Technical Report" (arxiv.org): https://arxiv.org/abs/2303.08774
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>47:37</itunes:duration>
                <itunes:episode>237</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner (Ep. 234)</title>
        <itunes:title>Money, Cryptocurrencies, and AI: Exploring the Future of Finance with Chris Skinner (Ep. 234)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-ep-234/</link>
                    <comments>https://datascienceathome.podbean.com/e/money-cryptocurrencies-and-ai-exploring-the-future-of-finance-with-chris-skinner-ep-234/#comments</comments>        <pubDate>Sun, 09 Jul 2023 21:37:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d2f43379-52f8-3d81-be62-5dff9ae825eb</guid>
                                    <description><![CDATA[<p>In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. 
From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. 
Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. 
Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.</p>
<p>Â </p>
<p>You can read about Chris at <a href='https://thefinanser.com/'>https://thefinanser.com/</a></p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps and
tools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use their
Macs as an actual working tool, covering complete use cases like coding, designing, project and time
management and so on. Once subscribed, you get full access to paid features of the apps, as well as to
new apps that are being constantly added.
So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you do
your work more efficiently for just a fraction of the price. Get 7 days for free at <a href='https://stpp.co/dsat'>https://stpp.co/dsat</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. <br>
From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. <br>
Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. <br>
Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.</p>
<p>Â </p>
<p>You can read about Chris at <a href='https://thefinanser.com/'>https://thefinanser.com/</a></p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps and<br>
tools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use their<br>
Macs as an actual working tool, covering complete use cases like coding, designing, project and time<br>
management and so on. Once subscribed, you get full access to paid features of the apps, as well as to<br>
new apps that are being constantly added.<br>
So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you do<br>
your work more efficiently for just a fraction of the price. Get 7 days for free at <a href='https://stpp.co/dsat'>https://stpp.co/dsat</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ix9vfu/ai-crypto-future-finance.mp3" length="53324649" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this captivating podcast episode, join renowned financial expert Chris Skinner as he delves into the fascinating realm of the future of money. From cryptocurrencies to government currencies, the metaverse to artificial intelligence (AI), Skinner explores the intricate interplay between technology and humanity. Gain valuable insights as he defines the future of money, examines the potential impact of cryptocurrencies on traditional government currencies, and addresses the advantages and disadvantages of digital currencies. Delve into the complex issues of regulation and governance in the context of emerging financial technologies, and discover Skinner's unique perspective on the metaverse and its implications for the future of money and technology. Brace yourself for an enlightening discussion on the integration of AI in the financial sector and its potential impact on humanity. Tune in to explore the cutting-edge concepts that shape our financial landscape and get a glimpse of what lies ahead.
Â 
You can read about Chris at https://thefinanser.com/
Â 
Sponsors
This episode is sponsored by Setapp.Â  Setapp is a platform that combines 230+ powerful MacOS and iOS apps andtools under one $9.99 subscription. Their selection of apps is mostly helpful for people who use theirMacs as an actual working tool, covering complete use cases like coding, designing, project and timemanagement and so on. Once subscribed, you get full access to paid features of the apps, as well as tonew apps that are being constantly added.So youâ€™ll always be sure youâ€™re not missing out on any cool apps and services that actually help you doyour work more efficiently for just a fraction of the price. Get 7 days for free at https://stpp.co/dsat
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>41:21</itunes:duration>
                <itunes:episode>236</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Debunking AGI Hype and Embracing Reality (Ep. 233)</title>
        <itunes:title>Debunking AGI Hype and Embracing Reality (Ep. 233)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/debunking-agi-hype-and-embracing-reality-ep-233/</link>
                    <comments>https://datascienceathome.podbean.com/e/debunking-agi-hype-and-embracing-reality-ep-233/#comments</comments>        <pubDate>Mon, 26 Jun 2023 13:37:33 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/4ba08666-6829-3eb8-a17e-84ea5cef7523</guid>
                                    <description><![CDATA[<p>In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. 
Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. 

If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.</p>
<p>Â </p>


Filip Piekniewski Bio




<p>Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.</p>




Â 


<p>Sponsors</p>
<ul><li>
<p>Finally, a better way to do B2B research.Â <a href='https://www.newtonx.com/datascience/'>NewtonXÂ </a>The Worldâ€™s Leading B2B Market Research Company</p>
</li>
<li>
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a>Â be your guide.
Check it out atÂ <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://twitter.com/filippie509'>https://twitter.com/filippie509</a></li>
<li><a href='http://blog.piekniewski.info/'>http://blog.piekniewski.info/ (</a>On limits of deep learning and where to go next with AI.)</li>
</ol><p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. <br>
Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. <br>
<br>
If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.</p>
<p>Â </p>


Filip Piekniewski Bio<br>




<p>Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.</p>




Â 


<p>Sponsors</p>
<ul><li>
<p>Finally, a better way to do B2B research.Â <a href='https://www.newtonx.com/datascience/'>NewtonXÂ </a>The Worldâ€™s Leading B2B Market Research Company</p>
</li>
<li>
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a>Â be your guide.<br>
Check it out atÂ <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
</li>
<li><a href='https://amethix.com/'>Amethix</a>Â works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://twitter.com/filippie509'>https://twitter.com/filippie509</a></li>
<li><a href='http://blog.piekniewski.info/'>http://blog.piekniewski.info/ (</a>On limits of deep learning and where to go next with AI.)</li>
</ol><p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/yuihc5/debunking-agi-hype-reality.mp3" length="74453686" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this thought-provoking episode, we sit down with the renowned AI expert, Filip Piekniewski, Phd, who fearlessly challenges the prevailing narratives surrounding artificial general intelligence (AGI) and the singularity. With a no-nonsense approach and a deep understanding of the field, Filip dismantles the hype and exposes some of the misconceptions about AI, LLMs and AGI. Join us as we delve into the real-world implications of AI, separating fact from fiction, and gaining a firm grasp on the tangible possibilities of AI advancement. If you're seeking a refreshingly pragmatic perspective on the future of AI, this episode is an absolute must-listen.
Â 


Filip Piekniewski Bio



Filip Piekniewski is a distinguished computer vision researcher and engineer, specializing in visual object tracking and perception. He approaches machine learning with a pragmatic mindset, recognizing its current limitations. Filip earned his Ph.D. from Warsaw University, where he explored neuroscience and later joined Brain Corporation in San Diego. His extensive study of neuroscience inspired him to develop innovative, bio-inspired machine learning architectures. Filip's unique blend of scientific curiosity and software engineering expertise allows him to quickly prototype and implement new ideas. He is known for his realistic perspective on AI, debunking AGI hype and focusing on tangible advancements.




Â 


Sponsors

Finally, a better way to do B2B research.Â NewtonXÂ The Worldâ€™s Leading B2B Market Research Company


Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. LetÂ Arctic WolfÂ be your guide.Check it out atÂ https://arcticwolf.com/datascience

AmethixÂ works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
References
https://twitter.com/filippie509
http://blog.piekniewski.info/ (On limits of deep learning and where to go next with AI.)
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>59:29</itunes:duration>
                <itunes:episode>235</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Full steam ahead! Unraveling Forward-Forward Neural Networks (Ep. 232)</title>
        <itunes:title>Full steam ahead! Unraveling Forward-Forward Neural Networks (Ep. 232)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/full-steam-ahead-unraveling-forward-forward-neural-networks-ep-232/</link>
                    <comments>https://datascienceathome.podbean.com/e/full-steam-ahead-unraveling-forward-forward-neural-networks-ep-232/#comments</comments>        <pubDate>Thu, 15 Jun 2023 20:34:22 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b6b72b02-6467-37cb-9dc1-eb65a442aa51</guid>
                                    <description><![CDATA[<p>In this exciting episode, we dive into the world of Forward-Forward Neural Networks, unveiling their mind-boggling power and potential. 
Join us as we demystify these advanced AI algorithms and explore how they're reshaping industries and revolutionizing machine learning. 
From self-driving cars to personalized medicine, discover the cutting-edge applications that are propelling us into a new era of AI greatness. 
Get ready to unlock the secrets of Forward-Forward Neural Networks and witness the future of artificial intelligence unfold before your eyes. 
Don't miss out â€“ tune in now and be part of the AI revolution!</p>
Sponsors
<ul><li>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></li>
<li><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/2212.13345'>The Forward-Forward Algorithm: Some Preliminary Investigations</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this exciting episode, we dive into the world of Forward-Forward Neural Networks, unveiling their mind-boggling power and potential. <br>
Join us as we demystify these advanced AI algorithms and explore how they're reshaping industries and revolutionizing machine learning. <br>
From self-driving cars to personalized medicine, discover the cutting-edge applications that are propelling us into a new era of AI greatness. <br>
Get ready to unlock the secrets of Forward-Forward Neural Networks and witness the future of artificial intelligence unfold before your eyes. <br>
Don't miss out â€“ tune in now and be part of the AI revolution!</p>
Sponsors
<ul><li>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></li>
<li><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.</li>
</ul>
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/2212.13345'>The Forward-Forward Algorithm: Some Preliminary Investigations</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/n6upwz/forward-forward-neural-networks.mp3" length="31628759" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this exciting episode, we dive into the world of Forward-Forward Neural Networks, unveiling their mind-boggling power and potential. Join us as we demystify these advanced AI algorithms and explore how they're reshaping industries and revolutionizing machine learning. From self-driving cars to personalized medicine, discover the cutting-edge applications that are propelling us into a new era of AI greatness. Get ready to unlock the secrets of Forward-Forward Neural Networks and witness the future of artificial intelligence unfold before your eyes. Don't miss out â€“ tune in now and be part of the AI revolution!
Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Defense, Robotics and Predictive maintenance.
Â 
References
The Forward-Forward Algorithm: Some Preliminary Investigations
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:35</itunes:duration>
                <itunes:episode>234</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The LLM Battle Begins: Google Bard vs ChatGPT (Ep. 231)</title>
        <itunes:title>The LLM Battle Begins: Google Bard vs ChatGPT (Ep. 231)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-llm-battle-begins-google-bard-vs-chatgpt/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-llm-battle-begins-google-bard-vs-chatgpt/#comments</comments>        <pubDate>Tue, 06 Jun 2023 06:30:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d499a075-4a8c-3b86-801c-e9cd280d2d59</guid>
                                    <description><![CDATA[<p>Brace yourselves as we uncover the mind-blowing AI model, Google Bard, that's poised to challenge ChatGPT and other conversational AI systems. Join us as we explore the revolutionary features of Bard, its cutting-edge architecture, and its ability to generate human-like responses. Discover why AI enthusiasts are buzzing with excitement. References: [1] [2] [3]</p>
<p>Â </p>
<p>Sponsors</p>
<p>Finally, a better way to do B2B research. <a href='https://www.newtonx.com/datascience/'>NewtonX </a>The World's Leading B2B Market Research Company</p>
<p>Â </p>
<p>References</p>
<ol><li>
<p>Google Unveils Palm-2: Its Revolutionary AI Model.Â  <a href='https://datascientest.com/en/google-unveils-palm-2-its-revolutionary-ai-model'>https://datascientest.com/en/google-unveils-palm-2-its-revolutionary-ai-model</a></p>
</li>
<li>
<p>Google AI - Discover Palm-2 <a href='https://ai.google/discover/palm2/'>https://ai.google/discover/palm2/</a></p>
</li>
<li>
<p>"Palm-2: A Large Scale Language Model for Conversational AI." ArXiv preprint arXiv:2305.10403 (2023).Â  <a href='https://arxiv.org/abs/2305.10403'>https://arxiv.org/abs/2305.10403</a></p>
</li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>Brace yourselves as we uncover the mind-blowing AI model, Google Bard, that's poised to challenge ChatGPT and other conversational AI systems. Join us as we explore the revolutionary features of Bard, its cutting-edge architecture, and its ability to generate human-like responses. Discover why AI enthusiasts are buzzing with excitement. References: [1] [2] [3]</p>
<p>Â </p>
<p>Sponsors</p>
<p>Finally, a better way to do B2B research. <a href='https://www.newtonx.com/datascience/'>NewtonX </a>The World's Leading B2B Market Research Company</p>
<p>Â </p>
<p>References</p>
<ol><li>
<p>Google Unveils Palm-2: Its Revolutionary AI Model.Â  <a href='https://datascientest.com/en/google-unveils-palm-2-its-revolutionary-ai-model'>https://datascientest.com/en/google-unveils-palm-2-its-revolutionary-ai-model</a></p>
</li>
<li>
<p>Google AI - Discover Palm-2 <a href='https://ai.google/discover/palm2/'>https://ai.google/discover/palm2/</a></p>
</li>
<li>
<p>"Palm-2: A Large Scale Language Model for Conversational AI." ArXiv preprint arXiv:2305.10403 (2023).Â  <a href='https://arxiv.org/abs/2305.10403'>https://arxiv.org/abs/2305.10403</a></p>
</li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ddgp96/llm-war-started.mp3" length="33352122" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Brace yourselves as we uncover the mind-blowing AI model, Google Bard, that's poised to challenge ChatGPT and other conversational AI systems. Join us as we explore the revolutionary features of Bard, its cutting-edge architecture, and its ability to generate human-like responses. Discover why AI enthusiasts are buzzing with excitement. References: [1] [2] [3]
Â 
Sponsors
Finally, a better way to do B2B research. NewtonX The World's Leading B2B Market Research Company
Â 
References

Google Unveils Palm-2: Its Revolutionary AI Model.Â  https://datascientest.com/en/google-unveils-palm-2-its-revolutionary-ai-model


Google AI - Discover Palm-2 https://ai.google/discover/palm2/


"Palm-2: A Large Scale Language Model for Conversational AI." ArXiv preprint arXiv:2305.10403 (2023).Â  https://arxiv.org/abs/2305.10403

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:03</itunes:duration>
                <itunes:episode>233</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Unleashing the Force: Blending Neural Networks and Physics for Epic Predictions (Ep. 230)</title>
        <itunes:title>Unleashing the Force: Blending Neural Networks and Physics for Epic Predictions (Ep. 230)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/unleashing-the-force-blending-neural-networks-and-physics-for-epic-predictions-ep-230/</link>
                    <comments>https://datascienceathome.podbean.com/e/unleashing-the-force-blending-neural-networks-and-physics-for-epic-predictions-ep-230/#comments</comments>        <pubDate>Tue, 30 May 2023 06:39:21 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b8bfb51c-80ee-3853-9544-a0e79a7ed143</guid>
                                    <description><![CDATA[<p>In this enlightening episode of our podcast, we delve into the fascinating realm of Physics Informed Neural Networks (PINNs) and explore how they combine the extraordinary prediction capabilities of neural networks with the unparalleled accuracy of physics models.</p>
<p>Join us as we unravel the mysteries behind PINNs and their potential to revolutionize various scientific and engineering domains. We'll discuss the underlying principles that enable these networks to incorporate physical laws and constraints, resulting in enhanced predictions and a deeper understanding of complex systems.</p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is supported by Mimecast - the email security solution that every business needs. With Mimecast, you get a security solution that is specifically designed for email and workplace collaboration. Head to <a href='https://mimecast.com'>mimecast.com</a> for a free trial.</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<p class="project-name">Physics Informed Deep Learning <a href='https://maziarraissi.github.io/PINNs/'>https://maziarraissi.github.io/PINNs/</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this enlightening episode of our podcast, we delve into the fascinating realm of Physics Informed Neural Networks (PINNs) and explore how they combine the extraordinary prediction capabilities of neural networks with the unparalleled accuracy of physics models.</p>
<p>Join us as we unravel the mysteries behind PINNs and their potential to revolutionize various scientific and engineering domains. We'll discuss the underlying principles that enable these networks to incorporate physical laws and constraints, resulting in enhanced predictions and a deeper understanding of complex systems.</p>
<p>Â </p>
<p>Sponsors</p>
<p>This episode is supported by Mimecast - the email security solution that every business needs. With Mimecast, you get a security solution that is specifically designed for email and workplace collaboration. Head to <a href='https://mimecast.com'>mimecast.com</a> for a free trial.</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<p class="project-name">Physics Informed Deep Learning <a href='https://maziarraissi.github.io/PINNs/'>https://maziarraissi.github.io/PINNs/</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/zdcat3/physics-informed-neural-networks.mp3" length="39502276" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this enlightening episode of our podcast, we delve into the fascinating realm of Physics Informed Neural Networks (PINNs) and explore how they combine the extraordinary prediction capabilities of neural networks with the unparalleled accuracy of physics models.
Join us as we unravel the mysteries behind PINNs and their potential to revolutionize various scientific and engineering domains. We'll discuss the underlying principles that enable these networks to incorporate physical laws and constraints, resulting in enhanced predictions and a deeper understanding of complex systems.
Â 
Sponsors
This episode is supported by Mimecast - the email security solution that every business needs. With Mimecast, you get a security solution that is specifically designed for email and workplace collaboration. Head to mimecast.com for a free trial.
Â 
Â 
References
Physics Informed Deep Learning https://maziarraissi.github.io/PINNs/]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:56</itunes:duration>
                <itunes:episode>232</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AIâ€™s Impact on Software Engineering: Killing Old Principles? [RB] (Ep. 229)</title>
        <itunes:title>AIâ€™s Impact on Software Engineering: Killing Old Principles? [RB] (Ep. 229)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-s-impact-on-software-engineering-killing-old-principles-rb-ep-229/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-s-impact-on-software-engineering-killing-old-principles-rb-ep-229/#comments</comments>        <pubDate>Thu, 25 May 2023 06:46:41 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/39826a21-7e4a-3bab-bb7e-d70b50a91503</guid>
                                    <description><![CDATA[


<p>In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.</p>
<p>Â </p>
Sponsors
Bloomberg
<p>At Bloomberg, they solve complex, real-world problems for customers across the global capital markets. From real-time market data to sophisticated analytics, powerful trading tools, and more, Bloomberg engineers work with systems that operate at scale. 
If you're a software engineer looking for an exciting and fulfilling career, head over to <a href='https://bloomberg.com/careers'>bloomberg.com/careers</a> to learn more. 
</p>
Â 
Arctic Wolf
<p>Cybercriminals are evolving. Their techniques and tactics are more advanced, intricate, and dangerous than ever before. Industries and governments around the world are fighting back, unveiling new regulations meant to better protect data against this rising threat. Arctic Wolf â€” the leader in security operations â€” is on a mission to end cyber risk by giving organizations the protection, information, and confidence they need to protect their people, technology, and data. 
Visit <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a> to take your first step.</p>


]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.</p>
<p>Â </p>
Sponsors
Bloomberg
<p>At Bloomberg, they solve complex, real-world problems for customers across the global capital markets. From real-time market data to sophisticated analytics, powerful trading tools, and more, Bloomberg engineers work with systems that operate at scale. <br>
If you're a software engineer looking for an exciting and fulfilling career, head over to <a href='https://bloomberg.com/careers'>bloomberg.com/careers</a> to learn more. <br>
</p>
Â <br>
Arctic Wolf
<p>Cybercriminals are evolving. Their techniques and tactics are more advanced, intricate, and dangerous than ever before. Industries and governments around the world are fighting back, unveiling new regulations meant to better protect data against this rising threat. Arctic Wolf â€” the leader in security operations â€” is on a mission to end cyber risk by giving organizations the protection, information, and confidence they need to protect their people, technology, and data. <br>
Visit <a href='https://arcticwolf.com/datascience'>arcticwolf.com/datascience</a> to take your first step.</p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/twyjre/ai-killing-software-engineering-RB.mp3" length="19606354" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.
Â 
Sponsors
Bloomberg
At Bloomberg, they solve complex, real-world problems for customers across the global capital markets. From real-time market data to sophisticated analytics, powerful trading tools, and more, Bloomberg engineers work with systems that operate at scale. If you're a software engineer looking for an exciting and fulfilling career, head over to bloomberg.com/careers to learn more. 
Â Arctic Wolf
Cybercriminals are evolving. Their techniques and tactics are more advanced, intricate, and dangerous than ever before. Industries and governments around the world are fighting back, unveiling new regulations meant to better protect data against this rising threat. Arctic Wolf â€” the leader in security operations â€” is on a mission to end cyber risk by giving organizations the protection, information, and confidence they need to protect their people, technology, and data. Visit arcticwolf.com/datascience to take your first step.


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>13:54</itunes:duration>
                <itunes:episode>231</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Warning! Mathematical Mayhem Ahead: Demystifying Liquid Time-Constant Networks (Ep. 228)</title>
        <itunes:title>Warning! Mathematical Mayhem Ahead: Demystifying Liquid Time-Constant Networks (Ep. 228)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/warning-mathematical-mayhem-ahead-demystifying-liquid-time-constant-networks-ep-228/</link>
                    <comments>https://datascienceathome.podbean.com/e/warning-mathematical-mayhem-ahead-demystifying-liquid-time-constant-networks-ep-228/#comments</comments>        <pubDate>Tue, 16 May 2023 06:17:57 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/90215a76-7f96-3994-bff5-b0f01e183ea8</guid>
                                    <description><![CDATA[<p>Hold on to your calculators and buckle up for a wild mathematical ride in this episode! Brace yourself as we dive into the fascinating realm of Liquid Time-Constant Networks (LTCs), where mathematical content reaches new heights of excitement.</p>
<p>In this mind-bending adventure, we demystify the intricacies of LTCs, from complex equations to mind-boggling mathematical concepts, we break them down into digestible explanations.</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.science.org/doi/10.1126/scirobotics.adc8892'>https://www.science.org/doi/10.1126/scirobotics.adc8892</a></p>
<p><a href='https://spectrum.ieee.org/liquid-neural-networks#toggle-gdpr'>https://spectrum.ieee.org/liquid-neural-networks#toggle-gdpr</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Hold on to your calculators and buckle up for a wild mathematical ride in this episode! Brace yourself as we dive into the fascinating realm of Liquid Time-Constant Networks (LTCs), where mathematical content reaches new heights of excitement.</p>
<p>In this mind-bending adventure, we demystify the intricacies of LTCs, from complex equations to mind-boggling mathematical concepts, we break them down into digestible explanations.</p>
<p>Â </p>
<p>References</p>
<p><a href='https://www.science.org/doi/10.1126/scirobotics.adc8892'>https://www.science.org/doi/10.1126/scirobotics.adc8892</a></p>
<p><a href='https://spectrum.ieee.org/liquid-neural-networks#toggle-gdpr'>https://spectrum.ieee.org/liquid-neural-networks#toggle-gdpr</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pcqsem/liquid-neural-networks.mp3" length="27253984" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Hold on to your calculators and buckle up for a wild mathematical ride in this episode! Brace yourself as we dive into the fascinating realm of Liquid Time-Constant Networks (LTCs), where mathematical content reaches new heights of excitement.
In this mind-bending adventure, we demystify the intricacies of LTCs, from complex equations to mind-boggling mathematical concepts, we break them down into digestible explanations.
Â 
References
https://www.science.org/doi/10.1126/scirobotics.adc8892
https://spectrum.ieee.org/liquid-neural-networks#toggle-gdpr
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:59</itunes:duration>
                <itunes:episode>230</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Efficiently Retraining Language Models: How to Level Up Without Breaking the Bank (Ep. 227)</title>
        <itunes:title>Efficiently Retraining Language Models: How to Level Up Without Breaking the Bank (Ep. 227)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/efficiently-retraining-language-models-how-to-level-up-without-breaking-the-bank-ep-227/</link>
                    <comments>https://datascienceathome.podbean.com/e/efficiently-retraining-language-models-how-to-level-up-without-breaking-the-bank-ep-227/#comments</comments>        <pubDate>Thu, 11 May 2023 07:54:18 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/56e498ef-a67e-3231-a77f-028bf6571565</guid>
                                    <description><![CDATA[<p>Get ready for an eye-opening episode! ğŸ™ï¸</p>
<p>In our latest podcast episode, we dive deep into the world of LoRa (Low-Rank Adaptation) for large language models (LLMs). This groundbreaking technique is revolutionizing the way we approach language model training by leveraging low-rank approximations.</p>
<p>Join us as we unravel the mysteries of LoRa and discover how it enables us to retrain LLMs with minimal expenditure of money and resources. We'll explore the ingenious strategies and practical methods that empower you to fine-tune your language models without breaking the bank.</p>
<p>Whether you're a researcher, developer, or language model enthusiast, this episode is packed with invaluable insights. Learn how to unlock the potential of LLMs without draining your resources.</p>
<p>Tune in and join the conversation as we unravel the secrets of LoRa low-rank adaptation and show you how to retrain LLMs on a budget.</p>
<p>Listen to the full episode now on your favorite podcast platform! ğŸ§âœ¨</p>
Â 
References
<ul><li class="title mathjax">LoRA: Low-Rank Adaptation of Large Language Models <a href='https://arxiv.org/abs/2106.09685'>https://arxiv.org/abs/2106.09685</a></li>
<li class="firstHeading mw-first-heading">Low-rank approximation <a href='https://en.wikipedia.org/wiki/Low-rank_approximation'>https://en.wikipedia.org/wiki/Low-rank_approximation</a></li>
<li>Attention is all you need <a href='https://arxiv.org/pdf/1706.03762.pdf'>https://arxiv.org/pdf/1706.03762.pdf</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Get ready for an eye-opening episode! ğŸ™ï¸</p>
<p>In our latest podcast episode, we dive deep into the world of LoRa (Low-Rank Adaptation) for large language models (LLMs). This groundbreaking technique is revolutionizing the way we approach language model training by leveraging low-rank approximations.</p>
<p>Join us as we unravel the mysteries of LoRa and discover how it enables us to retrain LLMs with minimal expenditure of money and resources. We'll explore the ingenious strategies and practical methods that empower you to fine-tune your language models without breaking the bank.</p>
<p>Whether you're a researcher, developer, or language model enthusiast, this episode is packed with invaluable insights. Learn how to unlock the potential of LLMs without draining your resources.</p>
<p>Tune in and join the conversation as we unravel the secrets of LoRa low-rank adaptation and show you how to retrain LLMs on a budget.</p>
<p>Listen to the full episode now on your favorite podcast platform! ğŸ§âœ¨</p>
Â 
References
<ul><li class="title mathjax">LoRA: Low-Rank Adaptation of Large Language Models <a href='https://arxiv.org/abs/2106.09685'>https://arxiv.org/abs/2106.09685</a></li>
<li class="firstHeading mw-first-heading">Low-rank approximation <a href='https://en.wikipedia.org/wiki/Low-rank_approximation'>https://en.wikipedia.org/wiki/Low-rank_approximation</a></li>
<li>Attention is all you need <a href='https://arxiv.org/pdf/1706.03762.pdf'>https://arxiv.org/pdf/1706.03762.pdf</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/hbyym4/train-llm-fast-lora.mp3" length="43982531" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Get ready for an eye-opening episode! ğŸ™ï¸
In our latest podcast episode, we dive deep into the world of LoRa (Low-Rank Adaptation) for large language models (LLMs). This groundbreaking technique is revolutionizing the way we approach language model training by leveraging low-rank approximations.
Join us as we unravel the mysteries of LoRa and discover how it enables us to retrain LLMs with minimal expenditure of money and resources. We'll explore the ingenious strategies and practical methods that empower you to fine-tune your language models without breaking the bank.
Whether you're a researcher, developer, or language model enthusiast, this episode is packed with invaluable insights. Learn how to unlock the potential of LLMs without draining your resources.
Tune in and join the conversation as we unravel the secrets of LoRa low-rank adaptation and show you how to retrain LLMs on a budget.
Listen to the full episode now on your favorite podcast platform! ğŸ§âœ¨
Â 
References
LoRA: Low-Rank Adaptation of Large Language Models https://arxiv.org/abs/2106.09685
Low-rank approximation https://en.wikipedia.org/wiki/Low-rank_approximation
Attention is all you need https://arxiv.org/pdf/1706.03762.pdf
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:50</itunes:duration>
                <itunes:episode>229</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Revolutionize Your AI Game: How Running Large Language Models Locally Gives You an Unfair Advantage Over Big Tech Giants (Ep. 226)</title>
        <itunes:title>Revolutionize Your AI Game: How Running Large Language Models Locally Gives You an Unfair Advantage Over Big Tech Giants (Ep. 226)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-llm-revolution-ep-225/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-llm-revolution-ep-225/#comments</comments>        <pubDate>Wed, 03 May 2023 16:47:22 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/053a7a3f-384f-339b-8af2-1fa76f8276d1</guid>
                                    <description><![CDATA[


<p>This is the first episode about the latest trend in artificial intelligence that's shaking up the industry - running large language models locally on your machine. This new approach allows you to bypass the limitations and constraints of cloud-based models controlled by big tech companies, and take control of your own AI journey.</p>
<p>We'll delve into the benefits of running models locally, such as increased speed, improved privacy and security, and greater customization and flexibility. We'll also discuss the technical requirements and considerations for running these models on your own hardware, and provide practical tips and advice to get you started.</p>
<p>Join us as we uncover the secrets to unleashing the full potential of large language models and taking your AI game to the next level!</p>
<p>
Sponsors</p>
<p>AI-powered Email Security Best-in-class protection against the most sophisticated attacks,
from phishing and impersonation to BEC and zero-day threats 
<a href='https://www.mimecast.com/'>https://www.mimecast.com/</a></p>
<p>Â </p>
<p class="app-h1">Â </p>



<p>References </p>
<ul><li><a href='https://agi-sphere.com/llama-models/'>https://agi-sphere.com/llama-models/</a></li>
<li><a href='https://crfm.stanford.edu/2023/03/13/alpaca.html'>https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li>
<li><a href='https://beebom.com/how-run-chatgpt-like-language-model-pc-offline/'>https://beebom.com/how-run-chatgpt-like-language-model-pc-offline/</a></li>
<li><a href='https://sharegpt.com/'>https://sharegpt.com/</a></li>
<li><a href='https://stability.ai/'>https://stability.ai/</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[


<p>This is the first episode about the latest trend in artificial intelligence that's shaking up the industry - running large language models locally on your machine. This new approach allows you to bypass the limitations and constraints of cloud-based models controlled by big tech companies, and take control of your own AI journey.</p>
<p>We'll delve into the benefits of running models locally, such as increased speed, improved privacy and security, and greater customization and flexibility. We'll also discuss the technical requirements and considerations for running these models on your own hardware, and provide practical tips and advice to get you started.</p>
<p>Join us as we uncover the secrets to unleashing the full potential of large language models and taking your AI game to the next level!</p>
<p><br>
Sponsors</p>
<p>AI-powered Email Security Best-in-class protection against the most sophisticated attacks,<br>
from phishing and impersonation to BEC and zero-day threats <br>
<a href='https://www.mimecast.com/'>https://www.mimecast.com/</a></p>
<p>Â </p>
<p class="app-h1">Â </p>



<p>References </p>
<ul><li><a href='https://agi-sphere.com/llama-models/'>https://agi-sphere.com/llama-models/</a></li>
<li><a href='https://crfm.stanford.edu/2023/03/13/alpaca.html'>https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li>
<li><a href='https://beebom.com/how-run-chatgpt-like-language-model-pc-offline/'>https://beebom.com/how-run-chatgpt-like-language-model-pc-offline/</a></li>
<li><a href='https://sharegpt.com/'>https://sharegpt.com/</a></li>
<li><a href='https://stability.ai/'>https://stability.ai/</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/62pkw3/local-llms-revolution.mp3" length="54469333" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


This is the first episode about the latest trend in artificial intelligence that's shaking up the industry - running large language models locally on your machine. This new approach allows you to bypass the limitations and constraints of cloud-based models controlled by big tech companies, and take control of your own AI journey.
We'll delve into the benefits of running models locally, such as increased speed, improved privacy and security, and greater customization and flexibility. We'll also discuss the technical requirements and considerations for running these models on your own hardware, and provide practical tips and advice to get you started.
Join us as we uncover the secrets to unleashing the full potential of large language models and taking your AI game to the next level!
Sponsors
AI-powered Email Security Best-in-class protection against the most sophisticated attacks,from phishing and impersonation to BEC and zero-day threats https://www.mimecast.com/
Â 
Â 



References 
https://agi-sphere.com/llama-models/
https://crfm.stanford.edu/2023/03/13/alpaca.html
https://beebom.com/how-run-chatgpt-like-language-model-pc-offline/
https://sharegpt.com/
https://stability.ai/
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>43:42</itunes:duration>
                <itunes:episode>228</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust: A Journey to High-Performance and Confidence in Code at Amethix Technologies (Ep. 225)</title>
        <itunes:title>Rust: A Journey to High-Performance and Confidence in Code at Amethix Technologies (Ep. 225)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-a-journey-to-high-performance-and-confidence-in-code-at-amethix-technologies-ep-225/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-a-journey-to-high-performance-and-confidence-in-code-at-amethix-technologies-ep-225/#comments</comments>        <pubDate>Wed, 26 Apr 2023 08:43:21 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/8b807c8f-0461-3813-9982-12c22c9f9b3e</guid>
                                    <description><![CDATA[<p>The journey of porting our projects to Rust was intense, but it was a decision we made to improve the quality of our software. The migration was not an easy task, as it required a considerable amount of time and resources. However, it was worth the effort as we have seen significant improvements in code reusability, code cleanliness, and performance.
In this episode I will tell you why you should consider taking that journey too.</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>The journey of porting our projects to Rust was intense, but it was a decision we made to improve the quality of our software. The migration was not an easy task, as it required a considerable amount of time and resources. However, it was worth the effort as we have seen significant improvements in code reusability, code cleanliness, and performance.<br>
In this episode I will tell you why you should consider taking that journey too.</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/rgdy26/rust-high-performance-journey.mp3" length="36498556" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The journey of porting our projects to Rust was intense, but it was a decision we made to improve the quality of our software. The migration was not an easy task, as it required a considerable amount of time and resources. However, it was worth the effort as we have seen significant improvements in code reusability, code cleanliness, and performance.In this episode I will tell you why you should consider taking that journey too.
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>27:16</itunes:duration>
                <itunes:episode>227</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The Power of Graph Neural Networks: Understanding the Future of AI - Part 2/2 (Ep.224)</title>
        <itunes:title>The Power of Graph Neural Networks: Understanding the Future of AI - Part 2/2 (Ep.224)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-power-of-graph-neural-networks-understanding-the-future-of-ai-part-22-ep224/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-power-of-graph-neural-networks-understanding-the-future-of-ai-part-22-ep224/#comments</comments>        <pubDate>Tue, 18 Apr 2023 14:15:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a4814cca-9bbe-3452-b7da-bd2c85bd7114</guid>
                                    <description><![CDATA[


<p>In this episode of our podcast, we dive deep into the fascinating world of Graph Neural Networks.</p>
<p>First, we explore Hierarchical Networks, which allow for the efficient representation and analysis of complex graph structures by breaking them down into smaller, more manageable components.</p>
<p>Next, we turn our attention to Generative Graph Models, which enable the creation of new graph structures that are similar to those in a given dataset. We discuss the inner workings of these models and their potential applications in fields such as drug discovery and social network analysis.</p>
<p>Finally, we delve into the essential Pooling Mechanism, which allows for the efficient passing of information across different parts of the graph neural network. We examine the various types of pooling mechanisms and their advantages and disadvantages.</p>
<p>Whether you're a seasoned graph neural network expert or just starting to explore the field, this episode has something for you. So join us for a deep dive into the power and potential of Graph Neural Networks.</p>
<p>Â </p>
References
<p>Machine Learning with Graphs - <a href='http://web.stanford.edu/class/cs224w/'>http://web.stanford.edu/class/cs224w/</a></p>
<p class="title mathjax">A Comprehensive Survey on Graph Neural Networks - <a href='https://arxiv.org/abs/1901.00596'>https://arxiv.org/abs/1901.00596</a></p>


]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode of our podcast, we dive deep into the fascinating world of Graph Neural Networks.</p>
<p>First, we explore Hierarchical Networks, which allow for the efficient representation and analysis of complex graph structures by breaking them down into smaller, more manageable components.</p>
<p>Next, we turn our attention to Generative Graph Models, which enable the creation of new graph structures that are similar to those in a given dataset. We discuss the inner workings of these models and their potential applications in fields such as drug discovery and social network analysis.</p>
<p>Finally, we delve into the essential Pooling Mechanism, which allows for the efficient passing of information across different parts of the graph neural network. We examine the various types of pooling mechanisms and their advantages and disadvantages.</p>
<p>Whether you're a seasoned graph neural network expert or just starting to explore the field, this episode has something for you. So join us for a deep dive into the power and potential of Graph Neural Networks.</p>
<p>Â </p>
References
<p>Machine Learning with Graphs - <a href='http://web.stanford.edu/class/cs224w/'>http://web.stanford.edu/class/cs224w/</a></p>
<p class="title mathjax">A Comprehensive Survey on Graph Neural Networks - <a href='https://arxiv.org/abs/1901.00596'>https://arxiv.org/abs/1901.00596</a></p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/d4pifu/graph-neural-networks-part-2-2.mp3" length="47363419" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode of our podcast, we dive deep into the fascinating world of Graph Neural Networks.
First, we explore Hierarchical Networks, which allow for the efficient representation and analysis of complex graph structures by breaking them down into smaller, more manageable components.
Next, we turn our attention to Generative Graph Models, which enable the creation of new graph structures that are similar to those in a given dataset. We discuss the inner workings of these models and their potential applications in fields such as drug discovery and social network analysis.
Finally, we delve into the essential Pooling Mechanism, which allows for the efficient passing of information across different parts of the graph neural network. We examine the various types of pooling mechanisms and their advantages and disadvantages.
Whether you're a seasoned graph neural network expert or just starting to explore the field, this episode has something for you. So join us for a deep dive into the power and potential of Graph Neural Networks.
Â 
References
Machine Learning with Graphs - http://web.stanford.edu/class/cs224w/
A Comprehensive Survey on Graph Neural Networks - https://arxiv.org/abs/1901.00596


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>35:32</itunes:duration>
                <itunes:episode>226</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The Power of Graph Neural Networks: Understanding the Future of AI - Part 1/2 (Ep.223)</title>
        <itunes:title>The Power of Graph Neural Networks: Understanding the Future of AI - Part 1/2 (Ep.223)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-power-of-graph-neural-networks-understanding-the-future-of-ai-part-12-ep223/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-power-of-graph-neural-networks-understanding-the-future-of-ai-part-12-ep223/#comments</comments>        <pubDate>Tue, 11 Apr 2023 12:02:18 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/aaf5b2c1-4c50-3bca-8641-e1401f3c291a</guid>
                                    <description><![CDATA[<p>In this episode, I explore the cutting-edge technology of graph neural networks (GNNs) and how they are revolutionizing the field of artificial intelligence. I break down the complex concepts behind GNNs and explain how they work by modeling the relationships between data points in a graph structure.</p>
<p>I also delve into the various real-world applications of GNNs, from drug discovery to recommendation systems, and how they are outperforming traditional machine learning models. </p>
<p>Join me and demystify this exciting area of AI research and discover the power of graph neural networks.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, I explore the cutting-edge technology of graph neural networks (GNNs) and how they are revolutionizing the field of artificial intelligence. I break down the complex concepts behind GNNs and explain how they work by modeling the relationships between data points in a graph structure.</p>
<p>I also delve into the various real-world applications of GNNs, from drug discovery to recommendation systems, and how they are outperforming traditional machine learning models. </p>
<p>Join me and demystify this exciting area of AI research and discover the power of graph neural networks.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/rn6tr3/graph-neural-networks-1-2.mp3" length="35958371" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, I explore the cutting-edge technology of graph neural networks (GNNs) and how they are revolutionizing the field of artificial intelligence. I break down the complex concepts behind GNNs and explain how they work by modeling the relationships between data points in a graph structure.
I also delve into the various real-world applications of GNNs, from drug discovery to recommendation systems, and how they are outperforming traditional machine learning models. 
Join me and demystify this exciting area of AI research and discover the power of graph neural networks.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>27:40</itunes:duration>
                <itunes:episode>225</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Leveling Up AI: Reinforcement Learning with Human Feedback (Ep. 222)</title>
        <itunes:title>Leveling Up AI: Reinforcement Learning with Human Feedback (Ep. 222)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ep-222/</link>
                    <comments>https://datascienceathome.podbean.com/e/ep-222/#comments</comments>        <pubDate>Tue, 04 Apr 2023 18:21:12 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/87b99e9b-4562-3327-888f-bf7ffb89f177</guid>
                                    <description><![CDATA[<p>In this episode, we dive into the not-so-secret sauce of ChatGPT, and what makes it a different model than its predecessors in the field of NLP and Large Language Models.</p>
<p>We explore how human feedback can be used to speed up the learning process in reinforcement learning, making it more efficient and effective.</p>
<p>Whether you're a machine learning practitioner, researcher, or simply curious about how machines learn, this episode will give you a fascinating glimpse into the world of reinforcement learning with human feedback.</p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='https://www.eff.org/how-to-fix-the-internet-podcast'> How to Fix the Internet</a>, a cool podcast from the Electronic Frontier Foundation and <a href='https://www.bloomberg.com'>Bloomberg</a>, global provider of financial news and information, including real-time and historical price data, financial data, trading news, and analyst coverage.
</p>
<p>Â </p>
References

<p class="text-2xl text-blue-400 my-0">Learning through human feedback</p>

<p><a href='https://www.deepmind.com/blog/learning-through-human-feedback'>https://www.deepmind.com/blog/learning-through-human-feedback</a></p>
<p>Â </p>
<p class="title mathjax">Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</p>
<p>https://arxiv.org/abs/2204.05862</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, we dive into the not-so-secret sauce of ChatGPT, and what makes it a different model than its predecessors in the field of NLP and Large Language Models.</p>
<p>We explore how human feedback can be used to speed up the learning process in reinforcement learning, making it more efficient and effective.</p>
<p>Whether you're a machine learning practitioner, researcher, or simply curious about how machines learn, this episode will give you a fascinating glimpse into the world of reinforcement learning with human feedback.</p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='https://www.eff.org/how-to-fix-the-internet-podcast'><em> How to Fix the Internet</em></a>, a cool podcast from the Electronic Frontier Foundation and <a href='https://www.bloomberg.com'>Bloomberg</a>, global provider of financial news and information, including real-time and historical price data, financial data, trading news, and analyst coverage.<br>
</p>
<p>Â </p>
References

<p class="text-2xl text-blue-400 my-0">Learning through human feedback</p>

<p><a href='https://www.deepmind.com/blog/learning-through-human-feedback'>https://www.deepmind.com/blog/learning-through-human-feedback</a></p>
<p>Â </p>
<p class="title mathjax">Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</p>
<p>https://arxiv.org/abs/2204.05862</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uu6if8/reinforcement-learning-human-feedback.mp3" length="33374766" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, we dive into the not-so-secret sauce of ChatGPT, and what makes it a different model than its predecessors in the field of NLP and Large Language Models.
We explore how human feedback can be used to speed up the learning process in reinforcement learning, making it more efficient and effective.
Whether you're a machine learning practitioner, researcher, or simply curious about how machines learn, this episode will give you a fascinating glimpse into the world of reinforcement learning with human feedback.
Â 
Sponsors
This episode is supported by  How to Fix the Internet, a cool podcast from the Electronic Frontier Foundation and Bloomberg, global provider of financial news and information, including real-time and historical price data, financial data, trading news, and analyst coverage.
Â 
References

Learning through human feedback

https://www.deepmind.com/blog/learning-through-human-feedback
Â 
Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback
https://arxiv.org/abs/2204.05862]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:39</itunes:duration>
                <itunes:episode>224</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The promise and pitfalls of GPT-4 (Ep. 221)</title>
        <itunes:title>The promise and pitfalls of GPT-4 (Ep. 221)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-promise-and-pitfalls-of-gpt-4-ep-221/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-promise-and-pitfalls-of-gpt-4-ep-221/#comments</comments>        <pubDate>Thu, 30 Mar 2023 09:39:28 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2ea5cbaf-9ac1-329a-b164-ad3c61e9f6b9</guid>
                                    <description><![CDATA[


<p>In this episode, we explore the potential of the highly anticipated GPT-4 language model and the challenges that come with its development. From its ability to generate highly coherent and creative text to concerns about ethical considerations and the potential misuse of such technology, we delve into the promise and pitfalls of GPT-4. 
Join us as we speak with experts in the field to gain insights into the latest developments and the impact that GPT-4 could have on the future of natural language processing.</p>
<p>Â </p>
<p>Â </p>


]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, we explore the potential of the highly anticipated GPT-4 language model and the challenges that come with its development. From its ability to generate highly coherent and creative text to concerns about ethical considerations and the potential misuse of such technology, we delve into the promise and pitfalls of GPT-4. <br>
Join us as we speak with experts in the field to gain insights into the latest developments and the impact that GPT-4 could have on the future of natural language processing.</p>
<p>Â </p>
<p>Â </p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7mcibk/promise-and-pitfallse-gpt4.mp3" length="37997008" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, we explore the potential of the highly anticipated GPT-4 language model and the challenges that come with its development. From its ability to generate highly coherent and creative text to concerns about ethical considerations and the potential misuse of such technology, we delve into the promise and pitfalls of GPT-4. Join us as we speak with experts in the field to gain insights into the latest developments and the impact that GPT-4 could have on the future of natural language processing.
Â 
Â 


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:38</itunes:duration>
                <itunes:episode>223</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AIâ€™s Impact on Software Engineering: Killing Old Principles? (Ep. 220)</title>
        <itunes:title>AIâ€™s Impact on Software Engineering: Killing Old Principles? (Ep. 220)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-s-impact-on-software-engineering-killing-old-principles/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-s-impact-on-software-engineering-killing-old-principles/#comments</comments>        <pubDate>Tue, 14 Mar 2023 18:22:58 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5690c260-675f-3c61-b8bd-9321c3b5ba3a</guid>
                                    <description><![CDATA[


<p>In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.</p>


]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.</p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/eyw33r/ai-killing-software-engineering.mp3" length="18524168" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, we dive into the ways in which AI and machine learning are disrupting traditional software engineering principles. With the advent of automation and intelligent systems, developers are increasingly relying on algorithms to create efficient and effective code. However, this reliance on AI can come at a cost to the tried-and-true methods of software engineering. Join us as we explore the pros and cons of this paradigm shift and discuss what it means for the future of software development.


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>13:26</itunes:duration>
                <itunes:episode>222</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Edge AI applications for military and space [RB] (Ep. 219)</title>
        <itunes:title>Edge AI applications for military and space [RB] (Ep. 219)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/edge-ai-applications-for-military-and-space-rb-ep-219/</link>
                    <comments>https://datascienceathome.podbean.com/e/edge-ai-applications-for-military-and-space-rb-ep-219/#comments</comments>        <pubDate>Thu, 09 Mar 2023 08:42:58 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5dc2ef2f-3a44-3331-ba6f-ce6c77c0aa76</guid>
                                    <description><![CDATA[]]></description>
                                                            <content:encoded><![CDATA[]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wdbmin/edge-military-space-rb-2.mp3" length="28399284" type="audio/mpeg"/>
        <itunes:summary><![CDATA[]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:59</itunes:duration>
                <itunes:episode>221</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Prove It Without Revealing It: Exploring the Power of Zero-Knowledge Proofs in Data Science (Ep. 218)</title>
        <itunes:title>Prove It Without Revealing It: Exploring the Power of Zero-Knowledge Proofs in Data Science (Ep. 218)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/prove-it-without-revealing-it-exploring-the-power-of-zero-knowledge-proofs-in-data-science-ep-218/</link>
                    <comments>https://datascienceathome.podbean.com/e/prove-it-without-revealing-it-exploring-the-power-of-zero-knowledge-proofs-in-data-science-ep-218/#comments</comments>        <pubDate>Mon, 27 Feb 2023 09:11:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/06f486cd-c3ea-327f-a11f-1fe74d72e9d2</guid>
                                    <description><![CDATA[


<p>In this episode, we dive into the fascinating world of zero-knowledge proofs and their impact on data science. Zero-knowledge proofs allow one party to prove to another that they know a secret without revealing the secret itself. This powerful concept has numerous applications in data science, from ensuring data privacy and security, to facilitating secure transactions and identity verification. We explore the mechanics of zero-knowledge proofs, its real-world applications, and how it is revolutionizing the way we handle sensitive information. 
Join us as we uncover the secrets of zero-knowledge proofs and its impact on the future of data science.</p>
<p>Â </p>
Sponsors
<p>Want to enjoy the 4K video anytime, anywhere?</p>
<p>With ASUS ZenWiFi you can. Asus ZenWiFi XD5 mesh system puts your WiFi on steroids. It has a super easy Setup, with Flexible Network Naming, Lifelong free AiProtection and of course WiFi 6 technology. With Asus ZenWifi XD5 you get superfast, reliable and secure WiFi connections in every corner of your home!
With Asus ZenWifi XD5, you get the best WiFi experience!</p>
<p>Find more atÂ  <a href='https://asus.click/ZenWiFi_XD5'>https://asus.click/ZenWiFi_XD5</a></p>


]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, we dive into the fascinating world of zero-knowledge proofs and their impact on data science. Zero-knowledge proofs allow one party to prove to another that they know a secret without revealing the secret itself. This powerful concept has numerous applications in data science, from ensuring data privacy and security, to facilitating secure transactions and identity verification. We explore the mechanics of zero-knowledge proofs, its real-world applications, and how it is revolutionizing the way we handle sensitive information. <br>
Join us as we uncover the secrets of zero-knowledge proofs and its impact on the future of data science.</p>
<p>Â </p>
Sponsors
<p>Want to enjoy the 4K video anytime, anywhere?</p>
<p>With ASUS ZenWiFi you can. Asus ZenWiFi XD5 mesh system puts your WiFi on steroids. It has a super easy Setup, with Flexible Network Naming, Lifelong free AiProtection and of course WiFi 6 technology. With Asus ZenWifi XD5 you get superfast, reliable and secure WiFi connections in every corner of your home!<br>
With Asus ZenWifi XD5, you get the best WiFi experience!</p>
<p>Find more atÂ  <a href='https://asus.click/ZenWiFi_XD5'>https://asus.click/ZenWiFi_XD5</a></p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nkj4me/zero-knowledge-proofs-data-science.mp3" length="21122427" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, we dive into the fascinating world of zero-knowledge proofs and their impact on data science. Zero-knowledge proofs allow one party to prove to another that they know a secret without revealing the secret itself. This powerful concept has numerous applications in data science, from ensuring data privacy and security, to facilitating secure transactions and identity verification. We explore the mechanics of zero-knowledge proofs, its real-world applications, and how it is revolutionizing the way we handle sensitive information. Join us as we uncover the secrets of zero-knowledge proofs and its impact on the future of data science.
Â 
Sponsors
Want to enjoy the 4K video anytime, anywhere?
With ASUS ZenWiFi you can. Asus ZenWiFi XD5 mesh system puts your WiFi on steroids. It has a super easy Setup, with Flexible Network Naming, Lifelong free AiProtection and of course WiFi 6 technology. With Asus ZenWifi XD5 you get superfast, reliable and secure WiFi connections in every corner of your home!With Asus ZenWifi XD5, you get the best WiFi experience!
Find more atÂ  https://asus.click/ZenWiFi_XD5


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:52</itunes:duration>
                <itunes:episode>220</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Deep learning vs tabular models (Ep. 217)</title>
        <itunes:title>Deep learning vs tabular models (Ep. 217)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/deep-learning-vs-tabular-models/</link>
                    <comments>https://datascienceathome.podbean.com/e/deep-learning-vs-tabular-models/#comments</comments>        <pubDate>Tue, 21 Feb 2023 09:32:27 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a668309d-2525-356f-bfd6-e6badc549465</guid>
                                    <description><![CDATA[<p>Deep learning methods are not as effective with tabular data. Here is why, and what to do about it.</p>
<p>Â </p>
<p>Sponsors</p>
<p>If you're ready to take your WiFi game to the next level, head over to <a href='http://asus.click/ZenWiFi_XD5'>asus.click/ZenWiFi_XD5</a> or check out the show notes for this episode. Trust me, with ASUS ZenWiFi XD5, you'll get the best WiFi experience ever!</p>
<p>Â </p>
<p>References</p>
<ul><li><a href='https://paperswithcode.com/methods/category/deep-tabular-learning'>https://paperswithcode.com/methods/category/deep-tabular-learningÂ </a></li>
<li><a href='https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/'>https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Deep learning methods are not as effective with tabular data. Here is why, and what to do about it.</p>
<p>Â </p>
<p>Sponsors</p>
<p>If you're ready to take your WiFi game to the next level, head over to <a href='http://asus.click/ZenWiFi_XD5'>asus.click/ZenWiFi_XD5</a> or check out the show notes for this episode. Trust me, with ASUS ZenWiFi XD5, you'll get the best WiFi experience ever!</p>
<p>Â </p>
<p>References</p>
<ul><li><a href='https://paperswithcode.com/methods/category/deep-tabular-learning'>https://paperswithcode.com/methods/category/deep-tabular-learningÂ </a></li>
<li><a href='https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/'>https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uhxb6i/dl-vs-tabular-models.mp3" length="38782916" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Deep learning methods are not as effective with tabular data. Here is why, and what to do about it.
Â 
Sponsors
If you're ready to take your WiFi game to the next level, head over to asus.click/ZenWiFi_XD5 or check out the show notes for this episode. Trust me, with ASUS ZenWiFi XD5, you'll get the best WiFi experience ever!
Â 
References
https://paperswithcode.com/methods/category/deep-tabular-learningÂ 
https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:25</itunes:duration>
                <itunes:episode>205</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>[RB] Online learning is better than batch, right? Wrong! (Ep. 216)</title>
        <itunes:title>[RB] Online learning is better than batch, right? Wrong! (Ep. 216)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-online-learning-is-better-than-batch-right-wrong-ep-216/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-online-learning-is-better-than-batch-right-wrong-ep-216/#comments</comments>        <pubDate>Wed, 15 Feb 2023 07:56:53 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2e2888f0-e6c0-36f8-b6fd-bcb9d1e7463d</guid>
                                    <description><![CDATA[<p>In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.
Also in this episode, I have to deal with an intruder :)</p>
<p>Â </p>
<p>Â </p>
<p>Links</p>
<p>Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87. pp.Â 123â€“138. <a href='https://en.wikipedia.org/wiki/Doi_(identifier)'>doi</a>:<a href='https://doi.org/10.1145%2F41457.37515'>10.1145/41457.37515</a>. <a href='https://en.wikipedia.org/wiki/ISBN_(identifier)'>ISBN</a>Â <a href='https://en.wikipedia.org/wiki/Special:BookSources/089791242X'>089791242X</a>. <a href='https://en.wikipedia.org/wiki/S2CID_(identifier)'>S2CID</a>Â <a href='https://api.semanticscholar.org/CorpusID:7739589'>7739589</a>.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.<br>
Also in this episode, I have to deal with an intruder :)</p>
<p>Â </p>
<p>Â </p>
<p>Links</p>
<p>Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". <em>Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87</em>. pp.Â 123â€“138. <a href='https://en.wikipedia.org/wiki/Doi_(identifier)'>doi</a>:<a href='https://doi.org/10.1145%2F41457.37515'>10.1145/41457.37515</a>. <a href='https://en.wikipedia.org/wiki/ISBN_(identifier)'>ISBN</a>Â <a href='https://en.wikipedia.org/wiki/Special:BookSources/089791242X'>089791242X</a>. <a href='https://en.wikipedia.org/wiki/S2CID_(identifier)'>S2CID</a>Â <a href='https://api.semanticscholar.org/CorpusID:7739589'>7739589</a>.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nkvyiy/online-learning.mp3" length="37910420" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.Also in this episode, I have to deal with an intruder :)
Â 
Â 
Links
Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87. pp.Â 123â€“138. doi:10.1145/41457.37515. ISBNÂ 089791242X. S2CIDÂ 7739589.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:08</itunes:duration>
                <itunes:episode>219</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Chatting with ChatGPT: Pros and Cons of Advanced Language AI (Ep. 215)</title>
        <itunes:title>Chatting with ChatGPT: Pros and Cons of Advanced Language AI (Ep. 215)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/chatting-with-chatgpt-pros-and-cons-of-advanced-language-ai/</link>
                    <comments>https://datascienceathome.podbean.com/e/chatting-with-chatgpt-pros-and-cons-of-advanced-language-ai/#comments</comments>        <pubDate>Thu, 26 Jan 2023 09:00:09 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/09359882-9623-333a-9252-878d9916aaa8</guid>
                                    <description><![CDATA[


<p>In this episode, I'll be discussing the capabilities and limitations of ChatGPT, an advanced language AI model. I'll go over its power to understand and respond to natural language, and its applications in tasks such as language translation and text summarization. 
However, I'll also touch on the challenges that still need to be overcome such as bias and data privacy concerns. 

Tune in for a comprehensive look at the current state of advanced language AI.</p>



<p>Â </p>
<p>References</p>
<p><a href='https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/'>https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[


<p>In this episode, I'll be discussing the capabilities and limitations of ChatGPT, an advanced language AI model. I'll go over its power to understand and respond to natural language, and its applications in tasks such as language translation and text summarization. <br>
However, I'll also touch on the challenges that still need to be overcome such as bias and data privacy concerns. <br>
<br>
Tune in for a comprehensive look at the current state of advanced language AI.</p>



<p>Â </p>
<p>References</p>
<p><a href='https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/'>https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/u8syz7/limitations-chatgpt.mp3" length="40961827" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


In this episode, I'll be discussing the capabilities and limitations of ChatGPT, an advanced language AI model. I'll go over its power to understand and respond to natural language, and its applications in tasks such as language translation and text summarization. However, I'll also touch on the challenges that still need to be overcome such as bias and data privacy concerns. Tune in for a comprehensive look at the current state of advanced language AI.



Â 
References
https://datascienceathome.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-about-one-of-the-greatest-minds-in-history/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:27</itunes:duration>
                <itunes:episode>218</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Accelerating Perception Development with Synthetic Data (Ep. 214)</title>
        <itunes:title>Accelerating Perception Development with Synthetic Data (Ep. 214)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/a-novel-method-to-generate-reliable-data-with-parallel-domain-ceo-kevin-mcnamara-ep-214/</link>
                    <comments>https://datascienceathome.podbean.com/e/a-novel-method-to-generate-reliable-data-with-parallel-domain-ceo-kevin-mcnamara-ep-214/#comments</comments>        <pubDate>Sat, 14 Jan 2023 17:04:02 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/da62e61f-bd03-3a05-b1f3-53bb26583744</guid>
                                    <description><![CDATA[

In this episode I am with Kevin McNamara, founder and CEO of Parallel Domain. We speak about a very effective method to generate synthetic data that is currently in production at Parallel Domain.
Enjoy the show!
Â 
Â 
References
Parallel Domain Synthetic Data Improves Cyclist Detection (blog post):
<a href='https://paralleldomain.com/parallel-domain-synthetic-data-improves-cyclist-detection/'>https://paralleldomain.com/parallel-domain-synthetic-data-improves-cyclist-detection/</a>Â 
Â 
Beating the State of the Art in Object Tracking with Synthetic Data:
<a href='https://paralleldomain.com/beating-the-state-of-the-art-in-object-tracking-with-synthetic-data/'>https://paralleldomain.com/beating-the-state-of-the-art-in-object-tracking-with-synthetic-data/</a>Â 
Â 
Parallel Domain Open Synthetic Dataset:
<a href='https://paralleldomain.com/open-datasets/bicycle-detection'>https://paralleldomain.com/open-datasets/bicycle-detection</a>Â 
Â 
How Toyota Research Institute Trains Better Computer Vision Models with PD Synthetic DataÂ (interview):
<a href='https://www.youtube.com/watch?v=QIYttoVxf2w'>https://www.youtube.com/watch?v=QIYttoVxf2w</a>
Â 
Career Opportunities:
<a href='https://paralleldomain.com/careers'>https://paralleldomain.com/careers</a>

]]></description>
                                                            <content:encoded><![CDATA[

In this episode I am with Kevin McNamara, founder and CEO of Parallel Domain. We speak about a very effective method to generate synthetic data that is currently in production at Parallel Domain.
Enjoy the show!
Â 
Â 
References
Parallel Domain Synthetic Data Improves Cyclist Detection (blog post):
<a href='https://paralleldomain.com/parallel-domain-synthetic-data-improves-cyclist-detection/'>https://paralleldomain.com/parallel-domain-synthetic-data-improves-cyclist-detection/</a>Â 
Â 
Beating the State of the Art in Object Tracking with Synthetic Data:
<a href='https://paralleldomain.com/beating-the-state-of-the-art-in-object-tracking-with-synthetic-data/'>https://paralleldomain.com/beating-the-state-of-the-art-in-object-tracking-with-synthetic-data/</a>Â 
Â 
Parallel Domain Open Synthetic Dataset:
<a href='https://paralleldomain.com/open-datasets/bicycle-detection'>https://paralleldomain.com/open-datasets/bicycle-detection</a>Â 
Â 
How Toyota Research Institute Trains Better Computer Vision Models with PD Synthetic DataÂ (interview):
<a href='https://www.youtube.com/watch?v=QIYttoVxf2w'>https://www.youtube.com/watch?v=QIYttoVxf2w</a>
Â 
Career Opportunities:
<a href='https://paralleldomain.com/careers'>https://paralleldomain.com/careers</a>

]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/v2yfqd/parallel-domain.mp3" length="46247854" type="audio/mpeg"/>
        <itunes:summary><![CDATA[

In this episode I am with Kevin McNamara, founder and CEO of Parallel Domain. We speak about a very effective method to generate synthetic data that is currently in production at Parallel Domain.
Enjoy the show!
Â 
Â 
References
Parallel Domain Synthetic Data Improves Cyclist Detection (blog post):
https://paralleldomain.com/parallel-domain-synthetic-data-improves-cyclist-detection/Â 
Â 
Beating the State of the Art in Object Tracking with Synthetic Data:
https://paralleldomain.com/beating-the-state-of-the-art-in-object-tracking-with-synthetic-data/Â 
Â 
Parallel Domain Open Synthetic Dataset:
https://paralleldomain.com/open-datasets/bicycle-detectionÂ 
Â 
How Toyota Research Institute Trains Better Computer Vision Models with PD Synthetic DataÂ (interview):
https://www.youtube.com/watch?v=QIYttoVxf2w
Â 
Career Opportunities:
https://paralleldomain.com/careers

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>42:06</itunes:duration>
                <itunes:episode>217</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Edge AI applications for military and space [RB] (Ep. 213)</title>
        <itunes:title>Edge AI applications for military and space [RB] (Ep. 213)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/edge-ai-applications-for-military-and-space-rb-ep-213/</link>
                    <comments>https://datascienceathome.podbean.com/e/edge-ai-applications-for-military-and-space-rb-ep-213/#comments</comments>        <pubDate>Tue, 13 Dec 2022 18:50:48 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2fff4ba8-2bdb-3d7c-858b-3f08e79cd721</guid>
                                    <description><![CDATA[Our Sponsors
<p>NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ 
need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.</p>
<p>See NordPass Business in action now with a 3-month free trial here
<a href='https://nordpass.com/datascience'>https://nordpass.com/DATASCIENCE</a> with code DATASCIENCE</p>
<p>Â </p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[Our Sponsors
<p>NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ <br>
need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.</p>
<p>See NordPass Business in action now with a 3-month free trial here<br>
<a href='https://nordpass.com/datascience'>https://nordpass.com/DATASCIENCE</a> with code DATASCIENCE</p>
<p>Â </p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/qr4z3t/edge-military-space-rb.mp3" length="28914562" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsors
NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.
See NordPass Business in action now with a 3-month free trial herehttps://nordpass.com/DATASCIENCE with code DATASCIENCE
Â 
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:59</itunes:duration>
                <itunes:episode>216</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>From image to 3D model (Ep. 212)</title>
        <itunes:title>From image to 3D model (Ep. 212)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/from-image-to-3d-model/</link>
                    <comments>https://datascienceathome.podbean.com/e/from-image-to-3d-model/#comments</comments>        <pubDate>Thu, 08 Dec 2022 10:14:08 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/9b490024-6881-3064-ab74-e80d2dc39d78</guid>
                                    <description><![CDATA[<p>Is it possible to reconstruct a 3D model from a simple image?</p>
<p>Under certain constraints, it is! 
In this episode I tell you how.</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>

References
<p><a href='https://github.com/isl-org/Open3D'>https://github.com/isl-org/Open3D</a></p>
<p><a href='https://huggingface.co/docs/transformers/model_doc/glpn'>https://huggingface.co/docs/transformers/model_doc/glpn</a></p>
<p><a href='https://arxiv.org/abs/2201.07436'>https://arxiv.org/abs/2201.07436</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Is it possible to reconstruct a 3D model from a simple image?</p>
<p>Under certain constraints, it is! <br>
In this episode I tell you how.</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
<br>
References
<p><a href='https://github.com/isl-org/Open3D'>https://github.com/isl-org/Open3D</a></p>
<p><a href='https://huggingface.co/docs/transformers/model_doc/glpn'>https://huggingface.co/docs/transformers/model_doc/glpn</a></p>
<p><a href='https://arxiv.org/abs/2201.07436'>https://arxiv.org/abs/2201.07436</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4vbkb9/from-image-to-3d-model.mp3" length="29107422" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Is it possible to reconstruct a 3D model from a simple image?
Under certain constraints, it is! In this episode I tell you how.
Â 
Our Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â 
References
https://github.com/isl-org/Open3D
https://huggingface.co/docs/transformers/model_doc/glpn
https://arxiv.org/abs/2201.07436
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:45</itunes:duration>
                <itunes:episode>215</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Machine learning is physics (Ep. 211)</title>
        <itunes:title>Machine learning is physics (Ep. 211)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/machine-learning-is-physics-ep-211/</link>
                    <comments>https://datascienceathome.podbean.com/e/machine-learning-is-physics-ep-211/#comments</comments>        <pubDate>Fri, 02 Dec 2022 19:37:03 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f8ee25c8-83d4-3799-84b2-b52f8eb32747</guid>
                                    <description><![CDATA[<p>What if we borrowed from physics some theories that would interpret deep learning and machine learning in general?
Here is a list of plausible ways to interpret our beloved ML models and understand why they works, or they don't.

Enjoy the show!


</p>
Our Sponsors
<p>NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ 
need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.</p>
<p>See NordPass Business in action now with a 3-month free trial here
<a href='https://nordpass.com/datascience'>https://nordpass.com/DATASCIENCE</a> with codeDATASCIENCE</p>
<p>Â </p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>What if we borrowed from physics some theories that would interpret deep learning and machine learning in general?<br>
Here is a list of plausible ways to interpret our beloved ML models and understand why they works, or they don't.<br>
<br>
Enjoy the show!<br>
<br>
<br>
</p>
Our Sponsors
<p>NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ <br>
need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.</p>
<p>See NordPass Business in action now with a 3-month free trial here<br>
<a href='https://nordpass.com/datascience'>https://nordpass.com/DATASCIENCE</a> with codeDATASCIENCE</p>
<p>Â </p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/mbhk54/machine-learning-physics.mp3" length="32121211" type="audio/mpeg"/>
        <itunes:summary><![CDATA[What if we borrowed from physics some theories that would interpret deep learning and machine learning in general?Here is a list of plausible ways to interpret our beloved ML models and understand why they works, or they don't.Enjoy the show!
Our Sponsors
NordPass Business has developed a password manager, that will save you a lot of time and energy whenever youÂ need access to business accounts, work across devices, even with the other members of your team, or whenever you need to share sensitive data with your colleagues, or make payments efficiently. All this with the highest standard of cyber secure technology.
See NordPass Business in action now with a 3-month free trial herehttps://nordpass.com/DATASCIENCE with codeDATASCIENCE
Â 
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:54</itunes:duration>
                <itunes:episode>214</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Autonomous cars cannot drive. Here is why. (Ep. 210)</title>
        <itunes:title>Autonomous cars cannot drive. Here is why. (Ep. 210)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/autonomous-cars-cannot-drive-here-is-why-ep-210/</link>
                    <comments>https://datascienceathome.podbean.com/e/autonomous-cars-cannot-drive-here-is-why-ep-210/#comments</comments>        <pubDate>Mon, 21 Nov 2022 10:28:45 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6e13fb41-053f-3759-aecc-3453c7682c02</guid>
                                    <description><![CDATA[<p>If you think that the problem of self-driving cars has been solved, think twice.
As a matter of fact, the problem of self-driving cars cannot be solved with the technical solutions that companies are currently considering. 
Don't get fooled by marketing and PR on social media. Whoever is telling you they solved the problem of driving a vehicle fully autonomously, they are lying.
Here is why.</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>If you think that the problem of self-driving cars has been solved, think twice.<br>
As a matter of fact, the problem of self-driving cars cannot be solved with the technical solutions that companies are currently considering. <br>
Don't get fooled by marketing and PR on social media. Whoever is telling you they solved the problem of driving a vehicle fully autonomously, they are lying.<br>
Here is why.</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/beqpxf/why-self-driving-cars-is-not-solved-yet.mp3" length="44260442" type="audio/mpeg"/>
        <itunes:summary><![CDATA[If you think that the problem of self-driving cars has been solved, think twice.As a matter of fact, the problem of self-driving cars cannot be solved with the technical solutions that companies are currently considering. Don't get fooled by marketing and PR on social media. Whoever is telling you they solved the problem of driving a vehicle fully autonomously, they are lying.Here is why.
Â 
Our Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>35:04</itunes:duration>
                <itunes:episode>213</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Evolution of data platforms (Ep. 209)</title>
        <itunes:title>Evolution of data platforms (Ep. 209)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/evolution-of-data-platforms-ep-209/</link>
                    <comments>https://datascienceathome.podbean.com/e/evolution-of-data-platforms-ep-209/#comments</comments>        <pubDate>Tue, 08 Nov 2022 11:05:53 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/59e9064d-03af-3c2b-850e-3b3586b94415</guid>
                                    <description><![CDATA[<p>Let's look at the history of data platforms. How did they evolve? Why? 
Shall I switch to the latest architecture? 
Enjoy the show!</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Let's look at the history of data platforms. How did they evolve? Why? <br>
Shall I switch to the latest architecture? <br>
Enjoy the show!</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8x57pe/evolution-data-platforms.mp3" length="23451932" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Let's look at the history of data platforms. How did they evolve? Why? Shall I switch to the latest architecture? Enjoy the show!
Â 
Our Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:42</itunes:duration>
                <itunes:episode>212</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>[RB] Is studying AI in academia a waste of time? (Ep. 208)</title>
        <itunes:title>[RB] Is studying AI in academia a waste of time? (Ep. 208)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-is-studying-ai-in-academia-a-waste-of-time-ep-208/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-is-studying-ai-in-academia-a-waste-of-time-ep-208/#comments</comments>        <pubDate>Wed, 02 Nov 2022 09:52:45 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0bfe7ab5-b0ea-3940-9e1b-4499e1d06f45</guid>
                                    <description><![CDATA[<p>Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.
However, there is doubt about how powerful and effective such research efforts are.
Is studying AI in academia a waste of time?</p>
<p>Â </p>
Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â 
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.<br>
However, there is doubt about how powerful and effective such research efforts are.<br>
Is studying AI in academia a waste of time?</p>
<p>Â </p>
Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â <br>
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/mhnx9i/RB-ai-academia-waste-time.mp3" length="26731563" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.However, there is doubt about how powerful and effective such research efforts are.Is studying AI in academia a waste of time?
Â 
Our Sponsors
Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at online.uc.edu/obaisÂ 
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:01</itunes:duration>
                <itunes:episode>211</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Private machine learning done right (Ep. 207)</title>
        <itunes:title>Private machine learning done right (Ep. 207)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/private-machine-learning-done-right/</link>
                    <comments>https://datascienceathome.podbean.com/e/private-machine-learning-done-right/#comments</comments>        <pubDate>Tue, 25 Oct 2022 10:08:51 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1ebbb28e-d7b7-3a51-a983-a3349481777b</guid>
                                    <description><![CDATA[<p>There are many solutions to private machine learning. I am pretty confident when I say that the one we are speaking in this episode is probably one of the most feasible and reliable.
I am with Daniel Huynh, CEO of Mithril Security,Â  a graduate from Ecole Polytechnique with a specialisation in AI and data science. He worked at Microsoft on Privacy Enhancing Technologies under the office of the CTO of Microsoft France. He has written articles on Homomorphic Encryptions with the CKKS explained series (<a href='https://blog.openmined.org/ckks-explained-part-1-simple-encoding-and-decoding/'>https://blog.openmined.org/ckks-explained-part-1-simple-encoding-and-decoding/</a>). He is now focusing on Confidential Computing at Mithril Security and has written extensive articles on the topic: <a href='https://blog.mithrilsecurity.io/'>https://blog.mithrilsecurity.io/</a>.Â </p>
<p>In this show we speak about confidential computing, SGX and private machine learning</p>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;">Mithril Security: <a href='https://www.mithrilsecurity.io/'>https://www.mithrilsecurity.io/</a>Â </li>
<li style="font-weight:400;">BindAI GitHub: <a href='https://github.com/mithril-security/blindai'>https://github.com/mithril-security/blindai</a>Â </li>
<li style="font-weight:400;">Use cases for BlindAI:<ul><li style="font-weight:400;">Deploy Transformers models with confidentiality: <a href='https://blog.mithrilsecurity.io/transformers-with-confidentiality/'>https://blog.mithrilsecurity.io/transformers-with-confidentiality/</a></li>
<li style="font-weight:400;">Confidential medical image analysis with COVID-Net and BlindAI: <a href='https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/'>https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/</a>Â </li>
<li style="font-weight:400;">Build a privacy-by-design voice assistant with BlindAI: <a href='https://blog.mithrilsecurity.io/privacy-voice-ai-with-blindai/'>https://blog.mithrilsecurity.io/privacy-voice-ai-with-blindai/</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Confidential Computing Explained: <a href='https://blog.mithrilsecurity.io/confidential-computing-explained-part-1-introduction/'>https://blog.mithrilsecurity.io/confidential-computing-explained-part-1-introduction/</a>Â </li>
<li style="font-weight:400;">Confidential Computing Consortium: <a href='https://confidentialcomputing.io/'>https://confidentialcomputing.io/</a>Â </li>
<li style="font-weight:400;">Confidential Computing White Papers: <a href='https://confidentialcomputing.io/white-papers-reports/'>https://confidentialcomputing.io/white-papers-reports/</a>Â </li>
<li style="font-weight:400;">List of Intel processors with Intel SGX:<ul><li style="font-weight:400;"><a href='https://www.intel.com/content/www/us/en/support/articles/000028173/processors.html'>https://www.intel.com/content/www/us/en/support/articles/000028173/processors.html</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/ayeks/SGX-hardware'>https://github.com/ayeks/SGX-hardware</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Azure Confidential Computing VMs with SGX:<ul><li style="font-weight:400;">Azure Docs: <a href='https://docs.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclaves'>https://docs.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclaves</a>Â </li>
<li style="font-weight:400;">How to deploy BlindAI on Azure: <a href='https://docs.mithrilsecurity.io/getting-started/cloud-deployment/azure-dcsv3'>https://docs.mithrilsecurity.io/getting-started/cloud-deployment/azure-dcsv3</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Confidential Computing 101: <a href='https://www.youtube.com/watch?v=77U12Ss38Zc'>https://www.youtube.com/watch?v=77U12Ss38Zc</a>Â </li>
<li style="font-weight:400;">Rust: <a href='https://www.rust-lang.org/'>https://www.rust-lang.org/</a>Â </li>
<li style="font-weight:400;">ONNX: <a href='https://github.com/onnx/onnx'>https://github.com/onnx/onnx</a> </li>
<li style="font-weight:400;">Tract, a Rust inference engine for ONNX models: <a href='https://github.com/sonos/tract'>https://github.com/sonos/tract</a> </li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>There are many solutions to private machine learning. I am pretty confident when I say that the one we are speaking in this episode is probably one of the most feasible and reliable.<br>
I am with Daniel Huynh, CEO of Mithril Security,Â  a graduate from Ecole Polytechnique with a specialisation in AI and data science. He worked at Microsoft on Privacy Enhancing Technologies under the office of the CTO of Microsoft France. He has written articles on Homomorphic Encryptions with the CKKS explained series (<a href='https://blog.openmined.org/ckks-explained-part-1-simple-encoding-and-decoding/'>https://blog.openmined.org/ckks-explained-part-1-simple-encoding-and-decoding/</a>). He is now focusing on Confidential Computing at Mithril Security and has written extensive articles on the topic: <a href='https://blog.mithrilsecurity.io/'>https://blog.mithrilsecurity.io/</a>.Â </p>
<p>In this show we speak about confidential computing, SGX and private machine learning</p>
<p>Â </p>
<p>References</p>
<ul><li style="font-weight:400;">Mithril Security: <a href='https://www.mithrilsecurity.io/'>https://www.mithrilsecurity.io/</a>Â </li>
<li style="font-weight:400;">BindAI GitHub: <a href='https://github.com/mithril-security/blindai'>https://github.com/mithril-security/blindai</a>Â </li>
<li style="font-weight:400;">Use cases for BlindAI:<ul><li style="font-weight:400;">Deploy Transformers models with confidentiality: <a href='https://blog.mithrilsecurity.io/transformers-with-confidentiality/'>https://blog.mithrilsecurity.io/transformers-with-confidentiality/</a></li>
<li style="font-weight:400;">Confidential medical image analysis with COVID-Net and BlindAI: <a href='https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/'>https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/</a>Â </li>
<li style="font-weight:400;">Build a privacy-by-design voice assistant with BlindAI: <a href='https://blog.mithrilsecurity.io/privacy-voice-ai-with-blindai/'>https://blog.mithrilsecurity.io/privacy-voice-ai-with-blindai/</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Confidential Computing Explained: <a href='https://blog.mithrilsecurity.io/confidential-computing-explained-part-1-introduction/'>https://blog.mithrilsecurity.io/confidential-computing-explained-part-1-introduction/</a>Â </li>
<li style="font-weight:400;">Confidential Computing Consortium: <a href='https://confidentialcomputing.io/'>https://confidentialcomputing.io/</a>Â </li>
<li style="font-weight:400;">Confidential Computing White Papers: <a href='https://confidentialcomputing.io/white-papers-reports/'>https://confidentialcomputing.io/white-papers-reports/</a>Â </li>
<li style="font-weight:400;">List of Intel processors with Intel SGX:<ul><li style="font-weight:400;"><a href='https://www.intel.com/content/www/us/en/support/articles/000028173/processors.html'>https://www.intel.com/content/www/us/en/support/articles/000028173/processors.html</a>Â </li>
<li style="font-weight:400;"><a href='https://github.com/ayeks/SGX-hardware'>https://github.com/ayeks/SGX-hardware</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Azure Confidential Computing VMs with SGX:<ul><li style="font-weight:400;">Azure Docs: <a href='https://docs.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclaves'>https://docs.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclaves</a>Â </li>
<li style="font-weight:400;">How to deploy BlindAI on Azure: <a href='https://docs.mithrilsecurity.io/getting-started/cloud-deployment/azure-dcsv3'>https://docs.mithrilsecurity.io/getting-started/cloud-deployment/azure-dcsv3</a>Â </li>
</ul>
</li>
<li style="font-weight:400;">Confidential Computing 101: <a href='https://www.youtube.com/watch?v=77U12Ss38Zc'>https://www.youtube.com/watch?v=77U12Ss38Zc</a>Â </li>
<li style="font-weight:400;">Rust: <a href='https://www.rust-lang.org/'>https://www.rust-lang.org/</a>Â </li>
<li style="font-weight:400;">ONNX: <a href='https://github.com/onnx/onnx'>https://github.com/onnx/onnx</a> </li>
<li style="font-weight:400;">Tract, a Rust inference engine for ONNX models: <a href='https://github.com/sonos/tract'>https://github.com/sonos/tract</a> </li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/zpzp9q/blind-ai-private-machine-learning.mp3" length="31765849" type="audio/mpeg"/>
        <itunes:summary><![CDATA[There are many solutions to private machine learning. I am pretty confident when I say that the one we are speaking in this episode is probably one of the most feasible and reliable.I am with Daniel Huynh, CEO of Mithril Security,Â  a graduate from Ecole Polytechnique with a specialisation in AI and data science. He worked at Microsoft on Privacy Enhancing Technologies under the office of the CTO of Microsoft France. He has written articles on Homomorphic Encryptions with the CKKS explained series (https://blog.openmined.org/ckks-explained-part-1-simple-encoding-and-decoding/). He is now focusing on Confidential Computing at Mithril Security and has written extensive articles on the topic: https://blog.mithrilsecurity.io/.Â 
In this show we speak about confidential computing, SGX and private machine learning
Â 
References
Mithril Security: https://www.mithrilsecurity.io/Â 
BindAI GitHub: https://github.com/mithril-security/blindaiÂ 
Use cases for BlindAI:Deploy Transformers models with confidentiality: https://blog.mithrilsecurity.io/transformers-with-confidentiality/
Confidential medical image analysis with COVID-Net and BlindAI: https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/Â 
Build a privacy-by-design voice assistant with BlindAI: https://blog.mithrilsecurity.io/privacy-voice-ai-with-blindai/Â 

Confidential Computing Explained: https://blog.mithrilsecurity.io/confidential-computing-explained-part-1-introduction/Â 
Confidential Computing Consortium: https://confidentialcomputing.io/Â 
Confidential Computing White Papers: https://confidentialcomputing.io/white-papers-reports/Â 
List of Intel processors with Intel SGX:https://www.intel.com/content/www/us/en/support/articles/000028173/processors.htmlÂ 
https://github.com/ayeks/SGX-hardwareÂ 

Azure Confidential Computing VMs with SGX:Azure Docs: https://docs.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclavesÂ 
How to deploy BlindAI on Azure: https://docs.mithrilsecurity.io/getting-started/cloud-deployment/azure-dcsv3Â 

Confidential Computing 101: https://www.youtube.com/watch?v=77U12Ss38ZcÂ 
Rust: https://www.rust-lang.org/Â 
ONNX: https://github.com/onnx/onnx 
Tract, a Rust inference engine for ONNX models: https://github.com/sonos/tract 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:45</itunes:duration>
                <itunes:episode>206</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Edge AI for applications in military and space (Ep. 206)</title>
        <itunes:title>Edge AI for applications in military and space (Ep. 206)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/edge-ai-for-applications-in-militay-and-space-ep-206/</link>
                    <comments>https://datascienceathome.podbean.com/e/edge-ai-for-applications-in-militay-and-space-ep-206/#comments</comments>        <pubDate>Sat, 15 Oct 2022 17:01:11 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1123d082-e716-3c3e-9ced-966d743577bc</guid>
                                    <description><![CDATA[Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â 
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></description>
                                                            <content:encoded><![CDATA[Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â <br>
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/q9xp3q/ai-edge-military-space.mp3" length="29220763" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsors
Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at online.uc.edu/obaisÂ 
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:09</itunes:duration>
                <itunes:episode>210</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>[RB] What are generalist agents and why they can change the AI game (Ep. 205)</title>
        <itunes:title>[RB] What are generalist agents and why they can change the AI game (Ep. 205)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-what-are-generalist-agents-and-why-they-can-change-the-ai-game-ep-205/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-what-are-generalist-agents-and-why-they-can-change-the-ai-game-ep-205/#comments</comments>        <pubDate>Wed, 05 Oct 2022 08:56:10 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/da08c766-6362-3fc4-83d1-ba5782d5ff96</guid>
                                    <description><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
<a href='https://arxiv.org/pdf/2205.06175'>https://arxiv.org/pdf/2205.06175</a>
Â 
Â ]]></description>
                                                            <content:encoded><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
<a href='https://arxiv.org/pdf/2205.06175'>https://arxiv.org/pdf/2205.06175</a>
Â 
Â ]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/p3cu52/gato-generalist-model.mp3" length="26779781" type="audio/mpeg"/>
        <itunes:summary><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
https://arxiv.org/pdf/2205.06175
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:06</itunes:duration>
                <itunes:episode>209</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>LIDAR, cameras and autonomous vehicles (Ep. 204)</title>
        <itunes:title>LIDAR, cameras and autonomous vehicles (Ep. 204)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/lidar-cameras-and-autonomous-vehicles/</link>
                    <comments>https://datascienceathome.podbean.com/e/lidar-cameras-and-autonomous-vehicles/#comments</comments>        <pubDate>Wed, 28 Sep 2022 07:12:30 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6648a634-b0b5-3a84-b304-b9bcc47ed938</guid>
                                    <description><![CDATA[<p>How does an autonomous vehicle see? How does it sense the road? 
They are equipped of many sensors, of course. Are they all powerful enough? Small enough to hide them and make your car look beautiful?Â 
In this episode I speak about LIDAR, high resolution cameras and some machine learning methods adapted to a minimal number of sensors. </p>
<p>Â </p>
Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â 
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
References
<p><a href='https://patents.google.com/patent/US20220043449A1/en?oq=20220043449'>https://patents.google.com/patent/US20220043449A1/en?oq=20220043449</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>How does an autonomous vehicle see? How does it sense the road? <br>
They are equipped of many sensors, of course. Are they all powerful enough? Small enough to hide them and make your car look beautiful?Â <br>
In this episode I speak about LIDAR, high resolution cameras and some machine learning methods adapted to a minimal number of sensors. </p>
<p>Â </p>
Our Sponsors
<p>Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â <br>
Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at <a href='https://online.uc.edu/obais/'>online.uc.edu/obaisÂ </a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
References
<p><a href='https://patents.google.com/patent/US20220043449A1/en?oq=20220043449'>https://patents.google.com/patent/US20220043449A1/en?oq=20220043449</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/9fed7b/lidar-tesla-av.mp3" length="27210193" type="audio/mpeg"/>
        <itunes:summary><![CDATA[How does an autonomous vehicle see? How does it sense the road? They are equipped of many sensors, of course. Are they all powerful enough? Small enough to hide them and make your car look beautiful?Â In this episode I speak about LIDAR, high resolution cameras and some machine learning methods adapted to a minimal number of sensors. 
Â 
Our Sponsors
Ready to advance your career in data science? University of Cincinnati Online offers nationally recognized educational programs in business analytics and information systems. Predictive Analytics Today named UC as the No.1 MS Data Science school in the country and is nationally recognized with a proven track record of placing students at high-profile companies such as Google, Amazon and P&G.Â Discover more about the University of Cincinnatiâ€™s 100% online masterâ€™s degree programs at online.uc.edu/obaisÂ 
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â 
References
https://patents.google.com/patent/US20220043449A1/en?oq=20220043449
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:56</itunes:duration>
                <itunes:episode>202</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Predicting Out Of Memory Kill events with Machine Learning (Ep. 203)</title>
        <itunes:title>Predicting Out Of Memory Kill events with Machine Learning (Ep. 203)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/predicting-out-of-memory-kill-events-with-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/predicting-out-of-memory-kill-events-with-machine-learning/#comments</comments>        <pubDate>Tue, 20 Sep 2022 19:54:04 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/795a64d2-a5a5-3b82-84a7-7e1ca4c86394</guid>
                                    <description><![CDATA[<p>Sometimes applications crash. Some other times applications crash because memory is exhausted. Such issues exist because of bugs in the code, or heavy memory usage for reasons that were not expected during design and implementation. 
Can we use machine learning to predict and eventually detect out of memory kills from the operating system?</p>
<p>Apparently, the Netflix app many of us use on a daily basis leverage ML and time series analysis to prevent OOM-kills.</p>
<p>Enjoy the show!</p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
Transcript
<p>1
00:00:04,150 --> 00:00:09,034
And here we are again with the season four of the Data Science at Home podcast.</p>
<p>2
00:00:09,142 --> 00:00:19,170
This time we have something for you if you want to help us shape the data science leaders of the future, we have created the the Data Science at Home's Ambassador program.</p>
<p>3
00:00:19,340 --> 00:00:28,378
Ambassadors are volunteers who are passionate about data science and want to give back to our growing community of data science professionals and enthusiasts.</p>
<p>4
00:00:28,534 --> 00:00:37,558
You will be instrumental in helping us achieve our goal of raising awareness about the critical role of data science in cutting edge technologies.</p>
<p>5
00:00:37,714 --> 00:00:45,740
If you want to learn more about this program, visit the Ambassadors page on our website@datascienceathome.com.</p>
<p>6
00:00:46,430 --> 00:00:49,234
Welcome back to another episode of Data Science at Home podcast.</p>
<p>7
00:00:49,282 --> 00:00:55,426
I'm Francesco Podcasting from the Regular Office of Amethyx Technologies, based in Belgium.</p>
<p>8
00:00:55,618 --> 00:01:02,914
In this episode, I want to speak about a machine learning problem that has been formulated at Netflix.</p>
<p>9
00:01:03,022 --> 00:01:22,038
And for the record, Netflix is not sponsoring this episode, though I still believe that this problem is a very well known problem, a very common one across factors, which is how to predict out of memory kill in an application and formulate this problem as a machine learning problem.</p>
<p>10
00:01:22,184 --> 00:01:39,142
So this is something that, as I said, is very interesting, not just because of Netflix, but because it allows me to explain a few points that, as I said, are kind of invariance across sectors.</p>
<p>11
00:01:39,226 --> 00:01:56,218
Regardless of your application, is a video streaming application or any other communication type of application, or a fintech application, or energy, or whatever, this memory kill, out of memory kill still occurs.</p>
<p>12
00:01:56,314 --> 00:02:05,622
And what is an out of memory kill? Well, it's essentially the extreme event in which the machine doesn't have any more memory left.</p>
<p>13
00:02:05,756 --> 00:02:16,678
And so usually the operating system can start eventually swapping, which means using the SSD or the hard drive as a source of memory.</p>
<p>14
00:02:16,834 --> 00:02:19,100
But that, of course, will slow down a lot.</p>
<p>15
00:02:19,430 --> 00:02:45,210
And eventually when there is a bug or a memory leak, or if there are other applications running on the same machine, of course there is some kind of limiting factor that essentially kills the application, something that occurs from the operating system most of the time that kills the application in order to prevent the application from monopolizing the entire machine, the hardware of the machine.</p>
<p>16
00:02:45,710 --> 00:02:48,500
And so this is a very important problem.</p>
<p>17
00:02:49,070 --> 00:03:03,306
Also, it is important to have an episode about this because there are some strategies that I've used at Netflix that are pretty much in line with what I believe machine learning should be about.</p>
<p>18
00:03:03,368 --> 00:03:25,062
And usually people would go for the fancy solution there like this extremely accurate predictors or machine learning models, but you should have a massive number of parameters and that try to figure out whatever is happening on that machine that is running that application.</p>
<p>19
00:03:25,256 --> 00:03:29,466
While the solution at Netflix is pretty straightforward, it's pretty simple.</p>
<p>20
00:03:29,588 --> 00:03:33,654
And so one would say then why making an episode after this? Well.</p>
<p>21
00:03:33,692 --> 00:03:45,730
Because I think that we need more sobriety when it comes to machine learning and I believe we still need to spend a lot of time thinking about what data to collect.</p>
<p>22
00:03:45,910 --> 00:03:59,730
Reasoning about what is the problem at hand and what is the data that can actually tickle the particular machine learning model and then of course move to the actual prediction that is the actual model.</p>
<p>23
00:03:59,900 --> 00:04:15,910
That most of the time it doesn't need to be one of these super fancy things that you see on the news around chatbots or autonomous gaming agent or drivers and so on and so forth.</p>
<p>24
00:04:16,030 --> 00:04:28,518
So there are essentially two data sets that the people at Netflix focus on which are consistently different, dramatically different in fact.</p>
<p>25
00:04:28,604 --> 00:04:45,570
These are data about device characteristics and capabilities and of course data that are collected at Runtime and that give you a picture of what's going on in the memory of the device, right? So that's the so called runtime memory data and out of memory kills.</p>
<p>26
00:04:45,950 --> 00:05:03,562
So the first type of data is I would consider it very static because it considers for example, the device type ID, the version of the software development kit that application is running, cache capacities, buffer capacities and so on and so forth.</p>
<p>27
00:05:03,646 --> 00:05:11,190
So it's something that most of the time doesn't change across sessions and so that's why it's considered static.</p>
<p>28
00:05:12,050 --> 00:05:18,430
In contrast, the other type of data, the Runtime memory data, as the name says it's runtime.</p>
<p>29
00:05:18,490 --> 00:05:24,190
So it varies across the life of the session it's collected at Runtime.</p>
<p>30
00:05:24,250 --> 00:05:25,938
So it's very dynamic data.</p>
<p>31
00:05:26,084 --> 00:05:36,298
And example of these records are for example, profile, movie details, playback information, current memory usage, et cetera, et cetera.</p>
<p>32
00:05:36,334 --> 00:05:56,086
So this is the data that actually moves and moves in the sense that it changes depending on how the user is actually using the Netflix application, what movie or what profile description, what movie detail has been loaded for that particular movie and so on and so forth.</p>
<p>33
00:05:56,218 --> 00:06:15,094
So one thing that of course the first difficulty of the first challenge that the people at Netflix had to deal with was how would you combine these two things, very static and usually small tables versus very dynamic and usually large tables or views.</p>
<p>34
00:06:15,142 --> 00:06:36,702
Well, there is some sort of join on key that is performed by the people at Netflix in order to put together these different data resolutions, right, which is data of the same phenomenon but from different sources and with different carrying very different signals in there.</p>
<p>35
00:06:36,896 --> 00:06:48,620
So the device capabilities is captured usually by the static data and of course the other data, the Runtime memory and out of memory kill data.</p>
<p>36
00:06:48,950 --> 00:07:04,162
These are also, as I said, the data that will describe pretty accurately how is the user using that particular application on that particular hardware.</p>
<p>37
00:07:04,306 --> 00:07:17,566
Now of course, when it comes to data and deer, there is nothing new that people at Netflix have introduced dealing with missing data for example, or incorporating knowledge of devices.</p>
<p>38
00:07:17,698 --> 00:07:26,062
It's all stuff that it's part of the so called data cleaning and data collection strategy, right? Or data preparation.</p>
<p>39
00:07:26,146 --> 00:07:40,782
That is, whatever you're going to do in order to make that data or a combination of these data sources, let's say, compatible with the way your machine learning model will understand or will read that data.</p>
<p>40
00:07:40,916 --> 00:07:58,638
So if you think of a big data platform, the first step, the first challenge you have to deal, you have to deal with is how can I, first of all, collect the right amount of information, the right data, but also how to transform this data for my particular big data platform.</p>
<p>41
00:07:58,784 --> 00:08:12,798
And that's something that, again, nothing new, nothing fancy, just basics, what we have been used to, what we are used to seeing now for the last decade or more, that's exactly what they do.</p>
<p>42
00:08:12,944 --> 00:08:15,222
And now let me tell you something important.</p>
<p>43
00:08:15,416 --> 00:08:17,278
Cybercriminals are evolving.</p>
<p>44
00:08:17,374 --> 00:08:22,446
Their techniques and tactics are more advanced, intricate and dangerous than ever before.</p>
<p>45
00:08:22,628 --> 00:08:30,630
Industries and governments around the world are fighting back on dealing new regulations meant to better protect data against this rising threat.</p>
<p>46
00:08:30,950 --> 00:08:39,262
Today, the world of cybersecurity compliance is a complex one, and understanding the requirements your organization must adhere to can be a daunting task.</p>
<p>47
00:08:39,406 --> 00:08:42,178
But not when the pack has your best architect.</p>
<p>48
00:08:42,214 --> 00:08:53,840
Wolf, the leader in security operations, is on a mission to end cyber risk by giving organizations the protection, information and confidence they need to protect their people, technology and data.</p>
<p>49
00:08:54,170 --> 00:09:02,734
The new interactive compliance portal helps you discover the regulations in your region and industry and start the journey towards achieving and maintaining compliance.</p>
<p>50
00:09:02,902 --> 00:09:07,542
Visit Arcticwolves.com DataScience to take your first step.</p>
<p>51
00:09:07,676 --> 00:09:11,490
That's arcticwolf.com DataScience.</p>
<p>52
00:09:12,050 --> 00:09:18,378
I think that the most important part, though, I think are actually equally important.</p>
<p>53
00:09:18,464 --> 00:09:26,854
But the way they treat runtime memory data and out of memory kill data is by using sliding windows.</p>
<p>54
00:09:26,962 --> 00:09:38,718
So that's something that is really worth mentioning, because the way you would frame this problem is something is happening at some point in time and I have to kind of predict that event.</p>
<p>55
00:09:38,864 --> 00:09:49,326
That is usually an outlier in the sense that these events are quite rare, fortunately, because Netflix would not be as usable as we believe it is.</p>
<p>56
00:09:49,448 --> 00:10:04,110
So you would like to predict these weird events by looking at a historical view or an historical amount of records that you have before this particular event, which is the kill of the application.</p>
<p>57
00:10:04,220 --> 00:10:12,870
So the concept of the sliding window, the sliding window approach is something that comes as the most natural thing anyone would do.</p>
<p>58
00:10:13,040 --> 00:10:18,366
And that's exactly what the researchers and Netflix have done.</p>
<p>59
00:10:18,488 --> 00:10:25,494
So unexpectedly, in my opinion, they treated this problem as a time series, which is exactly what it is.</p>
<p>60
00:10:25,652 --> 00:10:26,190
Now.</p>
<p>61
00:10:26,300 --> 00:10:26,754
They.</p>
<p>62
00:10:26,852 --> 00:10:27,330
Of course.</p>
<p>63
00:10:27,380 --> 00:10:31,426
Use this sliding window with a different horizon.</p>
<p>64
00:10:31,558 --> 00:10:32,190
Five minutes.</p>
<p>65
00:10:32,240 --> 00:10:32,838
Four minutes.</p>
<p>66
00:10:32,924 --> 00:10:33,702
Two minutes.</p>
<p>67
00:10:33,836 --> 00:10:36,366
As close as possible to the event.</p>
<p>68
00:10:36,548 --> 00:10:38,886
Because maybe there are some.</p>
<p>69
00:10:39,008 --> 00:10:39,762
Let's say.</p>
<p>70
00:10:39,896 --> 00:10:45,678
Other dynamics that can raise when you are very close to the event or when you are very far from it.</p>
<p>71
00:10:45,704 --> 00:10:50,166
Like five minutes far from the out of memory kill.</p>
<p>72
00:10:50,348 --> 00:10:51,858
Might have some other.</p>
<p>73
00:10:51,944 --> 00:10:52,410
Let's say.</p>
<p>74
00:10:52,460 --> 00:10:55,986
Diagrams or shapes in the data.</p>
<p>75
00:10:56,168 --> 00:11:11,310
So for example, you might have a certain number of allocations that keep growing and growing, but eventually they grow with a certain curve or a certain rate that you can measure when you are five to ten minutes far from the out of memory kill.</p>
<p>76
00:11:11,420 --> 00:11:16,566
When you are two minutes far from the out of memory kill, probably this trend will change.</p>
<p>77
00:11:16,688 --> 00:11:30,800
And so probably what you would expect is that the memory is already half or more saturated and therefore, for example, the operating system starts swapping or other things are happening that you are going to measure in this.</p>
<p>78
00:11:31,550 --> 00:11:39,730
And that would give you a much better picture of what's going on in the, let's say, closest neighborhood of that event, the time window.</p>
<p>79
00:11:39,790 --> 00:11:51,042
The sliding window and time window approach is definitely worth mentioning because this is something that you can apply if you think pretty much anywhere right now.</p>
<p>80
00:11:51,116 --> 00:11:52,050
What they did.</p>
<p>81
00:11:52,160 --> 00:12:04,146
In addition to having a time window, a sliding window, they also assign different levels to memory readings that are closer to the out of memory kill.</p>
<p>82
00:12:04,208 --> 00:12:10,062
And usually these levels are higher and higher as we get closer and closer to the out of memory kill.</p>
<p>83
00:12:10,136 --> 00:12:15,402
So this means that, for example, we would have, for a five minute window, we would have a level one.</p>
<p>84
00:12:15,596 --> 00:12:22,230
Five minute means five minutes far from the out of memory kill, four minutes would be a level two.</p>
<p>85
00:12:22,280 --> 00:12:37,234
Three minutes it's much closer would be a level three, two minutes would be a level four, which means like kind of the severity of the event as we get closer and closer to the actual event when the application is actually killed.</p>
<p>86
00:12:37,342 --> 00:12:51,474
So by looking at this approach, nothing new there, even, I would say not even a seasoned data scientist would have understood that using a sliding window is the way to go.</p>
<p>87
00:12:51,632 --> 00:12:55,482
I'm not saying that Netflix engineers are not seasoned enough.</p>
<p>88
00:12:55,556 --> 00:13:04,350
Actually they do a great job every day to keep giving us video streaming platforms that actually never fail or almost never fail.</p>
<p>89
00:13:04,910 --> 00:13:07,460
So spot on there, guys, good job.</p>
<p>90
00:13:07,850 --> 00:13:27,738
But looking at this sliding window approach, the direct consequence of this is that they can plot, they can do some sort of graphical analysis of the out of memory kills versus the memory usage that can give the reader or the data scientist a very nice picture of what's going on there.</p>
<p>91
00:13:27,824 --> 00:13:39,330
And so you would have, for example, and I would definitely report some of the pictures, some of the diagrams and graphs in the show notes of this episode on the official website datascienceaton.com.</p>
<p>92
00:13:39,500 --> 00:13:48,238
But essentially what you can see there is that there might be premature peaks at, let's say, a lower memory reading.</p>
<p>93
00:13:48,334 --> 00:14:08,958
And usually these are some kind of false positives or anomalies that should not be there, then it's possible to set a threshold where the threshold to start lowering the memory usage because after that threshold something nasty can happen and usually happens according to your data.</p>
<p>94
00:14:09,104 --> 00:14:18,740
And then of course there is another graph about the Gaussian distribution or in fact no sharp peak at all.</p>
<p>95
00:14:19,250 --> 00:14:21,898
That is like kills or out of memory.</p>
<p>96
00:14:21,934 --> 00:14:33,754
Kills are more or less distributed in a normalized fashion and then of course there are the genuine peaks that indicate that kills near, let's say, the threshold.</p>
<p>97
00:14:33,802 --> 00:14:38,758
And so usually you would see that after that particular threshold of memory usage.</p>
<p>98
00:14:38,914 --> 00:14:42,142
You see most of the out of memory kills.</p>
<p>99
00:14:42,226 --> 00:14:45,570
Which makes sense because given a particular device.</p>
<p>100
00:14:45,890 --> 00:14:48,298
Which means certain amount of memories.</p>
<p>101
00:14:48,394 --> 00:14:50,338
Certain memory characteristics.</p>
<p>102
00:14:50,494 --> 00:14:53,074
Certain version of the SDK and so on and so forth.</p>
<p>103
00:14:53,182 --> 00:14:53,814
You can say.</p>
<p>104
00:14:53,852 --> 00:14:54,090
Okay.</p>
<p>105
00:14:54,140 --> 00:15:10,510
Well for this device type I have this memory memory usage threshold and after this I see that I have a relatively high number of out of memory kills immediately after this threshold.</p>
<p>106
00:15:10,570 --> 00:15:18,150
And this means that probably that is the threshold you would like to consider as the critical threshold you should never or almost never cross.</p>
<p>107
00:15:18,710 --> 00:15:38,758
So once you have this picture in front of you, you can start thinking of implementing some mechanisms that can monitor the memory usage and of course kind of preemptively dialocate things or keep that memory threshold as low as possible with respect to the critical threshold.</p>
<p>108
00:15:38,794 --> 00:15:53,446
So you can start implementing some logic that prevents the application from being killed by the operating system so that you would in fact reduce the rate of out of memory kills overall.</p>
<p>109
00:15:53,578 --> 00:16:11,410
Now, as always and as also the engineers state in their blog post, in the technical post, they say well, it's much more important for us to predict with a certain amount of false positive rather than false negatives.</p>
<p>110
00:16:11,590 --> 00:16:18,718
False negatives means missing an out of memory kill that actually occurred but got not predicted.</p>
<p>111
00:16:18,874 --> 00:16:40,462
If you are a regular listener of this podcast, that statement should resonate with you because this is exactly what happens, for example in healthcare applications, which means that doctors or algorithms that operate in healthcare would definitely prefer to have a bit more false positives rather than more false negatives.</p>
<p>112
00:16:40,486 --> 00:16:54,800
Because missing that someone is sick means that you are not providing a cure and you're just sending the patient home when he or she is sick, right? That's the false positive, it's the mess.</p>
<p>113
00:16:55,130 --> 00:16:57,618
So that's a false negative, it's the mess.</p>
<p>114
00:16:57,764 --> 00:17:09,486
But having a false positive, what can go wrong with having a false positive? Well, probably you will undergo another test to make sure that the first test is confirmed or not.</p>
<p>115
00:17:09,608 --> 00:17:16,018
So adding a false positive in this case is relatively okay with respect to having a false negative.</p>
<p>116
00:17:16,054 --> 00:17:19,398
And that's exactly what happens to the Netflix application.</p>
<p>117
00:17:19,484 --> 00:17:32,094
Now, I don't want to say that of course Netflix application is as critical as, for example, the application that predicts a cancer or an xray or something on an xray or disorder or disease of some sort.</p>
<p>118
00:17:32,252 --> 00:17:48,090
But what I'm saying is that there are some analogies when it comes to machine learning and artificial intelligence and especially data science, the old school data science, there are several things that kind of are, let's say, invariant across sectors.</p>
<p>119
00:17:48,410 --> 00:17:56,826
And so, you know, two worlds like the media streaming or video streaming and healthcare are of course very different from each other.</p>
<p>120
00:17:56,888 --> 00:18:05,274
But when it comes to machine learning and data science applications, well, there are a lot of analogies there.</p>
<p>121
00:18:05,372 --> 00:18:06,202
And indeed.</p>
<p>122
00:18:06,286 --> 00:18:10,234
In terms of the models that they use at Netflix to predict.</p>
<p>123
00:18:10,342 --> 00:18:24,322
Once they have the sliding window data and essentially they have the ground truth of where this out of memory kill happened and what happened before to the memory of the application or the machine.</p>
<p>124
00:18:24,466 --> 00:18:24,774
Well.</p>
<p>125
00:18:24,812 --> 00:18:30,514
Then the models they use to predict these things is these events is Artificial Neural Networks.</p>
<p>126
00:18:30,622 --> 00:18:31,714
Xg Boost.</p>
<p>127
00:18:31,822 --> 00:18:36,742
Ada Boost or Adaptive Boosting Elastic Net with Softmax and so on and so forth.</p>
<p>128
00:18:36,766 --> 00:18:39,226
So nothing fancy.</p>
<p>129
00:18:39,418 --> 00:18:45,046
As you can see, Xg Boost is probably one of the most used I would have expected even random forest.</p>
<p>130
00:18:45,178 --> 00:18:47,120
Probably they do, they've tried that.</p>
<p>131
00:18:47,810 --> 00:18:58,842
But XGBoost is probably one of the most used models on kaggle competitions for a reason, because it works and it leverages a lot.</p>
<p>132
00:18:58,916 --> 00:19:04,880
The data preparation step, that solves already more than half of the problem.</p>
<p>133
00:19:05,810 --> 00:19:07,270
Thank you so much for listening.</p>
<p>134
00:19:07,330 --> 00:19:11,910
I also invite you, as always, to join the Discord Channel.</p>
<p>135
00:19:12,020 --> 00:19:15,966
You will find a link on the official website datascience@home.com.</p>
<p>136
00:19:16,148 --> 00:19:17,600
Speak with you next time.</p>
<p>137
00:19:18,350 --> 00:19:21,382
You've been listening to Data Science at home podcast.</p>
<p>138
00:19:21,466 --> 00:19:26,050
Be sure to subscribe on itunes, Stitcher, or Pot Bean to get new, fresh episodes.</p>
<p>139
00:19:26,110 --> 00:19:31,066
For more, please follow us on Instagram, Twitter and Facebook or visit our website at datascienceathome.com</p>
<p>Â </p>
References
<p><a href='https://netflixtechblog.com/formulating-out-of-memory-kill-prediction-on-the-netflix-app-as-a-machine-learning-problem-989599029109'>https://netflixtechblog.com/formulating-out-of-memory-kill-prediction-on-the-netflix-app-as-a-machine-learning-problem-989599029109</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Sometimes applications crash. Some other times applications crash because memory is exhausted. Such issues exist because of bugs in the code, or heavy memory usage for reasons that were not expected during design and implementation. <br>
Can we use machine learning to predict and eventually detect out of memory kills from the operating system?</p>
<p>Apparently, the Netflix app many of us use on a daily basis leverage ML and time series analysis to prevent OOM-kills.</p>
<p>Enjoy the show!</p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
Transcript
<p>1<br>
00:00:04,150 --> 00:00:09,034<br>
And here we are again with the season four of the Data Science at Home podcast.</p>
<p>2<br>
00:00:09,142 --> 00:00:19,170<br>
This time we have something for you if you want to help us shape the data science leaders of the future, we have created the the Data Science at Home's Ambassador program.</p>
<p>3<br>
00:00:19,340 --> 00:00:28,378<br>
Ambassadors are volunteers who are passionate about data science and want to give back to our growing community of data science professionals and enthusiasts.</p>
<p>4<br>
00:00:28,534 --> 00:00:37,558<br>
You will be instrumental in helping us achieve our goal of raising awareness about the critical role of data science in cutting edge technologies.</p>
<p>5<br>
00:00:37,714 --> 00:00:45,740<br>
If you want to learn more about this program, visit the Ambassadors page on our website@datascienceathome.com.</p>
<p>6<br>
00:00:46,430 --> 00:00:49,234<br>
Welcome back to another episode of Data Science at Home podcast.</p>
<p>7<br>
00:00:49,282 --> 00:00:55,426<br>
I'm Francesco Podcasting from the Regular Office of Amethyx Technologies, based in Belgium.</p>
<p>8<br>
00:00:55,618 --> 00:01:02,914<br>
In this episode, I want to speak about a machine learning problem that has been formulated at Netflix.</p>
<p>9<br>
00:01:03,022 --> 00:01:22,038<br>
And for the record, Netflix is not sponsoring this episode, though I still believe that this problem is a very well known problem, a very common one across factors, which is how to predict out of memory kill in an application and formulate this problem as a machine learning problem.</p>
<p>10<br>
00:01:22,184 --> 00:01:39,142<br>
So this is something that, as I said, is very interesting, not just because of Netflix, but because it allows me to explain a few points that, as I said, are kind of invariance across sectors.</p>
<p>11<br>
00:01:39,226 --> 00:01:56,218<br>
Regardless of your application, is a video streaming application or any other communication type of application, or a fintech application, or energy, or whatever, this memory kill, out of memory kill still occurs.</p>
<p>12<br>
00:01:56,314 --> 00:02:05,622<br>
And what is an out of memory kill? Well, it's essentially the extreme event in which the machine doesn't have any more memory left.</p>
<p>13<br>
00:02:05,756 --> 00:02:16,678<br>
And so usually the operating system can start eventually swapping, which means using the SSD or the hard drive as a source of memory.</p>
<p>14<br>
00:02:16,834 --> 00:02:19,100<br>
But that, of course, will slow down a lot.</p>
<p>15<br>
00:02:19,430 --> 00:02:45,210<br>
And eventually when there is a bug or a memory leak, or if there are other applications running on the same machine, of course there is some kind of limiting factor that essentially kills the application, something that occurs from the operating system most of the time that kills the application in order to prevent the application from monopolizing the entire machine, the hardware of the machine.</p>
<p>16<br>
00:02:45,710 --> 00:02:48,500<br>
And so this is a very important problem.</p>
<p>17<br>
00:02:49,070 --> 00:03:03,306<br>
Also, it is important to have an episode about this because there are some strategies that I've used at Netflix that are pretty much in line with what I believe machine learning should be about.</p>
<p>18<br>
00:03:03,368 --> 00:03:25,062<br>
And usually people would go for the fancy solution there like this extremely accurate predictors or machine learning models, but you should have a massive number of parameters and that try to figure out whatever is happening on that machine that is running that application.</p>
<p>19<br>
00:03:25,256 --> 00:03:29,466<br>
While the solution at Netflix is pretty straightforward, it's pretty simple.</p>
<p>20<br>
00:03:29,588 --> 00:03:33,654<br>
And so one would say then why making an episode after this? Well.</p>
<p>21<br>
00:03:33,692 --> 00:03:45,730<br>
Because I think that we need more sobriety when it comes to machine learning and I believe we still need to spend a lot of time thinking about what data to collect.</p>
<p>22<br>
00:03:45,910 --> 00:03:59,730<br>
Reasoning about what is the problem at hand and what is the data that can actually tickle the particular machine learning model and then of course move to the actual prediction that is the actual model.</p>
<p>23<br>
00:03:59,900 --> 00:04:15,910<br>
That most of the time it doesn't need to be one of these super fancy things that you see on the news around chatbots or autonomous gaming agent or drivers and so on and so forth.</p>
<p>24<br>
00:04:16,030 --> 00:04:28,518<br>
So there are essentially two data sets that the people at Netflix focus on which are consistently different, dramatically different in fact.</p>
<p>25<br>
00:04:28,604 --> 00:04:45,570<br>
These are data about device characteristics and capabilities and of course data that are collected at Runtime and that give you a picture of what's going on in the memory of the device, right? So that's the so called runtime memory data and out of memory kills.</p>
<p>26<br>
00:04:45,950 --> 00:05:03,562<br>
So the first type of data is I would consider it very static because it considers for example, the device type ID, the version of the software development kit that application is running, cache capacities, buffer capacities and so on and so forth.</p>
<p>27<br>
00:05:03,646 --> 00:05:11,190<br>
So it's something that most of the time doesn't change across sessions and so that's why it's considered static.</p>
<p>28<br>
00:05:12,050 --> 00:05:18,430<br>
In contrast, the other type of data, the Runtime memory data, as the name says it's runtime.</p>
<p>29<br>
00:05:18,490 --> 00:05:24,190<br>
So it varies across the life of the session it's collected at Runtime.</p>
<p>30<br>
00:05:24,250 --> 00:05:25,938<br>
So it's very dynamic data.</p>
<p>31<br>
00:05:26,084 --> 00:05:36,298<br>
And example of these records are for example, profile, movie details, playback information, current memory usage, et cetera, et cetera.</p>
<p>32<br>
00:05:36,334 --> 00:05:56,086<br>
So this is the data that actually moves and moves in the sense that it changes depending on how the user is actually using the Netflix application, what movie or what profile description, what movie detail has been loaded for that particular movie and so on and so forth.</p>
<p>33<br>
00:05:56,218 --> 00:06:15,094<br>
So one thing that of course the first difficulty of the first challenge that the people at Netflix had to deal with was how would you combine these two things, very static and usually small tables versus very dynamic and usually large tables or views.</p>
<p>34<br>
00:06:15,142 --> 00:06:36,702<br>
Well, there is some sort of join on key that is performed by the people at Netflix in order to put together these different data resolutions, right, which is data of the same phenomenon but from different sources and with different carrying very different signals in there.</p>
<p>35<br>
00:06:36,896 --> 00:06:48,620<br>
So the device capabilities is captured usually by the static data and of course the other data, the Runtime memory and out of memory kill data.</p>
<p>36<br>
00:06:48,950 --> 00:07:04,162<br>
These are also, as I said, the data that will describe pretty accurately how is the user using that particular application on that particular hardware.</p>
<p>37<br>
00:07:04,306 --> 00:07:17,566<br>
Now of course, when it comes to data and deer, there is nothing new that people at Netflix have introduced dealing with missing data for example, or incorporating knowledge of devices.</p>
<p>38<br>
00:07:17,698 --> 00:07:26,062<br>
It's all stuff that it's part of the so called data cleaning and data collection strategy, right? Or data preparation.</p>
<p>39<br>
00:07:26,146 --> 00:07:40,782<br>
That is, whatever you're going to do in order to make that data or a combination of these data sources, let's say, compatible with the way your machine learning model will understand or will read that data.</p>
<p>40<br>
00:07:40,916 --> 00:07:58,638<br>
So if you think of a big data platform, the first step, the first challenge you have to deal, you have to deal with is how can I, first of all, collect the right amount of information, the right data, but also how to transform this data for my particular big data platform.</p>
<p>41<br>
00:07:58,784 --> 00:08:12,798<br>
And that's something that, again, nothing new, nothing fancy, just basics, what we have been used to, what we are used to seeing now for the last decade or more, that's exactly what they do.</p>
<p>42<br>
00:08:12,944 --> 00:08:15,222<br>
And now let me tell you something important.</p>
<p>43<br>
00:08:15,416 --> 00:08:17,278<br>
Cybercriminals are evolving.</p>
<p>44<br>
00:08:17,374 --> 00:08:22,446<br>
Their techniques and tactics are more advanced, intricate and dangerous than ever before.</p>
<p>45<br>
00:08:22,628 --> 00:08:30,630<br>
Industries and governments around the world are fighting back on dealing new regulations meant to better protect data against this rising threat.</p>
<p>46<br>
00:08:30,950 --> 00:08:39,262<br>
Today, the world of cybersecurity compliance is a complex one, and understanding the requirements your organization must adhere to can be a daunting task.</p>
<p>47<br>
00:08:39,406 --> 00:08:42,178<br>
But not when the pack has your best architect.</p>
<p>48<br>
00:08:42,214 --> 00:08:53,840<br>
Wolf, the leader in security operations, is on a mission to end cyber risk by giving organizations the protection, information and confidence they need to protect their people, technology and data.</p>
<p>49<br>
00:08:54,170 --> 00:09:02,734<br>
The new interactive compliance portal helps you discover the regulations in your region and industry and start the journey towards achieving and maintaining compliance.</p>
<p>50<br>
00:09:02,902 --> 00:09:07,542<br>
Visit Arcticwolves.com DataScience to take your first step.</p>
<p>51<br>
00:09:07,676 --> 00:09:11,490<br>
That's arcticwolf.com DataScience.</p>
<p>52<br>
00:09:12,050 --> 00:09:18,378<br>
I think that the most important part, though, I think are actually equally important.</p>
<p>53<br>
00:09:18,464 --> 00:09:26,854<br>
But the way they treat runtime memory data and out of memory kill data is by using sliding windows.</p>
<p>54<br>
00:09:26,962 --> 00:09:38,718<br>
So that's something that is really worth mentioning, because the way you would frame this problem is something is happening at some point in time and I have to kind of predict that event.</p>
<p>55<br>
00:09:38,864 --> 00:09:49,326<br>
That is usually an outlier in the sense that these events are quite rare, fortunately, because Netflix would not be as usable as we believe it is.</p>
<p>56<br>
00:09:49,448 --> 00:10:04,110<br>
So you would like to predict these weird events by looking at a historical view or an historical amount of records that you have before this particular event, which is the kill of the application.</p>
<p>57<br>
00:10:04,220 --> 00:10:12,870<br>
So the concept of the sliding window, the sliding window approach is something that comes as the most natural thing anyone would do.</p>
<p>58<br>
00:10:13,040 --> 00:10:18,366<br>
And that's exactly what the researchers and Netflix have done.</p>
<p>59<br>
00:10:18,488 --> 00:10:25,494<br>
So unexpectedly, in my opinion, they treated this problem as a time series, which is exactly what it is.</p>
<p>60<br>
00:10:25,652 --> 00:10:26,190<br>
Now.</p>
<p>61<br>
00:10:26,300 --> 00:10:26,754<br>
They.</p>
<p>62<br>
00:10:26,852 --> 00:10:27,330<br>
Of course.</p>
<p>63<br>
00:10:27,380 --> 00:10:31,426<br>
Use this sliding window with a different horizon.</p>
<p>64<br>
00:10:31,558 --> 00:10:32,190<br>
Five minutes.</p>
<p>65<br>
00:10:32,240 --> 00:10:32,838<br>
Four minutes.</p>
<p>66<br>
00:10:32,924 --> 00:10:33,702<br>
Two minutes.</p>
<p>67<br>
00:10:33,836 --> 00:10:36,366<br>
As close as possible to the event.</p>
<p>68<br>
00:10:36,548 --> 00:10:38,886<br>
Because maybe there are some.</p>
<p>69<br>
00:10:39,008 --> 00:10:39,762<br>
Let's say.</p>
<p>70<br>
00:10:39,896 --> 00:10:45,678<br>
Other dynamics that can raise when you are very close to the event or when you are very far from it.</p>
<p>71<br>
00:10:45,704 --> 00:10:50,166<br>
Like five minutes far from the out of memory kill.</p>
<p>72<br>
00:10:50,348 --> 00:10:51,858<br>
Might have some other.</p>
<p>73<br>
00:10:51,944 --> 00:10:52,410<br>
Let's say.</p>
<p>74<br>
00:10:52,460 --> 00:10:55,986<br>
Diagrams or shapes in the data.</p>
<p>75<br>
00:10:56,168 --> 00:11:11,310<br>
So for example, you might have a certain number of allocations that keep growing and growing, but eventually they grow with a certain curve or a certain rate that you can measure when you are five to ten minutes far from the out of memory kill.</p>
<p>76<br>
00:11:11,420 --> 00:11:16,566<br>
When you are two minutes far from the out of memory kill, probably this trend will change.</p>
<p>77<br>
00:11:16,688 --> 00:11:30,800<br>
And so probably what you would expect is that the memory is already half or more saturated and therefore, for example, the operating system starts swapping or other things are happening that you are going to measure in this.</p>
<p>78<br>
00:11:31,550 --> 00:11:39,730<br>
And that would give you a much better picture of what's going on in the, let's say, closest neighborhood of that event, the time window.</p>
<p>79<br>
00:11:39,790 --> 00:11:51,042<br>
The sliding window and time window approach is definitely worth mentioning because this is something that you can apply if you think pretty much anywhere right now.</p>
<p>80<br>
00:11:51,116 --> 00:11:52,050<br>
What they did.</p>
<p>81<br>
00:11:52,160 --> 00:12:04,146<br>
In addition to having a time window, a sliding window, they also assign different levels to memory readings that are closer to the out of memory kill.</p>
<p>82<br>
00:12:04,208 --> 00:12:10,062<br>
And usually these levels are higher and higher as we get closer and closer to the out of memory kill.</p>
<p>83<br>
00:12:10,136 --> 00:12:15,402<br>
So this means that, for example, we would have, for a five minute window, we would have a level one.</p>
<p>84<br>
00:12:15,596 --> 00:12:22,230<br>
Five minute means five minutes far from the out of memory kill, four minutes would be a level two.</p>
<p>85<br>
00:12:22,280 --> 00:12:37,234<br>
Three minutes it's much closer would be a level three, two minutes would be a level four, which means like kind of the severity of the event as we get closer and closer to the actual event when the application is actually killed.</p>
<p>86<br>
00:12:37,342 --> 00:12:51,474<br>
So by looking at this approach, nothing new there, even, I would say not even a seasoned data scientist would have understood that using a sliding window is the way to go.</p>
<p>87<br>
00:12:51,632 --> 00:12:55,482<br>
I'm not saying that Netflix engineers are not seasoned enough.</p>
<p>88<br>
00:12:55,556 --> 00:13:04,350<br>
Actually they do a great job every day to keep giving us video streaming platforms that actually never fail or almost never fail.</p>
<p>89<br>
00:13:04,910 --> 00:13:07,460<br>
So spot on there, guys, good job.</p>
<p>90<br>
00:13:07,850 --> 00:13:27,738<br>
But looking at this sliding window approach, the direct consequence of this is that they can plot, they can do some sort of graphical analysis of the out of memory kills versus the memory usage that can give the reader or the data scientist a very nice picture of what's going on there.</p>
<p>91<br>
00:13:27,824 --> 00:13:39,330<br>
And so you would have, for example, and I would definitely report some of the pictures, some of the diagrams and graphs in the show notes of this episode on the official website datascienceaton.com.</p>
<p>92<br>
00:13:39,500 --> 00:13:48,238<br>
But essentially what you can see there is that there might be premature peaks at, let's say, a lower memory reading.</p>
<p>93<br>
00:13:48,334 --> 00:14:08,958<br>
And usually these are some kind of false positives or anomalies that should not be there, then it's possible to set a threshold where the threshold to start lowering the memory usage because after that threshold something nasty can happen and usually happens according to your data.</p>
<p>94<br>
00:14:09,104 --> 00:14:18,740<br>
And then of course there is another graph about the Gaussian distribution or in fact no sharp peak at all.</p>
<p>95<br>
00:14:19,250 --> 00:14:21,898<br>
That is like kills or out of memory.</p>
<p>96<br>
00:14:21,934 --> 00:14:33,754<br>
Kills are more or less distributed in a normalized fashion and then of course there are the genuine peaks that indicate that kills near, let's say, the threshold.</p>
<p>97<br>
00:14:33,802 --> 00:14:38,758<br>
And so usually you would see that after that particular threshold of memory usage.</p>
<p>98<br>
00:14:38,914 --> 00:14:42,142<br>
You see most of the out of memory kills.</p>
<p>99<br>
00:14:42,226 --> 00:14:45,570<br>
Which makes sense because given a particular device.</p>
<p>100<br>
00:14:45,890 --> 00:14:48,298<br>
Which means certain amount of memories.</p>
<p>101<br>
00:14:48,394 --> 00:14:50,338<br>
Certain memory characteristics.</p>
<p>102<br>
00:14:50,494 --> 00:14:53,074<br>
Certain version of the SDK and so on and so forth.</p>
<p>103<br>
00:14:53,182 --> 00:14:53,814<br>
You can say.</p>
<p>104<br>
00:14:53,852 --> 00:14:54,090<br>
Okay.</p>
<p>105<br>
00:14:54,140 --> 00:15:10,510<br>
Well for this device type I have this memory memory usage threshold and after this I see that I have a relatively high number of out of memory kills immediately after this threshold.</p>
<p>106<br>
00:15:10,570 --> 00:15:18,150<br>
And this means that probably that is the threshold you would like to consider as the critical threshold you should never or almost never cross.</p>
<p>107<br>
00:15:18,710 --> 00:15:38,758<br>
So once you have this picture in front of you, you can start thinking of implementing some mechanisms that can monitor the memory usage and of course kind of preemptively dialocate things or keep that memory threshold as low as possible with respect to the critical threshold.</p>
<p>108<br>
00:15:38,794 --> 00:15:53,446<br>
So you can start implementing some logic that prevents the application from being killed by the operating system so that you would in fact reduce the rate of out of memory kills overall.</p>
<p>109<br>
00:15:53,578 --> 00:16:11,410<br>
Now, as always and as also the engineers state in their blog post, in the technical post, they say well, it's much more important for us to predict with a certain amount of false positive rather than false negatives.</p>
<p>110<br>
00:16:11,590 --> 00:16:18,718<br>
False negatives means missing an out of memory kill that actually occurred but got not predicted.</p>
<p>111<br>
00:16:18,874 --> 00:16:40,462<br>
If you are a regular listener of this podcast, that statement should resonate with you because this is exactly what happens, for example in healthcare applications, which means that doctors or algorithms that operate in healthcare would definitely prefer to have a bit more false positives rather than more false negatives.</p>
<p>112<br>
00:16:40,486 --> 00:16:54,800<br>
Because missing that someone is sick means that you are not providing a cure and you're just sending the patient home when he or she is sick, right? That's the false positive, it's the mess.</p>
<p>113<br>
00:16:55,130 --> 00:16:57,618<br>
So that's a false negative, it's the mess.</p>
<p>114<br>
00:16:57,764 --> 00:17:09,486<br>
But having a false positive, what can go wrong with having a false positive? Well, probably you will undergo another test to make sure that the first test is confirmed or not.</p>
<p>115<br>
00:17:09,608 --> 00:17:16,018<br>
So adding a false positive in this case is relatively okay with respect to having a false negative.</p>
<p>116<br>
00:17:16,054 --> 00:17:19,398<br>
And that's exactly what happens to the Netflix application.</p>
<p>117<br>
00:17:19,484 --> 00:17:32,094<br>
Now, I don't want to say that of course Netflix application is as critical as, for example, the application that predicts a cancer or an xray or something on an xray or disorder or disease of some sort.</p>
<p>118<br>
00:17:32,252 --> 00:17:48,090<br>
But what I'm saying is that there are some analogies when it comes to machine learning and artificial intelligence and especially data science, the old school data science, there are several things that kind of are, let's say, invariant across sectors.</p>
<p>119<br>
00:17:48,410 --> 00:17:56,826<br>
And so, you know, two worlds like the media streaming or video streaming and healthcare are of course very different from each other.</p>
<p>120<br>
00:17:56,888 --> 00:18:05,274<br>
But when it comes to machine learning and data science applications, well, there are a lot of analogies there.</p>
<p>121<br>
00:18:05,372 --> 00:18:06,202<br>
And indeed.</p>
<p>122<br>
00:18:06,286 --> 00:18:10,234<br>
In terms of the models that they use at Netflix to predict.</p>
<p>123<br>
00:18:10,342 --> 00:18:24,322<br>
Once they have the sliding window data and essentially they have the ground truth of where this out of memory kill happened and what happened before to the memory of the application or the machine.</p>
<p>124<br>
00:18:24,466 --> 00:18:24,774<br>
Well.</p>
<p>125<br>
00:18:24,812 --> 00:18:30,514<br>
Then the models they use to predict these things is these events is Artificial Neural Networks.</p>
<p>126<br>
00:18:30,622 --> 00:18:31,714<br>
Xg Boost.</p>
<p>127<br>
00:18:31,822 --> 00:18:36,742<br>
Ada Boost or Adaptive Boosting Elastic Net with Softmax and so on and so forth.</p>
<p>128<br>
00:18:36,766 --> 00:18:39,226<br>
So nothing fancy.</p>
<p>129<br>
00:18:39,418 --> 00:18:45,046<br>
As you can see, Xg Boost is probably one of the most used I would have expected even random forest.</p>
<p>130<br>
00:18:45,178 --> 00:18:47,120<br>
Probably they do, they've tried that.</p>
<p>131<br>
00:18:47,810 --> 00:18:58,842<br>
But XGBoost is probably one of the most used models on kaggle competitions for a reason, because it works and it leverages a lot.</p>
<p>132<br>
00:18:58,916 --> 00:19:04,880<br>
The data preparation step, that solves already more than half of the problem.</p>
<p>133<br>
00:19:05,810 --> 00:19:07,270<br>
Thank you so much for listening.</p>
<p>134<br>
00:19:07,330 --> 00:19:11,910<br>
I also invite you, as always, to join the Discord Channel.</p>
<p>135<br>
00:19:12,020 --> 00:19:15,966<br>
You will find a link on the official website datascience@home.com.</p>
<p>136<br>
00:19:16,148 --> 00:19:17,600<br>
Speak with you next time.</p>
<p>137<br>
00:19:18,350 --> 00:19:21,382<br>
You've been listening to Data Science at home podcast.</p>
<p>138<br>
00:19:21,466 --> 00:19:26,050<br>
Be sure to subscribe on itunes, Stitcher, or Pot Bean to get new, fresh episodes.</p>
<p>139<br>
00:19:26,110 --> 00:19:31,066<br>
For more, please follow us on Instagram, Twitter and Facebook or visit our website at datascienceathome.com</p>
<p>Â </p>
References
<p><a href='https://netflixtechblog.com/formulating-out-of-memory-kill-prediction-on-the-netflix-app-as-a-machine-learning-problem-989599029109'>https://netflixtechblog.com/formulating-out-of-memory-kill-prediction-on-the-netflix-app-as-a-machine-learning-problem-989599029109</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cejk9f/predict-out-of-memory-kill-netflix.mp3" length="26127927" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Sometimes applications crash. Some other times applications crash because memory is exhausted. Such issues exist because of bugs in the code, or heavy memory usage for reasons that were not expected during design and implementation. Can we use machine learning to predict and eventually detect out of memory kills from the operating system?
Apparently, the Netflix app many of us use on a daily basis leverage ML and time series analysis to prevent OOM-kills.
Enjoy the show!
Our Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â 
Transcript
100:00:04,150 --> 00:00:09,034And here we are again with the season four of the Data Science at Home podcast.
200:00:09,142 --> 00:00:19,170This time we have something for you if you want to help us shape the data science leaders of the future, we have created the the Data Science at Home's Ambassador program.
300:00:19,340 --> 00:00:28,378Ambassadors are volunteers who are passionate about data science and want to give back to our growing community of data science professionals and enthusiasts.
400:00:28,534 --> 00:00:37,558You will be instrumental in helping us achieve our goal of raising awareness about the critical role of data science in cutting edge technologies.
500:00:37,714 --> 00:00:45,740If you want to learn more about this program, visit the Ambassadors page on our website@datascienceathome.com.
600:00:46,430 --> 00:00:49,234Welcome back to another episode of Data Science at Home podcast.
700:00:49,282 --> 00:00:55,426I'm Francesco Podcasting from the Regular Office of Amethyx Technologies, based in Belgium.
800:00:55,618 --> 00:01:02,914In this episode, I want to speak about a machine learning problem that has been formulated at Netflix.
900:01:03,022 --> 00:01:22,038And for the record, Netflix is not sponsoring this episode, though I still believe that this problem is a very well known problem, a very common one across factors, which is how to predict out of memory kill in an application and formulate this problem as a machine learning problem.
1000:01:22,184 --> 00:01:39,142So this is something that, as I said, is very interesting, not just because of Netflix, but because it allows me to explain a few points that, as I said, are kind of invariance across sectors.
1100:01:39,226 --> 00:01:56,218Regardless of your application, is a video streaming application or any other communication type of application, or a fintech application, or energy, or whatever, this memory kill, out of memory kill still occurs.
1200:01:56,314 --> 00:02:05,622And what is an out of memory kill? Well, it's essentially the extreme event in which the machine doesn't have any more memory left.
1300:02:05,756 --> 00:02:16,678And so usually the operating system can start eventually swapping, which means using the SSD or the hard drive as a source of memory.
1400:02:16,834 --> 00:02:19,100But that, of course, will slow down a lot.
1500:02:19,430 --> 00:02:45,210And eventually when there is a bug or a memory leak, or if there are other applications running on the same machine, of course there is some kind of limiting factor that essentially kills the application, something that occurs from the operating system most of the time that kills the application in order to prevent the application from monopolizing the entire machine, the hardware of the machine.
1600:02:45,710 --> 00:02:48,500And so this is a very important problem.
1700:02:49,070 --> 00:03:03,306Also, it is important to have an episode about this because there are some strategies that I've used at Netflix that are pretty much in line with what I]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:33</itunes:duration>
                <itunes:episode>203</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Is studying AI in academia a waste of time? (Ep. 202)</title>
        <itunes:title>Is studying AI in academia a waste of time? (Ep. 202)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-in-academia-is-a-waste-of-time/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-in-academia-is-a-waste-of-time/#comments</comments>        <pubDate>Tue, 13 Sep 2022 07:03:50 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d97a105e-a91c-3b9b-a132-fe20b498a93f</guid>
                                    <description><![CDATA[<p>Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.
However, there is doubt about how powerful and effective such research efforts are.
Is studying AI in academia a waste of time?</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.<br>
However, there is doubt about how powerful and effective such research efforts are.<br>
Is studying AI in academia a waste of time?</p>
<p>Â </p>
Our Sponsors
<p>Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let <a href='https://arcticwolf.com/datascience'>Arctic Wolf</a> be your guide.<br>
Check it out at <a href='https://arcticwolf.com/datascience'>https://arcticwolf.com/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com/'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/kysvft/ai-academia-waste-time.mp3" length="23917335" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Companies and other business entities are actively involved in defining data products and applied research every year. Academia has always played a role in creating new methods and solutions/algorithms in the fields of machine learning and artificial intelligence.However, there is doubt about how powerful and effective such research efforts are.Is studying AI in academia a waste of time?
Â 
Our Sponsors
Explore the Complex World of Regulations. Compliance can be overwhelming. Multiple frameworks. Overlapping requirements. Let Arctic Wolf be your guide.Check it out at https://arcticwolf.com/datascience
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations and startups, so they can create a better future for everyone they serve. We provide solutions in AI/ML, Fintech, Healthcare/RWE, and Predictive maintenance.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:28</itunes:duration>
                <itunes:episode>204</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Zero-Cost Proxies: How to find the best neural network without training (Ep. 201)</title>
        <itunes:title>Zero-Cost Proxies: How to find the best neural network without training (Ep. 201)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/zero-cost-proxies/</link>
                    <comments>https://datascienceathome.podbean.com/e/zero-cost-proxies/#comments</comments>        <pubDate>Wed, 07 Sep 2022 07:14:47 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/aecadfe6-9c0e-31fd-afb2-bb3538ccaedd</guid>
                                    <description><![CDATA[<p>Neural networks are becoming massive monsters that are hard to train (without the "regular" 12 last-generation GPUs).
Is there a way to skip that?</p>
<p>Let me introduce you to Zero-Cost proxies</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/'>https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/</a></li>
<li>https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/</li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>Neural networks are becoming massive monsters that are hard to train (without the "regular" 12 last-generation GPUs).<br>
Is there a way to skip that?</p>
<p>Let me introduce you to Zero-Cost proxies</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<ol><li><a href='https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/'>https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/</a></li>
<li>https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/</li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/w8fgu6/zero-cost-proxies.mp3" length="26103628" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Neural networks are becoming massive monsters that are hard to train (without the "regular" 12 last-generation GPUs).Is there a way to skip that?
Let me introduce you to Zero-Cost proxies
Â 
Â 
References
https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/
https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:35</itunes:duration>
                <itunes:episode>201</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Online learning is better than batch, right? Wrong! (Ep. 200)</title>
        <itunes:title>Online learning is better than batch, right? Wrong! (Ep. 200)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/online-learning-is-better-than-batch-right-wrong-ep-200/</link>
                    <comments>https://datascienceathome.podbean.com/e/online-learning-is-better-than-batch-right-wrong-ep-200/#comments</comments>        <pubDate>Mon, 13 Jun 2022 06:40:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/e759c9ec-add8-3bff-9751-9f0e58285100</guid>
                                    <description><![CDATA[<p>In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.
Also in this episode, I have to deal with an intruder :) </p>
<p>Â </p>
<p>Â </p>
<p>Links</p>
<p>Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87. pp.Â 123â€“138. <a href='https://en.wikipedia.org/wiki/Doi_(identifier)'>doi</a>:<a href='https://doi.org/10.1145%2F41457.37515'>10.1145/41457.37515</a>. <a href='https://en.wikipedia.org/wiki/ISBN_(identifier)'>ISBN</a>Â <a href='https://en.wikipedia.org/wiki/Special:BookSources/089791242X'>089791242X</a>. <a href='https://en.wikipedia.org/wiki/S2CID_(identifier)'>S2CID</a>Â <a href='https://api.semanticscholar.org/CorpusID:7739589'>7739589</a>.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.<br>
Also in this episode, I have to deal with an intruder :) </p>
<p>Â </p>
<p>Â </p>
<p>Links</p>
<p>Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". <em>Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87</em>. pp.Â 123â€“138. <a href='https://en.wikipedia.org/wiki/Doi_(identifier)'>doi</a>:<a href='https://doi.org/10.1145%2F41457.37515'>10.1145/41457.37515</a>. <a href='https://en.wikipedia.org/wiki/ISBN_(identifier)'>ISBN</a>Â <a href='https://en.wikipedia.org/wiki/Special:BookSources/089791242X'>089791242X</a>. <a href='https://en.wikipedia.org/wiki/S2CID_(identifier)'>S2CID</a>Â <a href='https://api.semanticscholar.org/CorpusID:7739589'>7739589</a>.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nkvyiy/online-learning.mp3" length="37910420" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about online learning systems and why blindly choosing such a paradigm can lead to very unpredictable and expensive outcomes.Also in this episode, I have to deal with an intruder :) 
Â 
Â 
Links
Birman, K.; Joseph, T. (1987). "Exploiting virtual synchrony in distributed systems". Proceedings of the Eleventh ACM Symposium on Operating Systems Principles - SOSP '87. pp.Â 123â€“138. doi:10.1145/41457.37515. ISBNÂ 089791242X. S2CIDÂ 7739589.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:08</itunes:duration>
                <itunes:episode>200</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What are generalist agents and why they can change the AI game (Ep. 199)</title>
        <itunes:title>What are generalist agents and why they can change the AI game (Ep. 199)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-are-generalist-agents-and-why-they-can-change-the-ai-game-ep-199/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-are-generalist-agents-and-why-they-can-change-the-ai-game-ep-199/#comments</comments>        <pubDate>Fri, 03 Jun 2022 13:34:42 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0b029130-1e5f-3dbd-a7fb-7e3d7218b7c5</guid>
                                    <description><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
<a href='https://arxiv.org/pdf/2205.06175'>https://arxiv.org/pdf/2205.06175</a>
Â 
Â ]]></description>
                                                            <content:encoded><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
<a href='https://arxiv.org/pdf/2205.06175'>https://arxiv.org/pdf/2205.06175</a>
Â 
Â ]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/p3cu52/gato-generalist-model.mp3" length="26779781" type="audio/mpeg"/>
        <itunes:summary><![CDATA[That deep learning alone is not sufficient to solve artificial general intelligence, is more and more accepted statement.
Generalist agents have great properties that can overcome some of the limitations of single-task deep learning models.
Be aware, we are still far from AGI, though.
Â 
So what are generalist agents?
Â 
References
https://arxiv.org/pdf/2205.06175
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:06</itunes:duration>
                <itunes:episode>199</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Streaming data with ease. With Chip Kent from Deephaven Data Labs (Ep. 198)</title>
        <itunes:title>Streaming data with ease. With Chip Kent from Deephaven Data Labs (Ep. 198)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/streaming-data-with-ease-with-chip-kent-from-deephaven-data-labs-ep-198/</link>
                    <comments>https://datascienceathome.podbean.com/e/streaming-data-with-ease-with-chip-kent-from-deephaven-data-labs-ep-198/#comments</comments>        <pubDate>Fri, 27 May 2022 10:04:59 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3d16524f-7be8-35a1-a063-fb2e0a622f09</guid>
                                    <description><![CDATA[<p>In this episode, I am with Chip Kent, chief data scientist at<a href='http://deephaven.io/'> Deephaven Data Labs</a>. </p>
<p>We speak about streaming data, real-time, and other powerful tools part of the Deephaven platform.</p>
<p>Â </p>
<p>Links</p>
<ul><li>Deephaven - <a href='https://deephaven.io'>https://deephaven.io</a></li>
<li>Deephaven Community Core Documentation - â€‹â€‹<a href='https://deephaven.io/core/docs/'>https://deephaven.io/core/docs/</a></li>
<li>Deephaven Community Slack - <a href='https://join.slack.com/t/deephavencommunity/shared_invite/zt-11x3hiufp-DmOMWDAvXv_pNDUlVkagLQ'>https://join.slack.com/t/deephavencommunity/shared_invite/zt-11x3hiufp-DmOMWDAvXv_pNDUlVkagLQ</a></li>
</ul>
<p>GitHub:</p>
<ul><li style="font-weight:400;">Deephaven Community Core - <a href='https://github.com/deephaven/deephaven-core'>https://github.com/deephaven/deephaven-core</a></li>
<li style="font-weight:400;">Barrage - <a href='https://github.com/deephaven/barrage'>https://github.com/deephaven/barrage</a></li>
<li style="font-weight:400;">Deephaven web components - <a href='https://github.com/deephaven/web-client-ui'>https://github.com/deephaven/web-client-ui</a></li>
</ul>
<p>YouTube Channel - <a href='https://www.youtube.com/channel/UCoaYOlkX555PSTTJz8ZaI_w'>https://www.youtube.com/channel/UCoaYOlkX555PSTTJz8ZaI_w</a></p>
<p>Blog postsÂ </p>
<ul><li style="font-weight:400;">Real-time classification with Deephaven and SciKit-Learn - <a href='https://deephaven.io/blog/2022/02/02/learn-scikit/'>https://deephaven.io/blog/2022/02/02/learn-scikit/</a></li>
<li style="font-weight:400;">Display a quadrillion rows of data in the browser - <a href='https://deephaven.io/blog/2022/01/24/displaying-a-quadrillion-rows/'>https://deephaven.io/blog/2022/01/24/displaying-a-quadrillion-rows/</a></li>
<li style="font-weight:400;">A performance comparison between Materialize and Deephaven - <a href='https://deephaven.io/blog/2022/03/05/deephaven-materialize-study/'>https://deephaven.io/blog/2022/03/05/deephaven-materialize-study/</a></li>
</ul>
<p>Careers <a href='https://deephaven.io/company/careers/'>https://deephaven.io/company/careers/</a></p>
<p>Community Slack <a href='http://deephaven.io/slack'>http://deephaven.io/slack</a>.Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, I am with Chip Kent, chief data scientist at<a href='http://deephaven.io/'> Deephaven Data Labs</a>. </p>
<p>We speak about streaming data, real-time, and other powerful tools part of the Deephaven platform.</p>
<p>Â </p>
<p>Links</p>
<ul><li>Deephaven - <a href='https://deephaven.io'>https://deephaven.io</a></li>
<li>Deephaven Community Core Documentation - â€‹â€‹<a href='https://deephaven.io/core/docs/'>https://deephaven.io/core/docs/</a></li>
<li>Deephaven Community Slack - <a href='https://join.slack.com/t/deephavencommunity/shared_invite/zt-11x3hiufp-DmOMWDAvXv_pNDUlVkagLQ'>https://join.slack.com/t/deephavencommunity/shared_invite/zt-11x3hiufp-DmOMWDAvXv_pNDUlVkagLQ</a></li>
</ul>
<p>GitHub:</p>
<ul><li style="font-weight:400;">Deephaven Community Core - <a href='https://github.com/deephaven/deephaven-core'>https://github.com/deephaven/deephaven-core</a></li>
<li style="font-weight:400;">Barrage - <a href='https://github.com/deephaven/barrage'>https://github.com/deephaven/barrage</a></li>
<li style="font-weight:400;">Deephaven web components - <a href='https://github.com/deephaven/web-client-ui'>https://github.com/deephaven/web-client-ui</a></li>
</ul>
<p>YouTube Channel - <a href='https://www.youtube.com/channel/UCoaYOlkX555PSTTJz8ZaI_w'>https://www.youtube.com/channel/UCoaYOlkX555PSTTJz8ZaI_w</a></p>
<p>Blog postsÂ </p>
<ul><li style="font-weight:400;">Real-time classification with Deephaven and SciKit-Learn - <a href='https://deephaven.io/blog/2022/02/02/learn-scikit/'>https://deephaven.io/blog/2022/02/02/learn-scikit/</a></li>
<li style="font-weight:400;">Display a quadrillion rows of data in the browser - <a href='https://deephaven.io/blog/2022/01/24/displaying-a-quadrillion-rows/'>https://deephaven.io/blog/2022/01/24/displaying-a-quadrillion-rows/</a></li>
<li style="font-weight:400;">A performance comparison between Materialize and Deephaven - <a href='https://deephaven.io/blog/2022/03/05/deephaven-materialize-study/'>https://deephaven.io/blog/2022/03/05/deephaven-materialize-study/</a></li>
</ul>
<p>Careers <a href='https://deephaven.io/company/careers/'>https://deephaven.io/company/careers/</a></p>
<p>Community Slack <a href='http://deephaven.io/slack'>http://deephaven.io/slack</a>.Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pydjsh/real-time-deephaven.mp3" length="30241228" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, I am with Chip Kent, chief data scientist at Deephaven Data Labs. 
We speak about streaming data, real-time, and other powerful tools part of the Deephaven platform.
Â 
Links
Deephaven - https://deephaven.io
Deephaven Community Core Documentation - â€‹â€‹https://deephaven.io/core/docs/
Deephaven Community Slack - https://join.slack.com/t/deephavencommunity/shared_invite/zt-11x3hiufp-DmOMWDAvXv_pNDUlVkagLQ
GitHub:
Deephaven Community Core - https://github.com/deephaven/deephaven-core
Barrage - https://github.com/deephaven/barrage
Deephaven web components - https://github.com/deephaven/web-client-ui
YouTube Channel - https://www.youtube.com/channel/UCoaYOlkX555PSTTJz8ZaI_w
Blog postsÂ 
Real-time classification with Deephaven and SciKit-Learn - https://deephaven.io/blog/2022/02/02/learn-scikit/
Display a quadrillion rows of data in the browser - https://deephaven.io/blog/2022/01/24/displaying-a-quadrillion-rows/
A performance comparison between Materialize and Deephaven - https://deephaven.io/blog/2022/03/05/deephaven-materialize-study/
Careers https://deephaven.io/company/careers/
Community Slack http://deephaven.io/slack.Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:48</itunes:duration>
                <itunes:episode>198</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Learning from data to create personalized experiences with Matt Swalley from Omneky (Ep. 197)</title>
        <itunes:title>Learning from data to create personalized experiences with Matt Swalley from Omneky (Ep. 197)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/learning-from-data-to-create-personalized-experiences-ep-197/</link>
                    <comments>https://datascienceathome.podbean.com/e/learning-from-data-to-create-personalized-experiences-ep-197/#comments</comments>        <pubDate>Mon, 16 May 2022 18:04:46 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f18f4057-5c25-3968-a932-a909f49f78ef</guid>
                                    <description><![CDATA[<p>In this episode I speak with Matt Swalley, Chief Business Officer of <a href='https://www.omneky.com/'>Omneky</a>, an AI platform that generates, analyzes and optimizes personalized ad creatives at scale.</p>
<p>We speak about the way AI is used for generating customized recommendation and creating experiences with data aggregation and analytics. And yes! respecting the privacy of individuals.

</p>
<p>Â </p>
<p>Links</p>
<p>Grow your business with personalized ads <a href='https://www.omneky.com/'>https://www.omneky.com/</a></p>
<p>Data Science at Home Podcast (Live) <a href='https://www.twitch.tv/datascienceathome'>https://www.twitch.tv/datascienceathome</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with Matt Swalley, Chief Business Officer of <a href='https://www.omneky.com/'>Omneky</a>, an AI platform that generates, analyzes and optimizes personalized ad creatives at scale.</p>
<p>We speak about the way AI is used for generating customized recommendation and creating experiences with data aggregation and analytics. And yes! respecting the privacy of individuals.<br>
<br>
</p>
<p>Â </p>
<p>Links</p>
<p>Grow your business with personalized ads <a href='https://www.omneky.com/'>https://www.omneky.com/</a></p>
<p>Data Science at Home Podcast (Live) <a href='https://www.twitch.tv/datascienceathome'>https://www.twitch.tv/datascienceathome</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/bqxk22/personalized-experiences-omneky.mp3" length="30151638" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Matt Swalley, Chief Business Officer of Omneky, an AI platform that generates, analyzes and optimizes personalized ad creatives at scale.
We speak about the way AI is used for generating customized recommendation and creating experiences with data aggregation and analytics. And yes! respecting the privacy of individuals.
Â 
Links
Grow your business with personalized ads https://www.omneky.com/
Data Science at Home Podcast (Live) https://www.twitch.tv/datascienceathome]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:39</itunes:duration>
                <itunes:episode>197</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>State of Artificial Intelligence 2022 (Ep. 196)</title>
        <itunes:title>State of Artificial Intelligence 2022 (Ep. 196)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/state-of-artificial-intelligence-2022-ep-196/</link>
                    <comments>https://datascienceathome.podbean.com/e/state-of-artificial-intelligence-2022-ep-196/#comments</comments>        <pubDate>Fri, 06 May 2022 08:37:31 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a5ab01ac-4d7b-3f5a-be85-e2dfc6c7249f</guid>
                                    <description><![CDATA[<p>Let's take a break and think about the state of AI in 2022. 
In this episode I summarize the long report from the <a href='https://hai.stanford.edu/'>Stanford Institute for Human-Centered Artificial Intelligence</a> (HAI)</p>
<p>Enjoy!</p>
References
<p><a href='https://spectrum.ieee.org/artificial-intelligence-index'>https://spectrum.ieee.org/artificial-intelligence-index</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Let's take a break and think about the state of AI in 2022. <br>
In this episode I summarize the long report from the <a href='https://hai.stanford.edu/'>Stanford Institute for Human-Centered Artificial Intelligence</a> (HAI)</p>
<p>Enjoy!</p>
References
<p><a href='https://spectrum.ieee.org/artificial-intelligence-index'>https://spectrum.ieee.org/artificial-intelligence-index</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jrizz7/state-of-ai-2022.mp3" length="27541301" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Let's take a break and think about the state of AI in 2022. In this episode I summarize the long report from the Stanford Institute for Human-Centered Artificial Intelligence (HAI)
Enjoy!
References
https://spectrum.ieee.org/artificial-intelligence-index
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:26</itunes:duration>
                <itunes:episode>196</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Improving your AI by finding issues within data pockets (Ep. 195)</title>
        <itunes:title>Improving your AI by finding issues within data pockets (Ep. 195)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/improving-your-ai-by-finding-issues-within-data-pockets-ep-195/</link>
                    <comments>https://datascienceathome.podbean.com/e/improving-your-ai-by-finding-issues-within-data-pockets-ep-195/#comments</comments>        <pubDate>Thu, 21 Apr 2022 07:38:20 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/67603c38-377d-30bb-a550-e2a5d9488edc</guid>
                                    <description><![CDATA[<p>In this episode I have a conversation with, Itai Bar-Sinai, CPO & Cofounder of Mona. </p>
<p>We speak about several interesting points about data and monitoring.
Why is AI monitoring so different from monitoring classic software?
How to reduce the gap between data science and business?
What is the role of MLOps in the data monitoring field?
</p>
<p>With over 10 years of experience with AI and as the CPO and head of customer success at Mona, the leading AI monitoring intelligence company, Itai has a unique view of the AI industry. Working closely with data science and ML teams applying dozens of AI solutions in over 10 industries, Itai encounters the wide variety of business use-cases, organizational structures and cultures, and technologies and tools used in todayâ€™s AI world.</p>
<p>Â </p>
References
<p><a href='https://www.monalabs.io'>https://www.monalabs.io</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I have a conversation with, Itai Bar-Sinai, CPO & Cofounder of Mona. </p>
<p>We speak about several interesting points about data and monitoring.<br>
Why is AI monitoring so different from monitoring classic software?<br>
How to reduce the gap between data science and business?<br>
What is the role of MLOps in the data monitoring field?<br>
</p>
<p>With over 10 years of experience with AI and as the CPO and head of customer success at Mona, the leading AI monitoring intelligence company, Itai has a unique view of the AI industry. Working closely with data science and ML teams applying dozens of AI solutions in over 10 industries, Itai encounters the wide variety of business use-cases, organizational structures and cultures, and technologies and tools used in todayâ€™s AI world.</p>
<p>Â </p>
References
<p><a href='https://www.monalabs.io'>https://www.monalabs.io</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/hwi2n5/monalabs.mp3" length="39502513" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I have a conversation with, Itai Bar-Sinai, CPO & Cofounder of Mona. 
We speak about several interesting points about data and monitoring.Why is AI monitoring so different from monitoring classic software?How to reduce the gap between data science and business?What is the role of MLOps in the data monitoring field?
With over 10 years of experience with AI and as the CPO and head of customer success at Mona, the leading AI monitoring intelligence company, Itai has a unique view of the AI industry. Working closely with data science and ML teams applying dozens of AI solutions in over 10 industries, Itai encounters the wide variety of business use-cases, organizational structures and cultures, and technologies and tools used in todayâ€™s AI world.
Â 
References
https://www.monalabs.io
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:03</itunes:duration>
                <itunes:episode>195</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Fake data that looks, feels, and behaves like production.(Ep.194)</title>
        <itunes:title>Fake data that looks, feels, and behaves like production.(Ep.194)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/fake-data-that-looks-feels-and-behaves-like-productionep194/</link>
                    <comments>https://datascienceathome.podbean.com/e/fake-data-that-looks-feels-and-behaves-like-productionep194/#comments</comments>        <pubDate>Wed, 13 Apr 2022 17:51:01 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f88af6c6-0fa5-35a2-b224-ff1c899902d4</guid>
                                    <description><![CDATA[<p>I am with Ander Steele,  data scientist and mathematician with a passion for privacy and Shannon Bayatpur, product manager with a background in technical writing and computer science, from Tonic.ai. We speak about data. Fake data. 
</p>
<p>But all we say is authentic. </p>
<p>Â </p>
<p>Links</p>
<p><a href='https://www.tonic.ai/?ref=datascienceathome'>Tonic website</a>Â  
</p>
<p><a href='https://boards.greenhouse.io/tonic?ref=datascienceathome'>Career page</a>
</p>
<p><a href='https://www.tonic.ai/blog/using-neural-networks-to-synthesize-complex-data-relationships-with-smart-linking?ref=datascienceathome'>Neural networks for synthetic data</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>I am with Ander Steele,  data scientist and mathematician with a passion for privacy and Shannon Bayatpur, product manager with a background in technical writing and computer science, from Tonic.ai. We speak about data. Fake data. <br>
</p>
<p>But all we say is authentic. </p>
<p>Â </p>
<p>Links</p>
<p><a href='https://www.tonic.ai/?ref=datascienceathome'>Tonic website</a>Â  <br>
</p>
<p><a href='https://boards.greenhouse.io/tonic?ref=datascienceathome'>Career page</a><br>
</p>
<p><a href='https://www.tonic.ai/blog/using-neural-networks-to-synthesize-complex-data-relationships-with-smart-linking?ref=datascienceathome'>Neural networks for synthetic data</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/kd92p3/tonic_ai.mp3" length="29504542" type="audio/mpeg"/>
        <itunes:summary><![CDATA[I am with Ander Steele,  data scientist and mathematician with a passion for privacy and Shannon Bayatpur, product manager with a background in technical writing and computer science, from Tonic.ai. We speak about data. Fake data. 
But all we say is authentic. 
Â 
Links
Tonic websiteÂ  
Career page
Neural networks for synthetic data]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:33</itunes:duration>
                <itunes:episode>194</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Batteries and AI in Automotive (Ep. 193)</title>
        <itunes:title>Batteries and AI in Automotive (Ep. 193)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/batteries-and-ai-in-automotive-ep-193/</link>
                    <comments>https://datascienceathome.podbean.com/e/batteries-and-ai-in-automotive-ep-193/#comments</comments>        <pubDate>Fri, 01 Apr 2022 07:27:08 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/413d03d3-d06b-3635-a0ac-15b635117b9e</guid>
                                    <description><![CDATA[<p>In this episode my friend and I speak about AI, batteries and automotive.
Dennis Berner, founder of Digitlabs has been operating in the field of automotive and batteries for a long time. His point of views are absolutely a must to listen to. 

Below a list of the links he mentioned in the show.</p>
<ol><li><a href='https://amethix.com'>https://amethix.com</a></li>
<li style="font-weight:400;"><a href='https://digitlabs.com'>https://digitlabs.com</a></li>
<li style="font-weight:400;"><a href='https://www.moia.io'>https://www.moia.io</a></li>
<li style="font-weight:400;"><a href='https://www.elli.eco'>https://www.elli.eco</a></li>
<li style="font-weight:400;"><a href='https://www.uber.com'>https://www.uber.com</a></li>
<li style="font-weight:400;"><a href='https://www.didiglobal.com/'>https://www.didiglobal.com/</a></li>
<li style="font-weight:400;"><a href='https://waymo.com/'>https://waymo.com/</a></li>
<li style="font-weight:400;"><a href='https://group.mercedes-benz.com/'>https://group.mercedes-benz.com/</a></li>
<li style="font-weight:400;"><a href='https://www.fakultaet73.de'>https://www.fakultaet73.de</a></li>
<li style="font-weight:400;"><a href='https://www.bmw.de'>https://www.bmw.de</a></li>
<li style="font-weight:400;"><a href='https://www.volkswagen.de'>https://www.volkswagen.de</a></li>
<li style="font-weight:400;"><a href='https://cariad.technology/'>https://cariad.technology/</a></li>
</ol><p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode my friend and I speak about AI, batteries and automotive.<br>
Dennis Berner, founder of Digitlabs has been operating in the field of automotive and batteries for a long time. His point of views are absolutely a must to listen to. <br>
<br>
Below a list of the links he mentioned in the show.</p>
<ol><li><a href='https://amethix.com'>https://amethix.com</a></li>
<li style="font-weight:400;"><a href='https://digitlabs.com'>https://digitlabs.com</a></li>
<li style="font-weight:400;"><a href='https://www.moia.io'>https://www.moia.io</a></li>
<li style="font-weight:400;"><a href='https://www.elli.eco'>https://www.elli.eco</a></li>
<li style="font-weight:400;"><a href='https://www.uber.com'>https://www.uber.com</a></li>
<li style="font-weight:400;"><a href='https://www.didiglobal.com/'>https://www.didiglobal.com/</a></li>
<li style="font-weight:400;"><a href='https://waymo.com/'>https://waymo.com/</a></li>
<li style="font-weight:400;"><a href='https://group.mercedes-benz.com/'>https://group.mercedes-benz.com/</a></li>
<li style="font-weight:400;"><a href='https://www.fakultaet73.de'>https://www.fakultaet73.de</a></li>
<li style="font-weight:400;"><a href='https://www.bmw.de'>https://www.bmw.de</a></li>
<li style="font-weight:400;"><a href='https://www.volkswagen.de'>https://www.volkswagen.de</a></li>
<li style="font-weight:400;"><a href='https://cariad.technology/'>https://cariad.technology/</a></li>
</ol><p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/qrjmby/batteries-ai-av.mp3" length="40346025" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode my friend and I speak about AI, batteries and automotive.Dennis Berner, founder of Digitlabs has been operating in the field of automotive and batteries for a long time. His point of views are absolutely a must to listen to. Below a list of the links he mentioned in the show.
https://amethix.com
https://digitlabs.com
https://www.moia.io
https://www.elli.eco
https://www.uber.com
https://www.didiglobal.com/
https://waymo.com/
https://group.mercedes-benz.com/
https://www.fakultaet73.de
https://www.bmw.de
https://www.volkswagen.de
https://cariad.technology/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:17</itunes:duration>
                <itunes:episode>193</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Collect data at the edge [RB] (Ep. 192)</title>
        <itunes:title>Collect data at the edge [RB] (Ep. 192)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/collect-data-at-the-edge-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/collect-data-at-the-edge-rb/#comments</comments>        <pubDate>Fri, 25 Mar 2022 16:16:24 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/056bf1f9-b611-318d-81df-ae65f9e695c9</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by NordVPN</p>
<p>NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='https://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p style="text-align:left;">
and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p style="text-align:left;"><a href='https://tsecond.us/company/manavalan-krishnan/'>https://tsecond.us/company/manavalan-krishnan/</a></p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.<br>
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by NordVPN</p>
<p>NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='https://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p style="text-align:left;"><br>
and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p style="text-align:left;"><a href='https://tsecond.us/company/manavalan-krishnan/'>https://tsecond.us/company/manavalan-krishnan/</a></p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/x9yxxc/capture-data-edge-rb.mp3" length="39197755" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.
Â 
This episode is brought to you by NordVPN
NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing nordvpn.com/DATASCIENCE or use coupon code DATASCIENCE and get a massive discount.
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

https://tsecond.us/company/manavalan-krishnan/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:25</itunes:duration>
                <itunes:episode>192</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Bayesian Machine Learning with Ravin Kumar (Ep. 191)</title>
        <itunes:title>Bayesian Machine Learning with Ravin Kumar (Ep. 191)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/bayesian-machine-learning-with-ravin-kumar-ep-191/</link>
                    <comments>https://datascienceathome.podbean.com/e/bayesian-machine-learning-with-ravin-kumar-ep-191/#comments</comments>        <pubDate>Sat, 19 Mar 2022 16:36:33 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7fe655c4-0456-3fed-a8fe-b80fae607824</guid>
                                    <description><![CDATA[<p>This is one episode where passion for math, statistics and computers are merged. 
I have a very interesting conversation with Ravin,Â  data scientist at Google where he uses data to inform decisions.</p>
<p>He has previously worked at Sweetgreen, designing systems that would benefit team members and communities through sustainable and healthy food, and SpaceX, creating tools that would ultimately launch rocket ships. </p>
<p>All opinions in this episode are his own and none of the companies he has worked for are represented.</p>
<p>Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://go.railz.ai/Railz-DSH'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://www.amazon.com/dp/036789436X/ref=tsm_1_fb_lk'>Bayesian Modeling and Computation in Python (Chapman & Hall/CRC Texts in Statistical Science)
 amazon.com</a></li>
<li style="font-weight:400;"><a href='https://bayesiancomputationbook.com/welcome.html'>Bayesian Modeling and Computation in Python</a></li>
<li style="font-weight:400;"><a href='https://twitter.com/canyon289'>https://twitter.com/canyon289</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>This is one episode where passion for math, statistics and computers are merged. <br>
I have a very interesting conversation with Ravin,Â  data scientist at Google where he uses data to inform decisions.</p>
<p>He has previously worked at Sweetgreen, designing systems that would benefit team members and communities through sustainable and healthy food, and SpaceX, creating tools that would ultimately launch rocket ships. </p>
<p>All opinions in this episode are his own and none of the companies he has worked for are represented.</p>
<p>Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://go.railz.ai/Railz-DSH'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://www.amazon.com/dp/036789436X/ref=tsm_1_fb_lk'>Bayesian Modeling and Computation in Python (Chapman & Hall/CRC Texts in Statistical Science)<br>
 amazon.com</a></li>
<li style="font-weight:400;"><a href='https://bayesiancomputationbook.com/welcome.html'>Bayesian Modeling and Computation in Python</a></li>
<li style="font-weight:400;"><a href='https://twitter.com/canyon289'>https://twitter.com/canyon289</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/besvg7/bayesian-with-ravin-kumar.mp3" length="37656932" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This is one episode where passion for math, statistics and computers are merged. I have a very interesting conversation with Ravin,Â  data scientist at Google where he uses data to inform decisions.
He has previously worked at Sweetgreen, designing systems that would benefit team members and communities through sustainable and healthy food, and SpaceX, creating tools that would ultimately launch rocket ships. 
All opinions in this episode are his own and none of the companies he has worked for are represented.
Â 
This episode is brought to you by RailzAI
The Railz API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.
Â 
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Â 
References
Bayesian Modeling and Computation in Python (Chapman & Hall/CRC Texts in Statistical Science) amazon.com
Bayesian Modeling and Computation in Python
https://twitter.com/canyon289
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:12</itunes:duration>
                <itunes:episode>191</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What is spatial data science? With Matt Forest from Carto (Ep. 190)</title>
        <itunes:title>What is spatial data science? With Matt Forest from Carto (Ep. 190)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-is-spatial-data-science-with-matt-forest-from-carto-ep-190/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-is-spatial-data-science-with-matt-forest-from-carto-ep-190/#comments</comments>        <pubDate>Wed, 02 Mar 2022 12:10:28 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/e29d8c03-728d-3bc4-a372-d8b5d8becc5e</guid>
                                    <description><![CDATA[<p>In this episode I am with Matt Forrest, VP of Solutions Engineering at Carto. We speak about machine learning applied to spatial data, spatial SQL and GIS (Geographic Information System).
Enjoy the show!
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://go.railz.ai/Railz-DSH'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p>Carto <a href='https://carto.com'>https://carto.com</a></p>
<p>Spatial Feature Engineering: <a href='https://geographicdata.science/book/intro.html'>https://geographicdata.science/book/intro.html</a></p>
<p>CARTO Blog: <a href='https://carto.com/blog/'>https://carto.com/blog/</a></p>
<p>Spatial SQL Resources: <a href='https://forrest.nyc/learn-spatial-sql/'>https://forrest.nyc/learn-spatial-sql/</a></p>
<p>Spatial Data Science: <a href='https://forrest.nyc/geospatial-python'>https://forrest.nyc/geospatial-python</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I am with Matt Forrest, VP of Solutions Engineering at Carto. We speak about machine learning applied to spatial data, spatial SQL and GIS (Geographic Information System).<br>
Enjoy the show!<br>
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://go.railz.ai/Railz-DSH'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p>Carto <a href='https://carto.com'>https://carto.com</a></p>
<p>Spatial Feature Engineering: <a href='https://geographicdata.science/book/intro.html'>https://geographicdata.science/book/intro.html</a></p>
<p>CARTO Blog: <a href='https://carto.com/blog/'>https://carto.com/blog/</a></p>
<p>Spatial SQL Resources: <a href='https://forrest.nyc/learn-spatial-sql/'>https://forrest.nyc/learn-spatial-sql/</a></p>
<p>Spatial Data Science: <a href='https://forrest.nyc/geospatial-python'>https://forrest.nyc/geospatial-python</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/384zm6/carto.mp3" length="29395109" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am with Matt Forrest, VP of Solutions Engineering at Carto. We speak about machine learning applied to spatial data, spatial SQL and GIS (Geographic Information System).Enjoy the show!
Â 
This episode is brought to you by RailzAI
The Railz API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data. Get free access to their API and more. Just tell them you came through Data Science at Home podcast.
Â 
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

Carto https://carto.com
Spatial Feature Engineering: https://geographicdata.science/book/intro.html
CARTO Blog: https://carto.com/blog/
Spatial SQL Resources: https://forrest.nyc/learn-spatial-sql/
Spatial Data Science: https://forrest.nyc/geospatial-python
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:31</itunes:duration>
                <itunes:episode>190</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Connect. Collect. Normalize. Analyze. An interview with the people from Railz AI (Ep. 189)</title>
        <itunes:title>Connect. Collect. Normalize. Analyze. An interview with the people from Railz AI (Ep. 189)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/connect-collect-normalize-analyze-railz-ai-ep-189/</link>
                    <comments>https://datascienceathome.podbean.com/e/connect-collect-normalize-analyze-railz-ai-ep-189/#comments</comments>        <pubDate>Tue, 22 Feb 2022 13:35:34 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/092166f4-9ce0-35d0-9f30-9a9d77a4171b</guid>
                                    <description><![CDATA[<p>In this episode I am with Pasha Zavari - Director of Data Science and Derek Manuge - Co-founder and CTO at Railz. 
Railz is a very interesting company with an incredible mission: normalizing and extracting insights from the most tedious data out there, financial data.
Guess what technology stack are they on? 
Enjoy the show!
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://railz.ai'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by NordVPN</p>
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p>Railz Homepage: <a href='https://go.railz.ai/Railz-DSH'>https://go.railz.ai/Railz-DSH</a></p>
<p>Railz API Document: <a href='https://go.railz.ai/RailzAPI-DSH'>https://go.railz.ai/RailzAPI-DSH</a></p>
<p>Railz API Signup: <a href='https://go.railz.ai/RailzSignup-DSH'>https://go.railz.ai/RailzSignup-DSH</a></p>
<p>Railz Startup Pricing: <a href='https://go.railz.ai/RailzStartupPricing-DSH'>https://go.railz.ai/RailzStartupPricing-DSH</a></p>
<p>Railz Careers: <a href='https://secure.collage.co/jobs/railz'>https://secure.collage.co/jobs/railz</a>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I am with Pasha Zavari - Director of Data Science and Derek Manuge - Co-founder and CTO at Railz. <br>
Railz is a very interesting company with an incredible mission: normalizing and extracting insights from the most tedious data out there, financial data.<br>
Guess what technology stack are they on? <br>
Enjoy the show!<br>
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by RailzAI</p>
<p class="sc-1pihsbj-0 iZBGjJ">The <a href='https://railz.ai'>Railz</a> API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by NordVPN</p>
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p>Railz Homepage: <a href='https://go.railz.ai/Railz-DSH'>https://go.railz.ai/Railz-DSH</a></p>
<p>Railz API Document: <a href='https://go.railz.ai/RailzAPI-DSH'>https://go.railz.ai/RailzAPI-DSH</a></p>
<p>Railz API Signup: <a href='https://go.railz.ai/RailzSignup-DSH'>https://go.railz.ai/RailzSignup-DSH</a></p>
<p>Railz Startup Pricing: <a href='https://go.railz.ai/RailzStartupPricing-DSH'>https://go.railz.ai/RailzStartupPricing-DSH</a></p>
<p>Railz Careers: <a href='https://secure.collage.co/jobs/railz'>https://secure.collage.co/jobs/railz</a>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2zm9cv/railz-ai.mp3" length="58879465" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am with Pasha Zavari - Director of Data Science and Derek Manuge - Co-founder and CTO at Railz. Railz is a very interesting company with an incredible mission: normalizing and extracting insights from the most tedious data out there, financial data.Guess what technology stack are they on? Enjoy the show!
Â 
This episode is brought to you by RailzAI
The Railz API connects to major accounting platforms to provide you with quick access to normalized and analyzed financial data.
Â 
Sponsored by NordVPN
NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing nordvpn.com/DATASCIENCE or use coupon code DATASCIENCE and get a massive discount.
Â 
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

Railz Homepage: https://go.railz.ai/Railz-DSH
Railz API Document: https://go.railz.ai/RailzAPI-DSH
Railz API Signup: https://go.railz.ai/RailzSignup-DSH
Railz Startup Pricing: https://go.railz.ai/RailzStartupPricing-DSH
Railz Careers: https://secure.collage.co/jobs/railzÂ ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>46:44</itunes:duration>
        <itunes:season>5</itunes:season>
        <itunes:episode>189</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>History of data science [RB] (Ep. 188)</title>
        <itunes:title>History of data science [RB] (Ep. 188)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/history-of-data-science-rb-ep-188/</link>
                    <comments>https://datascienceathome.podbean.com/e/history-of-data-science-rb-ep-188/#comments</comments>        <pubDate>Wed, 16 Feb 2022 09:54:12 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5cad0b57-9db1-34a6-be91-4c42a9ed5099</guid>
                                    <description><![CDATA[<p style="text-align:left;">How did we get here? Who invented the methods data scientists use every day? 
</p>
<p style="text-align:left;">We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at <a href='https://www.dataiku.com'>Dataiku</a>. We cover topics about the history of data science, ethical AI and... </p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Dataiku</p>
<p class="top30">With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by NordVPN</p>
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p><a href='http://www.historyofdatascience.com'>www.historyofdatascience.com</a></p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">How did we get here? Who invented the methods data scientists use every day? <br>
</p>
<p style="text-align:left;">We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at <a href='https://www.dataiku.com'>Dataiku</a>. We cover topics about the history of data science, ethical AI and... </p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Dataiku</p>
<p class="top30">With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by NordVPN</p>
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p><a href='http://www.historyofdatascience.com'>www.historyofdatascience.com</a></p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/fkwub3/rb-history-datascience.mp3" length="50122842" type="audio/mpeg"/>
        <itunes:summary><![CDATA[How did we get here? Who invented the methods data scientists use every day? 
We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at Dataiku. We cover topics about the history of data science, ethical AI and... 
Â 
This episode is brought to you by Dataiku
With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.
Â 
Sponsored by NordVPN
NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing nordvpn.com/DATASCIENCE or use coupon code DATASCIENCE and get a massive discount.
Â 
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

www.historyofdatascience.com
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>39:54</itunes:duration>
                <itunes:episode>188</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Artificial Intelligence and Cloud Automation with Leon Kuperman from Cast.ai (Ep. 187)</title>
        <itunes:title>Artificial Intelligence and Cloud Automation with Leon Kuperman from Cast.ai (Ep. 187)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/artificial-intelligence-and-cloud-automation-with-leon-kuperman-from-castai-ep-187/</link>
                    <comments>https://datascienceathome.podbean.com/e/artificial-intelligence-and-cloud-automation-with-leon-kuperman-from-castai-ep-187/#comments</comments>        <pubDate>Tue, 08 Feb 2022 12:54:24 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3b40ad61-6670-3059-b28c-96cbf12d1909</guid>
                                    <description><![CDATA[<p>In this episode I speak about AI and cloud automation with Leon Kuperman, co-founder and CTO at CAST AI. Formerly Vice President of Security Products OCI at Oracle, Leonâ€™s professional experience spans across tech companies such as IBM, Truition, and HostedPCI.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Sponsored by NordVPN
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://cast.ai/'>https://cast.ai/</a></li>
<li style="font-weight:400;">Cloud automation 
<a href='https://cast.ai/blog/cloud-automation-in-2021-the-new-normal-in-the-tech-industry/'>https://cast.ai/blog/cloud-automation-in-2021-the-new-normal-in-the-tech-industry/</a> 
</li>
<li style="font-weight:400;">Cloud cost management 
<a href='https://cast.ai/blog/cloud-cost-management-alone-wont-fix-your-cloud-spend-problem/'>https://cast.ai/blog/cloud-cost-management-alone-wont-fix-your-cloud-spend-problem/</a>
</li>
<li style="font-weight:400;">Case study on how gross margin could be increased by cloud automation 
<a href='https://cast.ai/blog/the-hidden-shortcut-to-increasing-fintech-gross-margins-cloud-automation/'>https://cast.ai/blog/the-hidden-shortcut-to-increasing-fintech-gross-margins-cloud-automation/</a>
</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about AI and cloud automation with Leon Kuperman, co-founder and CTO at CAST AI. Formerly Vice President of Security Products OCI at Oracle, Leonâ€™s professional experience spans across tech companies such as IBM, Truition, and HostedPCI.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Sponsored by NordVPN
<p><a href='https://nordvpn.com/'>NordVPN</a> protects your privacy while you are online. Get secure and private access to the internet by surfing <a href='http://nordvpn.com/DATASCIENCE'>nordvpn.com/DATASCIENCE</a> or use coupon code DATASCIENCE and get a massive discount.</p>
<p>Â </p>
References
<ul><li style="font-weight:400;"><a href='https://cast.ai/'>https://cast.ai/</a></li>
<li style="font-weight:400;">Cloud automation <br>
<a href='https://cast.ai/blog/cloud-automation-in-2021-the-new-normal-in-the-tech-industry/'>https://cast.ai/blog/cloud-automation-in-2021-the-new-normal-in-the-tech-industry/</a> <br>
</li>
<li style="font-weight:400;">Cloud cost management <br>
<a href='https://cast.ai/blog/cloud-cost-management-alone-wont-fix-your-cloud-spend-problem/'>https://cast.ai/blog/cloud-cost-management-alone-wont-fix-your-cloud-spend-problem/</a><br>
</li>
<li style="font-weight:400;">Case study on how gross margin could be increased by cloud automation <br>
<a href='https://cast.ai/blog/the-hidden-shortcut-to-increasing-fintech-gross-margins-cloud-automation/'>https://cast.ai/blog/the-hidden-shortcut-to-increasing-fintech-gross-margins-cloud-automation/</a><br>
</li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/h9imnd/cast-ai-part-1.mp3" length="42932801" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about AI and cloud automation with Leon Kuperman, co-founder and CTO at CAST AI. Formerly Vice President of Security Products OCI at Oracle, Leonâ€™s professional experience spans across tech companies such as IBM, Truition, and HostedPCI.
Enjoy the episode!
Â 
Chat with me
Join us on Discord community chat to discuss the show, suggest new episodes and chat with other listeners!
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Sponsored by NordVPN
NordVPN protects your privacy while you are online. Get secure and private access to the internet by surfing nordvpn.com/DATASCIENCE or use coupon code DATASCIENCE and get a massive discount.
Â 
References
https://cast.ai/
Cloud automation https://cast.ai/blog/cloud-automation-in-2021-the-new-normal-in-the-tech-industry/ 
Cloud cost management https://cast.ai/blog/cloud-cost-management-alone-wont-fix-your-cloud-spend-problem/
Case study on how gross margin could be increased by cloud automation https://cast.ai/blog/the-hidden-shortcut-to-increasing-fintech-gross-margins-cloud-automation/
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>40:28</itunes:duration>
                <itunes:episode>187</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Embedded Machine Learning: Part 5 - Machine Learning Compiler Optimization (Ep. 186)</title>
        <itunes:title>Embedded Machine Learning: Part 5 - Machine Learning Compiler Optimization (Ep. 186)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-5-machine-learning-compiler-optimization-ep-186/</link>
                    <comments>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-5-machine-learning-compiler-optimization-ep-186/#comments</comments>        <pubDate>Thu, 03 Feb 2022 09:59:21 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/84624a23-d940-3ddf-8d8d-c3ef5adc9a3d</guid>
                                    <description><![CDATA[<p>This is the last episode of the series "Embedded ML" and I made it for the bravest :) 
I speak about machine learning compiler optimization to a much greater detail.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://tvm.apache.org/'>https://tvm.apache.org/</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>This is the last episode of the series "Embedded ML" and I made it for the bravest :) <br>
I speak about machine learning compiler optimization to a much greater detail.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://tvm.apache.org/'>https://tvm.apache.org/</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wu7qqh/embedded-ml-5.mp3" length="63459760" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This is the last episode of the series "Embedded ML" and I made it for the bravest :) I speak about machine learning compiler optimization to a much greater detail.
Enjoy the episode!
Â 
Chat with me
Join us on Discord community chat to discuss the show, suggest new episodes and chat with other listeners!
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Links
Amethix Embedded Machine Learning
https://tvm.apache.org/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>49:12</itunes:duration>
                <itunes:episode>186</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Embedded Machine Learning: Part 4 - Machine Learning Compilers (Ep. 185)</title>
        <itunes:title>Embedded Machine Learning: Part 4 - Machine Learning Compilers (Ep. 185)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-4-machine-learning-compilers-ep-185/</link>
                    <comments>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-4-machine-learning-compilers-ep-185/#comments</comments>        <pubDate>Tue, 25 Jan 2022 07:51:48 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d103e49c-c51a-32ce-9ceb-78d4f7535281</guid>
                                    <description><![CDATA[<p>In this episode I speak about machine learning compilers, the most important tools to bridge the gap between high level frontends, ML backends and hardware target architectures.</p>
<p>There are several compilers one can choose. Before that, let's get familiar with what a compiler is supposed to do.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://tvm.apache.org/'>https://tvm.apache.org/</a></li>
<li><a href='https://github.com/pytorch/glow'>https://github.com/pytorch/glow</a></li>
<li><a href='https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html'>https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html</a></li>
<li>Â </li>
</ul>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about machine learning compilers, the most important tools to bridge the gap between high level frontends, ML backends and hardware target architectures.</p>
<p>There are several compilers one can choose. Before that, let's get familiar with what a compiler is supposed to do.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://tvm.apache.org/'>https://tvm.apache.org/</a></li>
<li><a href='https://github.com/pytorch/glow'>https://github.com/pytorch/glow</a></li>
<li><a href='https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html'>https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html</a></li>
<li>Â </li>
</ul>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/v5qz9c/embedded-ml-4.mp3" length="43148679" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about machine learning compilers, the most important tools to bridge the gap between high level frontends, ML backends and hardware target architectures.
There are several compilers one can choose. Before that, let's get familiar with what a compiler is supposed to do.
Enjoy the episode!
Â 
Chat with me
Join us on Discord community chat to discuss the show, suggest new episodes and chat with other listeners!
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Links
Amethix Embedded Machine Learning
https://tvm.apache.org/
https://github.com/pytorch/glow
https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html
Â 
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>34:05</itunes:duration>
                <itunes:episode>185</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Embedded Machine Learning: Part 3 - Network Quantization (Ep. 184)</title>
        <itunes:title>Embedded Machine Learning: Part 3 - Network Quantization (Ep. 184)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-3-ep-184/</link>
                    <comments>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-3-ep-184/#comments</comments>        <pubDate>Thu, 20 Jan 2022 09:42:44 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1a669168-159d-340c-828b-1c1c651df7f5</guid>
                                    <description><![CDATA[<p>In this episode I speak about neural network quantization, a technique that makes networks feasible for embedded systems and small devices.</p>
<p>There are many quantization techniques depending on several factors that are all important to consider during design and implementation.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://pytorch.org/blog/introduction-to-quantization-on-pytorch/'>Introduction to quantization on Pytorch</a></li>
</ul>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about neural network quantization, a technique that makes networks feasible for embedded systems and small devices.</p>
<p>There are many quantization techniques depending on several factors that are all important to consider during design and implementation.</p>
<p>Enjoy the episode!</p>
<p>Â </p>
Chat with me
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
Sponsored by Amethix Technologies
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
Links
<ul><li><a href='https://amethix.com/portfolios/embedded-ml'>Amethix Embedded Machine Learning</a></li>
<li><a href='https://pytorch.org/blog/introduction-to-quantization-on-pytorch/'>Introduction to quantization on Pytorch</a></li>
</ul>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uvycue/embedded-ml-3.mp3" length="33659358" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about neural network quantization, a technique that makes networks feasible for embedded systems and small devices.
There are many quantization techniques depending on several factors that are all important to consider during design and implementation.
Enjoy the episode!
Â 
Chat with me
Join us on Discord community chat to discuss the show, suggest new episodes and chat with other listeners!
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Links
Amethix Embedded Machine Learning
Introduction to quantization on Pytorch
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:30</itunes:duration>
                <itunes:episode>184</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Embedded Machine Learning: Part 2 (Ep. 183)</title>
        <itunes:title>Embedded Machine Learning: Part 2 (Ep. 183)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-2-ep-183/</link>
                    <comments>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-2-ep-183/#comments</comments>        <pubDate>Sat, 15 Jan 2022 08:51:03 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/4534cefd-1524-3dcb-a341-e3b911d905e8</guid>
                                    <description><![CDATA[<p>In Part 2 of Embedded Machine Learning, I speak about one important technique to prune a neural network and perform inference on small devices. Such technique helps preserving most of the accuracy with a model orders of magnitude smaller.</p>
<p>Enjoy the show!</p>
<p>Â </p>
<p>Â </p>
References
<ol><li class="title mathjax"><a href='https://arxiv.org/abs/1803.03635'>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks </a></li>
</ol><p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In Part 2 of Embedded Machine Learning, I speak about one important technique to prune a neural network and perform inference on small devices. Such technique helps preserving most of the accuracy with a model orders of magnitude smaller.</p>
<p>Enjoy the show!</p>
<p>Â </p>
<p>Â </p>
References
<ol><li class="title mathjax"><a href='https://arxiv.org/abs/1803.03635'>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks </a></li>
</ol><p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tbwgdh/embedded-ml-2.mp3" length="20653044" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In Part 2 of Embedded Machine Learning, I speak about one important technique to prune a neural network and perform inference on small devices. Such technique helps preserving most of the accuracy with a model orders of magnitude smaller.
Enjoy the show!
Â 
Â 
References
The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:49</itunes:duration>
                <itunes:episode>183</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Embedded Machine Learning: Part 1 (Ep.182)</title>
        <itunes:title>Embedded Machine Learning: Part 1 (Ep.182)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-1-ep182/</link>
                    <comments>https://datascienceathome.podbean.com/e/embedded-machine-learning-part-1-ep182/#comments</comments>        <pubDate>Mon, 10 Jan 2022 06:15:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/858a6485-532a-31aa-a5a9-e91173d55764</guid>
                                    <description><![CDATA[<p style="text-align:left;">This episode is the first of a series about Embedded Machine Learning. I explain the requirements of tiny devices and how it is possible to run machine learning models.</p>
<p style="text-align:left;">Â </p>
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<p><a href='https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/'>https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">This episode is the first of a series about Embedded Machine Learning. I explain the requirements of tiny devices and how it is possible to run machine learning models.</p>
<p style="text-align:left;">Â </p>
<p>Join us on <a href='https://discord.com/invite/4UNKGf3'>Discord</a> community chat to discuss the show, suggest new episodes and chat with other listeners!</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">Sponsored by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<p><a href='https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/'>https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/udbvnk/embedded-ml-1.mp3" length="50230952" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This episode is the first of a series about Embedded Machine Learning. I explain the requirements of tiny devices and how it is possible to run machine learning models.
Â 
Join us on Discord community chat to discuss the show, suggest new episodes and chat with other listeners!
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Â 
References
https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:00</itunes:duration>
                <itunes:episode>182</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>History of Data Science (Ep. 181)</title>
        <itunes:title>History of Data Science (Ep. 181)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/history-of-data-science-ep-181/</link>
                    <comments>https://datascienceathome.podbean.com/e/history-of-data-science-ep-181/#comments</comments>        <pubDate>Sun, 19 Dec 2021 06:30:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/9c854220-46c5-3ca5-8fb0-aca792c89851</guid>
                                    <description><![CDATA[<p style="text-align:left;">How did we get here? Who invented the methods data scientists use every day? 
</p>
<p style="text-align:left;">We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at <a href='https://www.dataiku.com'>Dataiku</a>. We cover topics about the history of data science, ethical AI and... </p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Dataiku</p>
<p class="top30">With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p><a href='http://www.historyofdatascience.com'>www.historyofdatascience.com</a></p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">How did we get here? Who invented the methods data scientists use every day? <br>
</p>
<p style="text-align:left;">We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at <a href='https://www.dataiku.com'>Dataiku</a>. We cover topics about the history of data science, ethical AI and... </p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Dataiku</p>
<p class="top30">With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p><a href='http://www.historyofdatascience.com'>www.historyofdatascience.com</a></p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/kmfqpw/dataiku.mp3" length="76529082" type="audio/mpeg"/>
        <itunes:summary><![CDATA[How did we get here? Who invented the methods data scientists use every day? 
We answer such questions and much more in this wonderful episode with Triveni Gandhi, Senior Data Scientist and Shaun McGirr, AI Evangelist at Dataiku. We cover topics about the history of data science, ethical AI and... 
Â 
This episode is brought to you by Dataiku
With Dataiku, you have everything you need to build and deploy AI projects in one place, including easy-to-use data preparation and pipelines, AutoML, and advanced automation.
Â 
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

www.historyofdatascience.com
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>39:51</itunes:duration>
                <itunes:episode>181</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Capturing Data at the Edge (Ep. 180)</title>
        <itunes:title>Capturing Data at the Edge (Ep. 180)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/capturing-data-at-the-edge-ep-180/</link>
                    <comments>https://datascienceathome.podbean.com/e/capturing-data-at-the-edge-ep-180/#comments</comments>        <pubDate>Tue, 14 Dec 2021 08:20:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ecc714c4-fbe3-368a-87a3-1f18f6af41e3</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Tsecond</p>
<p style="text-align:left;">The growth of data being created at static and moving edges across industries such as air travel, ocean and space exploration, shipping and freight, oil and gas, media, and more proposes numerous challenges in capturing, processing, and analyzing large amounts of data.</p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p style="text-align:left;"><a href='https://tsecond.us/company/manavalan-krishnan/'>https://tsecond.us/company/manavalan-krishnan/</a></p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.<br>
</p>
<p style="text-align:left;">Â </p>
<p style="text-align:left;">This episode is brought to you by Tsecond</p>
<p style="text-align:left;">The growth of data being created at static and moving edges across industries such as air travel, ocean and space exploration, shipping and freight, oil and gas, media, and more proposes numerous challenges in capturing, processing, and analyzing large amounts of data.</p>
<p style="text-align:left;">and by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>

<p style="text-align:left;">Â </p>
References

<p style="text-align:left;"><a href='https://tsecond.us/company/manavalan-krishnan/'>https://tsecond.us/company/manavalan-krishnan/</a></p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/fjcd6v/bryck_boeingaikkh.mp3" length="68295286" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Manavalan Krishnan from Tsecond about capturing massive amounts of data at the edge with security and reliability in mind.
Â 
This episode is brought to you by Tsecond
The growth of data being created at static and moving edges across industries such as air travel, ocean and space exploration, shipping and freight, oil and gas, media, and more proposes numerous challenges in capturing, processing, and analyzing large amounts of data.
and by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

Â 
References

https://tsecond.us/company/manavalan-krishnan/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>35:34</itunes:duration>
                <itunes:episode>180</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>[RB] Composable Artificial Intelligence (Ep. 179)</title>
        <itunes:title>[RB] Composable Artificial Intelligence (Ep. 179)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-composable-artificial-intelligence-ep-179/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-composable-artificial-intelligence-ep-179/#comments</comments>        <pubDate>Tue, 07 Dec 2021 08:25:30 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/bf20ec86-d6d5-317c-8b96-91a783a0765e</guid>
                                    <description><![CDATA[<p>If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.</p>
<p>Come chat with us on <a href='https://discord.gg/4UNKGf3'>Discord</a></p>
Â 
Sponsors
<p>This episode is brought to you by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.</p>
<p>Come chat with us on <a href='https://discord.gg/4UNKGf3'>Discord</a></p>
Â 
Sponsors
<p>This episode is brought to you by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/88jmhr/composable_AI-rebroadcastbw1c0.mp3" length="33078880" type="audio/mpeg"/>
        <itunes:summary><![CDATA[If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.
Come chat with us on Discord
Â 
Sponsors
This episode is brought to you by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:13</itunes:duration>
                <itunes:episode>179</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What is a data mesh and why it is relevant (Ep. 178)</title>
        <itunes:title>What is a data mesh and why it is relevant (Ep. 178)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-is-a-data-mesh-and-why-it-is-relevant-ep-178/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-is-a-data-mesh-and-why-it-is-relevant-ep-178/#comments</comments>        <pubDate>Tue, 30 Nov 2021 07:40:08 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/685b3021-8a9c-35a7-b6b5-99e2424d678a</guid>
                                    <description><![CDATA[Sponsors
<p>This episode is brought to you by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Join us on Discord</p>
<p>Feel free to drop by and <a href='https://discord.gg/4UNKGf3'>have a chat</a> with the host and the followers of the show</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[Sponsors
<p>This episode is brought to you by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Join us on Discord</p>
<p>Feel free to drop by and <a href='https://discord.gg/4UNKGf3'>have a chat</a> with the host and the followers of the show</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/epi4wv/data_meshahzer.mp3" length="30914687" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Sponsors
This episode is brought to you by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Join us on Discord
Feel free to drop by and have a chat with the host and the followers of the show
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:05</itunes:duration>
                <itunes:episode>178</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Environmentally friendly AI (Ep. 177)</title>
        <itunes:title>Environmentally friendly AI (Ep. 177)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-must-get-green-ep-177/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-must-get-green-ep-177/#comments</comments>        <pubDate>Tue, 23 Nov 2021 10:15:36 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f0872793-46c2-30b3-b578-af3adf073012</guid>
                                    <description><![CDATA[Sponsors
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></description>
                                                            <content:encoded><![CDATA[Sponsors
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xe8hwt/green_AI_assua.mp3" length="37409773" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Sponsors
This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors https://www.arm.com/
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:28</itunes:duration>
                <itunes:episode>177</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Do you fear of AI? Why? (Ep. 176)</title>
        <itunes:title>Do you fear of AI? Why? (Ep. 176)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/fear-of-ai-do-not-worry/</link>
                    <comments>https://datascienceathome.podbean.com/e/fear-of-ai-do-not-worry/#comments</comments>        <pubDate>Tue, 16 Nov 2021 06:27:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5e9c1de6-9b59-366d-be57-3c86956330c5</guid>
                                    <description><![CDATA[<p>This episode summarizes a study about trends of AI in 2021, the way AI is perceived by people of different background and some other weird questions.</p>
<p>For instance, would you have sexual intercourse with a robot? Would you be in a relationship with an artificial intelligence?</p>
<p>The study has been conducted by Tidio.com and reported at <a href='https://www.tidio.com/blog/ai-trends/'>https://www.tidio.com/blog/ai-trends/</a></p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='http://amethix.com'>Amethix Technologies</a>.
Amethix uses machine learning and advanced analytics to empower people and organizations to ask and answer complex questions like never before.
Coming soon at <a href='https://amethix.com'>https://amethix.com</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>This episode summarizes a study about trends of AI in 2021, the way AI is perceived by people of different background and some other weird questions.</p>
<p>For instance, would you have sexual intercourse with a robot? Would you be in a relationship with an artificial intelligence?</p>
<p>The study has been conducted by Tidio.com and reported at <a href='https://www.tidio.com/blog/ai-trends/'>https://www.tidio.com/blog/ai-trends/</a></p>
<p>Â </p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='http://amethix.com'>Amethix Technologies</a>.<br>
Amethix uses machine learning and advanced analytics to empower people and organizations to ask and answer complex questions like never before.<br>
Coming soon at <a href='https://amethix.com'>https://amethix.com</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7uvyrt/fear_of_AI7md2z.mp3" length="38982135" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This episode summarizes a study about trends of AI in 2021, the way AI is perceived by people of different background and some other weird questions.
For instance, would you have sexual intercourse with a robot? Would you be in a relationship with an artificial intelligence?
The study has been conducted by Tidio.com and reported at https://www.tidio.com/blog/ai-trends/
Â 
Â 
Sponsors
This episode is supported by Amethix Technologies.Amethix uses machine learning and advanced analytics to empower people and organizations to ask and answer complex questions like never before.Coming soon at https://amethix.com]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:18</itunes:duration>
                <itunes:episode>176</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Composable models and artificial general intelligence (Ep. 175)</title>
        <itunes:title>Composable models and artificial general intelligence (Ep. 175)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/composable-models-and-artificial-general-intelligence/</link>
                    <comments>https://datascienceathome.podbean.com/e/composable-models-and-artificial-general-intelligence/#comments</comments>        <pubDate>Tue, 09 Nov 2021 13:55:35 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/758d2f3b-027c-3f4c-bd26-bb0ed7660bf0</guid>
                                    <description><![CDATA[<p>If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.</p>
<p>Â </p>
Sponsors
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.</p>
<p>Â </p>
Sponsors
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/yvm7nh/composable_AI6yxuq.mp3" length="31913609" type="audio/mpeg"/>
        <itunes:summary><![CDATA[If you think deep learning is a method to get to AGI, think again. Humans, as well as all mammals think in a... composable way.
Â 
Sponsors
This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors https://www.arm.com/
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:37</itunes:duration>
                <itunes:episode>175</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Ethics and explainability in AI with Erika Agostinelli from IBM (ep. 174)</title>
        <itunes:title>Ethics and explainability in AI with Erika Agostinelli from IBM (ep. 174)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ethics-and-explainability-in-ai-with-erika-agostinelli-from-ibm-ep-174/</link>
                    <comments>https://datascienceathome.podbean.com/e/ethics-and-explainability-in-ai-with-erika-agostinelli-from-ibm-ep-174/#comments</comments>        <pubDate>Tue, 02 Nov 2021 07:46:44 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f50c2a83-b0dc-38b4-ba86-bc68194cb002</guid>
                                    <description><![CDATA[<p>AI, ethics, and explainability. 
Are these topics that only large corporations can spend resources on? 
Can product-focused startups even think about them?</p>
<p>We answer such questions in this amazing episode with Erika Agostinelli from the AI Elite team at IBM.</p>
<p>Â </p>
<p>Sponsored by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>AIX360:</p>
<p><a href='https://aix360.mybluemix.net/'>https://aix360.mybluemix.net/</a></p>
<p>Â </p>
<p>Questioning the AI: Informing Design Practices for Explainable AI User Experiences</p>
<p><a href='https://arxiv.org/abs/2001.02478'>https://arxiv.org/abs/2001.02478</a></p>
<p>Â </p>
<p>Explainable AI - IBM</p>
<p><a href='https://www.ibm.com/uk-en/watson/explainable-ai'>https://www.ibm.com/uk-en/watson/explainable-ai</a></p>
<p>Â </p>
<p>AI Ethics - IBM</p>
<p><a href='https://www.ibm.com/artificial-intelligence/ethics'>https://www.ibm.com/artificial-intelligence/ethics</a></p>
<p>Â </p>
<p>Erika Agostinelliâ€™s personal webpage:Â </p>
<p><a href='https://www.erikaagostinelli.com/'>https://www.erikaagostinelli.com/</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>AI, ethics, and explainability. <br>
Are these topics that only large corporations can spend resources on? <br>
Can product-focused startups even think about them?</p>
<p>We answer such questions in this amazing episode with Erika Agostinelli from the <em>AI Elite team</em> at IBM.</p>
<p>Â </p>
<p>Sponsored by Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>AIX360:</p>
<p><a href='https://aix360.mybluemix.net/'>https://aix360.mybluemix.net/</a></p>
<p>Â </p>
<p>Questioning the AI: Informing Design Practices for Explainable AI User Experiences</p>
<p><a href='https://arxiv.org/abs/2001.02478'>https://arxiv.org/abs/2001.02478</a></p>
<p>Â </p>
<p>Explainable AI - IBM</p>
<p><a href='https://www.ibm.com/uk-en/watson/explainable-ai'>https://www.ibm.com/uk-en/watson/explainable-ai</a></p>
<p>Â </p>
<p>AI Ethics - IBM</p>
<p><a href='https://www.ibm.com/artificial-intelligence/ethics'>https://www.ibm.com/artificial-intelligence/ethics</a></p>
<p>Â </p>
<p>Erika Agostinelliâ€™s personal webpage:Â </p>
<p><a href='https://www.erikaagostinelli.com/'>https://www.erikaagostinelli.com/</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2mu2zu/ai_ethics_and_explainability_with_erika_agostinelliam2ai.mp3" length="59957836" type="audio/mpeg"/>
        <itunes:summary><![CDATA[AI, ethics, and explainability. Are these topics that only large corporations can spend resources on? Can product-focused startups even think about them?
We answer such questions in this amazing episode with Erika Agostinelli from the AI Elite team at IBM.
Â 
Sponsored by Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
AIX360:
https://aix360.mybluemix.net/
Â 
Questioning the AI: Informing Design Practices for Explainable AI User Experiences
https://arxiv.org/abs/2001.02478
Â 
Explainable AI - IBM
https://www.ibm.com/uk-en/watson/explainable-ai
Â 
AI Ethics - IBM
https://www.ibm.com/artificial-intelligence/ethics
Â 
Erika Agostinelliâ€™s personal webpage:Â 
https://www.erikaagostinelli.com/]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:13</itunes:duration>
                <itunes:episode>174</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Is neural hash by Apple violating our privacy? (Ep. 173)</title>
        <itunes:title>Is neural hash by Apple violating our privacy? (Ep. 173)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/is-neural-hash-by-apple-violating-our-privacy-ep-173/</link>
                    <comments>https://datascienceathome.podbean.com/e/is-neural-hash-by-apple-violating-our-privacy-ep-173/#comments</comments>        <pubDate>Tue, 26 Oct 2021 15:43:26 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/90b438b9-59d3-3c78-8772-10f3a230c3ea</guid>
                                    <description><![CDATA[Sponsor
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[Sponsor
<p>This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors <a href='https://www.arm.com/'>https://www.arm.com/</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/5mkm7n/what_is_neural_hash_and_why_it_mattersbpqhf.mp3" length="29491954" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Sponsor
This episode is brought to you by Advanced RISC Machines (ARM). ARM is a family of reduced instruction set computing architectures for computer processors https://www.arm.com/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:21</itunes:duration>
                <itunes:episode>173</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Fighting Climate Change as a Technologist (Ep. 172)</title>
        <itunes:title>Fighting Climate Change as a Technologist (Ep. 172)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/fighting-climate-change-as-a-technologist-ep-172/</link>
                    <comments>https://datascienceathome.podbean.com/e/fighting-climate-change-as-a-technologist-ep-172/#comments</comments>        <pubDate>Tue, 19 Oct 2021 08:42:22 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2bbea2b7-c204-37df-afac-370848763134</guid>
                                    <description><![CDATA[<p>The content of this episode has been created by <a href='https://kerkour.com'>Sylvain Kerkour</a>Â 
Feel free to subscribe to his newsletter at <a href='https://kerkour.com/'>https://kerkour.com</a></p>
<p>Â </p>
Projects worth considering
<ul><li><a href='https://www.opensourceecology.org/'>Open Source Ecology</a>: are building a set of Open Source and reusable blueprints for a civilization that you can build yourself. From powercube to an entire tractor.</li>
<li><a href='https://frame.work'>The Framework laptop</a>: while you can live without a phone, itâ€™s close to impossible to live without a computer nowadays. So better buy one that you will be able to use for a decade by being easily repairable and upgradable.</li>
<li><a href='https://gouach.com/'>Gouach repairable batteries</a>: Batteries are the challenge of the decade. So better start making repairable batteries today.</li>
<li><a href='https://postmarketos.org/'>postmarketOS</a>: An <a href='https://ollieparanoid.github.io/post/postmarketOS/'>Operating System that aims for at least a 10 years life-cycle for devices</a>.</li>
<li><a href='https://www.drawdown.org/solutions/table-of-solutions'>Project Drawdown</a>: propose a lot of applicable solutions with their potential savings.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>The content of this episode has been created by <a href='https://kerkour.com'>Sylvain Kerkour</a>Â <br>
Feel free to subscribe to his newsletter at <a href='https://kerkour.com/'>https://kerkour.com</a></p>
<p>Â </p>
Projects worth considering
<ul><li><a href='https://www.opensourceecology.org/'>Open Source Ecology</a>: are building a set of Open Source and reusable blueprints for a civilization that you can build yourself. From powercube to an entire tractor.</li>
<li><a href='https://frame.work'>The Framework laptop</a>: while you can live without a phone, itâ€™s close to impossible to live without a computer nowadays. So better buy one that you will be able to use for a decade by being easily repairable and upgradable.</li>
<li><a href='https://gouach.com/'>Gouach repairable batteries</a>: Batteries are the challenge of the decade. So better start making repairable batteries today.</li>
<li><a href='https://postmarketos.org/'>postmarketOS</a>: An <a href='https://ollieparanoid.github.io/post/postmarketOS/'>Operating System that aims for at least a 10 years life-cycle for devices</a>.</li>
<li><a href='https://www.drawdown.org/solutions/table-of-solutions'>Project Drawdown</a>: propose a lot of applicable solutions with their potential savings.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ktqqtn/fighting_climate_change_as_a_technologist8gt89.mp3" length="37885410" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The content of this episode has been created by Sylvain KerkourÂ Feel free to subscribe to his newsletter at https://kerkour.com
Â 
Projects worth considering
Open Source Ecology: are building a set of Open Source and reusable blueprints for a civilization that you can build yourself. From powercube to an entire tractor.
The Framework laptop: while you can live without a phone, itâ€™s close to impossible to live without a computer nowadays. So better buy one that you will be able to use for a decade by being easily repairable and upgradable.
Gouach repairable batteries: Batteries are the challenge of the decade. So better start making repairable batteries today.
postmarketOS: An Operating System that aims for at least a 10 years life-cycle for devices.
Project Drawdown: propose a lot of applicable solutions with their potential savings.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:43</itunes:duration>
                <itunes:episode>172</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>AI in the Enterprise with IBM Global AI Strategist Mara Pometti (Ep. 171)</title>
        <itunes:title>AI in the Enterprise with IBM Global AI Strategist Mara Pometti (Ep. 171)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/ai-in-the-enterprise-with-ibm-global-ai-strategist-mara-pometti-ep-171/</link>
                    <comments>https://datascienceathome.podbean.com/e/ai-in-the-enterprise-with-ibm-global-ai-strategist-mara-pometti-ep-171/#comments</comments>        <pubDate>Mon, 11 Oct 2021 07:20:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/025a02e4-dc1f-302b-b663-b88df71b90e2</guid>
                                    <description><![CDATA[<p>IBM Global AI Strategist Mara Pometti is IBMâ€™s first AI Strategist. She defines and designs the strategy for AI solutions by revealing overlooked insights hidden in enterprisesâ€™ data. 
In this episode we speak about strategy, explainable AI and data storytelling.</p>
<p>Â </p>
References
<p>IBM Trustworthy AI: <a href='https://www.ibm.com/watson/trustworthy-ai'>https://www.ibm.com/watson/trustworthy-ai</a></p>
<p>IBM AIX360: <a href='https://aix360.mybluemix.net/'>https://aix360.mybluemix.net/</a></p>
<p>Explainable AI and Data Storytelling: <a href='https://medium.com/aixdesign/the-next-generation-of-storytelling-1d5fecc8f999'>https://medium.com/aixdesign/the-next-generation-of-storytelling-1d5fecc8f999</a></p>
<p>Mara Pomettiâ€™s website: <a href='http://www.marapometti.com'>www.marapometti.com</a></p>
<p>Mara Pometti LinkedIn: <a href='https://www.linkedin.com/in/mara-pometti-99962594'>https://www.linkedin.com/in/mara-pometti-99962594</a></p>
<p>Mara Pometti Twitter: <a href='https://twitter.com/91_pometti'>https://twitter.com/91_pometti</a>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>IBM Global AI Strategist Mara Pometti is IBMâ€™s first AI Strategist. She defines and designs the strategy for AI solutions by revealing overlooked insights hidden in enterprisesâ€™ data. <br>
In this episode we speak about strategy, explainable AI and data storytelling.</p>
<p>Â </p>
References
<p>IBM Trustworthy AI: <a href='https://www.ibm.com/watson/trustworthy-ai'>https://www.ibm.com/watson/trustworthy-ai</a></p>
<p>IBM AIX360: <a href='https://aix360.mybluemix.net/'>https://aix360.mybluemix.net/</a></p>
<p>Explainable AI and Data Storytelling: <a href='https://medium.com/aixdesign/the-next-generation-of-storytelling-1d5fecc8f999'>https://medium.com/aixdesign/the-next-generation-of-storytelling-1d5fecc8f999</a></p>
<p>Mara Pomettiâ€™s website: <a href='http://www.marapometti.com'>www.marapometti.com</a></p>
<p>Mara Pometti LinkedIn: <a href='https://www.linkedin.com/in/mara-pometti-99962594'>https://www.linkedin.com/in/mara-pometti-99962594</a></p>
<p>Mara Pometti Twitter: <a href='https://twitter.com/91_pometti'>https://twitter.com/91_pometti</a>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8fps69/mara_pometti_IBM7r836.mp3" length="67273793" type="audio/mpeg"/>
        <itunes:summary><![CDATA[IBM Global AI Strategist Mara Pometti is IBMâ€™s first AI Strategist. She defines and designs the strategy for AI solutions by revealing overlooked insights hidden in enterprisesâ€™ data. In this episode we speak about strategy, explainable AI and data storytelling.
Â 
References
IBM Trustworthy AI: https://www.ibm.com/watson/trustworthy-ai
IBM AIX360: https://aix360.mybluemix.net/
Explainable AI and Data Storytelling: https://medium.com/aixdesign/the-next-generation-of-storytelling-1d5fecc8f999
Mara Pomettiâ€™s website: www.marapometti.com
Mara Pometti LinkedIn: https://www.linkedin.com/in/mara-pometti-99962594
Mara Pometti Twitter: https://twitter.com/91_pomettiÂ 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>35:02</itunes:duration>
                <itunes:episode>171</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Speaking about data with Mikkel Settnes from Dreamdata.io (Ep. 170)</title>
        <itunes:title>Speaking about data with Mikkel Settnes from Dreamdata.io (Ep. 170)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/speaking-about-data-with-mikkel-settnes-from-dreamdataio/</link>
                    <comments>https://datascienceathome.podbean.com/e/speaking-about-data-with-mikkel-settnes-from-dreamdataio/#comments</comments>        <pubDate>Fri, 24 Sep 2021 15:05:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b620a5fd-01e8-33b7-b4cb-628d333e812c</guid>
                                    <description><![CDATA[<p>In this episode Mikkel and Francesco have a really interesting conversation about some key differences between large and small organization in approaching machine learning. 
Listen to the episode to know more.</p>
<p>Â </p>
References
<ul><li><a href='https://dreamdata.io/b2b-attribution'>https://dreamdata.io/b2b-attribution</a></li>
<li><a href='https://dreamdata.io/services'>https://dreamdata.io/services</a></li>
<li><a href='https://dreamdata.io/blog/10-use-cases-for-data-platform'>Â </a></li>
<li><a href='https://www.nature.com/articles/s43586-020-00001-2'>https://www.nature.com/articles/s43586-020-00001-2</a> </li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode Mikkel and Francesco have a really interesting conversation about some key differences between large and small organization in approaching machine learning. <br>
Listen to the episode to know more.</p>
<p>Â </p>
References
<ul><li><a href='https://dreamdata.io/b2b-attribution'>https://dreamdata.io/b2b-attribution</a></li>
<li><a href='https://dreamdata.io/services'>https://dreamdata.io/services</a></li>
<li><a href='https://dreamdata.io/blog/10-use-cases-for-data-platform'>Â </a></li>
<li><a href='https://www.nature.com/articles/s43586-020-00001-2'>https://www.nature.com/articles/s43586-020-00001-2</a> </li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/88vcp5/dreamdata.mp3" length="66187935" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode Mikkel and Francesco have a really interesting conversation about some key differences between large and small organization in approaching machine learning. Listen to the episode to know more.
Â 
References
https://dreamdata.io/b2b-attribution
https://dreamdata.io/services
Â 
https://www.nature.com/articles/s43586-020-00001-2 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>34:28</itunes:duration>
                <itunes:episode>170</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Send compute to data with POSH data-aware shell (Ep. 169)</title>
        <itunes:title>Send compute to data with POSH data-aware shell (Ep. 169)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/send-compute-to-data-with-posh-data-aware-shell-ep-169/</link>
                    <comments>https://datascienceathome.podbean.com/e/send-compute-to-data-with-posh-data-aware-shell-ep-169/#comments</comments>        <pubDate>Tue, 14 Sep 2021 12:55:37 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/56aee858-ad54-37e0-9410-b4adb2a961b0</guid>
                                    <description><![CDATA[Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>Paper <a href='https://deeptir.me/papers/posh-atc20.pdf'>https://deeptir.me/papers/posh-atc20.pdf</a></p>
<p>Code <a href='https://github.com/deeptir18/posh'>https://github.com/deeptir18/posh</a></p>
]]></description>
                                                            <content:encoded><![CDATA[Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>Paper <a href='https://deeptir.me/papers/posh-atc20.pdf'>https://deeptir.me/papers/posh-atc20.pdf</a></p>
<p>Code <a href='https://github.com/deeptir18/posh'>https://github.com/deeptir18/posh</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/rr2p4g/posh_data_aware_shellaku9q.mp3" length="42508875" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsors
Quantum Metric
Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at quantummetric.com/podoffer and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.
Â 
Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
Paper https://deeptir.me/papers/posh-atc20.pdf
Code https://github.com/deeptir18/posh]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:08</itunes:duration>
                <itunes:episode>169</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>How are organisations doing with data and AI? (Ep. 168)</title>
        <itunes:title>How are organisations doing with data and AI? (Ep. 168)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-are-organisations-doing-with-data-and-ai-ep-168/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-are-organisations-doing-with-data-and-ai-ep-168/#comments</comments>        <pubDate>Tue, 07 Sep 2021 15:15:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0778500d-a8df-34dc-b562-56970beae417</guid>
                                    <description><![CDATA[<p>A few weeks ago I was the guest of a very interesting show called "AI Today". 
In that episode I talked about some of the biggest trends emerging in AI and machine learning today as well as how organizations are dealing with and managing their data.</p>
<p>Â </p>
<p>The original show has been published at <a href='https://www.cognilytica.com/2021/08/11/ai-today-podcast-interview-with-francesco-gadaleta-host-of-data-science-at-home-podcast/'>https://www.cognilytica.com/2021/08/11/ai-today-podcast-interview-with-francesco-gadaleta-host-of-data-science-at-home-podcast/</a></p>
<p>Â </p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>A few weeks ago I was the guest of a very interesting show called "AI Today". <br>
In that episode I talked about some of the biggest trends emerging in AI and machine learning today as well as how organizations are dealing with and managing their data.</p>
<p>Â </p>
<p>The original show has been published at <a href='https://www.cognilytica.com/2021/08/11/ai-today-podcast-interview-with-francesco-gadaleta-host-of-data-science-at-home-podcast/'>https://www.cognilytica.com/2021/08/11/ai-today-podcast-interview-with-francesco-gadaleta-host-of-data-science-at-home-podcast/</a></p>
<p>Â </p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uc847d/AI_today_guestblhuw.mp3" length="68310332" type="audio/mpeg"/>
        <itunes:summary><![CDATA[A few weeks ago I was the guest of a very interesting show called "AI Today". In that episode I talked about some of the biggest trends emerging in AI and machine learning today as well as how organizations are dealing with and managing their data.
Â 
The original show has been published at https://www.cognilytica.com/2021/08/11/ai-today-podcast-interview-with-francesco-gadaleta-host-of-data-science-at-home-podcast/
Â 
Our Sponsors
Quantum Metric
Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at quantummetric.com/podoffer and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.
Â 
Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>35:34</itunes:duration>
                <itunes:episode>168</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Don't fight! Cooperate. Generative Teaching Networks (Ep. 167)</title>
        <itunes:title>Don't fight! Cooperate. Generative Teaching Networks (Ep. 167)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/dont-fight-cooperate-generative-teaching-networks-ep-167/</link>
                    <comments>https://datascienceathome.podbean.com/e/dont-fight-cooperate-generative-teaching-networks-ep-167/#comments</comments>        <pubDate>Tue, 31 Aug 2021 15:03:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/29ddb97c-d74f-3f69-bc11-e819569c3ee9</guid>
                                    <description><![CDATA[<p>Remember GANs? Generative Adversarial Networks for synthetic data generation?Â 
There is a new method called Generative Teaching Networks, that uses similar concepts - just quite the opposite :P - to train models faster, better and with less data.</p>
<p>Enjoy the show!</p>
Â 
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<ol><li class="title mathjax">Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data <a href='https://arxiv.org/abs/1912.07768'>https://arxiv.org/abs/1912.07768</a></li>
</ol><p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Remember GANs? Generative Adversarial Networks for synthetic data generation?Â <br>
There is a new method called Generative Teaching Networks, that uses similar concepts - just quite the opposite :P - to train models faster, better and with less data.</p>
<p>Enjoy the show!</p>
Â 
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<ol><li class="title mathjax">Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data <a href='https://arxiv.org/abs/1912.07768'>https://arxiv.org/abs/1912.07768</a></li>
</ol><p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/253jzu/generative_teaching_networksam9u2.mp3" length="30851993" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Remember GANs? Generative Adversarial Networks for synthetic data generation?Â There is a new method called Generative Teaching Networks, that uses similar concepts - just quite the opposite :P - to train models faster, better and with less data.
Enjoy the show!
Â 
Our Sponsors
Quantum Metric
Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at quantummetric.com/podoffer and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.
Â 
Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data https://arxiv.org/abs/1912.07768
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:03</itunes:duration>
                <itunes:episode>167</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>CSV sucks. Here is why. (Ep. 166)</title>
        <itunes:title>CSV sucks. Here is why. (Ep. 166)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/csv-sucks-here-is-why/</link>
                    <comments>https://datascienceathome.podbean.com/e/csv-sucks-here-is-why/#comments</comments>        <pubDate>Tue, 24 Aug 2021 15:05:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a61ff2ef-b23d-35b7-a030-fca279ea7b35</guid>
                                    <description><![CDATA[<p>It's time we get serious about replacing the CSV format with something that, guess what? it has been around for so long.</p>
<p>In this episode I explain the good parts of CSV files and the not so good ones. It's time we evolve to something better.</p>
<p>Â </p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>It's time we get serious about replacing the CSV format with something that, guess what? it has been around for so long.</p>
<p>In this episode I explain the good parts of CSV files and the not so good ones. It's time we evolve to something better.</p>
<p>Â </p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/yjsv3a/csv_sucksbqorm.mp3" length="38605972" type="audio/mpeg"/>
        <itunes:summary><![CDATA[It's time we get serious about replacing the CSV format with something that, guess what? it has been around for so long.
In this episode I explain the good parts of CSV files and the not so good ones. It's time we evolve to something better.
Â 
Our Sponsors
Quantum Metric
Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at quantummetric.com/podoffer and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.
Â 
Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:06</itunes:duration>
                <itunes:episode>166</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Reinforcement Learning is all you need. Or is it? (Ep. 165)</title>
        <itunes:title>Reinforcement Learning is all you need. Or is it? (Ep. 165)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/reinforcement-learning-is-all-you-need-or-is-it/</link>
                    <comments>https://datascienceathome.podbean.com/e/reinforcement-learning-is-all-you-need-or-is-it/#comments</comments>        <pubDate>Tue, 17 Aug 2021 14:57:35 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/6b26d329-5861-3a0b-8af4-735ea367a19c</guid>
                                    <description><![CDATA[<p>Is reinforcement learning sufficient to build truly intelligent machines? Listen to this episode to find out.</p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<ul><li><a href='https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/'>https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/</a></li>
<li><a href='https://pub.towardsai.net/building-reinforcement-learning-agents-that-learn-to-collaborate-and-compete-at-the-same-time-d081fea942d2'>https://pub.towardsai.net/building-reinforcement-learning-agents-that-learn-to-collaborate-and-compete-at-the-same-time-d081fea942d2</a></li>
<li><a href='https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978'>https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Is reinforcement learning sufficient to build truly intelligent machines? Listen to this episode to find out.</p>
Our Sponsors
<p>Quantum Metric</p>
<p>Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.</p>
<p>Â </p>
<p>Amethix Technologies</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
References
<ul><li><a href='https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/'>https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/</a></li>
<li><a href='https://pub.towardsai.net/building-reinforcement-learning-agents-that-learn-to-collaborate-and-compete-at-the-same-time-d081fea942d2'>https://pub.towardsai.net/building-reinforcement-learning-agents-that-learn-to-collaborate-and-compete-at-the-same-time-d081fea942d2</a></li>
<li><a href='https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978'>https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/dty28r/reinforcement_learning_is_all_you_need7l7da.mp3" length="58526743" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Is reinforcement learning sufficient to build truly intelligent machines? Listen to this episode to find out.
Our Sponsors
Quantum Metric
Stay off the naughty list this holiday season by reducing customer friction, increasing conversions, and personalizing the shopping experience. Want a sneak peak? Visit us at quantummetric.com/podoffer and see if you qualify to receive our â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to our platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.
Â 
Amethix Technologies
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Â 
References
https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/
https://pub.towardsai.net/building-reinforcement-learning-agents-that-learn-to-collaborate-and-compete-at-the-same-time-d081fea942d2
https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:28</itunes:duration>
                <itunes:episode>165</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What's happening with AI today? (Ep. 164)</title>
        <itunes:title>What's happening with AI today? (Ep. 164)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/whats-happening-with-ai-today-ep-164/</link>
                    <comments>https://datascienceathome.podbean.com/e/whats-happening-with-ai-today-ep-164/#comments</comments>        <pubDate>Wed, 11 Aug 2021 13:20:45 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/cdd15e2f-4706-3846-9fc9-c8d77420867c</guid>
                                    <description><![CDATA[
In this episode I have a wonderful chat with Ronald Schmelzer and Kathleen Walch, authors of "AI Today" the top podcast for those wanting a no-hype, practical, real-world insight into what enterprises, public sector agencies, thought leaders, leading technology companies, pundits, and experts are doing with AI today.
Â 
Â 
Sponsored by Quantum Metric
Did you know that 2021 holiday ecommerce sales are expected to exceed 2020 benchmarks?â€¨Are you prepared to capture every customer revenue opportunity? â€¨With Quantum Metric, you can be.
Visit their website at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive their â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to the platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.Â 
Â 
Â 
Sponsored by Amethix Technologies

<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>

Â 
Links
Â 
<ul><li>AI Today podcast: <a href='http://aitoday.live/'>http://aitoday.live/</a></li>
<li>CPMAI Methodology:Â <a href='https://www.cognilytica.com/cpmai-methodology/'>https://www.cognilytica.com/cpmai-methodology/</a></li>
</ul>
Â 
Â 
]]></description>
                                                            <content:encoded><![CDATA[
In this episode I have a wonderful chat with Ronald Schmelzer and Kathleen Walch, authors of <em>"AI Today" </em>the top podcast for those wanting a no-hype, practical, real-world insight into what enterprises, public sector agencies, thought leaders, leading technology companies, pundits, and experts are doing with AI today.
Â 
Â 
Sponsored by Quantum Metric
Did you know that 2021 holiday ecommerce sales are expected to exceed 2020 benchmarks?â€¨Are you prepared to capture every customer revenue opportunity? â€¨With Quantum Metric, you can be.
Visit their website at <a href='https://quantummetric.com/podoffer'>quantummetric.com/podoffer</a> and see if you qualify to receive their â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to the platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.Â 
Â 
Â 
Sponsored by Amethix Technologies

<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>

Â 
Links
Â 
<ul><li>AI Today podcast: <a href='http://aitoday.live/'>http://aitoday.live/</a></li>
<li>CPMAI Methodology:Â <a href='https://www.cognilytica.com/cpmai-methodology/'>https://www.cognilytica.com/cpmai-methodology/</a></li>
</ul>
Â 
Â 
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/fqypfm/AI_today_podcast_with_sponsor7ej60.mp3" length="48214018" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
In this episode I have a wonderful chat with Ronald Schmelzer and Kathleen Walch, authors of "AI Today" the top podcast for those wanting a no-hype, practical, real-world insight into what enterprises, public sector agencies, thought leaders, leading technology companies, pundits, and experts are doing with AI today.
Â 
Â 
Sponsored by Quantum Metric
Did you know that 2021 holiday ecommerce sales are expected to exceed 2020 benchmarks?â€¨Are you prepared to capture every customer revenue opportunity? â€¨With Quantum Metric, you can be.
Visit their website at quantummetric.com/podoffer and see if you qualify to receive their â€œ12 Days of Insightsâ€ offer with code DATASCIENCE. This offer gives you 12-day access to the platform coupled with a bespoke insight report that will help you identify where customers are struggling or engaging in your digital product.Â 
Â 
Â 
Sponsored by Amethix Technologies

Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 

Â 
Links
Â 
AI Today podcast: http://aitoday.live/
CPMAI Methodology:Â https://www.cognilytica.com/cpmai-methodology/
Â 
Â 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:06</itunes:duration>
                <itunes:episode>165</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>2 effective ways to explain your predictions (Ep. 163)</title>
        <itunes:title>2 effective ways to explain your predictions (Ep. 163)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/2-effective-ways-to-explain-your-predictions/</link>
                    <comments>https://datascienceathome.podbean.com/e/2-effective-ways-to-explain-your-predictions/#comments</comments>        <pubDate>Tue, 03 Aug 2021 09:52:11 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ba12ae3c-c08b-3212-868c-576a3549024b</guid>
                                    <description><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<ul><li>
<p>Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. â€œModel Class Reliance: Variable importance measures for any machine learning model class, from the â€˜Rashomonâ€™ perspective.â€ <a href='http://arxiv.org/abs/1801.01489'>http://arxiv.org/abs/1801.01489</a> (2018).</p>
</li>
<li>Python SHAP 
<a href='https://github.com/slundberg/shap'>https://github.com/slundberg/shap</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
<p>References</p>
<ul><li>
<p>Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. â€œModel Class Reliance: Variable importance measures for any machine learning model class, from the â€˜Rashomonâ€™ perspective.â€ <a href='http://arxiv.org/abs/1801.01489'>http://arxiv.org/abs/1801.01489</a> (2018).</p>
</li>
<li>Python SHAP <br>
<a href='https://github.com/slundberg/shap'>https://github.com/slundberg/shap</a></li>
</ul>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/s6923y/explainable_machine_learning8cw04.mp3" length="46705185" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsor
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Â 
References

Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. â€œModel Class Reliance: Variable importance measures for any machine learning model class, from the â€˜Rashomonâ€™ perspective.â€ http://arxiv.org/abs/1801.01489 (2018).

Python SHAP https://github.com/slundberg/shap
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:19</itunes:duration>
                <itunes:episode>158</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>The Netflix challenge. Fair or what? (Ep. 162)</title>
        <itunes:title>The Netflix challenge. Fair or what? (Ep. 162)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-netflix-challenge-fair-or-what/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-netflix-challenge-fair-or-what/#comments</comments>        <pubDate>Thu, 22 Jul 2021 10:04:38 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f8593243-d89c-3f73-8dd7-368bfbba4f50</guid>
                                    <description><![CDATA[<p>Remember the Netflix challenge?</p>
<p>It was a ton of money for the one who would have cracked the problem of recommending the best possible movie.</p>
<p>Was it a fair challenge? Did it work?
Let me tell you what happened...</p>
<p>Â </p>
Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Remember the Netflix challenge?</p>
<p>It was a ton of money for the one who would have cracked the problem of recommending the best possible movie.</p>
<p>Was it a fair challenge? Did it work?<br>
Let me tell you what happened...</p>
<p>Â </p>
Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vgcerh/the-netflix-prize.mp3" length="42115993" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Remember the Netflix challenge?
It was a ton of money for the one who would have cracked the problem of recommending the best possible movie.
Was it a fair challenge? Did it work?Let me tell you what happened...
Â 
Sponsors
Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link https://surfshark.deals/DATASCIENCE]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:56</itunes:duration>
                <itunes:episode>161</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Artificial Intelligence for Blockchains with Jonathan Ward CTO of Fetch AI (Ep. 161)</title>
        <itunes:title>Artificial Intelligence for Blockchains with Jonathan Ward CTO of Fetch AI (Ep. 161)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/with-jonathan-ward-cto-of-fetch-ai/</link>
                    <comments>https://datascienceathome.podbean.com/e/with-jonathan-ward-cto-of-fetch-ai/#comments</comments>        <pubDate>Thu, 15 Jul 2021 15:30:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0388849b-1b9a-3e4b-8a76-1ba1bacdc3ca</guid>
                                    <description><![CDATA[<p>In this episode Fetch AI CTO Jonathan Ward speaks about decentralization, AI, blockchain for smart cities and the enterprise.
Below some great links about collective learning, smart contracts in Rust and the Fetch AI ecosystem.</p>
<ul><li class="qt-">Decentralised collective learning: <a href='https://github.com/fetchai/colearn'>https://github.com/fetchai/colearn</a></li>
<li class="qt-">Smart contracting platform written in Rust <a href='https://docs.cosmwasm.com/docs/0.14/'>https://docs.cosmwasm.com/docs/0.14/</a></li>
<li class="qt-">Fetch.ai cosmwasm contracts for collective learning: <a href='https://github.com/fetchai/contract-learn'>https://github.com/fetchai/contract-learn</a></li>
<li class="qt-">How the Colearn system works: <a href='https://vimeo.com/440365943'>https://vimeo.com/440365943</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode Fetch AI CTO Jonathan Ward speaks about decentralization, AI, blockchain for smart cities and the enterprise.<br>
Below some great links about collective learning, smart contracts in Rust and the Fetch AI ecosystem.</p>
<ul><li class="qt-">Decentralised collective learning: <a href='https://github.com/fetchai/colearn'>https://github.com/fetchai/colearn</a></li>
<li class="qt-">Smart contracting platform written in Rust <a href='https://docs.cosmwasm.com/docs/0.14/'>https://docs.cosmwasm.com/docs/0.14/</a></li>
<li class="qt-">Fetch.ai cosmwasm contracts for collective learning: <a href='https://github.com/fetchai/contract-learn'>https://github.com/fetchai/contract-learn</a></li>
<li class="qt-">How the Colearn system works: <a href='https://vimeo.com/440365943'>https://vimeo.com/440365943</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/eds8uz/fetch_ai.mp3" length="62669555" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode Fetch AI CTO Jonathan Ward speaks about decentralization, AI, blockchain for smart cities and the enterprise.Below some great links about collective learning, smart contracts in Rust and the Fetch AI ecosystem.
Decentralised collective learning: https://github.com/fetchai/colearn
Smart contracting platform written in Rust https://docs.cosmwasm.com/docs/0.14/
Fetch.ai cosmwasm contracts for collective learning: https://github.com/fetchai/contract-learn
How the Colearn system works: https://vimeo.com/440365943
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:38</itunes:duration>
                <itunes:episode>164</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Apache Arrow, Ballista and Big Data in Rust with Andy Grove RB (Ep. 160)</title>
        <itunes:title>Apache Arrow, Ballista and Big Data in Rust with Andy Grove RB (Ep. 160)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/apache-arrow-ballista-and-big-data-in-rust-with-andy-grove-rb-ep-160/</link>
                    <comments>https://datascienceathome.podbean.com/e/apache-arrow-ballista-and-big-data-in-rust-with-andy-grove-rb-ep-160/#comments</comments>        <pubDate>Thu, 08 Jul 2021 15:04:30 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1375d166-6e23-3697-b956-8b969971d0e7</guid>
                                    <description><![CDATA[<p>Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? <a href='https://www.rust-lang.org/'>Rust</a>? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.
Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.</p>
Â 
Our Sponsors
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://arrow.apache.org/</a></p>
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://ballistacompute.org/</a></p>
<p>Â </p>
<p><a href='https://github.com/ballista-compute/ballista'>https://github.com/ballista-compute/ballista</a></p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? <a href='https://www.rust-lang.org/'>Rust</a>? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.<br>
Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.</p>
Â 
Our Sponsors
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
References
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://arrow.apache.org/</a></p>
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://ballistacompute.org/</a></p>
<p>Â </p>
<p><a href='https://github.com/ballista-compute/ballista'>https://github.com/ballista-compute/ballista</a></p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/3v4zpb/RB-ballista-with-andy-grove.mp3" length="55709698" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? Rust? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.
Â 
Our Sponsors
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
Â 
https://arrow.apache.org/
Â 
https://ballistacompute.org/
Â 
https://github.com/ballista-compute/ballista
Â 
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:01</itunes:duration>
                <itunes:episode>163</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>GitHub Copilot: yay or nay? (Ep. 159)</title>
        <itunes:title>GitHub Copilot: yay or nay? (Ep. 159)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/github-copilot-yay-or-nay/</link>
                    <comments>https://datascienceathome.podbean.com/e/github-copilot-yay-or-nay/#comments</comments>        <pubDate>Tue, 06 Jul 2021 09:27:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c203abef-bf65-33da-872c-d6f7c973de57</guid>
                                    <description><![CDATA[<p>It made already quite some noise in the news, GitHub copilot promises to be your pair programmer for life.
In this episode I explain how and what GitHub copilot does. Should developers be happy, scared or just keep coding the traditional way?</p>
<p>Â </p>
Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>It made already quite some noise in the news, GitHub copilot promises to be your pair programmer for life.<br>
In this episode I explain how and what GitHub copilot does. Should developers be happy, scared or just keep coding the traditional way?</p>
<p>Â </p>
Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2kyuws/github_copilot9mda6.mp3" length="62162152" type="audio/mpeg"/>
        <itunes:summary><![CDATA[It made already quite some noise in the news, GitHub copilot promises to be your pair programmer for life.In this episode I explain how and what GitHub copilot does. Should developers be happy, scared or just keep coding the traditional way?
Â 
Sponsors
Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link https://surfshark.deals/DATASCIENCE]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:22</itunes:duration>
                <itunes:episode>162</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Pandas vs Rust [RB] (Ep. 158)</title>
        <itunes:title>Pandas vs Rust [RB] (Ep. 158)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/pandasvs-rust-rb-ep-158/</link>
                    <comments>https://datascienceathome.podbean.com/e/pandasvs-rust-rb-ep-158/#comments</comments>        <pubDate>Thu, 01 Jul 2021 07:24:55 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/9bee1372-2c37-30db-ba15-f02bc0099cdd</guid>
                                    <description><![CDATA[Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. 
Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. <br>
Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vt89g5/RB_pandas_vs_rustbro7n.mp3" length="60639945" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Sponsors
Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link https://surfshark.deals/DATASCIENCE
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:35</itunes:duration>
                <itunes:episode>160</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>A simple trick for very unbalanced data (Ep. 157)</title>
        <itunes:title>A simple trick for very unbalanced data (Ep. 157)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/a-simple-trick-for-very-unbalanced-data-ep-157/</link>
                    <comments>https://datascienceathome.podbean.com/e/a-simple-trick-for-very-unbalanced-data-ep-157/#comments</comments>        <pubDate>Tue, 22 Jun 2021 11:40:49 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/d664eef5-52fb-39e8-96a8-d5b9c69a27fd</guid>
                                    <description><![CDATA[<p>Data from the real world are never perfectly balanced. In this episode I explain a simple yet effective trick to train models with very unbalanced data. Enjoy the show!</p>

Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a> </p>
<p>Â </p>
References
<ul><li>Leo Breiman, <a href='https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf'>Random Forests</a>, 2001</li>
<li>C. Chen, A. Liaw, L. Breiman, <a href='https://statistics.berkeley.edu/tech-reports/666'>Using Random Forest to Learn Imbalanced Data</a> (2004)</li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Data from the real world are never perfectly balanced. In this episode I explain a simple yet effective trick to train models with very unbalanced data. Enjoy the show!</p>
<br>
Sponsors
<p>Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link <a href='https://surfshark.deals/DATASCIENCE'>https://surfshark.deals/DATASCIENCE</a> </p>
<p>Â </p>
References
<ul><li>Leo Breiman, <a href='https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf'>Random Forests</a>, 2001</li>
<li>C. Chen, A. Liaw, L. Breiman, <a href='https://statistics.berkeley.edu/tech-reports/666'>Using Random Forest to Learn Imbalanced Data</a> (2004)</li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/44n8qz/dealing_with_very_unbalanced_data9micn.mp3" length="42296552" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Data from the real world are never perfectly balanced. In this episode I explain a simple yet effective trick to train models with very unbalanced data. Enjoy the show!
Sponsors
Get one of the best VPN at a massive discount with coupon code DATASCIENCE. It provides you with an 83% discount which unlocks the best price in the market plus 3 extra months for free. Here is the link https://surfshark.deals/DATASCIENCE 
Â 
References
Leo Breiman, Random Forests, 2001
C. Chen, A. Liaw, L. Breiman, Using Random Forest to Learn Imbalanced Data (2004)
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:02</itunes:duration>
                <itunes:episode>157</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Time to take your data back with Tapmydata (Ep. 156)</title>
        <itunes:title>Time to take your data back with Tapmydata (Ep. 156)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/time-to-take-your-data-back-with-tapmydata-ep-156/</link>
                    <comments>https://datascienceathome.podbean.com/e/time-to-take-your-data-back-with-tapmydata-ep-156/#comments</comments>        <pubDate>Tue, 15 Jun 2021 07:02:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a36856ab-142a-34c7-8b86-2a130bc353c4</guid>
                                    <description><![CDATA[In this episode I am with Gilbert Hill, head of strategy at <a href='https://tapmydata.com/'>https://tapmydata.com/</a>
We speak about personal data, blockchain and the ability to control it and monetize with another simple yet effective app in the ecosystem.
Â 
Â 
References
<ul><li dir="ltr"><a href='https://tapmydata.com/'>https://tapmydata.com/</a></li>
<li dir="ltr"><a href='https://medium.com/@tholder/we-dont-want-your-data-pushing-boundaries-in-data-collection-and-end-to-end-encryption-for-apps-ebd1d5f79df5'>https://medium.com/@tholder/we-dont-want-your-data-pushing-boundaries-in-data-collection-and-end-to-end-encryption-for-apps-ebd1d5f79df5</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[In this episode I am with Gilbert Hill, head of strategy at <a href='https://tapmydata.com/'>https://tapmydata.com/</a>
We speak about personal data, blockchain and the ability to control it and monetize with another simple yet effective app in the ecosystem.
Â 
Â 
References
<ul><li dir="ltr"><a href='https://tapmydata.com/'>https://tapmydata.com/</a></li>
<li dir="ltr"><a href='https://medium.com/@tholder/we-dont-want-your-data-pushing-boundaries-in-data-collection-and-end-to-end-encryption-for-apps-ebd1d5f79df5'>https://medium.com/@tholder/we-dont-want-your-data-pushing-boundaries-in-data-collection-and-end-to-end-encryption-for-apps-ebd1d5f79df5</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vyuq2x/tapmydata.mp3" length="79410493" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am with Gilbert Hill, head of strategy at https://tapmydata.com/
We speak about personal data, blockchain and the ability to control it and monetize with another simple yet effective app in the ecosystem.
Â 
Â 
References
https://tapmydata.com/
https://medium.com/@tholder/we-dont-want-your-data-pushing-boundaries-in-data-collection-and-end-to-end-encryption-for-apps-ebd1d5f79df5
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>41:21</itunes:duration>
                <itunes:episode>156</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>True Machine Intelligence just like the human brain (Ep. 155)</title>
        <itunes:title>True Machine Intelligence just like the human brain (Ep. 155)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/true-machine-intelligence-like-the-human-brain-ep-155/</link>
                    <comments>https://datascienceathome.podbean.com/e/true-machine-intelligence-like-the-human-brain-ep-155/#comments</comments>        <pubDate>Fri, 04 Jun 2021 08:18:57 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/e17dfcbd-e71d-3456-85b5-0aaf2e6370f7</guid>
                                    <description><![CDATA[<p>In this episode I have a really interesting conversation with Karan Grewal, member of the research staff at<a href='https://numenta.com/'> Numenta</a> where he investigates how biological principles of intelligence can be translated into silicon.
We speak about the thousand brains theory and why neural networks forget.
</p>
<p>Â </p>
<p>Â </p>
References
<ul><li style="font-weight:400;">Main paper on the Thousand Brains Theory: <a href='https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/full'>https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/full</a></li>
<li style="font-weight:400;">Blog post on Thousand Brains Theory: <a href='https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/'>https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/</a></li>
<li style="font-weight:400;">GLOM paper by Geoff Hinton: <a href='https://arxiv.org/pdf/2102.12627.pdf'>https://arxiv.org/pdf/2102.12627.pdf</a></li>
<li style="font-weight:400;">Why neural networks forget? <a href='https://numenta.com/blog/2021/02/04/why-neural-networks-forget-and-lessons-from-the-brain'>https://numenta.com/blog/2021/02/04/why-neural-networks-forget-and-lessons-from-the-brain</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I have a really interesting conversation with Karan Grewal, member of the research staff at<a href='https://numenta.com/'> Numenta</a> where he investigates how biological principles of intelligence can be translated into silicon.<br>
We speak about the thousand brains theory and why neural networks forget.<br>
</p>
<p>Â </p>
<p>Â </p>
References
<ul><li style="font-weight:400;">Main paper on the Thousand Brains Theory: <a href='https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/full'>https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/full</a></li>
<li style="font-weight:400;">Blog post on Thousand Brains Theory: <a href='https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/'>https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/</a></li>
<li style="font-weight:400;">GLOM paper by Geoff Hinton: <a href='https://arxiv.org/pdf/2102.12627.pdf'>https://arxiv.org/pdf/2102.12627.pdf</a></li>
<li style="font-weight:400;">Why neural networks forget? <a href='https://numenta.com/blog/2021/02/04/why-neural-networks-forget-and-lessons-from-the-brain'>https://numenta.com/blog/2021/02/04/why-neural-networks-forget-and-lessons-from-the-brain</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xmgqcn/numenta.mp3" length="64519442" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I have a really interesting conversation with Karan Grewal, member of the research staff at Numenta where he investigates how biological principles of intelligence can be translated into silicon.We speak about the thousand brains theory and why neural networks forget.
Â 
Â 
References
Main paper on the Thousand Brains Theory: https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/full
Blog post on Thousand Brains Theory: https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/
GLOM paper by Geoff Hinton: https://arxiv.org/pdf/2102.12627.pdf
Why neural networks forget? https://numenta.com/blog/2021/02/04/why-neural-networks-forget-and-lessons-from-the-brain
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:36</itunes:duration>
                <itunes:episode>155</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Delivering unstoppable data with Streamr (Ep. 154)</title>
        <itunes:title>Delivering unstoppable data with Streamr (Ep. 154)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/delivering-unstoppable-data-with-streamr-ep-154/</link>
                    <comments>https://datascienceathome.podbean.com/e/delivering-unstoppable-data-with-streamr-ep-154/#comments</comments>        <pubDate>Wed, 26 May 2021 06:58:41 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/e38b482f-b710-3e36-a8cb-b05ec350d592</guid>
                                    <description><![CDATA[<p>Delivering unstoppable data to unstoppable apps is now possible with <a href='https://streamr.network/'>Streamr Network</a> </p>
<p>Streamr is a layer zero protocol for real-time data which powers the decentralized Streamr pub/sub network. The technology works in tandem with companion blockchains - currently Ethereum and xDai chain - which are used for identity, security and payments. On top is the application layer, including the Data Union framework, Marketplace and Core, and all third party applications.Â </p>
<p>In this episode I have a very interesting conversation with Streamr founder and CEO Henri Pihkala
</p>
Â 
References
<ul><li style="font-weight:400;">Streamr project website: <a href='https://streamr.network/'>https://streamr.network/</a>Â </li>
<li style="font-weight:400;">More about the Streamr Network: <a href='https://streamr.network/discover/network'>https://streamr.network/discover/network</a>Â </li>
<li style="font-weight:400;">More about Data Unions: <a href='https://streamr.network/discover/data-unions'>https://streamr.network/discover/data-unions</a></li>
<li style="font-weight:400;">More about the Data Marketplace: <a href='https://streamr.network/discover/marketplace'>https://streamr.network/discover/marketplace</a>Â </li>
<li style="font-weight:400;">Developer docs: <a href='https://streamr.network/docs'>https://streamr.network/docs</a>Â </li>
<li style="font-weight:400;">Streamr Github: <a href='https://github.com/streamr-dev'>https://github.com/streamr-dev</a>Â </li>
<li style="font-weight:400;">Streamr Discord: <a href='https://discord.gg/gZAm8P7hK8'>https://discord.gg/gZAm8P7hK8</a>Â </li>
<li style="font-weight:400;">Streamr Twitter: <a href='https://twitter.com/streamr'>https://twitter.com/streamr</a>Â </li>
<li style="font-weight:400;">Streamr YouTube: <a href='https://www.youtube.com/channel/UCGWEA61RueG-9DV53s-ZyJQ'>https://www.youtube.com/channel/UCGWEA61RueG-9DV53s-ZyJQ</a>Â </li>
<li style="font-weight:400;">Streamr Reddit: <a href='https://reddit.com/r/streamr'>https://reddit.com/r/streamr</a>Â </li>
<li style="font-weight:400;">Scalability & latency research blog: <a href='https://blog.streamr.network/streamr-network-performance-and-scalability-whitepaper/'>https://blog.streamr.network/streamr-network-performance-and-scalability-whitepaper/</a>Â </li>
<li style="font-weight:400;">Swash, a Data Union built on Streamr: <a href='https://swashapp.io/'>https://swashapp.io/</a>Â </li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Delivering unstoppable data to unstoppable apps is now possible with <a href='https://streamr.network/'>Streamr Network</a> </p>
<p>Streamr is a layer zero protocol for real-time data which powers the decentralized Streamr pub/sub network. The technology works in tandem with companion blockchains - currently Ethereum and xDai chain - which are used for identity, security and payments. On top is the application layer, including the Data Union framework, Marketplace and Core, and all third party applications.Â </p>
<p>In this episode I have a very interesting conversation with Streamr founder and CEO Henri Pihkala<br>
</p>
Â 
References
<ul><li style="font-weight:400;">Streamr project website: <a href='https://streamr.network/'>https://streamr.network/</a>Â </li>
<li style="font-weight:400;">More about the Streamr Network: <a href='https://streamr.network/discover/network'>https://streamr.network/discover/network</a>Â </li>
<li style="font-weight:400;">More about Data Unions: <a href='https://streamr.network/discover/data-unions'>https://streamr.network/discover/data-unions</a></li>
<li style="font-weight:400;">More about the Data Marketplace: <a href='https://streamr.network/discover/marketplace'>https://streamr.network/discover/marketplace</a>Â </li>
<li style="font-weight:400;">Developer docs: <a href='https://streamr.network/docs'>https://streamr.network/docs</a>Â </li>
<li style="font-weight:400;">Streamr Github: <a href='https://github.com/streamr-dev'>https://github.com/streamr-dev</a>Â </li>
<li style="font-weight:400;">Streamr Discord: <a href='https://discord.gg/gZAm8P7hK8'>https://discord.gg/gZAm8P7hK8</a>Â </li>
<li style="font-weight:400;">Streamr Twitter: <a href='https://twitter.com/streamr'>https://twitter.com/streamr</a>Â </li>
<li style="font-weight:400;">Streamr YouTube: <a href='https://www.youtube.com/channel/UCGWEA61RueG-9DV53s-ZyJQ'>https://www.youtube.com/channel/UCGWEA61RueG-9DV53s-ZyJQ</a>Â </li>
<li style="font-weight:400;">Streamr Reddit: <a href='https://reddit.com/r/streamr'>https://reddit.com/r/streamr</a>Â </li>
<li style="font-weight:400;">Scalability & latency research blog: <a href='https://blog.streamr.network/streamr-network-performance-and-scalability-whitepaper/'>https://blog.streamr.network/streamr-network-performance-and-scalability-whitepaper/</a>Â </li>
<li style="font-weight:400;">Swash, a Data Union built on Streamr: <a href='https://swashapp.io/'>https://swashapp.io/</a>Â </li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/j97jmy/streamr_network.mp3" length="82555218" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Delivering unstoppable data to unstoppable apps is now possible with Streamr Network 
Streamr is a layer zero protocol for real-time data which powers the decentralized Streamr pub/sub network. The technology works in tandem with companion blockchains - currently Ethereum and xDai chain - which are used for identity, security and payments. On top is the application layer, including the Data Union framework, Marketplace and Core, and all third party applications.Â 
In this episode I have a very interesting conversation with Streamr founder and CEO Henri Pihkala
Â 
References
Streamr project website: https://streamr.network/Â 
More about the Streamr Network: https://streamr.network/discover/networkÂ 
More about Data Unions: https://streamr.network/discover/data-unions
More about the Data Marketplace: https://streamr.network/discover/marketplaceÂ 
Developer docs: https://streamr.network/docsÂ 
Streamr Github: https://github.com/streamr-devÂ 
Streamr Discord: https://discord.gg/gZAm8P7hK8Â 
Streamr Twitter: https://twitter.com/streamrÂ 
Streamr YouTube: https://www.youtube.com/channel/UCGWEA61RueG-9DV53s-ZyJQÂ 
Streamr Reddit: https://reddit.com/r/streamrÂ 
Scalability & latency research blog: https://blog.streamr.network/streamr-network-performance-and-scalability-whitepaper/Â 
Swash, a Data Union built on Streamr: https://swashapp.io/Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>43:00</itunes:duration>
                <itunes:episode>154</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>MLOps: the good, the bad and the ugly (Ep. 153)</title>
        <itunes:title>MLOps: the good, the bad and the ugly (Ep. 153)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/mlops-the-good-the-bad-and-the-ugly-ep-153/</link>
                    <comments>https://datascienceathome.podbean.com/e/mlops-the-good-the-bad-and-the-ugly-ep-153/#comments</comments>        <pubDate>Mon, 24 May 2021 15:20:58 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/190b0727-a1f6-3763-a77a-88a20ed81412</guid>
                                    <description><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pbb65m/mlops-part-3.mp3" length="47404013" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsor
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:41</itunes:duration>
                <itunes:episode>153</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>MLOps: what is and why it is important Part 2 (Ep. 152)</title>
        <itunes:title>MLOps: what is and why it is important Part 2 (Ep. 152)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/mlops-what-is-and-why-it-is-important-part-2-ep-152/</link>
                    <comments>https://datascienceathome.podbean.com/e/mlops-what-is-and-why-it-is-important-part-2-ep-152/#comments</comments>        <pubDate>Wed, 19 May 2021 09:02:46 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/70b5a2b9-730c-3fe7-8996-3943c6386e50</guid>
                                    <description><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Our Sponsor</p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jdekm8/mlops-part-2.mp3" length="58780027" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Sponsor
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:37</itunes:duration>
                <itunes:episode>152</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>MLOps: what is and why it is important (Ep. 151)</title>
        <itunes:title>MLOps: what is and why it is important (Ep. 151)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/mlops-what-is-and-why-it-is-important-ep-151/</link>
                    <comments>https://datascienceathome.podbean.com/e/mlops-what-is-and-why-it-is-important-ep-151/#comments</comments>        <pubDate>Tue, 11 May 2021 08:12:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2f08770d-38a3-33f1-b756-171851098cdc</guid>
                                    <description><![CDATA[<p>If you think that knowing Tensorflow and Scikit-learn is enough, think again.

MLOps is one of those trendy terms today. 
What is MLOps and why is it important? 
In this episode I speak about the undeniable evolution of the data scientist in the last 5-10 years. 

</p>
<p>Sponsors</p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>If you think that knowing Tensorflow and Scikit-learn is enough, think again.<br>
<br>
MLOps is one of those trendy terms today. <br>
What is MLOps and why is it important? <br>
In this episode I speak about the undeniable evolution of the data scientist in the last 5-10 years. <br>
<br>
</p>
<p>Sponsors</p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tvtefh/mlops-part-1.mp3" length="63504637" type="audio/mpeg"/>
        <itunes:summary><![CDATA[If you think that knowing Tensorflow and Scikit-learn is enough, think again.MLOps is one of those trendy terms today. What is MLOps and why is it important? In this episode I speak about the undeniable evolution of the data scientist in the last 5-10 years. 
Sponsors
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
Â 
Â 
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:04</itunes:duration>
                <itunes:episode>151</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Can I get paid for my data? With Mike Andi from Mytiki (Ep. 150)</title>
        <itunes:title>Can I get paid for my data? With Mike Andi from Mytiki (Ep. 150)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/can-i-get-paid-for-my-data-with-mike-andi-from-mytiki-ep-150/</link>
                    <comments>https://datascienceathome.podbean.com/e/can-i-get-paid-for-my-data-with-mike-andi-from-mytiki-ep-150/#comments</comments>        <pubDate>Wed, 28 Apr 2021 06:59:41 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ad46d088-a8d0-37f8-a880-3328c3df4cb9</guid>
                                    <description><![CDATA[Your data is worth thousands a year. Why arenâ€™t you getting your fair share? 
There is a company that has a mission: they want you to take back control and get paid for your data.
In this episode I speak about knowledge graphs, data confidentiality and privacy with Mike Audi, CEO of MyTiki.
Â 
Â 
You can reach them on their website <a href='https://mytiki.com/'>https://mytiki.com/</a>
Â 
Discord official channel 


<a href='https://discord.com/invite/evjYQq48Be'>https://discord.com/invite/evjYQq48Be</a>
Â 
Telegram
<a href='https://t.me/mytikiapp'>https://t.me/mytikiapp</a>
Â 
Signal
<a href='https://signal.group/#CjQKIA66Eq2VHecpcCd-cu-dziozMRSH3EuQdcZJNyMOYNi5EhC0coWtjWzKQ1dDKEjMqhkP'>https://signal.group/#CjQKIA66Eq2VHecpcCd-cu-dziozMRSH3EuQdcZJNyMOYNi5EhC0coWtjWzKQ1dDKEjMqhkP</a>
Â 
Â 

]]></description>
                                                            <content:encoded><![CDATA[Your data is worth thousands a year. Why arenâ€™t you getting your fair share? <br>
There is a company that has a mission: they want you to take back control and get paid for your data.
In this episode I speak about knowledge graphs, data confidentiality and privacy with Mike Audi, CEO of MyTiki.
Â 
Â 
You can reach them on their website <a href='https://mytiki.com/'>https://mytiki.com/</a>
Â 
Discord official channel 


<a href='https://discord.com/invite/evjYQq48Be'>https://discord.com/invite/evjYQq48Be</a>
Â 
Telegram
<a href='https://t.me/mytikiapp'>https://t.me/mytikiapp</a>
Â 
Signal
<a href='https://signal.group/#CjQKIA66Eq2VHecpcCd-cu-dziozMRSH3EuQdcZJNyMOYNi5EhC0coWtjWzKQ1dDKEjMqhkP'>https://signal.group/#CjQKIA66Eq2VHecpcCd-cu-dziozMRSH3EuQdcZJNyMOYNi5EhC0coWtjWzKQ1dDKEjMqhkP</a>
Â 
Â 

]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/etxwhv/mytiki-data-marketplace.mp3" length="74999351" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Your data is worth thousands a year. Why arenâ€™t you getting your fair share? There is a company that has a mission: they want you to take back control and get paid for your data.
In this episode I speak about knowledge graphs, data confidentiality and privacy with Mike Audi, CEO of MyTiki.
Â 
Â 
You can reach them on their website https://mytiki.com/
Â 
Discord official channel 


https://discord.com/invite/evjYQq48Be
Â 
Telegram
https://t.me/mytikiapp
Â 
Signal
https://signal.group/#CjQKIA66Eq2VHecpcCd-cu-dziozMRSH3EuQdcZJNyMOYNi5EhC0coWtjWzKQ1dDKEjMqhkP
Â 
Â 

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>39:04</itunes:duration>
                <itunes:episode>150</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Building high-growth data businesses with Lillian Pierson (Ep. 149)</title>
        <itunes:title>Building high-growth data businesses with Lillian Pierson (Ep. 149)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/building-high-growth-data-businesses-with-lillian-pearson-ep-149/</link>
                    <comments>https://datascienceathome.podbean.com/e/building-high-growth-data-businesses-with-lillian-pearson-ep-149/#comments</comments>        <pubDate>Mon, 19 Apr 2021 08:29:57 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c1d818f2-4ad3-32ea-8150-65d1e62ea897</guid>
                                    <description><![CDATA[

In this episode I have an amazing conversation with Lillian Pierson from <a href='https://www.data-mania.com'>data-mania.com</a>
This is an action-packed episode on how data professionals can quickly convert their data expertise into high-growth data businesses, all by selecting optimal business models, revenue models, and pricing structures.


If you want to know more or get in touch with Lillian, follow the links below:
<ol><li>Weekly Free Trainings: We currently publish 1 free training per week on YouTube! <a href='https://www.youtube.com/channel/UCK4MGP0A6lBjnQWAmcWBcKQ'>https://www.youtube.com/channel/UCK4MGP0A6lBjnQWAmcWBcKQ</a></li>
<li>Becoming World-Class Data Leaders and Data Entrepreneurs Facebook Group: <a href='https://www.facebook.com/groups/data.leaders.and.entrepreneurs'>https://www.facebook.com/groups/data.leaders.and.entrepreneurs</a></li>
<li>LinkedIn: <a href='https://www.linkedin.com/in/lillianpierson/'>https://www.linkedin.com/in/lillianpierson/</a></li>
<li>The Data Entrepreneurâ€™s Toolkit: A recommendation set for 32 free (or low-cost) tools & processes that'll actually grow your data business (even if you still havenâ€™t put up that website yet!). <a href='https://www.data-mania.com/data-entrepreneur-toolkit/'>https://www.data-mania.com/data-entrepreneur-toolkit/</a></li>
</ol>

]]></description>
                                                            <content:encoded><![CDATA[

In this episode I have an amazing conversation with Lillian Pierson from <a href='https://www.data-mania.com'>data-mania.com</a>
This is an action-packed episode on how data professionals can quickly convert their data expertise into high-growth data businesses, all by selecting optimal business models, revenue models, and pricing structures.<br>
<br>

If you want to know more or get in touch with Lillian, follow the links below:<br>
<ol><li>Weekly Free Trainings: We currently publish 1 free training per week on YouTube! <a href='https://www.youtube.com/channel/UCK4MGP0A6lBjnQWAmcWBcKQ'>https://www.youtube.com/channel/UCK4MGP0A6lBjnQWAmcWBcKQ</a></li>
<li>Becoming World-Class Data Leaders and Data Entrepreneurs Facebook Group: <a href='https://www.facebook.com/groups/data.leaders.and.entrepreneurs'>https://www.facebook.com/groups/data.leaders.and.entrepreneurs</a></li>
<li>LinkedIn: <a href='https://www.linkedin.com/in/lillianpierson/'>https://www.linkedin.com/in/lillianpierson/</a></li>
<li>The Data Entrepreneurâ€™s Toolkit: A recommendation set for 32 free (or low-cost) tools & processes that'll actually grow your data business (even if you still havenâ€™t put up that website yet!). <a href='https://www.data-mania.com/data-entrepreneur-toolkit/'>https://www.data-mania.com/data-entrepreneur-toolkit/</a></li>
</ol>

]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/q4zy5r/lillian-data-mania.mp3" length="49069999" type="audio/mpeg"/>
        <itunes:summary><![CDATA[

In this episode I have an amazing conversation with Lillian Pierson from data-mania.com
This is an action-packed episode on how data professionals can quickly convert their data expertise into high-growth data businesses, all by selecting optimal business models, revenue models, and pricing structures.
If you want to know more or get in touch with Lillian, follow the links below:Weekly Free Trainings: We currently publish 1 free training per week on YouTube! https://www.youtube.com/channel/UCK4MGP0A6lBjnQWAmcWBcKQ
Becoming World-Class Data Leaders and Data Entrepreneurs Facebook Group: https://www.facebook.com/groups/data.leaders.and.entrepreneurs
LinkedIn: https://www.linkedin.com/in/lillianpierson/
The Data Entrepreneurâ€™s Toolkit: A recommendation set for 32 free (or low-cost) tools & processes that'll actually grow your data business (even if you still havenâ€™t put up that website yet!). https://www.data-mania.com/data-entrepreneur-toolkit/


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:33</itunes:duration>
                <itunes:episode>149</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Learning and training in AI times (Ep. 148)</title>
        <itunes:title>Learning and training in AI times (Ep. 148)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/learning-and-training-in-ai-times-ep-148/</link>
                    <comments>https://datascienceathome.podbean.com/e/learning-and-training-in-ai-times-ep-148/#comments</comments>        <pubDate>Tue, 13 Apr 2021 10:00:43 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/80e7c970-8050-3ec8-9a90-d6a194e0e5fc</guid>
                                    <description><![CDATA[<p>Is there a gap between life sciences and data science?
What's the situation when it comes to interdisciplinary research?
In this episode I am with Laura Harris, Director of Training for the Institute of Cyber-Enabled Research (ICER) at Michigan State University (MSU), and we try to answer some of those questions.
</p>
<p>Â </p>
<p>You can contact Laura at  <a href='mailto:training@msu.edu'>training@msu.edu</a> or on <a href='https://www.linkedin.com/in/laura-harris-ph-d-2a741a18a/'>LinkedIn</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Is there a gap between life sciences and data science?<br>
What's the situation when it comes to interdisciplinary research?<br>
In this episode I am with Laura Harris, Director of Training for the Institute of Cyber-Enabled Research (ICER) at Michigan State University (MSU), and we try to answer some of those questions.<br>
</p>
<p>Â </p>
<p>You can contact Laura at  <a href='mailto:training@msu.edu'>training@msu.edu</a> or on <a href='https://www.linkedin.com/in/laura-harris-ph-d-2a741a18a/'>LinkedIn</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/djyfby/laura-training-in-ai-times.mp3" length="61223416" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Is there a gap between life sciences and data science?What's the situation when it comes to interdisciplinary research?In this episode I am with Laura Harris, Director of Training for the Institute of Cyber-Enabled Research (ICER) at Michigan State University (MSU), and we try to answer some of those questions.
Â 
You can contact Laura at  training@msu.edu or on LinkedIn]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:53</itunes:duration>
                <itunes:episode>148</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>You are the product [RB] (Ep. 147)</title>
        <itunes:title>You are the product [RB] (Ep. 147)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/you-are-the-product-rb-ep-147/</link>
                    <comments>https://datascienceathome.podbean.com/e/you-are-the-product-rb-ep-147/#comments</comments>        <pubDate>Sun, 11 Apr 2021 20:26:52 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5a054cdb-e0e9-38f4-8666-f3be1044613a</guid>
                                    <description><![CDATA[
In this episode I am with George Hosu from <a href='https://cerebralab.com'>Cerebralab</a>
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>

Links
<ul><li><a href='https://cerebralab.com'>https://cerebralab.com</a></li>
<li><a href='https://www.eugenewei.com/blog/2019/2/19/status-as-a-service'>https://www.eugenewei.com/blog/2019/2/19/status-as-a-service</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[
In this episode I am with George Hosu from <a href='https://cerebralab.com'>Cerebralab</a>
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>

Links
<ul><li><a href='https://cerebralab.com'>https://cerebralab.com</a></li>
<li><a href='https://www.eugenewei.com/blog/2019/2/19/status-as-a-service'>https://www.eugenewei.com/blog/2019/2/19/status-as-a-service</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cdfnkq/you-are-the-product.mp3" length="44456448" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
In this episode I am with George Hosu from Cerebralab
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.
Â 

Links
https://cerebralab.com
https://www.eugenewei.com/blog/2019/2/19/status-as-a-service
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>45:04</itunes:duration>
                <itunes:episode>147</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Polars: the fastest dataframe crate in Rust - with Ritchie Vink (Ep. 146)</title>
        <itunes:title>Polars: the fastest dataframe crate in Rust - with Ritchie Vink (Ep. 146)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/polars-the-fastest-dataframe-crate-in-rust-ep-146/</link>
                    <comments>https://datascienceathome.podbean.com/e/polars-the-fastest-dataframe-crate-in-rust-ep-146/#comments</comments>        <pubDate>Thu, 08 Apr 2021 07:39:10 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/5fa7c9fb-fbaa-306f-898e-2be04f8f9623</guid>
                                    <description><![CDATA[<p>In this episode I speak with Ritchie Vink, the author of Polars, a crate that is the fastest dataframe library at date of speaking :) If you want to participate to an amazing Rust open source project, this is your change to collaborate to the official repository in the references.</p>
<p>Â </p>
References
<p><a href='https://github.com/ritchie46/polars'>https://github.com/ritchie46/polars</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with Ritchie Vink, the author of Polars, a crate that is the fastest dataframe library at date of speaking :) If you want to participate to an amazing Rust open source project, this is your change to collaborate to the official repository in the references.</p>
<p>Â </p>
References
<p><a href='https://github.com/ritchie46/polars'>https://github.com/ritchie46/polars</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7ehkn4/polars-and-rust.mp3" length="63120951" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Ritchie Vink, the author of Polars, a crate that is the fastest dataframe library at date of speaking :) If you want to participate to an amazing Rust open source project, this is your change to collaborate to the official repository in the references.
Â 
References
https://github.com/ritchie46/polars
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:52</itunes:duration>
                <itunes:episode>146</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Apache Arrow, Ballista and Big Data in Rust with Andy Grove (Ep. 145)</title>
        <itunes:title>Apache Arrow, Ballista and Big Data in Rust with Andy Grove (Ep. 145)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/apache-arrow-ballista-and-big-data-in-rust-with-andy-grove-ep-145/</link>
                    <comments>https://datascienceathome.podbean.com/e/apache-arrow-ballista-and-big-data-in-rust-with-andy-grove-ep-145/#comments</comments>        <pubDate>Fri, 26 Mar 2021 10:43:54 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/eabd6f47-511c-35f5-bf2d-43fcf15d94e1</guid>
                                    <description><![CDATA[<p>Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? <a href='https://www.rust-lang.org/'>Rust</a>? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.
Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.</p>
Â 
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
References
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://arrow.apache.org/</a></p>
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://ballistacompute.org/</a></p>
<p>Â </p>
<p><a href='https://github.com/ballista-compute/ballista'>https://github.com/ballista-compute/ballista</a></p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? <a href='https://www.rust-lang.org/'>Rust</a>? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.<br>
Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.</p>
Â 
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>
References
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://arrow.apache.org/</a></p>
<p>Â </p>
<p><a href='https://ballistacompute.org/'>https://ballistacompute.org/</a></p>
<p>Â </p>
<p><a href='https://github.com/ballista-compute/ballista'>https://github.com/ballista-compute/ballista</a></p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tnsrr6/ballista-with-andy-grove.mp3" length="58102097" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Do you want to know the latest in big data analytics frameworks? Have you ever heard of Apache Arrow? Rust? Ballista? In this episode I speak with Andy Grove one of the main authors of Apache Arrow and Ballista compute engine.Andy explains some challenges while he was designing the Arrow and Ballista memory models and he describes some amazing solutions.
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.
Â 
References
Â 
https://arrow.apache.org/
Â 
https://ballistacompute.org/
Â 
https://github.com/ballista-compute/ballista
Â 
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:15</itunes:duration>
                <itunes:episode>145</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Pandas vs Rust (Ep. 144)</title>
        <itunes:title>Pandas vs Rust (Ep. 144)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/pandas-vs-rust-ep-144/</link>
                    <comments>https://datascienceathome.podbean.com/e/pandas-vs-rust-ep-144/#comments</comments>        <pubDate>Fri, 19 Mar 2021 13:23:01 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ccb47205-b441-38c3-9680-9f4a643e689e</guid>
                                    <description><![CDATA[<p>Pandas is the de-facto standard for data loading and manipulation. Python is the de-facto programming language for such operations. Rust is the underdog. Or is it?
In this episode I am showing you why that is no longer the case.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
Useful Links
<p><a href='https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas'>https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas</a></p>
<p><a href='https://github.com/ritchie46/polars'>https://github.com/ritchie46/polars</a></p>
<p><a href='https://github.com/rust-ndarray/ndarray'>https://github.com/rust-ndarray/ndarray</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Pandas is the de-facto standard for data loading and manipulation. Python is the de-facto programming language for such operations. Rust is the underdog. Or is it?<br>
In this episode I am showing you why that is no longer the case.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
Useful Links
<p><a href='https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas'>https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas</a></p>
<p><a href='https://github.com/ritchie46/polars'>https://github.com/ritchie46/polars</a></p>
<p><a href='https://github.com/rust-ndarray/ndarray'>https://github.com/rust-ndarray/ndarray</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/5d58xc/pandas-vs-rust.mp3" length="60815488" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Pandas is the de-facto standard for data loading and manipulation. Python is the de-facto programming language for such operations. Rust is the underdog. Or is it?In this episode I am showing you why that is no longer the case.
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â 
Â 
Useful Links
https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas
https://github.com/ritchie46/polars
https://github.com/rust-ndarray/ndarray
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:40</itunes:duration>
                <itunes:episode>144</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Concurrent is not parallel - Part 2 (Ep. 143)</title>
        <itunes:title>Concurrent is not parallel - Part 2 (Ep. 143)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/concurrent-is-not-parallel-part-2-ep-143/</link>
                    <comments>https://datascienceathome.podbean.com/e/concurrent-is-not-parallel-part-2-ep-143/#comments</comments>        <pubDate>Sat, 13 Mar 2021 08:46:54 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c08f4c67-8dbc-3078-8dff-eff2dcceb8cd</guid>
                                    <description><![CDATA[<p>In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems.</p>
<p>Rock-star data scientists must know how concurrency works and when to use it IMHO.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
Useful Links
<p><a href='http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/'>http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/</a></p>
<p><a href='https://doc.rust-lang.org/book/ch16-00-concurrency.html'>https://doc.rust-lang.org/book/ch16-00-concurrency.html</a></p>
<p><a href='https://urban-institute.medium.com/using-multiprocessing-to-make-python-code-faster-23ea5ef996ba'>https://urban-institute.medium.com/using-multiprocessing-to-make-python-code-faster-23ea5ef996ba</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems.</p>
<p>Rock-star data scientists must know how concurrency works and when to use it IMHO.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
Useful Links
<p><a href='http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/'>http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/</a></p>
<p><a href='https://doc.rust-lang.org/book/ch16-00-concurrency.html'>https://doc.rust-lang.org/book/ch16-00-concurrency.html</a></p>
<p><a href='https://urban-institute.medium.com/using-multiprocessing-to-make-python-code-faster-23ea5ef996ba'>https://urban-institute.medium.com/using-multiprocessing-to-make-python-code-faster-23ea5ef996ba</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/p9z2ya/concurrency-vs-parallelism-Part-2.mp3" length="29479415" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems.
Rock-star data scientists must know how concurrency works and when to use it IMHO.
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â 
Â 
Useful Links
http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/
https://doc.rust-lang.org/book/ch16-00-concurrency.html
https://urban-institute.medium.com/using-multiprocessing-to-make-python-code-faster-23ea5ef996ba
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:21</itunes:duration>
                <itunes:episode>143</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Concurrent is not parallel - Part 1 (Ep. 142)</title>
        <itunes:title>Concurrent is not parallel - Part 1 (Ep. 142)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/concurrent-is-not-parallel-part-1-ep-142/</link>
                    <comments>https://datascienceathome.podbean.com/e/concurrent-is-not-parallel-part-1-ep-142/#comments</comments>        <pubDate>Wed, 10 Mar 2021 13:26:51 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/04f630d7-11f0-3be8-8fae-4bbd5d978d14</guid>
                                    <description><![CDATA[<p>In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems. 

Rock-star data scientists must know how concurrency works and when to use it IMHO.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems. <br>
<br>
Rock-star data scientists must know how concurrency works and when to use it IMHO.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/rwu7ar/concurrency-vs-parallelism_-_Part_1_atjz8.mp3" length="61790169" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In plain English, concurrent and parallel are synonyms. Not for a CPU. And definitely not for programmers. In this episode I summarize the ways to parallelize on different architectures and operating systems. Rock-star data scientists must know how concurrency works and when to use it IMHO.
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:10</itunes:duration>
                <itunes:episode>142</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Backend technologies for machine learning in production (Ep. 141)</title>
        <itunes:title>Backend technologies for machine learning in production (Ep. 141)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/backend-technologies-for-machine-learning-in-production-ep-141/</link>
                    <comments>https://datascienceathome.podbean.com/e/backend-technologies-for-machine-learning-in-production-ep-141/#comments</comments>        <pubDate>Tue, 02 Mar 2021 07:47:49 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0d8e36da-04c3-3447-bf36-3bc4abf9631b</guid>
                                    <description><![CDATA[<p>This is one of the most dynamic and fascinating topics: API technologies for machine learning.</p>
<p>It's always fun to build ML models. But how about serving them in the real world? In this episode I speak about three must-know technologies to place your model behind an API.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>This is one of the most dynamic and fascinating topics: API technologies for machine learning.</p>
<p>It's always fun to build ML models. But how about serving them in the real world? In this episode I speak about three must-know technologies to place your model behind an API.</p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nb2v3g/api-technologies-for-ml.mp3" length="41990496" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This is one of the most dynamic and fascinating topics: API technologies for machine learning.
It's always fun to build ML models. But how about serving them in the real world? In this episode I speak about three must-know technologies to place your model behind an API.
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:11</itunes:duration>
                <itunes:episode>141</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>You are the product (Ep. 140)</title>
        <itunes:title>You are the product (Ep. 140)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/you-are-the-product-ep-140/</link>
                    <comments>https://datascienceathome.podbean.com/e/you-are-the-product-ep-140/#comments</comments>        <pubDate>Mon, 22 Feb 2021 17:16:17 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/674281ec-b5ef-3fa8-90f8-0f29b1777e99</guid>
                                    <description><![CDATA[
In this episode I am with George Hosu from <a href='https://cerebralab.com'>Cerebralab</a>
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>

Links
<ul><li><a href='https://cerebralab.com'>https://cerebralab.com</a></li>
<li><a href='https://www.eugenewei.com/blog/2019/2/19/status-as-a-service'>https://www.eugenewei.com/blog/2019/2/19/status-as-a-service</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[
In this episode I am with George Hosu from <a href='https://cerebralab.com'>Cerebralab</a>
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p>If building software is your passion, youâ€™ll love <a href='https://podcasts.apple.com/us/podcast/thoughtworks-technology-podcast/id881136697'>ThoughtWorks Technology Podcast</a>. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.</p>
<p>Â </p>

Links
<ul><li><a href='https://cerebralab.com'>https://cerebralab.com</a></li>
<li><a href='https://www.eugenewei.com/blog/2019/2/19/status-as-a-service'>https://www.eugenewei.com/blog/2019/2/19/status-as-a-service</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cdfnkq/you-are-the-product.mp3" length="44456448" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
In this episode I am with George Hosu from Cerebralab
and we speak about how dangerous it is not to pay for the services you use, and as a consequence how dangerous it is letting an algorithm decide what you like or not.
Â 

Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
If building software is your passion, youâ€™ll love ThoughtWorks Technology Podcast. Itâ€™s a podcast for techies by techies. Their team of experienced technologists take a deep dive into a tech topic thatâ€™s piqued their interest â€” it could be how machine learning is being used in astrophysics or maybe how to succeed at continuous delivery.
Â 

Links
https://cerebralab.com
https://www.eugenewei.com/blog/2019/2/19/status-as-a-service
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>45:04</itunes:duration>
                <itunes:episode>140</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>How to reinvent banking and finance with data and technology (Ep. 139)</title>
        <itunes:title>How to reinvent banking and finance with data and technology (Ep. 139)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/reinventing-banking-and-finance-with-data-and-technologyep-139/</link>
                    <comments>https://datascienceathome.podbean.com/e/reinventing-banking-and-finance-with-data-and-technologyep-139/#comments</comments>        <pubDate>Mon, 15 Feb 2021 09:41:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/12ec619b-90e7-35c8-892e-2471c39d5e8f</guid>
                                    <description><![CDATA[<p> The financial system is changing. It is becoming more efficient and integrated with many more services making our life more... digital. Is the old banking system doomed to fail? Or will it just be disrupted by the smaller players of the fintech industry?
In this episode we answer some of these fundamental questions with <a href='https://www.linkedin.com/in/ACoAAAADGZ4BJVO0gXKQbal4khDvUwI5cofrZR8'>Alessandro E. Hatami</a> from <a href='https://www.pacemakers.io/'>Pacemakers</a>
</p>
<p>Subscribe to the <a href='https://datascienceathome.substack.com/'>Newsletter</a> and come chat with us on the official <a href='https://discord.com/invite/4UNKGf3'>Discord channel </a></p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p> The financial system is changing. It is becoming more efficient and integrated with many more services making our life more... digital. Is the old banking system doomed to fail? Or will it just be disrupted by the smaller players of the fintech industry?<br>
In this episode we answer some of these fundamental questions with <a href='https://www.linkedin.com/in/ACoAAAADGZ4BJVO0gXKQbal4khDvUwI5cofrZR8'>Alessandro E. Hatami</a> from <a href='https://www.pacemakers.io/'>Pacemakers</a><br>
</p>
<p>Subscribe to the <a href='https://datascienceathome.substack.com/'>Newsletter</a> and come chat with us on the official <a href='https://discord.com/invite/4UNKGf3'>Discord channel </a></p>
<p>Â </p>
Our Sponsors
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.<br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p>Â </p>
<p><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7xk4d3/reinventing-banking-and-finance.mp3" length="54913397" type="audio/mpeg"/>
        <itunes:summary><![CDATA[ The financial system is changing. It is becoming more efficient and integrated with many more services making our life more... digital. Is the old banking system doomed to fail? Or will it just be disrupted by the smaller players of the fintech industry?In this episode we answer some of these fundamental questions with Alessandro E. Hatami from Pacemakers
Subscribe to the Newsletter and come chat with us on the official Discord channel 
Â 
Our Sponsors
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where masterâ€™s and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey.To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business. Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:47</itunes:duration>
                <itunes:episode>139</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What's up with WhatsApp? (Ep. 138)</title>
        <itunes:title>What's up with WhatsApp? (Ep. 138)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/whats-up-with-whatsapp-1612686479/</link>
                    <comments>https://datascienceathome.podbean.com/e/whats-up-with-whatsapp-1612686479/#comments</comments>        <pubDate>Sun, 07 Feb 2021 09:30:06 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/53713fbb-ebd0-395c-b213-702182eb3d1d</guid>
                                    <description><![CDATA[<p>Have you clicked the button? Accepted the new terms?</p>
<p>It's time we have a talk.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Have you clicked the button? Accepted the new terms?</p>
<p>It's time we have a talk.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uz8wjw/whatsapp-whatsup.mp3" length="48773535" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Have you clicked the button? Accepted the new terms?
It's time we have a talk.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:44</itunes:duration>
                <itunes:episode>138</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Is Rust flexible enough for a flexible data model? (Ep. 137)</title>
        <itunes:title>Is Rust flexible enough for a flexible data model? (Ep. 137)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/is-rust-flexible-enough-for-a-flexible-data-model-ep-137/</link>
                    <comments>https://datascienceathome.podbean.com/e/is-rust-flexible-enough-for-a-flexible-data-model-ep-137/#comments</comments>        <pubDate>Mon, 01 Feb 2021 08:54:33 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/458f222d-1777-36b4-bba2-aa28cca551f9</guid>
                                    <description><![CDATA[<p>In this podcast I get inspired by <a href='https://developer.mongodb.com/author/paul-done'>Paul Done</a>'s presentation about The Six Principles for Building Robust Yet Flexible Shared Data Applications, and show how powerful of a language Rust is while still maintaining the flexibility of less strict languages.
</p>
<p>Â </p>
Our Sponsor
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where master's and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey. 
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p style="margin-bottom:0in;line-height:100%;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this podcast I get inspired by <a href='https://developer.mongodb.com/author/paul-done'>Paul Done</a>'s presentation about The Six Principles for Building Robust Yet Flexible Shared Data Applications, and show how powerful of a language Rust is while still maintaining the flexibility of less strict languages.<br>
</p>
<p>Â </p>
Our Sponsor
<p>This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where master's and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey. <br>
To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit <a href='https://chapman.edu/datascience'>chapman.edu/datascience</a></p>
<p style="margin-bottom:0in;line-height:100%;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/rdmyav/data-agility-principles.mp3" length="45552735" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this podcast I get inspired by Paul Done's presentation about The Six Principles for Building Robust Yet Flexible Shared Data Applications, and show how powerful of a language Rust is while still maintaining the flexibility of less strict languages.
Â 
Our Sponsor
This episode is supported by Chapmanâ€™s Schmid College of Science and Technology, where master's and PhD students join in cutting-edge research as they prepare to take the next big leap in their professional journey. To learn more about the innovative tools and collaborative approach that distinguish the Chapman program in Computational and Data Sciences, visit chapman.edu/datascience
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:37</itunes:duration>
                <itunes:episode>137</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Is Apple M1 good for machine learning? (Ep.136)</title>
        <itunes:title>Is Apple M1 good for machine learning? (Ep.136)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/is-apple-m1-good-for-machine-learning-ep139/</link>
                    <comments>https://datascienceathome.podbean.com/e/is-apple-m1-good-for-machine-learning-ep139/#comments</comments>        <pubDate>Mon, 25 Jan 2021 18:10:42 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/903adf96-d3ad-391d-9b98-9edec7a39ba8</guid>
                                    <description><![CDATA[<p>In this episode I explain the basics of computer architecture and introduce some features of the Apple M1</p>
<p>Is it good for Machine Learning tasks?</p>
<p>Â </p>
References
<ul><li>Computer architectures book <a href='https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X'>https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X</a></li>
<li>Performance <a href='https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/'>https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I explain the basics of computer architecture and introduce some features of the Apple M1</p>
<p>Is it good for Machine Learning tasks?</p>
<p>Â </p>
References
<ul><li>Computer architectures book <a href='https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X'>https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X</a></li>
<li>Performance <a href='https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/'>https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gfsj8n/apple-m1-amx.mp3" length="47098090" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I explain the basics of computer architecture and introduce some features of the Apple M1
Is it good for Machine Learning tasks?
Â 
References
Computer architectures book https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X
Performance https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:21</itunes:duration>
                <itunes:episode>136</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust and deep learning with Daniel McKenna (Ep. 135)</title>
        <itunes:title>Rust and deep learning with Daniel McKenna (Ep. 135)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-and-deep-learning-with-daniel-mckenna-ep-135/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-and-deep-learning-with-daniel-mckenna-ep-135/#comments</comments>        <pubDate>Mon, 18 Jan 2021 09:25:05 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/938c40a0-7c2a-31d4-808e-da1b90b26b64</guid>
                                    <description><![CDATA[<p>In this episode I speak with Daniel McKenna about Rust, machine learning and artificial intelligence.</p>
<p>You can find Daniel from</p>
<ul><li><a href='http://github.com/xd009642'>http://github.com/xd009642</a>Â </li>
<li><a href='https://twitter.com/xd009642'>https://twitter.com/xd009642</a> 
</li>
</ul>
<p>Â </p>
<p>Don't forget to come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with Daniel McKenna about Rust, machine learning and artificial intelligence.</p>
<p>You can find Daniel from</p>
<ul><li><a href='http://github.com/xd009642'>http://github.com/xd009642</a>Â </li>
<li><a href='https://twitter.com/xd009642'>https://twitter.com/xd009642</a> <br>
</li>
</ul>
<p>Â </p>
<p>Don't forget to come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jnsvx3/rust-and-ml-daniel-mckenna.mp3" length="44135572" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Daniel McKenna about Rust, machine learning and artificial intelligence.
You can find Daniel from
http://github.com/xd009642Â 
https://twitter.com/xd009642 
Â 
Don't forget to come join me in our Discord channel speaking about all things data science.
Subscribe to the official NewsletterÂ and never miss an episode]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:59</itunes:duration>
                <itunes:episode>135</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Scaling machine learning with clusters and GPUs (Ep. 134)</title>
        <itunes:title>Scaling machine learning with clusters and GPUs (Ep. 134)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/scaling-machine-learning-with-clusters-and-gpus-ep-134/</link>
                    <comments>https://datascienceathome.podbean.com/e/scaling-machine-learning-with-clusters-and-gpus-ep-134/#comments</comments>        <pubDate>Thu, 31 Dec 2020 15:21:45 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/00b62bba-6560-33a6-911e-466037784685</guid>
                                    <description><![CDATA[<p>Let's finish this year with an amazing episode about scaling ML with clusters and GPUs. Kind of as a continuation of <a href='https://datascienceathome.com/what-data-transformation-library-should-i-use-pandas-vs-dask-vs-ray-vs-modin-vs-rapids-ep-112/'>Episode 112</a> I have a terrific conversation with Aaron Richter from Saturn Cloud about, well, making ML faster and scaling it to massive infrastructure.</p>
<p>Aaron can be reached on his website <a href='https://rikturr.com'>https://rikturr.com</a> and Twitter <a href='https://twitter.com/rikturr'>@rikturr</a></p>
<p>Â </p>
<p>Our Sponsor</p>
<p><a href='https://saturncloud.io'>Saturn Cloud</a> is a data science and machine learning platform for scalable Python analytics. Users can jump into cloud-based Jupyter and Dask to scale Python for big data using the libraries they know and love, while leveraging Docker and Kubernetes so that work is reproducible, shareable, and ready for production.</p>
<p>Try Saturn Cloud for free at <a href='https://saturncloud.io'>https://saturncloud.io</a>Â </p>
<p>Twitter: <a href='https://twitter.com/saturn_cloud'>@saturn_cloud</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Let's finish this year with an amazing episode about scaling ML with clusters and GPUs. Kind of as a continuation of <a href='https://datascienceathome.com/what-data-transformation-library-should-i-use-pandas-vs-dask-vs-ray-vs-modin-vs-rapids-ep-112/'>Episode 112</a> I have a terrific conversation with Aaron Richter from Saturn Cloud about, well, making ML faster and scaling it to massive infrastructure.</p>
<p>Aaron can be reached on his website <a href='https://rikturr.com'>https://rikturr.com</a> and Twitter <a href='https://twitter.com/rikturr'>@rikturr</a></p>
<p>Â </p>
<p>Our Sponsor</p>
<p><a href='https://saturncloud.io'>Saturn Cloud</a> is a data science and machine learning platform for scalable Python analytics. Users can jump into cloud-based Jupyter and Dask to scale Python for big data using the libraries they know and love, while leveraging Docker and Kubernetes so that work is reproducible, shareable, and ready for production.</p>
<p>Try Saturn Cloud for free at <a href='https://saturncloud.io'>https://saturncloud.io</a>Â </p>
<p>Twitter: <a href='https://twitter.com/saturn_cloud'>@saturn_cloud</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7kd3et/aaron-richter.mp3" length="59466316" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Let's finish this year with an amazing episode about scaling ML with clusters and GPUs. Kind of as a continuation of Episode 112 I have a terrific conversation with Aaron Richter from Saturn Cloud about, well, making ML faster and scaling it to massive infrastructure.
Aaron can be reached on his website https://rikturr.com and Twitter @rikturr
Â 
Our Sponsor
Saturn Cloud is a data science and machine learning platform for scalable Python analytics. Users can jump into cloud-based Jupyter and Dask to scale Python for big data using the libraries they know and love, while leveraging Docker and Kubernetes so that work is reproducible, shareable, and ready for production.
Try Saturn Cloud for free at https://saturncloud.ioÂ 
Twitter: @saturn_cloud
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:58</itunes:duration>
                <itunes:episode>134</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What is data ethics? (Ep. 133)</title>
        <itunes:title>What is data ethics? (Ep. 133)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-is-data-ethics-ep-133/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-is-data-ethics-ep-133/#comments</comments>        <pubDate>Sat, 19 Dec 2020 23:35:41 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c96e88bb-a0b8-3c81-9d2a-1c32240aa749</guid>
                                    <description><![CDATA[<p>What is data ethics? In this episode I have an interesting chat with Denny Wong from FaqBot and Muna.</p>
Â 
Our Sponsor
<a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
<ul><li style="max-width:100%;color:#111111;font-family:'Nylas-Pro', Helvetica, 'Lucidia Grande', sans-serif;font-size:14.5px;font-style:normal;font-weight:400;letter-spacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;"><a href='https://twitter.com/Dewotak'>Denny's Twitter profile</a></li>
<li style="max-width:100%;color:#111111;font-family:'Nylas-Pro', Helvetica, 'Lucidia Grande', sans-serif;font-size:14.5px;font-style:normal;font-weight:400;letter-spacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;">The data ethics awareness <a href='https://www.eventbrite.be/e/data-ethics-awareness-training-and-workshop-for-ai-practitioners-tickets-131588164743'>workshop</a> for AI practitioners</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>What is data ethics? In this episode I have an interesting chat with Denny Wong from FaqBot and Muna.</p>
Â 
Our Sponsor
<a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
<ul><li style="max-width:100%;color:#111111;font-family:'Nylas-Pro', Helvetica, 'Lucidia Grande', sans-serif;font-size:14.5px;font-style:normal;font-weight:400;letter-spacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;"><a href='https://twitter.com/Dewotak'>Denny's Twitter profile</a></li>
<li style="max-width:100%;color:#111111;font-family:'Nylas-Pro', Helvetica, 'Lucidia Grande', sans-serif;font-size:14.5px;font-style:normal;font-weight:400;letter-spacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;">The data ethics awareness <a href='https://www.eventbrite.be/e/data-ethics-awareness-training-and-workshop-for-ai-practitioners-tickets-131588164743'>workshop</a> for AI practitioners</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/mtu22k/denny-data-ethics.mp3" length="49165293" type="audio/mpeg"/>
        <itunes:summary><![CDATA[What is data ethics? In this episode I have an interesting chat with Denny Wong from FaqBot and Muna.
Â 
Our Sponsor
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
Denny's Twitter profile
The data ethics awareness workshop for AI practitioners
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>25:36</itunes:duration>
                <itunes:episode>133</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>A Standard for the Python Array API (Ep. 132)</title>
        <itunes:title>A Standard for the Python Array API (Ep. 132)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/a-standard-for-the-python-array-api-ep-132/</link>
                    <comments>https://datascienceathome.podbean.com/e/a-standard-for-the-python-array-api-ep-132/#comments</comments>        <pubDate>Tue, 08 Dec 2020 09:10:01 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/4260dd1f-581a-3413-b54e-007dea990e4c</guid>
                                    <description><![CDATA[Our Links
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
References
<ol><li style="font-weight:400;"><a href='https://data-apis.org/blog/announcing_the_consortium'>https://data-apis.org/blog/announcing_the_consortium</a></li>
<li style="font-weight:400;"><a href='https://data-apis.github.io/array-api/latest/'>https://data-apis.github.io/array-api/latest/</a></li>
<li style="font-weight:400;"><a href='https://github.com/data-apis/python-record-api'>https://github.com/data-apis/python-record-api</a></li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[Our Links
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
References
<ol><li style="font-weight:400;"><a href='https://data-apis.org/blog/announcing_the_consortium'>https://data-apis.org/blog/announcing_the_consortium</a></li>
<li style="font-weight:400;"><a href='https://data-apis.github.io/array-api/latest/'>https://data-apis.github.io/array-api/latest/</a></li>
<li style="font-weight:400;"><a href='https://github.com/data-apis/python-record-api'>https://github.com/data-apis/python-record-api</a></li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gmauu4/python-array-api-standard.mp3" length="55286565" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Links
Come join me in our Discord channel speaking about all things data science.
Subscribe to the official NewsletterÂ and never miss an episode
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
ProtonMail offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
References
https://data-apis.org/blog/announcing_the_consortium
https://data-apis.github.io/array-api/latest/
https://github.com/data-apis/python-record-api
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>33:40</itunes:duration>
                <itunes:episode>132</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What happens to data transfer after Schrems II? (Ep. 131)</title>
        <itunes:title>What happens to data transfer after Schrems II? (Ep. 131)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-happens-to-data-transfer-after-schrems-ii/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-happens-to-data-transfer-after-schrems-ii/#comments</comments>        <pubDate>Fri, 04 Dec 2020 08:00:09 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c8e127f9-1966-3f2c-934d-86964763ce41</guid>
                                    <description><![CDATA[<p>In this episode Adam Leon Smith, CTO of DragonFly and expert in data regulations explains some of the consequences of Schrems II and data transfers from EU to US.</p>
<p>Â </p>
<p>For very interesting references and a practical example, subscribe to our <a href='https://datascienceathome.substack.com/'>Newsletter</a></p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode Adam Leon Smith, CTO of DragonFly and expert in data regulations explains some of the consequences of Schrems II and data transfers from EU to US.</p>
<p>Â </p>
<p>For very interesting references and a practical example, subscribe to our <a href='https://datascienceathome.substack.com/'>Newsletter</a></p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tts332/schrems2-regulation.mp3" length="61283602" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode Adam Leon Smith, CTO of DragonFly and expert in data regulations explains some of the consequences of Schrems II and data transfers from EU to US.
Â 
For very interesting references and a practical example, subscribe to our Newsletter
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:54</itunes:duration>
                <itunes:episode>131</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Test-First Machine Learning [RB] (Ep. 130)</title>
        <itunes:title>Test-First Machine Learning [RB] (Ep. 130)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/test-first-machine-learning-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/test-first-machine-learning-rb/#comments</comments>        <pubDate>Tue, 01 Dec 2020 11:48:21 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/ede11173-5182-3243-8878-d3c4edd99467</guid>
                                    <description><![CDATA[Our Links
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Â 
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[Our Links
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Â 
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/646zv6/test-first-machine-learningRB.mp3" length="35419938" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Our Links
Come join me in our Discord channel speaking about all things data science.
Subscribe to the official NewsletterÂ and never miss an episode
Follow me on Twitch during my live coding sessions usually in Rust and Python
Â 
Our Sponsors
ProtonMail offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:51</itunes:duration>
                <itunes:episode>130</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Similarity in Machine Learning (Ep. 129)</title>
        <itunes:title>Similarity in Machine Learning (Ep. 129)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/similarity-in-machine-learning-ep-129/</link>
                    <comments>https://datascienceathome.podbean.com/e/similarity-in-machine-learning-ep-129/#comments</comments>        <pubDate>Tue, 24 Nov 2020 09:40:37 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7f5d004f-280e-3de6-9a5c-1acdc20d2218</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPN's apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>Subscribe to the official <a href='https://datascienceathome.substack.com/'>Newsletter</a>Â and never miss an episode</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPN's apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/j5nksu/similarity-ml-episode.mp3" length="50466771" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Subscribe to the official NewsletterÂ and never miss an episode
Our Sponsors
ProtonMail offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonMail and ProtonVPN's apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the worldâ€™s strongest privacy laws
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:19</itunes:duration>
                <itunes:episode>129</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Distill data and train faster, better, cheaper (Ep. 128)</title>
        <itunes:title>Distill data and train faster, better, cheaper (Ep. 128)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/distill-data-and-train-faster-better-cheaper-ep-128/</link>
                    <comments>https://datascienceathome.podbean.com/e/distill-data-and-train-faster-better-cheaper-ep-128/#comments</comments>        <pubDate>Tue, 17 Nov 2020 10:12:12 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/fbc3782d-92f5-3b1b-8e00-15834ca85e1b</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
Â 
References
<p><a href='https://arxiv.org/pdf/2009.08449.pdf'>Dataset distillation (official paper) </a></p>
<p><a href='https://github.com/SsnL/dataset-distillation/'>GitHub repo 
</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
Â 
References
<p><a href='https://arxiv.org/pdf/2009.08449.pdf'>Dataset distillation (official paper) </a></p>
<p><a href='https://github.com/SsnL/dataset-distillation/'>GitHub repo <br>
</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6ykyv9/dataset-distillation.mp3" length="39106076" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
Dataset distillation (official paper) 
GitHub repo 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:46</itunes:duration>
                <itunes:episode>128</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Machine Learning in Rust: Amadeus with Alec Mocatta [RB] (ep. 127)</title>
        <itunes:title>Machine Learning in Rust: Amadeus with Alec Mocatta [RB] (ep. 127)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/machine-learning-in-rust-amadeus-with-alec-mocatta-rb-ep-127/</link>
                    <comments>https://datascienceathome.podbean.com/e/machine-learning-in-rust-amadeus-with-alec-mocatta-rb-ep-127/#comments</comments>        <pubDate>Wed, 11 Nov 2020 08:27:33 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/503012b2-a0de-3c90-8bbb-0576d9fd694a</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonvpn.com/datascience'>ProtonVPN</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the world's strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonvpn.com/datascience'>ProtonVPN</a> offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the world's strongest privacy laws</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2kpqe6/RB-rust-ml-mocatta.mp3" length="38362286" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
ProtonVPN offers a simple and trusted solution to protect your internet connection and access blocked or restricted websites. All of ProtonVPNâ€™s apps are open source and have been inspected by cybersecurity experts, and Proton is based in Switzerland, home to some of the world's strongest privacy laws
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:19</itunes:duration>
                <itunes:episode>127</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Top-3 ways to put machine learning models into production (Ep. 126)</title>
        <itunes:title>Top-3 ways to put machine learning models into production (Ep. 126)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/top-3-ways-to-put-machine-learning-models-into-production-ep-126/</link>
                    <comments>https://datascienceathome.podbean.com/e/top-3-ways-to-put-machine-learning-models-into-production-ep-126/#comments</comments>        <pubDate>Sat, 07 Nov 2020 10:26:14 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/499e4c64-e4e2-3522-9521-23f5546a2169</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='http://physicspodcast.com'>physicspodcast.com</a> is not just a physics podcast. But also interviews with scientists, scholars, authors and reflections on the history and future of science and technology are all in the wheelhouse.</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='http://physicspodcast.com'>physicspodcast.com</a> is not just a physics podcast. But also interviews with scientists, scholars, authors and reflections on the history and future of science and technology are all in the wheelhouse.</li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/mftc2t/ml-prod-3-methods.mp3" length="30082362" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
physicspodcast.com is not just a physics podcast. But also interviews with scientists, scholars, authors and reflections on the history and future of science and technology are all in the wheelhouse.
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:27</itunes:duration>
                <itunes:episode>126</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Remove noise from data with deep learning (Ep.125)</title>
        <itunes:title>Remove noise from data with deep learning (Ep.125)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/remove-noise-from-data-with-deep-learning-ep125/</link>
                    <comments>https://datascienceathome.podbean.com/e/remove-noise-from-data-with-deep-learning-ep125/#comments</comments>        <pubDate>Tue, 03 Nov 2020 08:25:45 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3606fd00-cad0-36a0-9274-829918052321</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> is a secure and private email provider that protects yourmessages with end-to-end encryption and zero-access encryption so that besides you, noone can access them. </li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.

</li>
</ul>
References
<ul><li><a href='https://github.com/AllenInstitute/deepinterpolation'>DeepInterpolation </a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
Our Sponsors
<ul><li><a href='https://protonmail.com/datascience'>ProtonMail</a> is a secure and private email provider that protects yourmessages with end-to-end encryption and zero-access encryption so that besides you, noone can access them. </li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.<br>
<br>
</li>
</ul>
References
<ul><li><a href='https://github.com/AllenInstitute/deepinterpolation'>DeepInterpolation </a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/a7k54j/data-denoising-full.mp3" length="42557279" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
ProtonMail is a secure and private email provider that protects yourmessages with end-to-end encryption and zero-access encryption so that besides you, noone can access them. 
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
References
DeepInterpolation 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:59</itunes:duration>
                <itunes:episode>125</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What is contrastive learning and why it is so powerful? (Ep. 124)</title>
        <itunes:title>What is contrastive learning and why it is so powerful? (Ep. 124)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-is-contrastive-learning-and-why-it-is-so-powerful-ep-124/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-is-contrastive-learning-and-why-it-is-so-powerful-ep-124/#comments</comments>        <pubDate>Fri, 30 Oct 2020 18:48:03 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/373a0fd1-dc2c-3303-bbb3-a450dee7c7ec</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>

Our Sponsors
<ul><li>The <a href='https://monday.com/datascience'>Monday</a> Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a></li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/2002.05709'>A Simple Framework for Contrastive Learning of Visual Representations</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<br>
Our Sponsors
<ul><li>The <a href='https://monday.com/datascience'>Monday</a> Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a></li>
<li><a href='https://amethix.com'>Amethix</a> use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.</li>
</ul>
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/2002.05709'>A Simple Framework for Contrastive Learning of Visual Representations</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pm8whe/sim_CLR_contrastive_learning.mp3" length="44519226" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Our Sponsors
The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on monday.com
Amethix use advanced Artificial Intelligence and Machine Learning to build data platforms and predictive engines in domain like finance, healthcare, pharmaceuticals, logistics, energy. Amethix provide solutions to collect and secure data with higher transparency and disintermediation, and build the statistical models that will support your business.
Â 
References
A Simple Framework for Contrastive Learning of Visual Representations
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:12</itunes:duration>
                <itunes:episode>124</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Neural search (Ep. 123)</title>
        <itunes:title>Neural search (Ep. 123)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/neural-search-ep-123/</link>
                    <comments>https://datascienceathome.podbean.com/e/neural-search-ep-123/#comments</comments>        <pubDate>Fri, 23 Oct 2020 06:06:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/b41f8304-c2bf-3e70-a103-e8de5294f2a6</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wbqd86/neural-search.mp3" length="32688607" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
This episode is supported by Monday.com
The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on monday.com.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:18</itunes:duration>
                <itunes:episode>123</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Let's talk about federated learning (Ep. 122)</title>
        <itunes:title>Let's talk about federated learning (Ep. 122)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/lets-talk-about-federated-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/lets-talk-about-federated-learning/#comments</comments>        <pubDate>Sun, 18 Oct 2020 14:20:11 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/865278b5-3d7c-3fb7-ad86-d65bb88840bf</guid>
                                    <description><![CDATA[<p>Let's talk about federated learning. Why is it important? Why large organizations are not ready yet?</p>
<p>Â </p>
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Let's talk about federated learning. Why is it important? Why large organizations are not ready yet?</p>
<p>Â </p>
<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pxsjia/federated-learning.mp3" length="45292948" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Let's talk about federated learning. Why is it important? Why large organizations are not ready yet?
Â 
Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
This episode is supported by Monday.com
The Monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on monday.com.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:10</itunes:duration>
                <itunes:episode>122</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>How to test machine learning in production (Ep. 121)</title>
        <itunes:title>How to test machine learning in production (Ep. 121)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-to-test-machine-learning-in-production-ep-121/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-to-test-machine-learning-in-production-ep-121/#comments</comments>        <pubDate>Sun, 11 Oct 2020 10:52:58 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f2be866e-64cc-353d-a9b6-432dcaaf010f</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>Â </p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>Monday.com bring teams together so you can plan, manage and track everything your team is working on in one centralized place</p>
<p>The monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>Â </p>
<p>This episode is supported by <a href='https://monday.com/datascience'>Monday.com</a></p>
<p>Monday.com bring teams together so you can plan, manage and track everything your team is working on in one centralized place</p>
<p>The monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on <a href='https://monday.com/datascience'>monday.com</a>.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ugukqe/testing-ml-in-production.mp3" length="47908360" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
Â 
This episode is supported by Monday.com
Monday.com bring teams together so you can plan, manage and track everything your team is working on in one centralized place
The monday Apps Challenge is bringing developers around the world together to compete in order to build apps that can improve the way teams work together on monday.com.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:48</itunes:duration>
                <itunes:episode>121</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Why synthetic data cannot boost machine learning (Ep. 120)</title>
        <itunes:title>Why synthetic data cannot boost machine learning (Ep. 120)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/why-synthetic-data-cannot-boost-machine-learning-ep-120/</link>
                    <comments>https://datascienceathome.podbean.com/e/why-synthetic-data-cannot-boost-machine-learning-ep-120/#comments</comments>        <pubDate>Sat, 26 Sep 2020 13:57:08 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3448f238-a8d3-3773-8a5e-d50e5ebf8add</guid>
                                    <description><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://freecontent.manning.com/livemanning-conferences-women-in-tech/?utm_source=push&utm_medium=organic&utm_campaign=rust_datasci_at_home'>Women in Tech</a> by Manning Conferences</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Come join me in our <a href='https://discord.gg/4UNKGf3'>Discord</a> channel speaking about all things data science.</p>
<p>Follow me on <a href='https://www.twitch.tv/codingossip'>Twitch</a> during my live coding sessions usually in Rust and Python</p>
<p>This episode is supported by <a href='https://freecontent.manning.com/livemanning-conferences-women-in-tech/?utm_source=push&utm_medium=organic&utm_campaign=rust_datasci_at_home'>Women in Tech</a> by Manning Conferences</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/qdxpn6/synthetic-data-to-boost-machine-learning.mp3" length="39599030" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Come join me in our Discord channel speaking about all things data science.
Follow me on Twitch during my live coding sessions usually in Rust and Python
This episode is supported by Women in Tech by Manning Conferences]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:23</itunes:duration>
                <itunes:episode>120</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Machine learning in production: best practices [LIVE from twitch.tv] (Ep. 119)</title>
        <itunes:title>Machine learning in production: best practices [LIVE from twitch.tv] (Ep. 119)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/machine-learning-in-production-best-practices-live-from-twitchtv/</link>
                    <comments>https://datascienceathome.podbean.com/e/machine-learning-in-production-best-practices-live-from-twitchtv/#comments</comments>        <pubDate>Wed, 16 Sep 2020 12:32:39 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/48dad95d-473f-3347-8b13-3f863ed71d95</guid>
                                    <description><![CDATA[<p>Hey there! Having the best time of my life ;)</p>
<p>This is the first episode I record while I am live on my new <a href='https://www.twitch.tv/codingossip'>Twitch channel</a> :) So much fun!</p>
<p>Feel free to follow me for the next live streaming. You can also see me coding machine learning stuff in Rust :)) </p>
<p>Don't forget to jump on the usual <a href='https://discord.gg/4UNKGf3'>Discord</a> and have a chat</p>
<p>I'll see you there!</p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Hey there! Having the best time of my life ;)</p>
<p>This is the first episode I record while I am live on my new <a href='https://www.twitch.tv/codingossip'>Twitch channel</a> :) So much fun!</p>
<p>Feel free to follow me for the next live streaming. You can also see me coding machine learning stuff in Rust :)) </p>
<p>Don't forget to jump on the usual <a href='https://discord.gg/4UNKGf3'>Discord</a> and have a chat</p>
<p>I'll see you there!</p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ngu7gk/machine-learning-in-production.mp3" length="60003558" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Hey there! Having the best time of my life ;)
This is the first episode I record while I am live on my new Twitch channel :) So much fun!
Feel free to follow me for the next live streaming. You can also see me coding machine learning stuff in Rust :)) 
Don't forget to jump on the usual Discord and have a chat
I'll see you there!
Â 
Â 
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:31</itunes:duration>
                <itunes:episode>119</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Testing in machine learning: checking deeplearning models (Ep. 118)</title>
        <itunes:title>Testing in machine learning: checking deeplearning models (Ep. 118)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/testing-in-machine-learning-check-deeplearning-models-ep-118/</link>
                    <comments>https://datascienceathome.podbean.com/e/testing-in-machine-learning-check-deeplearning-models-ep-118/#comments</comments>        <pubDate>Fri, 04 Sep 2020 13:11:32 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7799b35c-9fee-33b5-85d6-cc3f95ec1612</guid>
                                    <description><![CDATA[<p>In this episode I speak with <a href='https://i.disc0tech.com/'>Adam Leon Smith</a>, CTO at DragonFly and expert in testing strategies for software and machine learning.
We cover testing with deep learning (neuron coverage, threshold coverage, sign change coverage, layer coverage, etc.), combinatorial testing and their practical aspects.</p>
<p>On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.
If you want to meet the tribe, tune in september 15th to the <a href='http://mng.bz/lXJ8'>live@manning</a> rust conference.</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with <a href='https://i.disc0tech.com/'>Adam Leon Smith</a>, CTO at DragonFly and expert in testing strategies for software and machine learning.<br>
We cover testing with deep learning (neuron coverage, threshold coverage, sign change coverage, layer coverage, etc.), combinatorial testing and their practical aspects.</p>
<p>On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.<br>
If you want to meet the tribe, tune in september 15th to the <a href='http://mng.bz/lXJ8'>live@manning</a> rust conference.</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/hdsg95/testing-machine-learning-ep3.mp3" length="29656849" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Adam Leon Smith, CTO at DragonFly and expert in testing strategies for software and machine learning.We cover testing with deep learning (neuron coverage, threshold coverage, sign change coverage, layer coverage, etc.), combinatorial testing and their practical aspects.
On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.If you want to meet the tribe, tune in september 15th to the live@manning rust conference.
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:17</itunes:duration>
                <itunes:episode>118</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Testing in machine learning: generating tests and data (Ep. 117)</title>
        <itunes:title>Testing in machine learning: generating tests and data (Ep. 117)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/testing-in-machine-learning-generating-tests-and-data-ep-117/</link>
                    <comments>https://datascienceathome.podbean.com/e/testing-in-machine-learning-generating-tests-and-data-ep-117/#comments</comments>        <pubDate>Sat, 29 Aug 2020 16:57:57 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/240ceffa-16bf-31f5-ac09-89458ecf04a5</guid>
                                    <description><![CDATA[<p>In this episode I speak with <a href='https://i.disc0tech.com/'>Adam Leon Smith</a>, CTO at DragonFly and expert in testing strategies for software and machine learning.</p>
<p>Â </p>
<p>On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.
If you want to meet the tribe, tune in september 15th to the <a href='http://mng.bz/lXJ8'>live@manning</a> rust conference.</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with <a href='https://i.disc0tech.com/'>Adam Leon Smith</a>, CTO at DragonFly and expert in testing strategies for software and machine learning.</p>
<p>Â </p>
<p>On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.<br>
If you want to meet the tribe, tune in september 15th to the <a href='http://mng.bz/lXJ8'>live@manning</a> rust conference.</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/i5p9d3/testing-machine-learning-ep2.mp3" length="34465314" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Adam Leon Smith, CTO at DragonFly and expert in testing strategies for software and machine learning.
Â 
On September 15th there will be a live@Manning Rust conference. In one Rust-full day you will attend many talks about what's special about rust, building high performance web services or video game, about web assembly and much more.If you want to meet the tribe, tune in september 15th to the live@manning rust conference.
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:18</itunes:duration>
                <itunes:episode>117</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Why you care about homomorphic encryption (Ep. 116)</title>
        <itunes:title>Why you care about homomorphic encryption (Ep. 116)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/why-you-care-about-homomorphic-encryption-ep-116/</link>
                    <comments>https://datascienceathome.podbean.com/e/why-you-care-about-homomorphic-encryption-ep-116/#comments</comments>        <pubDate>Wed, 12 Aug 2020 07:13:12 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/adb71ed2-a364-3142-947c-d1cb32a9a924</guid>
                                    <description><![CDATA[<p>After deep learning, a new entry is about ready to go on stage. The usual journalists are warming up their keyboards for blogs, news feeds, tweets, in one word, hype.
This time it's all about privacy and data confidentiality. The new words, homomorphic encryption.</p>
<p>Â </p>
<p>Join and chat with us on the official <a href='https://discord.gg/4UNKGf3'>Discord</a> channel.</p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>
<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
<p>Â </p>
References
<p>
<a href='https://eprint.iacr.org/2019/1113'>Towards a Homomorphic Machine Learning Big Data Pipeline for the Financial Services Sector</a></p>
<p><a href='https://github.com/IBM/fhe-toolkit-linux'>IBM Fully Homomorphic Encryption Toolkit for Linux</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>After deep learning, a new entry is about ready to go on stage. The usual journalists are warming up their keyboards for blogs, news feeds, tweets, in one word, hype.<br>
This time it's all about privacy and data confidentiality. The new words, <em>homomorphic encryption</em>.</p>
<p>Â </p>
<p>Join and chat with us on the official <a href='https://discord.gg/4UNKGf3'>Discord</a> channel.</p>
<p>Â </p>
Sponsors
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>
<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
<p>Â </p>
References
<p><br>
<a href='https://eprint.iacr.org/2019/1113'>Towards a Homomorphic Machine Learning Big Data Pipeline for the Financial Services Sector</a></p>
<p><a href='https://github.com/IBM/fhe-toolkit-linux'>IBM Fully Homomorphic Encryption Toolkit for Linux</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/phzh4n/machine-learning-homomorphic-encryption.mp3" length="31434345" type="audio/mpeg"/>
        <itunes:summary><![CDATA[After deep learning, a new entry is about ready to go on stage. The usual journalists are warming up their keyboards for blogs, news feeds, tweets, in one word, hype.This time it's all about privacy and data confidentiality. The new words, homomorphic encryption.
Â 
Join and chat with us on the official Discord channel.
Â 
Sponsors
This episode is supported by Amethix Technologies.
Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.
Â 
References
Towards a Homomorphic Machine Learning Big Data Pipeline for the Financial Services Sector
IBM Fully Homomorphic Encryption Toolkit for Linux]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:50</itunes:duration>
                <itunes:episode>116</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Test-First machine learning (Ep. 115)</title>
        <itunes:title>Test-First machine learning (Ep. 115)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/test-first-machine-learning-ep-115/</link>
                    <comments>https://datascienceathome.podbean.com/e/test-first-machine-learning-ep-115/#comments</comments>        <pubDate>Mon, 03 Aug 2020 16:16:40 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c2a654fc-4961-3968-a3c6-bf83629fa021</guid>
                                    <description><![CDATA[<p>In this episode I speak about a testing methodology for machine learning models that are supposed to be integrated in production environments. </p>
<p>Don't forget to come chat with us in our <a href='https://discord.gg/4UNKGf3'>Discord channel</a></p>
<p>Â </p>
<p>Enjoy the show!</p>
<p>Â </p>
<p>--</p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>
<p>Â </p>
<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about a testing methodology for machine learning models that are supposed to be integrated in production environments. </p>
<p>Don't forget to come chat with us in our <a href='https://discord.gg/4UNKGf3'>Discord channel</a></p>
<p>Â </p>
<p>Enjoy the show!</p>
<p>Â </p>
<p>--</p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>
<p>Â </p>
<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/sxj54v/test-first-machine-learning.mp3" length="33268998" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about a testing methodology for machine learning models that are supposed to be integrated in production environments. 
Don't forget to come chat with us in our Discord channel
Â 
Enjoy the show!
Â 
--
This episode is supported by Amethix Technologies.
Â 
Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:44</itunes:duration>
                <itunes:episode>112</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>GPT-3 cannot code (and never will) (Ep. 114)</title>
        <itunes:title>GPT-3 cannot code (and never will) (Ep. 114)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/gpt-3-sucks-at-coding/</link>
                    <comments>https://datascienceathome.podbean.com/e/gpt-3-sucks-at-coding/#comments</comments>        <pubDate>Sun, 26 Jul 2020 12:55:50 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/edc01aa7-2f82-3d28-a962-106a1e2ae8b0</guid>
                                    <description><![CDATA[<p>The hype around GPT-3 is alarming and gives and provides us with the awful picture of people misunderstanding artificial intelligence. In response to some comments that claim GPT-3 will take developers' jobs, in this episode I express some personal opinions about the state of AI in generating source code (and in particular GPT-3).</p>
<p>Â </p>
<p>If you have comments about this episode or just want to chat, come join us on the official <a href='https://discord.gg/4UNKGf3'>Discord channel</a>.</p>
<p>Â </p>
<p>Â </p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>



<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>


]]></description>
                                                            <content:encoded><![CDATA[<p>The hype around GPT-3 is alarming and gives and provides us with the awful picture of people misunderstanding artificial intelligence. In response to some comments that claim GPT-3 will take developers' jobs, in this episode I express some personal opinions about the state of AI in generating source code (and in particular GPT-3).</p>
<p>Â </p>
<p>If you have comments about this episode or just want to chat, come join us on the official <a href='https://discord.gg/4UNKGf3'>Discord channel</a>.</p>
<p>Â </p>
<p>Â </p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a>.</p>



<p>Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.</p>


]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/dbcmck/gpt-3-personal-opinion.mp3" length="32271131" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The hype around GPT-3 is alarming and gives and provides us with the awful picture of people misunderstanding artificial intelligence. In response to some comments that claim GPT-3 will take developers' jobs, in this episode I express some personal opinions about the state of AI in generating source code (and in particular GPT-3).
Â 
If you have comments about this episode or just want to chat, come join us on the official Discord channel.
Â 
Â 
This episode is supported by Amethix Technologies.



Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. They are a consulting firm focused on data science, machine learning, and artificial intelligence.


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:06</itunes:duration>
                <itunes:episode>111</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Make Stochastic Gradient Descent Fast Again (Ep. 113)</title>
        <itunes:title>Make Stochastic Gradient Descent Fast Again (Ep. 113)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/make-stochastic-gradient-descent-fast-again-ep-113/</link>
                    <comments>https://datascienceathome.podbean.com/e/make-stochastic-gradient-descent-fast-again-ep-113/#comments</comments>        <pubDate>Wed, 22 Jul 2020 10:53:18 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/8a8b3454-adf7-3068-b6ab-a6b15e8b9971</guid>
                                    <description><![CDATA[<p>There is definitely room for improvement in the family of algorithms of stochastic gradient descent. In this episode I explain a relatively simple method that has shown to improve on the Adam optimizer. But, watch out! This approach does not generalize well.</p>
<p>Join our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> and chat with us.</p>
<p>Â </p>
References
<ul><li><a href='https://koaning.io/posts/more-descent-less-gradient/'>More descent, less gradient</a></li>
<li><a href='https://en.wikipedia.org/wiki/Taylor_series'>Taylor Series</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>There is definitely room for improvement in the family of algorithms of stochastic gradient descent. In this episode I explain a relatively simple method that has shown to improve on the Adam optimizer. But, watch out! This approach does not generalize well.</p>
<p>Join our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> and chat with us.</p>
<p>Â </p>
References
<ul><li><a href='https://koaning.io/posts/more-descent-less-gradient/'>More descent, less gradient</a></li>
<li><a href='https://en.wikipedia.org/wiki/Taylor_series'>Taylor Series</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/y2rdc7/more-descent-less-gradient.mp3" length="35826527" type="audio/mpeg"/>
        <itunes:summary><![CDATA[There is definitely room for improvement in the family of algorithms of stochastic gradient descent. In this episode I explain a relatively simple method that has shown to improve on the Adam optimizer. But, watch out! This approach does not generalize well.
Join our Discord channel and chat with us.
Â 
References
More descent, less gradient
Taylor Series
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:35</itunes:duration>
                <itunes:episode>110</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>What data transformation library should I use? Pandas vs Dask vs Ray vs Modin vs Rapids (Ep. 112)</title>
        <itunes:title>What data transformation library should I use? Pandas vs Dask vs Ray vs Modin vs Rapids (Ep. 112)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/a-comparison-of-data-transformation-frameworks-pandas-vs-dask-vs-ray-vs-modin-vs-rapids-ep-112/</link>
                    <comments>https://datascienceathome.podbean.com/e/a-comparison-of-data-transformation-frameworks-pandas-vs-dask-vs-ray-vs-modin-vs-rapids-ep-112/#comments</comments>        <pubDate>Sun, 19 Jul 2020 12:30:56 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c35d4a50-cc37-5b79-a9fe-e250e796b7a8</guid>
                                    <description><![CDATA[<p>In this episode I speak about data transformation frameworks available for the data scientist who writes Python code. 
The usual suspect is clearly Pandas, as the most widely used library and de-facto standard. However when data volumes increase and distributed algorithms are in place (according to a map-reduce paradigm of computation), Pandas no longer performs as expected. Other frameworks play a role in such context.Â </p>
<p>In this episode I explain the frameworks that are the best equivalent to Pandas in bigdata contexts.</p>
<p>Don't forget to join our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> and comment previous episodes or propose new ones.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a></p>



<p><a href='https://amethix.com'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. Amethix is a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
<p>Â </p>



References
<ul><li>
<p> Pandas a fast, powerful, flexible and easy to use open source data analysis and manipulation tool - <a href='https://pandas.pydata.org/'>https://pandas.pydata.org/</a></p>
</li>
<li>
<p>Modin - Scale your pandas workflows by changing one line of code - <a href='https://github.com/modin-project/modin'>https://github.com/modin-project/modin</a></p>
</li>
<li class="lead">
<p>Dask advanced parallelism for analytics <a href='https://dask.org/'>https://dask.org/</a></p>
</li>
<li>
<p>Ray is a fast and simple framework for building and running distributed applications <a href='https://github.com/ray-project/ray'>https://github.com/ray-project/ray</a></p>
</li>
<li>
<p>RAPIDS - GPU data science <a href='https://rapids.ai/'>https://rapids.ai/</a></p>
</li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about data transformation frameworks available for the data scientist who writes Python code. <br>
The usual suspect is clearly Pandas, as the most widely used library and de-facto standard. However when data volumes increase and distributed algorithms are in place (according to a map-reduce paradigm of computation), Pandas no longer performs as expected. Other frameworks play a role in such context.Â </p>
<p>In this episode I explain the frameworks that are the best equivalent to Pandas in bigdata contexts.</p>
<p>Don't forget to join our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> and comment previous episodes or propose new ones.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://amethix.com'>Amethix Technologies</a></p>



<p><a href='https://amethix.com'>Amethix</a> works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. Amethix is a consulting firm focused on data science, machine learning, and artificial intelligence.</p>
<p>Â </p>



References
<ul><li>
<p> Pandas a fast, powerful, flexible and easy to use open source data analysis and manipulation tool - <a href='https://pandas.pydata.org/'>https://pandas.pydata.org/</a></p>
</li>
<li>
<p>Modin - Scale your pandas workflows by changing one line of code - <a href='https://github.com/modin-project/modin'>https://github.com/modin-project/modin</a></p>
</li>
<li class="lead">
<p>Dask advanced parallelism for analytics <a href='https://dask.org/'>https://dask.org/</a></p>
</li>
<li>
<p>Ray is a fast and simple framework for building and running distributed applications <a href='https://github.com/ray-project/ray'>https://github.com/ray-project/ray</a></p>
</li>
<li>
<p>RAPIDS - GPU data science <a href='https://rapids.ai/'>https://rapids.ai/</a></p>
</li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8msppe/pandas-dask-ray-modin.mp3" length="36890627" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about data transformation frameworks available for the data scientist who writes Python code. The usual suspect is clearly Pandas, as the most widely used library and de-facto standard. However when data volumes increase and distributed algorithms are in place (according to a map-reduce paradigm of computation), Pandas no longer performs as expected. Other frameworks play a role in such context.Â 
In this episode I explain the frameworks that are the best equivalent to Pandas in bigdata contexts.
Don't forget to join our Discord channel and comment previous episodes or propose new ones.
Â 
This episode is supported by Amethix Technologies



Amethix works to create and maximize the impact of the worldâ€™s leading corporations, startups, and nonprofits, so they can create a better future for everyone they serve. Amethix is a consulting firm focused on data science, machine learning, and artificial intelligence.
Â 



References

 Pandas a fast, powerful, flexible and easy to use open source data analysis and manipulation tool - https://pandas.pydata.org/


Modin - Scale your pandas workflows by changing one line of code - https://github.com/modin-project/modin


Dask advanced parallelism for analytics https://dask.org/


Ray is a fast and simple framework for building and running distributed applications https://github.com/ray-project/ray


RAPIDS - GPU data science https://rapids.ai/

]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:10</itunes:duration>
                <itunes:episode>109</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>[RB] Itâ€™s cold outside. Letâ€™s speak about AI winter (Ep. 111)</title>
        <itunes:title>[RB] Itâ€™s cold outside. Letâ€™s speak about AI winter (Ep. 111)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-it-s-cold-outside-let-s-speak-about-ai-winter-ep-111/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-it-s-cold-outside-let-s-speak-about-ai-winter-ep-111/#comments</comments>        <pubDate>Fri, 03 Jul 2020 14:18:27 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c1ee203f-abca-5fdc-a8c5-78fc552ca41b</guid>
                                    <description><![CDATA[<p>In this episode I speak with <a href='https://blog.piekniewski.info/2018/10/29/ai-winter-update/'>FilipÂ Piekniewski</a>Â about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.</p>
<p>Join us to our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> to discuss your favorite episode and propose new ones. </p>
<p>Â </p>
<p>This episode is brought to you by <a href='https://protonmail.com/datascience'>Protonmail </a></p>
<p style="margin-bottom:.11in;line-height:108%;">Click on the link in the description or go toÂ <a href='https://protonmail.com/datascience'>protonmail.com/datascience</a> and get 20% off their annual subscription.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak with <a href='https://blog.piekniewski.info/2018/10/29/ai-winter-update/'>FilipÂ Piekniewski</a>Â about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.</p>
<p>Join us to our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> to discuss your favorite episode and propose new ones. </p>
<p>Â </p>
<p>This episode is brought to you by <a href='https://protonmail.com/datascience'>Protonmail </a></p>
<p style="margin-bottom:.11in;line-height:108%;">Click on the link in the description or go toÂ <a href='https://protonmail.com/datascience'>protonmail.com/datascience</a> and get 20% off their annual subscription.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/85p26q/_RB_episode-filip-december-2019_66ne8.mp3" length="54827599" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with FilipÂ PiekniewskiÂ about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.
Join us to our Discord channel to discuss your favorite episode and propose new ones. 
Â 
This episode is brought to you by Protonmail 
Click on the link in the description or go toÂ protonmail.com/datascience and get 20% off their annual subscription.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:54</itunes:duration>
                <itunes:episode>108</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust and machine learning #4: practical tools (Ep. 110)</title>
        <itunes:title>Rust and machine learning #4: practical tools (Ep. 110)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-and-machine-learning-tools-for-production-ep-110/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-and-machine-learning-tools-for-production-ep-110/#comments</comments>        <pubDate>Mon, 29 Jun 2020 10:30:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/15a86964-5fba-548c-959d-06a4b27d1764</guid>
                                    <description><![CDATA[<p>In this episode I make a non exhaustive list of machine learning tools and frameworks, written in Rust. Not all of them are mature enough for production environments. I believe that community effort can change this very quickly.</p>
<p>To make a comparison with the Python ecosystem I will cover frameworks for linear algebra (numpy), dataframes (pandas), off-the-shelf machine learning (scikit-learn), deep learning (tensorflow) and reinforcement learning (openAI).</p>
<p>Rust is the language of the future.
Happy coding!Â </p>
Reference
<ol><li><a href='https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms'>BLAS linear algebra https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms</a></li>
<li><a href='https://github.com/nevi-me/rust-dataframe'>Rust dataframeÂ https://github.com/nevi-me/rust-dataframe</a></li>
<li><a href='https://github.com/maciejkula/rustlearn'>Rustlearn https://github.com/maciejkula/rustlearn</a></li>
<li><a href='https://github.com/AtheMathmo/rusty-machine'>Rusty machine https://github.com/AtheMathmo/rusty-machine</a></li>
<li><a href='https://lib.rs/crates/tensorflow'>Tensorflow bindings https://lib.rs/crates/tensorflow</a></li>
<li><a href='https://lib.rs/crates/juice'>Juice (machine learning for hackers) https://lib.rs/crates/juice</a></li>
<li><a href='https://lib.rs/crates/rsrl'>Rust reinforcement learning https://lib.rs/crates/rsrl</a></li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I make a non exhaustive list of machine learning tools and frameworks, written in Rust. Not all of them are mature enough for production environments. I believe that community effort can change this very quickly.</p>
<p>To make a comparison with the Python ecosystem I will cover frameworks for linear algebra (numpy), dataframes (pandas), off-the-shelf machine learning (scikit-learn), deep learning (tensorflow) and reinforcement learning (openAI).</p>
<p>Rust is the language of the future.<br>
Happy coding!Â </p>
Reference
<ol><li><a href='https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms'>BLAS linear algebra https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms</a></li>
<li><a href='https://github.com/nevi-me/rust-dataframe'>Rust dataframeÂ https://github.com/nevi-me/rust-dataframe</a></li>
<li><a href='https://github.com/maciejkula/rustlearn'>Rustlearn https://github.com/maciejkula/rustlearn</a></li>
<li><a href='https://github.com/AtheMathmo/rusty-machine'>Rusty machine https://github.com/AtheMathmo/rusty-machine</a></li>
<li><a href='https://lib.rs/crates/tensorflow'>Tensorflow bindings https://lib.rs/crates/tensorflow</a></li>
<li><a href='https://lib.rs/crates/juice'>Juice (machine learning for hackers) https://lib.rs/crates/juice</a></li>
<li><a href='https://lib.rs/crates/rsrl'>Rust reinforcement learning https://lib.rs/crates/rsrl</a></li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/18gd2s/ts-episode-15.mp3" length="42459602" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I make a non exhaustive list of machine learning tools and frameworks, written in Rust. Not all of them are mature enough for production environments. I believe that community effort can change this very quickly.
To make a comparison with the Python ecosystem I will cover frameworks for linear algebra (numpy), dataframes (pandas), off-the-shelf machine learning (scikit-learn), deep learning (tensorflow) and reinforcement learning (openAI).
Rust is the language of the future.Happy coding!Â 
Reference
BLAS linear algebra https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms
Rust dataframeÂ https://github.com/nevi-me/rust-dataframe
Rustlearn https://github.com/maciejkula/rustlearn
Rusty machine https://github.com/AtheMathmo/rusty-machine
Tensorflow bindings https://lib.rs/crates/tensorflow
Juice (machine learning for hackers) https://lib.rs/crates/juice
Rust reinforcement learning https://lib.rs/crates/rsrl
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:18</itunes:duration>
                <itunes:episode>107</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust and machine learning #3 with Alec Mocatta (Ep. 109)</title>
        <itunes:title>Rust and machine learning #3 with Alec Mocatta (Ep. 109)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-and-machine-learning-3-with-alec-mocatta-ep-109/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-and-machine-learning-3-with-alec-mocatta-ep-109/#comments</comments>        <pubDate>Mon, 22 Jun 2020 11:48:40 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/79dc6520-2031-56d3-b087-f12544993930</guid>
                                    <description><![CDATA[<p>In the 3rd episode of Rust and machine learning I speak with Alec Mocatta. 
Alec is a +20 year experience professional programmer who has been spending time at the interception of distributed systems and data analytics. He's the founder of two startups in the distributed system space and author of <a href='https://github.com/constellation-rs/amadeus'>Amadeus</a>, an open-source framework that encourages you to write clean and reusable code that works, regardless of data scale, locally or distributed across a cluster.</p>
<p>Only for June 24th, <a href='https://www.meetup.com/Rust-London-User-Group/events/271183454/'>LDN *Virtual* Talks June 2020 with Bippit (Alec speaking about Amadeus)</a>
</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In the 3rd episode of Rust and machine learning I speak with Alec Mocatta. <br>
Alec is a +20 year experience professional programmer who has been spending time at the interception of distributed systems and data analytics. He's the founder of two startups in the distributed system space and author of <a href='https://github.com/constellation-rs/amadeus'>Amadeus</a>, an open-source framework that encourages you to write clean and reusable code that works, regardless of data scale, locally or distributed across a cluster.</p>
<p>Only for June 24th, <a href='https://www.meetup.com/Rust-London-User-Group/events/271183454/'>LDN *Virtual* Talks June 2020 with Bippit (Alec speaking about Amadeus)</a><br>
</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/01sy99/rust-ml-mocatta.mp3" length="37495361" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the 3rd episode of Rust and machine learning I speak with Alec Mocatta. Alec is a +20 year experience professional programmer who has been spending time at the interception of distributed systems and data analytics. He's the founder of two startups in the distributed system space and author of Amadeus, an open-source framework that encourages you to write clean and reusable code that works, regardless of data scale, locally or distributed across a cluster.
Only for June 24th, LDN *Virtual* Talks June 2020 with Bippit (Alec speaking about Amadeus)
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:58</itunes:duration>
                <itunes:episode>106</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust and machine learning #2 with Luca Palmieri (Ep. 108)</title>
        <itunes:title>Rust and machine learning #2 with Luca Palmieri (Ep. 108)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-and-machine-learning-2-with-luca-palmieri-ep-108/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-and-machine-learning-2-with-luca-palmieri-ep-108/#comments</comments>        <pubDate>Fri, 19 Jun 2020 11:17:40 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/008deba4-15ca-5398-a355-1e2bc5af3100</guid>
                                    <description><![CDATA[<p>In the second episode of Rust and Machine learning I am speaking with Luca Palmieri, who has been spending a large part of his career at the interception of machine learning and data engineering. 
In addition, Luca contributed to several projects closer to the machine learning community using the Rust programming language. <a href='https://docs.rs/linfa/0.1.2/linfa/'>Linfa</a> is an ambitious project that definitely deserves the attention of the data science community (and it's written in Rust, with Python bindings! How cool??!).</p>
<p>Â </p>
References
<ul><li>Series Announcement - Zero to Production in Rust <a href='https://www.lpalmieri.com/posts/2020-05-10-announcement-zero-to-production-in-rust/'>https://www.lpalmieri.com/posts/2020-05-10-announcement-zero-to-production-in-rust/</a></li>
<li>Zero To Production #0: Foreword <a href='https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/'>https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/</a></li>
<li>Taking ML to production with Rust: a 25x speedup <a href='https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/'>https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>In the second episode of <em>Rust and Machine learning</em> I am speaking with Luca Palmieri, who has been spending a large part of his career at the interception of machine learning and data engineering. <br>
In addition, Luca contributed to several projects closer to the machine learning community using the Rust programming language. <a href='https://docs.rs/linfa/0.1.2/linfa/'><em>Linfa</em></a> is an ambitious project that definitely deserves the attention of the data science community (and it's written in Rust, with Python bindings! How cool??!).</p>
<p>Â </p>
References
<ul><li>Series Announcement - Zero to Production in Rust <a href='https://www.lpalmieri.com/posts/2020-05-10-announcement-zero-to-production-in-rust/'>https://www.lpalmieri.com/posts/2020-05-10-announcement-zero-to-production-in-rust/</a></li>
<li>Zero To Production #0: Foreword <a href='https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/'>https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/</a></li>
<li>Taking ML to production with Rust: a 25x speedup <a href='https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/'>https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/abh2bb/rust-ml-palmieri.mp3" length="41037094" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the second episode of Rust and Machine learning I am speaking with Luca Palmieri, who has been spending a large part of his career at the interception of machine learning and data engineering. In addition, Luca contributed to several projects closer to the machine learning community using the Rust programming language. Linfa is an ambitious project that definitely deserves the attention of the data science community (and it's written in Rust, with Python bindings! How cool??!).
Â 
References
Series Announcement - Zero to Production in Rust https://www.lpalmieri.com/posts/2020-05-10-announcement-zero-to-production-in-rust/
Zero To Production #0: Foreword https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/
Taking ML to production with Rust: a 25x speedup https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>27:02</itunes:duration>
                <itunes:episode>105</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Rust and machine learning #1 (Ep. 107)</title>
        <itunes:title>Rust and machine learning #1 (Ep. 107)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rust-and-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/rust-and-machine-learning/#comments</comments>        <pubDate>Wed, 17 Jun 2020 07:14:43 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/3a2d82b7-e4b9-5e83-8a24-178d45c42abd</guid>
                                    <description><![CDATA[<p>This is the first episode of a series about the Rust programming language and the role it can play in the machine learning field.</p>
<p><a href='https://www.rust-lang.org/'>Rust</a> is one of the most beautiful languages I have ever studied so far. I personally come from the C programming language, though for professional activities in machine learning I had to switch to the loved and hated Python language.</p>
<p>This episode is clearly not providing you with an exhaustive list of the benefits of Rust, nor its capabilities. For this you can check the references and start getting familiar with what I think it's going to be the language of the next 20 years.</p>
<p>Â </p>
Sponsored
<p>This episode is supported by Pryml Technologies. <a href='https://pryml.io'>Pryml</a> offers secure and cost effective data privacy solutions for your organisation. It generates a synthetic alternative without disclosing you confidential data.</p>
<p>Â </p>
References
<ul><li><a href='https://doc.rust-lang.org/book/'>The Rust Programming LanguageÂ </a></li>
<li><a href='https://rust-lang-nursery.github.io/rust-cookbook/'>Cookin' with Rust</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>This is the first episode of a series about the Rust programming language and the role it can play in the machine learning field.</p>
<p><a href='https://www.rust-lang.org/'>Rust</a> is one of the most beautiful languages I have ever studied so far. I personally come from the C programming language, though for professional activities in machine learning I had to switch to the loved and hated Python language.</p>
<p>This episode is clearly not providing you with an exhaustive list of the benefits of Rust, nor its capabilities. For this you can check the references and start getting familiar with what I think it's going to be the language of the next 20 years.</p>
<p>Â </p>
Sponsored
<p>This episode is supported by Pryml Technologies. <a href='https://pryml.io'>Pryml</a> offers secure and cost effective data privacy solutions for your organisation. It generates a synthetic alternative without disclosing you confidential data.</p>
<p>Â </p>
References
<ul><li><a href='https://doc.rust-lang.org/book/'>The Rust Programming LanguageÂ </a></li>
<li><a href='https://rust-lang-nursery.github.io/rust-cookbook/'>Cookin' with Rust</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/aloipf/ts-episode-14.mp3" length="41341885" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This is the first episode of a series about the Rust programming language and the role it can play in the machine learning field.
Rust is one of the most beautiful languages I have ever studied so far. I personally come from the C programming language, though for professional activities in machine learning I had to switch to the loved and hated Python language.
This episode is clearly not providing you with an exhaustive list of the benefits of Rust, nor its capabilities. For this you can check the references and start getting familiar with what I think it's going to be the language of the next 20 years.
Â 
Sponsored
This episode is supported by Pryml Technologies. Pryml offers secure and cost effective data privacy solutions for your organisation. It generates a synthetic alternative without disclosing you confidential data.
Â 
References
The Rust Programming LanguageÂ 
Cookin' with Rust
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:27</itunes:duration>
                <itunes:episode>104</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Protecting workers with artificial intelligence (with Sandeep Pandya CEO Everguard.ai)(Ep. 106)</title>
        <itunes:title>Protecting workers with artificial intelligence (with Sandeep Pandya CEO Everguard.ai)(Ep. 106)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/protecting-workers-with-artificial-intelligence-with-sandeed-pandya-ceo-everguardaiep-106/</link>
                    <comments>https://datascienceathome.podbean.com/e/protecting-workers-with-artificial-intelligence-with-sandeed-pandya-ceo-everguardaiep-106/#comments</comments>        <pubDate>Mon, 15 Jun 2020 07:29:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f611cf3f-ad46-57b9-a79e-73dc8de117e0</guid>
                                    <description><![CDATA[<p>In this episode I have a chat with Sandeep Pandya, CEO at <a href='https://everguard.ai/'>Everguard.ai</a> a company that uses sensor fusion, computer vision and more to provide safer working environments to workers in heavy industry.
Sandeep is a senior executive who can hide the complexity of the topic with great talent.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://pryml.io/'>Pryml.io</a> 
Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.
Test ideas. Launch new products. Fast. Secure.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I have a chat with Sandeep Pandya, CEO at <a href='https://everguard.ai/'>Everguard.ai</a> a company that uses sensor fusion, computer vision and more to provide safer working environments to workers in heavy industry.<br>
Sandeep is a senior executive who can hide the complexity of the topic with great talent.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://pryml.io/'>Pryml.io</a> <br>
Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.<br>
Test ideas. Launch new products. Fast. Secure.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/491rfb/ts-episode-13.mp3" length="28837728" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I have a chat with Sandeep Pandya, CEO at Everguard.ai a company that uses sensor fusion, computer vision and more to provide safer working environments to workers in heavy industry.Sandeep is a senior executive who can hide the complexity of the topic with great talent.
Â 
This episode is supported by Pryml.io Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.Test ideas. Launch new products. Fast. Secure.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:20</itunes:duration>
                <itunes:episode>103</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Compressing deep learning models: rewinding (Ep.105)</title>
        <itunes:title>Compressing deep learning models: rewinding (Ep.105)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/compressing-deep-learning-models-rewinding-ep105/</link>
                    <comments>https://datascienceathome.podbean.com/e/compressing-deep-learning-models-rewinding-ep105/#comments</comments>        <pubDate>Mon, 01 Jun 2020 08:37:33 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/9ae24a6b-75d7-5f78-8f5c-672bae2449bf</guid>
                                    <description><![CDATA[<p>As a continuation of the <a href='https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/'>previous episode</a> in this one I cover the topic about compressing deep learning models and explain another simple yet fantastic approach that can lead to much smaller models that still perform as good as the original one.</p>
<p>Don't forget to join our <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-es8emg9c-6IAgTPZSYM53nIMMZwdpAw'>Slack channel</a> and discuss previous episodes or propose new ones.</p>
<p>This episode is supported by <a href='https://pryml.io'>Pryml.io</a> 
Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.</p>
<p>Â </p>
References
<p class="title mathjax">Comparing Rewinding and Fine-tuning in Neural Network Pruning
<a href='https://arxiv.org/abs/2003.02389'>https://arxiv.org/abs/2003.02389</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>As a continuation of the <a href='https://datascienceathome.com/compressing-deep-learning-models-distillation-ep-104/'>previous episode</a> in this one I cover the topic about compressing deep learning models and explain another simple yet fantastic approach that can lead to much smaller models that still perform as good as the original one.</p>
<p>Don't forget to join our <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-es8emg9c-6IAgTPZSYM53nIMMZwdpAw'>Slack channel</a> and discuss previous episodes or propose new ones.</p>
<p>This episode is supported by <a href='https://pryml.io'>Pryml.io</a> <br>
Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.</p>
<p>Â </p>
References
<p class="title mathjax">Comparing Rewinding and Fine-tuning in Neural Network Pruning<br>
<a href='https://arxiv.org/abs/2003.02389'>https://arxiv.org/abs/2003.02389</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/v6ttky/ts-episode-12.mp3" length="29196604" type="audio/mpeg"/>
        <itunes:summary><![CDATA[As a continuation of the previous episode in this one I cover the topic about compressing deep learning models and explain another simple yet fantastic approach that can lead to much smaller models that still perform as good as the original one.
Don't forget to join our Slack channel and discuss previous episodes or propose new ones.
This episode is supported by Pryml.io Pryml is an enterprise-scale platform to synthesise data and deploy applications built on that data back to a production environment.
Â 
References
Comparing Rewinding and Fine-tuning in Neural Network Pruninghttps://arxiv.org/abs/2003.02389
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:31</itunes:duration>
                <itunes:episode>102</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Compressing deep learning models: distillation (Ep.104)</title>
        <itunes:title>Compressing deep learning models: distillation (Ep.104)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/compressing-deep-learning-models-distillation-ep104/</link>
                    <comments>https://datascienceathome.podbean.com/e/compressing-deep-learning-models-distillation-ep104/#comments</comments>        <pubDate>Wed, 20 May 2020 08:04:10 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/7162df07-03ec-5437-83d7-58fd29809ed9</guid>
                                    <description><![CDATA[<p>Using large deep learning models on limited hardware or edge devices is definitely prohibitive. There are methods to compress large models by orders of magnitude and maintain similar accuracy during inference.</p>
<p>In this episode I explain one of the first methods: knowledge distillation</p>
<p>Â Come <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-es8emg9c-6IAgTPZSYM53nIMMZwdpAw'>join us on Slack</a> </p>
Reference
<ul><li class="title mathjax">Distilling the Knowledge in a Neural Network <a href='https://arxiv.org/abs/1503.02531'>https://arxiv.org/abs/1503.02531</a></li>
<li class="title mathjax">Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks <a href='https://arxiv.org/abs/2004.05937'>https://arxiv.org/abs/2004.05937</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Using large deep learning models on limited hardware or edge devices is definitely prohibitive. There are methods to compress large models by orders of magnitude and maintain similar accuracy during inference.</p>
<p>In this episode I explain one of the first methods: knowledge distillation</p>
<p>Â Come <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-es8emg9c-6IAgTPZSYM53nIMMZwdpAw'>join us on Slack</a> </p>
Reference
<ul><li class="title mathjax">Distilling the Knowledge in a Neural Network <a href='https://arxiv.org/abs/1503.02531'>https://arxiv.org/abs/1503.02531</a></li>
<li class="title mathjax">Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks <a href='https://arxiv.org/abs/2004.05937'>https://arxiv.org/abs/2004.05937</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/m7j023/ts-episode-11.mp3" length="31915625" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Using large deep learning models on limited hardware or edge devices is definitely prohibitive. There are methods to compress large models by orders of magnitude and maintain similar accuracy during inference.
In this episode I explain one of the first methods: knowledge distillation
Â Come join us on Slack 
Reference
Distilling the Knowledge in a Neural Network https://arxiv.org/abs/1503.02531
Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks https://arxiv.org/abs/2004.05937
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:19</itunes:duration>
                <itunes:episode>101</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Pandemics and the risks of collecting data (Ep. 103)</title>
        <itunes:title>Pandemics and the risks of collecting data (Ep. 103)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/pandemics-and-the-risks-of-collecting-data-ep-103/</link>
                    <comments>https://datascienceathome.podbean.com/e/pandemics-and-the-risks-of-collecting-data-ep-103/#comments</comments>        <pubDate>Fri, 08 May 2020 09:59:11 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f35684e0-57f3-5e73-b10e-7da8061abe84</guid>
                                    <description><![CDATA[<p>Codiv-19 is an emergency. True. Let's just not prepare for another emergency about privacy violation when this one is over.</p>
<p>Â </p>
<p>Join our new <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-dj1oluhu-MT9DoD5gqsAX4o6POmfnVQ'>Slack channel</a></p>
<p>Â </p>
<p>This episode is supported by Proton. You can check them out at protonmail.com or protonvpn.com</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Codiv-19 is an emergency. True. Let's just not prepare for another emergency about privacy violation when this one is over.</p>
<p>Â </p>
<p>Join our new <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-dj1oluhu-MT9DoD5gqsAX4o6POmfnVQ'>Slack channel</a></p>
<p>Â </p>
<p>This episode is supported by Proton. You can check them out at protonmail.com or protonvpn.com</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/r4y8o1/ts-episode-10.mp3" length="27348883" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Codiv-19 is an emergency. True. Let's just not prepare for another emergency about privacy violation when this one is over.
Â 
Join our new Slack channel
Â 
This episode is supported by Proton. You can check them out at protonmail.com or protonvpn.com]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:09</itunes:duration>
                <itunes:episode>100</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Why average can get your predictions very wrong (ep. 102)</title>
        <itunes:title>Why average can get your predictions very wrong (ep. 102)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/why-average-can-get-your-predictions-very-wrong-ep-102/</link>
                    <comments>https://datascienceathome.podbean.com/e/why-average-can-get-your-predictions-very-wrong-ep-102/#comments</comments>        <pubDate>Sun, 19 Apr 2020 14:36:55 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1718cc7d-da1e-5e34-8221-b5f64f68300d</guid>
                                    <description><![CDATA[<p>Whenever people reason about probability of events, they have the tendency to consider average values between two extremes.Â 
In this episode I explain why such a way of approximating is wrong and dangerous, with a numerical example.</p>
<p>We are moving our community to <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-dj1oluhu-MT9DoD5gqsAX4o6POmfnVQ'>Slack</a>. See you there!</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Whenever people reason about probability of events, they have the tendency to consider average values between two extremes.Â <br>
In this episode I explain why such a way of approximating is wrong and dangerous, with a numerical example.</p>
<p>We are moving our community to <a href='https://join.slack.com/t/datascienceathome/shared_invite/zt-dj1oluhu-MT9DoD5gqsAX4o6POmfnVQ'>Slack</a>. See you there!</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jgsm3z/ts-episode-9.mp3" length="21076824" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Whenever people reason about probability of events, they have the tendency to consider average values between two extremes.Â In this episode I explain why such a way of approximating is wrong and dangerous, with a numerical example.
We are moving our community to Slack. See you there!
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:40</itunes:duration>
                <itunes:episode>99</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Activate deep learning neurons faster with Dynamic RELU (ep. 101)</title>
        <itunes:title>Activate deep learning neurons faster with Dynamic RELU (ep. 101)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/activate-neurons-faster-with-dynamic-relu-ep-101/</link>
                    <comments>https://datascienceathome.podbean.com/e/activate-neurons-faster-with-dynamic-relu-ep-101/#comments</comments>        <pubDate>Wed, 01 Apr 2020 14:13:59 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/1b25ed89-4e46-561a-b80e-1dd1cbc0cb9b</guid>
                                    <description><![CDATA[<p>In this episode I briefly explain the concept behind activation functions in deep learning. One of the most widely used activation function is the rectified linear unit (ReLU).Â 
While there are several flavors of ReLU in the literature, in this episode I speak about a very interesting approach that keeps computational complexity low while improving performance quite consistently.</p>
<p>This episode is supported by <a href='https://pryml.io'>pryml.io</a>. At pryml we let companies share confidential data. Visit our website.</p>
<p>Don't forget to join us on <a href='https://discord.gg/4UNKGf3'>discord channel</a> to propose new episode or discuss the previous ones.Â </p>
References
<p class="title mathjax">Dynamic ReLUÂ <a href='https://arxiv.org/abs/2003.10027'>https://arxiv.org/abs/2003.10027</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I briefly explain the concept behind activation functions in deep learning. One of the most widely used activation function is the rectified linear unit (ReLU).Â <br>
While there are several flavors of ReLU in the literature, in this episode I speak about a very interesting approach that keeps computational complexity low while improving performance quite consistently.</p>
<p>This episode is supported by <a href='https://pryml.io'>pryml.io</a>. At pryml we let companies share confidential data. Visit our website.</p>
<p>Don't forget to join us on <a href='https://discord.gg/4UNKGf3'>discord channel</a> to propose new episode or discuss the previous ones.Â </p>
References
<p class="title mathjax">Dynamic ReLUÂ <a href='https://arxiv.org/abs/2003.10027'>https://arxiv.org/abs/2003.10027</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/pxhxgx/ts-episode-8.mp3" length="30418552" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I briefly explain the concept behind activation functions in deep learning. One of the most widely used activation function is the rectified linear unit (ReLU).Â While there are several flavors of ReLU in the literature, in this episode I speak about a very interesting approach that keeps computational complexity low while improving performance quite consistently.
This episode is supported by pryml.io. At pryml we let companies share confidential data. Visit our website.
Don't forget to join us on discord channel to propose new episode or discuss the previous ones.Â 
References
Dynamic ReLUÂ https://arxiv.org/abs/2003.10027]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:18</itunes:duration>
                <itunes:episode>98</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>WARNING!! Neural networks can memorize secrets (ep. 100)</title>
        <itunes:title>WARNING!! Neural networks can memorize secrets (ep. 100)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/neural-networks-can-memorize-secrets-ep-100/</link>
                    <comments>https://datascienceathome.podbean.com/e/neural-networks-can-memorize-secrets-ep-100/#comments</comments>        <pubDate>Mon, 23 Mar 2020 07:49:06 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/2ecb1fc2-094b-5fa6-beeb-a671d0e06258</guid>
                                    <description><![CDATA[<p>One of the best features of neural networks and machine learning models is to memorize patterns from training data and apply those to unseen observations. That's where the magic is.Â 
However, there are scenarios in which the same machine learning models learn patterns so well such that they can disclose some of the data they have been trained on. This phenomenon goes under the name of unintended memorization and it is extremely dangerous.</p>
<p>Think about a language generator that discloses the passwords, the credit card numbers and the social security numbers of the records it has been trained on. Or more generally, think about a synthetic data generator that can disclose the training data it is trying to protect.Â </p>
<p>In this episode I explain why unintended memorization is a real problem in machine learning. Except for differentially private training there is no other way to mitigate such a problem in realistic conditions.
At <a href='https://pryml.io'>Pryml</a> we are very aware of this. Which is why we have been developing a synthetic data generation technology that is not affected by such an issue.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://harmonizely.com'>Harmonizely</a>.Â 
Harmonizely lets youÂ build your own unique scheduling pageÂ based on your availability so you can start scheduling meetings in just a couple minutes.
Get started by connecting your online calendar and configuring your meeting preferences.
Then, start sharing your scheduling page with your invitees!</p>
<p>Â </p>
References

<p>The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks
<a href='https://www.usenix.org/conference/usenixsecurity19/presentation/carlini'>https://www.usenix.org/conference/usenixsecurity19/presentation/carlini</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>One of the best features of neural networks and machine learning models is to memorize patterns from training data and apply those to unseen observations. That's where the magic is.Â <br>
However, there are scenarios in which the same machine learning models learn patterns so well such that they can disclose some of the data they have been trained on. This phenomenon goes under the name of <em>unintended memorization</em> and it is extremely dangerous.</p>
<p>Think about a language generator that discloses the passwords, the credit card numbers and the social security numbers of the records it has been trained on. Or more generally, think about a synthetic data generator that can disclose the training data it is trying to protect.Â </p>
<p>In this episode I explain why unintended memorization is a real problem in machine learning. Except for <em>differentially private training</em> there is no other way to mitigate such a problem in realistic conditions.<br>
At <a href='https://pryml.io'>Pryml</a> we are very aware of this. Which is why we have been developing a synthetic data generation technology that is not affected by such an issue.</p>
<p>Â </p>
<p>This episode is supported by <a href='https://harmonizely.com'>Harmonizely</a>.Â <br>
Harmonizely lets youÂ build your own unique scheduling pageÂ based on your availability so you can start scheduling meetings in just a couple minutes.<br>
Get started by connecting your online calendar and configuring your meeting preferences.<br>
Then, start sharing your scheduling page with your invitees!</p>
<p>Â </p>
References

<p>The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks<br>
<a href='https://www.usenix.org/conference/usenixsecurity19/presentation/carlini'>https://www.usenix.org/conference/usenixsecurity19/presentation/carlini</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/yzxtrq/ts-episode-7.mp3" length="33457027" type="audio/mpeg"/>
        <itunes:summary><![CDATA[One of the best features of neural networks and machine learning models is to memorize patterns from training data and apply those to unseen observations. That's where the magic is.Â However, there are scenarios in which the same machine learning models learn patterns so well such that they can disclose some of the data they have been trained on. This phenomenon goes under the name of unintended memorization and it is extremely dangerous.
Think about a language generator that discloses the passwords, the credit card numbers and the social security numbers of the records it has been trained on. Or more generally, think about a synthetic data generator that can disclose the training data it is trying to protect.Â 
In this episode I explain why unintended memorization is a real problem in machine learning. Except for differentially private training there is no other way to mitigate such a problem in realistic conditions.At Pryml we are very aware of this. Which is why we have been developing a synthetic data generation technology that is not affected by such an issue.
Â 
This episode is supported by Harmonizely.Â Harmonizely lets youÂ build your own unique scheduling pageÂ based on your availability so you can start scheduling meetings in just a couple minutes.Get started by connecting your online calendar and configuring your meeting preferences.Then, start sharing your scheduling page with your invitees!
Â 
References

The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networkshttps://www.usenix.org/conference/usenixsecurity19/presentation/carlini
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:16</itunes:duration>
                <itunes:episode>97</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Attacks to machine learning model: inferring ownership of training data (Ep. 99) </title>
        <itunes:title>Attacks to machine learning model: inferring ownership of training data (Ep. 99) </itunes:title>
        <link>https://datascienceathome.podbean.com/e/attacks-to-machine-learning-model-inferring-ownership-ep-99/</link>
                    <comments>https://datascienceathome.podbean.com/e/attacks-to-machine-learning-model-inferring-ownership-ep-99/#comments</comments>        <pubDate>Sat, 14 Mar 2020 10:15:06 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/161f8c92-b3ef-5dc7-b397-2290e6d2268b</guid>
                                    <description><![CDATA[<p>In this episode I explain a very effective technique that allows one to infer the membership of any record at hand to the (private) training dataset used to train the target model. The effectiveness of such technique is due to the fact that it works on black-box models of which there is no access to the data used for training, nor model parameters and hyperparameters. Such a scenario is very realistic and typical of machine learning as a service APIs.Â </p>
<p>This episode is supported by <a href='https://pryml.io'>pryml.io</a>, a platform I am personally working on that enables data sharing without giving up confidentiality.Â </p>
<p>Â </p>
<p>As promised below is the schema of the attack explained in the episode.</p>
<p>Â </p>
<p>Â </p>
References
<p class="document-title"><a href='https://ieeexplore.ieee.org/document/7958568'>Membership Inference Attacks Against Machine Learning Models</a></p>
Â 
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I explain a very effective technique that allows one to infer the membership of any record at hand to the (private) training dataset used to train the target model. The effectiveness of such technique is due to the fact that it works on black-box models of which there is no access to the data used for training, nor model parameters and hyperparameters. Such a scenario is very realistic and typical of machine learning as a service APIs.Â </p>
<p>This episode is supported by <a href='https://pryml.io'>pryml.io</a>, a platform I am personally working on that enables data sharing without giving up confidentiality.Â </p>
<p>Â </p>
<p>As promised below is the schema of the attack explained in the episode.</p>
<p>Â </p>
<p>Â </p>
References
<p class="document-title"><a href='https://ieeexplore.ieee.org/document/7958568'>Membership Inference Attacks Against Machine Learning Models</a></p>
Â 
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/a9mbt2/ts-episode-6.mp3" length="27491700" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I explain a very effective technique that allows one to infer the membership of any record at hand to the (private) training dataset used to train the target model. The effectiveness of such technique is due to the fact that it works on black-box models of which there is no access to the data used for training, nor model parameters and hyperparameters. Such a scenario is very realistic and typical of machine learning as a service APIs.Â 
This episode is supported by pryml.io, a platform I am personally working on that enables data sharing without giving up confidentiality.Â 
Â 
As promised below is the schema of the attack explained in the episode.
Â 
Â 
References
Membership Inference Attacks Against Machine Learning Models
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:39</itunes:duration>
                <itunes:episode>96</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Don't be naive with data anonymization (Ep. 98)</title>
        <itunes:title>Don't be naive with data anonymization (Ep. 98)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/dont-be-naive-with-data-anonymization-ep-98/</link>
                    <comments>https://datascienceathome.podbean.com/e/dont-be-naive-with-data-anonymization-ep-98/#comments</comments>        <pubDate>Sun, 08 Mar 2020 16:33:31 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/c372f10e-1495-535d-a08b-aca1179cf50d</guid>
                                    <description><![CDATA[<p>Masking, obfuscating, stripping, shuffling.Â 
All the above techniques try to do one simple thing: keeping the data private while sharing it with third parties. Unfortunately, they are not the silver bullet to confidentiality.Â 

All the players in the synthetic data space rely on simplistic techniques that are not secure, might not be compliant and risky for production. 
At <a href='/datascienceathome/episode/pryml.io'>pryml</a> we do things differently.Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Masking, obfuscating, stripping, shuffling.Â <br>
All the above techniques try to do one simple thing: keeping the data private while sharing it with third parties. Unfortunately, they are not the silver bullet to confidentiality.Â <br>
<br>
All the players in the synthetic data space rely on simplistic techniques that are not secure, might not be compliant and risky for production. <br>
At <a href='/datascienceathome/episode/pryml.io'>pryml</a> we do things differently.Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/62zun9/ts-episode-5.mp3" length="19274190" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Masking, obfuscating, stripping, shuffling.Â All the above techniques try to do one simple thing: keeping the data private while sharing it with third parties. Unfortunately, they are not the silver bullet to confidentiality.Â All the players in the synthetic data space rely on simplistic techniques that are not secure, might not be compliant and risky for production. At pryml we do things differently.Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>13:41</itunes:duration>
                <itunes:episode>95</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
            </item>
    <item>
        <title>Why sharing real data is dangerous (Ep. 97)</title>
        <itunes:title>Why sharing real data is dangerous (Ep. 97)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/why-sharing-real-data-is-dangerous-ep-97/</link>
                    <comments>https://datascienceathome.podbean.com/e/why-sharing-real-data-is-dangerous-ep-97/#comments</comments>        <pubDate>Sun, 01 Mar 2020 09:20:38 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/dc20ef6e-3ba1-53b4-8b8f-6464bc7acf2e</guid>
                                    <description><![CDATA[<p>There are very good reasons why a financial institution should never share their data. Actually, they should never even move their data. Ever.
In this episode I explain you why.</p>
<p>Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>There are very good reasons why a financial institution should never share their data. Actually, they should never even move their data. Ever.<br>
In this episode I explain you why.</p>
<p>Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jgqdkq/ts-episode-4.mp3" length="14948345" type="audio/mpeg"/>
        <itunes:summary><![CDATA[There are very good reasons why a financial institution should never share their data. Actually, they should never even move their data. Ever.In this episode I explain you why.
Â 
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>10:35</itunes:duration>
                <itunes:episode>94</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>Building reproducible machine learning in production (Ep. 96)</title>
        <itunes:title>Building reproducible machine learning in production (Ep. 96)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/building-reproducible-machine-learning-in-production-ep-96/</link>
                    <comments>https://datascienceathome.podbean.com/e/building-reproducible-machine-learning-in-production-ep-96/#comments</comments>        <pubDate>Sat, 22 Feb 2020 16:59:54 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/76da26cf-5fbd-5c51-8be1-02dcd81d1d34</guid>
                                    <description><![CDATA[<p>Building reproducible models is essential for all those scenarios in which the lead developer is collaborating with other team members. Reproducibility in machine learning shall not be an art, rather it should be achieved via a methodical approach.Â 
In this episode I give a few suggestions about how to make your ML models reproducible and keep your workflow as smooth.</p>
<p>Enjoy the show!

Come visit us on our <a href='https://discord.gg/4UNKGf3'>discord</a> channel and have a chat</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Building reproducible models is essential for all those scenarios in which the lead developer is collaborating with other team members. Reproducibility in machine learning shall not be an art, rather it should be achieved via a methodical approach.Â <br>
In this episode I give a few suggestions about how to make your ML models reproducible and keep your workflow as smooth.</p>
<p>Enjoy the show!<br>
<br>
Come visit us on our <a href='https://discord.gg/4UNKGf3'>discord</a> channel and have a chat</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8ud4r8/ts-episode-3.mp3" length="21372520" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Building reproducible models is essential for all those scenarios in which the lead developer is collaborating with other team members. Reproducibility in machine learning shall not be an art, rather it should be achieved via a methodical approach.Â In this episode I give a few suggestions about how to make your ML models reproducible and keep your workflow as smooth.
Enjoy the show!Come visit us on our discord channel and have a chat]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:20</itunes:duration>
                <itunes:episode>93</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>Bridging the gap between data science and data engineering: metrics  (Ep. 95)</title>
        <itunes:title>Bridging the gap between data science and data engineering: metrics  (Ep. 95)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/bridging-the-gap-between-data-science-and-data-engineering-metrics-ep-95/</link>
                    <comments>https://datascienceathome.podbean.com/e/bridging-the-gap-between-data-science-and-data-engineering-metrics-ep-95/#comments</comments>        <pubDate>Fri, 14 Feb 2020 17:20:44 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/f6c799b3-9a57-5e78-9d88-4aabbcee7c90</guid>
                                    <description><![CDATA[<p>Data science and data engineering are usually two different departments in organisations. Bridging the gap between the two is essential to success. Many times the brilliant applications created by data scientists don't find a match in production, just because they are not production-ready.</p>
<p>In this episode I have a talk with Daan Gerits, co-founder and CTO at <a href='/datascienceathome/episode/pryml.io'>Pryml.io</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Data science and data engineering are usually two different departments in organisations. Bridging the gap between the two is essential to success. Many times the brilliant applications created by data scientists don't find a match in production, just because they are not production-ready.</p>
<p>In this episode I have a talk with Daan Gerits, co-founder and CTO at <a href='/datascienceathome/episode/pryml.io'>Pryml.io</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/c4hva8/ts-episode-2.mp3" length="25296210" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Data science and data engineering are usually two different departments in organisations. Bridging the gap between the two is essential to success. Many times the brilliant applications created by data scientists don't find a match in production, just because they are not production-ready.
In this episode I have a talk with Daan Gerits, co-founder and CTO at Pryml.io
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>13:25</itunes:duration>
                <itunes:episode>92</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>A big welcome to Pryml: faster machine learning applications to production (Ep. 94)</title>
        <itunes:title>A big welcome to Pryml: faster machine learning applications to production (Ep. 94)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/a-big-welcome-to-pryml-faster-machine-learning-applications-to-production/</link>
                    <comments>https://datascienceathome.podbean.com/e/a-big-welcome-to-pryml-faster-machine-learning-applications-to-production/#comments</comments>        <pubDate>Fri, 07 Feb 2020 10:20:54 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/0ed755f7-253f-530b-ace5-d0d6ff738f81</guid>
                                    <description><![CDATA[<p>Why so much silence?Â Building a company! That's why :)Â 
I am building <a href='https://pryml.io'>pryml</a>, a platform that allows data scientists build their applications on data they cannot get access to.Â 
This is the first of a series of episodes in which I will speak about the technology and the challenges we are facing while we build it.Â </p>
<p>Happy listening and stay tuned!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Why so much silence?Â Building a company! That's why :)Â <br>
I am building <a href='https://pryml.io'>pryml</a>, a platform that allows data scientists build their applications on data they cannot get access to.Â <br>
This is the first of a series of episodes in which I will speak about the technology and the challenges we are facing while we build it.Â </p>
<p>Happy listening and stay tuned!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nqckeb/ts-episode-1.mp3" length="16276425" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Why so much silence?Â Building a company! That's why :)Â I am building pryml, a platform that allows data scientists build their applications on data they cannot get access to.Â This is the first of a series of episodes in which I will speak about the technology and the challenges we are facing while we build it.Â 
Happy listening and stay tuned!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>09:26</itunes:duration>
                <itunes:episode>91</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>It's cold outside. Let's speak about AI winter (Ep. 93)</title>
        <itunes:title>It's cold outside. Let's speak about AI winter (Ep. 93)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/its-cold-outside-lets-speak-about-ai-winter-ep-93/</link>
                    <comments>https://datascienceathome.podbean.com/e/its-cold-outside-lets-speak-about-ai-winter-ep-93/#comments</comments>        <pubDate>Tue, 31 Dec 2019 13:15:09 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/88e75a1e-9482-5520-a31d-fc8d3203463b</guid>
                                    <description><![CDATA[<p>In the last episode of 2019 I speak with <a href='https://blog.piekniewski.info/2018/10/29/ai-winter-update/'>FilipÂ Piekniewski</a>Â about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.</p>
<p>Join us to our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> to discuss your favorite episode and propose new ones.Â 
IÂ would like to thank all of you for supporting and inspiring us. I wish you a wonderful 2020!

Francesco and the team of Data Science at Home</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In the last episode of 2019 I speak with <a href='https://blog.piekniewski.info/2018/10/29/ai-winter-update/'>FilipÂ Piekniewski</a>Â about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.</p>
<p>Join us to our <a href='https://discord.gg/4UNKGf3'>Discord channel</a> to discuss your favorite episode and propose new ones.Â <br>
IÂ would like to thank all of you for supporting and inspiring us. I wish you a wonderful 2020!<br>
<br>
Francesco and the team of Data Science at Home</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7w3ktq/episode-filip-december-2019.mp3" length="70679325" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the last episode of 2019 I speak with FilipÂ PiekniewskiÂ about some of the most worth noting findings in AI and machine learning in 2019. As a matter of fact, the entire field of AI has been inflated by hype and claims that are hard to believe. A lot of the promises made a few years ago have revealed quite hard to achieve, if not impossible. Let's stay grounded and realistic on the potential of this amazing field of research, not to bring disillusion in the near future.
Join us to our Discord channel to discuss your favorite episode and propose new ones.Â IÂ would like to thank all of you for supporting and inspiring us. I wish you a wonderful 2020!Francesco and the team of Data Science at Home]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:48</itunes:duration>
                <itunes:episode>90</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>The dark side of AI: bias in the machine (Ep. 92)</title>
        <itunes:title>The dark side of AI: bias in the machine (Ep. 92)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-bias-in-the-machine-ep-92/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-bias-in-the-machine-ep-92/#comments</comments>        <pubDate>Sat, 28 Dec 2019 08:12:06 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/81f17466-bf5c-5389-aeb4-601f10359008</guid>
                                    <description><![CDATA[<p>Â </p>
<p>This is the fourth and last episode of mini series "The dark side of AI". 
I am your host Francesco and Iâ€™m with Chiara Tonini from London. The title of todayâ€™s episode is Bias in the machineÂ </p>
<p>Â </p>
<p>Â </p>
<p>C: Francesco, today we are starting with an infuriating discussion. Are you ready to be angry?Â </p>
<p>Â </p>
<p>
F: yeah sure is this about brexit?Â 
No, I donâ€™t talk about that. In 1986 the New York Cityâ€™s Rockefeller University conducted a study on breast and uterine cancers and their link to obesity. Like in all clinical trials up to that point, the subjects of the study were all men.Â 
So Francesco, do you see a problem with this approach?Â </p>
<p>Â </p>
<p>F: No problem at all, as long as those men had a perfectly healthy uterus.
In medicine, up to the end of the 20th century, medical studies and clinical trials were conducted on men, medicine dosage and therapy calculated on men (white men). The female body has historically been considered an exception, or variation, from a male body.Â </p>
<p>Â </p>
<p>F: Like Eve coming from Adamâ€™s rib. I thought we were past that...
When the female body has been under analysis, the focus was on the difference between it and the male body, the so-called â€œbikini approachâ€: the reproductive organs are different, therefore we study those, and those only. For a long time medicine assumed this was the only difference.Â </p>
<p>Â </p>
<p>Oh goodÂ ...
This has led to a hugely harmful fallout across society. Because women had reproductive organs, they should reproduce, and all else about them was deemed uninteresting. Still today, they consider a woman without children somehow to have betrayed her biological destiny. This somehow does not apply to a man without children, who also has reproductive organs.Â </p>
<p>Â </p>
<p>F: so this is an example of a very specific type of bias in medicine, regarding clinical trials and medical studies, that is not only harmful for the purposes of these studies, but has ripple effects in all of society
Only in the 2010 a serious conversation has started about the damage caused by not including women in clinical trials. There are many many examples (which we list in the references for this episode).Â </p>
<p>Â </p>
<p>Give me one
Researchers consider cardiovascular disease a male disease - they even call it â€œthe widowerâ€. They conduct studies on male samples. But it turns out, the symptoms of a heart attack, especially the ones leading up to one, are different in women. This led to doctors not recognising or dismissing the early symptoms in women.Â </p>
<p>Â </p>
<p>F: I was reading that women are also subject to chronic pain much more than men: for example migraines, and pain related to endometriosis. But there is extensive evidence now of doctors dismissing womenâ€™s pain, as either imaginary, or â€œinevitableâ€, like it is a normal state of being and does not need a cure at all.Â </p>
<p>Â </p>
<p>The failure of the medical community as a whole to recognise this obvious bias up to the 21st century is an example of how insidious the problem of bias is.</p>
<p>Â </p>
<p>There are 3 fundamental types of bias:Â </p>
<p>Â </p>
<ol><li>One: Stochastic drift: you train your model on a dataset, and you validate the model on a split of the training set. When you apply your model out in the world, you systematically add bias in the predictions due to the training data being too specific</li>
<li>Two: The bias in the model, introduced by your choice of the parameters of your model.Â Â </li>
<li>Three: The bias in your training sample: people put training samples together, and people have culture, experience, and prejudice. As we will see today, this is the most dangerous and subtle bias. Today weâ€™ll talk about this bias.</li>
</ol><p>Â </p>
<p>Bias is a warping of our understanding of reality. We see reality through the lens of our experience and our culture. The origin of bias can date back to traditions going back centuries, and is so ingrained in our way of thinking, that we donâ€™t even see it anymore.Â </p>
<p>Â </p>
<p>F: And let me add, when it comes to machine learning, we see reality through the lens of data. Bias is everywhere, and we could spend hours and hours talking about it. Itâ€™s complicated.Â </p>
<p>Â </p>
<p>Itâ€™s about to become more complicated.Â </p>
<p>Â </p>
<p>F: of course, if I know youâ€¦
Letâ€™s throw artificial intelligence in the mix.Â </p>
<p>Â </p>
<p>F: You know, there was a happier time when this sentence didnâ€™t fill me with a sense of dread...Â 
ImageNet is an online database of over 14 million photos, compiled more than a decade ago at Stanford University. They used it to train machine learning algorithms for image recognition and computer vision, and played an important role in the rise of deep learning. Weâ€™ve all played with it, right? The cats and dogs classifier when learning Tensorflow? (I am a dog by the way. )</p>
<p>Â </p>
<p>F: ImageNet has been a critical asset for computer-vision research. There was an annual international competition to create algorithms that could most accurately label subsets of images. 
In 2012, a team from the University of Toronto used a Convolutional Neural Network to handily win the top prize. That moment is widely considered a turning point in the development of contemporary AI. The final year of the ImageNet competition was 2017, and accuracy in classifying objects in the limited subset had risen from 71% to 97%.Â But that subset did not include the â€œPersonâ€ category, where the accuracy was much lower...Â 
ImageNet contained photos of thousands of people, with labels. This included straightforward tags like â€œteacher,â€ â€œdancerâ€ and â€œplumberâ€, as well as highly charged labels like â€œfailure, loserâ€ and â€œslut, slovenly woman, trollop.â€</p>
<p>Â </p>
<p>F: Uh Oh.Â 
Then â€œImageNet Rouletteâ€ was created, by an artist called Trevor Paglen and a Microsoft researcher named Kate Crawford. It was a digital art project, where you could upload your photo and let the classifier identify you, based on the labels of the database. Imagine how well that went.Â </p>
<p>Â </p>
<p>F: I bet it didâ€™t work
Of course it didnâ€™t work. Random people were classified as â€œorphansâ€ or â€œnon-smokerâ€ or â€œalcoholicâ€. Somebody with glasses was a â€œnerdâ€.Â Tabong Kima, a 24-year old African American, was classified as â€œoffenderâ€ and â€œwrongdoerâ€.Â </p>
<p>Â </p>
<p>F: and there it is.Â 
Quote from Trevor Paglen: â€œWe want to show how layers of bias and racism and misogyny move from one system to the next. The point is to let people see the work that is being done behind the scenes, to see how we are being processed and categorized all the time.â€</p>
<p>Â </p>
<p>F: The ImageNet labels were applied by thousands of unknown people, most likely in the United States, hired by the team from Stanford, and working through the crowdsourcing service Amazon Mechanical Turk. They earned pennies for each photo they labeled, churning through hundreds of labels an hour. The labels were not verified in any way : if a labeler thought someone looks â€œshadyâ€, this label is just a result of their prejudice, but has no basis in reality.
As they did, biases were baked into the database. Paglen quote again: â€œThe way we classify images is a product of our worldview,â€ he said. â€œAny kind of classification system is always going to reflect the values of the person doing the classifying.â€ They defined what a â€œloserâ€ looked like. And a â€œslut.â€ And a â€œwrongdoer.â€</p>
<p>Â </p>
<p>F: The labels originally came from another sprawling collection of data called WordNet, a kind of conceptual dictionary for machines built by researchers at Princeton University in the 1980s. But with these inflammatory labels included, the Stanford researchers may not have realized what they were doing.
What is happening here is the transferring of bias from one system to the next.Â </p>
<p>Â </p>
<p>Tech jobs, in past decades but still today, predominantly go to white males from a narrow social class. Inevitably, they imprint the technology with their worldview.Â So their algorithms learn that a person of color is a criminal, and a woman with a certain look is a slut.Â </p>
<p>Â </p>
<p>Iâ€™m not saying they do it on purpose, but the lack of diversity in the tech industry translates into a narrower world view, which has real consequences in the quality of AI systems.Â </p>
<p>Â </p>
<p>F: Diversity in tech teams is often framed as an equality issue (which of course it is), but there are enormous advantages in it: it allows to create that cognitive diversity that will reflect into superior products or services. 
I believe this is an ongoing problem. In recent months, researchers have shown that face-recognition services from companies like Amazon, Microsoft and IBM can be biased against women and people of color.Â </p>
<p>Â </p>
<p>Crawford and Paglen argue this: 
â€œIn many narratives around AI it is assumed that ongoing technical improvements will resolve all problems and limitations. 
But what if the opposite is true? What if the challenge of getting computers to â€œdescribe what they seeâ€ will always be a problem? The automated interpretation of images is an inherently social and political project, rather than a purely technical one. Understanding the politics within AI systems matters more than ever, as they are quickly moving into the architecture of social institutions: deciding whom to interview for a job, which students are paying attention in class, which suspects to arrest, and much else.â€</p>
<p>Â </p>
<p>F: You are using the words â€œinterpretation of imagesâ€ here, as opposed to â€œdescriptionâ€ or â€œclassificationâ€. Certain images depict something concrete, with an objective reality. Like an apple. But other imagesâ€¦ not so much?Â </p>
<p>Â </p>
<p>ImageNet contain images only corresponding to nouns (not verbs for example). Noun categories such as â€œappleâ€ are well defined. 
But not all nouns are created equal. Linguist George Lakoff points out that the concept of an â€œappleâ€ is more nouny than the concept of â€œlightâ€, which in turn is more nouny than a concept such as â€œhealth.â€ 
Nouns occupy various places on an axis from concrete to abstract, and from descriptive to judgmental. The images corresponding to these nouns become more and more ambiguous.
These gradients have been erased in the logic of ImageNet. Everything is flattened out and pinned to a label. 
The results can be problematic, illogical, and cruel, especially when it comes to labels applied to people.Â </p>
<p>Â </p>
<p>F: so when an image is interpreted as Drug Addict, Crazy, Hypocrite, Spinster, Schizophrenic, Mulatto, Red Neckâ€¦ this is not an objective description of reality, itâ€™s somebodyâ€™s worldview coming to the surface. 
The selection of images for these categories skews the meaning in ways that are gendered, racialized, ableist, and ageist. ImageNet is an object lesson in what happens when people are categorized like objects. 
And this practice has only become more common in recent years, often inside the big AI companies, where there is no way for outsiders to see how images are being ordered and classified.Â </p>
<p>Â </p>
<p>The bizarre thing about these systems is that they remind of early 20th century criminologists like Lombroso, or phrenologists (including Nazi scientists), and physiognomy in general. This was a discipline founded on the assumption that there is a relationship between an image of a person and the character of that person. If you are a murderer, or a Jew, the shape of your head for instance will tell.Â </p>
<p>Â </p>
<p>F: In reaction to these ideas, Reneâ€™ Magritte produced that famous painting of the pipe with the tag â€œThis is not a pipeâ€.</p>
<p>Â </p>
<p>You know that famous photograph of the soldier kissing the nurse at the end of the second world war? The nurse came public about it when she was like 90 years old, and told how this total stranger in the street had grabbed her and kissed her. This is a picture of sexual harassment. And knowing that, it does not seem romantic anymore.Â </p>
<p>Â </p>
<p>F: not romantic at all indeed

Images do not describe themselves. This is a feature that artists have explored for centuries. We see those images differently when we see how theyâ€™re labeled. The correspondence between image, label, and referent is fluid. Whatâ€™s more, those relations can change over time as the cultural context of an image shifts, and can mean different things depending on who looks, and where they are located. Images are open to interpretation and reinterpretation. Entire subfields of philosophy, art history, and media theory are dedicated to teasing out all the nuances of the unstable relationship between images and meanings.
The common mythos of AI and the data it draws on, is that they are objectively and scientifically classifying the world. But itâ€™s not true, everywhere there is politics, ideology, prejudices, and all of the subjective stuff of history.Â </p>
<p>Â </p>
<p>F: When we survey the most widely used training sets, we find that this is the rule rather than the exception.
Training sets are the foundation on which contemporary machine-learning systems are built. They are central to how AI systems recognize and interpret the world.
By looking at the construction of these training sets and their underlying structures, we discover many unquestioned assumptions that are shaky and skewed. These assumptions inform the way AI systems workâ€”and failâ€”to this day.
And the impenetrability of the algorithms, the impossibility of reconstructing the decision-making of a NN, hides the bias further away from scrutiny. When an algorithm is a black box and you canâ€™t look inside, you have no way of analysing its bias.Â </p>
<p>Â </p>
<p>And the skewness and bias of these algorithms have real effects in society, the more you use AI in the judicial system, in medicine, the job market, in security systems based on facial recognition, the list goes on and on.Â </p>
<p>Â </p>
<p>Last year Google unveiled BERT (Bidirectional Encoder Representations from Transformers). Itâ€™s an AI system that learns to talk: itâ€™s a Natural Language Processing engine to generate written (or spoken) language.Â </p>
<p>Â </p>
<p>F: we have an <a href='https://datascienceathome.com/more-powerful-deep-learning-with-transformers/'>episode</a> Â in which we explain all that </p>
<p>Â </p>
<p>
They trained it from lots and lots of digitized information, as varied as old books, Wikipedia entries and news articles. They baked decades and even centuries of biases â€” along with a few new ones â€” into all that material. So for instance BERT is extremely sexist: it associates with male almost all professions and positive attributes (except for â€œmomâ€).Â </p>
<p>Â </p>
<p>BERT is widely used in industry and academia. For example it can interpret news headlines automatically. Even Googleâ€™s search engine use it.Â </p>
<p>Â </p>
<p>Try googling â€œCEOâ€, and you get out a gallery of images of old white men.</p>
<p>Â </p>
<p>F: such a pervasive and flawed AI system can propagate inequality at scale. And itâ€™s super dangerous because itâ€™s subtle. Especially in industry, query results will not be tested and examined for bias. AI is a black box and researchers take results at face value.Â </p>
<p>Â </p>
<p>There are many cases of algorithm-based discrimination in the job market. Targeting candidates for tech jobs for instance, may be done by algorithms that will not recognise women as potential candidates. Therefore, they will not be exposed to as many job ads as men. Or, automated HR systems will rank them lower (for the same CV) and screen them out.Â </p>
<p>Â </p>
<p>In the US, algorithms are used to calculate bail. The majority of the prison population in the US is composed of people of colour, as a result of a systemic bias that goes back centuries. An algorithm learns that a person of colour is more likely to commit a crime, is more likely to not be able to afford bail, is more likely to violate parole. Therefore, people of colour will receive harsher punishments for the same crime. This amplifies this inequality at scale.Â </p>
<p>Â </p>
Conclusion
<p>Â </p>
<p>Question everything, never take predictions of your models at face value. Always question how your training samples have been put together, who put them together, when and in what context. Always remember that your model produces an interpretation of reality, not a faithful depiction.Â 
Treat reality responsibly.Â </p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Â </p>
<p>This is the fourth and last episode of mini series <em>"The dark side of AI"</em>. <br>
I am your host Francesco and Iâ€™m with Chiara Tonini from London. The title of todayâ€™s episode is B<em>ias in the machine</em>Â </p>
<p>Â </p>
<p>Â </p>
<p>C: Francesco, today we are starting with an infuriating discussion. Are you ready to be angry?Â </p>
<p>Â </p>
<p><br>
F: yeah sure is this about brexit?Â <br>
No, I donâ€™t talk about that. In 1986 the New York Cityâ€™s Rockefeller University conducted a study on breast and uterine cancers and their link to obesity. Like in all clinical trials up to that point, the subjects of the study were all men.Â <br>
So Francesco, do you see a problem with this approach?Â </p>
<p>Â </p>
<p>F: No problem at all, as long as those men had a perfectly healthy uterus.<br>
In medicine, up to the end of the 20th century, medical studies and clinical trials were conducted on men, medicine dosage and therapy calculated on men (white men). The female body has historically been considered an exception, or variation, from a male body.Â </p>
<p>Â </p>
<p>F: Like Eve coming from Adamâ€™s rib. I thought we were past that...<br>
When the female body has been under analysis, the focus was on the difference between it and the male body, the so-called<em> â€œbikini approachâ€</em>: the reproductive organs are different, therefore we study those, and those only. For a long time medicine assumed this was the only difference.Â </p>
<p>Â </p>
<p>Oh goodÂ ...<br>
This has led to a hugely harmful fallout across society. Because women had reproductive organs, they should reproduce, and all else about them was deemed uninteresting. Still today, they consider a woman without children somehow to have betrayed her biological destiny. This somehow does not apply to a man without children, who also has reproductive organs.Â </p>
<p>Â </p>
<p>F: so this is an example of a very specific type of bias in medicine, regarding clinical trials and medical studies, that is not only harmful for the purposes of these studies, but has ripple effects in all of society<br>
Only in the 2010 a serious conversation has started about the damage caused by not including women in clinical trials. There are many many examples (which we list in the references for this episode).Â </p>
<p>Â </p>
<p>Give me one<br>
Researchers consider cardiovascular disease a male disease - they even call it â€œthe widowerâ€. They conduct studies on male samples. But it turns out, the symptoms of a heart attack, especially the ones leading up to one, are different in women. This led to doctors not recognising or dismissing the early symptoms in women.Â </p>
<p>Â </p>
<p>F: I was reading that women are also subject to chronic pain much more than men: for example migraines, and pain related to endometriosis. But there is extensive evidence now of doctors dismissing womenâ€™s pain, as either imaginary, or â€œinevitableâ€, like it is a normal state of being and does not need a cure at all.Â </p>
<p>Â </p>
<p>The failure of the medical community as a whole to recognise this obvious bias up to the 21st century is an example of how insidious the problem of bias is.</p>
<p>Â </p>
<p>There are 3 fundamental types of bias:Â </p>
<p>Â </p>
<ol><li>One: Stochastic drift: you train your model on a dataset, and you validate the model on a split of the training set. When you apply your model out in the world, you systematically add bias in the predictions due to the training data being too specific</li>
<li>Two: The bias in the model, introduced by your choice of the parameters of your model.Â Â </li>
<li>Three: The bias in your training sample: people put training samples together, and people have culture, experience, and prejudice. As we will see today, this is the most dangerous and subtle bias. Today weâ€™ll talk about this bias.</li>
</ol><p>Â </p>
<p>Bias is a warping of our understanding of reality. We see reality through the lens of our experience and our culture. The origin of bias can date back to traditions going back centuries, and is so ingrained in our way of thinking, that we donâ€™t even see it anymore.Â </p>
<p>Â </p>
<p>F: And let me add, when it comes to machine learning, we see reality through the lens of data. Bias is everywhere, and we could spend hours and hours talking about it. Itâ€™s complicated.Â </p>
<p>Â </p>
<p>Itâ€™s about to become more complicated.Â </p>
<p>Â </p>
<p>F: of course, if I know youâ€¦<br>
Letâ€™s throw artificial intelligence in the mix.Â </p>
<p>Â </p>
<p>F: You know, there was a happier time when this sentence didnâ€™t fill me with a sense of dread...Â <br>
ImageNet is an online database of over 14 million photos, compiled more than a decade ago at Stanford University. They used it to train machine learning algorithms for image recognition and computer vision, and played an important role in the rise of deep learning. Weâ€™ve all played with it, right? The cats and dogs classifier when learning Tensorflow? (I am a dog by the way. )</p>
<p>Â </p>
<p>F: ImageNet has been a critical asset for computer-vision research. There was an annual international competition to create algorithms that could most accurately label subsets of images. <br>
In 2012, a team from the University of Toronto used a Convolutional Neural Network to handily win the top prize. That moment is widely considered a turning point in the development of contemporary AI. The final year of the ImageNet competition was 2017, and accuracy in classifying objects in the limited subset had risen from 71% to 97%.Â But that subset did not include the â€œPersonâ€ category, where the accuracy was much lower...Â <br>
ImageNet contained photos of thousands of people, with labels. This included straightforward tags like â€œteacher,â€ â€œdancerâ€ and â€œplumberâ€, as well as highly charged labels like â€œfailure, loserâ€ and â€œslut, slovenly woman, trollop.â€</p>
<p>Â </p>
<p>F: Uh Oh.Â <br>
Then â€œImageNet Rouletteâ€ was created, by an artist called Trevor Paglen and a Microsoft researcher named Kate Crawford. It was a digital art project, where you could upload your photo and let the classifier identify you, based on the labels of the database. Imagine how well that went.Â </p>
<p>Â </p>
<p>F: I bet it didâ€™t work<br>
Of course it didnâ€™t work. Random people were classified as â€œorphansâ€ or â€œnon-smokerâ€ or â€œalcoholicâ€. Somebody with glasses was a â€œnerdâ€.Â Tabong Kima, a 24-year old African American, was classified as â€œoffenderâ€ and â€œwrongdoerâ€.Â </p>
<p>Â </p>
<p>F: and there it is.Â <br>
Quote from Trevor Paglen: â€œWe want to show how layers of bias and racism and misogyny move from one system to the next. The point is to let people see the work that is being done behind the scenes, to see how we are being processed and categorized all the time.â€</p>
<p>Â </p>
<p>F: The ImageNet labels were applied by thousands of unknown people, most likely in the United States, hired by the team from Stanford, and working through the crowdsourcing service Amazon Mechanical Turk. They earned pennies for each photo they labeled, churning through hundreds of labels an hour. The labels were not verified in any way : if a labeler thought someone looks â€œshadyâ€, this label is just a result of their prejudice, but has no basis in reality.<br>
As they did, biases were baked into the database. Paglen quote again: â€œThe way we classify images is a product of our worldview,â€ he said. â€œAny kind of classification system is always going to reflect the values of the person doing the classifying.â€ They defined what a â€œloserâ€ looked like. And a â€œslut.â€ And a â€œwrongdoer.â€</p>
<p>Â </p>
<p>F: The labels originally came from another sprawling collection of data called WordNet, a kind of conceptual dictionary for machines built by researchers at Princeton University in the 1980s. But with these inflammatory labels included, the Stanford researchers may not have realized what they were doing.<br>
What is happening here is the transferring of bias from one system to the next.Â </p>
<p>Â </p>
<p>Tech jobs, in past decades but still today, predominantly go to white males from a narrow social class. Inevitably, they imprint the technology with their worldview.Â So their algorithms learn that a person of color is a criminal, and a woman with a certain look is a slut.Â </p>
<p>Â </p>
<p>Iâ€™m not saying they do it on purpose, but the lack of diversity in the tech industry translates into a narrower world view, which has real consequences in the quality of AI systems.Â </p>
<p>Â </p>
<p>F: Diversity in tech teams is often framed as an equality issue (which of course it is), but there are enormous advantages in it: it allows to create that cognitive diversity that will reflect into superior products or services. <br>
I believe this is an ongoing problem. In recent months, researchers have shown that face-recognition services from companies like Amazon, Microsoft and IBM can be biased against women and people of color.Â </p>
<p>Â </p>
<p>Crawford and Paglen argue this: <br>
â€œIn many narratives around AI it is assumed that ongoing technical improvements will resolve all problems and limitations. <br>
But what if the opposite is true? What if the challenge of getting computers to â€œdescribe what they seeâ€ will always be a problem? The automated interpretation of images is an inherently social and political project, rather than a purely technical one. Understanding the politics within AI systems matters more than ever, as they are quickly moving into the architecture of social institutions: deciding whom to interview for a job, which students are paying attention in class, which suspects to arrest, and much else.â€</p>
<p>Â </p>
<p>F: You are using the words â€œinterpretation of imagesâ€ here, as opposed to â€œdescriptionâ€ or â€œclassificationâ€. Certain images depict something concrete, with an objective reality. Like an apple. But other imagesâ€¦ not so much?Â </p>
<p>Â </p>
<p>ImageNet contain images only corresponding to nouns (not verbs for example). Noun categories such as â€œappleâ€ are well defined. <br>
But not all nouns are created equal. Linguist George Lakoff points out that the concept of an â€œappleâ€ is more nouny than the concept of â€œlightâ€, which in turn is more nouny than a concept such as â€œhealth.â€ <br>
Nouns occupy various places on an axis from concrete to abstract, and from descriptive to judgmental. The images corresponding to these nouns become more and more ambiguous.<br>
These gradients have been erased in the logic of ImageNet. Everything is flattened out and pinned to a label. <br>
The results can be problematic, illogical, and cruel, especially when it comes to labels applied to people.Â </p>
<p>Â </p>
<p>F: so when an image is interpreted as Drug Addict, Crazy, Hypocrite, Spinster, Schizophrenic, Mulatto, Red Neckâ€¦ this is not an objective description of reality, itâ€™s somebodyâ€™s worldview coming to the surface. <br>
The selection of images for these categories skews the meaning in ways that are gendered, racialized, ableist, and ageist. ImageNet is an object lesson in what happens when people are categorized like objects. <br>
And this practice has only become more common in recent years, often inside the big AI companies, where there is no way for outsiders to see how images are being ordered and classified.Â </p>
<p>Â </p>
<p>The bizarre thing about these systems is that they remind of early 20th century criminologists like Lombroso, or phrenologists (including Nazi scientists), and physiognomy in general. This was a discipline founded on the assumption that there is a relationship between an image of a person and the character of that person. If you are a murderer, or a Jew, the shape of your head for instance will tell.Â </p>
<p>Â </p>
<p>F: In reaction to these ideas, Reneâ€™ Magritte produced that famous painting of the pipe with the tag â€œThis is not a pipeâ€.</p>
<p>Â </p>
<p>You know that famous photograph of the soldier kissing the nurse at the end of the second world war? The nurse came public about it when she was like 90 years old, and told how this total stranger in the street had grabbed her and kissed her. This is a picture of sexual harassment. And knowing that, it does not seem romantic anymore.Â </p>
<p>Â </p>
<p>F: not romantic at all indeed<br>
<br>
Images do not describe themselves. This is a feature that artists have explored for centuries. We see those images differently when we see how theyâ€™re labeled. The correspondence between image, label, and referent is fluid. Whatâ€™s more, those relations can change over time as the cultural context of an image shifts, and can mean different things depending on who looks, and where they are located. Images are open to interpretation and reinterpretation. Entire subfields of philosophy, art history, and media theory are dedicated to teasing out all the nuances of the unstable relationship between images and meanings.<br>
The common mythos of AI and the data it draws on, is that they are objectively and scientifically classifying the world. But itâ€™s not true, everywhere there is politics, ideology, prejudices, and all of the subjective stuff of history.Â </p>
<p>Â </p>
<p>F: When we survey the most widely used training sets, we find that this is the rule rather than the exception.<br>
Training sets are the foundation on which contemporary machine-learning systems are built. They are central to how AI systems recognize and interpret the world.<br>
By looking at the construction of these training sets and their underlying structures, we discover many unquestioned assumptions that are shaky and skewed. These assumptions inform the way AI systems workâ€”and failâ€”to this day.<br>
And the impenetrability of the algorithms, the impossibility of reconstructing the decision-making of a NN, hides the bias further away from scrutiny. When an algorithm is a black box and you canâ€™t look inside, you have no way of analysing its bias.Â </p>
<p>Â </p>
<p>And the skewness and bias of these algorithms have real effects in society, the more you use AI in the judicial system, in medicine, the job market, in security systems based on facial recognition, the list goes on and on.Â </p>
<p>Â </p>
<p>Last year Google unveiled BERT (Bidirectional Encoder Representations from Transformers). Itâ€™s an AI system that learns to talk: itâ€™s a Natural Language Processing engine to generate written (or spoken) language.Â </p>
<p>Â </p>
<p>F: we have an <a href='https://datascienceathome.com/more-powerful-deep-learning-with-transformers/'>episode</a> Â in which we explain all that </p>
<p>Â </p>
<p><br>
They trained it from lots and lots of digitized information, as varied as old books, Wikipedia entries and news articles. They baked decades and even centuries of biases â€” along with a few new ones â€” into all that material. So for instance BERT is extremely sexist: it associates with male almost all professions and positive attributes (except for â€œmomâ€).Â </p>
<p>Â </p>
<p>BERT is widely used in industry and academia. For example it can interpret news headlines automatically. Even Googleâ€™s search engine use it.Â </p>
<p>Â </p>
<p>Try googling â€œCEOâ€, and you get out a gallery of images of old white men.</p>
<p>Â </p>
<p>F: such a pervasive and flawed AI system can propagate inequality at scale. And itâ€™s super dangerous because itâ€™s subtle. Especially in industry, query results will not be tested and examined for bias. AI is a black box and researchers take results at face value.Â </p>
<p>Â </p>
<p>There are many cases of algorithm-based discrimination in the job market. Targeting candidates for tech jobs for instance, may be done by algorithms that will not recognise women as potential candidates. Therefore, they will not be exposed to as many job ads as men. Or, automated HR systems will rank them lower (for the same CV) and screen them out.Â </p>
<p>Â </p>
<p>In the US, algorithms are used to calculate bail. The majority of the prison population in the US is composed of people of colour, as a result of a systemic bias that goes back centuries. An algorithm learns that a person of colour is more likely to commit a crime, is more likely to not be able to afford bail, is more likely to violate parole. Therefore, people of colour will receive harsher punishments for the same crime. This amplifies this inequality at scale.Â </p>
<p>Â </p>
Conclusion
<p>Â </p>
<p>Question everything, never take predictions of your models at face value. Always question how your training samples have been put together, who put them together, when and in what context. Always remember that your model produces an interpretation of reality, not a faithful depiction.Â <br>
Treat reality responsibly.Â </p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/srsnrc/episode4-TDSAI.mp3" length="39242106" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Â 
This is the fourth and last episode of mini series "The dark side of AI". I am your host Francesco and Iâ€™m with Chiara Tonini from London. The title of todayâ€™s episode is Bias in the machineÂ 
Â 
Â 
C: Francesco, today we are starting with an infuriating discussion. Are you ready to be angry?Â 
Â 
F: yeah sure is this about brexit?Â No, I donâ€™t talk about that. In 1986 the New York Cityâ€™s Rockefeller University conducted a study on breast and uterine cancers and their link to obesity. Like in all clinical trials up to that point, the subjects of the study were all men.Â So Francesco, do you see a problem with this approach?Â 
Â 
F: No problem at all, as long as those men had a perfectly healthy uterus.In medicine, up to the end of the 20th century, medical studies and clinical trials were conducted on men, medicine dosage and therapy calculated on men (white men). The female body has historically been considered an exception, or variation, from a male body.Â 
Â 
F: Like Eve coming from Adamâ€™s rib. I thought we were past that...When the female body has been under analysis, the focus was on the difference between it and the male body, the so-called â€œbikini approachâ€: the reproductive organs are different, therefore we study those, and those only. For a long time medicine assumed this was the only difference.Â 
Â 
Oh goodÂ ...This has led to a hugely harmful fallout across society. Because women had reproductive organs, they should reproduce, and all else about them was deemed uninteresting. Still today, they consider a woman without children somehow to have betrayed her biological destiny. This somehow does not apply to a man without children, who also has reproductive organs.Â 
Â 
F: so this is an example of a very specific type of bias in medicine, regarding clinical trials and medical studies, that is not only harmful for the purposes of these studies, but has ripple effects in all of societyOnly in the 2010 a serious conversation has started about the damage caused by not including women in clinical trials. There are many many examples (which we list in the references for this episode).Â 
Â 
Give me oneResearchers consider cardiovascular disease a male disease - they even call it â€œthe widowerâ€. They conduct studies on male samples. But it turns out, the symptoms of a heart attack, especially the ones leading up to one, are different in women. This led to doctors not recognising or dismissing the early symptoms in women.Â 
Â 
F: I was reading that women are also subject to chronic pain much more than men: for example migraines, and pain related to endometriosis. But there is extensive evidence now of doctors dismissing womenâ€™s pain, as either imaginary, or â€œinevitableâ€, like it is a normal state of being and does not need a cure at all.Â 
Â 
The failure of the medical community as a whole to recognise this obvious bias up to the 21st century is an example of how insidious the problem of bias is.
Â 
There are 3 fundamental types of bias:Â 
Â 
One: Stochastic drift: you train your model on a dataset, and you validate the model on a split of the training set. When you apply your model out in the world, you systematically add bias in the predictions due to the training data being too specific
Two: The bias in the model, introduced by your choice of the parameters of your model.Â Â 
Three: The bias in your training sample: people put training samples together, and people have culture, experience, and prejudice. As we will see today, this is the most dangerous and subtle bias. Today weâ€™ll talk about this bias.
Â 
Bias is a warping of our understanding of reality. We see reality through the lens of our experience and our culture. The origin of bias can date back to traditions going back centuries, and is so ingrained in our way of thinking, that we donâ€™t even see it anymore.Â 
Â 
F: And let me add, when it comes to machine learning, we see reality through the lens of data. Bias is everywhere, and we could spend hours and hours talking about it. Itâ€™]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:26</itunes:duration>
                <itunes:episode>89</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>The dark side of AI: metadata and the death of privacy (Ep. 91)</title>
        <itunes:title>The dark side of AI: metadata and the death of privacy (Ep. 91)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-metadata-and-the-death-of-privacy-ep-91/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-metadata-and-the-death-of-privacy-ep-91/#comments</comments>        <pubDate>Mon, 23 Dec 2019 15:30:01 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/a5f467d2-1614-5b25-982b-bbb84e7049da</guid>
                                    <description><![CDATA[


Get in touch with us






Join the discussion about data science, machine learning and artificial intelligenceÂ on our <a href='https://discord.gg/4UNKGf3'>Discord server</a>



Â 
Episode transcript
<p>We always hear the word â€œmetadataâ€, usually in a sentence that goes like this</p>
<p>Â </p>

<p>Your Honor, I swear, we were not collecting users data, just metadata.</p>

<p>Â </p>
<p>Usually the guy saying this sentence is Zuckerberg, but could be anybody from Amazon or Google.Â â€œJustâ€ metadata, so no problem. This is one of the biggest lies about the reality of data collection.</p>
<p>Â </p>
<p>F: Ok the first question is, what the hell is metadata?Â </p>
<p>Â </p>
<p>Metadata is data about data.Â </p>
<p>Â </p>
<p>F: Okâ€¦ still not clear.
Imagine you make a phone call to your mum. How often do you call your mum, Francesco?

F: Every day of course! (coughing)</p>
<p>Â </p>
<p>Good boy! Ok, so letâ€™s talk about todayâ€™s phone call. Letâ€™s call â€œdataâ€ the stuff that you and your mum actually said. What did you talk about?Â </p>
<p>Â </p>
<p>
F: She was giving me the recipe for her famous lasagna.Â </p>
<p>So your mumâ€™s lasagna is the DATA. What is the metadata of this phone call? The lasagna has data of its own attached to it: the date and time when the conversation happened, the duration of the call, the unique hardware identifiers of your phone and your mumâ€™s phone, the identifiers of the two sim cards, the location of the cell towers that pinged the call, the GPS coordinates of the phones themselves.Â </p>
<p>Â </p>
<p>
F: yeah well, this lasagna comes with a lot of data :)Â </p>
<p>And this is assuming that this data is not linked to any other data like your Facebook account or your web browsing history. More of that later.Â </p>
<p>Â </p>
<p>
F: Whoa Whoa Whoa, ok. Letâ€™s put a pin in that. Going back to the â€œbasicâ€ metadata that you describe. I think we understand the concept of data about data. I am sure you did your research and you would love to paint me a dystopian nightmare, as always. Tell us why is this a big deal?Â </p>
<p>Â </p>
<p>
Metadata is a very big deal. In fact, metadata is far more â€œusefulâ€ than the actual data, where by â€œusefulâ€ I mean that it allows a third party to learn about you and your whole life. What I am saying is, the fact that you talk with your mum every day for 15 minutes is telling me more about you than the content of the actual conversations. In a way, the content does not matter. Only the metadata matters.Â </p>
<p>Â </p>
<p>
F: Ok, can you explain this point a bit more?Â </p>
<p>Â </p>
<p>Imagine this scenario: you work in an office in Brussels, and you go by car. Every day, you use your time in the car while you go home to call your mum. So every day around 6pm, a cell tower along the path from your office to your home pings a call from your phone to your mumâ€™s phone. Someone who is looking at your metadata, knows exactly where you are while you call your mum. Every day you will talk about something different, and it doesn't really matter.Â  Your location will come through loud and clear. A lot of additional information can be deduced from this too: for example, you are moving along a motorway, therefore you have a car. The metadata of a call to mum now becomes information on where you are at 6pm, and the way you travel.Â </p>
<p>Â </p>
<p>
F: I see. So metadata about the phone call is, in fact, real data about me.Â </p>
<p>Â </p>
<p>Exactly. YOU are what is interesting, not your mumâ€™s lasagna.</p>
<p>Â </p>
<p>
F: you say so because you havenâ€™t tried my mumâ€™s lasagna. But I totally get your point.</p>
<p>Â </p>
<p>
Now, imagine that one day, instead of going straight home, you decide to go somewhere else. Maybe you are secretly looking for another job. Your metadata is recording the fact that after work you visit the offices of a rival company. Maybe you are a journalist and you visit your anonymous source. Your metadata records wherever you go, and one of these places is your secret meeting with your source.Â Anyoneâ€™s metadata can be combined with yours. There will be someone who was with you at the time and place of your secret meeting. Anyone who comes in contact with you can be tagged and monitored. Now their anonymity has been reduced.Â </p>
<p>Â </p>
<p>
F: I get it. So, compared to the content of my conversation, its metadata contains more actionable information. And this is the most useful, and most precious, kind of information about me. What I do, what I like, who I am, beyond the particular conversation.Â </p>
<p>Â </p>
<p>
Precisely. If companies like <a href='http://facebook.com'>Facebook</a> or the phone companies had the explicit permission to collect all the usersâ€™ data, including all content of conversations, itâ€™s still the metadata that wouldÂ  generate the most actionable information. They would probably throw the content of conversations away. In the vast majority of instances, the content does not matter. Unless you are an actual spy talking about state secrets, nobody cares.Â </p>
<p>Â </p>
<p>
F: Letâ€™s stay on the spy point for a minute. One could say, So what? As I have heard this many times. So what if my metadata contains actionable information, and there are entities that collect it. If I am an honest person, I have nothing to hide.Â </p>
<p>Â </p>
<p>
There are two aspects to the problem of privacy. Government surveillance, and corporate - in other words private - surveillance.Â 
Government surveillance is a topic that has been covered flawlessly by Edward Snowden in his book <a href='https://www.amazon.com/Permanent-Record-Edward-Snowden/dp/1250237238'>â€œPermanent Recordâ€</a>, and in the documentary about his activity, â€œCitizenfourâ€. Which I both recommend, and in fact I think every data scientist should read and watch. 
Letâ€™s just briefly mention the obvious: just because something comes from a government, it does not mean itâ€™s legal or legitimate, or even ethical or moral. What if your government is corrupt, or authoritarian. What if you are a dissident and you are fighting for human rights. What if you are a journalist, trying to uncover government corruption.Â </p>
<p>Â </p>
<p>
F: In other words,Â  it is a false equivalence to say that protecting your privacy has anything to do with having something to hide.</p>
<p>Â </p>
<p>
Mass surveillance of private citizens without cause is a danger to individual freedom as well as civil liberties. Government exists to serve its citizens, not the other way around. To freely paraphrase Snowden, as individuals have no power compared to the government, the only way the system works is if the government is completely transparent to the citizens, so that they can collectively change it, and at the same time the single citizens are opaque to the government, so that it cannot abuse its power. But today the opposite happens: we citizens are completely naked and exposed in front of a completely opaque government machine, with secret surveillance programs on us, that we donâ€™t even know exist. We are not free to self-determine, or do anything about government power, really.</p>
<p>Â </p>
<p>Â 
F: We could really talk for days and days about government mass surveillance. But letâ€™s go back to metadata, and letâ€™s talk about the commercial use of it. Metadata for sale. You mentioned this term, â€œcorporate surveillanceâ€. It soundsâ€¦. Ominous.Â </p>
<p>Â </p>
<p>
We live in privacy hell, Francesco.Â </p>
<p>Â </p>
<p>
F: I get that. According to your research, where can we find metadata?Â Â </p>
<p>Â </p>
<p>
First of all, metadata is everywhere. We are swimming in it. In each and every interaction between two people, that make use of digital technology, metadata is generated automatically, without the userâ€™s consent. When two people interact, two machines also interact, recording the â€œcontextâ€ of this interaction. Who we are, when, where, why, what we want. 

F: And that doesnâ€™t seem avoidable. In fact metadata must be generated by devices and software to just work properly. I look at it as an intrinsic component that cannot be removed from the communication system, whatever it is. The problem is who owns it. So tell me, who has such data?Â </p>
<p>Â </p>
<p>
It does not matter, because itâ€™s all for sale. Which means, we are for sale.Â </p>
<p>Â </p>
<p>
F: Ok, holy s**t, this keeps getting darker. Letâ€™s have a practical example, shall we?Â </p>
<p>Â </p>
<p>
Have you booked a flight recently?Â </p>
<p>Â </p>
<p>
F: Yep. Iâ€™m going to Berlin, and in fact so are you. For a hackathon, no less.Â </p>
<p>Â </p>
<p>
Have you ever heard of a company called <a href='https://adara.com/'>Adara</a>?Â </p>
<p>Â </p>
<p>
F: Noâ€¦ Cannot say that I have.Â </p>
<p>Â </p>
<p>
Adara is a â€œPredictive Traveler Intelligenceâ€ company.Â </p>
<p>Â </p>
<p>
F: sounds pretty pretentious. Kinda douchy.Â </p>
<p>Â </p>
<p>
This came up on the terrifying twitter account of Wolfie Christl, author among other things of a great report about corporate surveillance for Cracked Labs. Go check him out on twitter, heâ€™s great.Â </p>
<p>Â </p>
<p>
F: Sure I will add what I find to the show notes of this episode. Oh and by the way you can find all this stuff on datascienceathome.com 
Sorry go ahead.Â </p>
<p>Â </p>
<p>
Adara collects data - metadata - about travel-related online searches, purchases, devices, passenger records, loyalty program records. Data from clients that include major airlines, major airports, hotel chains and car rental chains. It creates a profile, a â€œtraveler graphâ€ in real time, for 750 million people around the world. A profile based on personal identifiers.Â </p>
<p>Â </p>
<p>F: uhh uhh Then what?</p>
<p>Â </p>
<p>
Then Adara sells these profiles.Â </p>
<p>Â </p>
<p>
F: Okâ€¦ I have to say, the box that I tick giving consent to the third-party use of my personal data when I use an airline website does not quite convey how far my data actually goes.Â </p>
<p>Â </p>
<p>
Consent. LOL.Â Adara calculates a: â€œtraveler value scoreâ€ based on customer behaviour and needs across the global travel ecosystem, over time.</p>
<p>Â </p>
<p>The score is in the Salesforce Service Cloud, for sale to anyone.Â 
This score, and your profile, determine the personalisation of travel offers and treatment, before purchase, during booking, post purchase, at check in, in airport, at destination.Â 
In their own website, Adara explains how customer service agents for their myriad of clients - for example a front desk agent at a hotel - can instantly see the Traveler value score. Therefore they will treat you differently based on this score.Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p>
F: Oh so if you have money to spend they will treat you differently</p>
<p>Â </p>
<p>
The score is used to assess your potential value, to inform service and customer service strategies for you, as well as personalised messaging and relevant offers. And of course, the pricing you see when you look for flights.Â Low score? Prepare yourself to wait to have your call rerouted to a customer service agent.Â Would you ever tick a box to give consent to this?Â </p>
<p>Â </p>
<p>
F: Fuck no. How is this even legal? What about the GDPR?Â </p>
<p>Â </p>
<p>
It is, in fact, illegal. Adara is based in the US, but they collect data through data warehouses in the Netherlands. They claim they are GDPR-compliant.Â However, they collect all the data, and then decide on the specific business use, which is definitely not GDPR compliant.Â </p>
<p>Â </p>
<p>
F: exactly! According to GDPR the user has to know in advance what the business use of the data they are giving consent for!!
With GDPR and future regulations, there is a way to control how the data is used and with what purpose. Regulations are still blurred or undefined when it comes to metadata. For example, thereâ€™s no regulation for the number of records in a database or the timestamp when such recordÂ  was created. As a matter of fact data is useless without metadata.Â </p>
<p>Â </p>
<p>
One cannot even collect data without metadata.Â </p>
<p>Â </p>
<p>
Whatsapp, telegram, Facebook messenger... they all create metadata. So one might say â€œIâ€™ve got end-to-end encryption, buddyâ€. Sure thing. How about the metadata attached to that encrypted gibberish nobody is really interested in?Â To show you how unavoidable the concept of metadata is, even Signal developed by the Signal Foundation which is considered the truly end-to-end and open source protocol for confidential information exchange, can see metadata. At Signal they claim they just donâ€™t keep it, as they also state in the Signalâ€™s privacy policy.</p>
<p>Â </p>
<p>
"Certain information (e.g. a recipient's identifier, an encrypted message body, etc.) is transmitted to us solely for the purpose of placing calls or transmitting messages. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose." 
This is one of those issues that shall be solved with legislation.</p>
<p>Â </p>
<p>But like money laundering, your data is caught in a storm of transactions so intricate that at a certain point, how do you even check...
All participating companies share customer data with each other (a process called value exchange). They let marketers utilize the data, for example to target people after they have searched for flights or hotels. Adara creates audience segments and sells them, for example to Google, for advertisement targeting.Â The consumer data broker LiveRamp for example lists Adara as a data provider.Â </p>
<p>Â </p>
<p>
F: consumer data broker. I am starting to get what you mean when you say that we are for sale.Â </p>
<p>Â </p>
<p>
Letâ€™s talk about LiveRamp, part of Acxiom.Â </p>
<p>Â </p>
<p>
F: there they go... Acxiom... I heard of themÂ </p>
<p>Â </p>
<p>
They self-describe as an â€œIdentity Resolution Platformâ€.Â </p>
<p>Â </p>
<p>
F: I mean, George Orwell would be proud.Â </p>
<p>Â </p>
<p>
Their mission? â€œTo connect offline data and online data back to a single identifierâ€. In other words, clients can â€œresolve allâ€ of their â€œoffline and online identifiers back to the individual consumerâ€. 
Various digital profiles, like the ones generated on social media or when you visit a website,Â are matched to databases which contains names, postal addresses, email addresses, phone numbers, geo locations and IP addresses, online and mobile identifiers, such as cookie and device IDs. 

F: well, all this stuff is possible if and only if someone gets in possession of all these profiles, or well... they purchase them. Still, what the f**k.Â </p>
<p>Â </p>
<p>
A cute example? Imagine you register on any random website but you donâ€™t want to give them your home address. They just buy it from LiveRamp, which gets it from your phone geolocation data - which is for sale. Where does your phone sit still for 12 hours every night? Thatâ€™s your home address. Easy.</p>
<p>Â </p>
<p>
F: And they definitely know how much time do I spend at the gym, without even checking my Instagram! Ok this is another level of creepy.Â </p>
<p>Â </p>
<p>
Clients of LiveRamp can upload their own consumer data to the platform, combine it with data from hundreds of 100 third-party data providers, and then utilize it on more than 500 marketing technology platforms.Â They can use this data to find and target people with specific characteristics, to recognize and track consumers across devices and platforms, to profile and categorize them, to personalize content for them, and to measure how they behave. For example, clients could â€œrecognize a website visitorâ€ and â€œprovide a customized offerâ€ based on extensive profile data, without requiring said user to log in to the website. Furthermore, LiveRamp has a data store, for other companies to â€œbuy and sell valuable customer dataâ€.Â </p>
<p>Â </p>
<p>
F: What is even the point of giving me the choice to consent to anything online?</p>
<p>Â </p>
<p>
In short, there is no point.Â </p>
<p>Â </p>
<p>
F: it seems we are so behind with regulations on data sharing. GDPR is not cutting it, not really. With programmatic advertising we have created a monster that has really grown out of control. 
So: our lives are completely transparent to private corporations, that constantly surveil us en-masse, and exploit all of our data to sell us shit. How does this affect our freedom? How about we just donâ€™t buy it? Can it be that simple? And I would not take a no for an answer here.</p>
<p>Â </p>
<p>Unfortunately, no.Â </p>
<p>Â </p>
<p>
F:Â  oh crap!</p>
<p>Â </p>
<p>Iâ€™m going to read you a passage from Permanent Record:Â Â </p>
<p>Â </p>
<p>Who among us can predict the future? Who would dare to? 
The answer to the first question is no one, really, and the answer to the second is everyone, especially every government and business on the planet. This is what that data of ours is used for. Algorithms analyze it for patterns of established behaviour in order to extrapolate behaviours to come, a type of digital prophecy thatâ€™s only slightly more accurate that analog methods like palm reading. Once you go digging into the actual technical mechanisms by which predictability is calculated, you come to understand that its science is, in fact, anti-scientific, and fatally misnamed: predictability is actually manipulation. </p>
<p>Â </p>
<p>
A website that tells you that because you liked book 1 then you might also like book 2, isnâ€™t offering an educated guess as much as a mechanism of subtle coercion.Â We canâ€™t allow ourselves to be used in this way, to be used against the future. We canâ€™t permit our data to be used to sell us the very things that must not be sold, such as journalism. [....] 
We canâ€™t let the god-like surveillance weâ€™re under be used to â€œcalculateâ€ our citizenship scores, or to â€œpredictâ€ our criminal activity; to tell us what kind of education we can have, or what kind of job we can have [...], to discriminate against us based on our financial, legal, and medical histories, not to mention our ethnicity or race, which are constructs that data often assumes or imposes. </p>
<p>Â </p>
<p>
[...] if we allow [our data] to be used to identify us, then it will be used to victimize us, even to modify us - to remake the very essence of our humanity in the image of the technology that seeks its control. Of course, all of the above has already happened.Â </p>
<p>Â </p>
<p>F: In other words, we are surveilled and our data collected, and used to affect every aspect of our lives - what we read, what movies we watch, where we travel, what we buy, who we date, what we study, where we workâ€¦ This is a self-fulfilling prophecy for all of humanity, and the prophet is a stupid, imperfect algorithm optimised just to make money. 
So I guess my message of today for all Data Scientists out there is this: justâ€¦ don't.Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
References
<p>Â </p>
<ul><li><a href='https://github.com/signalapp'>https://github.com/signalapp</a></li>
</ul>
<p>Â </p>
<ul><li>Wolfie Christl reportÂ <a href='https://crackedlabs.org/en/corporate-surveillance'>https://crackedlabs.org/en/corporate-surveillance</a></li>
</ul>
<p>Â </p>
<ul><li><a href='http://t.co/ahT9a35M9P?amp=1'>wolfie.crackedlabs.org</a></li>
</ul>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[


Get in touch with us






Join the discussion about data science, machine learning and artificial intelligenceÂ on our <a href='https://discord.gg/4UNKGf3'>Discord server</a>



Â 
Episode transcript
<p>We always hear the word â€œmetadataâ€, usually in a sentence that goes like this</p>
<p>Â </p>

<p>Your Honor, I swear, we were not collecting users data, just metadata.</p>

<p>Â </p>
<p>Usually the guy saying this sentence is Zuckerberg, but could be anybody from Amazon or Google.Â â€œJustâ€ metadata, so no problem. This is one of the biggest lies about the reality of data collection.</p>
<p>Â </p>
<p>F: Ok the first question is, what the hell is metadata?Â </p>
<p>Â </p>
<p>Metadata is data about data.Â </p>
<p>Â </p>
<p>F: Okâ€¦ still not clear.<br>
Imagine you make a phone call to your mum. How often do you call your mum, Francesco?<br>
<br>
F: Every day of course! (coughing)</p>
<p>Â </p>
<p>Good boy! Ok, so letâ€™s talk about todayâ€™s phone call. Letâ€™s call â€œdataâ€ the stuff that you and your mum actually said. What did you talk about?Â </p>
<p>Â </p>
<p><br>
F: She was giving me the recipe for her famous lasagna.Â </p>
<p>So your mumâ€™s lasagna is the DATA. What is the metadata of this phone call? The lasagna has data of its own attached to it: the date and time when the conversation happened, the duration of the call, the unique hardware identifiers of your phone and your mumâ€™s phone, the identifiers of the two sim cards, the location of the cell towers that pinged the call, the GPS coordinates of the phones themselves.Â </p>
<p>Â </p>
<p><br>
F: yeah well, this lasagna comes with a lot of data :)Â </p>
<p>And this is assuming that this data is not linked to any other data like your Facebook account or your web browsing history. More of that later.Â </p>
<p>Â </p>
<p><br>
F: Whoa Whoa Whoa, ok. Letâ€™s put a pin in that. Going back to the â€œbasicâ€ metadata that you describe. I think we understand the concept of data about data. I am sure you did your research and you would love to paint me a dystopian nightmare, as always. Tell us why is this a big deal?Â </p>
<p>Â </p>
<p><br>
Metadata is a very big deal. In fact, metadata is far more â€œusefulâ€ than the actual data, where by â€œusefulâ€ I mean that it allows a third party to learn about you and your whole life. What I am saying is, the fact that you talk with your mum every day for 15 minutes is telling me more about you than the content of the actual conversations. In a way, the content does not matter. Only the metadata matters.Â </p>
<p>Â </p>
<p><br>
F: Ok, can you explain this point a bit more?Â </p>
<p>Â </p>
<p>Imagine this scenario: you work in an office in Brussels, and you go by car. Every day, you use your time in the car while you go home to call your mum. So every day around 6pm, a cell tower along the path from your office to your home pings a call from your phone to your mumâ€™s phone. Someone who is looking at your metadata, knows exactly where you are while you call your mum. Every day you will talk about something different, and it doesn't really matter.Â  Your location will come through loud and clear. A lot of additional information can be deduced from this too: for example, you are moving along a motorway, therefore you have a car. The metadata of a call to mum now becomes information on where you are at 6pm, and the way you travel.Â </p>
<p>Â </p>
<p><br>
F: I see. So metadata about the phone call is, in fact, real data about me.Â </p>
<p>Â </p>
<p>Exactly. YOU are what is interesting, not your mumâ€™s lasagna.</p>
<p>Â </p>
<p><br>
F: you say so because you havenâ€™t tried my mumâ€™s lasagna. But I totally get your point.</p>
<p>Â </p>
<p><br>
Now, imagine that one day, instead of going straight home, you decide to go somewhere else. Maybe you are secretly looking for another job. Your metadata is recording the fact that after work you visit the offices of a rival company. Maybe you are a journalist and you visit your anonymous source. Your metadata records wherever you go, and one of these places is your secret meeting with your source.Â Anyoneâ€™s metadata can be combined with yours. There will be someone who was with you at the time and place of your secret meeting. Anyone who comes in contact with you can be tagged and monitored. Now their anonymity has been reduced.Â </p>
<p>Â </p>
<p><br>
F: I get it. So, compared to the content of my conversation, its metadata contains more actionable information. And this is the most useful, and most precious, kind of information about me. What I do, what I like, who I am, beyond the particular conversation.Â </p>
<p>Â </p>
<p><br>
Precisely. If companies like <a href='http://facebook.com'>Facebook</a> or the phone companies had the explicit permission to collect all the usersâ€™ data, including all content of conversations, itâ€™s still the metadata that wouldÂ  generate the most actionable information. They would probably throw the content of conversations away. In the vast majority of instances, the content does not matter. Unless you are an actual spy talking about state secrets, nobody cares.Â </p>
<p>Â </p>
<p><br>
F: Letâ€™s stay on the spy point for a minute. One could say, So what? As I have heard this many times. So what if my metadata contains actionable information, and there are entities that collect it. If I am an honest person, I have nothing to hide.Â </p>
<p>Â </p>
<p><br>
There are two aspects to the problem of privacy. Government surveillance, and corporate - in other words private - surveillance.Â <br>
Government surveillance is a topic that has been covered flawlessly by Edward Snowden in his book <a href='https://www.amazon.com/Permanent-Record-Edward-Snowden/dp/1250237238'>â€œPermanent Recordâ€</a>, and in the documentary about his activity, â€œCitizenfourâ€. Which I both recommend, and in fact I think every data scientist should read and watch. <br>
Letâ€™s just briefly mention the obvious: just because something comes from a government, it does not mean itâ€™s legal or legitimate, or even ethical or moral. What if your government is corrupt, or authoritarian. What if you are a dissident and you are fighting for human rights. What if you are a journalist, trying to uncover government corruption.Â </p>
<p>Â </p>
<p><br>
F: In other words,Â  it is a false equivalence to say that protecting your privacy has anything to do with having something to hide.</p>
<p>Â </p>
<p><br>
Mass surveillance of private citizens without cause is a danger to individual freedom as well as civil liberties. Government exists to serve its citizens, not the other way around. To freely paraphrase Snowden, as individuals have no power compared to the government, the only way the system works is if the government is completely transparent to the citizens, so that they can collectively change it, and at the same time the single citizens are opaque to the government, so that it cannot abuse its power. But today the opposite happens: we citizens are completely naked and exposed in front of a completely opaque government machine, with secret surveillance programs on us, that we donâ€™t even know exist. We are not free to self-determine, or do anything about government power, really.</p>
<p>Â </p>
<p>Â <br>
F: We could really talk for days and days about government mass surveillance. But letâ€™s go back to metadata, and letâ€™s talk about the commercial use of it. Metadata for sale. You mentioned this term, â€œcorporate surveillanceâ€. It soundsâ€¦. Ominous.Â </p>
<p>Â </p>
<p><br>
We live in privacy hell, Francesco.Â </p>
<p>Â </p>
<p><br>
F: I get that. According to your research, where can we find metadata?Â Â </p>
<p>Â </p>
<p><br>
First of all, metadata is everywhere. We are swimming in it. In each and every interaction between two people, that make use of digital technology, metadata is generated automatically, without the userâ€™s consent. When two people interact, two machines also interact, recording the â€œcontextâ€ of this interaction. Who we are, when, where, why, what we want. <br>
<br>
F: And that doesnâ€™t seem avoidable. In fact metadata must be generated by devices and software to just work properly. I look at it as an intrinsic component that cannot be removed from the communication system, whatever it is. The problem is who owns it. So tell me, who has such data?Â </p>
<p>Â </p>
<p><br>
It does not matter, because itâ€™s all for sale. Which means, we are for sale.Â </p>
<p>Â </p>
<p><br>
F: Ok, holy s**t, this keeps getting darker. Letâ€™s have a practical example, shall we?Â </p>
<p>Â </p>
<p><br>
Have you booked a flight recently?Â </p>
<p>Â </p>
<p><br>
F: Yep. Iâ€™m going to Berlin, and in fact so are you. For a hackathon, no less.Â </p>
<p>Â </p>
<p><br>
Have you ever heard of a company called <a href='https://adara.com/'>Adara</a>?Â </p>
<p>Â </p>
<p><br>
F: Noâ€¦ Cannot say that I have.Â </p>
<p>Â </p>
<p><br>
Adara is a â€œPredictive Traveler Intelligenceâ€ company.Â </p>
<p>Â </p>
<p><br>
F: sounds pretty pretentious. Kinda douchy.Â </p>
<p>Â </p>
<p><br>
This came up on the terrifying twitter account of Wolfie Christl, author among other things of a great report about corporate surveillance for Cracked Labs. Go check him out on twitter, heâ€™s great.Â </p>
<p>Â </p>
<p><br>
F: Sure I will add what I find to the show notes of this episode. Oh and by the way you can find all this stuff on datascienceathome.com <br>
Sorry go ahead.Â </p>
<p>Â </p>
<p><br>
Adara collects data - metadata - about travel-related online searches, purchases, devices, passenger records, loyalty program records. Data from clients that include major airlines, major airports, hotel chains and car rental chains. It creates a profile, a â€œtraveler graphâ€ in real time, for 750 million people around the world. A profile based on personal identifiers.Â </p>
<p>Â </p>
<p>F: uhh uhh Then what?</p>
<p>Â </p>
<p><br>
Then Adara sells these profiles.Â </p>
<p>Â </p>
<p><br>
F: Okâ€¦ I have to say, the box that I tick giving consent to the third-party use of my personal data when I use an airline website does not quite convey how far my data actually goes.Â </p>
<p>Â </p>
<p><br>
Consent. LOL.Â Adara calculates a: <em>â€œtraveler value scoreâ€ based on customer behaviour and needs across the global travel ecosystem, over time.</em></p>
<p>Â </p>
<p>The score is in the Salesforce Service Cloud, for sale to anyone.Â <br>
This score, and your profile, determine the personalisation of travel offers and treatment, before purchase, during booking, post purchase, at check in, in airport, at destination.Â <br>
In their own website, Adara explains how customer service agents for their myriad of clients - for example a front desk agent at a hotel - can instantly see the <em>Traveler value score</em>. Therefore they will treat you differently based on this score.Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
<p><br>
F: Oh so if you have money to spend they will treat you differently</p>
<p>Â </p>
<p><br>
The score is used to assess your potential value, to inform service and customer service strategies for you, as well as personalised messaging and relevant offers. And of course, the pricing you see when you look for flights.Â Low score? Prepare yourself to wait to have your call rerouted to a customer service agent.Â Would you ever tick a box to give consent to this?Â </p>
<p>Â </p>
<p><br>
F: Fuck no. How is this even legal? What about the GDPR?Â </p>
<p>Â </p>
<p><br>
It is, in fact, illegal. Adara is based in the US, but they collect data through data warehouses in the Netherlands. They claim they are GDPR-compliant.Â However, they collect all the data, and then decide on the specific business use, which is definitely not GDPR compliant.Â </p>
<p>Â </p>
<p><br>
F: exactly! According to GDPR the user has to know in advance what the business use of the data they are giving consent for!!<br>
With GDPR and future regulations, there is a way to control how the data is used and with what purpose. Regulations are still blurred or undefined when it comes to metadata. For example, thereâ€™s no regulation for the number of records in a database or the timestamp when such recordÂ  was created. As a matter of fact data is useless without metadata.Â </p>
<p>Â </p>
<p><br>
One cannot even collect data without metadata.Â </p>
<p>Â </p>
<p><br>
Whatsapp, telegram, Facebook messenger... they all create metadata. So one might say â€œIâ€™ve got end-to-end encryption, buddyâ€. Sure thing. How about the metadata attached to that encrypted gibberish nobody is really interested in?Â To show you how unavoidable the concept of metadata is, even Signal developed by the Signal Foundation which is considered the truly end-to-end and open source protocol for confidential information exchange, can see metadata. At Signal they claim they just donâ€™t keep it, as they also state in the Signalâ€™s privacy policy.</p>
<p>Â </p>
<p><br>
"Certain information (e.g. a recipient's identifier, an encrypted message body, etc.) is transmitted to us solely for the purpose of placing calls or transmitting messages. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose." <br>
This is one of those issues that shall be solved with legislation.</p>
<p>Â </p>
<p>But like money laundering, your data is caught in a storm of transactions so intricate that at a certain point, how do you even check...<br>
All participating companies share customer data with each other (a process called value exchange). They let marketers utilize the data, for example to target people after they have searched for flights or hotels. Adara creates audience segments and sells them, for example to Google, for advertisement targeting.Â The consumer data broker LiveRamp for example lists Adara as a data provider.Â </p>
<p>Â </p>
<p><br>
F: consumer data broker. I am starting to get what you mean when you say that we are for sale.Â </p>
<p>Â </p>
<p><br>
Letâ€™s talk about LiveRamp, part of Acxiom.Â </p>
<p>Â </p>
<p><br>
F: there they go... Acxiom... I heard of themÂ </p>
<p>Â </p>
<p><br>
They self-describe as an â€œIdentity Resolution Platformâ€.Â </p>
<p>Â </p>
<p><br>
F: I mean, George Orwell would be proud.Â </p>
<p>Â </p>
<p><br>
Their mission? <em>â€œTo connect offline data and online data back to a single identifierâ€. In other words, clients can â€œresolve allâ€ of their â€œoffline and online identifiers back to the individual consumerâ€. </em><br>
Various digital profiles, like the ones generated on social media or when you visit a website,Â are matched to databases which contains names, postal addresses, email addresses, phone numbers, geo locations and IP addresses, online and mobile identifiers, such as cookie and device IDs. <br>
<br>
F: well, all this stuff is possible if and only if someone gets in possession of all these profiles, or well... they purchase them. Still, what the f**k.Â </p>
<p>Â </p>
<p><br>
A cute example? Imagine you register on any random website but you donâ€™t want to give them your home address. They just buy it from LiveRamp, which gets it from your phone geolocation data - which is for sale. Where does your phone sit still for 12 hours every night? Thatâ€™s your home address. Easy.</p>
<p>Â </p>
<p><br>
F: And they definitely know how much time do I spend at the gym, without even checking my Instagram! Ok this is another level of creepy.Â </p>
<p>Â </p>
<p><br>
Clients of LiveRamp can upload their own consumer data to the platform, combine it with data from hundreds of 100 third-party data providers, and then utilize it on more than 500 marketing technology platforms.Â They can use this data to find and target people with specific characteristics, to recognize and track consumers <em>across devices and platforms</em>, to profile and categorize them, to personalize content for them, and to measure how they behave. For example, clients could â€œrecognize a website visitorâ€ and â€œprovide a customized offerâ€ based on extensive profile data, <em>without requiring said user to log in to the website.</em> Furthermore, LiveRamp has a data store, for other companies to â€œbuy and sell valuable customer dataâ€.Â </p>
<p>Â </p>
<p><br>
F: What is even the point of giving me the choice to consent to anything online?</p>
<p>Â </p>
<p><br>
In short, there is no point.Â </p>
<p>Â </p>
<p><br>
F: it seems we are so behind with regulations on data sharing. GDPR is not cutting it, not really. With programmatic advertising we have created a monster that has really grown out of control. <br>
So: our lives are completely transparent to private corporations, that constantly surveil us en-masse, and exploit all of our data to sell us shit. How does this affect our freedom? How about we just donâ€™t buy it? Can it be that simple? And I would not take a no for an answer here.</p>
<p>Â </p>
<p>Unfortunately, no.Â </p>
<p>Â </p>
<p><br>
F:Â  oh crap!</p>
<p>Â </p>
<p>Iâ€™m going to read you a passage from Permanent Record:Â Â </p>
<p>Â </p>
<p><em>Who among us can predict the future? Who would dare to? <br>
The answer to the first question is no one, really, and the answer to the second is everyone, especially every government and business on the planet. This is what that data of ours is used for. Algorithms analyze it for patterns of established behaviour in order to extrapolate behaviours to come, a type of digital prophecy thatâ€™s only slightly more accurate that analog methods like palm reading. Once you go digging into the actual technical mechanisms by which predictability is calculated, you come to understand that its science is, in fact, anti-scientific, and fatally misnamed: predictability is actually manipulation. </em></p>
<p>Â </p>
<p><em><br>
A website that tells you that because you liked book 1 then you might also like book 2, isnâ€™t offering an educated guess as much as a mechanism of subtle coercion.Â We canâ€™t allow ourselves to be used in this way, to be used against the future. We canâ€™t permit our data to be used to sell us the very things that must not be sold, such as journalism. [....]</em> <br>
<em>We canâ€™t let the god-like surveillance weâ€™re under be used to â€œcalculateâ€ our citizenship scores, or to â€œpredictâ€ our criminal activity; to tell us what kind of education we can have, or what kind of job we can have [...], to discriminate against us based on our financial, legal, and medical histories, not to mention our ethnicity or race, which are constructs that data often assumes or imposes. </em></p>
<p>Â </p>
<p><em><br>
[...] if we allow [our data] to be used to identify us, then it will be used to victimize us, even to modify us - to remake the very essence of our humanity in the image of the technology that seeks its control. Of course, all of the above has already happened.Â </em></p>
<p>Â </p>
<p>F: In other words, we are surveilled and our data collected, and used to affect every aspect of our lives - what we read, what movies we watch, where we travel, what we buy, who we date, what we study, where we workâ€¦ This is a self-fulfilling prophecy for all of humanity, and the prophet is a stupid, imperfect algorithm optimised just to make money. <br>
So I guess my message of today for all Data Scientists out there is this: justâ€¦ don't.Â </p>
<p>Â </p>
<p>Â </p>
<p>Â </p>
References
<p>Â </p>
<ul><li><a href='https://github.com/signalapp'>https://github.com/signalapp</a></li>
</ul>
<p>Â </p>
<ul><li>Wolfie Christl reportÂ <a href='https://crackedlabs.org/en/corporate-surveillance'>https://crackedlabs.org/en/corporate-surveillance</a></li>
</ul>
<p>Â </p>
<ul><li><a href='http://t.co/ahT9a35M9P?amp=1'>wolfie.crackedlabs.org</a></li>
</ul>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/du3ntf/episode3-TDSAI.mp3" length="44165665" type="audio/mpeg"/>
        <itunes:summary><![CDATA[


Get in touch with us






Join the discussion about data science, machine learning and artificial intelligenceÂ on our Discord server



Â 
Episode transcript
We always hear the word â€œmetadataâ€, usually in a sentence that goes like this
Â 

Your Honor, I swear, we were not collecting users data, just metadata.

Â 
Usually the guy saying this sentence is Zuckerberg, but could be anybody from Amazon or Google.Â â€œJustâ€ metadata, so no problem. This is one of the biggest lies about the reality of data collection.
Â 
F: Ok the first question is, what the hell is metadata?Â 
Â 
Metadata is data about data.Â 
Â 
F: Okâ€¦ still not clear.Imagine you make a phone call to your mum. How often do you call your mum, Francesco?F: Every day of course! (coughing)
Â 
Good boy! Ok, so letâ€™s talk about todayâ€™s phone call. Letâ€™s call â€œdataâ€ the stuff that you and your mum actually said. What did you talk about?Â 
Â 
F: She was giving me the recipe for her famous lasagna.Â 
So your mumâ€™s lasagna is the DATA. What is the metadata of this phone call? The lasagna has data of its own attached to it: the date and time when the conversation happened, the duration of the call, the unique hardware identifiers of your phone and your mumâ€™s phone, the identifiers of the two sim cards, the location of the cell towers that pinged the call, the GPS coordinates of the phones themselves.Â 
Â 
F: yeah well, this lasagna comes with a lot of data :)Â 
And this is assuming that this data is not linked to any other data like your Facebook account or your web browsing history. More of that later.Â 
Â 
F: Whoa Whoa Whoa, ok. Letâ€™s put a pin in that. Going back to the â€œbasicâ€ metadata that you describe. I think we understand the concept of data about data. I am sure you did your research and you would love to paint me a dystopian nightmare, as always. Tell us why is this a big deal?Â 
Â 
Metadata is a very big deal. In fact, metadata is far more â€œusefulâ€ than the actual data, where by â€œusefulâ€ I mean that it allows a third party to learn about you and your whole life. What I am saying is, the fact that you talk with your mum every day for 15 minutes is telling me more about you than the content of the actual conversations. In a way, the content does not matter. Only the metadata matters.Â 
Â 
F: Ok, can you explain this point a bit more?Â 
Â 
Imagine this scenario: you work in an office in Brussels, and you go by car. Every day, you use your time in the car while you go home to call your mum. So every day around 6pm, a cell tower along the path from your office to your home pings a call from your phone to your mumâ€™s phone. Someone who is looking at your metadata, knows exactly where you are while you call your mum. Every day you will talk about something different, and it doesn't really matter.Â  Your location will come through loud and clear. A lot of additional information can be deduced from this too: for example, you are moving along a motorway, therefore you have a car. The metadata of a call to mum now becomes information on where you are at 6pm, and the way you travel.Â 
Â 
F: I see. So metadata about the phone call is, in fact, real data about me.Â 
Â 
Exactly. YOU are what is interesting, not your mumâ€™s lasagna.
Â 
F: you say so because you havenâ€™t tried my mumâ€™s lasagna. But I totally get your point.
Â 
Now, imagine that one day, instead of going straight home, you decide to go somewhere else. Maybe you are secretly looking for another job. Your metadata is recording the fact that after work you visit the offices of a rival company. Maybe you are a journalist and you visit your anonymous source. Your metadata records wherever you go, and one of these places is your secret meeting with your source.Â Anyoneâ€™s metadata can be combined with yours. There will be someone who was with you at the time and place of your secret meeting. Anyone who comes in contact with you can be tagged and monitored. Now their anonymity has been reduced.Â 
Â 
F: I get it. So, compared to the content of my c]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>true</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:00</itunes:duration>
                <itunes:episode>88</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>The dark side of AI: recommend and manipulate (Ep. 90)</title>
        <itunes:title>The dark side of AI: recommend and manipulate (Ep. 90)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-recommend-and-manipulate-ep-90/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-dark-side-of-ai-recommend-and-manipulate-ep-90/#comments</comments>        <pubDate>Wed, 11 Dec 2019 11:07:38 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/the-dark-side-of-ai-recommend-and-manipulate-ep-90-02dc9f4016e05de3562886f95cb58813</guid>
                                    <description><![CDATA[<p>In 2017 a research group at the University of Washington did a study on the Black Lives Matter movement on Twitter. They constructed what they call aÂ â€œshared audience graphâ€Â to analyse the different groups of audiences participating in the debate, and found an alignment of the groups with the political left and political right, as well as clear alignments with groups participating in other debates, like environmental issues, abortion issues and so on. In simple terms, someone who is pro-environment, pro-abortion, left-leaning, is also supportive of theÂ <a href='https://blacklivesmatter.com/'>Black Lives Matter</a>Â movement, and viceversa.</p>
F: Ok, this seems to make sense, right? Butâ€¦ I suspect there is more to this story?
<p>So far, yesâ€¦. What they did not expect to find, though, was a pervasive network of Russian accounts participating in the debate, which turned out to be orchestrated by the Internet Research Agency, the not-so-secret Russian secret service agency of internet black ops. The same connected with the US election and Brexit referendum, allegedly.Â </p>
F: Are we talking about actual spies? Where are you going with this?
<p>Basically, the Russian accounts (part of them human and part of them bots) were infiltrating all aspects of the debate, both on the left and on the right side, and always taking the most extreme stances on any particular aspect of the debate. The aim was to radicalise the conversation, to make it more and more extreme, in a tactic of divide-and-conquer: turn the population against itself in an online civil war, push for policies that normally would be considered too extreme (for instance, give tanks to the police to control riots, force a curfew, try to ban Muslims from your country). Chaos and unrest have repercussions on international trade and relations, and can align to foreign interests.</p>
F: It seems like a pretty indirect and convoluted way of influencing a foreign powerâ€¦
<p>You might think so, but you are forgetting social media. This sort of operation is directly exploiting a core feature of internet social media platforms. And that feature, I am afraid, isÂ recommender systems.</p>
F: Whoa. Letâ€™s take a step back. Letâ€™s recap the general features of recommender systems, so we are on the same page.Â 
<p>The main purpose of recommender systems is to recommend people the same items similar people show an interest in.
Letâ€™s think about books and readers. The general idea is to find a way to predict the best book to the best reader. Amazon is doing it, Netflix is doing it, probably the bookstore down the road does that too, just on a smaller scale.
Some of the most common methods to implement recommender systems, use concepts such as cosine/correlation similarity, matrix factorization, neural autoencoders and sequence predictors.</p>
<p>The major issue of recommender systems is in their validation. Even though validation occurs in a way that is similar to many machine learning methods, one should recommend a set of items first (in production) and measure the efficacy of such a recommendation. But, recommending is already altering the entire scenario, a bit in the flavour of theÂ <a href='https://en.wikipedia.org/wiki/Uncertainty_principle'>Heisenberg principle of uncertainty</a>.Â </p>
F: In the attention economy, the business model is to monetise the time the user spends on a platform, by showing them ads. Recommender systems are crucial for this purpose.
Chiara, you are saying that these algorithms have effects that are problematic?
<p>As you say, recommender systems exist because the business model of social media platforms is to monetise attention. The most effective way to keep usersâ€™ attention is to show them stuff they could show an interest in.
In order to do that, one must segment the audience to find the best content for each user. But then, for each user, how do you keep them engaged, and make them consume more content?Â </p>
F: Youâ€™re going to say the word â€œfilter bubbleâ€ very soon.
<p>Spot on. To keep the user on the platform, you start by showing them content that they are interested in, and that agrees with their opinion.Â </p>
<p>But that is not all. How many videos of the same stuff can you watch, how many articles can you read? You must also escalate the content that the user sees, increasing theÂ wowÂ factor. The content goes from mild to extreme (conspiracy theories, hate speech etc).</p>
<p>The recommended content pushes the user opinion towards more extreme stances. It is hard to see from inside the bubble, but a simple experiment will show it. If you continue to click the first recommended video onÂ <a href='https://www.youtube.com/'>YouTube</a>, and you follow the chain of first recommended videos, soon you will find yourself watching stuff youâ€™d never have actively looked for, like conspiracy theories, or alt-right propaganda (or pranks that get progressively more cruel, videos by people committing suicide, and so on).</p>
F: So you are saying that this is not an accident: is this the basis of the optimisation of the recommender system?Â 
<p>Yes, and itâ€™s very effective. But obviously there are consequences.Â </p>
F: And Iâ€™m guessing they are not good.Â 
<p>The collective result of single users being pushed toward more radical stances is a radicalisation of the whole conversation, the disappearance of nuances in the argument, the trivialisation of complex issues. For example, the Brexit debate in 2016 was about trade deals and custom unions, and now it is about remain vs no deal, with almost nothing in between.Â </p>
F: Yes, the conversation is getting stupider. Is this just a giant accident? Just a sensible system that got out of control?
<p>Yes and no. Recommender systems originate as a tool for boosting commercial revenue, by selling more products.Â But applied to social media, they have caused an aberration:Â the recommendation of information, which leads to the so-calledÂ <a href='https://en.wikipedia.org/wiki/Filter_bubble'>filter bubbles</a>, the rise of fake news and disinformation, and the manipulation of the masses.Â </p>
<p>There is an intense debate in the scientific community about the polarising effects of the internet and social media on the population. An example of such study is a paper by Johnson et al. It predicts that whether and how a population becomes polarised is dictated by the nature of the underlying competition, rather than the validity of the information that individuals receive or their onlineÂ bubbles.Â </p>
F: I would like to stress on this finding. This is really f*cked up.Â Polarisation is not caused by the particular subject nor the way a debate is conducted. But by how legitimate the information seems to the single person. Which means that if I find a way to convince the single individuals about something, I will be in fact manipulating the debate at a community scale or, in some cases, globally!
Oh my god we seem to be so f*cked.
<p>Take for instance the people who believe that the Earth is flat. Or the time it took people to recognise global warming as scientific, despite the fact that, the threshold for scientific confirmation was reached decades ago.</p>
F: So, recommender systems let loose on social media platforms amplify controversy and conflict, and fringe opinions. I know Iâ€™m not going to like the answer, but Iâ€™m going to ask the question anyway.
This is all just an innocent mistake, right?Â 
<p>Last year, theÂ European Data Protection SupervisorÂ has published a report on online manipulation at scale.Â </p>
F: That does not sound good.
<p>The online digital ecosystem has connected people across the world with over 50% of the population on the Internet, albeit very unevenly in terms of geography, wealth and gender. The initial optimism about the potential of internet tools and social media for civic engagement has given way to concern that people are being manipulated. This happens through the combination of constant harvesting of often intimate information about them, and the control over the information they see online according to the category they are put into (so called segmentation of the audience). Arguably since 2016, but probably before, mass manipulation at scale has occurred during democratic elections. By using algorithms to game recommender systems, among other things, to spread misinformation. Remember Cambridge Analytica?Â </p>
F: I remember. I wish I didnâ€™t. But why does it work? Are we so easy to manipulate?Â 
<p>An interesting point is this. When one receives information collectively, as for example from the television news, it is far less likely that she develops extreme views (like, the Earth is flat), because she would base the discourse on a common understanding of reality. And people call out each otherâ€™s bulls*it.Â </p>
F: Fair enough.
<p>
But when one receives information singularly, like what happens via a recommender system through micro-targeting, then reality has a different manifestation for each audience member, with no common ground. It is far more likely to adopt extreme views, because there is no way to fact check, and because the newsÂ feel personal. In fact, they tailor such news are to the users to push their buttons.
Francesco, if you show me George Clooney shirtless and holding a puppy, and George tells me that the Earth is flat, I might have doubts for a minute. Too personal?Â </p>
F:Â Thatâ€™s good to know about you.Â Iâ€™m more of a cat person.Â But, experts keep saying that we are moving towards personalisation of everything. While this makes sense for things like personalised medicine, it probably is not that beneficial with many other kinds of recommendations.Â Especially not the news.
But social media feeds are extremely personalised. What can we do?Â 
<p>Solutions have focused on transparency measures, exposing the source of information while neglecting the accountability of players in the ecosystem who profit from harmful behaviour.Â But these are band aids on bullet wounds.
The problem is the social media platforms. In October 2019 Zuckerberg was in front of congress again, because Facebook refuses to fact-check political advertisements, in 2019, after everything thatâ€™s happened.Â At the same time market concentration and the rise of platform dominance threatens media pluralism. This in turn, is leading to repeat and amplify a handful of news pieces and to silence independent journalism.Â </p>
F: When I think of a recommender system, I think of Netflix.
<ul><li>You liked this kind of show in the past, so here are more shows of the same genre</li>
<li>People like you have liked this other type of show. Hence, here it is for your consideration</li>
</ul>
<p>This seems relatively benign. Although, if you think some more, you realise that this mechanism will prevent you from actually discovering anything new. It just gives you more of what you are likely to like. But one would not think that this would have world-changing consequences.Â 
If you think of the news, this mechanism becomes lethal: in the mildest form â€“ which is already bad â€“ you will only hear opinions that already align with those of your own peer group. In the worst scenario, you will not hear some news at all, or you will hear a misleading or false version of the news, and you donâ€™t even know that a different version exists.</p>
<p>In the Brexit referendum, misleading or false content (like the famous NHS money that supposedly was going to the EU instead) has been amplified in filter bubbles. Each bubble of people was essentially understanding a different version of the same issue. Brexit was a million different things, depending on your social media feeds.
And of course, there are malicious players in the game, like the russian Internet Research Agency and Cambridge Analytica, who actively exploited this features in order to swing the vote.Â </p>
F: Even the traditional media is starting to adopt recommender systems for the news content. This seems like a very bad idea, after all. Is there any other scenario in which recommender systems are not great?Â 
<p>Researchers use recommender systems in a variety of applications.
For instance, in the job market. A recommender system limits exposure to certain information about jobs on the basis of the personâ€™s gender or inferred health status, and therefore it perpetuates discriminatory attitudes and practices. In the US, researchers use recommender systems to calculate the bail fee for people who have been arrested, disproportionately penalising people of colour. This has to do with the training of the algorithm. In an already unequal system (where for instance there are few women in top managerial positions, and more African-Americans in jail than white Americans) a recommender system will by design amplify such inequality.Â </p>
F: Recommender systems are part of the problem, and they make everything worse. But the origin of the problem lies somewhere else, I suspect.Â 
<p>Yep. The problem with recommender systems goes even deeper. I would rather connect it to the problem ofÂ privacy. A recommender system only works if it knows its audience. They are so powerful, because they know everything about us.Â 
We donâ€™t have any privacy anymore. Online players know exactly who we are, our lives are transparent to both corporations and governments. For an excellent analysis of this, read Snowdenâ€™s book â€œ<a href='https://www.amazon.com/Permanent-Record-Edward-Snowden/dp/1250237238'>Permanent Record</a>â€. I highlyÂ recommendÂ it.Â </p>
F:Â The pun was intended wasnâ€™t it?
<p>With all this information about us, we are put into â€œcategoriesâ€ for specific purposes: selling us products, influencing our vote. They target us with ads aimed at our specific category, and this generates more discussion and more content on our social media. Recommender systems amplify the targeting by design.Â They would be much less effective, and much less dangerous, in a world where our lives are private.Â </p>
F: Social media platforms base their whole business model in â€œknowing usâ€. The business model itself is problematic.Â 
<p>As we said in theÂ <a href='https://datascienceathome.com/the-dark-side-of-ai-social-media-and-the-optimization-of-addiction/'>previous episode</a>, the internet has become centralised, with a handful of platforms controlling most of the traffic. In some countries like Myanmar, internet access itself is provided and controlled by Facebook.Â </p>
F: Chiara, whereâ€™s Myanmar?
<p>In South-East Asia, between India and Thailand.
In effect, the forum for public discourse and the available space for freedom of speech is now bounded by the profit motives of powerful private companies. Due to technical complexity or on the grounds of commercial secrecy, such companies decline to explain how decisions are made. Mostly, they make decisions via recommender algorithms, which amplify bias and segregation. And at the same time the few major platforms with their extraordinary reach offer an easy target for people seeking to use the system for malicious ends.Â </p>
Conclusion
<p>This is our call to all data scientists out there. Be aware of personalisation in building recommender systems. Personalising is not always beneficial. There are a few cases where it is, e.g. medicine, genetics, drug discovery. Many other cases where it is detrimental e.g. news, consumer products/services, opinions.
Personalisation by algorithm, and in particular of the news, leads to a fragmentation of reality that undermines democracy. Collectively we need to push for reigning in targeted advertising, and the path to this leads to more strict rules on privacy. As long as we are completely transparent to commercial and governmental players, like we are today, we are vulnerable to lies, misdirection and manipulation.
As Christopher Wylie (the Cambridge Analytica whistleblower) eloquently said, itâ€™s like going on a date, where you know nothing about the other person, but they know absolutely everything about you.
We are left without agency, and without real choice.
In other words, we are f*cked</p>
References
<p>BlackÂ  lives matter / Internet Research Agency (IRA) articles:Â </p>
<p><a href='http://faculty.washington.edu/kstarbi/Stewart_Starbird_Drawing_the_Lines_of_Contention-final.pdf'>http://faculty.washington.edu/kstarbi/Stewart_Starbird_Drawing_the_Lines_of_Contention-final.pdf</a></p>
<p><a href='https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4'>https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4</a></p>
<p><a href='https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4'>https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4</a></p>
<p><a href='https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf'>https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf</a></p>
<p>IRA tactics:
<a href='https://int.nyt.com/data/documenthelper/533-read-report-internet-research-agency/7871ea6d5b7bedafbf19/optimized/full.pdf#page=1'>https://int.nyt.com/data/documenthelper/533-read-report-internet-research-agency/7871ea6d5b7bedafbf19/optimized/full.pdf#page=1</a></p>
<p><a href='https://int.nyt.com/data/documenthelper/534-oxford-russia-internet-research-agency/c6588b4a7b940c551c38/optimized/full.pdf#page=1'>https://int.nyt.com/data/documenthelper/534-oxford-russia-internet-research-agency/c6588b4a7b940c551c38/optimized/full.pdf#page=1</a></p>
<p>EDPS report
<a href='https://edps.europa.eu/sites/edp/files/publication/18-03-19_online_manipulation_en.pdf'>https://edps.europa.eu/sites/edp/files/publication/18-03-19_online_manipulation_en.pdf</a></p>
<p>Johnson et al.Â  â€œPopulation polarization dynamics and next-generation social media algorithmsâ€Â <a href='https://arxiv.org/abs/1712.06009'>https://arxiv.org/abs/1712.06009</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In 2017 a research group at the University of Washington did a study on the Black Lives Matter movement on Twitter. They constructed what they call aÂ <em>â€œshared audience graphâ€</em>Â to analyse the different groups of audiences participating in the debate, and found an alignment of the groups with the political left and political right, as well as clear alignments with groups participating in other debates, like environmental issues, abortion issues and so on. In simple terms, someone who is pro-environment, pro-abortion, left-leaning, is also supportive of theÂ <a href='https://blacklivesmatter.com/'>Black Lives Matter</a>Â movement, and viceversa.</p>
F: Ok, this seems to make sense, right? Butâ€¦ I suspect there is more to this story?
<p>So far, yesâ€¦. What they did not expect to find, though, was a pervasive network of Russian accounts participating in the debate, which turned out to be orchestrated by the Internet Research Agency, the not-so-secret Russian secret service agency of internet black ops. The same connected with the US election and Brexit referendum, allegedly.Â </p>
F: Are we talking about actual spies? Where are you going with this?
<p>Basically, the Russian accounts (part of them human and part of them bots) were infiltrating all aspects of the debate, both on the left and on the right side, and always taking the most extreme stances on any particular aspect of the debate. The aim was to radicalise the conversation, to make it more and more extreme, in a tactic of divide-and-conquer: turn the population against itself in an online civil war, push for policies that normally would be considered too extreme (for instance, give tanks to the police to control riots, force a curfew, try to ban Muslims from your country). Chaos and unrest have repercussions on international trade and relations, and can align to foreign interests.</p>
F: It seems like a pretty indirect and convoluted way of influencing a foreign powerâ€¦
<p>You might think so, but you are forgetting social media. This sort of operation is directly exploiting a core feature of internet social media platforms. And that feature, I am afraid, isÂ recommender systems.</p>
F: Whoa. Letâ€™s take a step back. Letâ€™s recap the general features of recommender systems, so we are on the same page.Â 
<p>The main purpose of recommender systems is to recommend people the same items similar people show an interest in.<br>
Letâ€™s think about books and readers. The general idea is to find a way to predict the best book to the best reader. Amazon is doing it, Netflix is doing it, probably the bookstore down the road does that too, just on a smaller scale.<br>
Some of the most common methods to implement recommender systems, use concepts such as cosine/correlation similarity, matrix factorization, neural autoencoders and sequence predictors.</p>
<p>The major issue of recommender systems is in their validation. Even though validation occurs in a way that is similar to many machine learning methods, one should recommend a set of items first (in production) and measure the efficacy of such a recommendation. But, recommending is already altering the entire scenario, a bit in the flavour of theÂ <a href='https://en.wikipedia.org/wiki/Uncertainty_principle'>Heisenberg principle of uncertainty</a>.Â </p>
F: In the attention economy, the business model is to monetise the time the user spends on a platform, by showing them ads. Recommender systems are crucial for this purpose.<br>
Chiara, you are saying that these algorithms have effects that are problematic?
<p>As you say, recommender systems exist because the business model of social media platforms is to monetise attention. The most effective way to keep usersâ€™ attention is to show them stuff they could show an interest in.<br>
In order to do that, one must segment the audience to find the best content for each user. But then, for each user, how do you keep them engaged, and make them consume more content?Â </p>
F: Youâ€™re going to say the word â€œfilter bubbleâ€ very soon.
<p>Spot on. To keep the user on the platform, you start by showing them content that they are interested in, and that agrees with their opinion.Â </p>
<p>But that is not all. How many videos of the same stuff can you watch, how many articles can you read? You must also escalate the content that the user sees, increasing theÂ wowÂ factor. The content goes from mild to extreme (conspiracy theories, hate speech etc).</p>
<p>The recommended content pushes the user opinion towards more extreme stances. It is hard to see from inside the bubble, but a simple experiment will show it. If you continue to click the first recommended video onÂ <a href='https://www.youtube.com/'>YouTube</a>, and you follow the chain of first recommended videos, soon you will find yourself watching stuff youâ€™d never have actively looked for, like conspiracy theories, or alt-right propaganda (or pranks that get progressively more cruel, videos by people committing suicide, and so on).</p>
F: So you are saying that this is not an accident: is this the basis of the optimisation of the recommender system?Â 
<p>Yes, and itâ€™s very effective. But obviously there are consequences.Â </p>
F: And Iâ€™m guessing they are not good.Â 
<p>The collective result of single users being pushed toward more radical stances is a radicalisation of the whole conversation, the disappearance of nuances in the argument, the trivialisation of complex issues. For example, the Brexit debate in 2016 was about trade deals and custom unions, and now it is about remain vs no deal, with almost nothing in between.Â </p>
F: Yes, the conversation is getting stupider. Is this just a giant accident? Just a sensible system that got out of control?
<p>Yes and no. Recommender systems originate as a tool for boosting commercial revenue, by selling more products.Â But applied to social media, they have caused an aberration:Â the recommendation of information, which leads to the so-calledÂ <a href='https://en.wikipedia.org/wiki/Filter_bubble'>filter bubbles</a>, the rise of fake news and disinformation, and the manipulation of the masses.Â </p>
<p>There is an intense debate in the scientific community about the polarising effects of the internet and social media on the population. An example of such study is a paper by Johnson et al. It predicts that whether and how a population becomes polarised is dictated by the nature of the underlying competition, rather than the validity of the information that individuals receive or their onlineÂ <em>bubbles</em>.Â </p>
F: I would like to stress on this finding. This is really f*cked up.Â Polarisation is not caused by the particular subject nor the way a debate is conducted. But by how legitimate the information seems to the single person. Which means that if I find a way to convince the single individuals about something, I will be in fact manipulating the debate at a community scale or, in some cases, globally!<br>
Oh my god we seem to be so f*cked.
<p>Take for instance the people who believe that the Earth is flat. Or the time it took people to recognise global warming as scientific, despite the fact that, the threshold for scientific confirmation was reached decades ago.</p>
F: So, recommender systems let loose on social media platforms amplify controversy and conflict, and fringe opinions. I know Iâ€™m not going to like the answer, but Iâ€™m going to ask the question anyway.<br>
This is all just an innocent mistake, right?Â 
<p>Last year, theÂ European Data Protection SupervisorÂ has published a report on online manipulation at scale.Â </p>
F: That does not sound good.
<p>The online digital ecosystem has connected people across the world with over 50% of the population on the Internet, albeit very unevenly in terms of geography, wealth and gender. The initial optimism about the potential of internet tools and social media for civic engagement has given way to concern that people are being manipulated. This happens through the combination of constant harvesting of often intimate information about them, and the control over the information they see online according to the category they are put into (so called segmentation of the audience). Arguably since 2016, but probably before, mass manipulation at scale has occurred during democratic elections. By using algorithms to game recommender systems, among other things, to spread misinformation. Remember Cambridge Analytica?Â </p>
F: I remember. I wish I didnâ€™t. But why does it work? Are we so easy to manipulate?Â 
<p>An interesting point is this. When one receives information collectively, as for example from the television news, it is far less likely that she develops extreme views (like, the Earth is flat), because she would base the discourse on a common understanding of reality. And people call out each otherâ€™s bulls*it.Â </p>
F: Fair enough.
<p><br>
But when one receives information singularly, like what happens via a recommender system through micro-targeting, then reality has a different manifestation for each audience member, with no common ground. It is far more likely to adopt extreme views, because there is no way to fact check, and because the newsÂ <em>feel personal</em>. In fact, they tailor such news are to the users to push their buttons.<br>
Francesco, if you show me George Clooney shirtless and holding a puppy, and George tells me that the Earth is flat, I might have doubts for a minute. Too personal?Â </p>
F:Â Thatâ€™s good to know about you.Â Iâ€™m more of a cat person.Â But, experts keep saying that we are moving towards personalisation of everything. While this makes sense for things like personalised medicine, it probably is not that beneficial with many other kinds of recommendations.Â Especially not the news.<br>
But social media feeds are extremely personalised. What can we do?Â 
<p>Solutions have focused on transparency measures, exposing the source of information while neglecting the accountability of players in the ecosystem who profit from harmful behaviour.Â But these are band aids on bullet wounds.<br>
The problem is the social media platforms. In October 2019 Zuckerberg was in front of congress again, because Facebook refuses to fact-check political advertisements, in 2019, after everything thatâ€™s happened.Â At the same time market concentration and the rise of platform dominance threatens media pluralism. This in turn, is leading to repeat and amplify a handful of news pieces and to silence independent journalism.Â </p>
F: When I think of a recommender system, I think of Netflix.
<ul><li>You liked this kind of show in the past, so here are more shows of the same genre</li>
<li>People like you have liked this other type of show. Hence, here it is for your consideration</li>
</ul>
<p>This seems relatively benign. Although, if you think some more, you realise that this mechanism will prevent you from actually discovering anything new. It just gives you more of what you are likely to like. But one would not think that this would have world-changing consequences.Â <br>
If you think of the news, this mechanism becomes lethal: in the mildest form â€“ which is already bad â€“ you will only hear opinions that already align with those of your own peer group. In the worst scenario, you will not hear some news at all, or you will hear a misleading or false version of the news, and you donâ€™t even know that a different version exists.</p>
<p>In the Brexit referendum, misleading or false content (like the famous NHS money that supposedly was going to the EU instead) has been amplified in filter bubbles. Each bubble of people was essentially understanding a different version of the same issue. Brexit was a million different things, depending on your social media feeds.<br>
And of course, there are malicious players in the game, like the russian Internet Research Agency and Cambridge Analytica, who actively exploited this features in order to swing the vote.Â </p>
F: Even the traditional media is starting to adopt recommender systems for the news content. This seems like a very bad idea, after all. Is there any other scenario in which recommender systems are not great?Â 
<p>Researchers use recommender systems in a variety of applications.<br>
For instance, in the job market. A recommender system limits exposure to certain information about jobs on the basis of the personâ€™s gender or inferred health status, and therefore it perpetuates discriminatory attitudes and practices. In the US, researchers use recommender systems to calculate the bail fee for people who have been arrested, disproportionately penalising people of colour. This has to do with the training of the algorithm. In an already unequal system (where for instance there are few women in top managerial positions, and more African-Americans in jail than white Americans) a recommender system will by design amplify such inequality.Â </p>
F: Recommender systems are part of the problem, and they make everything worse. But the origin of the problem lies somewhere else, I suspect.Â 
<p>Yep. The problem with recommender systems goes even deeper. I would rather connect it to the problem ofÂ <em>privacy</em>. A recommender system only works if it knows its audience. They are so powerful, because they know everything about us.Â <br>
We donâ€™t have any privacy anymore. Online players know exactly who we are, our lives are transparent to both corporations and governments. For an excellent analysis of this, read Snowdenâ€™s book â€œ<a href='https://www.amazon.com/Permanent-Record-Edward-Snowden/dp/1250237238'>Permanent Record</a>â€. I highlyÂ <em>recommend</em>Â it.Â </p>
F:Â The pun was intended wasnâ€™t it?
<p>With all this information about us, we are put into â€œ<em>categories</em>â€ for specific purposes: selling us products, influencing our vote. They target us with ads aimed at our specific category, and this generates more discussion and more content on our social media. Recommender systems amplify the targeting by design.Â They would be much less effective, and much less dangerous, in a world where our lives are private.Â </p>
F: Social media platforms base their whole business model in â€œknowing usâ€. The business model itself is problematic.Â 
<p>As we said in theÂ <a href='https://datascienceathome.com/the-dark-side-of-ai-social-media-and-the-optimization-of-addiction/'>previous episode</a>, the internet has become centralised, with a handful of platforms controlling most of the traffic. In some countries like Myanmar, internet access itself is provided and controlled by Facebook.Â </p>
F: Chiara, whereâ€™s Myanmar?
<p>In South-East Asia, between India and Thailand.<br>
In effect, the forum for public discourse and the available space for freedom of speech is now bounded by the profit motives of powerful private companies. Due to technical complexity or on the grounds of commercial secrecy, such companies decline to explain how decisions are made. Mostly, they make decisions via recommender algorithms, which amplify bias and segregation. And at the same time the few major platforms with their extraordinary reach offer an easy target for people seeking to use the system for malicious ends.Â </p>
Conclusion
<p>This is our call to all data scientists out there. Be aware of personalisation in building recommender systems. Personalising is not always beneficial. There are a few cases where it is, e.g. medicine, genetics, drug discovery. Many other cases where it is detrimental e.g. news, consumer products/services, opinions.<br>
Personalisation by algorithm, and in particular of the news, leads to a fragmentation of reality that undermines democracy. Collectively we need to push for reigning in targeted advertising, and the path to this leads to more strict rules on privacy. As long as we are completely transparent to commercial and governmental players, like we are today, we are vulnerable to lies, misdirection and manipulation.<br>
As Christopher Wylie (the Cambridge Analytica whistleblower) eloquently said, itâ€™s like going on a date, where you know nothing about the other person, but they know absolutely everything about you.<br>
We are left without agency, and without real choice.<br>
In other words, we are f*cked</p>
References
<p>BlackÂ  lives matter / Internet Research Agency (IRA) articles:Â </p>
<p><a href='http://faculty.washington.edu/kstarbi/Stewart_Starbird_Drawing_the_Lines_of_Contention-final.pdf'>http://faculty.washington.edu/kstarbi/Stewart_Starbird_Drawing_the_Lines_of_Contention-final.pdf</a></p>
<p><a href='https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4'>https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4</a></p>
<p><a href='https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4'>https://medium.com/s/story/the-trolls-within-how-russian-information-operations-infiltrated-online-communities-691fb969b9e4</a></p>
<p><a href='https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf'>https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf</a></p>
<p>IRA tactics:<br>
<a href='https://int.nyt.com/data/documenthelper/533-read-report-internet-research-agency/7871ea6d5b7bedafbf19/optimized/full.pdf#page=1'>https://int.nyt.com/data/documenthelper/533-read-report-internet-research-agency/7871ea6d5b7bedafbf19/optimized/full.pdf#page=1</a></p>
<p><a href='https://int.nyt.com/data/documenthelper/534-oxford-russia-internet-research-agency/c6588b4a7b940c551c38/optimized/full.pdf#page=1'>https://int.nyt.com/data/documenthelper/534-oxford-russia-internet-research-agency/c6588b4a7b940c551c38/optimized/full.pdf#page=1</a></p>
<p>EDPS report<br>
<a href='https://edps.europa.eu/sites/edp/files/publication/18-03-19_online_manipulation_en.pdf'>https://edps.europa.eu/sites/edp/files/publication/18-03-19_online_manipulation_en.pdf</a></p>
<p>Johnson et al.Â  â€œPopulation polarization dynamics and next-generation social media algorithmsâ€Â <a href='https://arxiv.org/abs/1712.06009'>https://arxiv.org/abs/1712.06009</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/eqjz9q/087-episode2-tonini.mp3" length="39485358" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In 2017 a research group at the University of Washington did a study on the Black Lives Matter movement on Twitter. They constructed what they call aÂ â€œshared audience graphâ€Â to analyse the different groups of audiences participating in the debate, and found an alignment of the groups with the political left and political right, as well as clear alignments with groups participating in other debates, like environmental issues, abortion issues and so on. In simple terms, someone who is pro-environment, pro-abortion, left-leaning, is also supportive of theÂ Black Lives MatterÂ movement, and viceversa.
F: Ok, this seems to make sense, right? Butâ€¦ I suspect there is more to this story?
So far, yesâ€¦. What they did not expect to find, though, was a pervasive network of Russian accounts participating in the debate, which turned out to be orchestrated by the Internet Research Agency, the not-so-secret Russian secret service agency of internet black ops. The same connected with the US election and Brexit referendum, allegedly.Â 
F: Are we talking about actual spies? Where are you going with this?
Basically, the Russian accounts (part of them human and part of them bots) were infiltrating all aspects of the debate, both on the left and on the right side, and always taking the most extreme stances on any particular aspect of the debate. The aim was to radicalise the conversation, to make it more and more extreme, in a tactic of divide-and-conquer: turn the population against itself in an online civil war, push for policies that normally would be considered too extreme (for instance, give tanks to the police to control riots, force a curfew, try to ban Muslims from your country). Chaos and unrest have repercussions on international trade and relations, and can align to foreign interests.
F: It seems like a pretty indirect and convoluted way of influencing a foreign powerâ€¦
You might think so, but you are forgetting social media. This sort of operation is directly exploiting a core feature of internet social media platforms. And that feature, I am afraid, isÂ recommender systems.
F: Whoa. Letâ€™s take a step back. Letâ€™s recap the general features of recommender systems, so we are on the same page.Â 
The main purpose of recommender systems is to recommend people the same items similar people show an interest in.Letâ€™s think about books and readers. The general idea is to find a way to predict the best book to the best reader. Amazon is doing it, Netflix is doing it, probably the bookstore down the road does that too, just on a smaller scale.Some of the most common methods to implement recommender systems, use concepts such as cosine/correlation similarity, matrix factorization, neural autoencoders and sequence predictors.
The major issue of recommender systems is in their validation. Even though validation occurs in a way that is similar to many machine learning methods, one should recommend a set of items first (in production) and measure the efficacy of such a recommendation. But, recommending is already altering the entire scenario, a bit in the flavour of theÂ Heisenberg principle of uncertainty.Â 
F: In the attention economy, the business model is to monetise the time the user spends on a platform, by showing them ads. Recommender systems are crucial for this purpose.Chiara, you are saying that these algorithms have effects that are problematic?
As you say, recommender systems exist because the business model of social media platforms is to monetise attention. The most effective way to keep usersâ€™ attention is to show them stuff they could show an interest in.In order to do that, one must segment the audience to find the best content for each user. But then, for each user, how do you keep them engaged, and make them consume more content?Â 
F: Youâ€™re going to say the word â€œfilter bubbleâ€ very soon.
Spot on. To keep the user on the platform, you start by showing them content that they are interested in, and that agrees with their opinion.Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:33</itunes:duration>
                <itunes:episode>87</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>The dark side of AI: social media and the optimization of addiction (Ep. 89)</title>
        <itunes:title>The dark side of AI: social media and the optimization of addiction (Ep. 89)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/we-are-fked-social-media-and-the-optimization-of-addiction/</link>
                    <comments>https://datascienceathome.podbean.com/e/we-are-fked-social-media-and-the-optimization-of-addiction/#comments</comments>        <pubDate>Tue, 03 Dec 2019 03:00:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/we-are-fked-social-media-and-the-optimization-of-addiction-68818299ba082ac078f574cd38d6387a</guid>
                                    <description><![CDATA[<p>Chamath Palihapitiya, former Vice President of User Growth at Facebook, was giving a talk at Stanford University, when he said this: 
â€œI feel tremendous guilt. The short-term, dopamine-driven feedback loops that we have created are destroying how society works â€.</p>
<p>He was referring to how social media platforms leverage our neurological build-up in the same way slot machines and cocaine do, to keep us using their products as much as possible. They turn us into addicts.</p>
<p>Â </p>
<p>F: how many times do you check your Facebook in a day?</p>
<p>I am not a fan of Facebook. I do not have it on my phone.Â  Still, I check it in the morning on my laptop, and maybe twice more per day. I have a trick though: I do not scroll down. I only check the top bar to see if someone has invited me to an event, or contacted me directly. But from time to time, this resolution of mine slips, and I catch myself scrolling down, without even realising it!</p>
<p>Â </p>
<p>F: is it the first thing you check when you wake up?</p>
<p>No because usually I have a message from you!! :)Â But yes, while I have my coffee I do a sweep on Facebook and twitter and maybe Instagram, plus the news.</p>
<p>Â </p>
<p>F: Check how much time you spend on Facebook</p>
<p>And then sum it up to your email, twitter, reddit, youtube, instagram, etc. (all viable channels for ads to reach you)</p>
<p>We have an answer. More on that later.Â 
Clearly in this episode there is some form of addiction we would like to talk about. So letâ€™s start from the beginning: how does addiction work?</p>
<p>Dopamine is a hormone produced by our body, and in the brain it works as a neurotransmitter, a chemical that neurons use to transmit signals to each other. One of the main functions of dopamine is to shape the â€œreward-motivated behaviourâ€: this is the way our brain learns through association, positive reinforcement, incentives, and positively-valenced emotions, in particular, pleasure. In other words, it makes our brain desire more of the things that make us feel good. These things can be for example good food, sex, and crucially, good social interactions, like hugging your friends or your baby, or having a laugh together.Â Because we are evolved to be social animals with complex social structures, successful social interactions are an evolutionary advantage, and therefore they trigger dopamine release in our brain, which makes us feel good, and reinforces the association between the action and the reward. This feeling motivates us to repeat the behaviour.</p>
<p>Â </p>
<p>F: now that you mention reinforcement, I recall that this mechanism is so powerful and effective that in fact we have been inspired by nature and replicated it in-silico with reinforcement learning. The idea is to motivate (and eventually create an addictive pattern) an agent to follow what is called the optimal policy by giving it positive rewards or punishing it when things donâ€™t go the way we planned.Â </p>
<p>In our brain, every time an action produces a reward, the connection between action and reward becomes stronger. Through reinforcement, a baby learns to distinguish a cat from a dog, or that fire hurts (that was me).</p>
<p>Â </p>
<p>F: and so this means that all the social interactions people get from social media platforms are in fact doing the same, right?Â </p>
<p>Yes, but with a difference: smartphones in our pockets keep us connected to an unlimited reserve of constant social interactions. This constant flux of notifications - the rewards - flood our brain with dopamine. The mechanism of reinforcement can spin out of control. The reward pathways in our brain can malfunction, and this leads to addiction.Â </p>
<p>Â </p>
<p>F: you are saying that social media has LITERALLY the effect of a drug?Â </p>
<p>Yes. In fact, social media platforms are DESIGNED to exploit the rewards systems in our brain. They are designed to work like a drug. 
Have you been to a casino and played roulette or the slot machines?Â </p>
<p>Â </p>
<p>F: ...maybe?</p>
<p>Why is it fun to play roulette? The fun comes from the WAIT before the reward. You put a chip on a number, you donâ€™t know how itâ€™s going to go. You wait for the ball to spin, you get excited. And from time to time, BAM! Your number comes out. Now, compare this with posting something on facebook. You write a message into the void, waitâ€¦. And then the LIKES start coming in.Â </p>
<p>Â </p>
<p>F:Â  yeah i find that familiar...Â </p>
<p>Contrary to the casino, social media platforms do not want our money, in fact they are free. What they want is, and what we are buying into with, is our time. Because the longer we stay on, the longer they can show us ads, and the more money advertisers can pay them. This is no accident, this is the business model.Â But asking for our time out loud would not work, we would probably not consciously give it to them. So, like a casino, they make it hard for us to get off, once we are on: they make us crave the likes, the right-swipes, the retweets, the subscriptions. So we check in, we stay on, we keep scrolling, because we hope to get those rewards.Â The short-term satisfaction of getting a â€œlikeâ€ is a little boost of dopamine in our brain. We get used to it, and we want more.Â </p>
<p>Â </p>
<p>F: a lot of machine learning is also being deployed to amplify this form of addiction and make it.... Well more addictive :) But the question is: how such powerful ads and scenarios are so effective because of the algorithms and how much just because humans are just wired to obey such dynamics? My question is: are we essentially flawed or are these algorithms truly powerful?Â </p>
<p>It is not a flaw, itâ€™s a feature. The way our brain has evolved has been in response to very specific needs. In particular for this conversation, our brain is wired to favour social interactions, because it is an evolutionary advantage. These algorithms exploit these features of the brain on purpose, they are designed to exploit them.Â </p>
<p>Â </p>
<p>F: I believe so, but I also believe that the human brain is a powerful machine, so it should be able to predict what satisfaction it can get from social media. So how does it happen that we become addicted?</p>
<p>An example of optimisation strategy that social media platforms use is based on the principle of â€œreward prediction error codingâ€.Â Our brain learns to find patterns in data - this is a basic survival skill - and therefore learns when to expect a reward for a given set of actions. I eat cake, therefore I am happy. Every time.Â 
Imagine a scenario, where we have learnt through experience that when we play slot machines in a casino, we learn that we win some money once every 100 times we pull the lever. The difference between predicted and received rewards is a known, fixed quantity. If so, just after winning once, we have almost zero incentive to play again.Â So the casino fixes the slot machines, to introduce a random element to the timing of the reward. Suddenly our prediction error increases substantially. In this margin of error, in the time between the action (pull the lever) and the reward (maybe) our brain has time to make us anticipate the result and make us excited at the possibility, and this releases dopamine. Playing in itself becomes a reward. 

F: There is an equivalent in reinforcement learning called the grid world which consists in a mouse getting to the cheese in a maze. In reinforcement learning, everything works smooth as long as the cheese stays in the same place.</p>
<p>Exactly! Now social media apps implement an equivalent trick, called â€œvariable reward schedulesâ€.</p>
<p>In our brain, after an action we get a reward or punishment, and we generate positive or negative feedback to that action. 
Social media apps optimise their algorithms for the ideal balance of negative and positive feedbackÂ  in our brains caused by the difference between these predicted and received rewards.Â </p>
<p>If we perceive a reward to be delivered at random, and - crucially - if checking for the reward comes at little cost, like opening the Facebook app, we end up checking for rewards all the time. Every time we are just a little bit bored, without even thinking, we check the app. The Facebook reward system (the schedule and triggers of notification and likes) has been optimised to maximise this behaviour.Â </p>
<p>Â </p>
<p>F: are you saying that buffering some likes and then finding the right moment to show them to the user can make the user crave for reward?Â </p>
<p>Oh yes. Instagram will withhold likes for a period of time, causing a dip in reward compared to the expected level. It will then deliver them later in larger bundles, thus boosting the reward above the expected value, which trigger extra dopamine release, which sends us on a high akin to a cocaine hit.</p>
<p>Â </p>
<p>F: Dear audience, do you remember my question? How much time do each of you spend on social media (or similar) in a day? And why do we still do it?</p>
<p>The fundamental feature here is how little is the perceived cost to check for the reward: I just need to open the app. We perceive this cost to be minimal, so we donâ€™t even think about it. YouTube for instance had the autoplay feature, so you need to do absolutely nothing to remain on the app.Â But the cost is cumulative over time, it becomes hours in our day, days in a month, years in our lives!! 2 hours of social media per day amounts to 1 month per year.Â </p>
<p>Â </p>
<p>F: But itâ€™s so EASY, it has become so natural to use social media for everything. To use Google for everything.</p>
<p>The convenience that the platforms give us is one of the most dangerous things about them, and not only for our individual life. The convenience of reaching so many users, together with the business model ofÂ monetising attention is one of the causes of the centralisation of the internet, i.e. the fact a few giant platforms control most of the internet traffic.Â Revenue from ads is concentrated on big platforms, and content creators have no other choice but to use them, if they want to be competitive.Â The internet went from looking like a distributed network to a centralised network.Â And this in turn causes data to be centralised, in a self-reinforcing loop. Most of human conversations and interactions pass through the servers of a handful of private corporations.</p>
<p>

</p>
<p>Conclusion</p>
<p>As Data scientists we should be aware of this (and we think mostly we are). We should also be ethically responsible. I think that being a data scientist no longer has a neutral connotation. Algorithms have this huge power of manipulating human behaviour, and letâ€™s be honest, we are the only ones who really understand how they work. So we have a responsibility here.Â </p>
<p>There are some organisations, like Data For Democracy for example, who are advocating for something equivalent to the Hippocratic Oath for data scientists. Do no harm.Â Â </p>
<p>Â </p>
References
<p class="content-title" lang="en">Dopamine reward prediction error codingÂ <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/'>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/</a></p>
<p class="hidden-xs hidden-print">Skinner - Operant ConditioningÂ <a href='https://www.simplypsychology.org/operant-conditioning.html'>https://www.simplypsychology.org/operant-conditioning.html</a></p>


<p class="entry-title">Dopamine, Smartphones & You: A battle for your timeÂ <a href='http://sitn.hms.harvard.edu/flash/2018/dopamine-smartphones-battle-time/'>http://sitn.hms.harvard.edu/flash/2018/dopamine-smartphones-battle-time/</a></p>


<p class="firstHeading" lang="en">Reward systemÂ <a href='https://en.wikipedia.org/wiki/Reward_system'>https://en.wikipedia.org/wiki/Reward_system</a></p>
<p>Data for democracyÂ <a href='/datascienceathome/episode/update/id/datafordemocracy.org'>datafordemocracy.org</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Chamath Palihapitiya, former Vice President of User Growth at Facebook, was giving a talk at Stanford University, when he said this: <br>
<em>â€œI feel tremendous guilt. The short-term, dopamine-driven feedback loops that we have created are destroying how society works â€.</em></p>
<p>He was referring to how social media platforms leverage our neurological build-up in the same way slot machines and cocaine do, to keep us using their products as much as possible. They turn us into addicts.</p>
<p>Â </p>
<p>F: how many times do you check your Facebook in a day?</p>
<p>I am not a fan of Facebook. I do not have it on my phone.Â  Still, I check it in the morning on my laptop, and maybe twice more per day. I have a trick though: I do not scroll down. I only check the top bar to see if someone has invited me to an event, or contacted me directly. But from time to time, this resolution of mine slips, and I catch myself scrolling down, without even realising it!</p>
<p>Â </p>
<p>F: is it the first thing you check when you wake up?</p>
<p>No because usually I have a message from you!! :)Â But yes, while I have my coffee I do a sweep on Facebook and twitter and maybe Instagram, plus the news.</p>
<p>Â </p>
<p><em>F: </em>Check how much time you spend on Facebook</p>
<p>And then sum it up to your email, twitter, reddit, youtube, instagram, etc. (all viable channels for ads to reach you)</p>
<p>We have an answer. More on that later.Â <br>
Clearly in this episode there is some form of addiction we would like to talk about. So letâ€™s start from the beginning: how does addiction work?</p>
<p>Dopamine is a hormone produced by our body, and in the brain it works as a neurotransmitter, a chemical that neurons use to transmit signals to each other. One of the main functions of dopamine is to shape the â€œreward-motivated behaviourâ€: this is the way our brain learns through association, positive reinforcement, incentives, and positively-valenced emotions, in particular, pleasure. In other words, it makes our brain desire more of the things that make us feel good. These things can be for example good food, sex, and crucially, good social interactions, like hugging your friends or your baby, or having a laugh together.Â Because we are evolved to be social animals with complex social structures, successful social interactions are an evolutionary advantage, and therefore they trigger dopamine release in our brain, which makes us feel good, and reinforces the association between the action and the reward. This feeling motivates us to repeat the behaviour.</p>
<p>Â </p>
<p>F: now that you mention reinforcement, I recall that this mechanism is so powerful and effective that in fact we have been inspired by nature and replicated it in-silico with reinforcement learning. The idea is to motivate (and eventually create an addictive pattern) an agent to follow what is called the optimal policy by giving it positive rewards or punishing it when things donâ€™t go the way we planned.Â </p>
<p>In our brain, every time an action produces a reward, the connection between action and reward becomes stronger. Through reinforcement, a baby learns to distinguish a cat from a dog, or that fire hurts (that was me).</p>
<p>Â </p>
<p>F: and so this means that all the social interactions people get from social media platforms are in fact doing the same, right?Â </p>
<p>Yes, but with a difference: smartphones in our pockets keep us connected to an unlimited reserve of constant social interactions. This constant flux of notifications - the rewards - flood our brain with dopamine. The mechanism of reinforcement can spin out of control. The reward pathways in our brain can malfunction, and this leads to addiction.Â </p>
<p>Â </p>
<p>F: you are saying that social media has LITERALLY the effect of a drug?Â </p>
<p>Yes. In fact, social media platforms are DESIGNED to exploit the rewards systems in our brain. They are designed to work like a drug. <br>
Have you been to a casino and played roulette or the slot machines?Â </p>
<p>Â </p>
<p>F: ...maybe?</p>
<p>Why is it fun to play roulette? The fun comes from the WAIT before the reward. You put a chip on a number, you donâ€™t know how itâ€™s going to go. You wait for the ball to spin, you get excited. And from time to time, BAM! Your number comes out. Now, compare this with posting something on facebook. You write a message into the void, waitâ€¦. And then the LIKES start coming in.Â </p>
<p>Â </p>
<p>F:Â  yeah i find that familiar...Â </p>
<p>Contrary to the casino, social media platforms do not want our money, in fact they are free. What they want is, and what we are buying into with, is our time. Because the longer we stay on, the longer they can show us ads, and the more money advertisers can pay them. This is no accident, this is the business model.Â But asking for our time out loud would not work, we would probably not consciously give it to them. So, like a casino, they make it hard for us to get off, once we are on: they make us crave the likes, the right-swipes, the retweets, the subscriptions. So we check in, we stay on, we keep scrolling, because we hope to get those rewards.Â The short-term satisfaction of getting a â€œlikeâ€ is a little boost of dopamine in our brain. We get used to it, and we want more.Â </p>
<p>Â </p>
<p>F: a lot of machine learning is also being deployed to amplify this form of addiction and make it.... Well more addictive :) But the question is: how such powerful ads and scenarios are so effective because of the algorithms and how much just because humans are just wired to obey such dynamics? My question is: are we essentially flawed or are these algorithms truly powerful?Â </p>
<p>It is not a flaw, itâ€™s a feature. The way our brain has evolved has been in response to very specific needs. In particular for this conversation, our brain is wired to favour social interactions, because it is an evolutionary advantage. These algorithms exploit these features of the brain on purpose, they are designed to exploit them.Â </p>
<p>Â </p>
<p>F: I believe so, but I also believe that the human brain is a powerful machine, so it should be able to predict what satisfaction it can get from social media. So how does it happen that we become addicted?</p>
<p>An example of optimisation strategy that social media platforms use is based on the principle of â€œreward prediction error codingâ€.Â Our brain learns to find patterns in data - this is a basic survival skill - and therefore learns when to expect a reward for a given set of actions. I eat cake, therefore I am happy. Every time.Â <br>
Imagine a scenario, where we have learnt through experience that when we play slot machines in a casino, we learn that we win some money once every 100 times we pull the lever. The difference between predicted and received rewards is a known, fixed quantity. If so, just after winning once, we have almost zero incentive to play again.Â So the casino fixes the slot machines, to introduce a random element to the timing of the reward. Suddenly our prediction error increases substantially. In this margin of error, in the time between the action (pull the lever) and the reward (maybe) our brain has time to make us anticipate the result and make us excited at the possibility, and this releases dopamine. Playing in itself becomes a reward. <br>
<br>
F: There is an equivalent in reinforcement learning called the grid world which consists in a mouse getting to the cheese in a maze. In reinforcement learning, everything works smooth as long as the cheese stays in the same place.</p>
<p>Exactly! Now social media apps implement an equivalent trick, called â€œvariable reward schedulesâ€.</p>
<p>In our brain, after an action we get a reward or punishment, and we generate positive or negative feedback to that action. <br>
Social media apps optimise their algorithms for the ideal balance of negative and positive feedbackÂ  in our brains caused by the difference between these predicted and received rewards.Â </p>
<p>If we perceive a reward to be delivered at random, and - crucially - if checking for the reward comes at little cost, like opening the Facebook app, we end up checking for rewards all the time. Every time we are just a little bit bored, without even thinking, we check the app. The Facebook reward system (the schedule and triggers of notification and likes) has been optimised to maximise this behaviour.Â </p>
<p>Â </p>
<p>F: are you saying that buffering some likes and then finding the right moment to show them to the user can make the user crave for reward?Â </p>
<p>Oh yes. Instagram will withhold likes for a period of time, causing a dip in reward compared to the expected level. It will then deliver them later in larger bundles, thus boosting the reward above the expected value, which trigger extra dopamine release, which sends us on a high akin to a cocaine hit.</p>
<p>Â </p>
<p>F: Dear audience, do you remember my question? How much time do each of you spend on social media (or similar) in a day? And why do we still do it?</p>
<p>The fundamental feature here is how little is the perceived cost to check for the reward: I just need to open the app. We perceive this cost to be minimal, so we donâ€™t even think about it. YouTube for instance had the autoplay feature, so you need to do absolutely nothing to remain on the app.Â But the cost is cumulative over time, it becomes hours in our day, days in a month, years in our lives!! 2 hours of social media per day amounts to 1 month per year.Â </p>
<p>Â </p>
<p>F: But itâ€™s so EASY, it has become so natural to use social media for everything. To use Google for everything.</p>
<p>The convenience that the platforms give us is one of the most dangerous things about them, and not only for our individual life. The convenience of reaching so many users, together with the business model ofÂ monetising attention is one of the causes of the centralisation of the internet, i.e. the fact a few giant platforms control most of the internet traffic.Â Revenue from ads is concentrated on big platforms, and content creators have no other choice but to use them, if they want to be competitive.Â The internet went from looking like a distributed network to a centralised network.Â And this in turn causes data to be centralised, in a self-reinforcing loop. Most of human conversations and interactions pass through the servers of a handful of private corporations.</p>
<p><br>
<br>
</p>
<p>Conclusion</p>
<p>As Data scientists we should be aware of this (and we think mostly we are). We should also be ethically responsible. I think that being a data scientist no longer has a neutral connotation. Algorithms have this huge power of manipulating human behaviour, and letâ€™s be honest, we are the only ones who really understand how they work. So we have a responsibility here.Â </p>
<p>There are some organisations, like Data For Democracy for example, who are advocating for something equivalent to the Hippocratic Oath for data scientists. Do no harm.Â Â </p>
<p>Â </p>
References
<p class="content-title" lang="en">Dopamine reward prediction error codingÂ <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/'>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/</a></p>
<p class="hidden-xs hidden-print">Skinner - Operant ConditioningÂ <a href='https://www.simplypsychology.org/operant-conditioning.html'>https://www.simplypsychology.org/operant-conditioning.html</a></p>


<p class="entry-title">Dopamine, Smartphones & You: A battle for your timeÂ <a href='http://sitn.hms.harvard.edu/flash/2018/dopamine-smartphones-battle-time/'>http://sitn.hms.harvard.edu/flash/2018/dopamine-smartphones-battle-time/</a></p>


<p class="firstHeading" lang="en">Reward systemÂ <a href='https://en.wikipedia.org/wiki/Reward_system'>https://en.wikipedia.org/wiki/Reward_system</a></p>
<p>Data for democracyÂ <a href='/datascienceathome/episode/update/id/datafordemocracy.org'>datafordemocracy.org</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ecyxmx/086_b.mp3" length="43708418" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Chamath Palihapitiya, former Vice President of User Growth at Facebook, was giving a talk at Stanford University, when he said this: â€œI feel tremendous guilt. The short-term, dopamine-driven feedback loops that we have created are destroying how society works â€.
He was referring to how social media platforms leverage our neurological build-up in the same way slot machines and cocaine do, to keep us using their products as much as possible. They turn us into addicts.
Â 
F: how many times do you check your Facebook in a day?
I am not a fan of Facebook. I do not have it on my phone.Â  Still, I check it in the morning on my laptop, and maybe twice more per day. I have a trick though: I do not scroll down. I only check the top bar to see if someone has invited me to an event, or contacted me directly. But from time to time, this resolution of mine slips, and I catch myself scrolling down, without even realising it!
Â 
F: is it the first thing you check when you wake up?
No because usually I have a message from you!! :)Â But yes, while I have my coffee I do a sweep on Facebook and twitter and maybe Instagram, plus the news.
Â 
F: Check how much time you spend on Facebook
And then sum it up to your email, twitter, reddit, youtube, instagram, etc. (all viable channels for ads to reach you)
We have an answer. More on that later.Â Clearly in this episode there is some form of addiction we would like to talk about. So letâ€™s start from the beginning: how does addiction work?
Dopamine is a hormone produced by our body, and in the brain it works as a neurotransmitter, a chemical that neurons use to transmit signals to each other. One of the main functions of dopamine is to shape the â€œreward-motivated behaviourâ€: this is the way our brain learns through association, positive reinforcement, incentives, and positively-valenced emotions, in particular, pleasure. In other words, it makes our brain desire more of the things that make us feel good. These things can be for example good food, sex, and crucially, good social interactions, like hugging your friends or your baby, or having a laugh together.Â Because we are evolved to be social animals with complex social structures, successful social interactions are an evolutionary advantage, and therefore they trigger dopamine release in our brain, which makes us feel good, and reinforces the association between the action and the reward. This feeling motivates us to repeat the behaviour.
Â 
F: now that you mention reinforcement, I recall that this mechanism is so powerful and effective that in fact we have been inspired by nature and replicated it in-silico with reinforcement learning. The idea is to motivate (and eventually create an addictive pattern) an agent to follow what is called the optimal policy by giving it positive rewards or punishing it when things donâ€™t go the way we planned.Â 
In our brain, every time an action produces a reward, the connection between action and reward becomes stronger. Through reinforcement, a baby learns to distinguish a cat from a dog, or that fire hurts (that was me).
Â 
F: and so this means that all the social interactions people get from social media platforms are in fact doing the same, right?Â 
Yes, but with a difference: smartphones in our pockets keep us connected to an unlimited reserve of constant social interactions. This constant flux of notifications - the rewards - flood our brain with dopamine. The mechanism of reinforcement can spin out of control. The reward pathways in our brain can malfunction, and this leads to addiction.Â 
Â 
F: you are saying that social media has LITERALLY the effect of a drug?Â 
Yes. In fact, social media platforms are DESIGNED to exploit the rewards systems in our brain. They are designed to work like a drug. Have you been to a casino and played roulette or the slot machines?Â 
Â 
F: ...maybe?
Why is it fun to play roulette? The fun comes from the WAIT before the reward. You put a chip on a number, you donâ€™t know how itâ€™s goin]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:45</itunes:duration>
                <itunes:episode>86</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>More powerful deep learning with transformers (Ep. 84) (Rebroadcast)</title>
        <itunes:title>More powerful deep learning with transformers (Ep. 84) (Rebroadcast)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/more-powerful-deep-learning-with-transformers-ep-84-rebroadcast/</link>
                    <comments>https://datascienceathome.podbean.com/e/more-powerful-deep-learning-with-transformers-ep-84-rebroadcast/#comments</comments>        <pubDate>Wed, 27 Nov 2019 23:24:40 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/more-powerful-deep-learning-with-transformers-ep-84-rebroadcast-a4cb90fa8a787241b6ab5ac0cece5fe6</guid>
                                    <description><![CDATA[<p>Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. 
Such architecture is built on top of another important concept already known to the community: self-attention.
In this episode I explain what these mechanisms are, how they work and why they are so powerful.</p>
<p>Don't forget to subscribe to our <a href='https://amethix.com/newsletter'>Newsletter</a>Â or join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:center;">Â </p>
References
<ul><li class="title mathjax">Attention is all you needÂ 
<a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a></li>
<li class="title mathjax">The illustrated transformerÂ 
<a href='https://jalammar.github.io/illustrated-transformer'>https://jalammar.github.io/illustrated-transformer
</a></li>
<li class="dm-h2 article-description">Self-attention for generative modelsÂ 
<a href='http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf'>http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. <br>
Such architecture is built on top of another important concept already known to the community: self-attention.<br>
In this episode I explain what these mechanisms are, how they work and why they are so powerful.</p>
<p>Don't forget to subscribe to our <a href='https://amethix.com/newsletter'>Newsletter</a>Â or join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:center;">Â </p>
References
<ul><li class="title mathjax">Attention is all you needÂ <br>
<a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a></li>
<li class="title mathjax">The illustrated transformerÂ <br>
<a href='https://jalammar.github.io/illustrated-transformer'>https://jalammar.github.io/illustrated-transformer<br>
</a></li>
<li class="dm-h2 article-description">Self-attention for generative modelsÂ <br>
<a href='http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf'>http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/86qzvj/084.mp3" length="72464847" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. Such architecture is built on top of another important concept already known to the community: self-attention.In this episode I explain what these mechanisms are, how they work and why they are so powerful.
Don't forget to subscribe to our NewsletterÂ or join the discussion on our Discord server
Â 
References
Attention is all you needÂ https://arxiv.org/abs/1706.03762
The illustrated transformerÂ https://jalammar.github.io/illustrated-transformer
Self-attention for generative modelsÂ http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:44</itunes:duration>
                <itunes:episode>85</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/datascienceathome_cover_v4.png" />    </item>
    <item>
        <title>How to improve the stability of training a GAN (Ep. 88)</title>
        <itunes:title>How to improve the stability of training a GAN (Ep. 88)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-to-improve-the-stability-of-training-a-gan-ep-88/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-to-improve-the-stability-of-training-a-gan-ep-88/#comments</comments>        <pubDate>Mon, 18 Nov 2019 03:30:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/how-to-improve-the-stability-of-training-a-gan-ep-88-4f36e6b31c6f33718eafdc494c57825c</guid>
                                    <description><![CDATA[<p>Generative Adversarial Networks or GANs are very powerful tools to generate data. However, training a GAN is not easy. More specifically, GANs suffer of three major issues such as instability of the training procedure, mode collapse and vanishing gradients.</p>
<p>Â </p>
<p>In this episode I not only explain the most challenging issues one would encounter while designing and training Generative Adversarial Networks. But also some methods and architectures to mitigate them. In addition I elucidate the three specific strategies that researchers are considering to improve the accuracy and the reliability of GANs.</p>
<p>Â </p>
The most tedious issues of GANs
<p>Â </p>
Convergence to equilibrium
<p>Â </p>
<p>A typical GAN is formed by at least two networks: a generator G and a discriminator D. The generator's task is to generate samples from random noise. In turn, the discriminator has to learn to distinguish fake samples from real ones. While it is theoretically possible that generators and discriminators converge to a Nash Equilibrium (at which both networks are in their optimal state), reaching such equilibrium is not easy.Â </p>
<p>Â </p>
Vanishing gradients
<p>Â </p>
<p>Moreover, a very accurate discriminator would push the loss function towards lower and lower values. This in turn, might cause the gradient to vanish and the entire network to stop learning completely.Â </p>
<p>Â </p>
Mode collapse
<p>Â </p>
<p>Another phenomenon that is easy to observe when dealing with GANs is mode collapse. That is the incapability of the model to generate diverse samples. This in turn, leads to generated data that are more and more similar to the previous ones. Hence, the entire generated dataset would be just concentrated around a particular statistical value.Â </p>
<p>Â </p>
The solution
<p>Â </p>
<p>Researchers have taken into consideration several approaches to overcome such issues. They have been playing with architectural changes, different loss functions and game theory.</p>
<p>Â </p>
<p>Listen to the full episode to know more about the most effective strategies to build GANs that are reliable and robust. 
Don't forget to <a href='https://discord.gg/4UNKGf3'>join the conversation</a> on our new Discord channel. See you there!</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Generative Adversarial Networks or GANs are very powerful tools to generate data. However, training a GAN is not easy. More specifically, GANs suffer of three major issues such as instability of the training procedure, mode collapse and vanishing gradients.</p>
<p>Â </p>
<p>In this episode I not only explain the most challenging issues one would encounter while designing and training Generative Adversarial Networks. But also some methods and architectures to mitigate them. In addition I elucidate the three specific strategies that researchers are considering to improve the accuracy and the reliability of GANs.</p>
<p>Â </p>
The most tedious issues of GANs
<p>Â </p>
Convergence to equilibrium
<p>Â </p>
<p>A typical GAN is formed by at least two networks: a generator G and a discriminator D. The generator's task is to generate samples from random noise. In turn, the discriminator has to learn to distinguish fake samples from real ones. While it is theoretically possible that generators and discriminators converge to a Nash Equilibrium (at which both networks are in their optimal state), reaching such equilibrium is not easy.Â </p>
<p>Â </p>
Vanishing gradients
<p>Â </p>
<p>Moreover, a very accurate discriminator would push the loss function towards lower and lower values. This in turn, might cause the gradient to vanish and the entire network to stop learning completely.Â </p>
<p>Â </p>
Mode collapse
<p>Â </p>
<p>Another phenomenon that is easy to observe when dealing with GANs is mode collapse. That is the incapability of the model to generate diverse samples. This in turn, leads to generated data that are more and more similar to the previous ones. Hence, the entire generated dataset would be just concentrated around a particular statistical value.Â </p>
<p>Â </p>
The solution
<p>Â </p>
<p>Researchers have taken into consideration several approaches to overcome such issues. They have been playing with architectural changes, different loss functions and game theory.</p>
<p>Â </p>
<p>Listen to the full episode to know more about the most effective strategies to build GANs that are reliable and robust. <br>
Don't forget to <a href='https://discord.gg/4UNKGf3'>join the conversation</a> on our new Discord channel. See you there!</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/gs49cv/GAN_stabilization.mp3" length="54425728" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Generative Adversarial Networks or GANs are very powerful tools to generate data. However, training a GAN is not easy. More specifically, GANs suffer of three major issues such as instability of the training procedure, mode collapse and vanishing gradients.
Â 
In this episode I not only explain the most challenging issues one would encounter while designing and training Generative Adversarial Networks. But also some methods and architectures to mitigate them. In addition I elucidate the three specific strategies that researchers are considering to improve the accuracy and the reliability of GANs.
Â 
The most tedious issues of GANs
Â 
Convergence to equilibrium
Â 
A typical GAN is formed by at least two networks: a generator G and a discriminator D. The generator's task is to generate samples from random noise. In turn, the discriminator has to learn to distinguish fake samples from real ones. While it is theoretically possible that generators and discriminators converge to a Nash Equilibrium (at which both networks are in their optimal state), reaching such equilibrium is not easy.Â 
Â 
Vanishing gradients
Â 
Moreover, a very accurate discriminator would push the loss function towards lower and lower values. This in turn, might cause the gradient to vanish and the entire network to stop learning completely.Â 
Â 
Mode collapse
Â 
Another phenomenon that is easy to observe when dealing with GANs is mode collapse. That is the incapability of the model to generate diverse samples. This in turn, leads to generated data that are more and more similar to the previous ones. Hence, the entire generated dataset would be just concentrated around a particular statistical value.Â 
Â 
The solution
Â 
Researchers have taken into consideration several approaches to overcome such issues. They have been playing with architectural changes, different loss functions and game theory.
Â 
Listen to the full episode to know more about the most effective strategies to build GANs that are reliable and robust. Don't forget to join the conversation on our new Discord channel. See you there!
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:20</itunes:duration>
                <itunes:episode>84</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>What if I train a neural network with random data? (with StanisÅ‚aw JastrzÄ™bski) (Ep. 87)</title>
        <itunes:title>What if I train a neural network with random data? (with StanisÅ‚aw JastrzÄ™bski) (Ep. 87)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/memorisation-and-generalisation-in-deep-learning-with-stanislaw-jastrzebski-ep-87/</link>
                    <comments>https://datascienceathome.podbean.com/e/memorisation-and-generalisation-in-deep-learning-with-stanislaw-jastrzebski-ep-87/#comments</comments>        <pubDate>Tue, 12 Nov 2019 07:21:53 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/memorisation-and-generalisation-in-deep-learning-with-stanislaw-jastrzebski-ep-87-b7137337ff0f254764d6c4de22d97565</guid>
                                    <description><![CDATA[<p>What happens to a neural network trained with random data? </p>
<p>Are massive neural networks just lookup tables or do they truly learn something?Â </p>
<p>Todayâ€™s episode will be about memorisation and generalisation in deep learning, with <a href='https://kudkudak.github.io/'>Stanislaw JastrzÄ™bski</a> from New York University.</p>
<p>Stan spent two summers as a visiting student with <a href='http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html'>Prof. Yoshua Bengio</a>Â and has been working onÂ </p>
<ul><li style="font-weight:400;">Understanding and improving how deep network generalise</li>
<li style="font-weight:400;">Representation Learning</li>
<li style="font-weight:400;">Natural Language Processing</li>
<li style="font-weight:400;">Computer Aided Drug Design</li>
</ul>
<p>Â </p>
What makes deep learning unique?
<p>I have asked him a few questions for which I was looking for an answer for a long time. For instance, what is deep learning bringing to the table that other methods donâ€™t or are not capable of?Â 
Stan believe that the one thing that makes deep learning special is representation learning. All the other competing methods, be it kernel machines, or random forests, do not have this capability. Moreover, optimisation (SGD) lies at the heart of representation learning in the sense that it allows finding good representations.Â </p>
<p>Â </p>
What really improves the training quality of a neural network?
<p>We discussed about the accuracy of neural networks depending pretty much on how good the Stochastic Gradient Descent method is at finding minima of the loss function. What would influence such minima?
Stan's answer has revealed that training set accuracy or loss value is not that interesting actually. It is relatively easy to overfit data (i.e. achieve the lowest loss possible), provided a large enough network, and a large enough computational budget. However, shape of the minima, or performance on validation sets are in a quite fascinating way influenced by optimisation. 
Optimisation in the beginning of the trajectory, steers such trajectory towards minima of certain properties that go much further than just training accuracy.</p>
<p>As always we spoke about the future of AI and the role deep learning will play.</p>
<p>I hope you enjoy the show!</p>
<p>Don't forget to <a href='https://discord.gg/4UNKGf3'>join the conversation</a> on our new Discord channel. See you there!</p>
<p>Â </p>
References
<p>Â </p>
<p>Homepage ofÂ StanisÅ‚aw JastrzÄ™bskiÂ <a href='https://kudkudak.github.io/'>https://kudkudak.github.io/</a></p>
<p>A Closer Look at Memorization in Deep NetworksÂ <a href='https://t.co/mpE4Mi98VM?amp=1'>https://arxiv.org/abs/1706.05394</a></p>
<p class="title mathjax">Three Factors Influencing Minima in SGDÂ <a href='https://t.co/6r3SUg6i7Z?amp=1'>https://arxiv.org/abs/1711.04623</a></p>
<p class="title mathjax">Don't Decay the Learning Rate, Increase the Batch SizeÂ <a href='https://t.co/9ZpYxpZPHK?amp=1'>https://arxiv.org/abs/1711.00489</a></p>
<p class="title mathjax">Stiffness: A New Perspective on Generalization in Neural NetworksÂ <a href='https://t.co/Gzsxogf7uT?amp=1'>https://arxiv.org/abs/1901.09491</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>What happens to a neural network trained with random data? </p>
<p>Are massive neural networks just lookup tables or do they truly learn something?Â </p>
<p>Todayâ€™s episode will be about memorisation and generalisation in deep learning, with <a href='https://kudkudak.github.io/'>Stanislaw JastrzÄ™bski</a> from New York University.</p>
<p>Stan spent two summers as a visiting student with <a href='http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html'>Prof. Yoshua Bengio</a>Â and has been working onÂ </p>
<ul><li style="font-weight:400;">Understanding and improving how deep network generalise</li>
<li style="font-weight:400;"><em>Representation Learning</em></li>
<li style="font-weight:400;"><em>Natural Language Processing</em></li>
<li style="font-weight:400;"><em>Computer Aided Drug Design</em></li>
</ul>
<p>Â </p>
What makes deep learning unique?
<p>I have asked him a few questions for which I was looking for an answer for a long time. For instance, what is deep learning bringing to the table that other methods donâ€™t or are not capable of?Â <br>
Stan believe that the one thing that makes deep learning special is representation learning. All the other competing methods, be it kernel machines, or random forests, do not have this capability. Moreover, optimisation (SGD) lies at the heart of representation learning in the sense that it allows finding good representations.Â </p>
<p>Â </p>
What really improves the training quality of a neural network?
<p>We discussed about the accuracy of neural networks depending pretty much on how good the Stochastic Gradient Descent method is at finding minima of the loss function. What would influence such minima?<br>
Stan's answer has revealed that training set accuracy or loss value is not that interesting actually. It is relatively easy to overfit data (i.e. achieve the lowest loss possible), provided a large enough network, and a large enough computational budget. However, shape of the minima, or performance on validation sets are in a quite fascinating way influenced by optimisation. <br>
Optimisation in the beginning of the trajectory, steers such trajectory towards minima of certain properties that go much further than just training accuracy.</p>
<p>As always we spoke about the future of AI and the role deep learning will play.</p>
<p>I hope you enjoy the show!</p>
<p>Don't forget to <a href='https://discord.gg/4UNKGf3'>join the conversation</a> on our new Discord channel. See you there!</p>
<p>Â </p>
References
<p>Â </p>
<p>Homepage ofÂ StanisÅ‚aw JastrzÄ™bskiÂ <a href='https://kudkudak.github.io/'>https://kudkudak.github.io/</a></p>
<p>A Closer Look at Memorization in Deep NetworksÂ <a href='https://t.co/mpE4Mi98VM?amp=1'>https://arxiv.org/abs/1706.05394</a></p>
<p class="title mathjax">Three Factors Influencing Minima in SGDÂ <a href='https://t.co/6r3SUg6i7Z?amp=1'>https://arxiv.org/abs/1711.04623</a></p>
<p class="title mathjax">Don't Decay the Learning Rate, Increase the Batch SizeÂ <a href='https://t.co/9ZpYxpZPHK?amp=1'>https://arxiv.org/abs/1711.00489</a></p>
<p class="title mathjax">Stiffness: A New Perspective on Generalization in Neural NetworksÂ <a href='https://t.co/Gzsxogf7uT?amp=1'>https://arxiv.org/abs/1901.09491</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/q5rxvq/stan_jas.mp3" length="37683954" type="audio/mpeg"/>
        <itunes:summary><![CDATA[What happens to a neural network trained with random data? 
Are massive neural networks just lookup tables or do they truly learn something?Â 
Todayâ€™s episode will be about memorisation and generalisation in deep learning, with Stanislaw JastrzÄ™bski from New York University.
Stan spent two summers as a visiting student with Prof. Yoshua BengioÂ and has been working onÂ 
Understanding and improving how deep network generalise
Representation Learning
Natural Language Processing
Computer Aided Drug Design
Â 
What makes deep learning unique?
I have asked him a few questions for which I was looking for an answer for a long time. For instance, what is deep learning bringing to the table that other methods donâ€™t or are not capable of?Â Stan believe that the one thing that makes deep learning special is representation learning. All the other competing methods, be it kernel machines, or random forests, do not have this capability. Moreover, optimisation (SGD) lies at the heart of representation learning in the sense that it allows finding good representations.Â 
Â 
What really improves the training quality of a neural network?
We discussed about the accuracy of neural networks depending pretty much on how good the Stochastic Gradient Descent method is at finding minima of the loss function. What would influence such minima?Stan's answer has revealed that training set accuracy or loss value is not that interesting actually. It is relatively easy to overfit data (i.e. achieve the lowest loss possible), provided a large enough network, and a large enough computational budget. However, shape of the minima, or performance on validation sets are in a quite fascinating way influenced by optimisation. Optimisation in the beginning of the trajectory, steers such trajectory towards minima of certain properties that go much further than just training accuracy.
As always we spoke about the future of AI and the role deep learning will play.
I hope you enjoy the show!
Don't forget to join the conversation on our new Discord channel. See you there!
Â 
References
Â 
Homepage ofÂ StanisÅ‚aw JastrzÄ™bskiÂ https://kudkudak.github.io/
A Closer Look at Memorization in Deep NetworksÂ https://arxiv.org/abs/1706.05394
Three Factors Influencing Minima in SGDÂ https://arxiv.org/abs/1711.04623
Don't Decay the Learning Rate, Increase the Batch SizeÂ https://arxiv.org/abs/1711.00489
Stiffness: A New Perspective on Generalization in Neural NetworksÂ https://arxiv.org/abs/1901.09491]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:37</itunes:duration>
                <itunes:episode>83</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Deeplearning is easier when it is illustrated (with Jon Krohn) (Ep. 86)</title>
        <itunes:title>Deeplearning is easier when it is illustrated (with Jon Krohn) (Ep. 86)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/deeplearning-is-easier-when-it-is-illustrated-with-jon-krohn-ep-86/</link>
                    <comments>https://datascienceathome.podbean.com/e/deeplearning-is-easier-when-it-is-illustrated-with-jon-krohn-ep-86/#comments</comments>        <pubDate>Tue, 05 Nov 2019 08:33:21 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/deeplearning-is-easier-when-it-is-illustrated-with-jon-krohn-ep-86-7f33d41c92c2ca63ea902f7b5920b2a9</guid>
                                    <description><![CDATA[In this episode I speak with Jon Krohn, author of <a href='https://www.deeplearningillustrated.com/'>Deeplearning Illustrated</a>Â a book that makes deep learning easier to grasp.Â 
We also talk about some important guidelines to take into account whenever you implement a deep learning model, how to deal with bias in machine learning used to match jobs to candidates and the future of AI.Â 
Â 
Â 
You can purchase the book fromÂ <a href='http://informit.com/dsathome'>informit.com/dsathome</a>Â with code DSATHOME and getÂ 40% off books/eBooks and 60% off video training]]></description>
                                                            <content:encoded><![CDATA[In this episode I speak with Jon Krohn, author of <a href='https://www.deeplearningillustrated.com/'>Deeplearning Illustrated</a>Â a book that makes deep learning easier to grasp.Â 
We also talk about some important guidelines to take into account whenever you implement a deep learning model, how to deal with bias in machine learning used to match jobs to candidates and the future of AI.Â 
Â 
Â 
You can purchase the book fromÂ <a href='http://informit.com/dsathome'>informit.com/dsathome</a>Â with code DSATHOME and getÂ 40% off books/eBooks and 60% off video training]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cuaqku/085.mp3" length="86198150" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak with Jon Krohn, author of Deeplearning IllustratedÂ a book that makes deep learning easier to grasp.Â 
We also talk about some important guidelines to take into account whenever you implement a deep learning model, how to deal with bias in machine learning used to match jobs to candidates and the future of AI.Â 
Â 
Â 
You can purchase the book fromÂ informit.com/dsathomeÂ with code DSATHOME and getÂ 40% off books/eBooks and 60% off video training]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>44:53</itunes:duration>
                <itunes:episode>82</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>[RB] How to generate very large images with GANs (Ep. 85)</title>
        <itunes:title>[RB] How to generate very large images with GANs (Ep. 85)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-how-to-generate-very-large-images-with-gans/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-how-to-generate-very-large-images-with-gans/#comments</comments>        <pubDate>Mon, 04 Nov 2019 08:41:32 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/rb-how-to-generate-very-large-images-with-gans-0b59f4b32e8f4a8ca0bc0a7319838771</guid>
                                    <description><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. 
The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.
Enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p class="title mathjax" style="text-align:left;">Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ <a href='https://arxiv.org/abs/1907.01376'>https://arxiv.org/abs/1907.01376</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. <br>
The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.<br>
Enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p class="title mathjax" style="text-align:left;">Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ <a href='https://arxiv.org/abs/1907.01376'>https://arxiv.org/abs/1907.01376</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/88dts4/077.mp3" length="28223030" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join the discussion on our Discord server
In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.Enjoy the show!
Â 
References
Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ https://arxiv.org/abs/1907.01376]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:41</itunes:duration>
                <itunes:episode>81</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>More powerful deep learning with transformers (Ep. 84)</title>
        <itunes:title>More powerful deep learning with transformers (Ep. 84)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/more-powerful-deep-learning-with-transformers/</link>
                    <comments>https://datascienceathome.podbean.com/e/more-powerful-deep-learning-with-transformers/#comments</comments>        <pubDate>Sun, 27 Oct 2019 07:59:59 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/more-powerful-deep-learning-with-transformers-9a640566c9276a38d7432bdea8799644</guid>
                                    <description><![CDATA[<p>Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. 
Such architecture is built on top of another important concept already known to the community: self-attention.
In this episode I explain what these mechanisms are, how they work and why they are so powerful.</p>
<p>Don't forget to subscribe to our <a href='https://amethix.com/newsletter'>Newsletter</a>Â or join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:center;">Â </p>
References
<ul><li class="title mathjax">Attention is all you needÂ 
<a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a></li>
<li class="title mathjax">The illustrated transformerÂ 
<a href='https://jalammar.github.io/illustrated-transformer'>https://jalammar.github.io/illustrated-transformer
</a></li>
<li class="dm-h2 article-description">Self-attention for generative modelsÂ 
<a href='http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf'>http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. <br>
Such architecture is built on top of another important concept already known to the community: self-attention.<br>
In this episode I explain what these mechanisms are, how they work and why they are so powerful.</p>
<p>Don't forget to subscribe to our <a href='https://amethix.com/newsletter'>Newsletter</a>Â or join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:center;">Â </p>
References
<ul><li class="title mathjax">Attention is all you needÂ <br>
<a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a></li>
<li class="title mathjax">The illustrated transformerÂ <br>
<a href='https://jalammar.github.io/illustrated-transformer'>https://jalammar.github.io/illustrated-transformer<br>
</a></li>
<li class="dm-h2 article-description">Self-attention for generative modelsÂ <br>
<a href='http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf'>http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/86qzvj/084.mp3" length="72464847" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Some of the most powerful NLP models like BERT and GPT-2 have one thing in common: they all use the transformer architecture. Such architecture is built on top of another important concept already known to the community: self-attention.In this episode I explain what these mechanisms are, how they work and why they are so powerful.
Don't forget to subscribe to our NewsletterÂ or join the discussion on our Discord server
Â 
References
Attention is all you needÂ https://arxiv.org/abs/1706.03762
The illustrated transformerÂ https://jalammar.github.io/illustrated-transformer
Self-attention for generative modelsÂ http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:44</itunes:duration>
                <itunes:episode>80</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>[RB] Replicating GPT-2, the most dangerous NLP model (with Aaron Gokaslan) (Ep. 83)</title>
        <itunes:title>[RB] Replicating GPT-2, the most dangerous NLP model (with Aaron Gokaslan) (Ep. 83)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-replicating-gpt-2-the-most-dangerous-nlp-model-with-aaron-gokaslan/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-replicating-gpt-2-the-most-dangerous-nlp-model-with-aaron-gokaslan/#comments</comments>        <pubDate>Fri, 18 Oct 2019 05:13:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/rb-replicating-gpt-2-the-most-dangerous-nlp-model-with-aaron-gokaslan-3a4a2cf78ea535d9a7254f4bf0916612</guid>
                                    <description><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>In this episode, I am with <a href='/datascienceathome/episode/update/id/%20https:/skylion007.github.io/'>Aaron Gokaslan</a>, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because too accurate to be published. </p>
<p>We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. 
Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!</p>

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

<a href='https://phillipi.github.io/pix2pix/'>https://phillipi.github.io/pix2pix/</a>
Â 
CycleGAN:
<a href='https://junyanz.github.io/CycleGAN/'>https://junyanz.github.io/CycleGAN/</a>
Â 
GANimorph

Paper: <a href='https://arxiv.org/abs/1808.04325'>https://arxiv.org/abs/1808.04325</a>
Code: <a href='https://github.com/brownvc/ganimorph'>https://github.com/brownvc/ganimorph</a>
Â 
UNIT:<a href='https://arxiv.org/abs/1703.00848'>https://arxiv.org/abs/1703.00848</a>




MUNIT:<a href='https://github.com/NVlabs/MUNIT'>https://github.com/NVlabs/MUNIT</a>
DRIT:Â <a href='https://github.com/HsinYingLee/DRIT'>https://github.com/HsinYingLee/DRIT</a>



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: <a href='https://talktotransformer.com/'>https://talktotransformer.com/</a>
Blogpost:Â <a href='https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc'>https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc</a>

The Original Transformer Paper: <a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a>
Grover: The FakeNews generator and detector: <a href='https://rowanzellers.com/grover/'>https://rowanzellers.com/grover/</a>
Â 



Â 
]]></description>
                                                            <content:encoded><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>In this episode, I am with <a href='/datascienceathome/episode/update/id/%20https:/skylion007.github.io/'>Aaron Gokaslan</a>, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because <em>too accurate to be published</em>. </p>
<p>We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. <br>
Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!</p>

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

<a href='https://phillipi.github.io/pix2pix/'>https://phillipi.github.io/pix2pix/</a>
Â 
CycleGAN:
<a href='https://junyanz.github.io/CycleGAN/'>https://junyanz.github.io/CycleGAN/</a>
Â 
GANimorph<br>

Paper: <a href='https://arxiv.org/abs/1808.04325'>https://arxiv.org/abs/1808.04325</a>
Code: <a href='https://github.com/brownvc/ganimorph'>https://github.com/brownvc/ganimorph</a>
Â 
UNIT:<a href='https://arxiv.org/abs/1703.00848'>https://arxiv.org/abs/1703.00848</a>




MUNIT:<a href='https://github.com/NVlabs/MUNIT'>https://github.com/NVlabs/MUNIT</a>
DRIT:Â <a href='https://github.com/HsinYingLee/DRIT'>https://github.com/HsinYingLee/DRIT</a>



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: <a href='https://talktotransformer.com/'>https://talktotransformer.com/</a>
Blogpost:Â <a href='https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc'>https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc</a>
<br>
The Original Transformer Paper: <a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a>
Grover: The FakeNews generator and detector: <a href='https://rowanzellers.com/grover/'>https://rowanzellers.com/grover/</a>
Â 



Â 
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/c5wgwg/079.mp3" length="72562649" type="audio/mpeg"/>
        <itunes:summary><![CDATA[



Join the discussion on our Discord server
Â 
In this episode, I am with Aaron Gokaslan, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because too accurate to be published. 
We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

https://phillipi.github.io/pix2pix/
Â 
CycleGAN:
https://junyanz.github.io/CycleGAN/
Â 
GANimorph
Paper: https://arxiv.org/abs/1808.04325
Code: https://github.com/brownvc/ganimorph
Â 
UNIT:https://arxiv.org/abs/1703.00848




MUNIT:https://github.com/NVlabs/MUNIT
DRIT:Â https://github.com/HsinYingLee/DRIT



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: https://talktotransformer.com/
Blogpost:Â https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
The Original Transformer Paper: https://arxiv.org/abs/1706.03762
Grover: The FakeNews generator and detector: https://rowanzellers.com/grover/
Â 



Â 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:47</itunes:duration>
                <itunes:episode>79</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>What is wrong with reinforcement learning? (Ep. 82)</title>
        <itunes:title>What is wrong with reinforcement learning? (Ep. 82)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/what-is-wrong-with-reinforcement-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/what-is-wrong-with-reinforcement-learning/#comments</comments>        <pubDate>Tue, 15 Oct 2019 05:09:48 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/what-is-wrong-with-reinforcement-learning-ce6ea06396c307e9819d54e408424a29</guid>
                                    <description><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>After reinforcement learning agents doing great at playing Atari video games, Alpha Go, doing financial trading, dealing with language modeling, let me tell you the real story here.
In this episode I want to shine some light on reinforcement learning (RL) and the limitations that every practitioner should consider before taking certain directions.Â RL seems to work so well! What is wrong with it?</p>
<p>Â </p>

<p style="text-align:center;">Are you a listener ofÂ Data Science at HomeÂ podcast? 
A reader of the Amethix Blog?Â 
Or did you subscribe to theÂ Artificial Intelligence at your fingertipsÂ newsletter? 
In any case letâ€™s stay in touch!Â 
<a href='https://amethix.com/survey/'>https://amethix.com/survey/</a></p>

<p>Â </p>
<p>Â </p>
References
<ul><li class="title mathjax">Emergence of Locomotion Behaviours in Rich EnvironmentsÂ 
<a href='https://arxiv.org/abs/1707.02286'>https://arxiv.org/abs/1707.02286</a></li>
<li class="title mathjax">Rainbow: Combining Improvements in Deep Reinforcement LearningÂ 
<a href='https://arxiv.org/abs/1710.02298'>https://arxiv.org/abs/1710.02298</a></li>
<li class="dm-h2 article-description">AlphaGo Zero: Starting from scratchÂ 
<a href='https://deepmind.com/blog/article/alphago-zero-starting-scratch'>https://deepmind.com/blog/article/alphago-zero-starting-scratch</a></li>
</ul>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>After reinforcement learning agents doing great at playing Atari video games, Alpha Go, doing financial trading, dealing with language modeling, let me tell you the real story here.<br>
In this episode I want to shine some light on reinforcement learning (RL) and the limitations that every practitioner should consider before taking certain directions.Â RL seems to work so well! What is wrong with it?</p>
<p>Â </p>

<p style="text-align:center;">Are you a listener ofÂ <em>Data Science at Home</em>Â podcast? <br>
A reader of the Amethix Blog?Â <br>
Or did you subscribe to theÂ <em>Artificial Intelligence at your fingertips</em>Â newsletter? <br>
In any case letâ€™s stay in touch!Â <br>
<a href='https://amethix.com/survey/'>https://amethix.com/survey/</a></p>

<p>Â </p>
<p>Â </p>
References
<ul><li class="title mathjax">Emergence of Locomotion Behaviours in Rich EnvironmentsÂ <br>
<a href='https://arxiv.org/abs/1707.02286'>https://arxiv.org/abs/1707.02286</a></li>
<li class="title mathjax">Rainbow: Combining Improvements in Deep Reinforcement LearningÂ <br>
<a href='https://arxiv.org/abs/1710.02298'>https://arxiv.org/abs/1710.02298</a></li>
<li class="dm-h2 article-description">AlphaGo Zero: Starting from scratchÂ <br>
<a href='https://deepmind.com/blog/article/alphago-zero-starting-scratch'>https://deepmind.com/blog/article/alphago-zero-starting-scratch</a></li>
</ul>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/psk5z6/082.mp3" length="41863546" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join the discussion on our Discord server
Â 
After reinforcement learning agents doing great at playing Atari video games, Alpha Go, doing financial trading, dealing with language modeling, let me tell you the real story here.In this episode I want to shine some light on reinforcement learning (RL) and the limitations that every practitioner should consider before taking certain directions.Â RL seems to work so well! What is wrong with it?
Â 

Are you a listener ofÂ Data Science at HomeÂ podcast? A reader of the Amethix Blog?Â Or did you subscribe to theÂ Artificial Intelligence at your fingertipsÂ newsletter? In any case letâ€™s stay in touch!Â https://amethix.com/survey/

Â 
Â 
References
Emergence of Locomotion Behaviours in Rich EnvironmentsÂ https://arxiv.org/abs/1707.02286
Rainbow: Combining Improvements in Deep Reinforcement LearningÂ https://arxiv.org/abs/1710.02298
AlphaGo Zero: Starting from scratchÂ https://deepmind.com/blog/article/alphago-zero-starting-scratch
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:48</itunes:duration>
                <itunes:episode>78</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Have you met Shannon? Conversation with Jimmy Soni and Rob Goodman about one of the greatest minds in history (Ep. 81)</title>
        <itunes:title>Have you met Shannon? Conversation with Jimmy Soni and Rob Goodman about one of the greatest minds in history (Ep. 81)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman/</link>
                    <comments>https://datascienceathome.podbean.com/e/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman/#comments</comments>        <pubDate>Thu, 10 Oct 2019 09:23:02 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/have-you-met-shannon-conversation-with-jimmy-soni-and-rob-goodman-4dc9e67d91ca63d3e240d9c78fae4324</guid>
                                    <description><![CDATA[

<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>In this episode I have an amazing conversation with Jimmy Soni and Rob Goodman, authors of â€œA mind at playâ€, a book entirely dedicated to the life and achievements of Claude Shannon.Â Claude Shannon does not need any introduction. But for those who need a refresh, Shannon is the inventor of the information age.Â </p>
<p>Have you heard of binary code, entropy in information theory, data compression theory (the stuff behind mp3, mpg, zip, etc.), error correcting codes (the stuff that makes your RAM work well), n-grams, block ciphers, the beta distribution, the uncertainty coefficient?</p>
<p>All that stuff has been invented by Claude Shannon :)Â </p>

Â 
Articles:Â 
<a href='https://medium.com/the-mission/10-000-hours-with-claude-shannon-12-lessons-on-life-and-learning-from-a-genius-e8b9297bee8f'>https://medium.com/the-mission/10-000-hours-with-claude-shannon-12-lessons-on-life-and-learning-from-a-genius-e8b9297bee8f</a>

<a href='https://medium.com/the-mission/on-claude-shannons-103rd-birthday-here-are-103-memorable-claude-shannon-quotes-maxims-and-843de4c716cf?source=your_stories_page---------------------------'>https://medium.com/the-mission/on-claude-shannons-103rd-birthday-here-are-103-memorable-claude-shannon-quotes-maxims-and-843de4c716cf?source=your_stories_page---------------------------</a>

<a href='http://nautil.us/issue/51/limits/how-information-got-re_invented'>http://nautil.us/issue/51/limits/how-information-got-re_invented</a>

<a href='http://nautil.us/issue/50/emergence/claude-shannon-the-las-vegas-cheat'>http://nautil.us/issue/50/emergence/claude-shannon-the-las-vegas-cheat</a>

Â 
Claude's papers:
<a href='https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f'>https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f</a>

<a href='http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf'>http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf</a>
Â 
A mind at play (book links):Â 
<a href='http://amzn.to/2pasLMz'>http://amzn.to/2pasLMz</a>Â -- Hardcover
<a href='https://amzn.to/2oCfVL0'>https://amzn.to/2oCfVL0</a> -- Audio]]></description>
                                                            <content:encoded><![CDATA[

<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Â </p>
<p>In this episode I have an amazing conversation with Jimmy Soni and Rob Goodman, authors of <em>â€œA mind at playâ€</em>, a book entirely dedicated to the life and achievements of Claude Shannon.Â Claude Shannon does not need any introduction. But for those who need a refresh, Shannon is the inventor of the information age.Â </p>
<p>Have you heard of binary code, entropy in information theory, data compression theory (the stuff behind mp3, mpg, zip, etc.), error correcting codes (the stuff that makes your RAM work well), n-grams, block ciphers, the beta distribution, the uncertainty coefficient?</p>
<p>All that stuff has been invented by Claude Shannon :)Â </p>

Â 
Articles:Â 
<a href='https://medium.com/the-mission/10-000-hours-with-claude-shannon-12-lessons-on-life-and-learning-from-a-genius-e8b9297bee8f'>https://medium.com/the-mission/10-000-hours-with-claude-shannon-12-lessons-on-life-and-learning-from-a-genius-e8b9297bee8f</a><br>

<a href='https://medium.com/the-mission/on-claude-shannons-103rd-birthday-here-are-103-memorable-claude-shannon-quotes-maxims-and-843de4c716cf?source=your_stories_page---------------------------'>https://medium.com/the-mission/on-claude-shannons-103rd-birthday-here-are-103-memorable-claude-shannon-quotes-maxims-and-843de4c716cf?source=your_stories_page---------------------------</a><br>

<a href='http://nautil.us/issue/51/limits/how-information-got-re_invented'>http://nautil.us/issue/51/limits/how-information-got-re_invented</a><br>

<a href='http://nautil.us/issue/50/emergence/claude-shannon-the-las-vegas-cheat'>http://nautil.us/issue/50/emergence/claude-shannon-the-las-vegas-cheat</a>

Â 
Claude's papers:
<a href='https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f'>https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f</a><br>

<a href='http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf'>http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf</a>
Â 
A mind at play (book links):Â 
<a href='http://amzn.to/2pasLMz'>http://amzn.to/2pasLMz</a>Â -- Hardcover
<a href='https://amzn.to/2oCfVL0'>https://amzn.to/2oCfVL0</a> -- Audio]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/fupg2r/081.mp3" length="62146270" type="audio/mpeg"/>
        <itunes:summary><![CDATA[

Join the discussion on our Discord server
Â 
In this episode I have an amazing conversation with Jimmy Soni and Rob Goodman, authors of â€œA mind at playâ€, a book entirely dedicated to the life and achievements of Claude Shannon.Â Claude Shannon does not need any introduction. But for those who need a refresh, Shannon is the inventor of the information age.Â 
Have you heard of binary code, entropy in information theory, data compression theory (the stuff behind mp3, mpg, zip, etc.), error correcting codes (the stuff that makes your RAM work well), n-grams, block ciphers, the beta distribution, the uncertainty coefficient?
All that stuff has been invented by Claude Shannon :)Â 

Â 
Articles:Â 
https://medium.com/the-mission/10-000-hours-with-claude-shannon-12-lessons-on-life-and-learning-from-a-genius-e8b9297bee8f
https://medium.com/the-mission/on-claude-shannons-103rd-birthday-here-are-103-memorable-claude-shannon-quotes-maxims-and-843de4c716cf?source=your_stories_page---------------------------
http://nautil.us/issue/51/limits/how-information-got-re_invented
http://nautil.us/issue/50/emergence/claude-shannon-the-las-vegas-cheat

Â 
Claude's papers:
https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f
http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf
Â 
A mind at play (book links):Â 
http://amzn.to/2pasLMzÂ -- Hardcover
https://amzn.to/2oCfVL0 -- Audio]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>32:21</itunes:duration>
                <itunes:episode>77</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Attacking machine learning for fun and profit (with the authors of SecML Ep. 80)</title>
        <itunes:title>Attacking machine learning for fun and profit (with the authors of SecML Ep. 80)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/attacking-machine-learning-for-fun-and-profit-conversation-with-the-authors-of-secml/</link>
                    <comments>https://datascienceathome.podbean.com/e/attacking-machine-learning-for-fun-and-profit-conversation-with-the-authors-of-secml/#comments</comments>        <pubDate>Tue, 01 Oct 2019 02:51:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/attacking-machine-learning-for-fun-and-profit-conversation-with-the-authors-of-secml-e5134f45cf533e4c13a0d0c36f52d73e</guid>
                                    <description><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>As ML plays a more and more relevant role in many domains of everyday life, itâ€™s quite obvious to see more and more attacks to ML systems. In this episode we talk about the most popular attacks against machine learning systems and some mitigations designed by researchers Ambra Demontis and Marco Melis, from the University of Cagliari (Italy). The guests are also the authors of SecML, an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithms.Â Both Ambra and Marco are members of research group <a href='https://pralab.diee.unica.it/'>PRAlab</a>, under the supervision of Prof. Fabio Roli.
Â </p>
SecML Contributors
<p>Marco Melis (Ph.D Student, Project Maintainer, <a href='https://www.linkedin.com/in/melismarco/)'>https://www.linkedin.com/in/melismarco/)</a>
Ambra Demontis (Postdoc, <a href='https://pralab.diee.unica.it/it/AmbraDemontis)'>https://pralab.diee.unica.it/it/AmbraDemontis)Â </a>
Maura Pintor (Ph.D Student, <a href='https://it.linkedin.com/in/maura-pintor)'>https://it.linkedin.com/in/maura-pintor)</a>
Battista Biggio (Assistant Professor, <a href='https://pralab.diee.unica.it/it/BattistaBiggio)'>https://pralab.diee.unica.it/it/BattistaBiggio)</a>

</p>
References
<p>SecML: an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithmsÂ <a href='https://secml.gitlab.io/'>https://secml.gitlab.io/</a>.</p>
<p>Demontis et al., â€œWhy Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks,â€ presented at the 28th USENIX Security Symposium (USENIX Security 19), 2019, pp. 321â€“338.Â <a href='https://www.usenix.org/conference/usenixsecurity19/presentation/demontis'>https://www.usenix.org/conference/usenixsecurity19/presentation/demontis</a></p>
<p>W. Koh and P. Liang, â€œUnderstanding Black-box Predictions via Influence Functions,â€ in International Conference on Machine Learning (ICML), 2017.Â <a href='https://arxiv.org/abs/1703.04730'>https://arxiv.org/abs/1703.04730</a></p>
<p>Melis, A. Demontis, B. Biggio, G. Brown, G. Fumera, and F. Roli, â€œIs Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid,â€ in 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), 2017, pp. 751â€“759.Â <a href='https://arxiv.org/abs/1708.06939'>https://arxiv.org/abs/1708.06939</a></p>
<p>Biggio and F. Roli, â€œWild Patterns: Ten Years After the Rise of Adversarial Machine Learning,â€ Pattern Recognition, vol. 84, pp. 317â€“331, 2018.Â <a href='https://arxiv.org/abs/1712.03141'>https://arxiv.org/abs/1712.03141</a></p>
<p>Biggio et al., â€œEvasion attacks against machine learning at test time,â€ in Machine Learning and Knowledge Discovery in Databases (ECML PKDD), Part III, 2013, vol. 8190, pp. 387â€“402.Â <a href='https://arxiv.org/abs/1708.06131'>https://arxiv.org/abs/1708.06131</a></p>
<p>Biggio, B. Nelson, and P. Laskov, â€œPoisoning attacks against support vector machines,â€ in 29th Intâ€™l Conf. on Machine Learning, 2012, pp. 1807â€“1814.Â <a href='https://arxiv.org/abs/1206.6389'>https://arxiv.org/abs/1206.6389</a></p>
<p>Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, â€œAdversarial classification,â€ in Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), Seattle, 2004, pp. 99â€“108.Â <a href='https://dl.acm.org/citation.cfm?id=1014066'>https://dl.acm.org/citation.cfm?id=1014066</a></p>
<p>Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. "Axiomatic attribution forÂ deep networks." Proceedings of the 34th International Conference on MachineÂ Learning-Volume 70. JMLR. org, 2017.Â <a href='https://arxiv.org/abs/1703.01365'>https://arxiv.org/abs/1703.01365</a>Â </p>
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "Model-agnosticÂ interpretability of machine learning." arXiv preprint arXiv:1606.05386 (2016).Â <a href='https://arxiv.org/abs/1606.05386'>https://arxiv.org/abs/1606.05386</a></p>
<p>Guo, Wenbo, et al. "Lemna: Explaining deep learning based securityÂ applications." Proceedings of the 2018 ACM SIGSAC Conference on ComputerÂ and Communications Security. ACM, 2018.Â <a href='https://dl.acm.org/citation.cfm?id=3243792'>https://dl.acm.org/citation.cfm?id=3243792</a></p>
<p>Bach, Sebastian, et al. "On pixel-wise explanations for non-linear classifierÂ decisions by layer-wise relevance propagation." PloS one 10.7 (2015):Â E0130140.Â <a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140'>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140</a>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>As ML plays a more and more relevant role in many domains of everyday life, itâ€™s quite obvious to see more and more attacks to ML systems. In this episode we talk about the most popular attacks against machine learning systems and some mitigations designed by researchers Ambra Demontis and Marco Melis, from the University of Cagliari (Italy). The guests are also the authors of SecML, an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithms.Â Both Ambra and Marco are members of research group <a href='https://pralab.diee.unica.it/'>PRAlab</a>, under the supervision of Prof. Fabio Roli.<br>
Â </p>
SecML Contributors
<p>Marco Melis (Ph.D Student, Project Maintainer, <a href='https://www.linkedin.com/in/melismarco/)'>https://www.linkedin.com/in/melismarco/)</a><br>
Ambra Demontis (Postdoc, <a href='https://pralab.diee.unica.it/it/AmbraDemontis)'>https://pralab.diee.unica.it/it/AmbraDemontis)Â </a><br>
Maura Pintor (Ph.D Student, <a href='https://it.linkedin.com/in/maura-pintor)'>https://it.linkedin.com/in/maura-pintor)</a><br>
Battista Biggio (Assistant Professor, <a href='https://pralab.diee.unica.it/it/BattistaBiggio)'>https://pralab.diee.unica.it/it/BattistaBiggio)</a><br>
<br>
</p>
References
<p>SecML: an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithmsÂ <a href='https://secml.gitlab.io/'>https://secml.gitlab.io/</a>.</p>
<p>Demontis <em>et al.</em>, â€œWhy Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks,â€ presented at the 28th USENIX Security Symposium (USENIX Security 19), 2019, pp. 321â€“338.Â <a href='https://www.usenix.org/conference/usenixsecurity19/presentation/demontis'>https://www.usenix.org/conference/usenixsecurity19/presentation/demontis</a></p>
<p>W. Koh and P. Liang, â€œUnderstanding Black-box Predictions via Influence Functions,â€ in <em>International Conference on Machine Learning (ICML)</em>, 2017.Â <a href='https://arxiv.org/abs/1703.04730'>https://arxiv.org/abs/1703.04730</a></p>
<p>Melis, A. Demontis, B. Biggio, G. Brown, G. Fumera, and F. Roli, â€œIs Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid,â€ in <em>2017 IEEE International Conference on Computer Vision Workshops (ICCVW)</em>, 2017, pp. 751â€“759.Â <a href='https://arxiv.org/abs/1708.06939'>https://arxiv.org/abs/1708.06939</a></p>
<p>Biggio and F. Roli, â€œWild Patterns: Ten Years After the Rise of Adversarial Machine Learning,â€ <em>Pattern Recognition</em>, vol. 84, pp. 317â€“331, 2018.Â <a href='https://arxiv.org/abs/1712.03141'>https://arxiv.org/abs/1712.03141</a></p>
<p>Biggio <em>et al.</em>, â€œEvasion attacks against machine learning at test time,â€ in <em>Machine Learning and Knowledge Discovery in Databases (ECML PKDD), Part III</em>, 2013, vol. 8190, pp. 387â€“402.Â <a href='https://arxiv.org/abs/1708.06131'>https://arxiv.org/abs/1708.06131</a></p>
<p>Biggio, B. Nelson, and P. Laskov, â€œPoisoning attacks against support vector machines,â€ in <em>29th Intâ€™l Conf. on Machine Learning</em>, 2012, pp. 1807â€“1814.Â <a href='https://arxiv.org/abs/1206.6389'>https://arxiv.org/abs/1206.6389</a></p>
<p>Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, â€œAdversarial classification,â€ in <em>Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</em>, Seattle, 2004, pp. 99â€“108.Â <a href='https://dl.acm.org/citation.cfm?id=1014066'>https://dl.acm.org/citation.cfm?id=1014066</a></p>
<p>Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. "Axiomatic attribution forÂ deep networks." Proceedings of the 34th International Conference on MachineÂ Learning-Volume 70. JMLR. org, 2017.Â <a href='https://arxiv.org/abs/1703.01365'>https://arxiv.org/abs/1703.01365</a>Â </p>
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "Model-agnosticÂ interpretability of machine learning." arXiv preprint arXiv:1606.05386 (2016).Â <a href='https://arxiv.org/abs/1606.05386'>https://arxiv.org/abs/1606.05386</a></p>
<p>Guo, Wenbo, et al. "Lemna: Explaining deep learning based securityÂ applications." Proceedings of the 2018 ACM SIGSAC Conference on ComputerÂ and Communications Security. ACM, 2018.Â <a href='https://dl.acm.org/citation.cfm?id=3243792'>https://dl.acm.org/citation.cfm?id=3243792</a></p>
<p>Bach, Sebastian, et al. "On pixel-wise explanations for non-linear classifierÂ decisions by layer-wise relevance propagation." PloS one 10.7 (2015):Â E0130140.Â <a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140'>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140</a>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xuq9a5/080.mp3" length="65433101" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join the discussion on our Discord server
As ML plays a more and more relevant role in many domains of everyday life, itâ€™s quite obvious to see more and more attacks to ML systems. In this episode we talk about the most popular attacks against machine learning systems and some mitigations designed by researchers Ambra Demontis and Marco Melis, from the University of Cagliari (Italy). The guests are also the authors of SecML, an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithms.Â Both Ambra and Marco are members of research group PRAlab, under the supervision of Prof. Fabio Roli.Â 
SecML Contributors
Marco Melis (Ph.D Student, Project Maintainer, https://www.linkedin.com/in/melismarco/)Ambra Demontis (Postdoc, https://pralab.diee.unica.it/it/AmbraDemontis)Â Maura Pintor (Ph.D Student, https://it.linkedin.com/in/maura-pintor)Battista Biggio (Assistant Professor, https://pralab.diee.unica.it/it/BattistaBiggio)
References
SecML: an open-source Python library for theÂ security evaluationÂ of Machine Learning (ML) algorithmsÂ https://secml.gitlab.io/.
Demontis et al., â€œWhy Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks,â€ presented at the 28th USENIX Security Symposium (USENIX Security 19), 2019, pp. 321â€“338.Â https://www.usenix.org/conference/usenixsecurity19/presentation/demontis
W. Koh and P. Liang, â€œUnderstanding Black-box Predictions via Influence Functions,â€ in International Conference on Machine Learning (ICML), 2017.Â https://arxiv.org/abs/1703.04730
Melis, A. Demontis, B. Biggio, G. Brown, G. Fumera, and F. Roli, â€œIs Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid,â€ in 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), 2017, pp. 751â€“759.Â https://arxiv.org/abs/1708.06939
Biggio and F. Roli, â€œWild Patterns: Ten Years After the Rise of Adversarial Machine Learning,â€ Pattern Recognition, vol. 84, pp. 317â€“331, 2018.Â https://arxiv.org/abs/1712.03141
Biggio et al., â€œEvasion attacks against machine learning at test time,â€ in Machine Learning and Knowledge Discovery in Databases (ECML PKDD), Part III, 2013, vol. 8190, pp. 387â€“402.Â https://arxiv.org/abs/1708.06131
Biggio, B. Nelson, and P. Laskov, â€œPoisoning attacks against support vector machines,â€ in 29th Intâ€™l Conf. on Machine Learning, 2012, pp. 1807â€“1814.Â https://arxiv.org/abs/1206.6389
Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, â€œAdversarial classification,â€ in Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), Seattle, 2004, pp. 99â€“108.Â https://dl.acm.org/citation.cfm?id=1014066
Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. "Axiomatic attribution forÂ deep networks." Proceedings of the 34th International Conference on MachineÂ Learning-Volume 70. JMLR. org, 2017.Â https://arxiv.org/abs/1703.01365Â 
Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "Model-agnosticÂ interpretability of machine learning." arXiv preprint arXiv:1606.05386 (2016).Â https://arxiv.org/abs/1606.05386
Guo, Wenbo, et al. "Lemna: Explaining deep learning based securityÂ applications." Proceedings of the 2018 ACM SIGSAC Conference on ComputerÂ and Communications Security. ACM, 2018.Â https://dl.acm.org/citation.cfm?id=3243792
Bach, Sebastian, et al. "On pixel-wise explanations for non-linear classifierÂ decisions by layer-wise relevance propagation." PloS one 10.7 (2015):Â E0130140.Â https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>34:04</itunes:duration>
                <itunes:episode>76</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>[RB] How to scale AI in your organisation (Ep. 79)</title>
        <itunes:title>[RB] How to scale AI in your organisation (Ep. 79)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-71-how-to-scale-ai-in-your-organisation/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-71-how-to-scale-ai-in-your-organisation/#comments</comments>        <pubDate>Thu, 26 Sep 2019 06:06:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-71-how-to-scale-ai-in-your-organisation-7b1683322182f6484906a2b8aba6251c</guid>
                                    <description><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">Scaling technology and business processes are not equal. Since the beginning of the enterprise technology, scaling software has been a difficult task to get right inside large organisations. When it comes to Artificial Intelligence and Machine Learning, it becomes vastly more complicated.Â </p>
<p style="text-align:left;">In this episode I propose a framework - in five pillars - for the business side of artificial intelligence.</p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">Scaling technology and business processes are not equal. Since the beginning of the enterprise technology, scaling software has been a difficult task to get right inside large organisations. When it comes to Artificial Intelligence and Machine Learning, it becomes vastly more complicated.Â </p>
<p style="text-align:left;">In this episode I propose a framework - in five pillars - for the business side of artificial intelligence.</p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/c96jrr/071-correct.mp3" length="25663448" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join the discussion on our Discord server
Scaling technology and business processes are not equal. Since the beginning of the enterprise technology, scaling software has been a difficult task to get right inside large organisations. When it comes to Artificial Intelligence and Machine Learning, it becomes vastly more complicated.Â 
In this episode I propose a framework - in five pillars - for the business side of artificial intelligence.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>13:21</itunes:duration>
                <itunes:episode>66</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Replicating GPT-2, the most dangerous NLP model (with Aaron Gokaslan) (Ep. 78)</title>
        <itunes:title>Replicating GPT-2, the most dangerous NLP model (with Aaron Gokaslan) (Ep. 78)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-79-cpt-2/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-79-cpt-2/#comments</comments>        <pubDate>Mon, 23 Sep 2019 05:40:59 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-79-cpt-2-5fb3728fb2107adc9370f8ae18f5be38</guid>
                                    <description><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>In this episode, I am with <a href='/datascienceathome/episode/update/id/%20https:/skylion007.github.io/'>Aaron Gokaslan</a>, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because too accurate to be published. </p>
<p>We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. 
Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!</p>

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

<a href='https://phillipi.github.io/pix2pix/'>https://phillipi.github.io/pix2pix/</a>
Â 
CycleGAN:
<a href='https://junyanz.github.io/CycleGAN/'>https://junyanz.github.io/CycleGAN/</a>
Â 
GANimorph

Paper: <a href='https://arxiv.org/abs/1808.04325'>https://arxiv.org/abs/1808.04325</a>
Code: <a href='https://github.com/brownvc/ganimorph'>https://github.com/brownvc/ganimorph</a>
Â 
UNIT:<a href='https://arxiv.org/abs/1703.00848'>https://arxiv.org/abs/1703.00848</a>




MUNIT:<a href='https://github.com/NVlabs/MUNIT'>https://github.com/NVlabs/MUNIT</a>
DRIT:Â <a href='https://github.com/HsinYingLee/DRIT'>https://github.com/HsinYingLee/DRIT</a>



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: <a href='https://talktotransformer.com/'>https://talktotransformer.com/</a>
Blogpost:Â <a href='https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc'>https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc</a>

The Original Transformer Paper: <a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a>
Grover: The FakeNews generator and detector: <a href='https://rowanzellers.com/grover/'>https://rowanzellers.com/grover/</a>
Â 



Â 
]]></description>
                                                            <content:encoded><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>In this episode, I am with <a href='/datascienceathome/episode/update/id/%20https:/skylion007.github.io/'>Aaron Gokaslan</a>, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because <em>too accurate to be published</em>. </p>
<p>We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. <br>
Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!</p>

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

<a href='https://phillipi.github.io/pix2pix/'>https://phillipi.github.io/pix2pix/</a>
Â 
CycleGAN:
<a href='https://junyanz.github.io/CycleGAN/'>https://junyanz.github.io/CycleGAN/</a>
Â 
GANimorph<br>

Paper: <a href='https://arxiv.org/abs/1808.04325'>https://arxiv.org/abs/1808.04325</a>
Code: <a href='https://github.com/brownvc/ganimorph'>https://github.com/brownvc/ganimorph</a>
Â 
UNIT:<a href='https://arxiv.org/abs/1703.00848'>https://arxiv.org/abs/1703.00848</a>




MUNIT:<a href='https://github.com/NVlabs/MUNIT'>https://github.com/NVlabs/MUNIT</a>
DRIT:Â <a href='https://github.com/HsinYingLee/DRIT'>https://github.com/HsinYingLee/DRIT</a>



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: <a href='https://talktotransformer.com/'>https://talktotransformer.com/</a>
Blogpost:Â <a href='https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc'>https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc</a>
<br>
The Original Transformer Paper: <a href='https://arxiv.org/abs/1706.03762'>https://arxiv.org/abs/1706.03762</a>
Grover: The FakeNews generator and detector: <a href='https://rowanzellers.com/grover/'>https://rowanzellers.com/grover/</a>
Â 



Â 
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/c5wgwg/079.mp3" length="72562649" type="audio/mpeg"/>
        <itunes:summary><![CDATA[



Join the discussion on our Discord server
In this episode, I am with Aaron Gokaslan, computer vision researcher, AI Resident at Facebook AI Research. Aaron is the author of OpenGPT-2,Â a parallel NLP model to the most discussed version that OpenAI decided not to release because too accurate to be published. 
We discuss about image-to-image translation, the dangers of the GPT-2 model and the future of AI. Moreover,Â Aaron provides some very interesting links and demos that will blow your mind!

Enjoy the show!Â 
References

Multimodal image to image translation (not all mentioned in the podcast but recommended by Aaron)
Pix2Pix:Â 

https://phillipi.github.io/pix2pix/
Â 
CycleGAN:
https://junyanz.github.io/CycleGAN/
Â 
GANimorph
Paper: https://arxiv.org/abs/1808.04325
Code: https://github.com/brownvc/ganimorph
Â 
UNIT:https://arxiv.org/abs/1703.00848




MUNIT:https://github.com/NVlabs/MUNIT
DRIT:Â https://github.com/HsinYingLee/DRIT



Â 

GPT-2 and relatedÂ 
Try OpenAI's GPT-2: https://talktotransformer.com/
Blogpost:Â https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
The Original Transformer Paper: https://arxiv.org/abs/1706.03762
Grover: The FakeNews generator and detector: https://rowanzellers.com/grover/
Â 



Â 
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>37:47</itunes:duration>
                <itunes:episode>74</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Training neural networks faster without GPU [RB] (Ep. 77)</title>
        <itunes:title>Training neural networks faster without GPU [RB] (Ep. 77)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-78-training-neural-networks-faster-without-gpu-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-78-training-neural-networks-faster-without-gpu-rb/#comments</comments>        <pubDate>Tue, 17 Sep 2019 05:32:35 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-78-training-neural-networks-faster-without-gpu-rb-10ef6fbe8b618d0f49ad3dfb23618689</guid>
                                    <description><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.</p>
<p>Enjoy the show!</p>
Â 
References
<p>Faster Neural Network Training with Data Echoing
<a href='https://arxiv.org/abs/1907.05550'>https://arxiv.org/abs/1907.05550</a></p>



]]></description>
                                                            <content:encoded><![CDATA[



<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p>Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.</p>
<p>Enjoy the show!</p>
Â 
References
<p>Faster Neural Network Training with Data Echoing<br>
<a href='https://arxiv.org/abs/1907.05550'>https://arxiv.org/abs/1907.05550</a></p>



]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/haz9x7/072.mp3" length="42923491" type="audio/mpeg"/>
        <itunes:summary><![CDATA[



Join the discussion on our Discord server
Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.
Enjoy the show!
Â 
References
Faster Neural Network Training with Data Echoinghttps://arxiv.org/abs/1907.05550



]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:21</itunes:duration>
                <itunes:episode>73</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>How to generate very large images with GANs (Ep. 76)</title>
        <itunes:title>How to generate very large images with GANs (Ep. 76)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-77-1567780446/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-77-1567780446/#comments</comments>        <pubDate>Fri, 06 Sep 2019 14:45:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-77-1567780446-cb4717690ffa5e6b7d30b0396635f314</guid>
                                    <description><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. 
The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.
Enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p class="title mathjax" style="text-align:left;">Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ <a href='https://arxiv.org/abs/1907.01376'>https://arxiv.org/abs/1907.01376</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Join the discussion on our <a href='https://discord.gg/4UNKGf3'>Discord server</a></p>
<p style="text-align:left;">In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. <br>
The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.<br>
Enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p class="title mathjax" style="text-align:left;">Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ <a href='https://arxiv.org/abs/1907.01376'>https://arxiv.org/abs/1907.01376</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/88dts4/077.mp3" length="28223030" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Join the discussion on our Discord server
In this episode I explain how a research group from the University of Lubeck dominated the curse of dimensionality for the generation of large medical images with GANs. The problem is not as trivial as it seems. Many researchers have failed in generating large images with GANs before. One interesting application of such approach is in medicine for the generation of CT and X-ray images.Enjoy the show!
Â 
References
Multi-scale GANs for Memory-efficient Generation of High Resolution Medical ImagesÂ https://arxiv.org/abs/1907.01376]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:41</itunes:duration>
                <itunes:episode>72</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>[RB] Complex video analysis made easy with Videoflow (Ep. 75)</title>
        <itunes:title>[RB] Complex video analysis made easy with Videoflow (Ep. 75)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-episode-76-complex-video-analysis-made-easy-with-videoflow/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-episode-76-complex-video-analysis-made-easy-with-videoflow/#comments</comments>        <pubDate>Thu, 29 Aug 2019 08:05:43 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/rb-episode-76-complex-video-analysis-made-easy-with-videoflow-f126cd710c88d5ead0813ead4949c7a4</guid>
                                    <description><![CDATA[<p>In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â </p>
<p>I have inspected the videoflow repo on <a href='https://github.com/videoflow/videoflow'>Github</a> and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ </p>
<p>Â </p>
References
<p>Videflow Github official repository 
<a href='https://github.com/videoflow/videoflow'>https://github.com/videoflow/videoflow</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â </p>
<p>I have inspected the videoflow repo on <a href='https://github.com/videoflow/videoflow'>Github</a> and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ </p>
<p>Â </p>
References
<p>Videflow Github official repository <br>
<a href='https://github.com/videoflow/videoflow'>https://github.com/videoflow/videoflow</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ynxtmx/069.mp3" length="58966096" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â 
I have inspected the videoflow repo on Github and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ 
Â 
References
Videflow Github official repository https://github.com/videoflow/videoflow
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:42</itunes:duration>
                <itunes:episode>71</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>[RB] Validate neural networks without data with Dr. Charles Martin (Ep. 74)</title>
        <itunes:title>[RB] Validate neural networks without data with Dr. Charles Martin (Ep. 74)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/rb-episode-75-validate-neural-networks-without-data-with-dr-charles-martin/</link>
                    <comments>https://datascienceathome.podbean.com/e/rb-episode-75-validate-neural-networks-without-data-with-dr-charles-martin/#comments</comments>        <pubDate>Tue, 27 Aug 2019 02:01:32 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/rb-episode-75-validate-neural-networks-without-data-with-dr-charles-martin-2554139b0c00d785977a79c1d7a80cc2</guid>
                                    <description><![CDATA[<p>In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â </p>
<p>The questions that Charles answers in the show are essentially two:
</p>
<ol><li>Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?

</li>
<li>How can we dominate DNN in a theoretically principled way?</li>
</ol><p>Â </p>
ReferencesÂ 


<ul><li class="f4">The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ <a href='https://github.com/CalculatedContent/WeightWatcher'>https://github.com/CalculatedContent/WeightWatcher</a>

</li>
<li class="f4">
Slack channel <a href='https://weightwatcherai.slack.com/'>https://weightwatcherai.slack.com/</a>


</li>
<li class="f4">
Dr. Charles Martin BlogÂ <a href='http://calculatedcontent.com/'>http://calculatedcontent.comÂ </a>and channelÂ <a href='https://www.youtube.com/c/calculationconsulting'>https://www.youtube.com/c/calculationconsulting

</a>
</li>
<li class="f4">
Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney
</li>
</ul>

]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â </p>
<p>The questions that Charles answers in the show are essentially two:<br>
</p>
<ol><li>Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?<br>
<br>
</li>
<li>How can we dominate DNN in a theoretically principled way?</li>
</ol><p>Â </p>
ReferencesÂ 


<ul><li class="f4">The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ <a href='https://github.com/CalculatedContent/WeightWatcher'>https://github.com/CalculatedContent/WeightWatcher</a><br>
<br>
</li>
<li class="f4">
Slack channel <a href='https://weightwatcherai.slack.com/'>https://weightwatcherai.slack.com/</a><br>
<br>

</li>
<li class="f4">
Dr. Charles Martin BlogÂ <a href='http://calculatedcontent.com/'>http://calculatedcontent.comÂ </a>and channelÂ <a href='https://www.youtube.com/c/calculationconsulting'>https://www.youtube.com/c/calculationconsulting<br>
<br>
</a>
</li>
<li class="f4">
Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney
</li>
</ul>

]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/isuwk6/070.mp3" length="85986663" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â 
The questions that Charles answers in the show are essentially two:
Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?
How can we dominate DNN in a theoretically principled way?
Â 
ReferencesÂ 


The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ https://github.com/CalculatedContent/WeightWatcher

Slack channel https://weightwatcherai.slack.com/


Dr. Charles Martin BlogÂ http://calculatedcontent.comÂ and channelÂ https://www.youtube.com/c/calculationconsulting


Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney


]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>44:46</itunes:duration>
                <itunes:episode>70</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>How to cluster tabular data with Markov Clustering (Ep. 73)</title>
        <itunes:title>How to cluster tabular data with Markov Clustering (Ep. 73)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-74-how-to-cluster-tabular-data-with-markov-clustering/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-74-how-to-cluster-tabular-data-with-markov-clustering/#comments</comments>        <pubDate>Wed, 21 Aug 2019 00:40:38 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-74-how-to-cluster-tabular-data-with-markov-clustering-2d1dcbf7c7497cfc0acf48b1ffed6dc7</guid>
                                    <description><![CDATA[<p>In this episode I explain how a community detection algorithm known as Markov clustering can be constructed by combining simple concepts like random walks, graphs, similarity matrix. Moreover, I highlight how one can build a similarity graph and then run a community detection algorithm on such graph to find clusters in tabular data.</p>
<p>You can find a simple hands-on code snippet to play with on the <a href='https://amethix.com/effective-community-detection-with-markov-clustering/'>Amethix Blog</a>Â </p>
<p>Enjoy the show!Â </p>
<p>Â </p>
References
<p>[1] S. Fortunato, â€œCommunity detection in graphsâ€, Physics Reports, volume 486, issues 3-5, pages 75-174, February 2010.</p>
<p>[2] Z. Yang, et al., â€œA Comparative Analysis of Community Detection Algorithms on Artificial Networksâ€, Scientific Reports volume 6, Article number: 30750 (2016)</p>
<p>[3] S. Dongen, â€œA cluster algorithm for graphsâ€, Technical Report, CWI (Centre for Mathematics and Computer Science) Amsterdam, The Netherlands, 2000.</p>
<p>[4] A. J. Enright, et al., â€œAn efficient algorithm for large-scale detection of protein familiesâ€, Nucleic Acids Research, volume 30, issue 7, pages 1575-1584, 2002.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I explain how a community detection algorithm known as Markov clustering can be constructed by combining simple concepts like random walks, graphs, similarity matrix. Moreover, I highlight how one can build a similarity graph and then run a community detection algorithm on such graph to find clusters in <em>tabular data</em>.</p>
<p>You can find a simple hands-on code snippet to play with on the <a href='https://amethix.com/effective-community-detection-with-markov-clustering/'>Amethix Blog</a>Â </p>
<p>Enjoy the show!Â </p>
<p>Â </p>
References
<p>[1] S. Fortunato, â€œCommunity detection in graphsâ€, Physics Reports, volume 486, issues 3-5, pages 75-174, February 2010.</p>
<p>[2] Z. Yang, et al., â€œA Comparative Analysis of Community Detection Algorithms on Artificial Networksâ€, Scientific Reports volume 6, Article number: 30750 (2016)</p>
<p>[3] S. Dongen, â€œA cluster algorithm for graphsâ€, Technical Report, CWI (Centre for Mathematics and Computer Science) Amsterdam, The Netherlands, 2000.</p>
<p>[4] A. J. Enright, et al., â€œAn efficient algorithm for large-scale detection of protein familiesâ€, Nucleic Acids Research, volume 30, issue 7, pages 1575-1584, 2002.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2n6t9x/074.mp3" length="39794648" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I explain how a community detection algorithm known as Markov clustering can be constructed by combining simple concepts like random walks, graphs, similarity matrix. Moreover, I highlight how one can build a similarity graph and then run a community detection algorithm on such graph to find clusters in tabular data.
You can find a simple hands-on code snippet to play with on the Amethix BlogÂ 
Enjoy the show!Â 
Â 
References
[1] S. Fortunato, â€œCommunity detection in graphsâ€, Physics Reports, volume 486, issues 3-5, pages 75-174, February 2010.
[2] Z. Yang, et al., â€œA Comparative Analysis of Community Detection Algorithms on Artificial Networksâ€, Scientific Reports volume 6, Article number: 30750 (2016)
[3] S. Dongen, â€œA cluster algorithm for graphsâ€, Technical Report, CWI (Centre for Mathematics and Computer Science) Amsterdam, The Netherlands, 2000.
[4] A. J. Enright, et al., â€œAn efficient algorithm for large-scale detection of protein familiesâ€, Nucleic Acids Research, volume 30, issue 7, pages 1575-1584, 2002.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:43</itunes:duration>
                <itunes:episode>69</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Waterfall or Agile? The best methodology for AI and machine learning (Ep. 72)</title>
        <itunes:title>Waterfall or Agile? The best methodology for AI and machine learning (Ep. 72)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-73-waterfall-or-agile-the-best-methodology-for-ai-and-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-73-waterfall-or-agile-the-best-methodology-for-ai-and-machine-learning/#comments</comments>        <pubDate>Wed, 14 Aug 2019 05:16:06 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-73-waterfall-or-agile-the-best-methodology-for-ai-and-machine-learning-9be76c0eba59600536a53736da30d78d</guid>
                                    <description><![CDATA[<p>The two most widely considered software development models in modern project management are, without any doubt, theÂ Waterfall MethodologyÂ and theÂ Agile Methodology. In this episode I make a comparison between the two and explain what I believe is the best choice for your machine learning project.</p>
<p>An interesting post to read (mentioned in the episode) isÂ How businesses can scale Artificial Intelligence & Machine LearningÂ <a href='https://amethix.com/how-businesses-can-scale-artificial-intelligence-machine-learning/'>https://amethix.com/how-businesses-can-scale-artificial-intelligence-machine-learning/</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>The two most widely considered software development models in modern project management are, without any doubt, theÂ <em>Waterfall Methodology</em>Â and theÂ <em>Agile Methodology</em>. In this episode I make a comparison between the two and explain what I believe is the best choice for your machine learning project.</p>
<p>An interesting post to read (mentioned in the episode) isÂ How businesses can scale Artificial Intelligence & Machine LearningÂ <a href='https://amethix.com/how-businesses-can-scale-artificial-intelligence-machine-learning/'>https://amethix.com/how-businesses-can-scale-artificial-intelligence-machine-learning/</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ctgh8h/073.mp3" length="27744884" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The two most widely considered software development models in modern project management are, without any doubt, theÂ Waterfall MethodologyÂ and theÂ Agile Methodology. In this episode I make a comparison between the two and explain what I believe is the best choice for your machine learning project.
An interesting post to read (mentioned in the episode) isÂ How businesses can scale Artificial Intelligence & Machine LearningÂ https://amethix.com/how-businesses-can-scale-artificial-intelligence-machine-learning/]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:26</itunes:duration>
                <itunes:episode>68</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Training neural networks faster without GPU (Ep. 71)</title>
        <itunes:title>Training neural networks faster without GPU (Ep. 71)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-72-training-neural-networks-faster-without-gpu/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-72-training-neural-networks-faster-without-gpu/#comments</comments>        <pubDate>Tue, 06 Aug 2019 06:37:53 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-72-training-neural-networks-faster-without-gpu-736965737a69f1903f64f0b68ae10b24</guid>
                                    <description><![CDATA[



<p>Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.</p>
<p>Enjoy the show!</p>
Â 
References
<p>Faster Neural Network Training with Data Echoing
<a href='https://arxiv.org/abs/1907.05550'>https://arxiv.org/abs/1907.05550</a></p>



]]></description>
                                                            <content:encoded><![CDATA[



<p>Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.</p>
<p>Enjoy the show!</p>
Â 
References
<p>Faster Neural Network Training with Data Echoing<br>
<a href='https://arxiv.org/abs/1907.05550'>https://arxiv.org/abs/1907.05550</a></p>



]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/haz9x7/072.mp3" length="42923491" type="audio/mpeg"/>
        <itunes:summary><![CDATA[



Training neural networks faster usually involves the usage of powerful GPUs. In this episode I explain an interesting method from a group of researchers from Google Brain, who can train neural networks faster by squeezing the hardware to their needs and making the training pipeline more dense.
Enjoy the show!
Â 
References
Faster Neural Network Training with Data Echoinghttps://arxiv.org/abs/1907.05550



]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:21</itunes:duration>
                <itunes:episode>67</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Validate neural networks without data with Dr. Charles Martin (Ep. 70)</title>
        <itunes:title>Validate neural networks without data with Dr. Charles Martin (Ep. 70)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-70-validate-neural-networks-without-data-with-dr-charles-martin/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-70-validate-neural-networks-without-data-with-dr-charles-martin/#comments</comments>        <pubDate>Tue, 23 Jul 2019 06:38:09 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-70-validate-neural-networks-without-data-with-dr-charles-martin-23e46c06530c167ae49707247a768aa2</guid>
                                    <description><![CDATA[<p>In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â </p>
<p>The questions that Charles answers in the show are essentially two:
</p>
<ol><li>Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?

</li>
<li>How can we dominate DNN in a theoretically principled way?</li>
</ol><p>Â </p>
ReferencesÂ 


<ul><li class="f4">The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ <a href='https://github.com/CalculatedContent/WeightWatcher'>https://github.com/CalculatedContent/WeightWatcher</a>

</li>
<li class="f4">
Slack channel <a href='https://weightwatcherai.slack.com/'>https://weightwatcherai.slack.com/</a>


</li>
<li class="f4">
Dr. Charles Martin BlogÂ <a href='http://calculatedcontent.com/'>http://calculatedcontent.comÂ </a>and channelÂ <a href='https://www.youtube.com/c/calculationconsulting'>https://www.youtube.com/c/calculationconsulting

</a>
</li>
<li class="f4">
Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney
</li>
</ul>



<p>Â </p>

Â ]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â </p>
<p>The questions that Charles answers in the show are essentially two:<br>
</p>
<ol><li>Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?<br>
<br>
</li>
<li>How can we dominate DNN in a theoretically principled way?</li>
</ol><p>Â </p>
ReferencesÂ 


<ul><li class="f4">The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ <a href='https://github.com/CalculatedContent/WeightWatcher'>https://github.com/CalculatedContent/WeightWatcher</a><br>
<br>
</li>
<li class="f4">
Slack channel <a href='https://weightwatcherai.slack.com/'>https://weightwatcherai.slack.com/</a><br>
<br>

</li>
<li class="f4">
Dr. Charles Martin BlogÂ <a href='http://calculatedcontent.com/'>http://calculatedcontent.comÂ </a>and channelÂ <a href='https://www.youtube.com/c/calculationconsulting'>https://www.youtube.com/c/calculationconsulting<br>
<br>
</a>
</li>
<li class="f4">
Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney
</li>
</ul>



<p>Â </p>

Â ]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/isuwk6/070.mp3" length="85986663" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, I am with Dr. Charles Martin from Calculation Consulting a machine learning and data science consulting company based in San Francisco. We speak about the nuts and bolts of deep neural networks and some impressive findings about the way they work.Â 
The questions that Charles answers in the show are essentially two:
Why is regularisation in deep learning seemingly quite different than regularisation in other areas on ML?
How can we dominate DNN in a theoretically principled way?
Â 
ReferencesÂ 


The WeightWatcher tool for predicting the accuracy of Deep Neural NetworksÂ https://github.com/CalculatedContent/WeightWatcher

Slack channel https://weightwatcherai.slack.com/


Dr. Charles Martin BlogÂ http://calculatedcontent.comÂ and channelÂ https://www.youtube.com/c/calculationconsulting


Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning - Charles H. Martin, Michael W. Mahoney




Â 

Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>44:46</itunes:duration>
                <itunes:episode>65</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Complex video analysis made easy with Videoflow (Ep. 69)</title>
        <itunes:title>Complex video analysis made easy with Videoflow (Ep. 69)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-68-videoflow/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-68-videoflow/#comments</comments>        <pubDate>Tue, 16 Jul 2019 02:00:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-68-videoflow-7715118d0600b0322ca08bee0a5aaa7f</guid>
                                    <description><![CDATA[<p>In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â </p>
<p>I have inspected the videoflow repo on <a href='https://github.com/videoflow/videoflow'>Github</a> and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ </p>
<p>Â </p>
References
<p>Videflow Github official repository 
<a href='https://github.com/videoflow/videoflow'>https://github.com/videoflow/videoflow</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â </p>
<p>I have inspected the videoflow repo on <a href='https://github.com/videoflow/videoflow'>Github</a> and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ </p>
<p>Â </p>
References
<p>Videflow Github official repository <br>
<a href='https://github.com/videoflow/videoflow'>https://github.com/videoflow/videoflow</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ynxtmx/069.mp3" length="58966096" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am withÂ Jadiel de Armas, senior software engineer at Disney and author of Videflow, a Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment.Â 
I have inspected the videoflow repo on Github and some of the capabilities of this framework and I must say that itâ€™s really interesting. Jadiel is going to tell us a lot more than what you can read from GithubÂ 
Â 
References
Videflow Github official repository https://github.com/videoflow/videoflow
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:42</itunes:duration>
                <itunes:episode>63</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Episode 68: AI and the future of banking with Chris Skinner [RB]</title>
        <itunes:title>Episode 68: AI and the future of banking with Chris Skinner [RB]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-68-ai-and-the-future-of-banking-with-chris-skinner-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-68-ai-and-the-future-of-banking-with-chris-skinner-rb/#comments</comments>        <pubDate>Tue, 09 Jul 2019 16:37:47 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-68-ai-and-the-future-of-banking-with-chris-skinner-rb-28d9e3e1171002d5bc94aa3463ed5995</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode I have a wonderful conversation with Chris Skinner.</p>
<p>Chris and I recently got in touch at The banking scene 2019, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. </p>
<p>After I got my hands on his last book Digital Human, I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode I have a wonderful conversation with Chris Skinner.</p>
<p>Chris and I recently got in touch at <em>The banking scene 2019</em>, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. </p>
<p>After I got my hands on his last book <em>Digital Human,</em> I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8ugkcp/068-062_RB.mp3" length="80097618" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I have a wonderful conversation with Chris Skinner.
Chris and I recently got in touch at The banking scene 2019, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. 
After I got my hands on his last book Digital Human, I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>41:42</itunes:duration>
                <itunes:episode>64</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Episode 67: Classic Computer Science Problems in Python</title>
        <itunes:title>Episode 67: Classic Computer Science Problems in Python</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-67-classic-computer-science-problems-in-python/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-67-classic-computer-science-problems-in-python/#comments</comments>        <pubDate>Tue, 02 Jul 2019 09:07:05 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-67-classic-computer-science-problems-in-python-d3bb4f6ad992b815289ab392688d73cf</guid>
                                    <description><![CDATA[<p>Today I am with David Kopec, author of Classic Computer Science Problems in Python, published by Manning Publications.</p>
<p>His book deepens your knowledge of problem solving techniques from the realm of computer science by challenging you with interesting and realistic scenarios, exercises, and of course algorithms. 
There are examples in the major topics any data scientist should be familiar with, for example search, clustering, graphs, and much more.</p>
<p>Get the book fromÂ <a href='https://www.manning.com/books/classic-computer-science-problems-in-python'>https://www.manning.com/books/classic-computer-science-problems-in-python</a>Â and use coupon codeÂ poddatascienceathome19 toÂ get 40% discount.</p>
<p>Â </p>
References
<p>TwitterÂ <a href='https://twitter.com/davekopec'>https://twitter.com/davekopec</a></p>
<p>GitHubÂ <a href='https://github.com/davecom'>https://github.com/davecom</a></p>
<p><a href='/datascienceathome/episode/update/id/classicproblems.com'>classicproblems.com</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Today I am with David Kopec, author of Classic Computer Science Problems in Python, published by Manning Publications.</p>
<p><em>His book </em>deepens your knowledge of problem solving techniques from the realm of computer science by challenging you with interesting and realistic scenarios, exercises, and of course algorithms. <br>
There are examples in the major topics any data scientist should be familiar with, for example search, clustering, graphs, and much more.</p>
<p>Get the book fromÂ <a href='https://www.manning.com/books/classic-computer-science-problems-in-python'>https://www.manning.com/books/classic-computer-science-problems-in-python</a>Â and use coupon codeÂ poddatascienceathome19 toÂ get 40% discount.</p>
<p>Â </p>
References
<p>TwitterÂ <a href='https://twitter.com/davekopec'>https://twitter.com/davekopec</a></p>
<p>GitHubÂ <a href='https://github.com/davecom'>https://github.com/davecom</a></p>
<p><a href='/datascienceathome/episode/update/id/classicproblems.com'>classicproblems.com</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/h876sz/067.mp3" length="54906381" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Today I am with David Kopec, author of Classic Computer Science Problems in Python, published by Manning Publications.
His book deepens your knowledge of problem solving techniques from the realm of computer science by challenging you with interesting and realistic scenarios, exercises, and of course algorithms. There are examples in the major topics any data scientist should be familiar with, for example search, clustering, graphs, and much more.
Get the book fromÂ https://www.manning.com/books/classic-computer-science-problems-in-pythonÂ and use coupon codeÂ poddatascienceathome19 toÂ get 40% discount.
Â 
References
TwitterÂ https://twitter.com/davekopec
GitHubÂ https://github.com/davecom
classicproblems.com]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:35</itunes:duration>
                <itunes:episode>62</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 66: More intelligent machines with self-supervised learning</title>
        <itunes:title>Episode 66: More intelligent machines with self-supervised learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-66-more-intelligent-machines-and-self-supervised-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-66-more-intelligent-machines-and-self-supervised-learning/#comments</comments>        <pubDate>Tue, 25 Jun 2019 07:12:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-66-more-intelligent-machines-and-self-supervised-learning-52bd56638eea30c57e2c91c9a25a7731</guid>
                                    <description><![CDATA[<p>In this episode I talk about a new paradigm of learning, which can be found a bit blurry and not really different from the other methods we know of, such as supervised and unsupervised learning. The method I introduce here is called self-supervised learning.</p>
<p>Enjoy the show!</p>
<p>Â </p>
Don't forget to subscribe to our Newsletter atÂ <a href='https://podcast.datascienceathome.com/datascienceathome/episode/update/id/amethix.com'>amethix.com</a>Â and get the latest updates in AI and machine learning. We do not spam. Promise!
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/1807.05520'>Deep Clustering for Unsupervised Learning of Visual Features</a></p>
<p class="title mathjax"><a href='https://arxiv.org/abs/1902.06162'>Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I talk about a new paradigm of learning, which can be found a bit blurry and not really different from the other methods we know of, such as supervised and unsupervised learning. The method I introduce here is called self-supervised learning.</p>
<p>Enjoy the show!</p>
<p>Â </p>
Don't forget to subscribe to our Newsletter atÂ <a href='https://podcast.datascienceathome.com/datascienceathome/episode/update/id/amethix.com'>amethix.com</a>Â and get the latest updates in AI and machine learning. We do not spam. Promise!
<p>Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/1807.05520'>Deep Clustering for Unsupervised Learning of Visual Features</a></p>
<p class="title mathjax"><a href='https://arxiv.org/abs/1902.06162'>Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ez7r2y/066.mp3" length="36370726" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I talk about a new paradigm of learning, which can be found a bit blurry and not really different from the other methods we know of, such as supervised and unsupervised learning. The method I introduce here is called self-supervised learning.
Enjoy the show!
Â 
Don't forget to subscribe to our Newsletter atÂ amethix.comÂ and get the latest updates in AI and machine learning. We do not spam. Promise!
Â 
References
Deep Clustering for Unsupervised Learning of Visual Features
Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:56</itunes:duration>
                <itunes:episode>61</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 65: AI knows biology. Or does it?</title>
        <itunes:title>Episode 65: AI knows biology. Or does it?</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-65-ai-knows-biology-or-does-it/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-65-ai-knows-biology-or-does-it/#comments</comments>        <pubDate>Sun, 23 Jun 2019 13:18:50 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-65-ai-knows-biology-or-does-it-8c1bdc4b248772b7dc2aa3256a34ff27</guid>
                                    <description><![CDATA[<p style="text-align:left;">The successes of deep learning for text analytics, also introduced in a recent post about sentiment analysis and published <a href='https://wp.me/paCFFW-kX'>here</a> are undeniable. Many other tasks in NLP have also benefitted from the superiority of deep learning methods over more traditional approaches. Such extraordinary results have also been possible due to the neural network approach to learn meaningful character and word embeddings, that is the representation space in which semantically similar objects are mapped to nearby vectors. 
All this is strictly related to a field one might initially find disconnected or off-topic: biology.</p>
<p style="text-align:left;">Â </p>
Don't forget to subscribe to our Newsletter at <a href='/datascienceathome/episode/update/id/amethix.com'>amethix.com</a>Â and get the latest updates in AI and machine learning. We do not spam. Promise!
Â 
References
<p>[1] Rives A., et al., â€œBiological structure and function emerge from scaling unsupervised learning to 250 million protein sequencesâ€, biorxiv, doi: https://doi.org/10.1101/622803</p>
<p>[2] Vaswani A., et al., â€œAttention is all you needâ€, Advances in neural information processing systems, pp. 5998â€“6008, 2017.</p>
<p>[3] Bahdanau D., et al., â€œNeural machine translation by jointly learning to align and translateâ€, arXiv, http://arxiv.org/abs/1409.0473.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">The successes of deep learning for text analytics, also introduced in a recent post about sentiment analysis and published <a href='https://wp.me/paCFFW-kX'>here</a> are undeniable. Many other tasks in NLP have also benefitted from the superiority of deep learning methods over more traditional approaches. Such extraordinary results have also been possible due to the neural network approach to learn meaningful character and word <em>embeddings</em>, that is the representation space in which semantically similar objects are mapped to nearby vectors. <br>
All this is strictly related to a field one might initially find disconnected or off-topic: <em>biology</em>.</p>
<p style="text-align:left;">Â </p>
Don't forget to subscribe to our Newsletter at <a href='/datascienceathome/episode/update/id/amethix.com'>amethix.com</a>Â and get the latest updates in AI and machine learning. We do not spam. Promise!
Â 
References
<p>[1] Rives A., et al., â€œBiological structure and function emerge from scaling unsupervised learning to 250 million protein sequencesâ€, biorxiv, doi: https://doi.org/10.1101/622803</p>
<p>[2] Vaswani A., et al., â€œAttention is all you needâ€, Advances in neural information processing systems, pp. 5998â€“6008, 2017.</p>
<p>[3] Bahdanau D., et al., â€œNeural machine translation by jointly learning to align and translateâ€, arXiv, http://arxiv.org/abs/1409.0473.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8zdie9/065.mp3" length="23519317" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The successes of deep learning for text analytics, also introduced in a recent post about sentiment analysis and published here are undeniable. Many other tasks in NLP have also benefitted from the superiority of deep learning methods over more traditional approaches. Such extraordinary results have also been possible due to the neural network approach to learn meaningful character and word embeddings, that is the representation space in which semantically similar objects are mapped to nearby vectors. All this is strictly related to a field one might initially find disconnected or off-topic: biology.
Â 
Don't forget to subscribe to our Newsletter at amethix.comÂ and get the latest updates in AI and machine learning. We do not spam. Promise!
Â 
References
[1] Rives A., et al., â€œBiological structure and function emerge from scaling unsupervised learning to 250 million protein sequencesâ€, biorxiv, doi: https://doi.org/10.1101/622803
[2] Vaswani A., et al., â€œAttention is all you needâ€, Advances in neural information processing systems, pp. 5998â€“6008, 2017.
[3] Bahdanau D., et al., â€œNeural machine translation by jointly learning to align and translateâ€, arXiv, http://arxiv.org/abs/1409.0473.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>12:14</itunes:duration>
                <itunes:episode>60</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 64: Get the best shot at NLP sentiment analysis</title>
        <itunes:title>Episode 64: Get the best shot at NLP sentiment analysis</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-64-sentiment-analysis-and-sub-word-embedding/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-64-sentiment-analysis-and-sub-word-embedding/#comments</comments>        <pubDate>Fri, 14 Jun 2019 14:21:22 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-64-sentiment-analysis-and-sub-word-embedding-250dabb73fa7df22f828c78dfb462b22</guid>
                                    <description><![CDATA[<p>The rapid diffusion of social media like Facebook and Twitter, and the massive use of different types of forums like Reddit, Quora, etc., is producing an impressive amount of text data every day.Â </p>
<p>There is one specific activity that many business owners have been contemplating over the last five years, that is identifying the social sentiment of their brand, by analysing the conversations of their users.</p>
<p>In this episode I explain how one can get the best shot at classifying sentences with deep learning and word embedding.</p>
<p>Â </p>
<p>Â </p>
Additional material
<p>Schematic representation of how to learn a word embedding matrix E by training a neural network that, given the previous M words, predicts the next word in a sentence.Â </p>
<p>Â </p>
<p></p>
<p>Â </p>
<p>Â </p>
<p>Word2Vec example source code</p>
<p><a href='https://gist.github.com/rlangone/ded90673f65e932fd14ae53a26e89eee#file-word2vec_example-py'>https://gist.github.com/rlangone/ded90673f65e932fd14ae53a26e89eee#file-word2vec_example-py</a></p>
Â 
<p>Â </p>
References
<p>[1] Mikolov, T. et al., "Distributed Representations of Words and Phrases and their Compositionality", Advances in Neural Information Processing Systems 26, pages 3111-3119, 2013.</p>
<p>[2] The Best Embedding Method for Sentiment Classification, <a href='https://medium.com/@bramblexu/blog-md-34c5d082a8c5'>https://medium.com/@bramblexu/blog-md-34c5d082a8c5</a></p>
<p>[3]Â The state of sentiment analysis: word, sub-word and character embeddingÂ 
<a href='https://amethix.com/state-of-sentiment-analysis-embedding/'>https://amethix.com/state-of-sentiment-analysis-embedding/</a></p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>The rapid diffusion of social media like Facebook and Twitter, and the massive use of different types of forums like Reddit, Quora, etc., is producing an impressive amount of text data every day.Â </p>
<p>There is one specific activity that many business owners have been contemplating over the last five years, that is identifying the social sentiment of their brand, by analysing the conversations of their users.</p>
<p>In this episode I explain how one can get the best shot at classifying sentences with deep learning and word embedding.</p>
<p>Â </p>
<p>Â </p>
Additional material
<p>Schematic representation of how to learn a word embedding matrix E by training a neural network that, given the previous M words, predicts the next word in a sentence.Â </p>
<p>Â </p>
<p></p>
<p>Â </p>
<p>Â </p>
<p>Word2Vec example source code</p>
<p><a href='https://gist.github.com/rlangone/ded90673f65e932fd14ae53a26e89eee#file-word2vec_example-py'>https://gist.github.com/rlangone/ded90673f65e932fd14ae53a26e89eee#file-word2vec_example-py</a></p>
Â 
<p>Â </p>
References
<p>[1] Mikolov, T. et al., "Distributed Representations of Words and Phrases and their Compositionality", Advances in Neural Information Processing Systems 26, pages 3111-3119, 2013.</p>
<p>[2] The Best Embedding Method for Sentiment Classification, <a href='https://medium.com/@bramblexu/blog-md-34c5d082a8c5'>https://medium.com/@bramblexu/blog-md-34c5d082a8c5</a></p>
<p>[3]Â The state of sentiment analysis: word, sub-word and character embeddingÂ <br>
<a href='https://amethix.com/state-of-sentiment-analysis-embedding/'>https://amethix.com/state-of-sentiment-analysis-embedding/</a></p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wn6z4u/064.mp3" length="24920316" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The rapid diffusion of social media like Facebook and Twitter, and the massive use of different types of forums like Reddit, Quora, etc., is producing an impressive amount of text data every day.Â 
There is one specific activity that many business owners have been contemplating over the last five years, that is identifying the social sentiment of their brand, by analysing the conversations of their users.
In this episode I explain how one can get the best shot at classifying sentences with deep learning and word embedding.
Â 
Â 
Additional material
Schematic representation of how to learn a word embedding matrix E by training a neural network that, given the previous M words, predicts the next word in a sentence.Â 
Â 

Â 
Â 
Word2Vec example source code
https://gist.github.com/rlangone/ded90673f65e932fd14ae53a26e89eee#file-word2vec_example-py
Â 
Â 
References
[1] Mikolov, T. et al., "Distributed Representations of Words and Phrases and their Compositionality", Advances in Neural Information Processing Systems 26, pages 3111-3119, 2013.
[2] The Best Embedding Method for Sentiment Classification, https://medium.com/@bramblexu/blog-md-34c5d082a8c5
[3]Â The state of sentiment analysis: word, sub-word and character embeddingÂ https://amethix.com/state-of-sentiment-analysis-embedding/
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>12:58</itunes:duration>
                <itunes:episode>59</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 63: Financial time series and machine learning </title>
        <itunes:title>Episode 63: Financial time series and machine learning </itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-63-financial-time-series-and-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-63-financial-time-series-and-machine-learning/#comments</comments>        <pubDate>Tue, 04 Jun 2019 12:35:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-63-financial-time-series-and-machine-learning-5e52c7a34f2ef21c2f0b8e7ce388d371</guid>
                                    <description><![CDATA[<p>In this episode I speak to Alexandr Honchar, data scientist and owner of blogÂ <a href='https://medium.com/@alexrachnog'>https://medium.com/@alexrachnog</a>
Alexandr has written very interesting posts about time series analysis for financial data. His blog is in my personal list of best tutorial blogs.Â 

We discuss about financial time series and machine learning, what makes predicting the price of stocks a very challenging task and why machine learning might not be enough.
As usual, I ask Alexandr how he sees machine learning in the next 10 years. His answer - in my opinion quite futuristic - makes perfect sense.Â </p>
<p>You can contact Alexandr on</p>
<ul><li>TwitterÂ <a href='https://twitter.com/AlexRachnog'>https://twitter.com/AlexRachnog</a></li>
<li>FacebookÂ <a href='https://www.facebook.com/rachnog'>https://www.facebook.com/rachnog</a></li>
<li>MediumÂ <a href='https://medium.com/@alexrachnog'>https://medium.com/@alexrachnog</a></li>
</ul>
<p>Â </p>
<p>Enjoy the show!</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak to Alexandr Honchar, data scientist and owner of blogÂ <a href='https://medium.com/@alexrachnog'>https://medium.com/@alexrachnog</a><br>
Alexandr has written very interesting posts about time series analysis for financial data. His blog is in my personal list of best tutorial blogs.Â <br>
<br>
We discuss about financial time series and machine learning, what makes predicting the price of stocks a very challenging task and why machine learning might not be enough.<br>
As usual, I ask Alexandr how he sees machine learning in the next 10 years. His answer - in my opinion quite futuristic - makes perfect sense.Â </p>
<p>You can contact Alexandr on</p>
<ul><li>TwitterÂ <a href='https://twitter.com/AlexRachnog'>https://twitter.com/AlexRachnog</a></li>
<li>FacebookÂ <a href='https://www.facebook.com/rachnog'>https://www.facebook.com/rachnog</a></li>
<li>MediumÂ <a href='https://medium.com/@alexrachnog'>https://medium.com/@alexrachnog</a></li>
</ul>
<p>Â </p>
<p>Enjoy the show!</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ckndp7/063.mp3" length="40588770" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak to Alexandr Honchar, data scientist and owner of blogÂ https://medium.com/@alexrachnogAlexandr has written very interesting posts about time series analysis for financial data. His blog is in my personal list of best tutorial blogs.Â We discuss about financial time series and machine learning, what makes predicting the price of stocks a very challenging task and why machine learning might not be enough.As usual, I ask Alexandr how he sees machine learning in the next 10 years. His answer - in my opinion quite futuristic - makes perfect sense.Â 
You can contact Alexandr on
TwitterÂ https://twitter.com/AlexRachnog
FacebookÂ https://www.facebook.com/rachnog
MediumÂ https://medium.com/@alexrachnog
Â 
Enjoy the show!
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:08</itunes:duration>
                <itunes:episode>58</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 62: AI and the future of banking with Chris Skinner</title>
        <itunes:title>Episode 62: AI and the future of banking with Chris Skinner</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-62-ai-and-the-future-of-banking-with-chris-skinner/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-62-ai-and-the-future-of-banking-with-chris-skinner/#comments</comments>        <pubDate>Tue, 28 May 2019 08:50:01 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-62-ai-and-the-future-of-banking-with-chris-skinner-cfa3ce51dd748629042332471619af1d</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode I have a wonderful conversation with Chris Skinner.</p>
<p>Chris and I recently got in touch at The banking scene 2019, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. </p>
<p>After I got my hands on his last book Digital Human, I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode I have a wonderful conversation with Chris Skinner.</p>
<p>Chris and I recently got in touch at <em>The banking scene 2019</em>, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. </p>
<p>After I got my hands on his last book <em>Digital Human,</em> I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/c8a58k/062-corrected.mp3" length="80766001" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I have a wonderful conversation with Chris Skinner.
Chris and I recently got in touch at The banking scene 2019, fintech conference recently held in Brussels. During that conference he talked as a real trouble maker - thatâ€™s how he defines himself - saying that â€œPeople are not educated with loans, credit, moneyâ€ and that â€œBanks are failing at digitalâ€. 
After I got my hands on his last book Digital Human, I invited him to the show to ask him a few questions about innovation, regulation and technology in finance.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>42:03</itunes:duration>
                <itunes:episode>57</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 61: The 4 best use cases of entropy in machine learning</title>
        <itunes:title>Episode 61: The 4 best use cases of entropy in machine learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-61-the-4-best-use-cases-of-entropy-in-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-61-the-4-best-use-cases-of-entropy-in-machine-learning/#comments</comments>        <pubDate>Tue, 21 May 2019 12:20:48 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-61-the-4-best-use-cases-of-entropy-in-machine-learning-c47eca925b78b3cb5a65a2d3b08a8079</guid>
                                    <description><![CDATA[<p>It all starts from physics.Â The entropy of an isolated system never decreasesâ€¦Â Everyone at school, at some point of his life, learned this in his physics class. What does this have to do with machine learning? 
To find out, listen to the show.</p>
<p>Â </p>
References
<p class="entry-title">Entropy in machine learningÂ 
<a href='https://amethix.com/entropy-in-machine-learning/'>https://amethix.com/entropy-in-machine-learning/</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p>It all starts from physics.Â <em>Th</em><em>e entropy of an isolated system never decreasesâ€¦</em>Â Everyone at school, at some point of his life, learned this in his physics class. What does this have to do with machine learning? <br>
To find out, listen to the show.</p>
<p>Â </p>
References
<p class="entry-title">Entropy in machine learningÂ <br>
<a href='https://amethix.com/entropy-in-machine-learning/'>https://amethix.com/entropy-in-machine-learning/</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/hn4e9m/061.mp3" length="41462305" type="audio/mpeg"/>
        <itunes:summary><![CDATA[It all starts from physics.Â The entropy of an isolated system never decreasesâ€¦Â Everyone at school, at some point of his life, learned this in his physics class. What does this have to do with machine learning? To find out, listen to the show.
Â 
References
Entropy in machine learningÂ https://amethix.com/entropy-in-machine-learning/]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:35</itunes:duration>
                <itunes:episode>56</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/data_science_at_home_podcast_cover.png" />    </item>
    <item>
        <title>Episode 60: Predicting your mouse click (and a crash course in deeplearning)</title>
        <itunes:title>Episode 60: Predicting your mouse click (and a crash course in deeplearning)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-60-predicting-the-next-button-to-click-and-a-crash-course-in-deeplearning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-60-predicting-the-next-button-to-click-and-a-crash-course-in-deeplearning/#comments</comments>        <pubDate>Thu, 16 May 2019 07:25:55 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-60-predicting-the-next-button-to-click-and-a-crash-course-in-deeplearning-69f6aff1ff89a0e47be547153b3e7beb</guid>
                                    <description><![CDATA[<p style="text-align:left;">Deep learning is the future. Get a crash course on deep learning. Now! 
In this episode I speak to Oliver Zeigermann, author of Deep Learning Crash Course published by Manning Publications atÂ <a href='https://www.manning.com/livevideo/deep-learning-crash-course'>https://www.manning.com/livevideo/deep-learning-crash-course</a></p>
<p class="p3" style="text-align:left;">Oliver (Twitter:Â <a href='https://twitter.com/@DJCordhose'>@DJCordhose</a>) is a veteran of neural networks and machine learning. In addition to the course - that teaches you concepts from prototype to production - he's working on a really cool project that predicts something people do every day... clicking their mouse.Â </p>
<p class="p3" style="text-align:left;">If you use promo codeÂ poddatascienceathome19Â you get a 40% discount for all products on the Manning platform</p>
<p class="p3" style="text-align:left;">Enjoy the show!</p>
<p class="p3" style="text-align:left;">Â </p>
References:
<p class="p3" style="text-align:left;">Â </p>
<p class="p3" style="text-align:left;">Deep Learning Crash Course (Manning Publications)</p>
<p class="p3" style="text-align:left;"><a href='https://www.manning.com/livevideo/deep-learning-crash-course?a_aid=djcordhose&a_bid=e8e77cbf'>https://www.manning.com/livevideo/deep-learning-crash-course?a_aid=djcordhose&a_bid=e8e77cbf</a></p>
<p class="p3" style="text-align:left;">Â </p>
<p>Companion notebooks for the code samples of the video course "Deep Learning Crash Course"</p>
<p class="p3" style="text-align:left;"><a href='https://github.com/DJCordhose/deep-learning-crash-course-notebooks/blob/master/README.md'>https://github.com/DJCordhose/deep-learning-crash-course-notebooks/blob/master/README.md</a></p>
<p>Â </p>
<p>Next-button-to-click predictor source code</p>
<p class="p3" style="text-align:left;"><a href='https://github.com/DJCordhose/ux-by-tfjs'>https://github.com/DJCordhose/ux-by-tfjs</a></p>
<p class="p3" style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Deep learning is the future. Get a crash course on deep learning. Now! <br>
In this episode I speak to Oliver Zeigermann, author of <em>Deep Learning Crash Course</em> published by Manning Publications atÂ <a href='https://www.manning.com/livevideo/deep-learning-crash-course'>https://www.manning.com/livevideo/deep-learning-crash-course</a></p>
<p class="p3" style="text-align:left;">Oliver (Twitter:Â <a href='https://twitter.com/@DJCordhose'>@DJCordhose</a>) is a veteran of neural networks and machine learning. In addition to the course - that teaches you concepts from prototype to production - he's working on a really cool project that predicts something people do every day... clicking their mouse.Â </p>
<p class="p3" style="text-align:left;">If you use promo codeÂ poddatascienceathome19Â you get a 40% discount for all products on the Manning platform</p>
<p class="p3" style="text-align:left;">Enjoy the show!</p>
<p class="p3" style="text-align:left;">Â </p>
References:
<p class="p3" style="text-align:left;">Â </p>
<p class="p3" style="text-align:left;">Deep Learning Crash Course (Manning Publications)</p>
<p class="p3" style="text-align:left;"><a href='https://www.manning.com/livevideo/deep-learning-crash-course?a_aid=djcordhose&a_bid=e8e77cbf'>https://www.manning.com/livevideo/deep-learning-crash-course?a_aid=djcordhose&a_bid=e8e77cbf</a></p>
<p class="p3" style="text-align:left;">Â </p>
<p>Companion notebooks for the code samples of the video course "Deep Learning Crash Course"</p>
<p class="p3" style="text-align:left;"><a href='https://github.com/DJCordhose/deep-learning-crash-course-notebooks/blob/master/README.md'>https://github.com/DJCordhose/deep-learning-crash-course-notebooks/blob/master/README.md</a></p>
<p>Â </p>
<p>Next-button-to-click predictor source code</p>
<p class="p3" style="text-align:left;"><a href='https://github.com/DJCordhose/ux-by-tfjs'>https://github.com/DJCordhose/ux-by-tfjs</a></p>
<p class="p3" style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nefthy/062.mp3" length="76493137" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Deep learning is the future. Get a crash course on deep learning. Now! In this episode I speak to Oliver Zeigermann, author of Deep Learning Crash Course published by Manning Publications atÂ https://www.manning.com/livevideo/deep-learning-crash-course
Oliver (Twitter:Â @DJCordhose) is a veteran of neural networks and machine learning. In addition to the course - that teaches you concepts from prototype to production - he's working on a really cool project that predicts something people do every day... clicking their mouse.Â 
If you use promo codeÂ poddatascienceathome19Â you get a 40% discount for all products on the Manning platform
Enjoy the show!
Â 
References:
Â 
Deep Learning Crash Course (Manning Publications)
https://www.manning.com/livevideo/deep-learning-crash-course?a_aid=djcordhose&a_bid=e8e77cbf
Â 
Companion notebooks for the code samples of the video course "Deep Learning Crash Course"
https://github.com/DJCordhose/deep-learning-crash-course-notebooks/blob/master/README.md
Â 
Next-button-to-click predictor source code
https://github.com/DJCordhose/ux-by-tfjs
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>39:50</itunes:duration>
                <itunes:episode>55</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 59: How to fool a smart camera with deep learning</title>
        <itunes:title>Episode 59: How to fool a smart camera with deep learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-59-reproducible-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-59-reproducible-machine-learning/#comments</comments>        <pubDate>Tue, 07 May 2019 14:07:29 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-59-reproducible-machine-learning-98943e021c47525a09fdb81ad6bb0fba</guid>
                                    <description><![CDATA[<p class="title mathjax">In this episode I met three crazy researchers from KULeuven (Belgium) who found a method to fool surveillance cameras and stay hidden just by holding a special t-shirt.Â 
We discussed about the technique they used and some consequences of their findings.</p>
<p class="title mathjax">They published their paper on <a href='https://arxiv.org/abs/1904.08653'>Arxiv</a> and made their source code available atÂ <a href='https://gitlab.com/EAVISE/adversarial-yolo'>https://gitlab.com/EAVISE/adversarial-yolo</a></p>
<p class="title mathjax">Enjoy the show!</p>
<p class="title mathjax">Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/1904.08653'>Fooling automated surveillance cameras: adversarial patches to attack person detectionÂ </a>
<a href='https://arxiv.org/search/cs?searchtype=author&query=Thys%2C+S'>Simen Thys</a>,Â <a href='https://arxiv.org/search/cs?searchtype=author&query=Van+Ranst%2C+W'>Wiebe Van Ranst</a>,Â <a href='https://arxiv.org/search/cs?searchtype=author&query=Goedem%C3%A9%2C+T'>Toon GoedemÃ©</a></p>
<p class="title mathjax">Â </p>
<p class="title mathjax">Eavise Research Group KULeuven (Belgium)
<a href='https://iiw.kuleuven.be/onderzoek/eavise'>https://iiw.kuleuven.be/onderzoek/eavise</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="title mathjax">In this episode I met three crazy researchers from KULeuven (Belgium) who found a method to fool surveillance cameras and stay hidden just by holding a special t-shirt.Â <br>
We discussed about the technique they used and some consequences of their findings.</p>
<p class="title mathjax">They published their paper on <a href='https://arxiv.org/abs/1904.08653'>Arxiv</a> and made their source code available atÂ <a href='https://gitlab.com/EAVISE/adversarial-yolo'>https://gitlab.com/EAVISE/adversarial-yolo</a></p>
<p class="title mathjax">Enjoy the show!</p>
<p class="title mathjax">Â </p>
References
<p class="title mathjax"><a href='https://arxiv.org/abs/1904.08653'>Fooling automated surveillance cameras: adversarial patches to attack person detectionÂ </a><br>
<a href='https://arxiv.org/search/cs?searchtype=author&query=Thys%2C+S'>Simen Thys</a>,Â <a href='https://arxiv.org/search/cs?searchtype=author&query=Van+Ranst%2C+W'>Wiebe Van Ranst</a>,Â <a href='https://arxiv.org/search/cs?searchtype=author&query=Goedem%C3%A9%2C+T'>Toon GoedemÃ©</a></p>
<p class="title mathjax">Â </p>
<p class="title mathjax">Eavise Research Group KULeuven (Belgium)<br>
<a href='https://iiw.kuleuven.be/onderzoek/eavise'>https://iiw.kuleuven.be/onderzoek/eavise</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/trkvh4/059.mp3" length="46467785" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I met three crazy researchers from KULeuven (Belgium) who found a method to fool surveillance cameras and stay hidden just by holding a special t-shirt.Â We discussed about the technique they used and some consequences of their findings.
They published their paper on Arxiv and made their source code available atÂ https://gitlab.com/EAVISE/adversarial-yolo
Enjoy the show!
Â 
References
Fooling automated surveillance cameras: adversarial patches to attack person detectionÂ Simen Thys,Â Wiebe Van Ranst,Â Toon GoedemÃ©
Â 
Eavise Research Group KULeuven (Belgium)https://iiw.kuleuven.be/onderzoek/eavise]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:11</itunes:duration>
                <itunes:episode>54</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 58: There is physics in deep learning!</title>
        <itunes:title>Episode 58: There is physics in deep learning!</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-58-there-is-physics-in-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-58-there-is-physics-in-deep-learning/#comments</comments>        <pubDate>Tue, 30 Apr 2019 09:30:34 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-58-there-is-physics-in-deep-learning-6a595057ba92cefe0391f95a490ee52a</guid>
                                    <description><![CDATA[<p style="text-align:left;">There is a connection between gradient descent based optimizers and the dynamics of damped harmonic oscillators. What does that mean? We now have a better theory for optimization algorithms.
In this episode I explain how all this works.</p>
<p style="text-align:left;">All the formulas I mention in the episode can be found in the postÂ <a href='https://amethix.com/the-physics-of-optimization-algorithms/'>The physics of optimization algorithms</a></p>
<p style="text-align:left;">Enjoy the show.</p>
<p style="text-align:left;">Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">There is a connection between gradient descent based optimizers and the dynamics of damped harmonic oscillators. What does that mean? We now have a better theory for optimization algorithms.<br>
In this episode I explain how all this works.</p>
<p style="text-align:left;">All the formulas I mention in the episode can be found in the postÂ <a href='https://amethix.com/the-physics-of-optimization-algorithms/'>The physics of optimization algorithms</a></p>
<p style="text-align:left;">Enjoy the show.</p>
<p style="text-align:left;">Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/dtpgp3/058.mp3" length="38257394" type="audio/mpeg"/>
        <itunes:summary><![CDATA[There is a connection between gradient descent based optimizers and the dynamics of damped harmonic oscillators. What does that mean? We now have a better theory for optimization algorithms.In this episode I explain how all this works.
All the formulas I mention in the episode can be found in the postÂ The physics of optimization algorithms
Enjoy the show.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:55</itunes:duration>
                <itunes:episode>53</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 57: Neural networks with infinite layers</title>
        <itunes:title>Episode 57: Neural networks with infinite layers</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-57-neural-networks-with-infinite-layers/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-57-neural-networks-with-infinite-layers/#comments</comments>        <pubDate>Tue, 23 Apr 2019 10:04:27 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-57-neural-networks-with-infinite-layers-f70b9f6fd5fb2cd9a81b28919d5c616a</guid>
                                    <description><![CDATA[<p style="text-align:left;">How are differential equations related to neural networks? What are the benefits of re-thinking neural network as a differential equation engine? In this episode we explain all this and we provide some material that is worth learning. Enjoy the show!</p>
<p style="text-align:left;">Â </p>
Residual Block
<p style="text-align:left;"></p>
<p>Â </p>
<p>Â </p>
References
<p style="text-align:left;">[1] K. He, et al., â€œDeep Residual Learning for Image Recognitionâ€, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016</p>
<p style="text-align:left;">[2] S. Hochreiter, et al., â€œLong short-term memoryâ€, Neural Computation 9(8), pages 1735-1780, 1997.</p>
<p style="text-align:left;">[3] Q. Liao, et al.,â€Bridging the gaps between residual learning, recurrent neural networks and visual cortexâ€, arXiv preprint, arXiv:1604.03640, 2016.</p>
<p style="text-align:left;">[4] Y. Lu, et al., â€œBeyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equationâ€, Proceedings of the 35th International Conference on Machine Learning (ICML), Stockholm, Sweden, 2018.</p>
<p style="text-align:left;">[5] T. Q. Chen, et al., â€ Neural Ordinary Differential Equationsâ€, Advances in Neural Information Processing Systems 31, pages 6571-6583}, 2018</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">How are differential equations related to neural networks? What are the benefits of re-thinking neural network as a differential equation engine? In this episode we explain all this and we provide some material that is worth learning. Enjoy the show!</p>
<p style="text-align:left;">Â </p>
Residual Block
<p style="text-align:left;"></p>
<p>Â </p>
<p>Â </p>
References
<p style="text-align:left;">[1] K. He, et al., â€œDeep Residual Learning for Image Recognitionâ€, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016</p>
<p style="text-align:left;">[2] S. Hochreiter, et al., â€œLong short-term memoryâ€, Neural Computation 9(8), pages 1735-1780, 1997.</p>
<p style="text-align:left;">[3] Q. Liao, et al.,â€Bridging the gaps between residual learning, recurrent neural networks and visual cortexâ€, arXiv preprint, arXiv:1604.03640, 2016.</p>
<p style="text-align:left;">[4] Y. Lu, et al., â€œBeyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equationâ€, Proceedings of the 35th International Conference on Machine Learning (ICML), Stockholm, Sweden, 2018.</p>
<p style="text-align:left;">[5] T. Q. Chen, et al., â€ Neural Ordinary Differential Equationsâ€, Advances in Neural Information Processing Systems 31, pages 6571-6583}, 2018</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6v78mz/057.mp3" length="31363575" type="audio/mpeg"/>
        <itunes:summary><![CDATA[How are differential equations related to neural networks? What are the benefits of re-thinking neural network as a differential equation engine? In this episode we explain all this and we provide some material that is worth learning. Enjoy the show!
Â 
Residual Block

Â 
Â 
References
[1] K. He, et al., â€œDeep Residual Learning for Image Recognitionâ€, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016
[2] S. Hochreiter, et al., â€œLong short-term memoryâ€, Neural Computation 9(8), pages 1735-1780, 1997.
[3] Q. Liao, et al.,â€Bridging the gaps between residual learning, recurrent neural networks and visual cortexâ€, arXiv preprint, arXiv:1604.03640, 2016.
[4] Y. Lu, et al., â€œBeyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equationâ€, Proceedings of the 35th International Conference on Machine Learning (ICML), Stockholm, Sweden, 2018.
[5] T. Q. Chen, et al., â€ Neural Ordinary Differential Equationsâ€, Advances in Neural Information Processing Systems 31, pages 6571-6583}, 2018]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:19</itunes:duration>
                <itunes:episode>52</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 56: The graph network </title>
        <itunes:title>Episode 56: The graph network </itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-56-the-graph-network/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-56-the-graph-network/#comments</comments>        <pubDate>Tue, 16 Apr 2019 08:32:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-56-the-graph-network-0d8feba7e8d1e7138659c82324fd4794</guid>
                                    <description><![CDATA[<p style="text-align:left;">Since the beginning of AI in the 1950s and until the 1980s, symbolic AI approaches have dominated the field. These approaches, also known as expert systems, used mathematical symbols to represent objects and the relationship between them, in order to depict the extensive knowledge bases built by humans.
 The opposite of the symbolic AI paradigm is named connectionism, which is behind the machine learning approaches of today</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Since the beginning of AI in the 1950s and until the 1980s, symbolic AI approaches have dominated the field. These approaches, also known as <em>expert systems</em>, used mathematical symbols to represent objects and the relationship between them, in order to depict the extensive knowledge bases built by humans.<br>
 The opposite of the symbolic AI paradigm is named <em>connectionism</em>, which is behind the machine learning approaches of today</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8u98un/056.mp3" length="31812463" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Since the beginning of AI in the 1950s and until the 1980s, symbolic AI approaches have dominated the field. These approaches, also known as expert systems, used mathematical symbols to represent objects and the relationship between them, in order to depict the extensive knowledge bases built by humans. The opposite of the symbolic AI paradigm is named connectionism, which is behind the machine learning approaches of today]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:34</itunes:duration>
                <itunes:episode>51</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 55: Beyond deep learning </title>
        <itunes:title>Episode 55: Beyond deep learning </itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-55-beyond-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-55-beyond-deep-learning/#comments</comments>        <pubDate>Tue, 09 Apr 2019 08:47:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-55-beyond-deep-learning-39f65586e78243938915d00fb3eed5aa</guid>
                                    <description><![CDATA[<p style="text-align:left;">The successes that deep learning systems have achieved in the last decade in all kinds of domains are unquestionable. Self-driving cars, skin cancer diagnostics, movie and song recommendations, language translation, automatic video surveillance, digital assistants represent just a few examples of the ongoing revolution that affects or is going to disrupt soon our everyday life.
But all that glitters is not goldâ€¦

Read the full post on the Amethix Technologies <a href='https://amethix.com/beyond-deep-learning-part-1/'>blog</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">The successes that deep learning systems have achieved in the last decade in all kinds of domains are unquestionable. Self-driving cars, skin cancer diagnostics, movie and song recommendations, language translation, automatic video surveillance, digital assistants represent just a few examples of the ongoing revolution that affects or is going to disrupt soon our everyday life.<br>
But all that glitters is not goldâ€¦<br>
<br>
Read the full post on the Amethix Technologies <a href='https://amethix.com/beyond-deep-learning-part-1/'>blog</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2s8m9n/055.mp3" length="33398200" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The successes that deep learning systems have achieved in the last decade in all kinds of domains are unquestionable. Self-driving cars, skin cancer diagnostics, movie and song recommendations, language translation, automatic video surveillance, digital assistants represent just a few examples of the ongoing revolution that affects or is going to disrupt soon our everyday life.But all that glitters is not goldâ€¦Read the full post on the Amethix Technologies blog]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:23</itunes:duration>
                <itunes:episode>50</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 54: Reproducible machine learning</title>
        <itunes:title>Episode 54: Reproducible machine learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-54-reproducible-machine-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-54-reproducible-machine-learning/#comments</comments>        <pubDate>Sat, 09 Mar 2019 14:53:29 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-54-reproducible-machine-learning-43b78e0e6407d7fbe7e4b3e36c1bd065</guid>
                                    <description><![CDATA[<p>In this episode I speak about how important reproducible machine learning pipelines are. 
When you are collaborating with diverse teams, several tasks will be distributed among different individuals. Everyone will have good reasons to change parts of your pipeline, leading to confusion and definitely a number of options that soon explode. 
In all those cases, tracking data and code is extremely helpful to build models that are reproducible anytime, anywhere. 
Listen to the podcast and learn how.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about how important reproducible machine learning pipelines are. <br>
When you are collaborating with diverse teams, several tasks will be distributed among different individuals. Everyone will have good reasons to change parts of your pipeline, leading to confusion and definitely a number of options that soon explode. <br>
In all those cases, tracking data and code is extremely helpful to build models that are reproducible anytime, anywhere. <br>
Listen to the podcast and learn how.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/nexuva/054.mp3" length="22740241" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about how important reproducible machine learning pipelines are. When you are collaborating with diverse teams, several tasks will be distributed among different individuals. Everyone will have good reasons to change parts of your pipeline, leading to confusion and definitely a number of options that soon explode. In all those cases, tracking data and code is extremely helpful to build models that are reproducible anytime, anywhere. Listen to the podcast and learn how.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>11:50</itunes:duration>
                <itunes:episode>49</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 53: Estimating uncertainty with neural networks</title>
        <itunes:title>Episode 53: Estimating uncertainty with neural networks</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-53-estimating-uncertainty-with-neural-networks/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-53-estimating-uncertainty-with-neural-networks/#comments</comments>        <pubDate>Wed, 23 Jan 2019 09:37:49 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-53-estimating-uncertainty-with-neural-networks-b03fee3a336aaeafe01752c4aca519ba</guid>
                                    <description><![CDATA[<p style="text-align:left;">Have you ever wanted to get an estimate of the uncertainty of your neural network? Clearly Bayesian modelling provides a solid framework to estimate uncertainty by design. However, there are many realistic cases in which Bayesian sampling is not really an option and ensemble models can play a role.</p>
<p style="text-align:left;">In this episode I describe a simple yet effective way to estimate uncertainty, without changing your neural networkâ€™s architecture nor your machine learning pipeline at all.</p>
<p style="text-align:left;">The post with mathematical background and sample source code is published <a href='https://amethix.com/2019/01/know-what-you-predict-estimating-uncertainty-with-neural-networks/'>here</a>.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Have you ever wanted to get an estimate of the uncertainty of your neural network? Clearly Bayesian modelling provides a solid framework to estimate uncertainty by design. However, there are many realistic cases in which Bayesian sampling is not really an option and ensemble models can play a role.</p>
<p style="text-align:left;">In this episode I describe a simple yet effective way to estimate uncertainty, without changing your neural networkâ€™s architecture nor your machine learning pipeline at all.</p>
<p style="text-align:left;">The post with mathematical background and sample source code is published <a href='https://amethix.com/2019/01/know-what-you-predict-estimating-uncertainty-with-neural-networks/'>here</a>.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4yjfyg/053.mp3" length="29091549" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Have you ever wanted to get an estimate of the uncertainty of your neural network? Clearly Bayesian modelling provides a solid framework to estimate uncertainty by design. However, there are many realistic cases in which Bayesian sampling is not really an option and ensemble models can play a role.
In this episode I describe a simple yet effective way to estimate uncertainty, without changing your neural networkâ€™s architecture nor your machine learning pipeline at all.
The post with mathematical background and sample source code is published here.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:08</itunes:duration>
                <itunes:episode>48</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 52: why do machine learning models fail? [RB]</title>
        <itunes:title>Episode 52: why do machine learning models fail? [RB]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-52-why-do-machine-learning-models-fail-rb/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-52-why-do-machine-learning-models-fail-rb/#comments</comments>        <pubDate>Thu, 17 Jan 2019 07:28:33 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-52-why-do-machine-learning-models-fail-rb-958ae906ea03bec3feb9035460aade46</guid>
                                    <description><![CDATA[<p>The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.</p>
<p>In this episode I explain when and why machine learning models fail from training to testing datasets.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.</p>
<p>In this episode I explain when and why machine learning models fail from training to testing datasets.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cjs6sv/052.mp3" length="30666419" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.
In this episode I explain when and why machine learning models fail from training to testing datasets.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:58</itunes:duration>
                <itunes:episode>47</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 51: Decentralized machine learning in the data marketplace (part 2)</title>
        <itunes:title>Episode 51: Decentralized machine learning in the data marketplace (part 2)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-51-decentralized-machine-learning-in-the-data-marketplace-part-2/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-51-decentralized-machine-learning-in-the-data-marketplace-part-2/#comments</comments>        <pubDate>Tue, 08 Jan 2019 12:13:55 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-51-decentralized-machine-learning-in-the-data-marketplace-part-2-be6dcf9c2787f104f47c7bf16dba0c9c</guid>
                                    <description><![CDATA[<p>In this episode I am completing the explanation about the integration fitchain-oceanprotocol that allows secure on-premise compute to operate in the decentralized data marketplace designed by <a href='/datascienceathome/episode/update/id/oceanprotocol.com'>Ocean Protocol</a>.</p>
<p>As mentioned in the show, this is a picture that provides a 10000-feet view of the integration.</p>
<p>Â </p>
<p>Â </p>
<p>I hope you enjoy the show!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I am completing the explanation about the integration fitchain-oceanprotocol that allows secure on-premise compute to operate in the decentralized data marketplace designed by <a href='/datascienceathome/episode/update/id/oceanprotocol.com'>Ocean Protocol</a>.</p>
<p>As mentioned in the show, this is a picture that provides a 10000-feet view of the integration.</p>
<p>Â </p>
<p>Â </p>
<p>I hope you enjoy the show!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/e953en/051.mp3" length="33330254" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I am completing the explanation about the integration fitchain-oceanprotocol that allows secure on-premise compute to operate in the decentralized data marketplace designed by Ocean Protocol.
As mentioned in the show, this is a picture that provides a 10000-feet view of the integration.
Â 
Â 
I hope you enjoy the show!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:08</itunes:duration>
                <itunes:episode>46</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 50: Decentralized machine learning in the data marketplace </title>
        <itunes:title>Episode 50: Decentralized machine learning in the data marketplace </itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-50-decentralized-machine-learning-in-the-data-marketplace/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-50-decentralized-machine-learning-in-the-data-marketplace/#comments</comments>        <pubDate>Wed, 26 Dec 2018 17:06:52 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-50-decentralized-machine-learning-in-the-data-marketplace-6bd4f521de681cb34aac0e048f7fc36b</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode I briefly explain how two massive technologies have been merged in 2018 (work in progress :) - one providing secure machine learning on isolated data, the other implementing a decentralized data marketplace.</p>
<p style="text-align:left;">In this episode I explain:</p>
<ul><li style="text-align:left;">How do we make machine learning decentralized and secure?</li>
<li style="text-align:left;">How can data owners keep their data private?</li>
<li style="text-align:left;">How can we benefit from blockchain technology for AI and machine learning?</li>
</ul>
<p>Â </p>
<p style="text-align:left;">I hope you enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p style="text-align:left;"><a href='/datascienceathome/episode/update/id/fitchain.io'>fitchain.io</a> decentralized machine learnin</p>
<p style="text-align:left;"><a href='/datascienceathome/episode/update/id/oceanprotocol.com'>Ocean protocol</a> decentralized data marketplace</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode I briefly explain how two massive technologies have been merged in 2018 (work in progress :) - one providing secure machine learning on isolated data, the other implementing a decentralized data marketplace.</p>
<p style="text-align:left;">In this episode I explain:</p>
<ul><li style="text-align:left;">How do we make machine learning decentralized and secure?</li>
<li style="text-align:left;">How can data owners keep their data private?</li>
<li style="text-align:left;">How can we benefit from blockchain technology for AI and machine learning?</li>
</ul>
<p>Â </p>
<p style="text-align:left;">I hope you enjoy the show!</p>
<p style="text-align:left;">Â </p>
References
<p style="text-align:left;"><a href='/datascienceathome/episode/update/id/fitchain.io'>fitchain.io</a> decentralized machine learnin</p>
<p style="text-align:left;"><a href='/datascienceathome/episode/update/id/oceanprotocol.com'>Ocean protocol</a> decentralized data marketplace</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tzamki/050.mp3" length="46652523" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I briefly explain how two massive technologies have been merged in 2018 (work in progress :) - one providing secure machine learning on isolated data, the other implementing a decentralized data marketplace.
In this episode I explain:
How do we make machine learning decentralized and secure?
How can data owners keep their data private?
How can we benefit from blockchain technology for AI and machine learning?
Â 
I hope you enjoy the show!
Â 
References
fitchain.io decentralized machine learnin
Ocean protocol decentralized data marketplace]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>24:17</itunes:duration>
                <itunes:episode>45</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 49: The promises of Artificial Intelligence</title>
        <itunes:title>Episode 49: The promises of Artificial Intelligence</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-49-the-promises-of-artificial-intelligence/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-49-the-promises-of-artificial-intelligence/#comments</comments>        <pubDate>Wed, 19 Dec 2018 20:56:17 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-49-the-promises-of-artificial-intelligence-dbe2812c2071f53558d73fd2ae8b558c</guid>
                                    <description><![CDATA[<p>It's always good to put in perspective all the findings in AI, in order to clear some of the most common misunderstandings and promises. 
In this episode I make a list of some of the most misleading statements about what artificial intelligence can achieve in the near future.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>It's always good to put in perspective all the findings in AI, in order to clear some of the most common misunderstandings and promises. <br>
In this episode I make a list of some of the most misleading statements about what artificial intelligence can achieve in the near future.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vb25wz/49.mp3" length="40334651" type="audio/mpeg"/>
        <itunes:summary><![CDATA[It's always good to put in perspective all the findings in AI, in order to clear some of the most common misunderstandings and promises. In this episode I make a list of some of the most misleading statements about what artificial intelligence can achieve in the near future.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:00</itunes:duration>
                <itunes:episode>44</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 48: Coffee, Machine Learning and Blockchain</title>
        <itunes:title>Episode 48: Coffee, Machine Learning and Blockchain</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-48-coffee-machine-learning-and-blockchain/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-48-coffee-machine-learning-and-blockchain/#comments</comments>        <pubDate>Sun, 21 Oct 2018 22:42:45 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-48-coffee-machine-learning-and-blockchain-e4283da8f956494b616884662537c634</guid>
                                    <description><![CDATA[<p style="text-align:left;">In this episode - which I advise to consume at night, in a quite place - I speak about private machine learning and blockchain, while I sip a cup of coffee in my home office.
There are several reasons why I believe we should start thinking about private machine learning...
It doesn't really matter what approach becomes successful and gets adopted, as long as it makes private machine learning possible. If people own their data, they should also own the by-product of such data.</p>
<p style="text-align:left;">Decentralized machine learning makes this scenario possible.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In this episode - which I advise to consume at night, in a quite place - I speak about private machine learning and blockchain, while I sip a cup of coffee in my home office.<br>
There are several reasons why I believe we should start thinking about private machine learning...<br>
It doesn't really matter what approach becomes successful and gets adopted, as long as it makes private machine learning possible. If people own their data, they should also own the by-product of such data.</p>
<p style="text-align:left;">Decentralized machine learning makes this scenario possible.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/skc84w/48.mp3" length="55305114" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode - which I advise to consume at night, in a quite place - I speak about private machine learning and blockchain, while I sip a cup of coffee in my home office.There are several reasons why I believe we should start thinking about private machine learning...It doesn't really matter what approach becomes successful and gets adopted, as long as it makes private machine learning possible. If people own their data, they should also own the by-product of such data.
Decentralized machine learning makes this scenario possible.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>28:48</itunes:duration>
                <itunes:episode>43</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 47: Are you ready for AI winter? [Rebroadcast]</title>
        <itunes:title>Episode 47: Are you ready for AI winter? [Rebroadcast]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-47-are-you-ready-for-ai-winter-rebroadcast/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-47-are-you-ready-for-ai-winter-rebroadcast/#comments</comments>        <pubDate>Tue, 11 Sep 2018 10:44:27 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-47-are-you-ready-for-ai-winter-rebroadcast-375a30cc6244322675d1f9af2d4ff3b9</guid>
                                    <description><![CDATA[<p style="text-align:left;">Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. 
His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â 
I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. 
He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. <br>
His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â <br>
I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. <br>
He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cwrtyk/47-34_rebroadcast.mp3" length="81983173" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>56:55</itunes:duration>
                <itunes:episode>42</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 46: why do machine learning models fail? (Part 2)</title>
        <itunes:title>Episode 46: why do machine learning models fail? (Part 2)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-46-why-do-machine-learning-models-fail-part-2/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-46-why-do-machine-learning-models-fail-part-2/#comments</comments>        <pubDate>Tue, 04 Sep 2018 11:07:53 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-46-why-do-machine-learning-models-fail-part-2-69db2ef2ee63349d2d46d2961d04b9a2</guid>
                                    <description><![CDATA[<p>In this episode I continue the conversation from the previous one, about failing machine learning models.</p>
<p>When data scientists have access to the distributions of training and testing datasets it becomes relatively easy to assess if a model will perform equally on both datasets. What happens with private datasets, where no access to the data can be granted?</p>
<p>At <a href='https://fitchain.io'>fitchain</a> we might have an answer to this fundamental problem.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I continue the conversation from the previous one, about failing machine learning models.</p>
<p>When data scientists have access to the distributions of training and testing datasets it becomes relatively easy to assess if a model will perform equally on both datasets. What happens with private datasets, where no access to the data can be granted?</p>
<p>At <a href='https://fitchain.io'>fitchain</a> we might have an answer to this fundamental problem.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/9zchmp/46.mp3" length="33052966" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I continue the conversation from the previous one, about failing machine learning models.
When data scientists have access to the distributions of training and testing datasets it becomes relatively easy to assess if a model will perform equally on both datasets. What happens with private datasets, where no access to the data can be granted?
At fitchain we might have an answer to this fundamental problem.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:12</itunes:duration>
                <itunes:episode>41</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://datascienceathome.podbean.com/mf/web/7t6ajw/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 45: why do machine learning models fail?</title>
        <itunes:title>Episode 45: why do machine learning models fail?</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-45-why-do-machine-learning-models-fail/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-45-why-do-machine-learning-models-fail/#comments</comments>        <pubDate>Tue, 28 Aug 2018 10:02:30 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-45-why-do-machine-learning-models-fail-0ffd654313a09065d71d2a92ce0ec416</guid>
                                    <description><![CDATA[<p style="text-align:left;">The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.</p>
<p style="text-align:left;">In this episode I explain when and why machine learning models fail from training to testing datasets.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.</p>
<p style="text-align:left;">In this episode I explain when and why machine learning models fail from training to testing datasets.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/srex59/45.mp3" length="31408715" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The success of a machine learning model depends on several factors and events. True generalization to data that the model has never seen before is more a chimera than a reality. But under specific conditions a well trained machine learning model can generalize well and perform with testing accuracy that is similar to the one performed during training.
In this episode I explain when and why machine learning models fail from training to testing datasets.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:21</itunes:duration>
                <itunes:episode>40</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 44: The predictive power of metadata</title>
        <itunes:title>Episode 44: The predictive power of metadata</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-44-the-predictive-power-of-metadata/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-44-the-predictive-power-of-metadata/#comments</comments>        <pubDate>Tue, 21 Aug 2018 08:01:22 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-44-the-predictive-power-of-metadata-3e0ca53995d698cebe862a3cae0c4cdf</guid>
                                    <description><![CDATA[<p>In this episode I don't talk about data. In fact, I talk about metadata.</p>
<p>While many machine learning models rely on certain amounts of data eg. text, images, audio and video, it has been proved how powerful is the signal carried by metadata, that is all data that is invisible to the end user.
Behind a tweet of 140 characters there are more than 140 fields of data that draw a much more detailed profile of the sender and the content she is producing... without ever considering the tweet itself.</p>
<p>Â </p>
<p>References 
You are your Metadata: Identification and Obfuscation of Social Media Users using Metadata Information https://www.ucl.ac.uk/~ucfamus/papers/icwsm18.pdf</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I don't talk about data. In fact, I talk about metadata.</p>
<p>While many machine learning models rely on certain amounts of data eg. text, images, audio and video, it has been proved how powerful is the signal carried by metadata, that is all data that is invisible to the end user.<br>
Behind a tweet of 140 characters there are more than 140 fields of data that draw a much more detailed profile of the sender and the content she is producing... without ever considering the tweet itself.</p>
<p>Â </p>
<p>References <br>
You are your Metadata: Identification and Obfuscation of Social Media Users using Metadata Information <em>https://www.ucl.ac.uk/~ucfamus/papers/icwsm18.pdf</em></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ydwugd/44.mp3" length="40596294" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I don't talk about data. In fact, I talk about metadata.
While many machine learning models rely on certain amounts of data eg. text, images, audio and video, it has been proved how powerful is the signal carried by metadata, that is all data that is invisible to the end user.Behind a tweet of 140 characters there are more than 140 fields of data that draw a much more detailed profile of the sender and the content she is producing... without ever considering the tweet itself.
Â 
References You are your Metadata: Identification and Obfuscation of Social Media Users using Metadata Information https://www.ucl.ac.uk/~ucfamus/papers/icwsm18.pdf]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:08</itunes:duration>
                <itunes:episode>39</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 43: Applied Text Analysis with Python (interview with Rebecca Bilbro)</title>
        <itunes:title>Episode 43: Applied Text Analysis with Python (interview with Rebecca Bilbro)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-43-applied-text-analysis-with-python-interview-with-rebecca-bilbro/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-43-applied-text-analysis-with-python-interview-with-rebecca-bilbro/#comments</comments>        <pubDate>Tue, 14 Aug 2018 08:22:52 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-43-applied-text-analysis-with-python-interview-with-rebecca-bilbro-d23e8c2046a4deeeededd8d5c7bcf5f2</guid>
                                    <description><![CDATA[<p>Todayâ€™s episode is about text analysis with python. 
Python is the de facto standard in machine learning. A large community, a generous choice in the set of libraries, at the price of less performant tasks, sometimes. But overall a decent language for typical data science tasks.
</p>
<p>I am with Rebecca Bilbro, co-author of Applied Text Analysis with Python, with Benjamin Bengfort and Tony Ojeda. </p>
<p>We speak about the evolution of applied text analysis, tools and pipelines, chatbots.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Todayâ€™s episode is about text analysis with python. <br>
Python is the de facto standard in machine learning. A large community, a generous choice in the set of libraries, at the price of less performant tasks, sometimes. But overall a decent language for typical data science tasks.<br>
</p>
<p>I am with Rebecca Bilbro, co-author of Applied Text Analysis with Python, with Benjamin Bengfort and Tony Ojeda. </p>
<p>We speak about the evolution of applied text analysis, tools and pipelines, chatbots.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/tuugn3/43.mp3" length="70152696" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Todayâ€™s episode is about text analysis with python. Python is the de facto standard in machine learning. A large community, a generous choice in the set of libraries, at the price of less performant tasks, sometimes. But overall a decent language for typical data science tasks.
I am with Rebecca Bilbro, co-author of Applied Text Analysis with Python, with Benjamin Bengfort and Tony Ojeda. 
We speak about the evolution of applied text analysis, tools and pipelines, chatbots.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>36:32</itunes:duration>
                <itunes:episode>38</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 42: Attacking deep learning models (rebroadcast)</title>
        <itunes:title>Episode 42: Attacking deep learning models (rebroadcast)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-42-attacking-deep-learning-models-rebroadcast/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-42-attacking-deep-learning-models-rebroadcast/#comments</comments>        <pubDate>Tue, 07 Aug 2018 07:21:55 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-42-attacking-deep-learning-models-rebroadcast-aba6148a9c91298e782f58156354f4e7</guid>
                                    <description><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
<p>Â </p>
<p class="graf graf--p graf-after--p">Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.</p>
<p class="graf graf--p graf-after--p">In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.</p>
]]></description>
                                                            <content:encoded><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
<p>Â </p>
<p class="graf graf--p graf-after--p">Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.</p>
<p class="graf graf--p graf-after--p">In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jg2sdr/42-35_rebroadcast.mp3" length="55820875" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
Â 
Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.
In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:04</itunes:duration>
                <itunes:episode>37</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 41: How can deep neural networks reason</title>
        <itunes:title>Episode 41: How can deep neural networks reason</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-41-1533014067/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-41-1533014067/#comments</comments>        <pubDate>Tue, 31 Jul 2018 07:16:45 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-41-1533014067-5fea2e91ed67355de1855f71dcee97e9</guid>
                                    <description><![CDATA[<p style="text-align:left;">Todayâ€™s episode Â will be about deep learning and reasoning. There has been a lot of discussion about the effectiveness of deep learning models and their capability to generalize, not only across domains but also on data that such models have never seen.</p>
<p style="text-align:left;">But there is a research group from the Department of Computer Science, Duke University that seems to be on something with deep learning and interpretability in computer vision.</p>
<p style="text-align:left;">Â </p>
References
<p style="text-align:left;">Prediction Analysis Lab Duke University <a href='https://users.cs.duke.edu/~cynthia/lab.html'>https://users.cs.duke.edu/~cynthia/lab.html</a></p>
<p class="title mathjax">This looks like that: deep learning for interpretable image recognitionÂ <a href='https://arxiv.org/abs/1806.10574'>https://arxiv.org/abs/1806.10574</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Todayâ€™s episode Â will be about deep learning and reasoning. There has been a lot of discussion about the effectiveness of deep learning models and their capability to generalize, not only across domains but also on data that such models have never seen.</p>
<p style="text-align:left;">But there is a research group from the Department of Computer Science, Duke University that seems to be on something with deep learning and interpretability in computer vision.</p>
<p style="text-align:left;">Â </p>
References
<p style="text-align:left;">Prediction Analysis Lab Duke University <a href='https://users.cs.duke.edu/~cynthia/lab.html'>https://users.cs.duke.edu/~cynthia/lab.html</a></p>
<p class="title mathjax">This looks like that: deep learning for interpretable image recognitionÂ <a href='https://arxiv.org/abs/1806.10574'>https://arxiv.org/abs/1806.10574</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/u584er/41.mp3" length="34698054" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Todayâ€™s episode Â will be about deep learning and reasoning. There has been a lot of discussion about the effectiveness of deep learning models and their capability to generalize, not only across domains but also on data that such models have never seen.
But there is a research group from the Department of Computer Science, Duke University that seems to be on something with deep learning and interpretability in computer vision.
Â 
References
Prediction Analysis Lab Duke University https://users.cs.duke.edu/~cynthia/lab.html
This looks like that: deep learning for interpretable image recognitionÂ https://arxiv.org/abs/1806.10574]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:03</itunes:duration>
                <itunes:episode>36</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 40: Deep learning and image compression</title>
        <itunes:title>Episode 40: Deep learning and image compression</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-40-deep-learning-and-image-compression/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-40-deep-learning-and-image-compression/#comments</comments>        <pubDate>Tue, 24 Jul 2018 07:15:16 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-40-deep-learning-and-image-compression-72f72d9ac2c49fe3e60fe9fa2f717382</guid>
                                    <description><![CDATA[<p>Todayâ€™s episode Â will be about deep learning and compression of data, and in particular compressing images. We all know how important compressing data is, reducing the size of digital objects without affecting the quality. 
As a very general rule, the more one compresses an image the lower the quality, due to a number of factors like bitrate, quantization error, etcetera. I am glad to be here with Tong Chen, Â researcher at the School of electronic Science and Engineering of Nanjing University, China. </p>
<p>Tong developed a deep learning based compression algorithm for images, that seems to improve over state of the art approaches like BPG, JPEG2000 and JPEG.</p>
<p>Â </p>
Reference
<p style="font-size: 19.9253px; font-family: sans-serif;"><a href='https://uk.arxiv.org/pdf/1806.01496.pdf'>Deep Image Compression via End-to-End Learning</a> - Haojie Liu, Tong Chen, Qiu Shen, Tao Yue, and Zhan Ma School of Electronic Science and Engineering, Nanjing University, Jiangsu, China</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Todayâ€™s episode Â will be about deep learning and compression of data, and in particular compressing images. We all know how important compressing data is, reducing the size of digital objects without affecting the quality. <br>
As a very general rule, the more one compresses an image the lower the quality, due to a number of factors like bitrate, quantization error, etcetera. I am glad to be here with Tong Chen, Â researcher at the School of electronic Science and Engineering of Nanjing University, China. </p>
<p>Tong developed a deep learning based compression algorithm for images, that seems to improve over state of the art approaches like BPG, JPEG2000 and JPEG.</p>
<p>Â </p>
Reference
<p style="font-size: 19.9253px; font-family: sans-serif;"><a href='https://uk.arxiv.org/pdf/1806.01496.pdf'>Deep Image Compression via End-to-End Learning</a> - Haojie Liu, Tong Chen, Qiu Shen, Tao Yue, and Zhan Ma School of Electronic Science and Engineering, Nanjing University, Jiangsu, China</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/qheddh/40.mp3" length="33305413" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Todayâ€™s episode Â will be about deep learning and compression of data, and in particular compressing images. We all know how important compressing data is, reducing the size of digital objects without affecting the quality. As a very general rule, the more one compresses an image the lower the quality, due to a number of factors like bitrate, quantization error, etcetera. I am glad to be here with Tong Chen, Â researcher at the School of electronic Science and Engineering of Nanjing University, China. 
Tong developed a deep learning based compression algorithm for images, that seems to improve over state of the art approaches like BPG, JPEG2000 and JPEG.
Â 
Reference
Deep Image Compression via End-to-End Learning - Haojie Liu, Tong Chen, Qiu Shen, Tao Yue, and Zhan Ma School of Electronic Science and Engineering, Nanjing University, Jiangsu, China
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:20</itunes:duration>
                <itunes:episode>35</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 39: What is L1-norm and L2-norm?</title>
        <itunes:title>Episode 39: What is L1-norm and L2-norm?</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-39-what-is-l1-norm-and-l2-norm/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-39-what-is-l1-norm-and-l2-norm/#comments</comments>        <pubDate>Thu, 19 Jul 2018 11:44:47 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-39-what-is-l1-norm-and-l2-norm-873581de6aa5f5a5e8e33d38cf84236d</guid>
                                    <description><![CDATA[<p>In this episode I explain the differences between L1 and L2 regularization that you can find in function minimization in basically any machine learning model.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I explain the differences between L1 and L2 regularization that you can find in function minimization in basically any machine learning model.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ypytdc/39.mp3" length="42109306" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I explain the differences between L1 and L2 regularization that you can find in function minimization in basically any machine learning model.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:55</itunes:duration>
                <itunes:episode>34</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 38: Collective intelligence (Part 2)</title>
        <itunes:title>Episode 38: Collective intelligence (Part 2)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-38-collective-intelligence-part-2/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-38-collective-intelligence-part-2/#comments</comments>        <pubDate>Tue, 17 Jul 2018 09:45:19 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-38-collective-intelligence-part-2-4b38957ee2e7c4de0900c98e5446f8da</guid>
                                    <description><![CDATA[<p style="text-align:left;">In the second part of this episode I am interviewing Johannes Castner from CollectiWise, a platform for collective intelligence. 
I am moving the conversation towards the more practical aspects of the project, asking about the centralised AGI and blockchain components that are essential part of the platform.
</p>
Â 
References 
<ol><li>Opencog.org
Thaler, Richard H., Sunstein, Cass R. and Balz, John P. (April 2, 2010). "Choice Architecture". <a href='https://en.wikipedia.org/wiki/Digital_object_identifier'>doi</a>:<a href='https://doi.org/10.2139/ssrn.1583509'>10.2139/ssrn.1583509</a>. <a href='https://en.wikipedia.org/wiki/Social_Science_Research_Network'>SSRN</a> <a href='https://ssrn.com/abstract=1583509'>1583509</a>â€¯</li>
<li>Teschner, F., Rothschild, D. & Gimpel, H. Group Decis Negot (2017) 26: 953. <a href='https://doi.org/10.1007/s10726-017-9531-0'>https://doi.org/10.1007/s10726-017-9531-0</a></li>
<li>Firas Khatib, Frank DiMaio, Foldit Contenders Group, Foldit Void Crushers Group, Seth Cooper, Maciej Kazmierczyk, Miroslaw Gilski, Szymon Krzywda, Helena Zabranska, Iva Pichova, James Thompson, Zoran PopoviÄ‡, Mariusz Jaskolski & David Baker, Crystal structure of a monomeric retroviral protease solved by protein folding game players, Nature Structural & Molecular Biology volume18, pages1175â€“1177 (2011)</li>
<li>Rosenthal, Franz; Dawood, Nessim Yosef David (1969). <a href='https://books.google.com/books?id=FlNZ5wmo5LAC'>The Muqaddimah : an introduction to history ; in three volumes. 1</a>. Princeton University Press. <a href='https://en.wikipedia.org/wiki/International_Standard_Book_Number'>ISBN</a> <a href='https://en.wikipedia.org/wiki/Special:BookSources/0-691-01754-9'>0-691-01754-9</a>.</li>
<li>Kevin J. Boudreau and Karim R. Lakhani, Using the Crowd as an Innovation Partner, April 2013.</li>
<li>Sam Bowles, The Moral Economy: Why Good Incentives are No Substitute for Good Citizens.
Amartya K. Sen, Rational Fools: A Critique of the Behavioral Foundations of Economic Theory, Philosophy & Public Affairs, Vol. 6, No. 4 (Summer, 1977), pp. 317-344, Published by:<a href='https://www.jstor.org/publisher/black'> Wiley</a>, Stable URL: http://www.jstor.org/stable/2264946</li>
</ol>]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In the second part of this episode I am interviewing Johannes Castner from CollectiWise, a platform for collective intelligence. <br>
I am moving the conversation towards the more practical aspects of the project, asking about the centralised AGI and blockchain components that are essential part of the platform.<br>
</p>
Â 
References 
<ol><li>Opencog.org<br>
Thaler, Richard H., Sunstein, Cass R. and Balz, John P. (April 2, 2010). "Choice Architecture". <a href='https://en.wikipedia.org/wiki/Digital_object_identifier'>doi</a>:<a href='https://doi.org/10.2139/ssrn.1583509'>10.2139/ssrn.1583509</a>. <a href='https://en.wikipedia.org/wiki/Social_Science_Research_Network'>SSRN</a> <a href='https://ssrn.com/abstract=1583509'>1583509</a>â€¯</li>
<li>Teschner, F., Rothschild, D. & Gimpel, H. Group Decis Negot (2017) 26: 953. <a href='https://doi.org/10.1007/s10726-017-9531-0'>https://doi.org/10.1007/s10726-017-9531-0</a></li>
<li>Firas Khatib, Frank DiMaio, Foldit Contenders Group, Foldit Void Crushers Group, Seth Cooper, Maciej Kazmierczyk, Miroslaw Gilski, Szymon Krzywda, Helena Zabranska, Iva Pichova, James Thompson, Zoran PopoviÄ‡, Mariusz Jaskolski & David Baker, <em>Crystal structure of a monomeric retroviral protease solved by protein folding game players, </em>Nature Structural & Molecular Biology volume18, pages1175â€“1177 (2011)</li>
<li>Rosenthal, Franz; Dawood, Nessim Yosef David (1969). <a href='https://books.google.com/books?id=FlNZ5wmo5LAC'><em>The Muqaddimah : an introduction to history ; in three volumes. 1</em></a>. Princeton University Press. <a href='https://en.wikipedia.org/wiki/International_Standard_Book_Number'>ISBN</a> <a href='https://en.wikipedia.org/wiki/Special:BookSources/0-691-01754-9'>0-691-01754-9</a>.</li>
<li>Kevin J. Boudreau and Karim R. Lakhani, <em>Using the Crowd as an Innovation Partner, </em>April 2013.</li>
<li>Sam Bowles, The Moral Economy: Why Good Incentives are No Substitute for Good Citizens.<br>
Amartya K. Sen, <em>Rational Fools: A Critique of the Behavioral Foundations of Economic Theory, </em>Philosophy & Public Affairs, Vol. 6, No. 4 (Summer, 1977), pp. 317-344, Published by:<a href='https://www.jstor.org/publisher/black'> Wiley</a>, Stable URL: http://www.jstor.org/stable/2264946</li>
</ol>]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vqaia9/38_2.mp3" length="89493340" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the second part of this episode I am interviewing Johannes Castner from CollectiWise, a platform for collective intelligence. I am moving the conversation towards the more practical aspects of the project, asking about the centralised AGI and blockchain components that are essential part of the platform.
Â 
References 
Opencog.orgThaler, Richard H., Sunstein, Cass R. and Balz, John P. (April 2, 2010). "Choice Architecture". doi:10.2139/ssrn.1583509. SSRN 1583509â€¯
Teschner, F., Rothschild, D. & Gimpel, H. Group Decis Negot (2017) 26: 953. https://doi.org/10.1007/s10726-017-9531-0
Firas Khatib, Frank DiMaio, Foldit Contenders Group, Foldit Void Crushers Group, Seth Cooper, Maciej Kazmierczyk, Miroslaw Gilski, Szymon Krzywda, Helena Zabranska, Iva Pichova, James Thompson, Zoran PopoviÄ‡, Mariusz Jaskolski & David Baker, Crystal structure of a monomeric retroviral protease solved by protein folding game players, Nature Structural & Molecular Biology volume18, pages1175â€“1177 (2011)
Rosenthal, Franz; Dawood, Nessim Yosef David (1969). The Muqaddimah : an introduction to history ; in three volumes. 1. Princeton University Press. ISBN 0-691-01754-9.
Kevin J. Boudreau and Karim R. Lakhani, Using the Crowd as an Innovation Partner, April 2013.
Sam Bowles, The Moral Economy: Why Good Incentives are No Substitute for Good Citizens.Amartya K. Sen, Rational Fools: A Critique of the Behavioral Foundations of Economic Theory, Philosophy & Public Affairs, Vol. 6, No. 4 (Summer, 1977), pp. 317-344, Published by: Wiley, Stable URL: http://www.jstor.org/stable/2264946
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>46:36</itunes:duration>
                <itunes:episode>33</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 38: Collective intelligence (Part 1)</title>
        <itunes:title>Episode 38: Collective intelligence (Part 1)</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-38-collective-intelligence-part-1/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-38-collective-intelligence-part-1/#comments</comments>        <pubDate>Thu, 12 Jul 2018 08:59:55 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-38-collective-intelligence-part-1-05e38c17616e18d2654ac17bb7b543fc</guid>
                                    <description><![CDATA[<p style="text-align:left;">This is the first part of the amazing episode with Johannes Castner, CEO and founder of CollectiWise. Johannes is finishing his PhD in Sustainable Development from Columbia University in New York City, and he is building a platform for collective intelligence. Today we talk about artificial general intelligence and wisdom. 
</p>
<p style="text-align:left;">All references and shownotes will be published after the next episode.
Enjoy and stay tuned!</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">This is the first part of the amazing episode with Johannes Castner, CEO and founder of CollectiWise. Johannes is finishing his PhD in Sustainable Development from Columbia University in New York City, and he is building a platform for collective intelligence. Today we talk about artificial general intelligence and wisdom. <br>
</p>
<p style="text-align:left;">All references and shownotes will be published after the next episode.<br>
Enjoy and stay tuned!</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/7vig88/38_1.mp3" length="59467987" type="audio/mpeg"/>
        <itunes:summary><![CDATA[This is the first part of the amazing episode with Johannes Castner, CEO and founder of CollectiWise. Johannes is finishing his PhD in Sustainable Development from Columbia University in New York City, and he is building a platform for collective intelligence. Today we talk about artificial general intelligence and wisdom. 
All references and shownotes will be published after the next episode.Enjoy and stay tuned!]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>30:58</itunes:duration>
                <itunes:episode>32</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 37: Predicting the weather with deep learning</title>
        <itunes:title>Episode 37: Predicting the weather with deep learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/predicting-the-weather-with-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/predicting-the-weather-with-deep-learning/#comments</comments>        <pubDate>Mon, 09 Jul 2018 08:35:50 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/predicting-the-weather-with-deep-learning-f1e13f8344485c4bde31dc401df6cc3c</guid>
                                    <description><![CDATA[<p>Predicting the weather is one of the most challenging tasks in machine learning due to the fact that physical phenomena are dynamic and riche of events. Moreover, most of traditional approaches to climate forecast are computationally prohibitive. 
It seems that a joint research between the Earth System Science at the University of California, Irvine and the faculty of Physics at LMU Munich has an interesting improvement on the scalability and accuracy of climate predictive modeling. The solution is... superparameterization and deep learning.</p>
<p>Â </p>
References Â Â  Â Â  Â Â Â  Â Â Â  Â Â Â  
<p style="text-align:left;">Could Machine Learning Break the Convection Parameterization Deadlock?Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  </p>
<ol style="text-align:left;"><li> Gentine, M. Pritchard, S. Rasp, G. Reinaudi, and G. Yacalis 
Earth and Environmental Engineering, Columbia University, New York, NY, USA, Earth System Science, University of California, Irvine, CA, USA, Faculty of Physics, LMU Munich, Munich, Germany</li>
</ol><p style="text-align:left;">Â Â Â  Â Â Â  Â Â Â  </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Predicting the weather is one of the most challenging tasks in machine learning due to the fact that physical phenomena are dynamic and riche of events. Moreover, most of traditional approaches to climate forecast are computationally prohibitive. <br>
It seems that a joint research between the Earth System Science at the University of California, Irvine and the faculty of Physics at LMU Munich has an interesting improvement on the scalability and accuracy of climate predictive modeling. The solution is... superparameterization and deep learning.</p>
<p>Â </p>
References Â Â  Â Â  Â Â Â  Â Â Â  Â Â Â  
<p style="text-align:left;">Could Machine Learning Break the Convection Parameterization Deadlock?Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  </p>
<ol style="text-align:left;"><li> Gentine, M. Pritchard, S. Rasp, G. Reinaudi, and G. Yacalis <br>
Earth and Environmental Engineering, Columbia University, New York, NY, USA, Earth System Science, University of California, Irvine, CA, USA, Faculty of Physics, LMU Munich, Munich, Germany</li>
</ol><p style="text-align:left;">Â Â Â  Â Â Â  Â Â Â  </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/a77ibt/37.mp3" length="50746851" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Predicting the weather is one of the most challenging tasks in machine learning due to the fact that physical phenomena are dynamic and riche of events. Moreover, most of traditional approaches to climate forecast are computationally prohibitive. It seems that a joint research between the Earth System Science at the University of California, Irvine and the faculty of Physics at LMU Munich has an interesting improvement on the scalability and accuracy of climate predictive modeling. The solution is... superparameterization and deep learning.
Â 
References Â Â  Â Â  Â Â Â  Â Â Â  Â Â Â  
Could Machine Learning Break the Convection Parameterization Deadlock?Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  Â Â Â  
 Gentine, M. Pritchard, S. Rasp, G. Reinaudi, and G. Yacalis Earth and Environmental Engineering, Columbia University, New York, NY, USA, Earth System Science, University of California, Irvine, CA, USA, Faculty of Physics, LMU Munich, Munich, Germany
Â Â Â  Â Â Â  Â Â Â  ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>26:25</itunes:duration>
                <itunes:episode>31</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 36: The dangers of machine learning and medicine</title>
        <itunes:title>Episode 36: The dangers of machine learning and medicine</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-dangers-of-machine-learning-and-medicine/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-dangers-of-machine-learning-and-medicine/#comments</comments>        <pubDate>Tue, 03 Jul 2018 13:44:15 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/the-dangers-of-machine-learning-and-medicine-9c524c614af29c6154e0b7888f7b196b</guid>
                                    <description><![CDATA[<p style="text-align:left;">Humans seem to have reached a cross-point, where they are asked to choose between functionality and privacy. But not both. Not both at all. No data, no service. Thatâ€™s what companies building personal finance services say. The same applies to marketing companies, social media companies, search engine companies, and healthcare institutions.</p>
<p style="text-align:left;">In this episode I speak about the reasons to aggregate data for precision medicine, the consequences of such strategies and how can researchers and organizations provide services to individuals while respecting their privacy.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Humans seem to have reached a cross-point, where they are asked to choose between functionality and privacy. But not both. Not both at all. <em>No data, no service.</em> Thatâ€™s what companies building personal finance services say. The same applies to marketing companies, social media companies, search engine companies, and healthcare institutions.</p>
<p style="text-align:left;">In this episode I speak about the reasons to aggregate data for precision medicine, the consequences of such strategies and how can researchers and organizations provide services to individuals while respecting their privacy.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6kx48h/36.mp3" length="42472095" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Humans seem to have reached a cross-point, where they are asked to choose between functionality and privacy. But not both. Not both at all. No data, no service. Thatâ€™s what companies building personal finance services say. The same applies to marketing companies, social media companies, search engine companies, and healthcare institutions.
In this episode I speak about the reasons to aggregate data for precision medicine, the consequences of such strategies and how can researchers and organizations provide services to individuals while respecting their privacy.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:07</itunes:duration>
                <itunes:episode>30</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience_v3.png" />    </item>
    <item>
        <title>Episode 35: Attacking deep learning models</title>
        <itunes:title>Episode 35: Attacking deep learning models</itunes:title>
        <link>https://datascienceathome.podbean.com/e/episode-35-attacking-deep-learning-models/</link>
                    <comments>https://datascienceathome.podbean.com/e/episode-35-attacking-deep-learning-models/#comments</comments>        <pubDate>Fri, 29 Jun 2018 11:44:13 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/episode-35-attacking-deep-learning-models-9ac5309986d991a3a99646ea50846585</guid>
                                    <description><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
<p>Â </p>
<p class="graf graf--p graf-after--p">Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.</p>
<p class="graf graf--p graf-after--p">In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.</p>
]]></description>
                                                            <content:encoded><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
<p>Â </p>
<p class="graf graf--p graf-after--p">Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.</p>
<p class="graf graf--p graf-after--p">In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8tid88/35.mp3" length="56120134" type="audio/mpeg"/>
        <itunes:summary><![CDATA[
Attacking deep learningÂ models
Compromising AI for fun andÂ profit
Â 
Deep learning models have shown very promising results in computer vision and sound recognition. As more and more deep learning based systems get integrated in disparate domains, they will keep affecting the life of people. Autonomous vehicles, medical imaging and banking applications, surveillance cameras and drones, digital assistants, are only a few real applications where deep learning plays a fundamental role. A malfunction in any of these applications will affect the quality of such integrated systems and compromise the security of the individuals who directly or indirectly use them.
In this episode, we explain how machine learning models can be attacked and what we can do to protect intelligent systems from beingÂ  compromised.
]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>29:13</itunes:duration>
                <itunes:episode>29</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/logo_squared_datascience.png" />    </item>
    <item>
        <title>Episode 34: Get ready for AI winter</title>
        <itunes:title>Episode 34: Get ready for AI winter</itunes:title>
        <link>https://datascienceathome.podbean.com/e/get-ready-for-ai-winter/</link>
                    <comments>https://datascienceathome.podbean.com/e/get-ready-for-ai-winter/#comments</comments>        <pubDate>Fri, 22 Jun 2018 11:05:42 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/get-ready-for-ai-winter-44cf68f7605bb991cbdbdc2212dad803</guid>
                                    <description><![CDATA[<p style="text-align:left;">Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. 
His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â 
I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. 
He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. <br>
His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â <br>
I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. <br>
He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/8bxipr/34.mp3" length="113423176" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Today I am having a conversation with Filip PiÄ™kniewski, researcher working on computer vision and AI at Koh Young Research America. His adventure with AI started in the 90s and since then a long list of experiences at the intersection of computer science and physics, led him to the conclusion that deep learning might not be sufficient nor appropriate to solve the problem of intelligence, specifically artificial intelligence. Â I read some of his publications and got familiar with some of his ideas. Honestly, I have been attracted by the fact that Filip does not buy the hype around AI and deep learning in particular. He doesnâ€™t seem to share the vision of folks like Elon Musk who claimed that we are going to see an exponential improvement in self driving cars among other things (he actually said that before a Tesla drove over a pedestrian).]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>59:04</itunes:duration>
                <itunes:episode>27</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 33: Decentralized Machine Learning and the proof-of-train</title>
        <itunes:title>Episode 33: Decentralized Machine Learning and the proof-of-train</itunes:title>
        <link>https://datascienceathome.podbean.com/e/decentralized-machine-learning-and-the-proof-of-train/</link>
                    <comments>https://datascienceathome.podbean.com/e/decentralized-machine-learning-and-the-proof-of-train/#comments</comments>        <pubDate>Mon, 11 Jun 2018 12:21:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/decentralized-machine-learning-and-the-proof-of-train-65003b7273b9b9bbdc50c9340758005b</guid>
                                    <description><![CDATA[<p style="text-align:left;">In the attempt of democratizing machine learning, data scientists should have the possibility to train their models on data they do not necessarily own, nor see. A model that is privately trained should be verified and uniquely identified across its entire life cycle, from its random initialization to setting the optimal values of its parameters.
How does blockchain allow all this? Fitchain is the decentralized machine learning platform that provides models an identity and a certification of their training procedure, the proof-of-train
</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In the attempt of democratizing machine learning, data scientists should have the possibility to train their models on data they do not necessarily own, nor see. A model that is privately trained should be <em class="markup--em markup--p-em">verified and uniquely identified</em> across its entire life cycle, from its random initialization to setting the optimal values of its parameters.<br>
How does blockchain allow all this? Fitchain is the decentralized machine learning platform that provides models an identity and a certification of their training procedure, the <em>proof-of-train</em><br>
</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/33vh7k/33.mp3" length="33953250" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the attempt of democratizing machine learning, data scientists should have the possibility to train their models on data they do not necessarily own, nor see. A model that is privately trained should be verified and uniquely identified across its entire life cycle, from its random initialization to setting the optimal values of its parameters.How does blockchain allow all this? Fitchain is the decentralized machine learning platform that provides models an identity and a certification of their training procedure, the proof-of-train]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:40</itunes:duration>
                <itunes:episode>26</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 32: I am back. I have been building fitchain</title>
        <itunes:title>Episode 32: I am back. I have been building fitchain</itunes:title>
        <link>https://datascienceathome.podbean.com/e/i-am-back-here-is-what-i-built/</link>
                    <comments>https://datascienceathome.podbean.com/e/i-am-back-here-is-what-i-built/#comments</comments>        <pubDate>Mon, 04 Jun 2018 12:45:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/i-am-back-here-is-what-i-built-0a97201eedd501d8cf7dcb819fb7c536</guid>
                                    <description><![CDATA[<p style="text-align:left;">I know, I have been away too long without publishing much in the last 3 months. 
But, there's a reason for that. I have been building a platform that combines machine learning with blockchain technology. 
Let me introduce you to fitchain and tell you more in this episode.</p>
<p style="text-align:left;">If you want to collaborate on the project or just think it's interesting, drop me a line on the contact page at <a href='https://fitchain.io'>fitchain.io</a></p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">I know, I have been away too long without publishing much in the last 3 months. <br>
But, there's a reason for that. I have been building a platform that combines machine learning with blockchain technology. <br>
Let me introduce you to fitchain and tell you more in this episode.</p>
<p style="text-align:left;">If you want to collaborate on the project or just think it's interesting, drop me a line on the contact page at <a href='https://fitchain.io'>fitchain.io</a></p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/qjbpu6/32.mp3" length="44641303" type="audio/mpeg"/>
        <itunes:summary><![CDATA[I know, I have been away too long without publishing much in the last 3 months. But, there's a reason for that. I have been building a platform that combines machine learning with blockchain technology. Let me introduce you to fitchain and tell you more in this episode.
If you want to collaborate on the project or just think it's interesting, drop me a line on the contact page at fitchain.io]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>23:14</itunes:duration>
                <itunes:episode>25</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Founder Interview â€“ Francesco Gadaleta of Fitchain</title>
        <itunes:title>Founder Interview â€“ Francesco Gadaleta of Fitchain</itunes:title>
        <link>https://datascienceathome.podbean.com/e/founder-interview-%e2%80%93-francesco-gadaleta-of-fitchain/</link>
                    <comments>https://datascienceathome.podbean.com/e/founder-interview-%e2%80%93-francesco-gadaleta-of-fitchain/#comments</comments>        <pubDate>Thu, 24 May 2018 12:51:27 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/founder-interview-%e2%80%93-francesco-gadaleta-of-fitchain-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[Cross-posting fromÂ <a href='http://cryptoradio.io/francesco-gadaleta-fitchain/'>Cryptoradio.io</a>
Overview
<p>Francesco Gadaleta introduces Fitchain, a decentralized machine learning platform that combines blockchain technology and AI to solve the data manipulation problem in restrictive environments such as healthcare or financial institutions.<a href='http://cryptoradio.io/francesco'>Francesco Gadaleta</a> is the founder of <a href='http://cryptoradio.io/fitchain_io'>Fitchain.io</a> and senior advisor to <a href='http://cryptoradio.io/abe'>Abe AI</a>. Fitchain is a platform that officially started in October 2017, which allows data scientists to write machine learning models on data they cannot see and access due to restrictions imposed in healthcare or financial environments. In the Fitchain platform, there are two actors, the data owner and the data scientist. They both run the Fitchain POD, which orchestrates the relationship between these two sides. The idea behind Fitchain is summarized in the thesis â€œdo not move the data, move the model â€“ bring the model where the data is stored.â€</p>
<p>The Fitchain team has also coined a new term called â€œproof of trainâ€ â€“ a way to guarantee that the model is truly trained at the organization, and that it becomes traceable on the blockchain. To develop the complex technological aspects of the platform, Fitchain has partnered up with <a href='http://cryptoradio.io/trent-mcconaghy-ocean-bigchaindb/'>BigChainDB</a>, the project we have recently featured on Crypto Radio.</p>
Roadmap
<p>Fitchain team is currently validating the assumptions and increasing the security of the platform. In the next few months, they will extend the portfolio of machine learning libraries and are planning to move from a B2B product towards a Fitchain for consumers. </p>
<p>By June 2018 they plan to start the Internet of PODs. They will also design the Fitchain token â€“ FitCoin, which will be a utility token to enable operating on the Fitchain platform.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[Cross-posting fromÂ <a href='http://cryptoradio.io/francesco-gadaleta-fitchain/'>Cryptoradio.io</a>
Overview
<p>Francesco Gadaleta introduces Fitchain, a decentralized machine learning platform that combines blockchain technology and AI to solve the data manipulation problem in restrictive environments such as healthcare or financial institutions.<a href='http://cryptoradio.io/francesco'>Francesco Gadaleta</a> is the founder of <a href='http://cryptoradio.io/fitchain_io'>Fitchain.io</a> and senior advisor to <a href='http://cryptoradio.io/abe'>Abe AI</a>. Fitchain is a platform that officially started in October 2017, which allows data scientists to write machine learning models on data they cannot see and access due to restrictions imposed in healthcare or financial environments. In the Fitchain platform, there are two actors, the data owner and the data scientist. They both run the Fitchain POD, which orchestrates the relationship between these two sides. The idea behind Fitchain is summarized in the thesis â€œdo not move the data, move the model â€“ bring the model where the data is stored.â€</p>
<p>The Fitchain team has also coined a new term called â€œproof of trainâ€ â€“ a way to guarantee that the model is truly trained at the organization, and that it becomes traceable on the blockchain. To develop the complex technological aspects of the platform, Fitchain has partnered up with <a href='http://cryptoradio.io/trent-mcconaghy-ocean-bigchaindb/'>BigChainDB</a>, the project we have recently featured on Crypto Radio.</p>
Roadmap
<p>Fitchain team is currently validating the assumptions and increasing the security of the platform. In the next few months, they will extend the portfolio of machine learning libraries and are planning to move from a B2B product towards a Fitchain for consumers. </p>
<p>By June 2018 they plan to start the Internet of PODs. They will also design the Fitchain token â€“ FitCoin, which will be a utility token to enable operating on the Fitchain platform.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/vezqdy/CR22.mp3" length="30027423" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Cross-posting fromÂ Cryptoradio.io
Overview
Francesco Gadaleta introduces Fitchain, a decentralized machine learning platform that combines blockchain technology and AI to solve the data manipulation problem in restrictive environments such as healthcare or financial institutions.Francesco Gadaleta is the founder of Fitchain.io and senior advisor to Abe AI. Fitchain is a platform that officially started in October 2017, which allows data scientists to write machine learning models on data they cannot see and access due to restrictions imposed in healthcare or financial environments. In the Fitchain platform, there are two actors, the data owner and the data scientist. They both run the Fitchain POD, which orchestrates the relationship between these two sides. The idea behind Fitchain is summarized in the thesis â€œdo not move the data, move the model â€“ bring the model where the data is stored.â€
The Fitchain team has also coined a new term called â€œproof of trainâ€ â€“ a way to guarantee that the model is truly trained at the organization, and that it becomes traceable on the blockchain. To develop the complex technological aspects of the platform, Fitchain has partnered up with BigChainDB, the project we have recently featured on Crypto Radio.
Roadmap
Fitchain team is currently validating the assumptions and increasing the security of the platform. In the next few months, they will extend the portfolio of machine learning libraries and are planning to move from a B2B product towards a Fitchain for consumers. 
By June 2018 they plan to start the Internet of PODs. They will also design the Fitchain token â€“ FitCoin, which will be a utility token to enable operating on the Fitchain platform.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>31:04</itunes:duration>
                <itunes:episode>24</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 31: The End of Privacy</title>
        <itunes:title>Episode 31: The End of Privacy</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-end-of-privacy/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-end-of-privacy/#comments</comments>        <pubDate>Mon, 02 Apr 2018 12:37:58 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/the-end-of-privacy-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p>Data is a complex topic, not only related to machine learning algorithms, but also and especially to privacy and security of individuals, the same individuals who create such data just by using the many mobile apps and services that characterize their digital life.</p>
<p>In this episode I am together with B.J.n Mendelson, author of â€œSocial Media is Bullshitâ€ from St. Martinâ€™s Press and world-renowned speaker on issues involving the myths and realities involving todayâ€™s Internet platforms. Â B.J. has a new a book about privacy and sent me a free copy of "Privacy, and how to get it back" that I read in just one day. That was enough to realise how much we have in common when it comes to data and data collection.</p>
<p>Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Data is a complex topic, not only related to machine learning algorithms, but also and especially to privacy and security of individuals, the same individuals who create such data just by using the many mobile apps and services that characterize their digital life.</p>
<p>In this episode I am together with B.J.n Mendelson, author of <em>â€œSocial Media is Bullshitâ€</em> from St. Martinâ€™s Press and world-renowned speaker on issues involving the myths and realities involving todayâ€™s Internet platforms. Â B.J. has a new a book about privacy and sent me a free copy of <em>"Privacy, and how to get it back"</em> that I read in just one day. That was enough to realise how much we have in common when it comes to data and data collection.</p>
<p>Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ieb6qv/31.mp3" length="75011890" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Data is a complex topic, not only related to machine learning algorithms, but also and especially to privacy and security of individuals, the same individuals who create such data just by using the many mobile apps and services that characterize their digital life.
In this episode I am together with B.J.n Mendelson, author of â€œSocial Media is Bullshitâ€ from St. Martinâ€™s Press and world-renowned speaker on issues involving the myths and realities involving todayâ€™s Internet platforms. Â B.J. has a new a book about privacy and sent me a free copy of "Privacy, and how to get it back" that I read in just one day. That was enough to realise how much we have in common when it comes to data and data collection.
Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>39:03</itunes:duration>
                <itunes:episode>23</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 30: Neural networks and genetic evolution: an unfeasible approach</title>
        <itunes:title>Episode 30: Neural networks and genetic evolution: an unfeasible approach</itunes:title>
        <link>https://datascienceathome.podbean.com/e/neural-networks-and-genetic-evolution-an-unfeasible-approach/</link>
                    <comments>https://datascienceathome.podbean.com/e/neural-networks-and-genetic-evolution-an-unfeasible-approach/#comments</comments>        <pubDate>Tue, 21 Nov 2017 13:15:33 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/neural-networks-and-genetic-evolution-an-unfeasible-approach-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p>Despite what researchers claim about genetic evolution, in this episode we give a realistic view of the field.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Despite what researchers claim about genetic evolution, in this episode we give a realistic view of the field.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/jrkhh2/30.mp3" length="32140351" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Despite what researchers claim about genetic evolution, in this episode we give a realistic view of the field.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:19</itunes:duration>
                <itunes:episode>22</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 29: Fail your AI company in 9 steps</title>
        <itunes:title>Episode 29: Fail your AI company in 9 steps</itunes:title>
        <link>https://datascienceathome.podbean.com/e/fail-your-ai-company-in-9-steps/</link>
                    <comments>https://datascienceathome.podbean.com/e/fail-your-ai-company-in-9-steps/#comments</comments>        <pubDate>Sat, 11 Nov 2017 18:44:18 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/fail-your-ai-company-in-9-steps-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">In order to succeed with artificial intelligence, it is better to know how to fail first. It is easier than you think.
Here are 9 easy steps to fail your AI startup.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In order to succeed with artificial intelligence, it is better to know how to fail first. It is easier than you think.<br>
Here are 9 easy steps to fail your AI startup.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/wska29/029.mp3" length="20834137" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In order to succeed with artificial intelligence, it is better to know how to fail first. It is easier than you think.Here are 9 easy steps to fail your AI startup.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:27</itunes:duration>
                <itunes:episode>21</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 28: Towards Artificial General Intelligence: preliminary talk </title>
        <itunes:title>Episode 28: Towards Artificial General Intelligence: preliminary talk </itunes:title>
        <link>https://datascienceathome.podbean.com/e/towards-artificial-general-intelligence-preliminary-talk/</link>
                    <comments>https://datascienceathome.podbean.com/e/towards-artificial-general-intelligence-preliminary-talk/#comments</comments>        <pubDate>Sat, 04 Nov 2017 18:04:25 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/towards-artificial-general-intelligence-preliminary-talk-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">The enthusiasm for artificial intelligence is raising some concerns especially with respect to some ventured conclusions about what AI can really do and what its direct descendent, artificial general intelligence would be capable of doing in the immediate future. From stealing jobs, to exterminating the entire human race, the creativity (of some) seems to have no limits.Â 
In this episode I make sure that everyone comes back to reality - which might sound less exciting than Hollywood but definitely more... real.Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">The enthusiasm for artificial intelligence is raising some concerns especially with respect to some ventured conclusions about what AI can really do and what its direct descendent, artificial general intelligence would be capable of doing in the immediate future. From stealing jobs, to exterminating the entire human race, the creativity (of some) seems to have no limits.Â <br>
In this episode I make sure that everyone comes back to reality - which might sound less exciting than Hollywood but definitely more... real.Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ibzsw8/028.mp3" length="29643881" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The enthusiasm for artificial intelligence is raising some concerns especially with respect to some ventured conclusions about what AI can really do and what its direct descendent, artificial general intelligence would be capable of doing in the immediate future. From stealing jobs, to exterminating the entire human race, the creativity (of some) seems to have no limits.Â In this episode I make sure that everyone comes back to reality - which might sound less exciting than Hollywood but definitely more... real.Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:34</itunes:duration>
                <itunes:episode>20</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 27: Techstars accelerator and the culture of fireflies</title>
        <itunes:title>Episode 27: Techstars accelerator and the culture of fireflies</itunes:title>
        <link>https://datascienceathome.podbean.com/e/techstars-accelerator-and-the-culture-of-fireflies/</link>
                    <comments>https://datascienceathome.podbean.com/e/techstars-accelerator-and-the-culture-of-fireflies/#comments</comments>        <pubDate>Mon, 30 Oct 2017 10:00:00 +0100</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/techstars-accelerator-and-the-culture-of-fireflies-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p class="graf graf--p" style="text-align:left;">In the aftermath of the <a href='http://www.techstars.com/programs/barclays-cape-town-program/'>Barclays Accelerator, powered by Techstars</a> experience, one of the most innovative and influential startup accelerators in the world, Iâ€™d like to give back to the community lessons learned, including the need for confidence, soft-skills, and efficiency, to be applied to startups that deal with artificial intelligence and data science.
In this episode I also share some thoughts about the culture of fireflies in modern and dynamic organisations.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p class="graf graf--p" style="text-align:left;">In the aftermath of the <a href='http://www.techstars.com/programs/barclays-cape-town-program/'>Barclays Accelerator, powered by Techstars</a> experience, one of the most innovative and influential startup accelerators in the world, Iâ€™d like to give back to the community lessons learned, including the need for confidence, soft-skills, and efficiency, to be applied to startups that deal with artificial intelligence and data science.<br>
In this episode I also share some thoughts about the <em>culture of fireflies</em> in modern and dynamic organisations.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/9y6sxs/027.mp3" length="25506712" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the aftermath of the Barclays Accelerator, powered by Techstars experience, one of the most innovative and influential startup accelerators in the world, Iâ€™d like to give back to the community lessons learned, including the need for confidence, soft-skills, and efficiency, to be applied to startups that deal with artificial intelligence and data science.In this episode I also share some thoughts about the culture of fireflies in modern and dynamic organisations.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:42</itunes:duration>
                <itunes:episode>19</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 26: Deep Learning and Alzheimer</title>
        <itunes:title>Episode 26: Deep Learning and Alzheimer</itunes:title>
        <link>https://datascienceathome.podbean.com/e/deep-learning-and-alzheimer/</link>
                    <comments>https://datascienceathome.podbean.com/e/deep-learning-and-alzheimer/#comments</comments>        <pubDate>Mon, 23 Oct 2017 12:35:58 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/deep-learning-and-alzheimer-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p>In this episode I speak about Deep Learning technology applied to Alzheimer disorder prediction. IÂ had a great chat withÂ Saman Sarraf, machine learning engineer at Konica Minolta, former lab manager at the Rotman Research Institute at Baycrest, University of Toronto and author ofÂ <a class="gsc_a_at">DeepAD: Alzheimerâ€² s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI.</a></p>
<p>I hope you enjoy the show.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I speak about Deep Learning technology applied to Alzheimer disorder prediction. IÂ had a great chat withÂ Saman Sarraf, machine learning engineer at Konica Minolta, former lab manager at the Rotman Research Institute at Baycrest, University of Toronto and author ofÂ <em><a class="gsc_a_at">DeepAD: Alzheimerâ€² s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI.</a></em></p>
<p>I hope you enjoy the show.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/a65y66/026-cut.mp3" length="77836038" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I speak about Deep Learning technology applied to Alzheimer disorder prediction. IÂ had a great chat withÂ Saman Sarraf, machine learning engineer at Konica Minolta, former lab manager at the Rotman Research Institute at Baycrest, University of Toronto and author ofÂ DeepAD: Alzheimerâ€² s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI.
I hope you enjoy the show.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>54:02</itunes:duration>
                <itunes:episode>18</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 25: How to become data scientist [RB]</title>
        <itunes:title>Episode 25: How to become data scientist [RB]</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-to-become-data-scientist/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-to-become-data-scientist/#comments</comments>        <pubDate>Mon, 16 Oct 2017 14:45:16 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/how-to-become-data-scientist-rb-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p>In this episode,Â I speak about the requirements and the skills to become data scientist and join an amazing community that is changing the world with data analyticsa</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode,Â I speak about the requirements and the skills to become data scientist and join an amazing community that is changing the world with data analyticsa</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/atsdtj/025_rb.mp3" length="23437814" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode,Â I speak about the requirements and the skills to become data scientist and join an amazing community that is changing the world with data analyticsa]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:16</itunes:duration>
                <itunes:episode>17</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 24: How to handle imbalanced datasets</title>
        <itunes:title>Episode 24: How to handle imbalanced datasets</itunes:title>
        <link>https://datascienceathome.podbean.com/e/imbalanced-datasets/</link>
                    <comments>https://datascienceathome.podbean.com/e/imbalanced-datasets/#comments</comments>        <pubDate>Mon, 09 Oct 2017 02:45:59 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/imbalanced-datasets-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">In machine learning and data science in general it is very common to deal at some point with imbalanced datasets and class distributions. This is the typical case where the number of observations that belong to one class is significantly lower than those belonging to the other classes. Â Actually this happens all the time, in several domains, from finance, to healthcare to social media, just to name a few I have personally worked with. 
Think about a bank detecting fraudulent transactions among millions or billions of daily operations, or equivalently in healthcare for the identification of rare disorders. 
In genetics but also with clinical lab tests this is a normal scenario, in which, fortunately there are very few patients affected by a disorder and therefore very few cases wrt the large pool of healthy patients (or not affected). 
There is no algorithm that can take into account the class distribution or the amount of observations in each class, if it is not explicitly designed to handle such situations.
 In this episode I speak about some effective techniques to handle imbalanced datasets, advising the right method, or the most appropriate one to the right dataset or problem.</p>
<p style="text-align:left;">In this episode I explain how to deal with such common and challenging scenarios.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In machine learning and data science in general it is very common to deal at some point with imbalanced datasets and class distributions. This is the typical case where the number of observations that belong to one class is significantly lower than those belonging to the other classes. Â Actually this happens all the time, in several domains, from finance, to healthcare to social media, just to name a few I have personally worked with. <br>
Think about a bank detecting fraudulent transactions among millions or billions of daily operations, or equivalently in healthcare for the identification of rare disorders. <br>
In genetics but also with clinical lab tests this is a normal scenario, in which, fortunately there are very few patients affected by a disorder and therefore very few cases wrt the large pool of healthy patients (or not affected). <br>
There is no algorithm that can take into account the class distribution or the amount of observations in each class, if it is not explicitly designed to handle such situations.<br>
 In this episode I speak about some effective techniques to handle imbalanced datasets, advising the right method, or the most appropriate one to the right dataset or problem.</p>
<p style="text-align:left;">In this episode I explain how to deal with such common and challenging scenarios.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/dw7w5m/024.mp3" length="30749801" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In machine learning and data science in general it is very common to deal at some point with imbalanced datasets and class distributions. This is the typical case where the number of observations that belong to one class is significantly lower than those belonging to the other classes. Â Actually this happens all the time, in several domains, from finance, to healthcare to social media, just to name a few I have personally worked with. Think about a bank detecting fraudulent transactions among millions or billions of daily operations, or equivalently in healthcare for the identification of rare disorders. In genetics but also with clinical lab tests this is a normal scenario, in which, fortunately there are very few patients affected by a disorder and therefore very few cases wrt the large pool of healthy patients (or not affected). There is no algorithm that can take into account the class distribution or the amount of observations in each class, if it is not explicitly designed to handle such situations. In this episode I speak about some effective techniques to handle imbalanced datasets, advising the right method, or the most appropriate one to the right dataset or problem.
In this episode I explain how to deal with such common and challenging scenarios.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:21</itunes:duration>
                <itunes:episode>16</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 23: Why do ensemble methods work?</title>
        <itunes:title>Episode 23: Why do ensemble methods work?</itunes:title>
        <link>https://datascienceathome.podbean.com/e/why-do-ensemble-methods-work/</link>
                    <comments>https://datascienceathome.podbean.com/e/why-do-ensemble-methods-work/#comments</comments>        <pubDate>Tue, 03 Oct 2017 13:05:00 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/why-do-ensemble-methods-work-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">Ensemble methods have been designed to improve the performance of the single model, when the single model is not very accurate. According to the general definition of ensembling, it consists in building a number of single classifiers and then combining or aggregating their predictions into one classifier that is usually stronger than the single one.</p>
<p style="text-align:left;">The key idea behind ensembling is that some models will do well when they model certain aspects of the data while others will do well in modelling other aspects. 
In this episode I show with a numeric example why and when ensemble methods work.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Ensemble methods have been designed to improve the performance of the single model, when the single model is not very accurate. According to the general definition of ensembling, it consists in building a number of single classifiers and then combining or aggregating their predictions into one classifier that is usually stronger than the single one.</p>
<p style="text-align:left;">The key idea behind ensembling is that some models will do well when they model certain aspects of the data while others will do well in modelling other aspects. <br>
In this episode I show with a numeric example why and when ensemble methods work.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6m9ghr/023.mp3" length="27361197" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Ensemble methods have been designed to improve the performance of the single model, when the single model is not very accurate. According to the general definition of ensembling, it consists in building a number of single classifiers and then combining or aggregating their predictions into one classifier that is usually stronger than the single one.
The key idea behind ensembling is that some models will do well when they model certain aspects of the data while others will do well in modelling other aspects. In this episode I show with a numeric example why and when ensemble methods work.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>18:59</itunes:duration>
                <itunes:episode>15</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 22: Parallelising and distributing Deep Learning</title>
        <itunes:title>Episode 22: Parallelising and distributing Deep Learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/parallelizing-and-distributing-stochastic-gradient-descent/</link>
                    <comments>https://datascienceathome.podbean.com/e/parallelizing-and-distributing-stochastic-gradient-descent/#comments</comments>        <pubDate>Mon, 25 Sep 2017 17:38:36 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/parallelizing-and-distributing-stochastic-gradient-descent-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">Continuing the discussion of the last two episodes, there is one more aspect of deep learning that I would love to consider and therefore left as a full episode, that is parallelising and distributing deep learning on relatively large clusters.</p>
<p style="text-align:left;">As a matter of fact, computing architectures are changing in a way that is encouraging parallelism more than ever before. And deep learning is no exception and despite the greatest improvements with commodity GPUs - graphical processing units, when it comes to speed, there is still room for improvement.</p>
<p style="text-align:left;">Together with the last two episodes, this one completes the picture of deep learning at scale. Indeed, as I mentioned in the previous episode, How to master optimisation in deep learning, the function optimizer is the horsepower of deep learning and neural networks in general. A slow and inaccurate optimisation method leads to networks that slowly converge to unreliable results.</p>
<p style="text-align:left;">In another episode titled â€œAdditional strategies for optimizing deeplearningâ€ I explained some ways to improve function minimisation and model tuning in order to get better parameters in less time. So feel free to listen to these episodes again, share them with your friends, even re-broadcast or download for your commute. </p>
<p style="text-align:left;">While the methods that I have explained so far represent a good starting point for prototyping a network, when you need to switch to production environments or take advantage of the most recent and advanced hardware capabilities of your GPU, well... in all those cases, you would like to do something more. Â </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Continuing the discussion of the last two episodes, there is one more aspect of deep learning that I would love to consider and therefore left as a full episode, that is parallelising and distributing deep learning on relatively large clusters.</p>
<p style="text-align:left;">As a matter of fact, computing architectures are changing in a way that is encouraging parallelism more than ever before. And deep learning is no exception and despite the greatest improvements with commodity GPUs - graphical processing units, when it comes to speed, there is still room for improvement.</p>
<p style="text-align:left;">Together with the last two episodes, this one completes the picture of deep learning at scale. Indeed, as I mentioned in the previous episode, <em>How to master optimisation in deep learning</em>, the function optimizer is the horsepower of deep learning and neural networks in general. A slow and inaccurate optimisation method leads to networks that slowly converge to unreliable results.</p>
<p style="text-align:left;">In another episode titled â€œ<em>Additional strategies for optimizing deeplearning</em>â€ I explained some ways to improve function minimisation and model tuning in order to get better parameters in less time. So feel free to listen to these episodes again, share them with your friends, even re-broadcast or download for your commute. </p>
<p style="text-align:left;">While the methods that I have explained so far represent a good starting point for prototyping a network, when you need to switch to production environments or take advantage of the most recent and advanced hardware capabilities of your GPU, well... in all those cases, you would like to do something more. Â </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4yi2q7/022.mp3" length="28395646" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Continuing the discussion of the last two episodes, there is one more aspect of deep learning that I would love to consider and therefore left as a full episode, that is parallelising and distributing deep learning on relatively large clusters.
As a matter of fact, computing architectures are changing in a way that is encouraging parallelism more than ever before. And deep learning is no exception and despite the greatest improvements with commodity GPUs - graphical processing units, when it comes to speed, there is still room for improvement.
Together with the last two episodes, this one completes the picture of deep learning at scale. Indeed, as I mentioned in the previous episode, How to master optimisation in deep learning, the function optimizer is the horsepower of deep learning and neural networks in general. A slow and inaccurate optimisation method leads to networks that slowly converge to unreliable results.
In another episode titled â€œAdditional strategies for optimizing deeplearningâ€ I explained some ways to improve function minimisation and model tuning in order to get better parameters in less time. So feel free to listen to these episodes again, share them with your friends, even re-broadcast or download for your commute. 
While the methods that I have explained so far represent a good starting point for prototyping a network, when you need to switch to production environments or take advantage of the most recent and advanced hardware capabilities of your GPU, well... in all those cases, you would like to do something more. Â ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:42</itunes:duration>
                <itunes:episode>14</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 21: Additional optimisation strategies for deep learning</title>
        <itunes:title>Episode 21: Additional optimisation strategies for deep learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/additional-optimisation-strategies-for-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/additional-optimisation-strategies-for-deep-learning/#comments</comments>        <pubDate>Mon, 18 Sep 2017 14:23:16 +0200</pubDate>
        <guid isPermaLink="false">datascienceathome.podbean.com/additional-optimisation-strategies-for-deep-learning-24b00f90dd1700f333f1ee8f1a4eedd1</guid>
                                    <description><![CDATA[<p style="text-align:left;">In the last episode How to master optimisation in deep learningÂ I explained some of the most challenging tasks of deep learning and some methodologies and algorithms to improve the speed of convergence of a minimisation method for deep learning. 
I explored the family of gradient descent methods - even though not exhaustively - giving a list of approaches that deep learning researchers are considering for different scenarios. Every method has its own benefits and drawbacks, pretty much depending on the type of data, and data sparsity. But there is one method that seems to be, at least empirically, the best approach so far. </p>
<p style="text-align:left;">Feel free to <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>listen</a> to the previous episode, <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>share</a> it, re-broadcast or just <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>download</a> for your commute.</p>
<p style="text-align:left;">In this episode I would like to continue that conversation about some additional strategies for optimising gradient descent in deep learning and introduce you to some tricks that might come useful when your neural network stops learning from data or when the learning process becomes so slow that it really seems it reached a plateau even by feeding in fresh data. </p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">In the last episode <em>How to master optimisation in deep learning</em>Â I explained some of the most challenging tasks of deep learning and some methodologies and algorithms to improve the speed of convergence of a minimisation method for deep learning. <br>
I explored the family of gradient descent methods - even though not exhaustively - giving a list of approaches that deep learning researchers are considering for different scenarios. Every method has its own benefits and drawbacks, pretty much depending on the type of data, and data sparsity. But there is one method that seems to be, at least empirically, the best approach so far. </p>
<p style="text-align:left;">Feel free to <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>listen</a> to the previous episode, <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>share</a> it, re-broadcast or just <a href='https://www.podbean.com/media/share/pb-y75qj-700faa'>download</a> for your commute.</p>
<p style="text-align:left;">In this episode I would like to continue that conversation about some additional strategies for optimising gradient descent in deep learning and introduce you to some tricks that might come useful when your neural network stops learning from data or when the learning process becomes so slow that it really seems it reached a plateau even by feeding in fresh data. </p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/6imk2u/021.mp3" length="21797115" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In the last episode How to master optimisation in deep learningÂ I explained some of the most challenging tasks of deep learning and some methodologies and algorithms to improve the speed of convergence of a minimisation method for deep learning. I explored the family of gradient descent methods - even though not exhaustively - giving a list of approaches that deep learning researchers are considering for different scenarios. Every method has its own benefits and drawbacks, pretty much depending on the type of data, and data sparsity. But there is one method that seems to be, at least empirically, the best approach so far. 
Feel free to listen to the previous episode, share it, re-broadcast or just download for your commute.
In this episode I would like to continue that conversation about some additional strategies for optimising gradient descent in deep learning and introduce you to some tricks that might come useful when your neural network stops learning from data or when the learning process becomes so slow that it really seems it reached a plateau even by feeding in fresh data. ]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:08</itunes:duration>
                <itunes:episode>13</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 20: How to master optimisation in deep learning</title>
        <itunes:title>Episode 20: How to master optimisation in deep learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/optimisation-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/optimisation-deep-learning/#comments</comments>        <pubDate>Mon, 28 Aug 2017 17:06:32 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/optimisation-deep-learning/</guid>
                                    <description><![CDATA[<p style="text-align:left;">The secret behind deep learning is not really a secret. It is function optimisation. What a neural network essentially does, is optimising a function. In this episode I illustrate a number of optimisation methods and explain which one is the best and why.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">The secret behind deep learning is not really a secret. It is function optimisation. What a neural network essentially does, is optimising a function. In this episode I illustrate a number of optimisation methods and explain which one is the best and why.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ct98iu/episode_20.mp3" length="28059422" type="audio/mpeg"/>
        <itunes:summary><![CDATA[The secret behind deep learning is not really a secret. It is function optimisation. What a neural network essentially does, is optimising a function. In this episode I illustrate a number of optimisation methods and explain which one is the best and why.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:29</itunes:duration>
                <itunes:episode>12</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 19: How to completely change your data analytics strategy with deep learning</title>
        <itunes:title>Episode 19: How to completely change your data analytics strategy with deep learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-to-completely-change-your-data-analytics-strategy-with-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-to-completely-change-your-data-analytics-strategy-with-deep-learning/#comments</comments>        <pubDate>Wed, 09 Aug 2017 17:39:25 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/how-to-completely-change-your-data-analytics-strategy-with-deep-learning/</guid>
                                    <description><![CDATA[<p style="text-align:left;">Over the past few years, neural networks have re-emerged as powerful machine-learning models, reaching state-of-the-art results in several fields like image recognition and speech processing. More recently, neural network models started to be applied also to textual data in order to deal with natural language, and there too with promising results. In this episode I explain why is deep learning performing the way it does, and what are some of the most tedious causes of failure.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Over the past few years, neural networks have re-emerged as powerful machine-learning models, reaching state-of-the-art results in several fields like image recognition and speech processing. More recently, neural network models started to be applied also to textual data in order to deal with natural language, and there too with promising results. In this episode I explain why is deep learning performing the way it does, and what are some of the most tedious causes of failure.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2mdynt/episode_19.mp3" length="22957396" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Over the past few years, neural networks have re-emerged as powerful machine-learning models, reaching state-of-the-art results in several fields like image recognition and speech processing. More recently, neural network models started to be applied also to textual data in order to deal with natural language, and there too with promising results. In this episode I explain why is deep learning performing the way it does, and what are some of the most tedious causes of failure.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:56</itunes:duration>
                <itunes:episode>11</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 18: Machines that learn like humans</title>
        <itunes:title>Episode 18: Machines that learn like humans</itunes:title>
        <link>https://datascienceathome.podbean.com/e/machines-that-learn-like-humans/</link>
                    <comments>https://datascienceathome.podbean.com/e/machines-that-learn-like-humans/#comments</comments>        <pubDate>Tue, 28 Mar 2017 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/machines-that-learn-like-humans/</guid>
                                    <description><![CDATA[<p style="text-align:left;">Artificial Intelligence allow machines to learn patterns from data. The way humans learn however is different and more efficient. With Lifelong Machine Learning, machines can learn the way human beings do, faster, and more efficiently</p>
]]></description>
                                                            <content:encoded><![CDATA[<p style="text-align:left;">Artificial Intelligence allow machines to learn patterns from data. The way humans learn however is different and more efficient. With Lifelong Machine Learning, machines can learn the way human beings do, faster, and more efficiently</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4esjdv/datascience_episode_18_lifelong_machine_learning.mp3" length="40422197" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Artificial Intelligence allow machines to learn patterns from data. The way humans learn however is different and more efficient. With Lifelong Machine Learning, machines can learn the way human beings do, faster, and more efficiently]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>42:06</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 17: Protecting privacy and confidentiality in data and communications</title>
        <itunes:title>Episode 17: Protecting privacy and confidentiality in data and communications</itunes:title>
        <link>https://datascienceathome.podbean.com/e/protecting-privacy-and-confidentiality-in-data-and-communications/</link>
                    <comments>https://datascienceathome.podbean.com/e/protecting-privacy-and-confidentiality-in-data-and-communications/#comments</comments>        <pubDate>Wed, 15 Feb 2017 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/protecting-privacy-and-confidentiality-in-data-and-communications/</guid>
                                    <description><![CDATA[<p>Talking about security of communication and privacy is never enough, especially when political instabilities are driving leaders towards decisions that will affect people on a global scale</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Talking about security of communication and privacy is never enough, especially when political instabilities are driving leaders towards decisions that will affect people on a global scale</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cykjkg/datascience_episode_privacy.mp3" length="16829405" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Talking about security of communication and privacy is never enough, especially when political instabilities are driving leaders towards decisions that will affect people on a global scale]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:31</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 16: 2017 Predictions in Data Science</title>
        <itunes:title>Episode 16: 2017 Predictions in Data Science</itunes:title>
        <link>https://datascienceathome.podbean.com/e/2017-predictions-in-data-science/</link>
                    <comments>https://datascienceathome.podbean.com/e/2017-predictions-in-data-science/#comments</comments>        <pubDate>Fri, 23 Dec 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/2017-predictions-in-data-science/</guid>
                                    <description><![CDATA[<p>We strongly believe 2017 will be a very interesting year for data science and artificial intelligence. Let me tell you what I expect and why.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>We strongly believe 2017 will be a very interesting year for data science and artificial intelligence. Let me tell you what I expect and why.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/ryk87x/datascience_episode_predictions_2017.mp3" length="19703169" type="audio/mpeg"/>
        <itunes:summary><![CDATA[We strongly believe 2017 will be a very interesting year for data science and artificial intelligence. Let me tell you what I expect and why.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>20:31</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 15: Statistical analysis of phenomena that smell like chaos</title>
        <itunes:title>Episode 15: Statistical analysis of phenomena that smell like chaos</itunes:title>
        <link>https://datascienceathome.podbean.com/e/statistical-analysis-of-phenomena-that-smell-like-chaos/</link>
                    <comments>https://datascienceathome.podbean.com/e/statistical-analysis-of-phenomena-that-smell-like-chaos/#comments</comments>        <pubDate>Mon, 05 Dec 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/statistical-analysis-of-phenomena-that-smell-like-chaos/</guid>
                                    <description><![CDATA[<p>Is the market really predictable? How do stock prices increase? What is their dynamics? Here is what I think about the magics and the reality of predictions applied to markets and the stock exchange.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Is the market really predictable? How do stock prices increase? What is their dynamics? Here is what I think about the magics and the reality of predictions applied to markets and the stock exchange.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/m6ihcd/datascience_episode_finance_chaos.mp3" length="9833480" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Is the market really predictable? How do stock prices increase? What is their dynamics? Here is what I think about the magics and the reality of predictions applied to markets and the stock exchange.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>10:14</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 14: The minimum required by a data scientist</title>
        <itunes:title>Episode 14: The minimum required by a data scientist</itunes:title>
        <link>https://datascienceathome.podbean.com/e/the-minimum-required-by-a-data-scientist/</link>
                    <comments>https://datascienceathome.podbean.com/e/the-minimum-required-by-a-data-scientist/#comments</comments>        <pubDate>Tue, 27 Sep 2016 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/the-minimum-required-by-a-data-scientist/</guid>
                                    <description><![CDATA[<p>Why the job of the data scientist can disappear soon. What is required by a data scientist to survive inflation.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Why the job of the data scientist can disappear soon. What is required by a data scientist to survive inflation.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/g5e7cz/datascience_episode_17_minimum_required.mp3" length="16107566" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Why the job of the data scientist can disappear soon. What is required by a data scientist to survive inflation.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:46</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 13: Data Science and Fraud Detection at iZettle</title>
        <itunes:title>Episode 13: Data Science and Fraud Detection at iZettle</itunes:title>
        <link>https://datascienceathome.podbean.com/e/data-science-and-fraud-detection-at-izettle/</link>
                    <comments>https://datascienceathome.podbean.com/e/data-science-and-fraud-detection-at-izettle/#comments</comments>        <pubDate>Tue, 06 Sep 2016 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/data-science-and-fraud-detection-at-izettle/</guid>
                                    <description><![CDATA[<p>Data science is making the difference also in fraud detection. In this episode I have a conversation with an expert in the field, Engineer Eyad Sibai, who works at iZettle, a fraud detection company</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Data science is making the difference also in fraud detection. In this episode I have a conversation with an expert in the field, Engineer Eyad Sibai, who works at iZettle, a fraud detection company</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/2dw76g/datascience_episode_fraud_detection.mp3" length="15873926" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Data science is making the difference also in fraud detection. In this episode I have a conversation with an expert in the field, Engineer Eyad Sibai, who works at iZettle, a fraud detection company]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:32</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/16.png" />    </item>
    <item>
        <title>Episode 12: EU Regulations and the rise of Data Hijackers</title>
        <itunes:title>Episode 12: EU Regulations and the rise of Data Hijackers</itunes:title>
        <link>https://datascienceathome.podbean.com/e/eu-regulations-and-the-rise-of-data-hijackers/</link>
                    <comments>https://datascienceathome.podbean.com/e/eu-regulations-and-the-rise-of-data-hijackers/#comments</comments>        <pubDate>Tue, 26 Jul 2016 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/eu-regulations-and-the-rise-of-data-hijackers/</guid>
                                    <description><![CDATA[<p>Extracting knowledge from large datasets with large number of variables is always tricky. Dimensionality reduction helps in analyzing high dimensional data, still maintaining most of the information hidden behind complexity. Here are some methods that you must try before further analysis (Part 1).</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Extracting knowledge from large datasets with large number of variables is always tricky. Dimensionality reduction helps in analyzing high dimensional data, still maintaining most of the information hidden behind complexity. Here are some methods that you must try before further analysis (Part 1).</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/78n6ih/datascience_episode_15_GDPR.mp3" length="15634728" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Extracting knowledge from large datasets with large number of variables is always tricky. Dimensionality reduction helps in analyzing high dimensional data, still maintaining most of the information hidden behind complexity. Here are some methods that you must try before further analysis (Part 1).]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:17</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 11: Representative Subsets For Big Data Learning</title>
        <itunes:title>Episode 11: Representative Subsets For Big Data Learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/representative-subsets-for-big-data-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/representative-subsets-for-big-data-learning/#comments</comments>        <pubDate>Tue, 03 May 2016 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/representative-subsets-for-big-data-learning/</guid>
                                    <description><![CDATA[<p>How would you perform accurate classification on a very large dataset by just looking at a sample of it</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>How would you perform accurate classification on a very large dataset by just looking at a sample of it</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/xhjg4s/datascience_episode_roccolangone.mp3" length="20568736" type="audio/mpeg"/>
        <itunes:summary><![CDATA[How would you perform accurate classification on a very large dataset by just looking at a sample of it]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>21:25</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 10: History and applications of Deep Learning</title>
        <itunes:title>Episode 10: History and applications of Deep Learning</itunes:title>
        <link>https://datascienceathome.podbean.com/e/history-and-applications-of-deep-learning/</link>
                    <comments>https://datascienceathome.podbean.com/e/history-and-applications-of-deep-learning/#comments</comments>        <pubDate>Mon, 14 Mar 2016 12:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/history-and-applications-of-deep-learning/</guid>
                                    <description><![CDATA[<p>What is deep learning?If you have no patience, deep learning is the result of training many layers of non-linear processing units for feature extraction and data transformation e.g. from pixel, to edges, to shapes, to object classification, to scene description, captioning, etc.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>What is deep learning?If you have no patience, deep learning is the result of training many layers of non-linear processing units for feature extraction and data transformation e.g. from pixel, to edges, to shapes, to object classification, to scene description, captioning, etc.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/cjuufd/datascience_episode_deeplearning.mp3" length="21752058" type="audio/mpeg"/>
        <itunes:summary><![CDATA[What is deep learning?If you have no patience, deep learning is the result of training many layers of non-linear processing units for feature extraction and data transformation e.g. from pixel, to edges, to shapes, to object classification, to scene description, captioning, etc.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:39</itunes:duration>
                <itunes:episode>10</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 9: Markov Chain Montecarlo with full conditionals</title>
        <itunes:title>Episode 9: Markov Chain Montecarlo with full conditionals</itunes:title>
        <link>https://datascienceathome.podbean.com/e/markov-chain-montecarlo-with-full-conditionals/</link>
                    <comments>https://datascienceathome.podbean.com/e/markov-chain-montecarlo-with-full-conditionals/#comments</comments>        <pubDate>Wed, 02 Mar 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/markov-chain-montecarlo-with-full-conditionals/</guid>
                                    <description><![CDATA[<p>At some point, statistical problems need sampling. Sampling consists in generating observations from a specific distribution.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>At some point, statistical problems need sampling. Sampling consists in generating observations from a specific distribution.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/zx97x5/datascience_episode_mcmc.mp3" length="17244835" type="audio/mpeg"/>
        <itunes:summary><![CDATA[At some point, statistical problems need sampling. Sampling consists in generating observations from a specific distribution.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>17:57</itunes:duration>
                <itunes:episode>9</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 8: Frequentists and Bayesians</title>
        <itunes:title>Episode 8: Frequentists and Bayesians</itunes:title>
        <link>https://datascienceathome.podbean.com/e/frequentists-and-bayesians/</link>
                    <comments>https://datascienceathome.podbean.com/e/frequentists-and-bayesians/#comments</comments>        <pubDate>Mon, 15 Feb 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/frequentists-and-bayesians/</guid>
                                    <description><![CDATA[<p>There are statisticians and data scientists... Among statisticians, there are some who just count. Some others whoâ€¦ think differently. In this show we explore the old time dilemma between frequentists and bayesians.Given a statistical problem, whoâ€™s going to be right?</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>There are statisticians and data scientists... Among statisticians, there are some who just count. Some others whoâ€¦ think differently. In this show we explore the old time dilemma between frequentists and bayesians.Given a statistical problem, whoâ€™s going to be right?</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/d9k4va/datascience_episode_frequentist_bayesians.mp3" length="6599865" type="audio/mpeg"/>
        <itunes:summary><![CDATA[There are statisticians and data scientists... Among statisticians, there are some who just count. Some others whoâ€¦ think differently. In this show we explore the old time dilemma between frequentists and bayesians.Given a statistical problem, whoâ€™s going to be right?]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>06:52</itunes:duration>
                <itunes:episode>7</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 7: 30 min with data scientist Sebastian Raschka</title>
        <itunes:title>Episode 7: 30 min with data scientist Sebastian Raschka</itunes:title>
        <link>https://datascienceathome.podbean.com/e/30-min-with-data-scientist-sebastian-raschka/</link>
                    <comments>https://datascienceathome.podbean.com/e/30-min-with-data-scientist-sebastian-raschka/#comments</comments>        <pubDate>Mon, 15 Feb 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/30-min-with-data-scientist-sebastian-raschka/</guid>
                                    <description><![CDATA[<p>In this show I interview Sebastian Raschka, data scientist and author of Python Machine Learning.In addition to the fun we had offline, there are great elements about machine learning, data science, current and future trends, to keep an ear on. Moreover, it is the conversation of two data scientists who contribute and operate in the field, on a daily basis.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this show I interview Sebastian Raschka, data scientist and author of Python Machine Learning.In addition to the fun we had offline, there are great elements about machine learning, data science, current and future trends, to keep an ear on. Moreover, it is the conversation of two data scientists who contribute and operate in the field, on a daily basis.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/m7d2cd/datascience_episode_raschka.mp3" length="33009036" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this show I interview Sebastian Raschka, data scientist and author of Python Machine Learning.In addition to the fun we had offline, there are great elements about machine learning, data science, current and future trends, to keep an ear on. Moreover, it is the conversation of two data scientists who contribute and operate in the field, on a daily basis.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>34:23</itunes:duration>
                <itunes:episode>8</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 6: How to be data scientist</title>
        <itunes:title>Episode 6: How to be data scientist</itunes:title>
        <link>https://datascienceathome.podbean.com/e/how-to-be-data-scientist/</link>
                    <comments>https://datascienceathome.podbean.com/e/how-to-be-data-scientist/#comments</comments>        <pubDate>Tue, 19 Jan 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/how-to-be-data-scientist/</guid>
                                    <description><![CDATA[<p>In this episode, we tell you how to become data scientist and join an amazing community that is changing the world with data analytics.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode, we tell you how to become data scientist and join an amazing community that is changing the world with data analytics.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/e3fnmk/datascience_episode3.mp3" length="14587456" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode, we tell you how to become data scientist and join an amazing community that is changing the world with data analytics.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>15:11</itunes:duration>
                <itunes:episode>6</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 5: Development and Testing Practices in Data Science</title>
        <itunes:title>Episode 5: Development and Testing Practices in Data Science</itunes:title>
        <link>https://datascienceathome.podbean.com/e/development-and-testing-practices-in-data-science/</link>
                    <comments>https://datascienceathome.podbean.com/e/development-and-testing-practices-in-data-science/#comments</comments>        <pubDate>Wed, 13 Jan 2016 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/development-and-testing-practices-in-data-science/</guid>
                                    <description><![CDATA[<p>Should data scientists follow the old good practices of software engineering? Data scientists make software after all.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Should data scientists follow the old good practices of software engineering? Data scientists make software after all.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/shdcs7/datascience_episode2.mp3" length="7329651" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Should data scientists follow the old good practices of software engineering? Data scientists make software after all.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>07:38</itunes:duration>
                <itunes:episode>5</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 1: Predictions in Data Science for 2016</title>
        <itunes:title>Episode 1: Predictions in Data Science for 2016</itunes:title>
        <link>https://datascienceathome.podbean.com/e/predictions-in-data-science-for-2016/</link>
                    <comments>https://datascienceathome.podbean.com/e/predictions-in-data-science-for-2016/#comments</comments>        <pubDate>Mon, 21 Dec 2015 13:00:00 +0100</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/predictions-in-data-science-for-2016/</guid>
                                    <description><![CDATA[<p>Itâ€™s time to experiment with Data Science at home. Since we are still dealing with our hosting service, consider the first episode purely experimental, even though the content might be of your interest, no matter what.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Itâ€™s time to experiment with Data Science at home. Since we are still dealing with our hosting service, consider the first episode purely experimental, even though the content might be of your interest, no matter what.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/di37ty/datascience_predictions_2016.mp3" length="14043029" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Itâ€™s time to experiment with Data Science at home. Since we are still dealing with our hosting service, consider the first episode purely experimental, even though the content might be of your interest, no matter what.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>19:30</itunes:duration>
                <itunes:episode>4</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 4: BigData on your desk</title>
        <itunes:title>Episode 4: BigData on your desk</itunes:title>
        <link>https://datascienceathome.podbean.com/e/bigdata-on-your-desk/</link>
                    <comments>https://datascienceathome.podbean.com/e/bigdata-on-your-desk/#comments</comments>        <pubDate>Thu, 23 Jul 2015 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/bigdata-on-your-desk/</guid>
                                    <description><![CDATA[<p>Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/uyrzrb/datascience_episode13_bigboards.mp3" length="16149723" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>16:49</itunes:duration>
                <itunes:episode>2</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 2: Networks and Graph Databases</title>
        <itunes:title>Episode 2: Networks and Graph Databases</itunes:title>
        <link>https://datascienceathome.podbean.com/e/networks-and-graph-databases/</link>
                    <comments>https://datascienceathome.podbean.com/e/networks-and-graph-databases/#comments</comments>        <pubDate>Thu, 23 Jul 2015 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/networks-and-graph-databases/</guid>
                                    <description><![CDATA[<p>Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/iz2fge/datascience_episode12_networks.mp3" length="21910822" type="audio/mpeg"/>
        <itunes:summary><![CDATA[Have you ever thought to get a Big Data infrastructure on your desk? Thatâ€™s right! On your desk.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>22:49</itunes:duration>
                <itunes:episode>3</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
    <item>
        <title>Episode 3: Data Science and Bio-Inspired Algorithms</title>
        <itunes:title>Episode 3: Data Science and Bio-Inspired Algorithms</itunes:title>
        <link>https://datascienceathome.podbean.com/e/data-science-and-bio-inspired-algorithms/</link>
                    <comments>https://datascienceathome.podbean.com/e/data-science-and-bio-inspired-algorithms/#comments</comments>        <pubDate>Wed, 08 Jul 2015 13:00:00 +0200</pubDate>
        <guid isPermaLink="false">http://datascienceathome.podbean.com/e/data-science-and-bio-inspired-algorithms/</guid>
                                    <description><![CDATA[<p>In this episode I meet Dr Eliseo Ferrante, formerly at the University of Leuven, currently researcher at the UniversitÃ© de Technologie de CompiÃ¨gne, who studies self-organization and evolution.</p>
]]></description>
                                                            <content:encoded><![CDATA[<p>In this episode I meet Dr Eliseo Ferrante, formerly at the University of Leuven, currently researcher at the UniversitÃ© de Technologie de CompiÃ¨gne, who studies self-organization and evolution.</p>
]]></content:encoded>
                                    
        <enclosure url="https://mcdn.podbean.com/mf/web/4xqhv8/datascience_episode14_swarm_intelligence.mp3" length="14238345" type="audio/mpeg"/>
        <itunes:summary><![CDATA[In this episode I meet Dr Eliseo Ferrante, formerly at the University of Leuven, currently researcher at the UniversitÃ© de Technologie de CompiÃ¨gne, who studies self-organization and evolution.]]></itunes:summary>
        <itunes:author>Francesco Gadaleta</itunes:author>
        <itunes:explicit>false</itunes:explicit>
        <itunes:block>No</itunes:block>
        <itunes:duration>14:49</itunes:duration>
                <itunes:episode>1</itunes:episode>
        <itunes:episodeType>full</itunes:episodeType>
        <itunes:image href="https://pbcdn1.podbean.com/imglogo/ep-logo/pbblog1799802/dsh_logo_v2.png" />    </item>
</channel>
</rss>
