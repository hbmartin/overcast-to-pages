<?xml version="1.0" encoding="UTF-8"?><?xml-stylesheet href="https://feeds.captivate.fm/style.xsl" type="text/xsl"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:podcast="https://podcastindex.org/namespace/1.0"><channel><atom:link href="https://feeds.captivate.fm/learnbayesstats/" rel="self" type="application/rss+xml"/><title><![CDATA[Learning Bayesian Statistics]]></title><podcast:guid>8a69aa5e-f765-514f-889c-c3997dcc46b6</podcast:guid><lastBuildDate>Wed, 18 Jun 2025 15:18:49 +0000</lastBuildDate><generator>Captivate.fm</generator><language><![CDATA[en]]></language><copyright><![CDATA[Copyright Alexandre Andorra]]></copyright><managingEditor>Alexandre Andorra</managingEditor><itunes:summary><![CDATA[Are you a researcher or data scientist / analyst / ninja? Do you want to learn Bayesian inference, stay up to date or simply want to understand what Bayesian inference is?

Then this podcast is for you! You'll hear from researchers and practitioners of all fields about how they use Bayesian statistics, and how in turn YOU can apply these methods in your modeling workflow.

When I started learning Bayesian methods, I really wished there were a podcast out there that could introduce me to the methods, the projects and the people who make all that possible. 

So I created "Learning Bayesian Statistics", where you'll get to hear how Bayesian statistics are used to detect black matter in outer space, forecast elections or understand how diseases spread and can ultimately be stopped.

But this show is not only about successes -- it's also about failures, because that's how we learn best. So you'll often hear the guests talking about what *didn't* work in their projects, why, and how they overcame these challenges. Because, in the end, we're all lifelong learners!

My name is Alex Andorra by the way, and I live in Estonia. By day, I'm a data scientist and modeler at the <a href="https://www.pymc-labs.io/">PyMC Labs</a> consultancy. By night, I don't (yet) fight crime, but I'm an open-source enthusiast and core contributor to the python packages <a href="https://docs.pymc.io/">PyMC</a> and <a href="https://arviz-devs.github.io/arviz/">ArviZ</a>. I also love <a href="https://www.pollsposition.com/">election forecasting</a> and, most importantly, Nutella. But I don't like talking about it – I prefer eating it.

So, whether you want to learn Bayesian statistics or hear about the latest libraries, books and applications, this podcast is for you -- just subscribe! You can also support the show and <a href="https://www.patreon.com/learnbayesstats">unlock exclusive Bayesian swag on Patreon</a>!]]></itunes:summary><image><url>https://artwork.captivate.fm/c4153149-677d-4c5c-9d1d-0b0a16beb8ca/2331893-1568966097324-58deab5a83dc6.jpg</url><title>Learning Bayesian Statistics</title><link><![CDATA[https://www.learnbayesstats.com]]></link></image><itunes:image href="https://artwork.captivate.fm/c4153149-677d-4c5c-9d1d-0b0a16beb8ca/2331893-1568966097324-58deab5a83dc6.jpg"/><itunes:owner><itunes:name>Alexandre Andorra</itunes:name></itunes:owner><itunes:author>Alexandre Andorra</itunes:author><description>Are you a researcher or data scientist / analyst / ninja? Do you want to learn Bayesian inference, stay up to date or simply want to understand what Bayesian inference is?

Then this podcast is for you! You&apos;ll hear from researchers and practitioners of all fields about how they use Bayesian statistics, and how in turn YOU can apply these methods in your modeling workflow.

When I started learning Bayesian methods, I really wished there were a podcast out there that could introduce me to the methods, the projects and the people who make all that possible. 

So I created &quot;Learning Bayesian Statistics&quot;, where you&apos;ll get to hear how Bayesian statistics are used to detect black matter in outer space, forecast elections or understand how diseases spread and can ultimately be stopped.

But this show is not only about successes -- it&apos;s also about failures, because that&apos;s how we learn best. So you&apos;ll often hear the guests talking about what *didn&apos;t* work in their projects, why, and how they overcame these challenges. Because, in the end, we&apos;re all lifelong learners!

My name is Alex Andorra by the way, and I live in Estonia. By day, I&apos;m a data scientist and modeler at the https://www.pymc-labs.io/ (PyMC Labs) consultancy. By night, I don&apos;t (yet) fight crime, but I&apos;m an open-source enthusiast and core contributor to the python packages https://docs.pymc.io/ (PyMC) and https://arviz-devs.github.io/arviz/ (ArviZ). I also love https://www.pollsposition.com/ (election forecasting) and, most importantly, Nutella. But I don&apos;t like talking about it – I prefer eating it.

So, whether you want to learn Bayesian statistics or hear about the latest libraries, books and applications, this podcast is for you -- just subscribe! You can also support the show and https://www.patreon.com/learnbayesstats (unlock exclusive Bayesian swag on Patreon)!</description><link>https://www.learnbayesstats.com</link><atom:link href="https://pubsubhubbub.appspot.com" rel="hub"/><itunes:subtitle><![CDATA[A podcast on Bayesian inference - the methods, the projects and the people who make it possible!]]></itunes:subtitle><itunes:explicit>false</itunes:explicit><itunes:type>episodic</itunes:type><itunes:category text="Technology"></itunes:category><itunes:category text="Science"></itunes:category><itunes:category text="Education"></itunes:category><itunes:new-feed-url>https://feeds.captivate.fm/learnbayesstats/</itunes:new-feed-url><podcast:locked>no</podcast:locked><podcast:medium>podcast</podcast:medium><podcast:funding url="https://www.patreon.com/learnbayesstats">Unlock exclusive content!</podcast:funding><item><title>BITESIZE | Exploring Dynamic Regression Models, with David Kohns</title><itunes:title>BITESIZE | Exploring Dynamic Regression Models, with David Kohns</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/134-bayesian-econometrics-state-space-models-dynamic-regression-david-kohns" rel="noopener noreferrer" target="_blank">episode 134</a> of the podcast, with David Kohns.</p><p>Alex and David discuss the future of probabilistic programming, focusing on advancements in time series modeling, model selection, and the integration of AI in prior elicitation. </p><p>The discussion highlights the importance of setting appropriate priors, the challenges of computational workflows, and the potential of normalizing flows to enhance Bayesian inference.</p><p>Get the full discussion <a href="https://learnbayesstats.com/episode/134-bayesian-econometrics-state-space-models-dynamic-regression-david-kohns" rel="noopener noreferrer" target="_blank">here</a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>Transcript</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/134-bayesian-econometrics-state-space-models-dynamic-regression-david-kohns" rel="noopener noreferrer" target="_blank">episode 134</a> of the podcast, with David Kohns.</p><p>Alex and David discuss the future of probabilistic programming, focusing on advancements in time series modeling, model selection, and the integration of AI in prior elicitation. </p><p>The discussion highlights the importance of setting appropriate priors, the challenges of computational workflows, and the potential of normalizing flows to enhance Bayesian inference.</p><p>Get the full discussion <a href="https://learnbayesstats.com/episode/134-bayesian-econometrics-state-space-models-dynamic-regression-david-kohns" rel="noopener noreferrer" target="_blank">here</a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>Transcript</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-exploring-dynamic-regression-models-david-kohns]]></link><guid isPermaLink="false">6f23b838-5572-4a90-9f3e-39f7748e58dd</guid><itunes:image href="https://artwork.captivate.fm/435609ad-871f-4671-926f-af43265b687c/0Gjz99FGsb2jhpmQLPe-9aQL.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 18 Jun 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/6f23b838-5572-4a90-9f3e-39f7748e58dd.mp3" length="30482372" type="audio/mpeg"/><itunes:duration>14:34</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/79762e81-94b0-4fe0-8d73-ae743679bfd7/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/79762e81-94b0-4fe0-8d73-ae743679bfd7/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | Exploring Dynamic Regression Models, with David Kohns"><podcast:source uri="https://youtu.be/tjQ3RkXeMuY"/></podcast:alternateEnclosure></item><item><title>#134 Bayesian Econometrics, State Space Models &amp; Dynamic Regression, with David Kohns</title><itunes:title>Bayesian Econometrics, State Space Models &amp; Dynamic Regression, with David Kohns</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Setting appropriate priors is crucial to avoid overfitting in models.</li><li class="ql-align-justify">R-squared can be used effectively in Bayesian frameworks for model evaluation.</li><li class="ql-align-justify">Dynamic regression can incorporate time-varying coefficients to capture changing relationships.</li><li class="ql-align-justify">Predictively consistent priors enhance model interpretability and performance.</li><li class="ql-align-justify">Identifiability is a challenge in time series models.</li><li class="ql-align-justify">State space models provide structure compared to Gaussian processes.</li><li class="ql-align-justify">Priors influence the model's ability to explain variance.</li><li class="ql-align-justify">Starting with simple models can reveal interesting dynamics.</li><li class="ql-align-justify">Understanding the relationship between states and variance is key.</li><li class="ql-align-justify">State-space models allow for dynamic analysis of time series data.</li><li class="ql-align-justify">AI can enhance the process of prior elicitation in statistical models.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">10:09 Understanding State Space Models</p><p class="ql-align-justify">14:53 Predictively Consistent Priors</p><p class="ql-align-justify">20:02 Dynamic Regression and AR Models</p><p class="ql-align-justify">25:08 Inflation Forecasting</p><p class="ql-align-justify">50:49 Understanding Time Series Data and Economic Analysis</p><p class="ql-align-justify">57:04 Exploring Dynamic Regression Models</p><p class="ql-align-justify">01:05:52 The Role of Priors</p><p class="ql-align-justify">01:15:36 Future Trends in Probabilistic Programming</p><p class="ql-align-justify">01:20:05 Innovations in Bayesian Model Selection</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Setting appropriate priors is crucial to avoid overfitting in models.</li><li class="ql-align-justify">R-squared can be used effectively in Bayesian frameworks for model evaluation.</li><li class="ql-align-justify">Dynamic regression can incorporate time-varying coefficients to capture changing relationships.</li><li class="ql-align-justify">Predictively consistent priors enhance model interpretability and performance.</li><li class="ql-align-justify">Identifiability is a challenge in time series models.</li><li class="ql-align-justify">State space models provide structure compared to Gaussian processes.</li><li class="ql-align-justify">Priors influence the model's ability to explain variance.</li><li class="ql-align-justify">Starting with simple models can reveal interesting dynamics.</li><li class="ql-align-justify">Understanding the relationship between states and variance is key.</li><li class="ql-align-justify">State-space models allow for dynamic analysis of time series data.</li><li class="ql-align-justify">AI can enhance the process of prior elicitation in statistical models.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">10:09 Understanding State Space Models</p><p class="ql-align-justify">14:53 Predictively Consistent Priors</p><p class="ql-align-justify">20:02 Dynamic Regression and AR Models</p><p class="ql-align-justify">25:08 Inflation Forecasting</p><p class="ql-align-justify">50:49 Understanding Time Series Data and Economic Analysis</p><p class="ql-align-justify">57:04 Exploring Dynamic Regression Models</p><p class="ql-align-justify">01:05:52 The Role of Priors</p><p class="ql-align-justify">01:15:36 Future Trends in Probabilistic Programming</p><p class="ql-align-justify">01:20:05 Innovations in Bayesian Model Selection</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Links from the show:</strong></p><ul><li>David's website: <a href="https://davkoh.github.io/" rel="noopener noreferrer" target="_blank">https://davkoh.github.io/</a></li><li>David on LinkedIn: <a href="https://www.linkedin.com/in/david-kohns-03984013b/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/david-kohns-03984013b/</a></li><li>David on GitHub: <a href="https://github.com/davkoh" rel="noopener noreferrer" target="_blank">https://github.com/davkoh</a></li><li>David on Google Scholar: <a href="https://scholar.google.com/citations?user=9gKE8e4AAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=9gKE8e4AAAAJ&amp;hl=en</a></li><li>Dynamic Regression Case Study: <a href="https://davkoh.github.io/case-studies/01_dyn_reg/dyn_reg_casestudy5.html" rel="noopener noreferrer" target="_blank">https://davkoh.github.io/case-studies/01_dyn_reg/dyn_reg_casestudy5.html</a></li><li>ARR2 Paper: <a href="https://projecteuclid.org/journals/bayesian-analysis/advance-publication/The-ARR2-Prior--Flexible-Predictive-Prior-Definition-for-Bayesian/10.1214/25-BA1512.full" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/journals/bayesian-analysis/advance-publication/The-ARR2-Prior--Flexible-Predictive-Prior-Definition-for-Bayesian/10.1214/25-BA1512.full</a></li><li>ARR2 Paper GitHub repository: <a href="https://github.com/n-kall/arr2/tree/main" rel="noopener noreferrer" target="_blank">https://github.com/n-kall/arr2/tree/main</a></li><li>ARR2 StanCon talk: <a href="https://www.youtube.com/watch?v=8XBe2jrOKvw&amp;list=PLCrWEzJgSUqzNzh6mjWsWUu-lSK59VXP6&amp;index=29" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=8XBe2jrOKvw&amp;list=PLCrWEzJgSUqzNzh6mjWsWUu-lSK59VXP6&amp;index=29</a></li><li>ARR2 Prior in PyMC: <a href="https://www.austinrochford.com/posts/r2-priors-pymc.html" rel="noopener noreferrer" target="_blank">https://www.austinrochford.com/posts/r2-priors-pymc.html</a></li><li>LBS #124 State Space Models &amp; Structural Time Series, with Jesse Grabowski: <a href="https://learnbayesstats.com/episode/124-state-space-models-structural-time-series-jesse-grabowski" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/124-state-space-models-structural-time-series-jesse-grabowski</a></li><li>LBS #107 Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt</a></li><li>LBS #74 Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt: <a href="https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt</a></li><li>Nutpie’s Normalizing Flows adaptation: <a href="https://pymc-devs.github.io/nutpie/nf-adapt.html" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/nutpie/nf-adapt.html</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/134-bayesian-econometrics-state-space-models-dynamic-regression-david-kohns]]></link><guid isPermaLink="false">838812e5-2291-4aa5-a099-143ed914e977</guid><itunes:image href="https://artwork.captivate.fm/d3713683-c573-4586-b328-ad310cc8ff0e/uwONbXOAMSKsL8pzE5pzPAxA.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 10 Jun 2025 18:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/838812e5-2291-4aa5-a099-143ed914e977.mp3" length="193789874" type="audio/mpeg"/><itunes:duration>01:40:55</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>134</itunes:episode><itunes:season>1</itunes:season><podcast:episode>134</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/cffc6cf8-5f84-4aa8-b5a6-044eaf126b57/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/cffc6cf8-5f84-4aa8-b5a6-044eaf126b57/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#134 Bayesian Econometrics, State Space Models &amp; Dynamic Regression, with David Kohns"><podcast:source uri="https://youtu.be/X8l0oW2BwGs"/></podcast:alternateEnclosure></item><item><title>BITESIZE | Why Your Models Might Be Wrong &amp; How to Fix it, with Sean Pinkney &amp; Adrian Seyboldt</title><itunes:title>BITESIZE | Why Your Models Might Be Wrong &amp; How to Fix it, with Sean Pinkney &amp; Adrian Seyboldt</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/133-making-models-more-efficient-flexible-sean-pinkney-adrian-seyboldt" rel="noopener noreferrer" target="_blank">episode 133</a> of the podcast, with Sean Pinkney &amp; Adrian Seyboldt.</p><p>The conversation delves into the concept of Zero-Sum Normal and its application in statistical modeling, particularly in hierarchical models. </p><p>Alex, Sean and Adrian discuss the implications of using zero-sum constraints, the challenges of incorporating new data points, and the importance of distinguishing between sample and population effects. </p><p>They also explore practical solutions for making predictions based on population parameters and the potential for developing tools to facilitate these processes.</p><p>Get the full discussion <a href="https://learnbayesstats.com/episode/133-making-models-more-efficient-flexible-sean-pinkney-adrian-seyboldt" rel="noopener noreferrer" target="_blank">here</a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>Transcript</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/133-making-models-more-efficient-flexible-sean-pinkney-adrian-seyboldt" rel="noopener noreferrer" target="_blank">episode 133</a> of the podcast, with Sean Pinkney &amp; Adrian Seyboldt.</p><p>The conversation delves into the concept of Zero-Sum Normal and its application in statistical modeling, particularly in hierarchical models. </p><p>Alex, Sean and Adrian discuss the implications of using zero-sum constraints, the challenges of incorporating new data points, and the importance of distinguishing between sample and population effects. </p><p>They also explore practical solutions for making predictions based on population parameters and the potential for developing tools to facilitate these processes.</p><p>Get the full discussion <a href="https://learnbayesstats.com/episode/133-making-models-more-efficient-flexible-sean-pinkney-adrian-seyboldt" rel="noopener noreferrer" target="_blank">here</a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>Transcript</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-why-your-models-might-be-wrong-how-to-fix-it-sean-pinkney-adrian-seyboldt]]></link><guid isPermaLink="false">78e63944-beb5-4b6f-bd3e-7df09d5b836c</guid><itunes:image href="https://artwork.captivate.fm/7b4e1d5f-5271-4cde-99ba-faf2ad1dcda6/uP26yiL73fcXdws3Ug1h0jXS.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 04 Jun 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/78e63944-beb5-4b6f-bd3e-7df09d5b836c.mp3" length="35287244" type="audio/mpeg"/><itunes:duration>17:04</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/969c156d-4a2c-468c-bc81-4fdb260fc0f1/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/969c156d-4a2c-468c-bc81-4fdb260fc0f1/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | Why Your Models Might Be Wrong &amp; How to Fix it, with Sean Pinkney &amp; Adrian Seyboldt"><podcast:source uri="https://youtu.be/fXcisAuecM4"/></podcast:alternateEnclosure></item><item><title>#133 Making Models More Efficient &amp; Flexible, with Sean Pinkney &amp; Adrian Seyboldt</title><itunes:title>Making Models More Efficient &amp; Flexible, with Sean Pinkney &amp; Adrian Seyboldt</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;) </p><p><strong>Takeaways</strong>:</p><ul><li>Zero Sum constraints allow for better sampling and estimation in hierarchical models.</li><li>Understanding the difference between population and sample means is crucial.</li><li>A library for zero-sum normal effects would be beneficial.</li><li>Practical solutions can yield decent predictions even with limitations.</li><li>Cholesky parameterization can be adapted for positive correlation matrices.</li><li>Understanding the geometry of sampling spaces is crucial.</li><li>The relationship between eigenvalues and sampling is complex.</li><li>Collaboration and sharing knowledge enhance research outcomes.</li><li>Innovative approaches can simplify complex statistical problems.</li></ul><br/><p><strong>Chapters</strong>:</p><p>03:35 Sean Pinkney's Journey to Bayesian Modeling</p><p>11:21 The Zero-Sum Normal Project Explained</p><p>18:52 Technical Insights on Zero-Sum Constraints</p><p>32:04 Handling New Elements in Bayesian Models</p><p>36:19 Understanding Population Parameters and Predictions</p><p>49:11 Exploring Flexible Cholesky Parameterization</p><p>01:07:23 Closing Thoughts and Future Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;) </p><p><strong>Takeaways</strong>:</p><ul><li>Zero Sum constraints allow for better sampling and estimation in hierarchical models.</li><li>Understanding the difference between population and sample means is crucial.</li><li>A library for zero-sum normal effects would be beneficial.</li><li>Practical solutions can yield decent predictions even with limitations.</li><li>Cholesky parameterization can be adapted for positive correlation matrices.</li><li>Understanding the geometry of sampling spaces is crucial.</li><li>The relationship between eigenvalues and sampling is complex.</li><li>Collaboration and sharing knowledge enhance research outcomes.</li><li>Innovative approaches can simplify complex statistical problems.</li></ul><br/><p><strong>Chapters</strong>:</p><p>03:35 Sean Pinkney's Journey to Bayesian Modeling</p><p>11:21 The Zero-Sum Normal Project Explained</p><p>18:52 Technical Insights on Zero-Sum Constraints</p><p>32:04 Handling New Elements in Bayesian Models</p><p>36:19 Understanding Population Parameters and Predictions</p><p>49:11 Exploring Flexible Cholesky Parameterization</p><p>01:07:23 Closing Thoughts and Future Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Sean's website: <a href="https://spinkney.github.io/" rel="noopener noreferrer" target="_blank">https://spinkney.github.io/</a></li><li>Sean on LinkedIn: <a href="https://www.linkedin.com/in/sean-pinkney123/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/sean-pinkney123/</a></li><li>Sean on GitHub: <a href="https://github.com/spinkney" rel="noopener noreferrer" target="_blank">https://github.com/spinkney</a></li><li>Sean on BlueSky: <a href="https://bsky.app/profile/spinkney.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/spinkney.bsky.social</a></li><li>Sean on Mastodon: <a href="https://fosstodon.org/@spinkney" rel="noopener noreferrer" target="_blank">https://fosstodon.org/@spinkney</a></li><li>Sean's talk at StanCon 2024: <a href="https://youtu.be/eE8Vqxs8OfQ?si=09-vNvCxpbz8enUj" rel="noopener noreferrer" target="_blank">https://youtu.be/eE8Vqxs8OfQ?si=09-vNvCxpbz8enUj</a></li><li>Flexible Cholesky Parameterization of Correlation Matrices: <a href="https://arxiv.org/abs/2405.07286" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2405.07286</a></li><li>Quantile Regressions in Stan: <a href="https://spinkney.github.io/posts/post-2-quantile-reg-series/post-2-quantile-reg-part-I/quantile-reg.html" rel="noopener noreferrer" target="_blank">https://spinkney.github.io/posts/post-2-quantile-reg-series/post-2-quantile-reg-part-I/quantile-reg.html</a></li><li>LBS #74 Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt: <a href="https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/133-making-models-more-efficient-flexible-sean-pinkney-adrian-seyboldt]]></link><guid isPermaLink="false">7783c364-3527-4835-ac1a-ca0e0b39da61</guid><itunes:image href="https://artwork.captivate.fm/1834c111-e490-4ba3-9ce5-30081a6e8a69/3fI4hfnjYOh7WjVYfDiYauvl.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 28 May 2025 07:45:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/7783c364-3527-4835-ac1a-ca0e0b39da61.mp3" length="138660241" type="audio/mpeg"/><itunes:duration>01:12:12</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>133</itunes:episode><itunes:season>1</itunes:season><podcast:episode>133</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/fea0a36f-e872-49dc-a22d-affbccdcff99/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/fea0a36f-e872-49dc-a22d-affbccdcff99/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#133 Making Models More Efficient &amp; Flexible, with Sean Pinkney &amp; Adrian Seyboldt"><podcast:source uri="https://youtu.be/PhtJylCi678"/></podcast:alternateEnclosure></item><item><title>BITESIZE | How AI is Redefining Human Interactions, with Tom Griffiths</title><itunes:title>BITESIZE | How AI is Redefining Human Interactions, with Tom Griffiths</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/132-bayesian-cognition-and-the-future-of-human-ai-interaction-tom-griffiths" rel="noopener noreferrer" target="_blank">episode 132</a> of the podcast, with Tom Griffiths.</p><p>Tom and Alex Andorra discuss the fundamental differences between human intelligence and artificial intelligence, emphasizing the constraints that shape human cognition, such as limited data, computational resources, and communication bandwidth. </p><p>They explore how AI systems currently learn and the potential for aligning AI with human cognitive processes. </p><p>The discussion also delves into the implications of AI in enhancing human decision-making and the importance of understanding human biases to create more effective AI systems.</p><p><strong>Get the full discussion </strong><a href="https://learnbayesstats.com/episode/132-bayesian-cognition-and-the-future-of-human-ai-interaction-tom-griffiths" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p><strong>Visit our </strong><a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank"><strong>Patreon page</strong></a><strong> to unlock exclusive Bayesian swag ;)</strong></p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/132-bayesian-cognition-and-the-future-of-human-ai-interaction-tom-griffiths" rel="noopener noreferrer" target="_blank">episode 132</a> of the podcast, with Tom Griffiths.</p><p>Tom and Alex Andorra discuss the fundamental differences between human intelligence and artificial intelligence, emphasizing the constraints that shape human cognition, such as limited data, computational resources, and communication bandwidth. </p><p>They explore how AI systems currently learn and the potential for aligning AI with human cognitive processes. </p><p>The discussion also delves into the implications of AI in enhancing human decision-making and the importance of understanding human biases to create more effective AI systems.</p><p><strong>Get the full discussion </strong><a href="https://learnbayesstats.com/episode/132-bayesian-cognition-and-the-future-of-human-ai-interaction-tom-griffiths" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p><strong>Visit our </strong><a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank"><strong>Patreon page</strong></a><strong> to unlock exclusive Bayesian swag ;)</strong></p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-how-ai-is-redefining-human-interactions-tom-griffiths]]></link><guid isPermaLink="false">e701bc99-f611-487c-99ef-093a17831153</guid><itunes:image href="https://artwork.captivate.fm/e67985e2-3f3f-47a7-8357-2bb8160b0e82/O8WrmStoTyGBjfXz9F50ypUv.jpeg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 21 May 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/e701bc99-f611-487c-99ef-093a17831153.mp3" length="44939716" type="audio/mpeg"/><itunes:duration>22:06</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/607e954d-8d29-4dba-adcf-95c8b09b2f59/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/607e954d-8d29-4dba-adcf-95c8b09b2f59/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | How AI is Redefining Human Interactions, with Tom Griffiths"><podcast:source uri="https://youtu.be/GCbEM0lBziQ"/></podcast:alternateEnclosure></item><item><title>#132 Bayesian Cognition and the Future of Human-AI Interaction, with Tom Griffiths</title><itunes:title>Bayesian Cognition and the Future of Human-AI Interaction, with Tom Griffiths</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p><em>Check out </em><a href="https://high-signal.delphina.ai/episode/fei-fei-on-how-human-centered-ai-actually-gets-built?utm_source=laplace&amp;utm_medium=podcast&amp;utm_campaign=feifei_launch" rel="noopener noreferrer" target="_blank"><em>Hugo’s latest episode</em></a><em> with Fei-Fei Li, on How Human-Centered AI Actually Gets Built</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Computational cognitive science seeks to understand intelligence mathematically.</li><li class="ql-align-justify">Bayesian statistics is crucial for understanding human cognition.</li><li class="ql-align-justify">Inductive biases help explain how humans learn from limited data.</li><li class="ql-align-justify">Eliciting prior distributions can reveal implicit beliefs.</li><li class="ql-align-justify">The wisdom of individuals can provide richer insights than averaging group responses.</li><li class="ql-align-justify">Generative AI can mimic human cognitive processes.</li><li class="ql-align-justify">Human intelligence is shaped by constraints of data, computation, and communication.</li><li class="ql-align-justify">AI systems operate under different constraints than human cognition. Human intelligence differs fundamentally from machine intelligence.</li><li class="ql-align-justify">Generative AI can complement and enhance human learning.</li><li class="ql-align-justify">AI systems currently lack intrinsic human compatibility.</li><li class="ql-align-justify">Language training in AI helps align its understanding with human perspectives.</li><li class="ql-align-justify">Reinforcement learning from human feedback can lead to misalignment of AI goals.</li><li class="ql-align-justify">Representational alignment can improve AI's understanding of human concepts.</li><li class="ql-align-justify">AI can help humans make better decisions by providing relevant information.</li><li class="ql-align-justify">Research should focus on solving problems rather than just methods.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Understanding Computational Cognitive Science</p><p class="ql-align-justify">13:52 Bayesian Models and Human Cognition</p><p class="ql-align-justify">29:50 Eliciting Implicit Prior Distributions</p><p class="ql-align-justify">38:07 The Relationship Between Human and AI Intelligence</p><p class="ql-align-justify">45:15 Aligning Human and Machine Preferences</p><p class="ql-align-justify">50:26 Innovations in AI and Human Interaction</p><p class="ql-align-justify">55:35 Resource Rationality in Decision Making</p><p class="ql-align-justify">01:00:07 Language Learning in AI Models</p><p...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p><em>Check out </em><a href="https://high-signal.delphina.ai/episode/fei-fei-on-how-human-centered-ai-actually-gets-built?utm_source=laplace&amp;utm_medium=podcast&amp;utm_campaign=feifei_launch" rel="noopener noreferrer" target="_blank"><em>Hugo’s latest episode</em></a><em> with Fei-Fei Li, on How Human-Centered AI Actually Gets Built</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Computational cognitive science seeks to understand intelligence mathematically.</li><li class="ql-align-justify">Bayesian statistics is crucial for understanding human cognition.</li><li class="ql-align-justify">Inductive biases help explain how humans learn from limited data.</li><li class="ql-align-justify">Eliciting prior distributions can reveal implicit beliefs.</li><li class="ql-align-justify">The wisdom of individuals can provide richer insights than averaging group responses.</li><li class="ql-align-justify">Generative AI can mimic human cognitive processes.</li><li class="ql-align-justify">Human intelligence is shaped by constraints of data, computation, and communication.</li><li class="ql-align-justify">AI systems operate under different constraints than human cognition. Human intelligence differs fundamentally from machine intelligence.</li><li class="ql-align-justify">Generative AI can complement and enhance human learning.</li><li class="ql-align-justify">AI systems currently lack intrinsic human compatibility.</li><li class="ql-align-justify">Language training in AI helps align its understanding with human perspectives.</li><li class="ql-align-justify">Reinforcement learning from human feedback can lead to misalignment of AI goals.</li><li class="ql-align-justify">Representational alignment can improve AI's understanding of human concepts.</li><li class="ql-align-justify">AI can help humans make better decisions by providing relevant information.</li><li class="ql-align-justify">Research should focus on solving problems rather than just methods.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Understanding Computational Cognitive Science</p><p class="ql-align-justify">13:52 Bayesian Models and Human Cognition</p><p class="ql-align-justify">29:50 Eliciting Implicit Prior Distributions</p><p class="ql-align-justify">38:07 The Relationship Between Human and AI Intelligence</p><p class="ql-align-justify">45:15 Aligning Human and Machine Preferences</p><p class="ql-align-justify">50:26 Innovations in AI and Human Interaction</p><p class="ql-align-justify">55:35 Resource Rationality in Decision Making</p><p class="ql-align-justify">01:00:07 Language Learning in AI Models</p><p class="ql-align-justify">01:06:04 Inductive Biases in Language Learning</p><p class="ql-align-justify">01:11:55 Advice for Aspiring Cognitive Scientists</p><p class="ql-align-justify">01:21:19 Future Trends in Cognitive Science and AI</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Check out Hugo’s latest episode with Fei-Fei Li, on How Human-Centered AI Actually Gets Built: <a href="https://high-signal.delphina.ai/episode/fei-fei-on-how-human-centered-ai-actually-gets-built?utm_source=ding&amp;utm_medium=podcast&amp;utm_campaign=feifei_launch" rel="noopener noreferrer" target="_blank">https://high-signal.delphina.ai/episode/fei-fei-on-how-human-centered-ai-actually-gets-built?utm_source=laplace&amp;utm_medium=podcast&amp;utm_campaign=feifei_launch</a></li><li>Tom's profile at Princeton University: <a href="https://psychology.princeton.edu/people/tom-griffiths" rel="noopener noreferrer" target="_blank">https://psychology.princeton.edu/people/tom-griffiths</a></li><li>Computational Cognitive Science Lab: <a href="https://cocosci.princeton.edu/" rel="noopener noreferrer" target="_blank">https://cocosci.princeton.edu/</a></li><li>Tom’s Google Scholar: <a href="https://scholar.google.com/citations?user=UAwKvEsAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=UAwKvEsAAAAJ&amp;hl=en</a></li><li>Tom's latest book, <em>Bayesian Models of Cognition</em>: <a href="https://mitpress.mit.edu/9780262049412/bayesian-models-of-cognition/" rel="noopener noreferrer" target="_blank">https://mitpress.mit.edu/9780262049412/bayesian-models-of-cognition/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/132-bayesian-cognition-and-the-future-of-human-ai-interaction-tom-griffiths]]></link><guid isPermaLink="false">0d4bed08-7254-49ee-9c0a-c321ac938338</guid><itunes:image href="https://artwork.captivate.fm/feb4fb1b-8e8c-484b-8604-92481d9bdb82/qTPX-fwtxr6Cmcdyn0oQaFF2.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 13 May 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/0d4bed08-7254-49ee-9c0a-c321ac938338.mp3" length="175809010" type="audio/mpeg"/><itunes:duration>01:30:15</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>132</itunes:episode><itunes:season>1</itunes:season><podcast:episode>132</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/0ffab14f-662b-4b30-b734-5b0cff2c2aad/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/0ffab14f-662b-4b30-b734-5b0cff2c2aad/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#132 Bayesian Cognition and the Future of Human-AI Interaction, with Tom Griffiths"><podcast:source uri="https://youtu.be/7UT3fUBjldk"/></podcast:alternateEnclosure></item><item><title>BITESIZE | Hacking Bayesian Models for Better Performance, with Luke Bornn</title><itunes:title>BITESIZE | Hacking Bayesian Models for Better Performance, with Luke Bornn</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/131-decision-making-under-high-uncertainty-luke-bornn" rel="noopener noreferrer" target="_blank">episode 131</a> of the podcast, with Luke Bornn.</p><p>Luke and Alex discuss the application of generative models in sports analytics. They emphasize the importance of Bayesian modeling to account for uncertainty and contextual variations in player data. </p><p>The discussion also covers the challenges of balancing model complexity with computational efficiency, the innovative ways to hack Bayesian models for improved performance, and the significance of understanding model fitting and discretization in statistical modeling.</p><p><strong>Get the full discussion</strong> <a href="https://learnbayesstats.com/episode/131-decision-making-under-high-uncertainty-luke-bornn" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/131-decision-making-under-high-uncertainty-luke-bornn" rel="noopener noreferrer" target="_blank">episode 131</a> of the podcast, with Luke Bornn.</p><p>Luke and Alex discuss the application of generative models in sports analytics. They emphasize the importance of Bayesian modeling to account for uncertainty and contextual variations in player data. </p><p>The discussion also covers the challenges of balancing model complexity with computational efficiency, the innovative ways to hack Bayesian models for improved performance, and the significance of understanding model fitting and discretization in statistical modeling.</p><p><strong>Get the full discussion</strong> <a href="https://learnbayesstats.com/episode/131-decision-making-under-high-uncertainty-luke-bornn" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-hacking-bayesian-models-for-better-performance-luke-bornn]]></link><guid isPermaLink="false">76caf5f1-946d-4da9-80ee-76bbff3ceeff</guid><itunes:image href="https://artwork.captivate.fm/329734e0-a9c4-4666-9b64-49afa6cad70e/wQ13CH__rLDc7gHQ5YDlil4Y.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 07 May 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/76caf5f1-946d-4da9-80ee-76bbff3ceeff.mp3" length="28605137" type="audio/mpeg"/><itunes:duration>13:35</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/f7aa4a8b-174b-44c7-85c4-5d4b4e131917/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/f7aa4a8b-174b-44c7-85c4-5d4b4e131917/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | Hacking Bayesian Models for Better Performance, with Luke Bornn"><podcast:source uri="https://youtu.be/-lIs1BBWhrg"/></podcast:alternateEnclosure></item><item><title>#131 Decision-Making Under High Uncertainty, with Luke Bornn</title><itunes:title>Decision-Making Under High Uncertainty, with Luke Bornn</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Player tracking data revolutionized sports analytics.</li><li class="ql-align-justify">Decision-making in sports involves managing uncertainty and budget constraints.</li><li class="ql-align-justify">Luke emphasizes the importance of portfolio optimization in team management.</li><li class="ql-align-justify">Clubs with high budgets can afford inefficiencies in player acquisition.</li><li class="ql-align-justify">Statistical methods provide a probabilistic approach to player value.</li><li class="ql-align-justify">Removing human bias is crucial in sports decision-making.</li><li class="ql-align-justify">Understanding player performance distributions aids in contract decisions.</li><li class="ql-align-justify">The goal is to maximize performance value per dollar spent.</li><li class="ql-align-justify">Model validation in sports requires focusing on edge cases.</li><li...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Player tracking data revolutionized sports analytics.</li><li class="ql-align-justify">Decision-making in sports involves managing uncertainty and budget constraints.</li><li class="ql-align-justify">Luke emphasizes the importance of portfolio optimization in team management.</li><li class="ql-align-justify">Clubs with high budgets can afford inefficiencies in player acquisition.</li><li class="ql-align-justify">Statistical methods provide a probabilistic approach to player value.</li><li class="ql-align-justify">Removing human bias is crucial in sports decision-making.</li><li class="ql-align-justify">Understanding player performance distributions aids in contract decisions.</li><li class="ql-align-justify">The goal is to maximize performance value per dollar spent.</li><li class="ql-align-justify">Model validation in sports requires focusing on edge cases.</li><li class="ql-align-justify">Generative models help account for uncertainty in player performance.</li><li class="ql-align-justify">Computational efficiency is key in handling large datasets.</li><li class="ql-align-justify">A diverse skill set enhances problem-solving in sports analytics.</li><li class="ql-align-justify">Broader knowledge in data science leads to innovative solutions.&nbsp;</li><li class="ql-align-justify">Integrating software engineering with statistics is crucial in sports analytics.</li><li class="ql-align-justify">Model validation often requires more work than model fitting itself.</li><li class="ql-align-justify">Understanding the context of data is essential for accurate predictions.</li><li class="ql-align-justify">Continuous learning and adaptation are essential in analytics.</li></ul><br/><p class="ql-align-justify"><strong>Chapters:</strong></p><p class="ql-align-justify">11:58 Transition from Academia to Sports Analytics</p><p class="ql-align-justify">20:44 Evolution of Sports Analytics and Data Sources</p><p class="ql-align-justify">23:53 Modeling Uncertainty in Decision Making</p><p class="ql-align-justify">32:05 The Role of Statistical Models in Player Evaluation</p><p class="ql-align-justify">39:20 Generative Models and Bayesian Framework in Sports</p><p class="ql-align-justify">46:54 Hacking Bayesian Models for Better Performance</p><p class="ql-align-justify">49:55 Understanding Computational Challenges in Bayesian Inference</p><p class="ql-align-justify">52:44 Exploring Different Approaches to Model Fitting</p><p class="ql-align-justify">56:30 Building a Comprehensive Statistical Toolbox</p><p class="ql-align-justify">01:00:37 The Importance of Data Management in Modeling</p><p class="ql-align-justify">01:03:21 Iterative Model Validation and Diagnostics</p><p class="ql-align-justify">01:06:53 Uncovering Insights from Sports Data</p><p class="ql-align-justify">01:16:47 Emerging Trends in Sports Analytics</p><p class="ql-align-justify">01:21:30 Future Directions and Personal Aspirations</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Luke’s website: <a href="http://www.lukebornn.com/" rel="noopener noreferrer" target="_blank">http://www.lukebornn.com/</a>&nbsp;</li><li>Luke on Linkedin: <a href="https://www.linkedin.com/in/lukebornn/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/lukebornn/</a></li><li>Luke on Wharton Moneyball: <a href="https://knowledge.wharton.upenn.edu/podcast/moneyball-highlights/luke-bornn-part-owner-of-ac-milan/" rel="noopener noreferrer" target="_blank">https://knowledge.wharton.upenn.edu/podcast/moneyball-highlights/luke-bornn-part-owner-of-ac-milan/</a></li><li>LBS #108 Modeling Sports &amp; Extracting Player Values, with Paul Sabin: <a href="https://learnbayesstats.com/episode/108-modeling-sports-extracting-player-values-paul-sabin" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/108-modeling-sports-extracting-player-values-paul-sabin</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/131-decision-making-under-high-uncertainty-luke-bornn]]></link><guid isPermaLink="false">f03ffbbb-e7af-4a0a-8a76-dd907accc8b1</guid><itunes:image href="https://artwork.captivate.fm/e0745855-9bf7-447a-9da8-40a42ec9d217/AbIn04DKJRtfTW-M0ph5EHa2.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 30 Apr 2025 08:00:00 -0300</pubDate><enclosure url="https://episodes.captivate.fm/episode/f03ffbbb-e7af-4a0a-8a76-dd907accc8b1.mp3" length="176206870" type="audio/mpeg"/><itunes:duration>01:31:46</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>131</itunes:episode><itunes:season>1</itunes:season><podcast:episode>131</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/fc42301d-d7ba-4060-b0c6-7023d21245d1/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/fc42301d-d7ba-4060-b0c6-7023d21245d1/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#131 Decision-Making Under High Uncertainty, with Luke Bornn"><podcast:source uri="https://youtu.be/7ffcCyEwBhA"/></podcast:alternateEnclosure></item><item><title>BITESIZE | Real-World Applications of Models in Public Health, with Adam Kucharski</title><itunes:title>BITESIZE | Real-World Applications of Models in Public Health, with Adam Kucharski</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/130-real-world-impact-epidemiological-models-adam-kucharski" rel="noopener noreferrer" target="_blank">episode 130</a> of the podcast, with epidemiological modeler Adam Kucharski.</p><p>This conversation explores the critical role of patient modeling during the COVID-19 pandemic, highlighting how these models informed public health decisions and the relationship between modeling and policy. </p><p>The discussion emphasizes the need for improved communication and understanding of data among the public and policymakers.</p><p><strong>Get the full discussion </strong><a href="https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank" style="font-family: var(--bs-font-sans-serif); font-size: 1.125rem;">Intro to Bayes Course</a><span style="font-family: var(--bs-font-sans-serif); font-size: 1.125rem; color: var(--bs-accordion-color);"> (first 2 lessons free)</span></li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/130-real-world-impact-epidemiological-models-adam-kucharski" rel="noopener noreferrer" target="_blank">episode 130</a> of the podcast, with epidemiological modeler Adam Kucharski.</p><p>This conversation explores the critical role of patient modeling during the COVID-19 pandemic, highlighting how these models informed public health decisions and the relationship between modeling and policy. </p><p>The discussion emphasizes the need for improved communication and understanding of data among the public and policymakers.</p><p><strong>Get the full discussion </strong><a href="https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin" rel="noopener noreferrer" target="_blank"><strong>here</strong></a>.</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank" style="font-family: var(--bs-font-sans-serif); font-size: 1.125rem;">Intro to Bayes Course</a><span style="font-family: var(--bs-font-sans-serif); font-size: 1.125rem; color: var(--bs-accordion-color);"> (first 2 lessons free)</span></li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-real-world-applications-models-public-health-adam-kucharski]]></link><guid isPermaLink="false">647e24f7-435d-480e-a030-68db8d991f7e</guid><itunes:image href="https://artwork.captivate.fm/ae907279-9a7b-48e4-8a6c-17b21253f829/Y944bwVCvwEo4Kuvb_3Jj7yD.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 23 Apr 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/51ddf976-6c96-486a-a4cd-1e0178f9e9b8/riverside-alexandre-andorra-compressed-audio-lbs-studio-0344.mp3" length="7887952" type="audio/mpeg"/><itunes:duration>16:26</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/80e579d9-406d-4854-b7b1-d7559979d029/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/80e579d9-406d-4854-b7b1-d7559979d029/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | Real-World Applications of Models in Public Health, with Adam Kucharski"><podcast:source uri="https://youtu.be/pv6Od74FMqY"/></podcast:alternateEnclosure></item><item><title>#130 The Real-World Impact of Epidemiological Models, with Adam Kucharski</title><itunes:title>The Real-World Impact of Epidemiological Models, with Adam Kucharski</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Epidemiology requires a blend of mathematical and statistical understanding.</li><li class="ql-align-justify">Models are essential for informing public health decisions during epidemics.</li><li class="ql-align-justify">The COVID-19 pandemic highlighted the importance of rapid modeling.</li><li class="ql-align-justify">Misconceptions about data can lead to misunderstandings in public health.</li><li class="ql-align-justify">Effective communication is crucial for conveying complex epidemiological concepts.</li><li class="ql-align-justify">Epidemic thinking can be applied to various fields, including marketing and finance.</li><li class="ql-align-justify">Public health policies should be informed by robust modeling and data analysis.</li><li class="ql-align-justify">Automation can help streamline data analysis in epidemic response.</li><li class="ql-align-justify">Understanding the limitations of models...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Epidemiology requires a blend of mathematical and statistical understanding.</li><li class="ql-align-justify">Models are essential for informing public health decisions during epidemics.</li><li class="ql-align-justify">The COVID-19 pandemic highlighted the importance of rapid modeling.</li><li class="ql-align-justify">Misconceptions about data can lead to misunderstandings in public health.</li><li class="ql-align-justify">Effective communication is crucial for conveying complex epidemiological concepts.</li><li class="ql-align-justify">Epidemic thinking can be applied to various fields, including marketing and finance.</li><li class="ql-align-justify">Public health policies should be informed by robust modeling and data analysis.</li><li class="ql-align-justify">Automation can help streamline data analysis in epidemic response.</li><li class="ql-align-justify">Understanding the limitations of models is key to effective decision-making</li><li class="ql-align-justify">Collaboration is key in developing complex models.</li><li class="ql-align-justify">Uncertainty estimation is crucial for effective decision-making.</li><li class="ql-align-justify">AI has the potential to enhance data interpretation in epidemiology.</li><li class="ql-align-justify">Educational initiatives should focus on understanding exponential growth and lagged outcomes.</li><li class="ql-align-justify">The complexity of modern epidemics requires a deeper understanding from the public.</li><li class="ql-align-justify">Understanding the balance between perfection and practicality is essential in modeling.</li></ul><br/><p class="ql-align-justify"><strong>Chapters:</strong></p><p class="ql-align-justify">00:00 Introduction to Epidemiological Modeling</p><p class="ql-align-justify">05:16 The Role of Bayesian Methods in Epidemic Forecasting</p><p class="ql-align-justify">11:29 Real-World Applications of Models in Public Health</p><p class="ql-align-justify">19:07 Common Misconceptions About Epidemiological Data</p><p class="ql-align-justify">27:43 Understanding the Spread of Ideas and Beliefs</p><p class="ql-align-justify">32:55 Workflow and Collaboration in Epidemiological Modeling</p><p class="ql-align-justify">34:51 Modeling Approaches in Epidemiology</p><p class="ql-align-justify">40:04 Challenges in Model Development</p><p class="ql-align-justify">45:55 Uncertainty in Epidemiological Models</p><p class="ql-align-justify">48:46 The Impact of AI on Epidemiology</p><p class="ql-align-justify">54:55 Educational Initiatives for Future Epidemiologists</p><p><strong>Links from the show:</strong></p><ul><li>Adam’s website: <a href="https://kucharski.substack.com/" rel="noopener noreferrer" target="_blank">https://kucharski.substack.com/</a></li><li>Adam on Google Scholar: <a href="https://scholar.google.com/citations?user=eIqfmHYAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=eIqfmHYAAAAJ&amp;hl=en</a></li><li>Adam on Linkedin: <a href="https://www.linkedin.com/in/adam-kucharski-1a1b0225b/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/adam-kucharski-1a1b0225b/</a></li><li>The Rules of Contagion: Why Things Spread - and Why They Stop: <a href="https://www.amazon.co.uk/Rules-Contagion-Things-Wellcome-Collection/dp/1788160207" rel="noopener noreferrer" target="_blank">https://www.amazon.co.uk/Rules-Contagion-Things-Wellcome-Collection/dp/1788160207</a></li><li>Adam's next book, The Uncertain Science of Certainty: <a href="https://proof.kucharski.io/" rel="noopener noreferrer" target="_blank">https://proof.kucharski.io/</a></li><li>LBS #50 Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter</a></li><li>LBS #51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/130-real-world-impact-epidemiological-models-adam-kucharski]]></link><guid isPermaLink="false">5a127dea-d264-4653-bc2f-9ca89e539e74</guid><itunes:image href="https://artwork.captivate.fm/e91060ca-e256-4d56-9682-9b7475678e21/gxX1SsWGuUnq1YGT7MsW24Sn.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 16 Apr 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/63071dda-0c3b-4b7e-9106-9a38bbf34cd2/episode-130-MP3.mp3" length="132663579" type="audio/mpeg"/><itunes:duration>01:09:05</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>130</itunes:episode><itunes:season>1</itunes:season><podcast:episode>130</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/cf2658bc-1d01-4cf8-ae2d-fb90758224d0/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/cf2658bc-1d01-4cf8-ae2d-fb90758224d0/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#130 The Real-World Impact of Epidemiological Models, with Adam Kucharski"><podcast:source uri="https://youtu.be/bNXs9jEromI"/></podcast:alternateEnclosure></item><item><title>BITESIZE | The Why &amp; How of Bayesian Deep Learning, with Vincent Fortuin</title><itunes:title>BITESIZE | The Why &amp; How of Bayesian Deep Learning, with Vincent Fortuin</itunes:title><description><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin" rel="noopener noreferrer" target="_blank">episode 129</a> of the podcast, with AI expert and researcher Vincent Fortuin.</p><p>This conversation delves into the intricacies of Bayesian deep learning, contrasting it with traditional deep learning and exploring its applications and challenges.</p><p>Get the <strong>full discussion</strong> at https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></description><content:encoded><![CDATA[<p>Today’s clip is from <a href="https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin" rel="noopener noreferrer" target="_blank">episode 129</a> of the podcast, with AI expert and researcher Vincent Fortuin.</p><p>This conversation delves into the intricacies of Bayesian deep learning, contrasting it with traditional deep learning and exploring its applications and challenges.</p><p>Get the <strong>full discussion</strong> at https://learnbayesstats.com/episode/129-bayesian-deep-learning-ai-for-science-vincent-fortuin</p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/bitesize-why-how-of-bayesian-deep-learning-vincent-fortuin]]></link><guid isPermaLink="false">1436fcaf-e522-4344-a7fe-9f4fa037b16d</guid><itunes:image href="https://artwork.captivate.fm/84b34bf3-46a9-477d-ba7b-b805a6c0cef2/dpjuzSjlYwLk1KSYg1XrZ6sz.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 09 Apr 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/ba24ce47-d049-4f4a-9189-499717c2ac87/riverside-alexandre-andorra-compressed-audio-lbs-studio-0335.mp3" length="5642258" type="audio/mpeg"/><itunes:duration>11:45</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/0ec1cd6b-78a9-4bdd-b1fb-499d350f0acf/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/0ec1cd6b-78a9-4bdd-b1fb-499d350f0acf/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="BITESIZE | The Why &amp; How of Bayesian Deep Learning, with Vincent Fortuin"><podcast:source uri="https://youtu.be/lEzmFOoee2Y"/></podcast:alternateEnclosure></item><item><title>#129 Bayesian Deep Learning &amp; AI for Science with Vincent Fortuin</title><itunes:title>Bayesian Deep Learning &amp; AI for Science with Vincent Fortuin</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">The hype around AI in science often fails to deliver practical results.</li><li class="ql-align-justify">Bayesian deep learning combines the strengths of deep learning and Bayesian statistics.</li><li class="ql-align-justify">Fine-tuning LLMs with Bayesian methods improves prediction calibration.</li><li class="ql-align-justify">There is no single dominant library for Bayesian deep learning yet.</li><li class="ql-align-justify">Real-world applications of Bayesian deep learning exist in various fields.</li><li class="ql-align-justify">Prior knowledge is crucial for the effectiveness of Bayesian deep learning.</li><li class="ql-align-justify">Data efficiency in AI can be enhanced by incorporating prior knowledge.</li><li class="ql-align-justify">Generative AI and Bayesian deep learning can inform each other.</li><li class="ql-align-justify">The complexity of a problem influences the choice between Bayesian and traditional deep learning.</li><li class="ql-align-justify">Meta-learning enhances the efficiency of Bayesian models.</li><li class="ql-align-justify">PAC-Bayesian theory merges Bayesian and frequentist ideas.</li><li class="ql-align-justify">Laplace inference offers a cost-effective approximation.</li><li class="ql-align-justify">Subspace inference can optimize parameter efficiency.</li><li class="ql-align-justify">Bayesian deep learning is crucial for reliable predictions.</li><li class="ql-align-justify">Effective communication of uncertainty is essential.</li><li class="ql-align-justify">Realistic benchmarks are needed for Bayesian methods</li><li class="ql-align-justify">Collaboration and communication in the AI community are vital.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p>00:00 Introduction to Bayesian Deep Learning</p><p>06:12 Vincent's Journey into Machine Learning</p><p>12:42 Defining Bayesian Deep Learning</p><p>17:23 Current Landscape of Bayesian Libraries</p><p>22:02 Real-World Applications of Bayesian Deep Learning</p><p>24:29 When to Use Bayesian Deep Learning</p><p>29:36 Data Efficient AI and Generative Modeling</p><p>31:59 Exploring Generative AI and Meta-Learning</p><p>34:19 Understanding Bayesian Deep Learning and Prior Knowledge</p><p>39:01 Algorithms for Bayesian Deep Learning Models</p><p>43:25 Advancements in Efficient Inference Techniques</p><p>49:35 The Future of AI Models and Reliability</p><p>52:47 Advice for Aspiring Researchers in AI</p><p>56:06 Future Projects and Research Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">The hype around AI in science often fails to deliver practical results.</li><li class="ql-align-justify">Bayesian deep learning combines the strengths of deep learning and Bayesian statistics.</li><li class="ql-align-justify">Fine-tuning LLMs with Bayesian methods improves prediction calibration.</li><li class="ql-align-justify">There is no single dominant library for Bayesian deep learning yet.</li><li class="ql-align-justify">Real-world applications of Bayesian deep learning exist in various fields.</li><li class="ql-align-justify">Prior knowledge is crucial for the effectiveness of Bayesian deep learning.</li><li class="ql-align-justify">Data efficiency in AI can be enhanced by incorporating prior knowledge.</li><li class="ql-align-justify">Generative AI and Bayesian deep learning can inform each other.</li><li class="ql-align-justify">The complexity of a problem influences the choice between Bayesian and traditional deep learning.</li><li class="ql-align-justify">Meta-learning enhances the efficiency of Bayesian models.</li><li class="ql-align-justify">PAC-Bayesian theory merges Bayesian and frequentist ideas.</li><li class="ql-align-justify">Laplace inference offers a cost-effective approximation.</li><li class="ql-align-justify">Subspace inference can optimize parameter efficiency.</li><li class="ql-align-justify">Bayesian deep learning is crucial for reliable predictions.</li><li class="ql-align-justify">Effective communication of uncertainty is essential.</li><li class="ql-align-justify">Realistic benchmarks are needed for Bayesian methods</li><li class="ql-align-justify">Collaboration and communication in the AI community are vital.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p>00:00 Introduction to Bayesian Deep Learning</p><p>06:12 Vincent's Journey into Machine Learning</p><p>12:42 Defining Bayesian Deep Learning</p><p>17:23 Current Landscape of Bayesian Libraries</p><p>22:02 Real-World Applications of Bayesian Deep Learning</p><p>24:29 When to Use Bayesian Deep Learning</p><p>29:36 Data Efficient AI and Generative Modeling</p><p>31:59 Exploring Generative AI and Meta-Learning</p><p>34:19 Understanding Bayesian Deep Learning and Prior Knowledge</p><p>39:01 Algorithms for Bayesian Deep Learning Models</p><p>43:25 Advancements in Efficient Inference Techniques</p><p>49:35 The Future of AI Models and Reliability</p><p>52:47 Advice for Aspiring Researchers in AI</p><p>56:06 Future Projects and Research Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Vincent’s website: <a href="https://fortuin.github.io/" rel="noopener noreferrer" target="_blank">https://fortuin.github.io/</a></li><li>Vincent on Linkedin: <a href="https://www.linkedin.com/in/vincent-fortuin-42426b134/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/vincent-fortuin-42426b134/</a></li><li>Vincent on GitHub: <a href="https://github.com/fortuin" rel="noopener noreferrer" target="_blank">https://github.com/fortuin</a></li><li>Vincent on Medium: <a href="https://medium.com/@vincefort" rel="noopener noreferrer" target="_blank">https://medium.com/@vincefort</a></li><li>Vincent on BlueSky: <a href="https://bsky.app/profile/vincefort.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/vincefort.bsky.social</a>&nbsp;</li><li>LBS #107 Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/</a></li><li>Position paper on Bayesian deep learning: <a href="https://proceedings.mlr.press/v235/papamarkou24b.html" rel="noopener noreferrer" target="_blank">https://proceedings.mlr.press/v235/papamarkou24b.html</a></li><li>Position paper on generative AI: <a href="https://arxiv.org/abs/2403.00025" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2403.00025</a></li><li>BNN review paper: <a href="https://arxiv.org/abs/2309.16314" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2309.16314</a></li><li>Priors in BDL review paper: <a href="https://onlinelibrary.wiley.com/doi/10.1111/insr.12502" rel="noopener noreferrer" target="_blank">https://onlinelibrary.wiley.com/doi/10.1111/insr.12502</a></li><li>BayesFlow: <a href="https://bayesflow.org/" rel="noopener noreferrer" target="_blank">https://bayesflow.org/</a></li><li>BayesianTorch: <a href="https://github.com/IntelLabs/bayesian-torch" rel="noopener noreferrer" target="_blank">https://github.com/IntelLabs/bayesian-torch</a></li><li>Laplace Torch: <a href="https://aleximmer.github.io/Laplace/" rel="noopener noreferrer" target="_blank">https://aleximmer.github.io/Laplace/</a></li><li>TyXe: <a href="https://github.com/TyXe-BDL/TyXe" rel="noopener noreferrer" target="_blank">https://github.com/TyXe-BDL/TyXe</a>&nbsp;</li><li>Introduction to PAC-Bayes: <a href="https://arxiv.org/abs/2110.11216" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2110.11216</a></li><li>Training GPT2 with Bayesian methods: <a href="https://proceedings.mlr.press/v235/shen24b.html" rel="noopener noreferrer" target="_blank">https://proceedings.mlr.press/v235/shen24b.html</a></li><li>Bayesian fine-tuning for LLMs: <a href="https://arxiv.org/abs/2405.03425" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2405.03425</a>&nbsp;</li><li>Try out NormalizingFlow initialization with Nutpie: <a href="https://discourse.pymc.io/t/new-experimental-sampling-algorithm-fisher-hmc-in-nutpie-for-pymc-and-stan-models/16114/5" rel="noopener noreferrer" target="_blank">https://discourse.pymc.io/t/new-experimental-sampling-algorithm-fisher-hmc-in-nutpie-for-pymc-and-stan-models/16114/5</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/129-bayesian-deep-learning-ai-for-science-vincent-fortuin]]></link><guid isPermaLink="false">734cdd21-0c4d-47b1-827f-7de8d411733e</guid><itunes:image href="https://artwork.captivate.fm/771513a6-3238-4102-9ff2-64c2591afc17/IbDKhx6kZ2-F20oC-rCugjH3.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 02 Apr 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/48786278-a7ff-4090-861b-7aca24e45173/riverside-episode-129-mp4-apr-9-2025-001-lbs-studio.mp3" length="30101229" type="audio/mpeg"/><itunes:duration>01:02:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>129</itunes:episode><itunes:season>1</itunes:season><podcast:episode>129</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/f27ca21b-793d-4f85-aa1d-3ff756a86d52/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/f27ca21b-793d-4f85-aa1d-3ff756a86d52/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#129 Bayesian Deep Learning &amp; AI for Science with Vincent Fortuin"><podcast:source uri="https://youtu.be/vrT2CjKLT3Y"/></podcast:alternateEnclosure></item><item><title>#128 Building a Winning Data Team in Football, with Matt Penn</title><itunes:title>Building a Winning Data Team in Football, with Matt Penn</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Matt emphasizes the importance of Bayesian statistics in scenarios with limited data.</li><li class="ql-align-justify">Communicating insights to coaches is a crucial skill for data analysts.</li><li class="ql-align-justify">Building a data team requires understanding the needs of the coaching staff.</li><li class="ql-align-justify">Player recruitment is a significant focus in football analytics.</li><li class="ql-align-justify">The integration of data science in sports is still evolving.</li><li class="ql-align-justify">Effective data modeling must consider the practical application in games.</li><li class="ql-align-justify">Collaboration between data analysts and coaches enhances decision-making.</li><li class="ql-align-justify">Having a robust data infrastructure is essential for efficient analysis.</li><li class="ql-align-justify">The landscape of sports analytics is becoming increasingly competitive.&nbsp;</li><li class="ql-align-justify">Player recruitment involves analyzing various data models.</li><li class="ql-align-justify">Biases in traditional football statistics can skew player evaluations.</li><li class="ql-align-justify">Statistical techniques should leverage the structure of football data.</li><li class="ql-align-justify">Tracking data opens new avenues for understanding player movements.</li><li class="ql-align-justify">The role of data analysis in football will continue to grow.</li><li class="ql-align-justify">Aspiring analysts should focus on curiosity and practical experience.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Football Analytics and Matt's Journey</p><p class="ql-align-justify">04:54 The Role of Bayesian Methods in Football</p><p class="ql-align-justify">10:20 Challenges in Communicating Data Insights</p><p class="ql-align-justify">17:03 Building Relationships with Coaches</p><p class="ql-align-justify">22:09 The Structure of the Data Team at Como</p><p class="ql-align-justify">26:18 Focus on Player Recruitment and Transfer Strategies</p><p class="ql-align-justify">28:48 January Transfer Window Insights</p><p class="ql-align-justify">30:54 Biases in Football Data Analysis</p><p class="ql-align-justify">34:11 Comparative Analysis of Men's and Women's Football</p><p class="ql-align-justify">36:55 Statistical Techniques in Football Analysis</p><p class="ql-align-justify">42:48 The Impact of Tracking Data on Football Analysis</p><p class="ql-align-justify">45:49 The Future of Data-Driven Football Strategies</p><p class="ql-align-justify">47:27 Advice for Aspiring Football Analysts</p><p...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Matt emphasizes the importance of Bayesian statistics in scenarios with limited data.</li><li class="ql-align-justify">Communicating insights to coaches is a crucial skill for data analysts.</li><li class="ql-align-justify">Building a data team requires understanding the needs of the coaching staff.</li><li class="ql-align-justify">Player recruitment is a significant focus in football analytics.</li><li class="ql-align-justify">The integration of data science in sports is still evolving.</li><li class="ql-align-justify">Effective data modeling must consider the practical application in games.</li><li class="ql-align-justify">Collaboration between data analysts and coaches enhances decision-making.</li><li class="ql-align-justify">Having a robust data infrastructure is essential for efficient analysis.</li><li class="ql-align-justify">The landscape of sports analytics is becoming increasingly competitive.&nbsp;</li><li class="ql-align-justify">Player recruitment involves analyzing various data models.</li><li class="ql-align-justify">Biases in traditional football statistics can skew player evaluations.</li><li class="ql-align-justify">Statistical techniques should leverage the structure of football data.</li><li class="ql-align-justify">Tracking data opens new avenues for understanding player movements.</li><li class="ql-align-justify">The role of data analysis in football will continue to grow.</li><li class="ql-align-justify">Aspiring analysts should focus on curiosity and practical experience.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Football Analytics and Matt's Journey</p><p class="ql-align-justify">04:54 The Role of Bayesian Methods in Football</p><p class="ql-align-justify">10:20 Challenges in Communicating Data Insights</p><p class="ql-align-justify">17:03 Building Relationships with Coaches</p><p class="ql-align-justify">22:09 The Structure of the Data Team at Como</p><p class="ql-align-justify">26:18 Focus on Player Recruitment and Transfer Strategies</p><p class="ql-align-justify">28:48 January Transfer Window Insights</p><p class="ql-align-justify">30:54 Biases in Football Data Analysis</p><p class="ql-align-justify">34:11 Comparative Analysis of Men's and Women's Football</p><p class="ql-align-justify">36:55 Statistical Techniques in Football Analysis</p><p class="ql-align-justify">42:48 The Impact of Tracking Data on Football Analysis</p><p class="ql-align-justify">45:49 The Future of Data-Driven Football Strategies</p><p class="ql-align-justify">47:27 Advice for Aspiring Football Analysts</p><p class="ql-align-justify">51:29 Future Projects in Football Analytics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia, Michael Cao, Yiğit Aşık and Suyog Chandramouli</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Matt on Linkedin: <a href="https://www.linkedin.com/in/matthew-penn-732551232/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/matthew-penn-732551232/</a></li><li>Matt on Google Scholar: <a href="https://scholar.google.com/citations?user=oY7jC7UAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=oY7jC7UAAAAJ&amp;hl=en</a></li><li>LBS #117, Unveiling the Power of Bayesian Experimental Design, with Desi Ivanova: <a href="https://learnbayesstats.com/episode/117-unveiling-power-bayesian-experimental-design-desi-ivanova/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/117-unveiling-power-bayesian-experimental-design-desi-ivanova/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/128-building-winning-data-team-football-matt-penn]]></link><guid isPermaLink="false">c0a80c03-fd50-407a-8a2f-09e15608ee92</guid><itunes:image href="https://artwork.captivate.fm/12b01376-e472-4310-ab5b-2529d094cc79/9BunljFW45kGNVONVU8Zo0P3.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 19 Mar 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/93381811-5aa3-440b-aea6-259742b683e3/episode-128-MP3.mp3" length="111717451" type="audio/mpeg"/><itunes:duration>58:11</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>128</itunes:episode><itunes:season>1</itunes:season><podcast:episode>128</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/c5682806-2baf-4111-8c2c-12f3ef2dd8db/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/c5682806-2baf-4111-8c2c-12f3ef2dd8db/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#128 Building a Winning Data Team in Football, with Matt Penn"><podcast:source uri="https://youtu.be/DtJhWPFvwp4"/></podcast:alternateEnclosure></item><item><title>#127 Saving Sharks... with Python, Causal Inference and Aaron MacNeil</title><itunes:title>Saving Sharks... with Python, Causal Inference and Aaron MacNeil</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia and Michael Cao</em>.</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Sharks play a crucial role in maintaining healthy ocean ecosystems.</li><li class="ql-align-justify">Bayesian statistics are particularly useful in data-poor environments like ecology.</li><li class="ql-align-justify">Teaching Bayesian statistics requires a shift in mindset from traditional statistical methods.</li><li class="ql-align-justify">The shark meat trade is significant and often overlooked.</li><li class="ql-align-justify">Ray meat trade is as large as shark meat trade, with specific markets dominating.</li><li class="ql-align-justify">Understanding the ecological roles of species is essential for effective conservation.</li><li class="ql-align-justify">Causal language is important in ecological research and should be encouraged.</li><li class="ql-align-justify">Evidence-driven decision-making is crucial in balancing human and ecological needs.</li><li class="ql-align-justify">Expert opinions are...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia and Michael Cao</em>.</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Sharks play a crucial role in maintaining healthy ocean ecosystems.</li><li class="ql-align-justify">Bayesian statistics are particularly useful in data-poor environments like ecology.</li><li class="ql-align-justify">Teaching Bayesian statistics requires a shift in mindset from traditional statistical methods.</li><li class="ql-align-justify">The shark meat trade is significant and often overlooked.</li><li class="ql-align-justify">Ray meat trade is as large as shark meat trade, with specific markets dominating.</li><li class="ql-align-justify">Understanding the ecological roles of species is essential for effective conservation.</li><li class="ql-align-justify">Causal language is important in ecological research and should be encouraged.</li><li class="ql-align-justify">Evidence-driven decision-making is crucial in balancing human and ecological needs.</li><li class="ql-align-justify">Expert opinions are crucial for understanding species composition in landings.</li><li class="ql-align-justify">Trade dynamics are influenced by import preferences and species availability.</li><li class="ql-align-justify">Bayesian modeling allows for the incorporation of various data sources and expert knowledge.</li><li class="ql-align-justify">Field data collection is essential for validating model assumptions.</li><li class="ql-align-justify">The complexity of trade relationships necessitates a nuanced approach to modeling.</li><li class="ql-align-justify">Understanding the impact of management interventions on landings is critical.</li><li class="ql-align-justify">The role of scientists in informing policy is vital for effective conservation efforts.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Marine Biology and Statistics</p><p class="ql-align-justify">04:33 The Role of Bayesian Statistics in Marine Research</p><p class="ql-align-justify">10:09 Challenges in Teaching Bayesian Statistics</p><p class="ql-align-justify">21:58 The Importance of Sharks in Ecosystems</p><p class="ql-align-justify">26:35 Understanding Shark Meat Trade and Conservation</p><p class="ql-align-justify">32:09 The Trade in Ray and Shark Meat</p><p class="ql-align-justify">36:18 Modeling Landings and Trade</p><p class="ql-align-justify">42:56 Challenges in Data Integration</p><p class="ql-align-justify">44:50 Running Complex Models</p><p class="ql-align-justify">51:57 Expert Elicitation and Prior Construction</p><p class="ql-align-justify">55:52 Future Directions and Research</p><p class="ql-align-justify">56:46 Reflections on Science and Policy</p><p><strong>Links from the show:</strong></p><ul><li>Fisheries Lab: <a href="https://ifisheries.org/?page_id=83" rel="noopener noreferrer" target="_blank">https://ifisheries.org/?page_id=83</a></li><li>LBS #51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/127-saving-sharks-python-causal-inference-aaron-macneil]]></link><guid isPermaLink="false">98cb47ca-c1c0-4879-a05a-8f62e8587145</guid><itunes:image href="https://artwork.captivate.fm/9ecae387-77d5-4b3a-b291-81c389c3cec2/YT9F4hejqB-C4aXl-h79KNrh.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 05 Mar 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/dc85f794-1ce8-48b5-8535-5a8de182fe08/episode-127-MP3.mp3" length="123177404" type="audio/mpeg"/><itunes:duration>01:04:08</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>127</itunes:episode><itunes:season>1</itunes:season><podcast:episode>127</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/2ff57b76-bc0c-4ba8-b731-ae1f44297d4b/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/2ff57b76-bc0c-4ba8-b731-ae1f44297d4b/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#127 Saving Sharks... with Python, Causal Inference and Aaron MacNeil"><podcast:source uri="https://youtu.be/0b2uUjpz3q4"/></podcast:alternateEnclosure></item><item><title>#126 MMM, CLV &amp; Bayesian Marketing Analytics, with Will Dean</title><itunes:title>MMM, CLV &amp; Bayesian Marketing Analytics, with Will Dean</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Marketing analytics is crucial for understanding customer behavior.</li><li class="ql-align-justify">PyMC Marketing offers tools for customer lifetime value analysis.</li><li class="ql-align-justify">Media mix modeling helps allocate marketing spend effectively.</li><li class="ql-align-justify">Customer Lifetime Value (CLV) models are essential for understanding long-term customer behavior.</li><li class="ql-align-justify">Productionizing models is essential for real-world applications.</li><li class="ql-align-justify">Productionizing models involves challenges like model artifact storage and version control.</li><li class="ql-align-justify">MLflow integration enhances model tracking and management.</li><li class="ql-align-justify">The open-source community fosters collaboration and innovation.</li><li class="ql-align-justify">Understanding time series is vital in marketing analytics.</li><li class="ql-align-justify">Continuous learning is key in the evolving field of data science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Will Dean and His Work</p><p class="ql-align-justify">10:48 Diving into PyMC Marketing</p><p class="ql-align-justify">17:10 Understanding Media Mix Modeling</p><p class="ql-align-justify">25:54 Challenges in Productionizing Models</p><p class="ql-align-justify">35:27 Exploring Customer Lifetime Value Models</p><p class="ql-align-justify">44:10 Learning and Development in Data Science</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Marketing analytics is crucial for understanding customer behavior.</li><li class="ql-align-justify">PyMC Marketing offers tools for customer lifetime value analysis.</li><li class="ql-align-justify">Media mix modeling helps allocate marketing spend effectively.</li><li class="ql-align-justify">Customer Lifetime Value (CLV) models are essential for understanding long-term customer behavior.</li><li class="ql-align-justify">Productionizing models is essential for real-world applications.</li><li class="ql-align-justify">Productionizing models involves challenges like model artifact storage and version control.</li><li class="ql-align-justify">MLflow integration enhances model tracking and management.</li><li class="ql-align-justify">The open-source community fosters collaboration and innovation.</li><li class="ql-align-justify">Understanding time series is vital in marketing analytics.</li><li class="ql-align-justify">Continuous learning is key in the evolving field of data science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Will Dean and His Work</p><p class="ql-align-justify">10:48 Diving into PyMC Marketing</p><p class="ql-align-justify">17:10 Understanding Media Mix Modeling</p><p class="ql-align-justify">25:54 Challenges in Productionizing Models</p><p class="ql-align-justify">35:27 Exploring Customer Lifetime Value Models</p><p class="ql-align-justify">44:10 Learning and Development in Data Science</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire, Mike Loncaric, David McCormick, Ronald Legere, Sergio Dolia and Michael Cao</em>.</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Get your ticket for Field of Play: <a href="https://www.fieldofplay.co.uk/tickets" rel="noopener noreferrer" target="_blank">https://www.fieldofplay.co.uk/tickets</a></li><li class="ql-align-justify">Will's website: <a href="https://wd60622.github.io/blog/" rel="noopener noreferrer" target="_blank">https://wd60622.github.io/blog/</a></li><li class="ql-align-justify">Will on GitHub: <a href="https://github.com/wd60622/" rel="noopener noreferrer" target="_blank">https://github.com/wd60622/</a></li><li class="ql-align-justify">Will on Linkedin: <a href="https://www.linkedin.com/in/williambdean/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/williambdean/</a></li><li class="ql-align-justify">PyMC-Marketing: <a href="https://www.pymc-marketing.io/en/stable/" rel="noopener noreferrer" target="_blank">https://www.pymc-marketing.io/en/stable/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/126-mmm-clv-bayesian-marketing-analytics-will-dean]]></link><guid isPermaLink="false">a8008b92-7601-467e-a32c-c6bb57e52035</guid><itunes:image href="https://artwork.captivate.fm/b272f1ee-1457-4424-8d39-23c6790a71f7/nc4Qq7L8Gb5CKGBACPiuf1AO.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 19 Feb 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f76b3740-0cd2-4e9e-b140-a28a287c4994/episode-126-MP3.mp3" length="105208249" type="audio/mpeg"/><itunes:duration>54:47</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>126</itunes:episode><itunes:season>1</itunes:season><podcast:episode>126</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/73327d09-b978-40d9-87ee-2a1f5215716c/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/73327d09-b978-40d9-87ee-2a1f5215716c/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#126 MMM, CLV &amp; Bayesian Marketing Analytics, with Will Dean"><podcast:source uri="https://youtu.be/VzZMW13RxF8"/></podcast:alternateEnclosure></item><item><title>#125 Bayesian Sports Analytics &amp; The Future of PyMC, with Chris Fonnesbeck</title><itunes:title>Bayesian Sports Analytics &amp; The Future of PyMC, with Chris Fonnesbeck</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire and Mike Loncaric.</em></p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">The evolution of sports modeling is tied to the availability of high-frequency data.</li><li class="ql-align-justify">Bayesian methods are valuable in handling messy, hierarchical data.</li><li class="ql-align-justify">Communication between data scientists and decision-makers is crucial for effective model use.</li><li class="ql-align-justify">Models are often wrong, and learning from mistakes is part of the process.</li><li class="ql-align-justify">Simplicity in models can sometimes yield better results than complexity.</li><li class="ql-align-justify">The integration of analytics in sports is still developing, with opportunities in various sports.</li><li class="ql-align-justify">Transparency in research and development teams enhances decision-making.</li><li class="ql-align-justify">Understanding uncertainty in models is essential for informed decisions.</li><li class="ql-align-justify">The balance between point estimates and full distributions is a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://topmate.io/alex_andorra/503302" rel="noopener noreferrer" target="_blank">Intro to Bayes Course</a> (first 2 lessons free)</li><li><a href="https://topmate.io/alex_andorra/1011122" rel="noopener noreferrer" target="_blank">Advanced Regression Course</a> (first 2 lessons free)</li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire and Mike Loncaric.</em></p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">The evolution of sports modeling is tied to the availability of high-frequency data.</li><li class="ql-align-justify">Bayesian methods are valuable in handling messy, hierarchical data.</li><li class="ql-align-justify">Communication between data scientists and decision-makers is crucial for effective model use.</li><li class="ql-align-justify">Models are often wrong, and learning from mistakes is part of the process.</li><li class="ql-align-justify">Simplicity in models can sometimes yield better results than complexity.</li><li class="ql-align-justify">The integration of analytics in sports is still developing, with opportunities in various sports.</li><li class="ql-align-justify">Transparency in research and development teams enhances decision-making.</li><li class="ql-align-justify">Understanding uncertainty in models is essential for informed decisions.</li><li class="ql-align-justify">The balance between point estimates and full distributions is a challenge.</li><li class="ql-align-justify">Iterative model development is key to improving analytics in sports.</li><li class="ql-align-justify">It's important to avoid falling in love with a single model.</li><li class="ql-align-justify">Data simulation can validate model structures before real data is used.</li><li class="ql-align-justify">Gaussian processes offer flexibility in modeling without strict functional forms.</li><li class="ql-align-justify">Structural time series help separate projection from observation noise.</li><li class="ql-align-justify">Transitioning from sports analytics to consulting opens new opportunities.</li><li class="ql-align-justify">Continuous learning is essential in the field of statistics.</li><li class="ql-align-justify">The demand for Bayesian methods is growing across various industries.</li><li class="ql-align-justify">Community-driven projects can lead to innovative solutions.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">03:07 The Evolution of Modeling in Sports Analytics</p><p class="ql-align-justify">06:03 Transitioning from Academia to Sports Modeling</p><p class="ql-align-justify">08:56 The Role of Bayesian Methods in Sports Analytics</p><p class="ql-align-justify">11:49 Communicating Models and Insights to Decision Makers</p><p class="ql-align-justify">15:12 Learning from Mistakes in Model Development</p><p class="ql-align-justify">18:06 The Importance of Model Flexibility and Iteration</p><p class="ql-align-justify">21:02 Utilizing Simulation for Model Validation</p><p class="ql-align-justify">23:50 Choosing the Right Model Structure for Data</p><p class="ql-align-justify">27:04 Starting with Simple Models and Building Complexity</p><p class="ql-align-justify">29:29 Advancements in Gaussian Processes and PyMC</p><p class="ql-align-justify">31:54 Exploring Structural Time Series and GPs</p><p class="ql-align-justify">37:34 Transitioning to PyMC Labs and New Opportunities</p><p class="ql-align-justify">42:40 Innovations in Variational Inference Methods</p><p class="ql-align-justify">48:50 Future Vision for PyMC and Community Engagement</p><p class="ql-align-justify">50:43 Surprises in Bayesian Methods Adoption</p><p class="ql-align-justify">54:08 Reflections on Problem Solving and Influential Figures</p><p><strong>Links from the show:</strong></p><ul><li>Alex's and Chris’ GP tutorial at PyData NYC: <a href="https://youtu.be/u6I5pN_Q6r4?si=5IzrQB_0k30Rmzhu" rel="noopener noreferrer" target="_blank">https://youtu.be/u6I5pN_Q6r4?si=5IzrQB_0k30Rmzhu</a></li><li class="ql-align-justify">Chris on GitHub: <a href="https://github.com/fonnesbeck" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck</a></li><li class="ql-align-justify">Chris on Linkedin: <a href="https://www.linkedin.com/in/christopher-fonnesbeck-374a492a/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/christopher-fonnesbeck-374a492a/</a></li><li class="ql-align-justify">Chris on Blue Sky: <a href="https://bsky.app/profile/fonnesbeck.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/fonnesbeck.bsky.social</a></li><li>Developing Hierarchical Models for Sports Analytics: <a href="https://www.pymc-labs.com/blog-posts/2023-09-15-Hierarchical-models-Chris-Fonnesbeck/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.com/blog-posts/2023-09-15-Hierarchical-models-Chris-Fonnesbeck/</a></li><li>Beyond Moneyball: Phillies Data Scientist Give Students a Real-World Look at How Today’s MLB Teams Use Data: <a href="https://datascience.virginia.edu/news/beyond-moneyball-phillies-data-scientist-give-students-real-world-look-how-todays-mlb-teams" rel="noopener noreferrer" target="_blank">https://datascience.virginia.edu/news/beyond-moneyball-phillies-data-scientist-give-students-real-world-look-how-todays-mlb-teams</a></li><li>HSGP Reference &amp; First Steps: <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html</a></li><li>HSGP Advanced Usage: <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Advanced.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Advanced.html</a></li><li>Data simulation with PyMC: <a href="https://tomicapretto.com/posts/2024-11-01_pymc-data-simulation/" rel="noopener noreferrer" target="_blank">https://tomicapretto.com/posts/2024-11-01_pymc-data-simulation/</a></li><li>LBS #124 State Space Models &amp; Structural Time Series, with Jesse Grabowski: <a href="https://learnbayesstats.com/episode/124-state-space-models-structural-time-series-jesse-grabowski" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/124-state-space-models-structural-time-series-jesse-grabowski</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/125-bayesian-sports-analytics-future-of-pymc-chris-fonnesbeck]]></link><guid isPermaLink="false">3d601a87-ff38-40e3-a007-7cfb0bac72f4</guid><itunes:image href="https://artwork.captivate.fm/36bb4ba1-e04e-4e52-9b29-03b0aa1919d6/odBXiHBtsXSVJNKo5yDcmNnI.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 05 Feb 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/8c36f93a-e380-4cee-a32e-500dd96cd550/episode-125-mp3.mp3" length="111854193" type="audio/mpeg"/><itunes:duration>58:15</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>125</itunes:episode><itunes:season>1</itunes:season><podcast:episode>125</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/3d944167-99b6-4955-84a9-cec1dcc3bb25/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/3d944167-99b6-4955-84a9-cec1dcc3bb25/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#125 Bayesian Sports Analytics &amp; The Future of PyMC, with Chris Fonnesbeck"><podcast:source uri="https://youtu.be/1vIwpwDRkJ4"/></podcast:alternateEnclosure></item><item><title>#124 State Space Models &amp; Structural Time Series, with Jesse Grabowski</title><itunes:title>State Space Models &amp; Structural Time Series, with Jesse Grabowski</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Bayesian statistics offers a robust framework for econometric modeling.</li><li class="ql-align-justify">State space models provide a comprehensive way to understand time series data.</li><li class="ql-align-justify">Gaussian random walks serve as a foundational model in time series analysis.</li><li class="ql-align-justify">Innovations represent external shocks that can significantly impact forecasts.</li><li class="ql-align-justify">Understanding the assumptions behind models is key to effective forecasting.</li><li class="ql-align-justify">Complex models are not always better; simplicity can be powerful.</li><li class="ql-align-justify">Forecasting requires careful consideration of potential disruptions. Understanding observed and hidden states is crucial in modeling.</li><li class="ql-align-justify">Latent abilities can be modeled as Gaussian random walks.</li><li class="ql-align-justify">State space models can be highly flexible and diverse.</li><li class="ql-align-justify">Composability allows for the integration of different model components.</li><li class="ql-align-justify">Trends in time series should reflect real-world dynamics.</li><li class="ql-align-justify">Seasonality can be captured through Fourier bases.</li><li class="ql-align-justify">AR components help model residuals in time series data.</li><li class="ql-align-justify">Exogenous regression components can enhance state space models.</li><li class="ql-align-justify">Causal analysis in time series often involves interventions and counterfactuals.</li><li class="ql-align-justify">Time-varying regression allows for dynamic relationships between variables.</li><li class="ql-align-justify">Kalman filters were originally developed for tracking rockets in space.</li><li class="ql-align-justify">The Kalman filter iteratively updates beliefs based on new data.</li><li class="ql-align-justify">Missing data can be treated as hidden states in the Kalman filter framework.</li><li class="ql-align-justify">The Kalman filter is a practical application of Bayes' theorem in a sequential context.</li><li class="ql-align-justify">Understanding the dynamics of systems is crucial for effective modeling.</li><li class="ql-align-justify">The state space module in PyMC simplifies complex time series modeling tasks.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Jesse Krabowski and Time Series Analysis</p><p class="ql-align-justify">04:33 Jesse's Journey into Bayesian Statistics</p><p class="ql-align-justify">10:51 Exploring State Space Models</p><p class="ql-align-justify">18:28 Understanding State Space Models and Their Components</p><p...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">Bayesian statistics offers a robust framework for econometric modeling.</li><li class="ql-align-justify">State space models provide a comprehensive way to understand time series data.</li><li class="ql-align-justify">Gaussian random walks serve as a foundational model in time series analysis.</li><li class="ql-align-justify">Innovations represent external shocks that can significantly impact forecasts.</li><li class="ql-align-justify">Understanding the assumptions behind models is key to effective forecasting.</li><li class="ql-align-justify">Complex models are not always better; simplicity can be powerful.</li><li class="ql-align-justify">Forecasting requires careful consideration of potential disruptions. Understanding observed and hidden states is crucial in modeling.</li><li class="ql-align-justify">Latent abilities can be modeled as Gaussian random walks.</li><li class="ql-align-justify">State space models can be highly flexible and diverse.</li><li class="ql-align-justify">Composability allows for the integration of different model components.</li><li class="ql-align-justify">Trends in time series should reflect real-world dynamics.</li><li class="ql-align-justify">Seasonality can be captured through Fourier bases.</li><li class="ql-align-justify">AR components help model residuals in time series data.</li><li class="ql-align-justify">Exogenous regression components can enhance state space models.</li><li class="ql-align-justify">Causal analysis in time series often involves interventions and counterfactuals.</li><li class="ql-align-justify">Time-varying regression allows for dynamic relationships between variables.</li><li class="ql-align-justify">Kalman filters were originally developed for tracking rockets in space.</li><li class="ql-align-justify">The Kalman filter iteratively updates beliefs based on new data.</li><li class="ql-align-justify">Missing data can be treated as hidden states in the Kalman filter framework.</li><li class="ql-align-justify">The Kalman filter is a practical application of Bayes' theorem in a sequential context.</li><li class="ql-align-justify">Understanding the dynamics of systems is crucial for effective modeling.</li><li class="ql-align-justify">The state space module in PyMC simplifies complex time series modeling tasks.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Jesse Krabowski and Time Series Analysis</p><p class="ql-align-justify">04:33 Jesse's Journey into Bayesian Statistics</p><p class="ql-align-justify">10:51 Exploring State Space Models</p><p class="ql-align-justify">18:28 Understanding State Space Models and Their Components</p><p class="ql-align-justify">40:39 Composability of State Space Models</p><p class="ql-align-justify">48:36 Understanding Trends and Derivatives</p><p class="ql-align-justify">52:35 The Importance of Seasonality in Time Series</p><p class="ql-align-justify">56:41 Components of Time Series Analysis</p><p class="ql-align-justify">01:00:46 Exogenous Regression in State Space Models</p><p class="ql-align-justify">01:06:41 Impulse Response Functions and Causality</p><p class="ql-align-justify">01:11:30 Why Kalman Filter Is So Powerful</p><p class="ql-align-justify">01:24:28 Future Directions and Applications</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire and Mike Loncaric.</em></p><p><strong>Links from the show:</strong></p><ul><li>Jesse on GitHub: <a href="https://github.com/jessegrabowski" rel="noopener noreferrer" target="_blank">https://github.com/jessegrabowski</a></li><li>Jesse on LinkedIn: <a href="http://www.linkedin.com/in/jessegrabowski" rel="noopener noreferrer" target="_blank">www.linkedin.com/in/jessegrabowski</a></li><li>Jesse on Google Scholar: <a href="https://scholar.google.com/citations?user=vOCjGPwAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=vOCjGPwAAAAJ&amp;hl=en</a></li><li>State space presentation repo: <a href="https://github.com/jessegrabowski/statespace-presentation/tree/main" rel="noopener noreferrer" target="_blank">https://github.com/jessegrabowski/statespace-presentation/tree/main</a></li><li>Try the statespace module on pymc-experimental: <a href="https://github.com/pymc-devs/pymc-experimental" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc-experimental</a></li><li class="ql-align-justify">Durbin, James, and Siem Jan Koopman. <em>Time series analysis by state space methods</em>, Oxford, 2012: <a href="https://academic.oup.com/book/16563?login=false" rel="noopener noreferrer" target="_blank">https://academic.oup.com/book/16563?login=false</a></li><li class="ql-align-justify">Hyndman, Rob and George Athanasopoulos, <em>Forecasting: Principals and Practice, 3rd Edition</em>. Otexts, 2018: <a href="https://otexts.com/fpp3/" rel="noopener noreferrer" target="_blank">https://otexts.com/fpp3/</a></li><li>Roger Labbe, <em>Kalman and Bayesian Filters in Python</em>: <a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python" rel="noopener noreferrer" target="_blank">https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python</a></li><li>Quantecon.org: <a href="https://quantecon.org/" rel="noopener noreferrer" target="_blank">https://quantecon.org/</a></li><li>Lecture on Kalman Filtering: <a href="https://python.quantecon.org/kalman.html" rel="noopener noreferrer" target="_blank">https://python.quantecon.org/kalman.html</a></li><li>Mamba – Linear-Time Sequence Modeling with State Spaces (state spaces in machine learning): <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbmpKcS0zRW9MSmZkeTgzaDRTeFZJRHp0b3NWQXxBQ3Jtc0trbDM1bU12YXJISmluN25UbmRJQ0JpNGdqR2tvX2VNRUJnNmJseDQ4UUtZMkhhVGpXc3ZwVXBBSTBqdERGRUdRY2VnbkpuZktzVTJCdGRHaUMyVUl1MlBad0lzM3pGNjUwMTBubkg3cGw2NXJDaFN0bw&amp;q=https%3A%2F%2Farxiv.org%2Fabs%2F2312.00752&amp;v=9dSkvxS2EB0" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2312.00752</a></li><li>Paper explanation: <a href="https://www.youtube.com/watch?v=9dSkvxS2EB0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=9dSkvxS2EB0</a></li><li>Good lecture on the statistics of the Kalman filter: <a href="https://www.youtube.com/watch?v=8lPBkkbtNW8" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=8lPBkkbtNW8</a></li><li>And on structural state space models: <a href="https://www.youtube.com/watch?v=2vf-d_fRCXs" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=2vf-d_fRCXs</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/124-state-space-models-structural-time-series-jesse-grabowski]]></link><guid isPermaLink="false">1a853892-ecfb-423e-9712-17efc2228d7a</guid><itunes:image href="https://artwork.captivate.fm/5662e376-8354-4167-8861-73b0426af127/rj88iTgemxjWaLLkmvIZrUti.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 22 Jan 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/cd56c386-dd21-48d0-8331-c9e8fcec71da/episode-124-MP3.mp3" length="183813178" type="audio/mpeg"/><itunes:duration>01:35:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>124</itunes:episode><itunes:season>1</itunes:season><podcast:episode>124</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/892f0b56-ca45-4bc4-9031-7bc5e8ca3ebd/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/892f0b56-ca45-4bc4-9031-7bc5e8ca3ebd/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#124 State Space Models &amp; Structural Time Series, with Jesse Grabowski"><podcast:source uri="https://youtu.be/pP0ObLbCo5U"/></podcast:alternateEnclosure></item><item><title>#123 BART &amp; The Future of Bayesian Tools, with Osvaldo Martin</title><itunes:title>BART &amp; The Future of Bayesian Tools, with Osvaldo Martin</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">BART models are non-parametric Bayesian models that approximate functions by summing trees.</li><li class="ql-align-justify">BART is recommended for quick modeling without extensive domain knowledge.</li><li class="ql-align-justify">PyMC-BART allows mixing BART models with various likelihoods and other models.</li><li class="ql-align-justify">Variable importance can be easily interpreted using BART models.</li><li class="ql-align-justify">PreliZ aims to provide better tools for prior elicitation in Bayesian statistics.</li><li class="ql-align-justify">The integration of BART with Bambi could enhance exploratory modeling.</li><li class="ql-align-justify">Teaching Bayesian statistics involves practical problem-solving approaches.</li><li class="ql-align-justify">Future developments in PyMC-BART include significant speed improvements.</li><li class="ql-align-justify">Prior predictive distributions can aid in understanding model behavior.</li><li class="ql-align-justify">Interactive learning tools can enhance understanding of statistical concepts.</li><li class="ql-align-justify">Integrating PreliZ with PyMC improves workflow transparency.</li><li class="ql-align-justify">Arviz 1.0 is being completely rewritten for better usability.</li><li class="ql-align-justify">Prior elicitation is crucial in Bayesian modeling.</li><li class="ql-align-justify">Point intervals and forest plots are effective for visualizing complex data.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Osvaldo Martin and Bayesian Statistics</p><p class="ql-align-justify">08:12 Exploring Bayesian Additive Regression Trees (BART)</p><p class="ql-align-justify">18:45 Prior Elicitation and the PreliZ Package</p><p class="ql-align-justify">29:56 Teaching Bayesian Statistics and Future Directions</p><p class="ql-align-justify">45:59 Exploring Prior Predictive Distributions</p><p class="ql-align-justify">52:08 Interactive Modeling with PreliZ</p><p class="ql-align-justify">54:06 The Evolution of ArviZ</p><p class="ql-align-justify">01:01:23 Advancements in ArviZ 1.0</p><p class="ql-align-justify">01:06:20 Educational Initiatives in Bayesian Statistics</p><p class="ql-align-justify">01:12:33 The Future of Bayesian Methods</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><ul><li class="ql-align-justify">BART models are non-parametric Bayesian models that approximate functions by summing trees.</li><li class="ql-align-justify">BART is recommended for quick modeling without extensive domain knowledge.</li><li class="ql-align-justify">PyMC-BART allows mixing BART models with various likelihoods and other models.</li><li class="ql-align-justify">Variable importance can be easily interpreted using BART models.</li><li class="ql-align-justify">PreliZ aims to provide better tools for prior elicitation in Bayesian statistics.</li><li class="ql-align-justify">The integration of BART with Bambi could enhance exploratory modeling.</li><li class="ql-align-justify">Teaching Bayesian statistics involves practical problem-solving approaches.</li><li class="ql-align-justify">Future developments in PyMC-BART include significant speed improvements.</li><li class="ql-align-justify">Prior predictive distributions can aid in understanding model behavior.</li><li class="ql-align-justify">Interactive learning tools can enhance understanding of statistical concepts.</li><li class="ql-align-justify">Integrating PreliZ with PyMC improves workflow transparency.</li><li class="ql-align-justify">Arviz 1.0 is being completely rewritten for better usability.</li><li class="ql-align-justify">Prior elicitation is crucial in Bayesian modeling.</li><li class="ql-align-justify">Point intervals and forest plots are effective for visualizing complex data.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Osvaldo Martin and Bayesian Statistics</p><p class="ql-align-justify">08:12 Exploring Bayesian Additive Regression Trees (BART)</p><p class="ql-align-justify">18:45 Prior Elicitation and the PreliZ Package</p><p class="ql-align-justify">29:56 Teaching Bayesian Statistics and Future Directions</p><p class="ql-align-justify">45:59 Exploring Prior Predictive Distributions</p><p class="ql-align-justify">52:08 Interactive Modeling with PreliZ</p><p class="ql-align-justify">54:06 The Evolution of ArviZ</p><p class="ql-align-justify">01:01:23 Advancements in ArviZ 1.0</p><p class="ql-align-justify">01:06:20 Educational Initiatives in Bayesian Statistics</p><p class="ql-align-justify">01:12:33 The Future of Bayesian Methods</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire and Mike Loncaric.</em></p><p><strong>Links from the show:</strong></p><ul><li>LBS #1 Bayes, open-source and bioinformatics, with Osvaldo Martin: <a href="https://learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin/</a></li><li>LBS #58 Bayesian Modeling and Computation, with Osvaldo Martin, Ravin Kumar and Junpeng Lao: <a href="https://learnbayesstats.com/episode/58-bayesian-modeling-computation-osvaldo-martin-ravin-kumar-junpeng-lao/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/58-bayesian-modeling-computation-osvaldo-martin-ravin-kumar-junpeng-lao/</a></li><li>LBS #112 Advanced Bayesian Regression, with Tomi Capretto: <a href="https://learnbayesstats.com/episode/112-advanced-bayesian-regression-tomi-capretto/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/112-advanced-bayesian-regression-tomi-capretto/</a></li><li>Osvaldo's website: <a href="https://aloctavodia.github.io/" rel="noopener noreferrer" target="_blank">https://aloctavodia.github.io/</a></li><li>Osvaldo on GitHub: <a href="https://github.com/aloctavodia" rel="noopener noreferrer" target="_blank">https://github.com/aloctavodia</a></li><li>Osvaldo on LinkedIn: <a href="https://www.linkedin.com/in/osvaldo-martin-447a662b1/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/osvaldo-martin-447a662b1/</a></li><li>Osvaldo on Google Scholar: <a href="https://scholar.google.com/citations?user=WUvDNnkAAAAJ" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=WUvDNnkAAAAJ</a></li><li>Osvaldo on Mastodon: <a href="https://bayes.club/@aloctavodia" rel="noopener noreferrer" target="_blank">https://bayes.club/@aloctavodia</a></li><li>Osvaldo on BlueSky: <a href="https://bsky.app/profile/aloctavodia.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/aloctavodia.bsky.social</a></li><li>PyMC-BART package: <a href="https://www.pymc.io/projects/bart/en/latest/index.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/bart/en/latest/index.html</a></li><li>PyMC-BART paper: <a href="https://arxiv.org/abs/2206.03619" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2206.03619</a></li><li>PreliZ for prior elicitation: <a href="https://preliz.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://preliz.readthedocs.io/en/latest/</a></li><li>Prior Knowledge Elicitation: The Past, Present, and Future: <a href="https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Prior-Knowledge-Elicitation-The-Past-Present-and-Future/10.1214/23-BA1381.full" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Prior-Knowledge-Elicitation-The-Past-Present-and-Future/10.1214/23-BA1381.full</a></li><li>ArviZ 1.0 repository: <a href="https://arviz-plots.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://arviz-plots.readthedocs.io/en/latest/</a></li><li>Practical MCMC course: <a href="https://www.intuitivebayes.com/practical-mcmc" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/practical-mcmc</a></li><li>Cohort Retention Analysis with BART: <a href="https://juanitorduz.github.io/retention_bart/" rel="noopener noreferrer" target="_blank">https://juanitorduz.github.io/retention_bart/</a></li><li>HSGP Reference &amp; First Steps: <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html</a></li><li>HSGP Advanced Usage: <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Advanced.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Advanced.html</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/123-bart-future-of-bayesian-tools-osvaldo-martin]]></link><guid isPermaLink="false">0cacb666-58e4-442d-8300-cf187aad95af</guid><itunes:image href="https://artwork.captivate.fm/7f7458e7-787b-46d9-a176-be3da52d831d/gOigdswlqg5OERXnSQNBC4xg.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 10 Jan 2025 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/450a7af2-1253-4f9c-b063-620c11c897f3/Episode-123-mp3.mp3" length="177112467" type="audio/mpeg"/><itunes:duration>01:32:13</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>123</itunes:episode><itunes:season>1</itunes:season><podcast:episode>123</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/c13ee99a-b9b1-4cf0-8a3b-1d2f37ea481f/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/c13ee99a-b9b1-4cf0-8a3b-1d2f37ea481f/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#123 BART &amp; The Future of Bayesian Tools, with Osvaldo Martin"><podcast:source uri="https://youtu.be/7POdNknJ1Es"/></podcast:alternateEnclosure></item><item><title>#122 Learning and Teaching in the Age of AI, with Hugo Bowne-Anderson</title><itunes:title>Learning and Teaching in the Age of AI, with Hugo Bowne-Anderson</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Effective data science education requires feedback and rapid iteration.</li><li class="ql-align-justify">Building LLM applications presents unique challenges and opportunities.</li><li class="ql-align-justify">The software development lifecycle for AI differs from traditional methods.</li><li class="ql-align-justify">Collaboration between data scientists and software engineers is crucial.</li><li class="ql-align-justify">Hugo's new course focuses on practical applications of LLMs.</li><li class="ql-align-justify">Continuous learning is essential in the fast-evolving tech landscape.</li><li class="ql-align-justify">Engaging learners through practical exercises enhances education.</li><li class="ql-align-justify">POC purgatory refers to the challenges faced in deploying LLM-powered software.</li><li class="ql-align-justify">Focusing on first principles can help overcome integration issues in AI.</li><li class="ql-align-justify">Aspiring data scientists should prioritize problem-solving over specific tools.</li><li class="ql-align-justify">Engagement with different parts of an organization is crucial for data scientists.</li><li class="ql-align-justify">Quick paths to value generation can help gain buy-in for data projects.</li><li class="ql-align-justify">Multimodal models are an exciting trend in AI development.</li><li class="ql-align-justify">Probabilistic programming has potential for future growth in data science.</li><li class="ql-align-justify">Continuous learning and curiosity are vital in the evolving field of data science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">09:13 Hugo's Journey in Data Science and Education</p><p class="ql-align-justify">14:57 The Appeal of Bayesian Statistics</p><p class="ql-align-justify">19:36 Learning and Teaching in Data Science</p><p class="ql-align-justify">24:53 Key Ingredients for Effective Data Science Education</p><p class="ql-align-justify">28:44 Podcasting Journey and Insights</p><p class="ql-align-justify">36:10 Building LLM Applications: Course Overview</p><p class="ql-align-justify">42:08 Navigating the Software Development Lifecycle</p><p class="ql-align-justify">48:06 Overcoming Proof of Concept Purgatory</p><p class="ql-align-justify">55:35 Guidance for Aspiring Data Scientists</p><p class="ql-align-justify">01:03:25 Exciting Trends in Data Science and AI</p><p class="ql-align-justify">01:10:51 Balancing Multiple Roles in Data Science</p><p class="ql-align-justify">01:15:23 Envisioning Accessible Data Science for All</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Effective data science education requires feedback and rapid iteration.</li><li class="ql-align-justify">Building LLM applications presents unique challenges and opportunities.</li><li class="ql-align-justify">The software development lifecycle for AI differs from traditional methods.</li><li class="ql-align-justify">Collaboration between data scientists and software engineers is crucial.</li><li class="ql-align-justify">Hugo's new course focuses on practical applications of LLMs.</li><li class="ql-align-justify">Continuous learning is essential in the fast-evolving tech landscape.</li><li class="ql-align-justify">Engaging learners through practical exercises enhances education.</li><li class="ql-align-justify">POC purgatory refers to the challenges faced in deploying LLM-powered software.</li><li class="ql-align-justify">Focusing on first principles can help overcome integration issues in AI.</li><li class="ql-align-justify">Aspiring data scientists should prioritize problem-solving over specific tools.</li><li class="ql-align-justify">Engagement with different parts of an organization is crucial for data scientists.</li><li class="ql-align-justify">Quick paths to value generation can help gain buy-in for data projects.</li><li class="ql-align-justify">Multimodal models are an exciting trend in AI development.</li><li class="ql-align-justify">Probabilistic programming has potential for future growth in data science.</li><li class="ql-align-justify">Continuous learning and curiosity are vital in the evolving field of data science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">09:13 Hugo's Journey in Data Science and Education</p><p class="ql-align-justify">14:57 The Appeal of Bayesian Statistics</p><p class="ql-align-justify">19:36 Learning and Teaching in Data Science</p><p class="ql-align-justify">24:53 Key Ingredients for Effective Data Science Education</p><p class="ql-align-justify">28:44 Podcasting Journey and Insights</p><p class="ql-align-justify">36:10 Building LLM Applications: Course Overview</p><p class="ql-align-justify">42:08 Navigating the Software Development Lifecycle</p><p class="ql-align-justify">48:06 Overcoming Proof of Concept Purgatory</p><p class="ql-align-justify">55:35 Guidance for Aspiring Data Scientists</p><p class="ql-align-justify">01:03:25 Exciting Trends in Data Science and AI</p><p class="ql-align-justify">01:10:51 Balancing Multiple Roles in Data Science</p><p class="ql-align-justify">01:15:23 Envisioning Accessible Data Science for All</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström, Stefan, Corey Abshire and Mike Loncaric.</em></p><p><strong>Links from the show</strong>:</p><ul><li>Alex's last paper, “Unveiling True Talent: The Soccer Factor Model for Skill Evaluation”: <a href="https://arxiv.org/abs/2412.05911" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2412.05911</a></li><li>Associated code and data: <a href="https://github.com/AlexAndorra/football-modeling/tree/main/40_submissions/MIT_Sloan_2025/01_Paper" rel="noopener noreferrer" target="_blank">https://github.com/AlexAndorra/football-modeling/tree/main/40_submissions/MIT_Sloan_2025/01_Paper</a></li><li>Hugo on Blue Sky: <a href="https://bsky.app/profile/hugobowne.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/hugobowne.bsky.social</a></li><li>Hugo’s website: <a href="https://hugobowne.github.io/" rel="noopener noreferrer" target="_blank">https://hugobowne.github.io/</a></li><li>Hugo on Linkedin: <a href="https://www.linkedin.com/in/hugo-bowne-anderson-045939a5/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/hugo-bowne-anderson-045939a5/</a></li><li>Hugo on GitHub: <a href="https://github.com/hugobowne" rel="noopener noreferrer" target="_blank">https://github.com/hugobowne</a></li><li>Vanishing Gradients podcast: <a href="https://vanishinggradients.fireside.fm/hosts/hugobowne" rel="noopener noreferrer" target="_blank">https://vanishinggradients.fireside.fm/hosts/hugobowne</a></li><li>High Signal podcast: <a href="https://high-signal.delphina.ai/" rel="noopener noreferrer" target="_blank">https://high-signal.delphina.ai/</a>&nbsp;</li><li>25% discount on Hugo’s course on Building LLM Applications: <a href="https://www.linkedin.com/safety/go?url=https%3A%2F%2Fmaven.com%2Fhugo-stefan%2Fbuilding-llm-apps-ds-and-swe-from-first-principles%3FpromoCode%3DLEARNBAYES25&amp;trk=flagship-messaging-web&amp;messageThreadUrn=urn%3Ali%3AmessagingThread%3A2-NWYxN2JmNzItZDAyZS00MGY0LTgzNGYtYWU0YTdiZWI4MWE4XzAxMA%3D%3D&amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_feed%3Bn8AX89hBTq%2BGxMENNSf9CQ%3D%3D" rel="noopener noreferrer" target="_blank">https://maven.com/hugo-stefan/building-llm-apps-ds-and-swe-from-first-principles?promoCode=LEARNBAYES25</a></li><li>Lightning lessons if people want to get a sense of Hugo's&nbsp; teaching style and content:</li><li><a href="https://maven.com/p/38a781/building-with-gen-ai-from-first-principles?utm_medium=ll_share_link&amp;utm_source=instructor" rel="noopener noreferrer" target="_blank">https://maven.com/p/38a781/building-with-gen-ai-from-first-principles?utm_medium=ll_share_link&amp;utm_source=instructor</a></li><li><a href="https://maven.com/p/a6f9bf/mastering-llm-application-testing?utm_medium=ll_share_link&amp;utm_source=instructor" rel="noopener noreferrer" target="_blank">https://maven.com/p/a6f9bf/mastering-llm-application-testing?utm_medium=ll_share_link&amp;utm_source=instructor</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong>:</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/122-learning-and-teaching-in-the-age-of-ai-hugo-bowne-anderson]]></link><guid isPermaLink="false">0e15eb43-a335-4b03-9824-501f5403fbba</guid><itunes:image href="https://artwork.captivate.fm/3eb1a32a-fc56-441a-838b-a967ade89fbf/VNWDl46o8RUAbJYmMvBIgUl6.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 26 Dec 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/3e7f4a21-8645-4514-aca3-ca31509c434a/Episode-122-MP3.mp3" length="159717094" type="audio/mpeg"/><itunes:duration>01:23:10</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>122</itunes:episode><itunes:season>1</itunes:season><podcast:episode>122</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/9ac7d826-da46-4ffb-af46-61db08f5fbb2/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/9ac7d826-da46-4ffb-af46-61db08f5fbb2/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#122 Learning and Teaching in the Age of AI, with Hugo Bowne-Anderson"><podcast:source uri="https://youtu.be/BRIYytbqtP0"/></podcast:alternateEnclosure></item><item><title>#121 Exploring Bayesian Structural Equation Modeling, with Nathaniel Forde</title><itunes:title>Exploring Bayesian Structural Equation Modeling, with Nathaniel Forde</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">CFA is commonly used in psychometrics to validate theoretical constructs.</li><li class="ql-align-justify">Theoretical structure is crucial in confirmatory factor analysis.</li><li class="ql-align-justify">Bayesian approaches offer flexibility in modeling complex relationships.</li><li class="ql-align-justify">Model validation involves both global and local fit measures.</li><li class="ql-align-justify">Sensitivity analysis is vital in Bayesian modeling to avoid skewed results.</li><li class="ql-align-justify">Complex models should be justified by their ability to answer specific questions.</li><li class="ql-align-justify">The choice of model complexity should balance fit and theoretical relevance. Fitting models to real data builds confidence in their validity.</li><li class="ql-align-justify">Divergences in model fitting indicate potential issues with model specification.</li><li class="ql-align-justify">Factor analysis can help clarify causal relationships between variables.</li><li class="ql-align-justify">Survey data is a valuable resource for understanding complex phenomena.</li><li class="ql-align-justify">Philosophical training enhances logical reasoning in data science.</li><li class="ql-align-justify">Causal inference is increasingly recognized in industry applications.</li><li class="ql-align-justify">Effective communication is essential for data scientists.</li><li class="ql-align-justify">Understanding confounding is crucial for accurate modeling.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">10:11 Understanding Structural Equation Modeling (SEM) and Confirmatory Factor Analysis (CFA)</p><p class="ql-align-justify">20:11 Application of SEM and CFA in HR Analytics</p><p class="ql-align-justify">30:10 Challenges and Advantages of Bayesian Approaches in SEM and CFA</p><p class="ql-align-justify">33:58 Evaluating Bayesian Models</p><p class="ql-align-justify">39:50 Challenges in Model Building</p><p class="ql-align-justify">44:15 Causal Relationships in SEM and CFA</p><p class="ql-align-justify">49:01 Practical Applications of SEM and CFA</p><p class="ql-align-justify">51:47 Influence of Philosophy on Data Science</p><p class="ql-align-justify">54:51 Designing Models with Confounding in Mind</p><p class="ql-align-justify">57:39 Future Trends in Causal Inference</p><p class="ql-align-justify">01:00:03 Advice for Aspiring Data Scientists</p><p class="ql-align-justify">01:02:48 Future Research Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy,]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">CFA is commonly used in psychometrics to validate theoretical constructs.</li><li class="ql-align-justify">Theoretical structure is crucial in confirmatory factor analysis.</li><li class="ql-align-justify">Bayesian approaches offer flexibility in modeling complex relationships.</li><li class="ql-align-justify">Model validation involves both global and local fit measures.</li><li class="ql-align-justify">Sensitivity analysis is vital in Bayesian modeling to avoid skewed results.</li><li class="ql-align-justify">Complex models should be justified by their ability to answer specific questions.</li><li class="ql-align-justify">The choice of model complexity should balance fit and theoretical relevance. Fitting models to real data builds confidence in their validity.</li><li class="ql-align-justify">Divergences in model fitting indicate potential issues with model specification.</li><li class="ql-align-justify">Factor analysis can help clarify causal relationships between variables.</li><li class="ql-align-justify">Survey data is a valuable resource for understanding complex phenomena.</li><li class="ql-align-justify">Philosophical training enhances logical reasoning in data science.</li><li class="ql-align-justify">Causal inference is increasingly recognized in industry applications.</li><li class="ql-align-justify">Effective communication is essential for data scientists.</li><li class="ql-align-justify">Understanding confounding is crucial for accurate modeling.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">10:11 Understanding Structural Equation Modeling (SEM) and Confirmatory Factor Analysis (CFA)</p><p class="ql-align-justify">20:11 Application of SEM and CFA in HR Analytics</p><p class="ql-align-justify">30:10 Challenges and Advantages of Bayesian Approaches in SEM and CFA</p><p class="ql-align-justify">33:58 Evaluating Bayesian Models</p><p class="ql-align-justify">39:50 Challenges in Model Building</p><p class="ql-align-justify">44:15 Causal Relationships in SEM and CFA</p><p class="ql-align-justify">49:01 Practical Applications of SEM and CFA</p><p class="ql-align-justify">51:47 Influence of Philosophy on Data Science</p><p class="ql-align-justify">54:51 Designing Models with Confounding in Mind</p><p class="ql-align-justify">57:39 Future Trends in Causal Inference</p><p class="ql-align-justify">01:00:03 Advice for Aspiring Data Scientists</p><p class="ql-align-justify">01:02:48 Future Research Directions</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström and Stefan.</em></p><p><strong>Links from the show:</strong></p><ul><li>Modeling Webinar – Bayesian Causal Inference &amp; Propensity Scores: <a href="https://www.youtube.com/watch?v=y9BeOr0AETw&amp;list=PL7RjIaSLWh5lDvhGf6qs_im0fRzOeFN5_&amp;index=9" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=y9BeOr0AETw&amp;list=PL7RjIaSLWh5lDvhGf6qs_im0fRzOeFN5_&amp;index=9</a></li><li>LBS #102, Bayesian Structural Equation Modeling &amp; Causal Inference in Psychometrics, with Ed Merkle: <a href="https://learnbayesstats.com/episode/102-bayesian-structural-equation-modeling-causal-inference-psychometrics-ed-merkle/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/102-bayesian-structural-equation-modeling-causal-inference-psychometrics-ed-merkle/</a>&nbsp;</li><li>Nate’s website: <a href="https://nathanielf.github.io/" rel="noopener noreferrer" target="_blank">https://nathanielf.github.io/</a></li><li>Nate on GitHub: <a href="https://github.com/NathanielF" rel="noopener noreferrer" target="_blank">https://github.com/NathanielF</a></li><li>Nate on Linkedin: <a href="https://www.linkedin.com/in/nathaniel-forde-2477a265/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/nathaniel-forde-2477a265/</a></li><li>Nate on Twitter: <a href="https://x.com/forde_nathaniel" rel="noopener noreferrer" target="_blank">https://x.com/forde_nathaniel</a></li><li>Confirmatory Factor Analysis and Structural Equation Models in Psychometrics: <a href="https://www.pymc.io/projects/examples/en/latest/case_studies/CFA_SEM.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/case_studies/CFA_SEM.html</a></li><li>Measurement, Latent Factors and the Garden of Forking Paths: <a href="https://nathanielf.github.io/posts/post-with-code/CFA_AND_SEM/CFA_AND_SEM.html" rel="noopener noreferrer" target="_blank">https://nathanielf.github.io/posts/post-with-code/CFA_AND_SEM/CFA_AND_SEM.html</a></li><li>Bayesian Non-parametric Causal Inference: <a href="https://www.pymc.io/projects/examples/en/latest/causal_inference/bayesian_nonparametric_causal.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/causal_inference/bayesian_nonparametric_causal.html</a></li><li>Simpson’s paradox: <a href="https://www.pymc.io/projects/examples/en/latest/causal_inference/GLM-simpsons-paradox.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/causal_inference/GLM-simpsons-paradox.html</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript:</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/121-exploring-bayesian-structural-equation-modeling-nathaniel-forde]]></link><guid isPermaLink="false">79399b63-f0f9-4acd-9f14-a90c5fdfe626</guid><itunes:image href="https://artwork.captivate.fm/3358718d-54d1-440b-9f82-6de904e67f0d/aSAm-UyQssb7M9SMX3esfTDw.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 11 Dec 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/abb5f1e2-d1ee-45c0-9e0f-c40849029a50/Episode-121-mp3.mp3" length="134297920" type="audio/mpeg"/><itunes:duration>01:08:13</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>121</itunes:episode><itunes:season>1</itunes:season><podcast:episode>121</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/0d03528d-499e-4859-9238-17155e76d4df/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/0d03528d-499e-4859-9238-17155e76d4df/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#121 Exploring Bayesian Structural Equation Modeling, with Nathaniel Forde"><podcast:source uri="https://youtu.be/6mL1J_b7_E0"/></podcast:alternateEnclosure></item><item><title>#120 Innovations in Infectious Disease Modeling, with Liza Semenova &amp; Chris Wymant</title><itunes:title>Innovations in Infectious Disease Modeling, with Liza Semenova &amp; Chris Wymant</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>-------------------------</p><p class="ql-align-justify"><em>Love the insights from this episode? Make sure you never miss a beat with </em><strong><em>Chatpods</em></strong><em>! Whether you're commuting, working out, or just on the go, Chatpods lets you </em><strong><em>capture and summarize key takeaways effortlessly.</em></strong></p><p class="ql-align-justify"><em>Save time, stay organized, and keep your thoughts at your fingertips.</em></p><p class="ql-align-justify"><em>Download Chatpods directly from</em><a href="https://apps.apple.com/us/app/chatpods/id6599838327" rel="noopener noreferrer" target="_blank"><em> App Store</em></a><em> or</em><a href="https://play.google.com/store/apps/details?id=com.myzy.nex" rel="noopener noreferrer" target="_blank"><em> Google Play</em></a><em> and use it to listen to this podcast today!</em></p><p class="ql-align-justify"><a href="https://www.chatpods.com/?fr=LearningBayesianStatistics" rel="noopener noreferrer" target="_blank"><em>https://www.chatpods.com/?fr=LearningBayesianStatistics</em></a></p><p class="ql-align-justify">-------------------------</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Epidemiology focuses on health at various scales, while biology often looks at micro-level details.</li><li class="ql-align-justify">Bayesian statistics helps connect models to data and quantify uncertainty.</li><li class="ql-align-justify">Recent advancements in data collection have improved the quality of epidemiological research.</li><li class="ql-align-justify">Collaboration between domain experts and statisticians is essential for effective research.</li><li class="ql-align-justify">The COVID-19 pandemic has led to increased data availability and international cooperation.</li><li class="ql-align-justify">Modeling infectious diseases requires understanding complex dynamics and statistical methods.</li><li class="ql-align-justify">Challenges in coding and communication between disciplines can hinder progress.</li><li class="ql-align-justify">Innovations in machine learning and neural networks are shaping the future of epidemiology.</li><li class="ql-align-justify">The importance of understanding the context and limitations of data in research.&nbsp;</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics and Epidemiology</p><p class="ql-align-justify">03:35 Guest Backgrounds and Their Journey</p><p class="ql-align-justify">10:04 Understanding Computational Biology vs. Epidemiology</p><p class="ql-align-justify">16:11 The Role of Bayesian Statistics in Epidemiology</p><p class="ql-align-justify">21:40 Recent Projects and Applications in Epidemiology</p><p class="ql-align-justify">31:30...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p>-------------------------</p><p class="ql-align-justify"><em>Love the insights from this episode? Make sure you never miss a beat with </em><strong><em>Chatpods</em></strong><em>! Whether you're commuting, working out, or just on the go, Chatpods lets you </em><strong><em>capture and summarize key takeaways effortlessly.</em></strong></p><p class="ql-align-justify"><em>Save time, stay organized, and keep your thoughts at your fingertips.</em></p><p class="ql-align-justify"><em>Download Chatpods directly from</em><a href="https://apps.apple.com/us/app/chatpods/id6599838327" rel="noopener noreferrer" target="_blank"><em> App Store</em></a><em> or</em><a href="https://play.google.com/store/apps/details?id=com.myzy.nex" rel="noopener noreferrer" target="_blank"><em> Google Play</em></a><em> and use it to listen to this podcast today!</em></p><p class="ql-align-justify"><a href="https://www.chatpods.com/?fr=LearningBayesianStatistics" rel="noopener noreferrer" target="_blank"><em>https://www.chatpods.com/?fr=LearningBayesianStatistics</em></a></p><p class="ql-align-justify">-------------------------</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Epidemiology focuses on health at various scales, while biology often looks at micro-level details.</li><li class="ql-align-justify">Bayesian statistics helps connect models to data and quantify uncertainty.</li><li class="ql-align-justify">Recent advancements in data collection have improved the quality of epidemiological research.</li><li class="ql-align-justify">Collaboration between domain experts and statisticians is essential for effective research.</li><li class="ql-align-justify">The COVID-19 pandemic has led to increased data availability and international cooperation.</li><li class="ql-align-justify">Modeling infectious diseases requires understanding complex dynamics and statistical methods.</li><li class="ql-align-justify">Challenges in coding and communication between disciplines can hinder progress.</li><li class="ql-align-justify">Innovations in machine learning and neural networks are shaping the future of epidemiology.</li><li class="ql-align-justify">The importance of understanding the context and limitations of data in research.&nbsp;</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics and Epidemiology</p><p class="ql-align-justify">03:35 Guest Backgrounds and Their Journey</p><p class="ql-align-justify">10:04 Understanding Computational Biology vs. Epidemiology</p><p class="ql-align-justify">16:11 The Role of Bayesian Statistics in Epidemiology</p><p class="ql-align-justify">21:40 Recent Projects and Applications in Epidemiology</p><p class="ql-align-justify">31:30 Sampling Challenges in Health Surveys</p><p class="ql-align-justify">34:22 Model Development and Computational Challenges</p><p class="ql-align-justify">36:43 Navigating Different Jargons in Survey Design</p><p class="ql-align-justify">39:35 Post-COVID Trends in Epidemiology</p><p class="ql-align-justify">42:49 Funding and Data Availability in Epidemiology</p><p class="ql-align-justify">45:05 Collaboration Across Disciplines</p><p class="ql-align-justify">48:21 Using Neural Networks in Bayesian Modeling</p><p class="ql-align-justify">51:42 Model Diagnostics in Epidemiology</p><p class="ql-align-justify">55:38 Parameter Estimation in Compartmental Models</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström and Stefan.</em></p><p><strong>Links from the show:</strong></p><ul><li>LBS #21, Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova: <a href="https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/</a></li><li>Liza’s website: <a href="https://www.elizaveta-semenova.com/" rel="noopener noreferrer" target="_blank">https://www.elizaveta-semenova.com/</a></li><li>Liza on GitHub: <a href="https://github.com/elizavetasemenova" rel="noopener noreferrer" target="_blank">https://github.com/elizavetasemenova</a></li><li>Liza on LinkedIn: <a href="https://www.linkedin.com/in/elizaveta-semenova/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/elizaveta-semenova/</a></li><li>Liza on Google Scholar: <a href="https://scholar.google.com/citations?user=jqGIgFEAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=jqGIgFEAAAAJ&amp;hl=en</a></li><li>Chris' page: <a href="https://www.bdi.ox.ac.uk/Team/c-wymant" rel="noopener noreferrer" target="_blank">https://www.bdi.ox.ac.uk/Team/c-wymant</a></li><li>Chris on GitHub: <a href="https://github.com/chrishiv" rel="noopener noreferrer" target="_blank">https://github.com/chrishiv</a></li><li>Chris on LinkedIn: <a href="https://www.linkedin.com/in/chris-wymant-65661274/?originalSubdomain=uk" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/chris-wymant-65661274/</a></li><li>Chris on Blue Sky: <a href="https://bsky.app/profile/chriswymant.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/chriswymant.bsky.social</a></li><li>Chris on Google Scholar: <a href="https://scholar.google.com/citations?user=OJ6t2UwAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=OJ6t2UwAAAAJ&amp;hl=en</a></li><li><strong>PriorVAE Paper</strong>: Explains how to build an emulator for a GP using a deep generative model (Variational Autoencoder, or VAE) and apply it within MCMC.&nbsp;<a href="https://royalsocietypublishing.org/doi/full/10.1098/rsif.2022.0094" rel="noopener noreferrer" target="_blank">Link to the paper</a></li><li><strong>PriorCVAE Paper</strong>: Builds on PriorVAE by encoding model parameters along with emulating stochastic process realisations. Includes examples for GPs, ODEs, and double-well models.&nbsp;<a href="https://arxiv.org/pdf/2304.04307" rel="noopener noreferrer" target="_blank">Link to the paper</a></li><li><strong>StanCon 2024 Tutorial</strong>: A tutorial covering the basics of sequential decision-making, with a demo of Bayesian Optimization using Stan.&nbsp;<a href="https://github.com/annariha/StanCon-2024-BO-Stan" rel="noopener noreferrer" target="_blank">Link to the tutorial</a></li><li><strong>Numpyro Course</strong>: Materials from a course Liza taught -- great for learning Numpyro.&nbsp;<a href="https://elizavetasemenova.github.io/prob-epi/01_intro.html" rel="noopener noreferrer" target="_blank">Link to the course</a></li><li><strong>aggVAE Paper</strong>: An application of PriorVAE to the problem of changing boundaries.&nbsp;<a href="https://arxiv.org/abs/2305.19779" rel="noopener noreferrer" target="_blank">Link to the paper</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/120-innovations-infectious-disease-modeling-liza-semenova-chris-wymant]]></link><guid isPermaLink="false">8f372809-3905-4110-8e1b-2f5ca1f95b33</guid><itunes:image href="https://artwork.captivate.fm/c7e5ec1c-898a-4e5c-b568-f9cfd5b06aa0/uWsE69fd1VnHDeSelXl1P4r3.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 27 Nov 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/d2f7e6da-a134-48fc-bcc5-7771f7ca3f0b/Episode-120-mp3.mp3" length="121697773" type="audio/mpeg"/><itunes:duration>01:01:39</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>120</itunes:episode><itunes:season>1</itunes:season><podcast:episode>120</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/26d8054f-6163-4c94-815f-13f8c2a80fe2/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/26d8054f-6163-4c94-815f-13f8c2a80fe2/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#120 Innovations in Infectious Disease Modeling, with Liza Semenova &amp; Chris Wymant"><podcast:source uri="https://youtu.be/m2ID2GvHib4"/></podcast:alternateEnclosure></item><item><title>#119 Causal Inference, Fiction Writing and Career Changes, with Robert Kubinec</title><itunes:title>Causal Inference, Fiction Writing and Career Changes, with Robert Kubinec</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Bob's research focuses on corruption and political economy.</li><li class="ql-align-justify">Measuring corruption is challenging due to the unobservable nature of the behavior.</li><li class="ql-align-justify">The challenge of studying corruption lies in obtaining honest data.</li><li class="ql-align-justify">Innovative survey techniques, like randomized response, can help gather sensitive data.</li><li class="ql-align-justify">Non-traditional backgrounds can enhance statistical research perspectives.</li><li class="ql-align-justify">Bayesian methods are particularly useful for estimating latent variables.</li><li class="ql-align-justify">Bayesian methods shine in situations with prior information.</li><li class="ql-align-justify">Expert surveys can help estimate uncertain outcomes effectively.</li><li class="ql-align-justify">Bob's novel, 'The Bayesian Hitman,' explores academia through a fictional lens.</li><li class="ql-align-justify">Writing fiction can enhance academic writing skills and creativity.</li><li class="ql-align-justify">The importance of community in statistics is emphasized, especially in the Stan community.</li><li class="ql-align-justify">Real-time online surveys could revolutionize data collection in social science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics and Bob Kubinec</p><p class="ql-align-justify">06:01 Bob's Academic Journey and Research Focus</p><p class="ql-align-justify">12:40 Measuring Corruption: Challenges and Methods</p><p class="ql-align-justify">18:54 Transition from Government to Academia</p><p class="ql-align-justify">26:41 The Influence of Non-Traditional Backgrounds in Statistics</p><p class="ql-align-justify">34:51 Bayesian Methods in Political Science Research</p><p class="ql-align-justify">42:08 Bayesian Methods in COVID Measurement</p><p class="ql-align-justify">51:12 The Journey of Writing a Novel</p><p class="ql-align-justify">01:00:24 The Intersection of Fiction and Academia</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Bob's research focuses on corruption and political economy.</li><li class="ql-align-justify">Measuring corruption is challenging due to the unobservable nature of the behavior.</li><li class="ql-align-justify">The challenge of studying corruption lies in obtaining honest data.</li><li class="ql-align-justify">Innovative survey techniques, like randomized response, can help gather sensitive data.</li><li class="ql-align-justify">Non-traditional backgrounds can enhance statistical research perspectives.</li><li class="ql-align-justify">Bayesian methods are particularly useful for estimating latent variables.</li><li class="ql-align-justify">Bayesian methods shine in situations with prior information.</li><li class="ql-align-justify">Expert surveys can help estimate uncertain outcomes effectively.</li><li class="ql-align-justify">Bob's novel, 'The Bayesian Hitman,' explores academia through a fictional lens.</li><li class="ql-align-justify">Writing fiction can enhance academic writing skills and creativity.</li><li class="ql-align-justify">The importance of community in statistics is emphasized, especially in the Stan community.</li><li class="ql-align-justify">Real-time online surveys could revolutionize data collection in social science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics and Bob Kubinec</p><p class="ql-align-justify">06:01 Bob's Academic Journey and Research Focus</p><p class="ql-align-justify">12:40 Measuring Corruption: Challenges and Methods</p><p class="ql-align-justify">18:54 Transition from Government to Academia</p><p class="ql-align-justify">26:41 The Influence of Non-Traditional Backgrounds in Statistics</p><p class="ql-align-justify">34:51 Bayesian Methods in Political Science Research</p><p class="ql-align-justify">42:08 Bayesian Methods in COVID Measurement</p><p class="ql-align-justify">51:12 The Journey of Writing a Novel</p><p class="ql-align-justify">01:00:24 The Intersection of Fiction and Academia</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke, Robert Flannery, Rasmus Hindström and Stefan.</em></p><p><strong>Links from the show:</strong></p><ul><li>Robert’s website (includes blog posts): <a href="https://www.robertkubinec.com/" rel="noopener noreferrer" target="_blank">https://www.robertkubinec.com/</a></li><li>Robert on GitHub: <a href="https://github.com/saudiwin" rel="noopener noreferrer" target="_blank">https://github.com/saudiwin</a></li><li>Robert on Linkedin: <a href="https://www.linkedin.com/in/robert-kubinec-9191a9a/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/robert-kubinec-9191a9a/</a></li><li>Robert on Google Scholar: <a href="https://scholar.google.com/citations?user=bhOaXR4AAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=bhOaXR4AAAAJ&amp;hl=en</a></li><li>Robert on Twitter: <a href="https://x.com/rmkubinec" rel="noopener noreferrer" target="_blank">https://x.com/rmkubinec</a></li><li>Robert on Bluesky: <a href="https://bsky.app/profile/rmkubinec.bsky.social" rel="noopener noreferrer" target="_blank">https://bsky.app/profile/rmkubinec.bsky.social</a></li><li>The Bayesian Hitman: <a href="https://www.amazon.com/Bayesian-Hitman-Robert-M-Kubinec/dp/B0D6M4WNRZ/" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Bayesian-Hitman-Robert-M-Kubinec/dp/B0D6M4WNRZ/</a></li><li>Ordbetareg overview: <a href="https://www.robertkubinec.com/ordbetareg" rel="noopener noreferrer" target="_blank">https://www.robertkubinec.com/ordbetareg</a></li><li>Idealstan – this isn’t out yet, but you can access an older working paper here: <a href="https://osf.io/preprints/osf/8j2bt" rel="noopener noreferrer" target="_blank">https://osf.io/preprints/osf/8j2bt</a></li><li>Ordinal Regression tutorial, Michael Betancourt: <a href="https://betanalpha.github.io/assets/case_studies/ordinal_regression.html" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/assets/case_studies/ordinal_regression.html</a></li><li>Andrew Heiss blog: <a href="https://www.andrewheiss.com/blog/" rel="noopener noreferrer" target="_blank">https://www.andrewheiss.com/blog/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/119-causal-inference-fiction-writing-career-changes-robert-kubinec]]></link><guid isPermaLink="false">115b9cb9-ae4c-4f7a-ae53-1715d1ec7a75</guid><itunes:image href="https://artwork.captivate.fm/ebf7f776-95e6-4593-ad56-7071524e7dd0/srxkgh1r8beD4riqBQDBj1iK.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 13 Nov 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/04a9bb45-36c9-4d72-ae5f-c9cf2431af2d/episo-119-mp3.mp3" length="166539068" type="audio/mpeg"/><itunes:duration>01:25:01</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>119</itunes:episode><itunes:season>1</itunes:season><podcast:episode>119</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/916fb3fe-8f48-453f-8278-999c5888adef/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/916fb3fe-8f48-453f-8278-999c5888adef/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#119 Causal Inference, Fiction Writing and Career Changes, with Robert Kubinec"><podcast:source uri="https://youtu.be/np85nQBfNc8"/></podcast:alternateEnclosure></item><item><title>#118 Exploring the Future of Stan, with Charles Margossian &amp; Brian Ward</title><itunes:title>Exploring the Future of Stan, with Charles Margossian &amp; Brian Ward</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">User experience is crucial for the adoption of Stan.</li><li class="ql-align-justify">Recent innovations include adding tuples to the Stan language, new features and improved error messages.</li><li class="ql-align-justify">Tuples allow for more efficient data handling in Stan.</li><li class="ql-align-justify">Beginners often struggle with the compiled nature of Stan.</li><li class="ql-align-justify">Improving error messages is crucial for user experience.</li><li class="ql-align-justify">BridgeStan allows for integration with other programming languages and makes it very easy for people to use Stan models.</li><li class="ql-align-justify">Community engagement is vital for the development of Stan.</li><li class="ql-align-justify">New samplers are being developed to enhance performance.</li><li class="ql-align-justify">The future of Stan includes more user-friendly features.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to the Live Episode</p><p class="ql-align-justify">02:55 Meet the Stan Core Developers</p><p class="ql-align-justify">05:47 Brian Ward's Journey into Bayesian Statistics</p><p class="ql-align-justify">09:10 Charles Margossian's Contributions to Stan</p><p class="ql-align-justify">11:49 Recent Projects and Innovations in Stan</p><p class="ql-align-justify">15:07 User-Friendly Features and Enhancements</p><p class="ql-align-justify">18:11 Understanding Tuples and Their Importance</p><p class="ql-align-justify">21:06 Challenges for Beginners in Stan</p><p class="ql-align-justify">24:08 Pedagogical Approaches to Bayesian Statistics</p><p class="ql-align-justify">30:54 Optimizing Monte Carlo Estimators</p><p class="ql-align-justify">32:24 Reimagining Stan's Structure</p><p class="ql-align-justify">34:21 The Promise of Automatic Reparameterization</p><p class="ql-align-justify">35:49 Exploring BridgeStan</p><p class="ql-align-justify">40:29 The Future of Samplers in Stan</p><p class="ql-align-justify">43:45 Evaluating New Algorithms</p><p class="ql-align-justify">47:01 Specific Algorithms for Unique Problems</p><p class="ql-align-justify">50:00 Understanding Model Performance</p><p class="ql-align-justify">54:21 The Impact of Stan on Bayesian Research</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">User experience is crucial for the adoption of Stan.</li><li class="ql-align-justify">Recent innovations include adding tuples to the Stan language, new features and improved error messages.</li><li class="ql-align-justify">Tuples allow for more efficient data handling in Stan.</li><li class="ql-align-justify">Beginners often struggle with the compiled nature of Stan.</li><li class="ql-align-justify">Improving error messages is crucial for user experience.</li><li class="ql-align-justify">BridgeStan allows for integration with other programming languages and makes it very easy for people to use Stan models.</li><li class="ql-align-justify">Community engagement is vital for the development of Stan.</li><li class="ql-align-justify">New samplers are being developed to enhance performance.</li><li class="ql-align-justify">The future of Stan includes more user-friendly features.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to the Live Episode</p><p class="ql-align-justify">02:55 Meet the Stan Core Developers</p><p class="ql-align-justify">05:47 Brian Ward's Journey into Bayesian Statistics</p><p class="ql-align-justify">09:10 Charles Margossian's Contributions to Stan</p><p class="ql-align-justify">11:49 Recent Projects and Innovations in Stan</p><p class="ql-align-justify">15:07 User-Friendly Features and Enhancements</p><p class="ql-align-justify">18:11 Understanding Tuples and Their Importance</p><p class="ql-align-justify">21:06 Challenges for Beginners in Stan</p><p class="ql-align-justify">24:08 Pedagogical Approaches to Bayesian Statistics</p><p class="ql-align-justify">30:54 Optimizing Monte Carlo Estimators</p><p class="ql-align-justify">32:24 Reimagining Stan's Structure</p><p class="ql-align-justify">34:21 The Promise of Automatic Reparameterization</p><p class="ql-align-justify">35:49 Exploring BridgeStan</p><p class="ql-align-justify">40:29 The Future of Samplers in Stan</p><p class="ql-align-justify">43:45 Evaluating New Algorithms</p><p class="ql-align-justify">47:01 Specific Algorithms for Unique Problems</p><p class="ql-align-justify">50:00 Understanding Model Performance</p><p class="ql-align-justify">54:21 The Impact of Stan on Bayesian Research</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang, Gary Clarke and Robert Flannery.</em></p><p><strong>Links from the show:</strong></p><ul><li>Come see the show live at PyData NYC: <a href="https://pydata.org/nyc2024/" rel="noopener noreferrer" target="_blank">https://pydata.org/nyc2024/</a></li><li>LBS #90, Demystifying MCMC &amp; Variational Inference, with Charles Margossian: <a href="https://learnbayesstats.com/episode/90-demystifying-mcmc-variational-inference-charles-margossian/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/90-demystifying-mcmc-variational-inference-charles-margossian/</a></li><li>Charles' website: <a href="https://charlesm93.github.io/" rel="noopener noreferrer" target="_blank">https://charlesm93.github.io/</a></li><li>Charles on GitHub: <a href="https://github.com/charlesm93" rel="noopener noreferrer" target="_blank">https://github.com/charlesm93</a></li><li>Charles on LinkedIn: <a href="https://www.linkedin.com/in/charles-margossian-3428935b/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/charles-margossian-3428935b/</a></li><li>Charles on Google Scholar: <a href="https://scholar.google.com/citations?user=nPtLsvIAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=nPtLsvIAAAAJ&amp;hl=en</a></li><li>Charles on Twitter: <a href="https://x.com/charlesm993" rel="noopener noreferrer" target="_blank">https://x.com/charlesm993</a></li><li>Brian's website: <a href="https://brianward.dev/" rel="noopener noreferrer" target="_blank">https://brianward.dev/</a></li><li>Brian on GitHub: <a href="https://github.com/WardBrian" rel="noopener noreferrer" target="_blank">https://github.com/WardBrian</a></li><li>Brian on LinkedIn: <a href="https://www.linkedin.com/in/ward-brianm/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/ward-brianm/</a></li><li>Brian on Google Scholar: <a href="https://scholar.google.com/citations?user=bzosqW0AAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=bzosqW0AAAAJ&amp;hl=en</a></li><li>Brian on Twitter: <a href="https://x.com/ward_brianm" rel="noopener noreferrer" target="_blank">https://x.com/ward_brianm</a></li><li>Bob Carpenter's reflections on StanCon: <a href="https://statmodeling.stat.columbia.edu/category/bayesian-statistics/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/category/bayesian-statistics/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/118-exploring-future-of-stan-charles-margossian-brian-ward]]></link><guid isPermaLink="false">4eb1c06d-8119-44c7-b204-f7e6f3fd1ab2</guid><itunes:image href="https://artwork.captivate.fm/5cabba57-669e-4ccb-9c39-491d82e78946/AUeYJdWExsLwzs5Zeu_omx32.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 30 Oct 2024 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/ee25fa3d-7638-4128-b2e8-bf93db2ee04b/episode-118-full-Mp3.mp3" length="116305160" type="audio/mpeg"/><itunes:duration>58:51</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>118</itunes:episode><itunes:season>1</itunes:season><podcast:episode>118</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/c263c860-272f-4a2b-8883-1ac7bfbcdeea/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/c263c860-272f-4a2b-8883-1ac7bfbcdeea/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#118 Exploring the Future of Stan, with Charles Margossian &amp; Brian Ward"><podcast:source uri="https://youtu.be/nTECQ_uvOBc"/></podcast:alternateEnclosure></item><item><title>#117 Unveiling the Power of Bayesian Experimental Design, with Desi Ivanova</title><itunes:title>Unveiling the Power of Bayesian Experimental Design, with Desi Ivanova</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Designing experiments is about optimal data gathering.</li><li class="ql-align-justify">The optimal design maximizes the amount of information.</li><li class="ql-align-justify">The best experiment reduces uncertainty the most.</li><li class="ql-align-justify">Computational challenges limit the feasibility of BED in practice.</li><li class="ql-align-justify">Amortized Bayesian inference can speed up computations.</li><li class="ql-align-justify">A good underlying model is crucial for effective BED.</li><li class="ql-align-justify">Adaptive experiments are more complex than static ones.</li><li class="ql-align-justify">The future of BED is promising with advancements in AI.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Experimental Design</p><p class="ql-align-justify">07:51 Understanding Bayesian Experimental Design</p><p class="ql-align-justify">19:58 Computational Challenges in Bayesian Experimental Design</p><p class="ql-align-justify">28:47 Innovations in Bayesian Experimental Design</p><p class="ql-align-justify">40:43 Practical Applications of Bayesian Experimental Design</p><p class="ql-align-justify">52:12 Future of Bayesian Experimental Design</p><p class="ql-align-justify">01:01:17 Real-World Applications and Impact</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Designing experiments is about optimal data gathering.</li><li class="ql-align-justify">The optimal design maximizes the amount of information.</li><li class="ql-align-justify">The best experiment reduces uncertainty the most.</li><li class="ql-align-justify">Computational challenges limit the feasibility of BED in practice.</li><li class="ql-align-justify">Amortized Bayesian inference can speed up computations.</li><li class="ql-align-justify">A good underlying model is crucial for effective BED.</li><li class="ql-align-justify">Adaptive experiments are more complex than static ones.</li><li class="ql-align-justify">The future of BED is promising with advancements in AI.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Experimental Design</p><p class="ql-align-justify">07:51 Understanding Bayesian Experimental Design</p><p class="ql-align-justify">19:58 Computational Challenges in Bayesian Experimental Design</p><p class="ql-align-justify">28:47 Innovations in Bayesian Experimental Design</p><p class="ql-align-justify">40:43 Practical Applications of Bayesian Experimental Design</p><p class="ql-align-justify">52:12 Future of Bayesian Experimental Design</p><p class="ql-align-justify">01:01:17 Real-World Applications and Impact</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang and Gary Clarke.</em></p><p><strong>Links from the show:</strong></p><ul><li>Come see the show live at PyData NYC: <a href="https://pydata.org/nyc2024/" rel="noopener noreferrer" target="_blank">https://pydata.org/nyc2024/</a></li><li class="ql-align-justify">Desi’s website: <a href="https://desirivanova.com/" rel="noopener noreferrer" target="_blank">https://desirivanova.com/</a></li><li>Desi on GitHub: <a href="https://github.com/desi-ivanova" rel="noopener noreferrer" target="_blank">https://github.com/desi-ivanova</a></li><li>Desi on Google Scholar: <a href="https://scholar.google.com/citations?user=AmX6sMIAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=AmX6sMIAAAAJ&amp;hl=en</a></li><li>Desi on Linkedin: <a href="https://www.linkedin.com/in/dr-ivanova/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/dr-ivanova/</a></li><li>Desi on Twitter: <a href="https://x.com/desirivanova" rel="noopener noreferrer" target="_blank">https://x.com/desirivanova</a></li><li>LBS #34, Multilevel Regression, Post-stratification &amp; Missing Data, with Lauren Kennedy: <a href="https://learnbayesstats.com/episode/34-multilevel-regression-post-stratification-missing-data-lauren-kennedy/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/34-multilevel-regression-post-stratification-missing-data-lauren-kennedy/</a></li><li>LBS #35, The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/</a></li><li>LBS #45, Biostats &amp; Clinical Trial Design, with Frank Harrell:<a href="https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell/</a></li><li>LBS #107, Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/</a></li><li class="ql-align-justify">Bayesian Experimental Design (BED) with BayesFlow and PyTorch: <a href="https://github.com/stefanradev93/BayesFlow/blob/dev/examples/michaelis_menten_BED_tutorial.ipynb" rel="noopener noreferrer" target="_blank">https://github.com/stefanradev93/BayesFlow/blob/dev/examples/michaelis_menten_BED_tutorial.ipynb</a></li><li>Paper – Modern Bayesian Experimental Design: <a href="https://arxiv.org/abs/2302.14545" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2302.14545</a></li><li>Paper – Optimal experimental design; Formulations and computations: <a href="https://arxiv.org/pdf/2407.16212" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/2407.16212</a></li><li class="ql-align-justify"><em>Information theory, inference and learning algorithms</em>, by the great late Sir David MacKay:&nbsp; <a href="https://www.inference.org.uk/itprnn/book.pdf" rel="noopener noreferrer" target="_blank">https://www.inference.org.uk/itprnn/book.pdf</a></li><li><em>Patterns, Predictions and Actions</em>, Moritz Hard and Ben Recht&nbsp; <a href="https://mlstory.org/index.html" rel="noopener noreferrer" target="_blank">https://mlstory.org/index.html</a> </li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/117-unveiling-power-bayesian-experimental-design-desi-ivanova]]></link><guid isPermaLink="false">e2e03b69-e381-4fe7-91ac-9c1b3e0f334a</guid><itunes:image href="https://artwork.captivate.fm/c3f52663-d6ba-44f7-9ece-f8113fae34f5/2dZiR-kZ16mXPdpHXPlGa2AW.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 15 Oct 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/17d21edd-34b0-4094-86b7-c7fdb81d3113/117-divanova-full-mp3.mp3" length="143886393" type="audio/mpeg"/><itunes:duration>01:13:12</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>117</itunes:episode><itunes:season>1</itunes:season><podcast:episode>117</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/f9de5983-234f-4cc4-bc5f-5822d1aa49f8/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/f9de5983-234f-4cc4-bc5f-5822d1aa49f8/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#117 Unveiling the Power of Bayesian Experimental Design, with Desi Ivanova"><podcast:source uri="https://youtu.be/8bn8C4_ByYQ"/></podcast:alternateEnclosure></item><item><title>#116 Mastering Soccer Analytics, with Ravi Ramineni</title><itunes:title>Mastering Soccer Analytics, with Ravi Ramineni</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Building an athlete management system and a scouting and recruitment platform are key goals in football analytics.</li><li class="ql-align-justify">The focus is on informing training decisions, preventing injuries, and making smart player signings.</li><li class="ql-align-justify">Avoiding false positives in player evaluations is crucial, and data analysis plays a significant role in making informed decisions.</li><li class="ql-align-justify">There are similarities between different football teams, and the sport has social and emotional aspects. Transitioning from on-premises SQL servers to cloud-based systems is a significant endeavor in football analytics.</li><li class="ql-align-justify">Analytics is a tool that aids the decision-making process and helps mitigate biases. The impact of analytics in soccer can be seen in the decline of long-range shots.</li><li class="ql-align-justify">Collaboration and trust between analysts and decision-makers are crucial for successful implementation of analytics.</li><li class="ql-align-justify">The limitations of available data in football analytics hinder the ability to directly measure decision-making on the field.&nbsp;</li><li class="ql-align-justify">Analyzing the impact of coaches in sports analytics is challenging due to the difficulty of separating their effect from other factors. Current data limitations make it hard to evaluate coaching performance accurately.</li><li class="ql-align-justify">Predictive metrics and modeling play a crucial role in soccer analytics, especially in predicting the career progression of young players.</li><li class="ql-align-justify">Improving tracking data and expanding its availability will be a significant focus in the future of soccer analytics.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Ravi and His Role at Seattle Sounders&nbsp;</p><p class="ql-align-justify">06:30 Building an Analytics Department</p><p class="ql-align-justify">15:00 The Impact of Analytics on Player Recruitment and Performance&nbsp;</p><p class="ql-align-justify">28:00 Challenges and Innovations in Soccer Analytics&nbsp;</p><p class="ql-align-justify">42:00 Player Health, Injury Prevention, and Training&nbsp;</p><p class="ql-align-justify">55:00 The Evolution of Data-Driven Strategies</p><p class="ql-align-justify">01:10:00 Future of Analytics in Sports</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson,]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Building an athlete management system and a scouting and recruitment platform are key goals in football analytics.</li><li class="ql-align-justify">The focus is on informing training decisions, preventing injuries, and making smart player signings.</li><li class="ql-align-justify">Avoiding false positives in player evaluations is crucial, and data analysis plays a significant role in making informed decisions.</li><li class="ql-align-justify">There are similarities between different football teams, and the sport has social and emotional aspects. Transitioning from on-premises SQL servers to cloud-based systems is a significant endeavor in football analytics.</li><li class="ql-align-justify">Analytics is a tool that aids the decision-making process and helps mitigate biases. The impact of analytics in soccer can be seen in the decline of long-range shots.</li><li class="ql-align-justify">Collaboration and trust between analysts and decision-makers are crucial for successful implementation of analytics.</li><li class="ql-align-justify">The limitations of available data in football analytics hinder the ability to directly measure decision-making on the field.&nbsp;</li><li class="ql-align-justify">Analyzing the impact of coaches in sports analytics is challenging due to the difficulty of separating their effect from other factors. Current data limitations make it hard to evaluate coaching performance accurately.</li><li class="ql-align-justify">Predictive metrics and modeling play a crucial role in soccer analytics, especially in predicting the career progression of young players.</li><li class="ql-align-justify">Improving tracking data and expanding its availability will be a significant focus in the future of soccer analytics.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Ravi and His Role at Seattle Sounders&nbsp;</p><p class="ql-align-justify">06:30 Building an Analytics Department</p><p class="ql-align-justify">15:00 The Impact of Analytics on Player Recruitment and Performance&nbsp;</p><p class="ql-align-justify">28:00 Challenges and Innovations in Soccer Analytics&nbsp;</p><p class="ql-align-justify">42:00 Player Health, Injury Prevention, and Training&nbsp;</p><p class="ql-align-justify">55:00 The Evolution of Data-Driven Strategies</p><p class="ql-align-justify">01:10:00 Future of Analytics in Sports</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan, Francesco Madrisotti, Ivy Huang and Gary Clarke.</em></p><p><strong>Links from the show:</strong></p><ul><li>LBS Sports Analytics playlist: <a href="https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4</a></li><li>Ravi on Linkedin: <a href="https://www.linkedin.com/in/ravi-ramineni-3798374/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/ravi-ramineni-3798374/</a></li><li>Ravi on Twitter: <a href="https://x.com/analyseFooty" rel="noopener noreferrer" target="_blank">https://x.com/analyseFooty</a></li><li>Decisions in Football - The Power of Compounding | StatsBomb Conference 2023: <a href="https://www.youtube.com/watch?v=D7CXtwDg9lM" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=D7CXtwDg9lM</a></li><li>The Signal and the Noise: <a href="https://www.amazon.com/Signal-Noise-Many-Predictions-Fail-but/dp/0143125087" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Signal-Noise-Many-Predictions-Fail-but/dp/0143125087</a></li><li>PreliZ – A tool-box for prior elicitation: <a href="https://preliz.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://preliz.readthedocs.io/en/latest/</a></li><li>Ravi talking on Ted Knutson's podcast: <a href="https://open.spotify.com/episode/1exLBfyFf0d1dm2IaXkd2v" rel="noopener noreferrer" target="_blank">https://open.spotify.com/episode/1exLBfyFf0d1dm2IaXkd2v</a></li><li>More about Ravi's work at the Seattle Sounders: <a href="https://www.trumedianetworks.com/expected-value-podcast/ravi-ramineni" rel="noopener noreferrer" target="_blank">https://www.trumedianetworks.com/expected-value-podcast/ravi-ramineni</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/116-mastering-soccer-analytics-ravi-ramineni]]></link><guid isPermaLink="false">44a558ba-a460-4b08-90db-72962ccaae6d</guid><itunes:image href="https://artwork.captivate.fm/98bdb56f-423c-4a3b-9fec-81abb63c9b98/umVcpcA9xWk-OBvRKlR7mCIP.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 02 Oct 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a14f982e-ef85-441b-be40-f08a0d439ae3/116-Rramineni-full-MP3.mp3" length="181447981" type="audio/mpeg"/><itunes:duration>01:32:46</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>116</itunes:episode><itunes:season>1</itunes:season><podcast:episode>116</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/2a12b0d5-7c62-41ca-b8d7-2682682084c6/transcript.json" type="application/json"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/2a12b0d5-7c62-41ca-b8d7-2682682084c6/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/2a12b0d5-7c62-41ca-b8d7-2682682084c6/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#116 Mastering Soccer Analytics, with Ravi Ramineni"><podcast:source uri="https://youtu.be/74HHGHtkEGg"/></podcast:alternateEnclosure></item><item><title>#115 Using Time Series to Estimate Uncertainty, with Nate Haines</title><itunes:title>Using Time Series to Estimate Uncertainty, with Nate Haines</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">State space models and traditional time series models are well-suited to forecast loss ratios in the insurance industry, although actuaries have been slow to adopt modern statistical methods.</li><li class="ql-align-justify">Working with limited data is a challenge, but informed priors and hierarchical models can help improve the modeling process.</li><li class="ql-align-justify">Bayesian model stacking allows for blending together different model predictions and taking the best of both (or all if more than 2 models) worlds.</li><li class="ql-align-justify">Model comparison is done using out-of-sample performance metrics, such as the expected log point-wise predictive density (ELPD). Brute leave-future-out cross-validation is often used due to the time-series nature of the data.</li><li class="ql-align-justify">Stacking or averaging models are trained on out-of-sample performance metrics to determine the weights for blending the predictions. Model stacking can be a powerful approach for combining predictions from candidate models. Hierarchical stacking in particular is useful when weights are assumed to vary according to covariates.</li><li class="ql-align-justify">BayesBlend is a Python package developed by Ledger Investing that simplifies the implementation of stacking models, including pseudo Bayesian model averaging, stacking, and hierarchical stacking.</li><li class="ql-align-justify">Evaluating the performance of patient time series models requires considering multiple metrics, including log likelihood-based metrics like ELPD, as well as more absolute metrics like RMSE and mean absolute error.</li><li class="ql-align-justify">Using robust variants of metrics like ELPD can help address issues with extreme outliers. For example, t-distribution estimators of ELPD as opposed to sample sum/mean estimators.</li><li class="ql-align-justify">It is important to evaluate model performance from different perspectives and consider the trade-offs between different metrics. Evaluating models based solely on traditional metrics can limit understanding and trust in the model. Consider additional factors such as interpretability, maintainability, and productionization.</li><li class="ql-align-justify">Simulation-based calibration (SBC) is a valuable tool for assessing parameter estimation and model correctness. It allows for the interpretation of model parameters and the identification of coding errors.</li><li class="ql-align-justify">In industries like insurance, where regulations may restrict model choices, classical statistical approaches still play a significant role. However, there is potential for Bayesian methods and generative AI in certain areas.</li></ul><br/><p...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">State space models and traditional time series models are well-suited to forecast loss ratios in the insurance industry, although actuaries have been slow to adopt modern statistical methods.</li><li class="ql-align-justify">Working with limited data is a challenge, but informed priors and hierarchical models can help improve the modeling process.</li><li class="ql-align-justify">Bayesian model stacking allows for blending together different model predictions and taking the best of both (or all if more than 2 models) worlds.</li><li class="ql-align-justify">Model comparison is done using out-of-sample performance metrics, such as the expected log point-wise predictive density (ELPD). Brute leave-future-out cross-validation is often used due to the time-series nature of the data.</li><li class="ql-align-justify">Stacking or averaging models are trained on out-of-sample performance metrics to determine the weights for blending the predictions. Model stacking can be a powerful approach for combining predictions from candidate models. Hierarchical stacking in particular is useful when weights are assumed to vary according to covariates.</li><li class="ql-align-justify">BayesBlend is a Python package developed by Ledger Investing that simplifies the implementation of stacking models, including pseudo Bayesian model averaging, stacking, and hierarchical stacking.</li><li class="ql-align-justify">Evaluating the performance of patient time series models requires considering multiple metrics, including log likelihood-based metrics like ELPD, as well as more absolute metrics like RMSE and mean absolute error.</li><li class="ql-align-justify">Using robust variants of metrics like ELPD can help address issues with extreme outliers. For example, t-distribution estimators of ELPD as opposed to sample sum/mean estimators.</li><li class="ql-align-justify">It is important to evaluate model performance from different perspectives and consider the trade-offs between different metrics. Evaluating models based solely on traditional metrics can limit understanding and trust in the model. Consider additional factors such as interpretability, maintainability, and productionization.</li><li class="ql-align-justify">Simulation-based calibration (SBC) is a valuable tool for assessing parameter estimation and model correctness. It allows for the interpretation of model parameters and the identification of coding errors.</li><li class="ql-align-justify">In industries like insurance, where regulations may restrict model choices, classical statistical approaches still play a significant role. However, there is potential for Bayesian methods and generative AI in certain areas.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Modeling in Insurance</p><p class="ql-align-justify">13:00 Time Series Models and Their Applications</p><p class="ql-align-justify">30:51 Bayesian Model Averaging Explained</p><p class="ql-align-justify">56:20 Impact of External Factors on Forecasting</p><p class="ql-align-justify">01:25:03 Future of Bayesian Modeling and AI</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Nate’s website: <a href="http://haines-lab.com/" rel="noopener noreferrer" target="_blank">http://haines-lab.com/</a></li><li>Nate on GitHub: <a href="https://github.com/Nathaniel-Haines" rel="noopener noreferrer" target="_blank">https://github.com/Nathaniel-Haines</a></li><li>Nate on Linkedin: <a href="https://www.linkedin.com/in/nathaniel-haines-216049101/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/nathaniel-haines-216049101/</a></li><li>Nate on Twitter: <a href="https://x.com/nate__haines" rel="noopener noreferrer" target="_blank">https://x.com/nate__haines</a></li><li>Nate on Google Scholar: <a href="https://scholar.google.com/citations?user=lg741SgAAAAJ" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=lg741SgAAAAJ</a></li><li>LBS #14 Hidden Markov Models &amp; Statistical Ecology, with Vianey Leos-Barajas: <a href="https://learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas/</a></li><li>LBS #107 Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/</a></li><li>LBS #109 Prior Sensitivity Analysis, Overfitting &amp; Model Selection, with Sonja Winter: <a href="https://learnbayesstats.com/episode/109-prior-sensitivity-analysis-overfitting-model-selection-sonja-winter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/109-prior-sensitivity-analysis-overfitting-model-selection-sonja-winter/</a></li><li>BayesBlend – Easy Model Blending: <a href="https://arxiv.org/abs/2405.00158" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2405.00158</a></li><li>BayesBlend documentation: <a href="https://ledger-investing-bayesblend.readthedocs-hosted.com/en/latest/" rel="noopener noreferrer" target="_blank">https://ledger-investing-bayesblend.readthedocs-hosted.com/en/latest/</a></li><li>SBC paper: <a href="https://arxiv.org/abs/1804.06788" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1804.06788</a></li><li>Isaac Asimov’s Foundation (Hari Seldon): <a href="https://en.wikipedia.org/wiki/Hari_Seldon" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Hari_Seldon</a></li><li>Stancon 2023 talk on Ledger’s Bayesian modeling workflow: <a href="https://github.com/stan-dev/stancon2023/blob/main/Nathaniel-Haines/slides.pdf" rel="noopener noreferrer" target="_blank">https://github.com/stan-dev/stancon2023/blob/main/Nathaniel-Haines/slides.pdf</a></li><li>Ledger’s Bayesian modeling workflow: <a href="https://arxiv.org/abs/2407.14666v1" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2407.14666v1</a></li><li>More on Ledger Investing: <a href="https://www.ledgerinvesting.com/about-us" rel="noopener noreferrer" target="_blank">https://www.ledgerinvesting.com/about-us</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/115-time-series-insurance-nate-haines]]></link><guid isPermaLink="false">070f4ab5-6e59-41e1-ac0b-1994a795e877</guid><itunes:image href="https://artwork.captivate.fm/e384d382-c394-4bf1-80d1-51b7df21c129/1zNwajGGn9iBsvGQL0zht-Hc.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 17 Sep 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/66cd8f00-55ef-49a9-8d1e-b58934108a4b/115-Nhaines-full-MP3.mp3" length="195072054" type="audio/mpeg"/><itunes:duration>01:39:51</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>115</itunes:episode><itunes:season>1</itunes:season><podcast:episode>115</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/73dd0cfd-9ef9-4254-ad46-019755d462be/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/73dd0cfd-9ef9-4254-ad46-019755d462be/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#115 Using Time Series to Estimate Uncertainty, with Nate Haines"><podcast:source uri="https://youtu.be/ws47-3pEAcc"/></podcast:alternateEnclosure></item><item><title>#114 From the Field to the Lab – A Journey in Baseball Science, with Jacob Buffa</title><itunes:title>From the Field to the Lab – A Journey in Baseball Science, with Jacob Buffa</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Education and visual communication are key in helping athletes understand the impact of nutrition on performance.</li><li class="ql-align-justify">Bayesian statistics are used to analyze player performance and injury risk.</li><li class="ql-align-justify">Integrating diverse data sources is a challenge but can provide valuable insights.</li><li class="ql-align-justify">Understanding the specific needs and characteristics of athletes is crucial in conditioning and injury prevention. The application of Bayesian statistics in baseball science requires experts in Bayesian methods.</li><li class="ql-align-justify">Traditional statistical methods taught in sports science programs are limited.</li><li class="ql-align-justify">Communicating complex statistical concepts, such as Bayesian analysis, to coaches and players is crucial.</li><li class="ql-align-justify">Conveying uncertainties and limitations of the models is essential for effective utilization.</li><li class="ql-align-justify">Emerging trends in baseball science include the use of biomechanical information and computer vision algorithms.</li><li class="ql-align-justify">Improving player performance and injury prevention are key goals for the future of baseball science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 The Role of Nutrition and Conditioning</p><p class="ql-align-justify">05:46 Analyzing Player Performance and Managing Injury Risks</p><p class="ql-align-justify">12:13 Educating Athletes on Dietary Choices</p><p class="ql-align-justify">18:02 Emerging Trends in Baseball Science</p><p class="ql-align-justify">29:49 Hierarchical Models and Player Analysis</p><p class="ql-align-justify">36:03 Challenges of Working with Limited Data</p><p class="ql-align-justify">39:49 Effective Communication of Statistical Concepts</p><p class="ql-align-justify">47:59 Future Trends: Biomechanical Data Analysis and Computer Vision Algorithms</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Education and visual communication are key in helping athletes understand the impact of nutrition on performance.</li><li class="ql-align-justify">Bayesian statistics are used to analyze player performance and injury risk.</li><li class="ql-align-justify">Integrating diverse data sources is a challenge but can provide valuable insights.</li><li class="ql-align-justify">Understanding the specific needs and characteristics of athletes is crucial in conditioning and injury prevention. The application of Bayesian statistics in baseball science requires experts in Bayesian methods.</li><li class="ql-align-justify">Traditional statistical methods taught in sports science programs are limited.</li><li class="ql-align-justify">Communicating complex statistical concepts, such as Bayesian analysis, to coaches and players is crucial.</li><li class="ql-align-justify">Conveying uncertainties and limitations of the models is essential for effective utilization.</li><li class="ql-align-justify">Emerging trends in baseball science include the use of biomechanical information and computer vision algorithms.</li><li class="ql-align-justify">Improving player performance and injury prevention are key goals for the future of baseball science.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 The Role of Nutrition and Conditioning</p><p class="ql-align-justify">05:46 Analyzing Player Performance and Managing Injury Risks</p><p class="ql-align-justify">12:13 Educating Athletes on Dietary Choices</p><p class="ql-align-justify">18:02 Emerging Trends in Baseball Science</p><p class="ql-align-justify">29:49 Hierarchical Models and Player Analysis</p><p class="ql-align-justify">36:03 Challenges of Working with Limited Data</p><p class="ql-align-justify">39:49 Effective Communication of Statistical Concepts</p><p class="ql-align-justify">47:59 Future Trends: Biomechanical Data Analysis and Computer Vision Algorithms</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show</strong>:</p><ul><li>LBS Sports Analytics playlist: <a href="https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4</a></li><li>Jacob on Linkedin: <a href="https://www.linkedin.com/in/jacob-buffa-46bb7481/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/jacob-buffa-46bb7481/</a></li><li>Jacob on Twitter: <a href="https://x.com/EBA_Buffa" rel="noopener noreferrer" target="_blank">https://x.com/EBA_Buffa</a></li><li>The Book – Playing The Percentages In Baseball: <a href="https://www.amazon.com/Book-Playing-Percentages-Baseball/dp/1494260174" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Book-Playing-Percentages-Baseball/dp/1494260174</a></li><li>Future Value – The Battle for Baseball's Soul and How Teams Will Find the Next Superstar: <a href="https://www.amazon.com/Future-Value-Battle-Baseballs-Superstar/dp/1629377678" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Future-Value-Battle-Baseballs-Superstar/dp/1629377678</a></li><li>The MVP Machine – How Baseball's New Nonconformists Are Using Data to Build Better Players: <a href="https://www.amazon.com/MVP-Machine-Baseballs-Nonconformists-Players/dp/1541698940" rel="noopener noreferrer" target="_blank">https://www.amazon.com/MVP-Machine-Baseballs-Nonconformists-Players/dp/1541698940</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong>:</p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/114-journey-baseball-science-jacob-buffa]]></link><guid isPermaLink="false">5311d766-e115-44ad-af74-ac4e441d53a3</guid><itunes:image href="https://artwork.captivate.fm/14de52b7-8c67-41db-a9d7-d271d775ad11/DAcsGsPK6QPeE5R_UPOPGvzV.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 05 Sep 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5e680fae-5085-4934-a9cd-df4058c3d4a7/114-jbuffa-full-mp3.mp3" length="121571951" type="audio/mpeg"/><itunes:duration>01:01:32</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>114</itunes:episode><itunes:season>1</itunes:season><podcast:episode>114</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/eca9a77d-6f67-40f8-9732-3da57507abe0/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/eca9a77d-6f67-40f8-9732-3da57507abe0/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#114 From the Field to the Lab – A Journey in Baseball Science, with Jacob Buffa"><podcast:source uri="https://youtu.be/Zb5ijR1eyvc"/></podcast:alternateEnclosure></item><item><title>#113 A Deep Dive into Bayesian Stats, with Alex Andorra, ft. the Super Data Science Podcast</title><itunes:title>A Deep Dive into Bayesian Stats, with Alex Andorra, ft. the Super Data Science Podcast</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Bayesian statistics is a powerful framework for handling complex problems, making use of prior knowledge, and excelling with limited data.</li><li class="ql-align-justify">Bayesian statistics provides a framework for updating beliefs and making predictions based on prior knowledge and observed data.</li><li class="ql-align-justify">Bayesian methods allow for the explicit incorporation of prior assumptions, which can provide structure and improve the reliability of the analysis.</li><li class="ql-align-justify">There are several Bayesian frameworks available, such as PyMC, Stan, and Bambi, each with its own strengths and features.</li><li class="ql-align-justify">PyMC is a powerful library for Bayesian modeling that allows for flexible and efficient computation.</li><li class="ql-align-justify">For beginners, it is recommended to start with introductory courses or resources that provide a step-by-step approach to learning Bayesian statistics.</li><li class="ql-align-justify">PyTensor leverages GPU acceleration and complex graph optimizations to improve the performance and scalability of Bayesian models.</li><li class="ql-align-justify">ArviZ is a library for post-modeling workflows in Bayesian statistics, providing tools for model diagnostics and result visualization.</li><li class="ql-align-justify">Gaussian processes are versatile non-parametric models that can be used for spatial and temporal data analysis in Bayesian statistics.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics</p><p class="ql-align-justify">07:32 Advantages of Bayesian Methods</p><p class="ql-align-justify">16:22 Incorporating Priors in Models</p><p class="ql-align-justify">23:26 Modeling Causal Relationships</p><p class="ql-align-justify">30:03 Introduction to PyMC, Stan, and Bambi</p><p class="ql-align-justify">34:30 Choosing the Right Bayesian Framework</p><p class="ql-align-justify">39:20 Getting Started with Bayesian Statistics</p><p class="ql-align-justify">44:39 Understanding Bayesian Statistics and PyMC</p><p class="ql-align-justify">49:01 Leveraging PyTensor for Improved Performance and Scalability</p><p class="ql-align-justify">01:02:37 Exploring Post-Modeling Workflows with ArviZ</p><p class="ql-align-justify">01:08:30 The Power of Gaussian Processes in Bayesian Modeling</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna,...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Bayesian statistics is a powerful framework for handling complex problems, making use of prior knowledge, and excelling with limited data.</li><li class="ql-align-justify">Bayesian statistics provides a framework for updating beliefs and making predictions based on prior knowledge and observed data.</li><li class="ql-align-justify">Bayesian methods allow for the explicit incorporation of prior assumptions, which can provide structure and improve the reliability of the analysis.</li><li class="ql-align-justify">There are several Bayesian frameworks available, such as PyMC, Stan, and Bambi, each with its own strengths and features.</li><li class="ql-align-justify">PyMC is a powerful library for Bayesian modeling that allows for flexible and efficient computation.</li><li class="ql-align-justify">For beginners, it is recommended to start with introductory courses or resources that provide a step-by-step approach to learning Bayesian statistics.</li><li class="ql-align-justify">PyTensor leverages GPU acceleration and complex graph optimizations to improve the performance and scalability of Bayesian models.</li><li class="ql-align-justify">ArviZ is a library for post-modeling workflows in Bayesian statistics, providing tools for model diagnostics and result visualization.</li><li class="ql-align-justify">Gaussian processes are versatile non-parametric models that can be used for spatial and temporal data analysis in Bayesian statistics.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Bayesian Statistics</p><p class="ql-align-justify">07:32 Advantages of Bayesian Methods</p><p class="ql-align-justify">16:22 Incorporating Priors in Models</p><p class="ql-align-justify">23:26 Modeling Causal Relationships</p><p class="ql-align-justify">30:03 Introduction to PyMC, Stan, and Bambi</p><p class="ql-align-justify">34:30 Choosing the Right Bayesian Framework</p><p class="ql-align-justify">39:20 Getting Started with Bayesian Statistics</p><p class="ql-align-justify">44:39 Understanding Bayesian Statistics and PyMC</p><p class="ql-align-justify">49:01 Leveraging PyTensor for Improved Performance and Scalability</p><p class="ql-align-justify">01:02:37 Exploring Post-Modeling Workflows with ArviZ</p><p class="ql-align-justify">01:08:30 The Power of Gaussian Processes in Bayesian Modeling</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Original episode on the Super Data Science podcast: <a href="https://www.superdatascience.com/podcast/bayesian-methods-and-applications-with-alexandre-andorra" rel="noopener noreferrer" target="_blank">https://www.superdatascience.com/podcast/bayesian-methods-and-applications-with-alexandre-andorra</a></li><li>Advanced Regression with Bambi and PyMC: <a href="https://www.intuitivebayes.com/advanced-regression" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/advanced-regression</a></li><li>Gaussian Processes: HSGP Reference &amp; First Steps: <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html</a></li><li>Modeling Webinar – Fast &amp; Efficient Gaussian Processes: <a href="https://www.youtube.com/watch?v=9tDMouGue8g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=9tDMouGue8g</a></li><li>Modeling spatial data with Gaussian processes in PyMC: <a href="https://www.pymc-labs.com/blog-posts/spatial-gaussian-process-01/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.com/blog-posts/spatial-gaussian-process-01/</a></li><li>Hierarchical Bayesian Modeling of Survey Data with Post-stratification: <a href="https://www.pymc-labs.com/blog-posts/2022-12-08-Salk/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.com/blog-posts/2022-12-08-Salk/</a></li><li>PyMC docs: <a href="https://www.pymc.io/welcome.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/welcome.html</a></li><li>Bambi docs: <a href="https://bambinos.github.io/bambi/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/</a></li><li>PyMC Labs: <a href="https://www.pymc-labs.com/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.com/</a></li><li>LBS #50 Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li>LBS #51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li>LBS #63 Media Mix Models &amp; Bayes for Marketing, with Luciano Paz: <a href="https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/</a></li><li>LBS #83 Multilevel Regression, Post-Stratification &amp; Electoral Dynamics, with Tarmo Jüristo: <a href="https://learnbayesstats.com/episode/83-multilevel-regression-post-stratification-electoral-dynamics-tarmo-juristo/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/83-multilevel-regression-post-stratification-electoral-dynamics-tarmo-juristo/</a></li><li>Jon Krohn on YouTube: <a href="https://www.youtube.com/JonKrohnLearns" rel="noopener noreferrer" target="_blank">https://www.youtube.com/JonKrohnLearns</a></li><li>Jon Krohn on Linkedin: <a href="https://www.linkedin.com/in/jonkrohn/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/jonkrohn/</a></li><li>Jon Krohn on Twitter: <a href="https://x.com/JonKrohnLearns" rel="noopener noreferrer" target="_blank">https://x.com/JonKrohnLearns</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/113-deep-dive-bayesian-stats-alex-andorra-super-data-science-podcast]]></link><guid isPermaLink="false">aea6ff23-c4be-418e-bc14-60967b4397a6</guid><itunes:image href="https://artwork.captivate.fm/5046e446-fa93-4421-afb6-c7b34e458f64/FvL7QRTRgcQI3IYEf_gp8vBE.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 22 Aug 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f0307824-c6fc-4b00-8ba1-0b927f7bed56/113-Super-data-science-full-mp3.mp3" length="177812348" type="audio/mpeg"/><itunes:duration>01:30:51</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>113</itunes:episode><itunes:season>1</itunes:season><podcast:episode>113</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/e406bfcb-ed79-4c83-a2a9-97e2979fa1e2/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/e406bfcb-ed79-4c83-a2a9-97e2979fa1e2/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#113 A Deep Dive into Bayesian Stats, with Alex Andorra, ft. the Super Data Science Podcast"><podcast:source uri="https://youtu.be/QY3TuJbgo98"/></podcast:alternateEnclosure></item><item><title>#112 Advanced Bayesian Regression, with Tomi Capretto</title><itunes:title>Advanced Bayesian Regression, with Tomi Capretto</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Teaching Bayesian Concepts Using M&amp;Ms: Tomi Capretto uses an engaging classroom exercise involving M&amp;Ms to teach Bayesian statistics, making abstract concepts tangible and intuitive for students.</li><li class="ql-align-justify">Practical Applications of Bayesian Methods: Discussion on the real-world application of Bayesian methods in projects at PyMC Labs and in university settings, emphasizing the practical impact and accessibility of Bayesian statistics.</li><li class="ql-align-justify">Contributions to Open-Source Software: Tomi’s involvement in developing Bambi and other open-source tools demonstrates the importance of community contributions to advancing statistical software.</li><li class="ql-align-justify">Challenges in Statistical Education: Tomi talks about the challenges and rewards of teaching complex statistical concepts to students who are accustomed to frequentist approaches, highlighting the shift to thinking probabilistically in Bayesian frameworks.</li><li class="ql-align-justify">Future of Bayesian Tools: The discussion also touches on the future enhancements for Bambi and PyMC, aiming to make these tools more robust and user-friendly for a wider audience, including those who are not professional statisticians.&nbsp;</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">05:36 Tomi's Work and Teaching</p><p class="ql-align-justify">10:28 Teaching Complex Statistical Concepts with Practical Exercises</p><p class="ql-align-justify">23:17 Making Bayesian Modeling Accessible in Python</p><p class="ql-align-justify">38:46 Advanced Regression with Bambi</p><p class="ql-align-justify">41:14 The Power of Linear Regression</p><p class="ql-align-justify">42:45 Exploring Advanced Regression Techniques</p><p class="ql-align-justify">44:11 Regression Models and Dot Products</p><p class="ql-align-justify">45:37 Advanced Concepts in Regression</p><p class="ql-align-justify">46:36 Diagnosing and Handling Overdispersion</p><p class="ql-align-justify">47:35 Parameter Identifiability and Overparameterization</p><p class="ql-align-justify">50:29 Visualizations and Course Highlights</p><p class="ql-align-justify">51:30 Exploring Niche and Advanced Concepts</p><p class="ql-align-justify">56:56 The Power of Zero-Sum Normal</p><p class="ql-align-justify">59:59 The Value of Exercises and Community</p><p class="ql-align-justify">01:01:56 Optimizing Computation with Sparse Matrices</p><p class="ql-align-justify">01:13:37 Avoiding MCMC and Exploring Alternatives</p><p class="ql-align-justify">01:18:27 Making Connections Between Different Models</p><p><strong>Thank you to my Patrons for making this episode...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Teaching Bayesian Concepts Using M&amp;Ms: Tomi Capretto uses an engaging classroom exercise involving M&amp;Ms to teach Bayesian statistics, making abstract concepts tangible and intuitive for students.</li><li class="ql-align-justify">Practical Applications of Bayesian Methods: Discussion on the real-world application of Bayesian methods in projects at PyMC Labs and in university settings, emphasizing the practical impact and accessibility of Bayesian statistics.</li><li class="ql-align-justify">Contributions to Open-Source Software: Tomi’s involvement in developing Bambi and other open-source tools demonstrates the importance of community contributions to advancing statistical software.</li><li class="ql-align-justify">Challenges in Statistical Education: Tomi talks about the challenges and rewards of teaching complex statistical concepts to students who are accustomed to frequentist approaches, highlighting the shift to thinking probabilistically in Bayesian frameworks.</li><li class="ql-align-justify">Future of Bayesian Tools: The discussion also touches on the future enhancements for Bambi and PyMC, aiming to make these tools more robust and user-friendly for a wider audience, including those who are not professional statisticians.&nbsp;</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">05:36 Tomi's Work and Teaching</p><p class="ql-align-justify">10:28 Teaching Complex Statistical Concepts with Practical Exercises</p><p class="ql-align-justify">23:17 Making Bayesian Modeling Accessible in Python</p><p class="ql-align-justify">38:46 Advanced Regression with Bambi</p><p class="ql-align-justify">41:14 The Power of Linear Regression</p><p class="ql-align-justify">42:45 Exploring Advanced Regression Techniques</p><p class="ql-align-justify">44:11 Regression Models and Dot Products</p><p class="ql-align-justify">45:37 Advanced Concepts in Regression</p><p class="ql-align-justify">46:36 Diagnosing and Handling Overdispersion</p><p class="ql-align-justify">47:35 Parameter Identifiability and Overparameterization</p><p class="ql-align-justify">50:29 Visualizations and Course Highlights</p><p class="ql-align-justify">51:30 Exploring Niche and Advanced Concepts</p><p class="ql-align-justify">56:56 The Power of Zero-Sum Normal</p><p class="ql-align-justify">59:59 The Value of Exercises and Community</p><p class="ql-align-justify">01:01:56 Optimizing Computation with Sparse Matrices</p><p class="ql-align-justify">01:13:37 Avoiding MCMC and Exploring Alternatives</p><p class="ql-align-justify">01:18:27 Making Connections Between Different Models</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p class="ql-align-justify"><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li>Tomi’s website: <a href="https://tomicapretto.com/" rel="noopener noreferrer" target="_blank">https://tomicapretto.com/</a></li><li>Tomi on GitHub: <a href="https://github.com/tomicapretto" rel="noopener noreferrer" target="_blank">https://github.com/tomicapretto</a></li><li>Tomi on Linkedin: <a href="https://www.linkedin.com/in/tom%C3%A1s-capretto-a89873106/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/tom%C3%A1s-capretto-a89873106/</a></li><li>Tomi on Twitter: <a href="https://x.com/caprettotomas" rel="noopener noreferrer" target="_blank">https://x.com/caprettotomas</a></li><li>Advanced Regression course (get 10% off if you’re a Patron of the show): <a href="https://www.intuitivebayes.com/advanced-regression" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/advanced-regression</a></li><li>Bambi: <a href="https://bambinos.github.io/bambi/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/</a></li><li>LBS #35 The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/</a></li><li>LBS #1 Bayes, open-source and bioinformatics, with Osvaldo Martin: <a href="https://learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin/</a></li><li>patsy - Describing statistical models in Python: <a href="https://patsy.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://patsy.readthedocs.io/en/latest/</a></li><li>formulae - Formulas for mixed-models in Python: <a href="https://bambinos.github.io/formulae/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/formulae/</a></li><li>Introducing Bayesian Analysis With m&amp;m's®: An Active-Learning Exercise for Undergraduates: <a href="https://www.tandfonline.com/doi/full/10.1080/10691898.2019.1604106" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/full/10.1080/10691898.2019.1604106</a></li><li>Richly Parameterized Linear Models Additive, Time Series, and Spatial Models Using Random Effects <a href="https://www.routledge.com/Richly-Parameterized-Linear-Models-Additive-Time-Series-and-Spatial-Models-Using-Random-Effects/Hodges/p/book/9780367533731" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Richly-Parameterized-Linear-Models-Additive-Time-Series-and-Spatial-Models-Using-Random-Effects/Hodges/p/book/9780367533731</a></li><li>Dan Simpson’s Blog (link to blogs with the ‘sparse matrices’ tag): <a href="https://dansblog.netlify.app/#category=Sparse%20matrices" rel="noopener noreferrer" target="_blank">https://dansblog.netlify.app/#category=Sparse%20matrices</a></li><li>Repository for Sparse Matrix-Vector dot product: <a href="https://github.com/tomicapretto/dot_tests" rel="noopener noreferrer" target="_blank">https://github.com/tomicapretto/dot_tests</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/112-advanced-bayesian-regression-tomi-capretto]]></link><guid isPermaLink="false">62c9c2b9-ac4c-4669-9d2d-2ed5c11d8f07</guid><itunes:image href="https://artwork.captivate.fm/ae2ba649-1abe-48e9-9498-a52850789f02/AMM_YvMSVCChlaO2jo3GqHbF.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 07 Aug 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/da73af57-3c85-4971-bf5d-7289834d09d6/112-tcapretto-full-mp3.mp3" length="170974592" type="audio/mpeg"/><itunes:duration>01:27:19</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>112</itunes:episode><itunes:season>1</itunes:season><podcast:episode>112</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/7da46e2e-10f3-4405-82c3-fc1a30ee9445/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/7da46e2e-10f3-4405-82c3-fc1a30ee9445/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#112 Advanced Bayesian Regression, with Tomi Capretto"><podcast:source uri="https://youtu.be/Gp8ysqWRKIE"/></podcast:alternateEnclosure></item><item><title>#111 Nerdinsights from the Football Field, with Patrick Ward</title><itunes:title>Nerdinsights from the Football Field, with Patrick Ward</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p class="ql-align-justify">Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Communicating Bayesian concepts to non-technical audiences in sports analytics can be challenging, but it is important to provide clear explanations and address limitations.</li><li class="ql-align-justify">Understanding the model and its assumptions is crucial for effective communication and decision-making.</li><li class="ql-align-justify">Involving domain experts, such as scouts and coaches, can provide valuable insights and improve the model's relevance and usefulness.</li><li class="ql-align-justify">Customizing the model to align with the specific needs and questions of the stakeholders is essential for successful implementation.&nbsp;</li><li class="ql-align-justify">Understanding the needs of decision-makers is crucial for effectively communicating and utilizing models in sports analytics.</li><li class="ql-align-justify">Predicting the impact of training loads on athletes' well-being and performance is a challenging frontier in sports analytics.</li><li class="ql-align-justify">Identifying discrete events in team sports data is essential for analysis and development of models.</li></ul><br/><p class="ql-align-justify"><strong>Chapters:</strong></p><p class="ql-align-justify">00:00 Bayesian Statistics in Sports Analytics</p><p class="ql-align-justify">18:29 Applying Bayesian Stats in Analyzing Player Performance and Injury Risk</p><p class="ql-align-justify">36:21 Challenges in Communicating Bayesian Concepts to Non-Statistical Decision-Makers</p><p class="ql-align-justify">41:04 Understanding Model Behavior and Validation through Simulations</p><p class="ql-align-justify">43:09 Applying Bayesian Methods in Sports Analytics</p><p class="ql-align-justify">48:03 Clarifying Questions and Utilizing Frameworks</p><p class="ql-align-justify">53:41 Effective Communication of Statistical Concepts</p><p class="ql-align-justify">57:50 Integrating Domain Expertise with Statistical Models</p><p class="ql-align-justify">01:13:43 The Importance of Good Data</p><p class="ql-align-justify">01:18:11 The Future of Sports Analytics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p class="ql-align-justify"><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p class="ql-align-justify">Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Communicating Bayesian concepts to non-technical audiences in sports analytics can be challenging, but it is important to provide clear explanations and address limitations.</li><li class="ql-align-justify">Understanding the model and its assumptions is crucial for effective communication and decision-making.</li><li class="ql-align-justify">Involving domain experts, such as scouts and coaches, can provide valuable insights and improve the model's relevance and usefulness.</li><li class="ql-align-justify">Customizing the model to align with the specific needs and questions of the stakeholders is essential for successful implementation.&nbsp;</li><li class="ql-align-justify">Understanding the needs of decision-makers is crucial for effectively communicating and utilizing models in sports analytics.</li><li class="ql-align-justify">Predicting the impact of training loads on athletes' well-being and performance is a challenging frontier in sports analytics.</li><li class="ql-align-justify">Identifying discrete events in team sports data is essential for analysis and development of models.</li></ul><br/><p class="ql-align-justify"><strong>Chapters:</strong></p><p class="ql-align-justify">00:00 Bayesian Statistics in Sports Analytics</p><p class="ql-align-justify">18:29 Applying Bayesian Stats in Analyzing Player Performance and Injury Risk</p><p class="ql-align-justify">36:21 Challenges in Communicating Bayesian Concepts to Non-Statistical Decision-Makers</p><p class="ql-align-justify">41:04 Understanding Model Behavior and Validation through Simulations</p><p class="ql-align-justify">43:09 Applying Bayesian Methods in Sports Analytics</p><p class="ql-align-justify">48:03 Clarifying Questions and Utilizing Frameworks</p><p class="ql-align-justify">53:41 Effective Communication of Statistical Concepts</p><p class="ql-align-justify">57:50 Integrating Domain Expertise with Statistical Models</p><p class="ql-align-justify">01:13:43 The Importance of Good Data</p><p class="ql-align-justify">01:18:11 The Future of Sports Analytics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p class="ql-align-justify"><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li>LBS Sports Analytics playlist: <a href="https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4</a></li><li>Patrick’s website: <a href="http://optimumsportsperformance.com/blog/" rel="noopener noreferrer" target="_blank">http://optimumsportsperformance.com/blog/</a></li><li>Patrick on GitHub: <a href="https://github.com/pw2" rel="noopener noreferrer" target="_blank">https://github.com/pw2</a></li><li>Patrick on Linkedin: <a href="https://www.linkedin.com/in/patrickward02/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/patrickward02/</a></li><li>Patrick on Twitter: <a href="https://twitter.com/OSPpatrick" rel="noopener noreferrer" target="_blank">https://twitter.com/OSPpatrick</a></li><li>Patrick &amp; Ellis Screencast: <a href="https://github.com/thebioengineer/TidyX" rel="noopener noreferrer" target="_blank">https://github.com/thebioengineer/TidyX</a></li><li>Patrick on Research Gate: <a href="https://www.researchgate.net/profile/Patrick-Ward-10" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/profile/Patrick-Ward-10</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript:</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/111-nerdinsights-football-field-patrick-ward]]></link><guid isPermaLink="false">e10456b3-bca8-4d12-9c09-e42ba63256cb</guid><itunes:image href="https://artwork.captivate.fm/58502245-c8cd-476b-aba4-cdb674794608/CypH0-fh-lBG_QKvZS6ZWf_T.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 24 Jul 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/32b0c679-05f4-4018-a317-1987021fe1ac/111-Pward-full-MP3.mp3" length="167913073" type="audio/mpeg"/><itunes:duration>01:25:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>111</itunes:episode><itunes:season>1</itunes:season><podcast:episode>111</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/d4be7004-fc3d-4a40-9f03-acbf905bd8e7/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/d4be7004-fc3d-4a40-9f03-acbf905bd8e7/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#111 Nerdinsights from the Football Field, with Patrick Ward"><podcast:source uri="https://youtu.be/Z9pWFI-Fn5I"/></podcast:alternateEnclosure></item><item><title>#110 Unpacking Bayesian Methods in AI with Sam Duffield</title><itunes:title>Unpacking Bayesian Methods in AI with Sam Duffield</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Use mini-batch methods to efficiently process large datasets within Bayesian frameworks in enterprise AI applications.</li><li class="ql-align-justify">Apply approximate inference techniques, like stochastic gradient MCMC and Laplace approximation, to optimize Bayesian analysis in practical settings.</li><li class="ql-align-justify">Explore thermodynamic computing to significantly speed up Bayesian computations, enhancing model efficiency and scalability.</li><li class="ql-align-justify">Leverage the Posteriors python package for flexible and integrated Bayesian analysis in modern machine learning workflows.</li><li class="ql-align-justify">Overcome challenges in Bayesian inference by simplifying complex concepts for non-expert audiences, ensuring the practical application of statistical models.</li><li class="ql-align-justify">Address the intricacies of model assumptions and communicate effectively to non-technical stakeholders to enhance decision-making processes.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Large-Scale Machine Learning</p><p class="ql-align-justify">11:26 Scalable and Flexible Bayesian Inference with Posteriors</p><p class="ql-align-justify">25:56 The Role of Temperature in Bayesian Models</p><p class="ql-align-justify">32:30 Stochastic Gradient MCMC for Large Datasets</p><p class="ql-align-justify">36:12 Introducing Posteriors: Bayesian Inference in Machine Learning</p><p class="ql-align-justify">41:22 Uncertainty Quantification and Improved Predictions</p><p class="ql-align-justify">52:05 Supporting New Algorithms and Arbitrary Likelihoods</p><p class="ql-align-justify">59:16 Thermodynamic Computing</p><p class="ql-align-justify">01:06:22 Decoupling Model Specification, Data Generation, and Inference</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Use mini-batch methods to efficiently process large datasets within Bayesian frameworks in enterprise AI applications.</li><li class="ql-align-justify">Apply approximate inference techniques, like stochastic gradient MCMC and Laplace approximation, to optimize Bayesian analysis in practical settings.</li><li class="ql-align-justify">Explore thermodynamic computing to significantly speed up Bayesian computations, enhancing model efficiency and scalability.</li><li class="ql-align-justify">Leverage the Posteriors python package for flexible and integrated Bayesian analysis in modern machine learning workflows.</li><li class="ql-align-justify">Overcome challenges in Bayesian inference by simplifying complex concepts for non-expert audiences, ensuring the practical application of statistical models.</li><li class="ql-align-justify">Address the intricacies of model assumptions and communicate effectively to non-technical stakeholders to enhance decision-making processes.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Large-Scale Machine Learning</p><p class="ql-align-justify">11:26 Scalable and Flexible Bayesian Inference with Posteriors</p><p class="ql-align-justify">25:56 The Role of Temperature in Bayesian Models</p><p class="ql-align-justify">32:30 Stochastic Gradient MCMC for Large Datasets</p><p class="ql-align-justify">36:12 Introducing Posteriors: Bayesian Inference in Machine Learning</p><p class="ql-align-justify">41:22 Uncertainty Quantification and Improved Predictions</p><p class="ql-align-justify">52:05 Supporting New Algorithms and Arbitrary Likelihoods</p><p class="ql-align-justify">59:16 Thermodynamic Computing</p><p class="ql-align-justify">01:06:22 Decoupling Model Specification, Data Generation, and Inference</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Sam on Twitter: <a href="https://x.com/Sam_Duffield" rel="noopener noreferrer" target="_blank">https://x.com/Sam_Duffield</a></li><li>Sam on Scholar: <a href="https://scholar.google.com/citations?user=7wm_ka8AAAAJ&amp;hl=en&amp;oi=ao" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=7wm_ka8AAAAJ&amp;hl=en&amp;oi=ao</a>&nbsp;</li><li>Sam on Linkedin: <a href="https://www.linkedin.com/in/samduffield/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/samduffield/</a></li><li>Sam on GitHub: <a href="https://github.com/SamDuffield" rel="noopener noreferrer" target="_blank">https://github.com/SamDuffield</a></li><li>Posteriors paper (new!): <a href="https://arxiv.org/abs/2406.00104" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2406.00104</a>&nbsp;</li><li>Blog post introducing Posteriors: <a href="https://blog.normalcomputing.ai/posts/introducing-posteriors/posteriors.html" rel="noopener noreferrer" target="_blank">https://blog.normalcomputing.ai/posts/introducing-posteriors/posteriors.html</a></li><li>Posteriors docs: <a href="https://normal-computing.github.io/posteriors/" rel="noopener noreferrer" target="_blank">https://normal-computing.github.io/posteriors/</a></li><li>Paper introducing Posteriors – Scalable Bayesian Learning with posteriors: <a href="https://arxiv.org/abs/2406.00104v1" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2406.00104v1</a></li><li>Normal Computing scholar: <a href="https://scholar.google.com/citations?hl=en&amp;user=jGCLWRUAAAAJ&amp;view_op=list_works" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?hl=en&amp;user=jGCLWRUAAAAJ&amp;view_op=list_works</a></li><li>Thermo blogs: <a href="https://blog.normalcomputing.ai/posts/2023-11-09-thermodynamic-inversion/thermo-inversion.html" rel="noopener noreferrer" target="_blank">https://blog.normalcomputing.ai/posts/2023-11-09-thermodynamic-inversion/thermo-inversion.html</a></li><li><a href="https://blog.normalcomputing.ai/posts/thermox/thermox.html" rel="noopener noreferrer" target="_blank">https://blog.normalcomputing.ai/posts/thermox/thermox.html</a></li><li>Great paper on SGMCMC: <a href="https://proceedings.neurips.cc/paper_files/paper/2015/file/9a4400501febb2a95e79248486a5f6d3-Paper.pdf" rel="noopener noreferrer" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2015/file/9a4400501febb2a95e79248486a5f6d3-Paper.pdf</a></li><li>David MacKay textbook on Sustainable Energy: <a href="https://www.withouthotair.com/" rel="noopener noreferrer" target="_blank">https://www.withouthotair.com/</a></li><li>LBS #107 - Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/</a></li><li>LBS #98 - Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/110-unpacking-bayesian-methods-ai-sam-duffield]]></link><guid isPermaLink="false">b21264af-a580-45fc-bb17-f3de26317b78</guid><itunes:image href="https://artwork.captivate.fm/20237b27-b0aa-4343-98cb-a2f2ed17d21c/eyoK7R-90R8fee8dMWu6Ckai.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 10 Jul 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/8ae31d05-4d52-4a56-beda-54dd75046476/110-Sduffield-full-MP3.mp3" length="142454218" type="audio/mpeg"/><itunes:duration>01:12:27</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>110</itunes:episode><itunes:season>1</itunes:season><podcast:episode>110</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/52d77409-45c8-437c-b12c-9da15953e188/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/52d77409-45c8-437c-b12c-9da15953e188/index.html" type="text/html"/></item><item><title>#109 Prior Sensitivity Analysis, Overfitting &amp; Model Selection, with Sonja Winter</title><itunes:title>Prior Sensitivity Analysis, Overfitting &amp; Model Selection, with Sonja Winter</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em> !</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong></p><ul><li class="ql-align-justify">Bayesian methods align better with researchers' intuitive understanding of research questions and provide more tools to evaluate and understand models.</li><li class="ql-align-justify">Prior sensitivity analysis is crucial for understanding the robustness of findings to changes in priors and helps in contextualizing research findings.</li><li class="ql-align-justify">Bayesian methods offer an elegant and efficient way to handle missing data in longitudinal studies, providing more flexibility and information for researchers.</li><li class="ql-align-justify">Fit indices in Bayesian model selection are effective in detecting underfitting but may struggle to detect overfitting, highlighting the need for caution in model complexity.</li><li class="ql-align-justify">Bayesian methods have the potential to revolutionize educational research by addressing the challenges of small samples, complex nesting structures, and longitudinal data.&nbsp;</li><li class="ql-align-justify">Posterior predictive checks are valuable for model evaluation and selection.</li></ul><br/><p><strong>Chapters</strong></p><p>00:00 The Power and Importance of Priors</p><p>09:29 Updating Beliefs and Choosing Reasonable Priors</p><p>16:08 Assessing Robustness with Prior Sensitivity Analysis</p><p>34:53 Aligning Bayesian Methods with Researchers' Thinking</p><p>37:10 Detecting Overfitting in SEM</p><p>43:48 Evaluating Model Fit with Posterior Predictive Checks</p><p>47:44 Teaching Bayesian Methods </p><p>54:07 Future Developments in Bayesian Statistics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em> !</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong></p><ul><li class="ql-align-justify">Bayesian methods align better with researchers' intuitive understanding of research questions and provide more tools to evaluate and understand models.</li><li class="ql-align-justify">Prior sensitivity analysis is crucial for understanding the robustness of findings to changes in priors and helps in contextualizing research findings.</li><li class="ql-align-justify">Bayesian methods offer an elegant and efficient way to handle missing data in longitudinal studies, providing more flexibility and information for researchers.</li><li class="ql-align-justify">Fit indices in Bayesian model selection are effective in detecting underfitting but may struggle to detect overfitting, highlighting the need for caution in model complexity.</li><li class="ql-align-justify">Bayesian methods have the potential to revolutionize educational research by addressing the challenges of small samples, complex nesting structures, and longitudinal data.&nbsp;</li><li class="ql-align-justify">Posterior predictive checks are valuable for model evaluation and selection.</li></ul><br/><p><strong>Chapters</strong></p><p>00:00 The Power and Importance of Priors</p><p>09:29 Updating Beliefs and Choosing Reasonable Priors</p><p>16:08 Assessing Robustness with Prior Sensitivity Analysis</p><p>34:53 Aligning Bayesian Methods with Researchers' Thinking</p><p>37:10 Detecting Overfitting in SEM</p><p>43:48 Evaluating Model Fit with Posterior Predictive Checks</p><p>47:44 Teaching Bayesian Methods </p><p>54:07 Future Developments in Bayesian Statistics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show</strong></p><ul><li>Sonja’s website: <a href="https://winterstat.github.io/" rel="noopener noreferrer" target="_blank">https://winterstat.github.io/</a></li><li>Sonja on Twitter: <a href="https://twitter.com/winterstat" rel="noopener noreferrer" target="_blank">https://twitter.com/winterstat</a></li><li>Sonja on GitHub: <a href="https://github.com/winterstat" rel="noopener noreferrer" target="_blank">https://github.com/winterstat</a></li><li>Under-Fitting and Over-Fitting – The Performance of Bayesian Model Selection and Fit Indices in SEM: <a href="https://www.tandfonline.com/doi/full/10.1080/10705511.2023.2280952" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/full/10.1080/10705511.2023.2280952</a></li><li>LBS #102 – Bayesian Structural Equation Modeling &amp; Causal Inference in Psychometrics, with Ed Merkle: <a href="https://youtu.be/lXd-qstzTh4?si=jLg_qZTt1oQqRO0R" rel="noopener noreferrer" target="_blank">https://youtu.be/lXd-qstzTh4?si=jLg_qZTt1oQqRO0R</a></li><li>LBS #107 - Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt: <a href="https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt/</a></li><li>BayesFlow tutorial: <a href="https://bayesflow.org/_examples/Intro_Amortized_Posterior_Estimation.html" rel="noopener noreferrer" target="_blank">https://bayesflow.org/_examples/Intro_Amortized_Posterior_Estimation.html</a></li><li>LBS #106 Active Statistics, Two Truths &amp; a Lie, with Andrew Gelman: <a href="https://learnbayesstats.com/episode/106-active-statistics-two-truths-a-lie-andrew-gelman/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/106-active-statistics-two-truths-a-lie-andrew-gelman/</a></li><li>LBS #61 Why we still use non-Bayesian methods, with EJ Wagenmakers: <a href="https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/</a></li><li>Bayesian Workflow paper: <a href="https://arxiv.org/abs/2011.01808" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2011.01808</a></li><li>Michael Betancourts'blog: <a href="https://betanalpha.github.io/writing/" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/writing/</a></li><li>LBS #35 The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/</a></li><li>Bayesian Model-Building Interface in Python: <a href="https://bambinos.github.io/bambi/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/</a></li><li>Advanced Regression online course: <a href="https://www.intuitivebayes.com/advanced-regression" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/advanced-regression</a></li><li>BLIMP: <a href="https://www.appliedmissingdata.com/blimp" rel="noopener noreferrer" target="_blank">https://www.appliedmissingdata.com/blimp</a>&nbsp;</li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/109-prior-sensitivity-analysis-overfitting-model-selection-sonja-winter]]></link><guid isPermaLink="false">cfdf98f9-47b8-4964-8eaa-be41328c3100</guid><itunes:image href="https://artwork.captivate.fm/b0f4e962-8718-4f86-b96a-e565f84b797d/XiWkq6XeLaZU6ImW7dlBU0Ze.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 25 Jun 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/27f799d3-c611-4dc3-aa4c-8c877fd97ee1/109-Swinter-full-MP3.mp3" length="139346144" type="audio/mpeg"/><itunes:duration>01:10:50</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>109</itunes:episode><itunes:season>1</itunes:season><podcast:episode>109</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/d11b5fb3-d66b-475f-89a6-4fbffcf70ae5/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/d11b5fb3-d66b-475f-89a6-4fbffcf70ae5/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#109 Prior Sensitivity Analysis, Overfitting &amp; Model Selection, with Sonja Winter"><podcast:source uri="https://youtu.be/vDqVbfZGC7k"/></podcast:alternateEnclosure></item><item><title>#108 Modeling Sports &amp; Extracting Player Values, with Paul Sabin</title><itunes:title>Modeling Sports &amp; Extracting Player Values, with Paul Sabin</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong></p><ul><li class="ql-align-justify">Convincing non-stats stakeholders in sports analytics can be challenging, but building trust and confirming their prior beliefs can help in gaining acceptance.</li><li class="ql-align-justify">Combining subjective beliefs with objective data in Bayesian analysis leads to more accurate forecasts.</li><li class="ql-align-justify">The availability of massive data sets has revolutionized sports analytics, allowing for more complex and accurate models.</li><li class="ql-align-justify">Sports analytics models should consider factors like rest, travel, and altitude to capture the full picture of team performance.</li><li class="ql-align-justify">The impact of budget on team performance in American sports and the use of plus-minus models in basketball and American football are important considerations in sports analytics.</li><li class="ql-align-justify">The future of sports analytics lies in making analysis more accessible and digestible for everyday fans.</li><li class="ql-align-justify">There is a need for more focus on estimating distributions and variance around estimates in sports analytics.</li><li class="ql-align-justify">AI tools can empower analysts to do their own analysis and make better decisions, but it's important to ensure they understand the assumptions and structure of the data.</li><li class="ql-align-justify">Measuring the value of certain positions, such as midfielders in soccer, is a challenging problem in sports analytics.</li><li class="ql-align-justify">Game theory plays a significant role in sports strategies, and optimal strategies can change over time as the game evolves.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong></p><p class="ql-align-justify">00:00 Introduction and Overview</p><p class="ql-align-justify">09:27 The Power of Bayesian Analysis in Sports Modeling</p><p class="ql-align-justify">16:28 The Revolution of Massive Data Sets in Sports Analytics</p><p class="ql-align-justify">31:03 The Impact of Budget in Sports Analytics</p><p class="ql-align-justify">39:35 Introduction to Sports Analytics</p><p class="ql-align-justify">52:22 Plus-Minus Models in American Football</p><p class="ql-align-justify">01:04:11 The Future of Sports Analytics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>awesome work</em></a><em>!</em></p><p>Visit our <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">Patreon page</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong></p><ul><li class="ql-align-justify">Convincing non-stats stakeholders in sports analytics can be challenging, but building trust and confirming their prior beliefs can help in gaining acceptance.</li><li class="ql-align-justify">Combining subjective beliefs with objective data in Bayesian analysis leads to more accurate forecasts.</li><li class="ql-align-justify">The availability of massive data sets has revolutionized sports analytics, allowing for more complex and accurate models.</li><li class="ql-align-justify">Sports analytics models should consider factors like rest, travel, and altitude to capture the full picture of team performance.</li><li class="ql-align-justify">The impact of budget on team performance in American sports and the use of plus-minus models in basketball and American football are important considerations in sports analytics.</li><li class="ql-align-justify">The future of sports analytics lies in making analysis more accessible and digestible for everyday fans.</li><li class="ql-align-justify">There is a need for more focus on estimating distributions and variance around estimates in sports analytics.</li><li class="ql-align-justify">AI tools can empower analysts to do their own analysis and make better decisions, but it's important to ensure they understand the assumptions and structure of the data.</li><li class="ql-align-justify">Measuring the value of certain positions, such as midfielders in soccer, is a challenging problem in sports analytics.</li><li class="ql-align-justify">Game theory plays a significant role in sports strategies, and optimal strategies can change over time as the game evolves.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong></p><p class="ql-align-justify">00:00 Introduction and Overview</p><p class="ql-align-justify">09:27 The Power of Bayesian Analysis in Sports Modeling</p><p class="ql-align-justify">16:28 The Revolution of Massive Data Sets in Sports Analytics</p><p class="ql-align-justify">31:03 The Impact of Budget in Sports Analytics</p><p class="ql-align-justify">39:35 Introduction to Sports Analytics</p><p class="ql-align-justify">52:22 Plus-Minus Models in American Football</p><p class="ql-align-justify">01:04:11 The Future of Sports Analytics</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary, Blake Walters, Jonathan Morgan and Francesco Madrisotti</em>.</p><p><strong>Links from the show:</strong></p><ul><li>LBS Sports Analytics playlist: <a href="https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL7RjIaSLWh5kDiPVMUSyhvFaXL3NoXOe4</a></li><li>Paul’s website: <a href="https://sabinanalytics.com/" rel="noopener noreferrer" target="_blank">https://sabinanalytics.com/</a></li><li>Paul on GitHub: <a href="https://github.com/sabinanalytics" rel="noopener noreferrer" target="_blank">https://github.com/sabinanalytics</a>&nbsp;</li><li>Paul on Linkedin: <a href="https://www.linkedin.com/in/rpaulsabin/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/rpaulsabin/</a></li><li>Paul on Twitter: <a href="https://twitter.com/SabinAnalytics" rel="noopener noreferrer" target="_blank">https://twitter.com/SabinAnalytics</a></li><li>Paul on Google Scholar: <a href="https://scholar.google.com/citations?user=wAezxZ4AAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=wAezxZ4AAAAJ&amp;hl=en</a></li><li>Soccer Power Ratings &amp; Projections: <a href="https://sabinanalytics.com/ratings/soccer/" rel="noopener noreferrer" target="_blank">https://sabinanalytics.com/ratings/soccer/</a></li><li>Estimating player value in American football using plus–minus models: <a href="https://www.degruyter.com/document/doi/10.1515/jqas-2020-0033/html" rel="noopener noreferrer" target="_blank">https://www.degruyter.com/document/doi/10.1515/jqas-2020-0033/html</a></li><li>World Football R Package: <a href="https://github.com/JaseZiv/worldfootballR" rel="noopener noreferrer" target="_blank">https://github.com/JaseZiv/worldfootballR</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/108-modeling-sports-extracting-player-values-paul-sabin]]></link><guid isPermaLink="false">c610bae8-5603-4c9a-97de-2b5c4f887bda</guid><itunes:image href="https://artwork.captivate.fm/0d700197-ba5e-4d7f-b2a1-e52ae0326197/sJ1jUHHhGqFIQTUb62-1JuBE.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 14 Jun 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/fc42927e-17b1-432b-8687-d67b45ec3cd9/108-full.mp3" length="37475492" type="audio/mpeg"/><itunes:duration>01:18:04</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>108</itunes:episode><itunes:season>1</itunes:season><podcast:episode>108</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/943320f5-0545-484c-9a32-ac8c231796fd/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/943320f5-0545-484c-9a32-ac8c231796fd/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#108 Modeling Sports &amp; Extracting Player Values, with Paul Sabin"><podcast:source uri="https://youtu.be/cQillgLRdWY"/></podcast:alternateEnclosure></item><item><title>#107 Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt</title><itunes:title>Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Marvin Schmitt introduces the concept of amortized Bayesian inference, where the upfront training phase of a neural network is followed by fast posterior inference.</p><p class="ql-align-justify">Marvin will guide us through this new concept, discussing his work in probabilistic machine learning and uncertainty quantification, using Bayesian inference with deep neural networks.&nbsp;</p><p class="ql-align-justify">He also introduces BayesFlow, a Python library for amortized Bayesian workflows, and discusses its use cases in various fields, while also touching on the concept of deep fusion and its relation to multimodal simulation-based inference.</p><p class="ql-align-justify">A PhD student in computer science at the University of Stuttgart, Marvin is supervised by two LBS guests you surely know — Paul Bürkner and Aki Vehtari. Marvin’s research combines deep learning and statistics, to make Bayesian inference fast and trustworthy.&nbsp;</p><p class="ql-align-justify">In his free time, Marvin enjoys board games and is a passionate guitar player.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary and Blake Walters</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Amortized Bayesian inference...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Marvin Schmitt introduces the concept of amortized Bayesian inference, where the upfront training phase of a neural network is followed by fast posterior inference.</p><p class="ql-align-justify">Marvin will guide us through this new concept, discussing his work in probabilistic machine learning and uncertainty quantification, using Bayesian inference with deep neural networks.&nbsp;</p><p class="ql-align-justify">He also introduces BayesFlow, a Python library for amortized Bayesian workflows, and discusses its use cases in various fields, while also touching on the concept of deep fusion and its relation to multimodal simulation-based inference.</p><p class="ql-align-justify">A PhD student in computer science at the University of Stuttgart, Marvin is supervised by two LBS guests you surely know — Paul Bürkner and Aki Vehtari. Marvin’s research combines deep learning and statistics, to make Bayesian inference fast and trustworthy.&nbsp;</p><p class="ql-align-justify">In his free time, Marvin enjoys board games and is a passionate guitar player.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary and Blake Walters</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Amortized Bayesian inference combines deep learning and statistics to make posterior inference fast and trustworthy.</li><li class="ql-align-justify">Bayesian neural networks can be used for full Bayesian inference on neural network weights.</li><li class="ql-align-justify">Amortized Bayesian inference decouples the training phase and the posterior inference phase, making posterior sampling much faster.</li><li class="ql-align-justify">BayesFlow is a Python library for amortized Bayesian workflows, providing a user-friendly interface and modular architecture.</li><li class="ql-align-justify">Self-consistency loss is a technique that combines simulation-based inference and likelihood-based Bayesian inference, with a focus on amortization</li><li class="ql-align-justify">The BayesFlow package aims to make amortized Bayesian inference more accessible and provides sensible default values for neural networks.</li><li class="ql-align-justify">Deep fusion techniques allow for the fusion of multiple sources of information in neural networks.</li><li class="ql-align-justify">Generative models that are expressive and have one-step inference are an emerging topic in deep learning and probabilistic machine learning.</li><li class="ql-align-justify">Foundation models, which have a large training set and can handle out-of-distribution cases, are another intriguing area of research.</li></ul><br/><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to Amortized Bayesian Inference</p><p class="ql-align-justify">07:39 Bayesian Neural Networks</p><p class="ql-align-justify">11:47 Amortized Bayesian Inference and Posterior Inference</p><p class="ql-align-justify">23:20 BayesFlow: A Python Library for Amortized Bayesian Workflows</p><p class="ql-align-justify">38:15 Self-consistency loss: Bridging Simulation-Based Inference and Likelihood-Based Bayesian Inference</p><p class="ql-align-justify">41:35 Amortized Bayesian Inference</p><p class="ql-align-justify">43:53 Fusing Multiple Sources of Information</p><p class="ql-align-justify">45:19 Compensating for Missing Data</p><p class="ql-align-justify">56:17 Emerging Topics: Expressive Generative Models and Foundation Models</p><p class="ql-align-justify">01:06:18 The Future of Deep Learning and Probabilistic Machine Learning</p><p><strong>Links from the show:</strong></p><ul><li>Marvin’s website: <a href="https://www.marvinschmitt.com/" rel="noopener noreferrer" target="_blank">https://www.marvinschmitt.com/</a></li><li>Marvin on GitHub: <a href="https://github.com/marvinschmitt" rel="noopener noreferrer" target="_blank">https://github.com/marvinschmitt</a></li><li>Marvin on Linkedin: <a href="https://www.linkedin.com/in/marvin-schmitt/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/marvin-schmitt/</a></li><li>Marvin on Twitter: <a href="https://twitter.com/MarvinSchmittML" rel="noopener noreferrer" target="_blank">https://twitter.com/MarvinSchmittML</a></li><li>The BayesFlow package for amortized Bayesian workflows: <a href="https://bayesflow.org/" rel="noopener noreferrer" target="_blank">https://bayesflow.org/</a>&nbsp;</li><li>BayesFlow Forums for users: <a href="https://discuss.bayesflow.org" rel="noopener noreferrer" target="_blank">https://discuss.bayesflow.org</a></li><li>BayesFlow software paper (JOSS): <a href="https://joss.theoj.org/papers/10.21105/joss.05702" rel="noopener noreferrer" target="_blank">https://joss.theoj.org/papers/10.21105/joss.05702</a></li><li>Tutorial on amortized Bayesian inference with BayesFlow (Python): <a href="https://colab.research.google.com/drive/1ub9SivzBI5fMbSTwVM1pABsMlRupgqRb?usp=sharing" rel="noopener noreferrer" target="_blank">https://colab.research.google.com/drive/1ub9SivzBI5fMbSTwVM1pABsMlRupgqRb?usp=sharing</a>&nbsp;</li><li>Towards Reliable Amortized Bayesian Inference: <a href="https://www.marvinschmitt.com/speaking/pdf/slides_reliable_abi_botb.pdf" rel="noopener noreferrer" target="_blank">https://www.marvinschmitt.com/speaking/pdf/slides_reliable_abi_botb.pdf</a></li><li>Expand the model space that we amortize over (multiverse analyses, power scaling, …): “Sensitivity-Aware Amortized Bayesian Inference” <a href="https://arxiv.org/abs/2310.11122" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2310.11122</a></li><li>Use heterogeneous data sources in amortized inference: “Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference” <a href="https://arxiv.org/abs/2311.10671" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2311.10671</a></li><li>Use likelihood density information (explicit or even learned on the fly): “Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference”&nbsp; <a href="https://arxiv.org/abs/2310.04395" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2310.04395</a></li><li>LBS #98 Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></li><li>LBS #101 Black Holes Collisions &amp; Gravitational Waves, with LIGO Experts Christopher Berry &amp; John Veitch: <a href="https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/</a></li><li>Deep Learning book:&nbsp;<a href="https://www.deeplearningbook.org/" rel="noopener noreferrer" target="_blank">https://www.deeplearningbook.org/</a></li><li>Statistical Rethinking:&nbsp;<a href="https://xcelab.net/rm/" rel="noopener noreferrer" target="_blank">https://xcelab.net/rm/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/107-amortized-bayesian-inference-deep-neural-networks-marvin-schmitt]]></link><guid isPermaLink="false">3e489726-1562-4e83-86aa-175206de3974</guid><itunes:image href="https://artwork.captivate.fm/ddf41f6f-b67f-409b-a201-51a8dd41f15b/iynO8KhWTe0atJ43yG1u1AZ8.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 29 May 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/fe865888-8435-428e-9517-a7af8e2d2c4a/107-full.mp3" length="39180138" type="audio/mpeg"/><itunes:duration>01:21:37</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>107</itunes:episode><itunes:season>1</itunes:season><podcast:episode>107</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/767222a6-162a-42cc-aae1-05efb3e62be5/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/767222a6-162a-42cc-aae1-05efb3e62be5/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#107 Amortized Bayesian Inference with Deep Neural Networks, with Marvin Schmitt"><podcast:source uri="https://youtu.be/_lotzkvy6mY"/></podcast:alternateEnclosure></item><item><title>#106 Active Statistics, Two Truths &amp; a Lie, with Andrew Gelman</title><itunes:title>Active Statistics, Two Truths &amp; a Lie, with Andrew Gelman</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">If there is one guest I don’t need to introduce, it’s mister Andrew Gelman. So… I won’t! I will refer you back to his two previous appearances on the show though, because learning from Andrew is always a pleasure. So go ahead and listen to episodes 20 and 27.</p><p class="ql-align-justify">In this episode, Andrew and I discuss his new book, Active Statistics, which focuses on teaching and learning statistics through active student participation. Like this episode, the book is divided into three parts: 1) The ideas of statistics, regression, and causal inference; 2) The value of storytelling to make statistical concepts more relatable and interesting; 3) The importance of teaching statistics in an active learning environment, where students are engaged in problem-solving and discussion.</p><p class="ql-align-justify">And Andrew is so active and knowledgeable that we of course touched on a variety of other topics — but for that, you’ll have to listen ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary and Blake Walters</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- Active learning is essential for teaching and learning statistics.</p><p class="ql-align-justify">- Storytelling can make...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">If there is one guest I don’t need to introduce, it’s mister Andrew Gelman. So… I won’t! I will refer you back to his two previous appearances on the show though, because learning from Andrew is always a pleasure. So go ahead and listen to episodes 20 and 27.</p><p class="ql-align-justify">In this episode, Andrew and I discuss his new book, Active Statistics, which focuses on teaching and learning statistics through active student participation. Like this episode, the book is divided into three parts: 1) The ideas of statistics, regression, and causal inference; 2) The value of storytelling to make statistical concepts more relatable and interesting; 3) The importance of teaching statistics in an active learning environment, where students are engaged in problem-solving and discussion.</p><p class="ql-align-justify">And Andrew is so active and knowledgeable that we of course touched on a variety of other topics — but for that, you’ll have to listen ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel, Adan Romero, Will Geary and Blake Walters</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- Active learning is essential for teaching and learning statistics.</p><p class="ql-align-justify">- Storytelling can make statistical concepts more relatable and interesting.</p><p class="ql-align-justify">- Teaching statistics in an active learning environment engages students in problem-solving and discussion.</p><p class="ql-align-justify">- The book Active Statistics includes 52 stories, class participation activities, computer demonstrations, and homework assignments to facilitate active learning.</p><p class="ql-align-justify">- Active learning, where students actively engage with the material through activities and discussions, is an effective approach to teaching statistics.</p><p class="ql-align-justify">- The flipped classroom model, where students read and prepare before class and engage in problem-solving activities during class, can enhance learning and understanding.</p><p class="ql-align-justify">- Clear organization and fluency in teaching statistics are important for student comprehension and engagement.</p><p class="ql-align-justify">- Visualization plays a crucial role in understanding statistical concepts and aids in comprehension.</p><p class="ql-align-justify">- The future of statistical education may involve new approaches and technologies, but the challenge lies in finding effective ways to teach basic concepts and make them relevant to real-world problems.</p><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction and Background</p><p class="ql-align-justify">08:09 The Importance of Stories in Statistics Education</p><p class="ql-align-justify">30:28 Using 'Two Truths and a Lie' to Teach Logistic Regression</p><p class="ql-align-justify">38:08 The Power of Storytelling in Teaching Statistics</p><p class="ql-align-justify">57:26 The Importance of Visualization in Understanding Statistics</p><p class="ql-align-justify">01:07:03 The Future of Statistical Education</p><p><strong>Links from the show:</strong></p><ul><li>Andrew’s website: <a href="http://www.stat.columbia.edu/~gelman/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/</a></li><li>Andrew’s blog: <a href="https://statmodeling.stat.columbia.edu/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/</a>&nbsp;</li><li>Twitter links to blog posts: <a href="https://twitter.com/statmodeling" rel="noopener noreferrer" target="_blank">https://twitter.com/statmodeling</a></li><li><em>Active Statistics</em> page: <a href="http://www.stat.columbia.edu/~gelman/active-statistics/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/active-statistics/</a></li><li>“Two truths and a lie” as a class-participation activity: <a href="http://www.stat.columbia.edu/~gelman/research/published/truths_paper.pdf" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/research/published/truths_paper.pdf</a></li><li>Rohan Alexander’s book, Telling Stories with Data:&nbsp; <a href="https://tellingstorieswithdata.com/" rel="noopener noreferrer" target="_blank">https://tellingstorieswithdata.com/</a></li><li>Use code ACTSTAT24 to buy <em>Active Statistics</em> with 20% off through July 15, 2024: <a href="http://www.cambridge.org/9781009436212" rel="noopener noreferrer" target="_blank">www.cambridge.org/9781009436212</a></li><li>LBS #27, Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns: <a href="https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/</a></li><li>LBS #20 Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/</a></li><li>Slamming the sham – A Bayesian model for adaptive adjustment with noisy control data: <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/chickens.pdf" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/research/unpublished/chickens.pdf</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/106-active-statistics-two-truths-a-lie-andrew-gelman]]></link><guid isPermaLink="false">b3fb44fc-952a-4692-adeb-c3af7a80213e</guid><itunes:image href="https://artwork.captivate.fm/b50591c0-9045-4fdd-bdc5-c9e3c1db9654/dgH0EcIob1eMAzJY3bVHJFgQ.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 16 May 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/98116000-08cf-4769-9a5f-291c8288233c/106.mp3" length="36855240" type="audio/mpeg"/><itunes:duration>01:16:47</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>106</itunes:episode><itunes:season>1</itunes:season><podcast:episode>106</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/635b806e-21c8-4a63-91b6-361e3609b87e/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/635b806e-21c8-4a63-91b6-361e3609b87e/index.html" type="text/html"/><podcast:alternateEnclosure type="video/youtube" title="#106 Active Statistics, Two Truths &amp; a Lie, with Andrew Gelman"><podcast:source uri="https://youtu.be/YiNK8hDk5M4"/></podcast:alternateEnclosure></item><item><title>#105 The Power of Bayesian Statistics in Glaciology, with Andy Aschwanden &amp; Doug Brinkerhoff</title><itunes:title>The Power of Bayesian Statistics in Glaciology, with Andy Aschwanden &amp; Doug Brinkerhoff</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Andy Aschwanden and Doug Brinkerhoff tell us about their work in glaciology and the application of Bayesian statistics in studying glaciers. They discuss the use of computer models and data analysis in understanding glacier behavior and predicting sea level rise, and a lot of other fascinating topics.</p><p class="ql-align-justify">Andy grew up in the Swiss Alps, and studied Earth Sciences, with a focus on atmospheric and climate science and glaciology. After his PhD, Andy moved to Fairbanks, Alaska, and became involved with the Parallel Ice Sheet Model, the first open-source and openly-developed ice sheet model.</p><p class="ql-align-justify">His first PhD student was no other than… Doug Brinkerhoff! Doug did an MS in computer science at the University of Montana, focusing on numerical methods for ice sheet modeling, and then moved to Fairbanks to complete his PhD. While in Fairbanks, he became an ardent Bayesian after “seeing that uncertainty needs to be embraced rather than ignored”. Doug has since moved back to Montana, becoming faculty in the University of Montana’s computer science department.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel</em>, <em>Adan Romero and Will Geary</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Andy Aschwanden and Doug Brinkerhoff tell us about their work in glaciology and the application of Bayesian statistics in studying glaciers. They discuss the use of computer models and data analysis in understanding glacier behavior and predicting sea level rise, and a lot of other fascinating topics.</p><p class="ql-align-justify">Andy grew up in the Swiss Alps, and studied Earth Sciences, with a focus on atmospheric and climate science and glaciology. After his PhD, Andy moved to Fairbanks, Alaska, and became involved with the Parallel Ice Sheet Model, the first open-source and openly-developed ice sheet model.</p><p class="ql-align-justify">His first PhD student was no other than… Doug Brinkerhoff! Doug did an MS in computer science at the University of Montana, focusing on numerical methods for ice sheet modeling, and then moved to Fairbanks to complete his PhD. While in Fairbanks, he became an ardent Bayesian after “seeing that uncertainty needs to be embraced rather than ignored”. Doug has since moved back to Montana, becoming faculty in the University of Montana’s computer science department.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell, Gal Kampel</em>, <em>Adan Romero and Will Geary</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- Computer models and data analysis play a crucial role in understanding glacier behavior and predicting sea level rise.</p><p class="ql-align-justify">- Reliable data, especially on ice thickness and climate forcing, are essential for accurate modeling.</p><p class="ql-align-justify">- The collaboration between glaciology and Bayesian statistics has led to breakthroughs in understanding glacier evolution forecasts.</p><p class="ql-align-justify">-There is a need for open-source packages and tools to make glaciological models more accessible. Glaciology and ice sheet modeling are complex fields that require collaboration between domain experts and data scientists.</p><p class="ql-align-justify">- The use of Bayesian statistics in glaciology allows for a probabilistic framework to understand and communicate uncertainty in predictions.</p><p class="ql-align-justify">- Real-time forecasting of glacier behavior is an exciting area of research that could provide valuable information for communities living near glaciers.</p><p class="ql-align-justify"> -There is a need for further research in understanding existing data sets and developing simpler methods to analyze them.</p><p class="ql-align-justify">- The future of glaciology research lies in studying Alaskan glaciers and understanding the challenges posed by the changing Arctic environment.</p><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction and Background</p><p class="ql-align-justify">08:54 The Role of Statistics in Glaciology</p><p class="ql-align-justify">31:46 Open-Source Packages and Tools</p><p class="ql-align-justify">52:06 The Power of Bayesian Statistics in Glaciology</p><p class="ql-align-justify">01:06:34 Understanding Existing Data Sets and Developing Simpler Methods</p><p><strong>Links from the show:</strong></p><ul><li>Andy’s website: <a href="https://glaciers.gi.alaska.edu/people/aschwanden" rel="noopener noreferrer" target="_blank">https://glaciers.gi.alaska.edu/people/aschwanden</a></li><li>Doug’s website: <a href="https://dbrinkerhoff.org/" rel="noopener noreferrer" target="_blank">https://dbrinkerhoff.org/</a></li><li>Andy on GitHub: <a href="https://github.com/aaschwanden" rel="noopener noreferrer" target="_blank">https://github.com/aaschwanden</a>&nbsp;</li><li>Doug on GitHub: <a href="https://github.com/douglas-brinkerhoff/" rel="noopener noreferrer" target="_blank">https://github.com/douglas-brinkerhoff/</a></li><li>Andy on Twitter: <a href="https://twitter.com/glacierandy?lang=fr" rel="noopener noreferrer" target="_blank">https://twitter.com/glacierandy?lang=fr</a></li><li>Andy on Google Scholar: <a href="https://scholar.google.com/citations?user=CuvsLvMAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=CuvsLvMAAAAJ&amp;hl=en</a></li><li>Doug on Google Scholar: <a href="https://scholar.google.com/citations?user=FqU6ON8AAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=FqU6ON8AAAAJ&amp;hl=en</a></li><li>LBS #64, Modeling the Climate &amp; Gravity Waves, with Laura Mansfield: <a href="https://learnbayesstats.com/episode/64-modeling-climate-gravity-waves-laura-mansfield/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/64-modeling-climate-gravity-waves-laura-mansfield/</a></li><li>Parallel Ice Sheet Model: <a href="http://www.pism.io" rel="noopener noreferrer" target="_blank">www.pism.io</a></li><li>PISM on GitHub: <a href="https://github.com/pism/pism" rel="noopener noreferrer" target="_blank">https://github.com/pism/pism</a></li><li>Greenland View of Three Simulated Greenland Ice Sheet Response Scenarios: <a href="https://svs.gsfc.nasa.gov/4727/" rel="noopener noreferrer" target="_blank">https://svs.gsfc.nasa.gov/4727/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/105-power-of-bayesian-statistics-in-glaciology-andy-aschwanden-doug-brinkerhoff]]></link><guid isPermaLink="false">ee49b4cf-16b3-4db9-bbb4-c5f766581729</guid><itunes:image href="https://artwork.captivate.fm/05dd4f87-e025-41fa-96ee-298f06b544b2/kAJ9usODUwT_rdAa8BQU5Hjf.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 02 May 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/0ee6c995-5a06-483e-9368-478474ac92bd/105.mp3" length="36203224" type="audio/mpeg"/><itunes:duration>01:15:25</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>105</itunes:episode><itunes:season>1</itunes:season><podcast:episode>105</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/156f5816-bf88-4781-a374-4610077acc89/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/156f5816-bf88-4781-a374-4610077acc89/index.html" type="text/html"/></item><item><title>#104 Automated Gaussian Processes &amp; Sequential Monte Carlo, with Feras Saad</title><itunes:title>Automated Gaussian Processes &amp; Sequential Monte Carlo, with Feras Saad</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">GPs are extremely powerful…. but hard to handle. One of the bottlenecks is learning the appropriate kernel. What if you could learn the structure of GP kernels automatically? Sounds really cool, but also a bit futuristic, doesn’t it?</p><p class="ql-align-justify">Well, think again, because in this episode, Feras Saad will teach us how to do just that! Feras is an Assistant Professor in the Computer Science Department at Carnegie Mellon University. He received his PhD in Computer Science from MIT, and, most importantly for our conversation, he’s the creator of AutoGP.jl, a Julia package for automatic Gaussian process modeling.</p><p class="ql-align-justify">Feras discusses the implementation of AutoGP, how it scales, what you can do with it, and how you can integrate its outputs in your models.</p><p class="ql-align-justify">Finally, Feras provides an overview of Sequential Monte Carlo and its usefulness in AutoGP, highlighting the ability of SMC to incorporate new data in a streaming fashion and explore multiple modes efficiently.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell and Gal Kampel</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- AutoGP is a Julia package for automatic Gaussian process modeling that learns the]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">GPs are extremely powerful…. but hard to handle. One of the bottlenecks is learning the appropriate kernel. What if you could learn the structure of GP kernels automatically? Sounds really cool, but also a bit futuristic, doesn’t it?</p><p class="ql-align-justify">Well, think again, because in this episode, Feras Saad will teach us how to do just that! Feras is an Assistant Professor in the Computer Science Department at Carnegie Mellon University. He received his PhD in Computer Science from MIT, and, most importantly for our conversation, he’s the creator of AutoGP.jl, a Julia package for automatic Gaussian process modeling.</p><p class="ql-align-justify">Feras discusses the implementation of AutoGP, how it scales, what you can do with it, and how you can integrate its outputs in your models.</p><p class="ql-align-justify">Finally, Feras provides an overview of Sequential Monte Carlo and its usefulness in AutoGP, highlighting the ability of SMC to incorporate new data in a streaming fashion and explore multiple modes efficiently.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser, Julio, Edvin Saveljev,</em> <em>Frederick Ayala, Jeffrey Powell and Gal Kampel</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- AutoGP is a Julia package for automatic Gaussian process modeling that learns the structure of GP kernels automatically.</p><p class="ql-align-justify">- It addresses the challenge of making structural choices for covariance functions by using a symbolic language and a recursive grammar to infer the expression of the covariance function given the observed data.</p><p class="ql-align-justify">-AutoGP incorporates sequential Monte Carlo inference to handle scalability and uncertainty in structure learning.</p><p class="ql-align-justify">- The package is implemented in Julia using the Gen probabilistic programming language, which provides support for sequential Monte Carlo and involutive MCMC.</p><p class="ql-align-justify">- Sequential Monte Carlo (SMC) and inductive MCMC are used in AutoGP to infer the structure of the model.</p><p class="ql-align-justify">- Integrating probabilistic models with language models can improve interpretability and trustworthiness in data-driven inferences.</p><p class="ql-align-justify">- Challenges in Bayesian workflows include the need for automated model discovery and scalability of inference algorithms.</p><p class="ql-align-justify">- Future developments in probabilistic reasoning systems include unifying people around data-driven inferences and improving the scalability and configurability of inference algorithms.</p><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to AutoGP</p><p class="ql-align-justify">26:28 Automatic Gaussian Process Modeling</p><p class="ql-align-justify">45:05 AutoGP: Automatic Discovery of Gaussian Process Model Structure</p><p class="ql-align-justify">53:39 Applying AutoGP to New Settings</p><p class="ql-align-justify">01:09:27 The Biggest Hurdle in the Bayesian Workflow</p><p class="ql-align-justify">01:19:14 Unifying People Around Data-Driven Inferences</p><p><strong>Links from the show:</strong></p><ul><li>Sign up to the Fast &amp; Efficient Gaussian Processes modeling webinar: <a href="https://topmate.io/alex_andorra/901986" rel="noopener noreferrer" target="_blank">https://topmate.io/alex_andorra/901986</a></li><li class="ql-align-justify">Feras’ website: <a href="https://www.cs.cmu.edu/~fsaad/" rel="noopener noreferrer" target="_blank">https://www.cs.cmu.edu/~fsaad/</a></li><li>LBS #3.1, What is Probabilistic Programming &amp; Why use it, with Colin Carroll: <a href="https://learnbayesstats.com/episode/3-1-what-is-probabilistic-programming-why-use-it-with-colin-carroll/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/3-1-what-is-probabilistic-programming-why-use-it-with-colin-carroll/</a></li><li>LBS #3.2, How to use Bayes in industry, with Colin Carroll: <a href="https://learnbayesstats.com/episode/3-2-how-to-use-bayes-in-industry-with-colin-carroll/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/3-2-how-to-use-bayes-in-industry-with-colin-carroll/</a></li><li>LBS #21, Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova: <a href="https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/</a></li><li>LBS #29, Model Assessment, Non-Parametric Models, And Much More, with Aki Vehtari: <a href="https://learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari/</a></li><li>LBS #63, Media Mix Models &amp; Bayes for Marketing, with Luciano Paz: <a href="https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/</a></li><li>LBS #83, Multilevel Regression, Post-Stratification &amp; Electoral Dynamics, with Tarmo Jüristo: <a href="https://learnbayesstats.com/episode/83-multilevel-regression-post-stratification-electoral-dynamics-tarmo-juristo/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/83-multilevel-regression-post-stratification-electoral-dynamics-tarmo-juristo/</a></li><li>AutoGP.jl, A Julia package for learning the covariance structure of Gaussian process time series models: <a href="https://probsys.github.io/AutoGP.jl/stable/" rel="noopener noreferrer" target="_blank">https://probsys.github.io/AutoGP.jl/stable/</a></li><li>Sequential Monte Carlo Learning for Time Series Structure Discovery: <a href="https://arxiv.org/abs/2307.09607" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2307.09607</a></li><li>Street Epistemlogy: <a href="https://www.youtube.com/@magnabosco210" rel="noopener noreferrer" target="_blank">https://www.youtube.com/@magnabosco210</a></li><li>You're not so smart Podcast: <a href="https://youarenotsosmart.com/podcast/" rel="noopener noreferrer" target="_blank">https://youarenotsosmart.com/podcast/</a></li><li>How Minds Change: <a href="https://www.davidmcraney.com/howmindschangehome" rel="noopener noreferrer" target="_blank">https://www.davidmcraney.com/howmindschangehome</a></li><li>Josh Tenebaum's lectures on computational cognitive science: <a href="https://www.youtube.com/playlist?list=PLUl4u3cNGP61RTZrT3MIAikp2G5EEvTjf" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PLUl4u3cNGP61RTZrT3MIAikp2G5EEvTjf</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/104-automated-gaussian-processes-sequential-monte-carlo-feras-saad]]></link><guid isPermaLink="false">0b644ca2-fbb4-41ad-aa17-17343b8d7285</guid><itunes:image href="https://artwork.captivate.fm/a7e3928f-d512-4701-ae8f-b24da1b2af68/lAa9V-ao3yHnhWllzJ8SuOvQ.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 16 Apr 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f01fbbd8-7d2b-4e0a-a790-cf19b3c1f998/riverside-alexandre-andorra-compressed-audio-lbs-studio-0160.mp3" length="43581458" type="audio/mpeg"/><itunes:duration>01:30:48</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>104</itunes:episode><itunes:season>1</itunes:season><podcast:episode>104</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/a116c207-c220-4c9a-9ee8-f77e6588cf95/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/a116c207-c220-4c9a-9ee8-f77e6588cf95/index.html" type="text/html"/></item><item><title>#103 Improving Sampling Algorithms &amp; Prior Elicitation, with Arto Klami</title><itunes:title>Improving Sampling Algorithms &amp; Prior Elicitation, with Arto Klami</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Changing perspective is often a great way to solve burning research problems. Riemannian spaces are such a perspective change, as Arto Klami, an Associate Professor of computer science at the University of Helsinki and member of the Finnish Center for Artificial Intelligence, will tell us in this episode.</p><p class="ql-align-justify">He explains the concept of Riemannian spaces, their application in inference algorithms, how they can help sampling Bayesian models, and their similarity with normalizing flows, that we discussed in episode 98.</p><p class="ql-align-justify">Arto also introduces PreliZ, a tool for prior elicitation, and highlights its benefits in simplifying the process of setting priors, thus improving the accuracy of our models.</p><p class="ql-align-justify">When Arto is not solving mathematical equations, you’ll find him cycling, or around a good board game.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- Riemannian spaces offer a way to improve computational efficiency and accuracy in Bayesian inference by considering the curvature of the posterior distribution.</p><p class="ql-align-justify">- Riemannian spaces can be used in Laplace approximation and Markov chain Monte Carlo...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Changing perspective is often a great way to solve burning research problems. Riemannian spaces are such a perspective change, as Arto Klami, an Associate Professor of computer science at the University of Helsinki and member of the Finnish Center for Artificial Intelligence, will tell us in this episode.</p><p class="ql-align-justify">He explains the concept of Riemannian spaces, their application in inference algorithms, how they can help sampling Bayesian models, and their similarity with normalizing flows, that we discussed in episode 98.</p><p class="ql-align-justify">Arto also introduces PreliZ, a tool for prior elicitation, and highlights its benefits in simplifying the process of setting priors, thus improving the accuracy of our models.</p><p class="ql-align-justify">When Arto is not solving mathematical equations, you’ll find him cycling, or around a good board game.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify">- Riemannian spaces offer a way to improve computational efficiency and accuracy in Bayesian inference by considering the curvature of the posterior distribution.</p><p class="ql-align-justify">- Riemannian spaces can be used in Laplace approximation and Markov chain Monte Carlo algorithms to better model the posterior distribution and explore challenging areas of the parameter space.</p><p class="ql-align-justify">- Normalizing flows are a complementary approach to Riemannian spaces, using non-linear transformations to warp the parameter space and improve sampling efficiency.</p><p class="ql-align-justify">- Evaluating the performance of Bayesian inference algorithms in challenging cases is a current research challenge, and more work is needed to establish benchmarks and compare different methods.&nbsp;</p><p class="ql-align-justify">- PreliZ is a package for prior elicitation in Bayesian modeling that facilitates communication with users through visualizations of predictive and parameter distributions.</p><p class="ql-align-justify">- Careful prior specification is important, and tools like PreliZ make the process easier and more reproducible.</p><p class="ql-align-justify">- Teaching Bayesian machine learning is challenging due to the combination of statistical and programming concepts, but it is possible to teach the basic reasoning behind Bayesian methods to a diverse group of students.</p><p class="ql-align-justify">- The integration of Bayesian approaches in data science workflows is becoming more accepted, especially in industries that already use deep learning techniques.</p><p class="ql-align-justify">- The future of Bayesian methods in AI research may involve the development of AI assistants for Bayesian modeling and probabilistic reasoning.</p><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction and Background</p><p class="ql-align-justify">02:05 Arto's Work and Background</p><p class="ql-align-justify">06:05 Introduction to Bayesian Inference</p><p class="ql-align-justify">12:46 Riemannian Spaces in Bayesian Inference</p><p class="ql-align-justify">27:24 Availability of Romanian-based Algorithms</p><p class="ql-align-justify">30:20 Practical Applications and Evaluation</p><p class="ql-align-justify">37:33 Introduction to Prelease</p><p class="ql-align-justify">38:03 Prior Elicitation</p><p class="ql-align-justify">39:01 Predictive Elicitation Techniques</p><p class="ql-align-justify">39:30 PreliZ: Interface with Users</p><p>40:27 PreliZ: General Purpose Tool</p><p>41:55 Getting Started with PreliZ</p><p class="ql-align-justify">42:45 Challenges of Setting Priors</p><p class="ql-align-justify">45:10 Reproducibility and Transparency in Priors</p><p class="ql-align-justify">46:07 Integration of Bayesian Approaches in Data Science Workflows</p><p class="ql-align-justify">55:11 Teaching Bayesian Machine Learning</p><p class="ql-align-justify">01:06:13 The Future of Bayesian Methods with AI Research</p><p class="ql-align-justify">01:10:16 Solving the Prior Elicitation Problem</p><p><strong>Links from the show:</strong></p><ul><li>LBS #29, Model Assessment, Non-Parametric Models, And Much More, with Aki Vehtari: <a href="https://learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari/</a></li><li>LBS #20 Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/</a></li><li>LBS #98 Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></li><li>Arto’s website: <a href="https://www.cs.helsinki.fi/u/aklami/" rel="noopener noreferrer" target="_blank">https://www.cs.helsinki.fi/u/aklami/</a></li><li>Arto on Google Scholar: <a href="https://scholar.google.com/citations?hl=en&amp;user=v8PeLGgAAAAJ" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?hl=en&amp;user=v8PeLGgAAAAJ</a></li><li>Multi-source probabilistic inference Group: <a href="https://www.helsinki.fi/en/researchgroups/multi-source-probabilistic-inference" rel="noopener noreferrer" target="_blank">https://www.helsinki.fi/en/researchgroups/multi-source-probabilistic-inference</a></li><li>FCAI web page: <a href="https://fcai.fi" rel="noopener noreferrer" target="_blank">https://fcai.fi</a></li><li>Probabilistic AI summer school lectures: <a href="https://www.youtube.com/channel/UCcMwNzhpePJE3xzOP_3pqsw" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCcMwNzhpePJE3xzOP_3pqsw</a></li><li>Keynote: "Better priors for everyone" by Arto Klami: <a href="https://www.youtube.com/watch?v=mEmiEHsfWyc&amp;ab_channel=ProbabilisticAISchool" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=mEmiEHsfWyc&amp;ab_channel=ProbabilisticAISchool</a></li><li>Variational Inference and Optimization I by Arto Klami: <a href="https://www.youtube.com/watch?v=60USDNc1nE8&amp;list=PLRy-VW__9hV8s--JkHXZvnd26KgjRP2ik&amp;index=3&amp;ab_channel=ProbabilisticAISchool" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=60USDNc1nE8&amp;list=PLRy-VW__9hV8s--JkHXZvnd26KgjRP2ik&amp;index=3&amp;ab_channel=ProbabilisticAISchool</a></li><li>PreliZ, A tool-box for prior elicitation: <a href="https://preliz.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://preliz.readthedocs.io/en/latest/</a></li><li>AISTATS paper that presents the new computationally efficient metric in context of MCMC: <a href="https://researchportal.helsinki.fi/en/publications/lagrangian-manifold-monte-carlo-on-monge-patches" rel="noopener noreferrer" target="_blank">https://researchportal.helsinki.fi/en/publications/lagrangian-manifold-monte-carlo-on-monge-patches</a></li><li>TMLR paper that scales up the solution for larger models, using the metric for sampling-based inference in deel learning: <a href="https://openreview.net/pdf?id=dXAuvo6CGI" rel="noopener noreferrer" target="_blank">https://openreview.net/pdf?id=dXAuvo6CGI</a></li><li>Riemannian Laplace approximation (to appear in AISTATS’24): <a href="https://arxiv.org/abs/2311.02766" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2311.02766</a></li><li>Prior Knowledge Elicitation -- The Past, Present, and Future: <a href="https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Prior-Knowledge-Elicitation-The-Past-Present-and-Future/10.1214/23-BA1381.full" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Prior-Knowledge-Elicitation-The-Past-Present-and-Future/10.1214/23-BA1381.full</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/103-improving-sampling-algorithms-prior-elicitation-arto-klami]]></link><guid isPermaLink="false">680c9f0e-42bc-4d30-8e09-36de483b22fa</guid><itunes:image href="https://artwork.captivate.fm/701f019b-5cb3-4920-bec3-24ec57c20d3f/nufL4PLpYy3LcGvsibxCfKf0.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 05 Apr 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a4a2a63f-d54c-4af0-be29-87e1cf7d37f8/103-aklami-full.mp3" length="35829360" type="audio/mpeg"/><itunes:duration>01:14:39</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>103</itunes:episode><itunes:season>1</itunes:season><podcast:episode>103</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/127bfa16-7dc1-49f2-a90a-a71edf19dea6/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/127bfa16-7dc1-49f2-a90a-a71edf19dea6/index.html" type="text/html"/></item><item><title>#102 Bayesian Structural Equation Modeling &amp; Causal Inference in Psychometrics, with Ed Merkle</title><itunes:title>Bayesian Structural Equation Modeling &amp; Causal Inference in Psychometrics, with Ed Merkle</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Structural Equation Modeling (SEM) is a key framework in causal inference. As I’m diving deeper and deeper into these topics to teach them and, well, finally understand them, I was delighted to host Ed Merkle on the show.</p><p class="ql-align-justify">A professor of psychological sciences at the University of Missouri, Ed discusses his work on Bayesian applications to psychometric models and model estimation, particularly in the context of Bayesian SEM. He explains the importance of BSEM in psychometrics and the challenges encountered in its estimation.</p><p class="ql-align-justify">Ed also introduces his blavaan package in R, which enhances researchers' capabilities in BSEM and has been instrumental in the dissemination of these methods. Additionally, he explores the role of Bayesian methods in forecasting and crowdsourcing wisdom.</p><p class="ql-align-justify">When he’s not thinking about stats and psychology, Ed can be found running, playing the piano, or playing 8-bit video games.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify"> - Bayesian SEM is a powerful framework in psychometrics that allows for the estimation of complex models involving multiple variables and causal relationships.</p><p class="ql-align-justify">-...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Structural Equation Modeling (SEM) is a key framework in causal inference. As I’m diving deeper and deeper into these topics to teach them and, well, finally understand them, I was delighted to host Ed Merkle on the show.</p><p class="ql-align-justify">A professor of psychological sciences at the University of Missouri, Ed discusses his work on Bayesian applications to psychometric models and model estimation, particularly in the context of Bayesian SEM. He explains the importance of BSEM in psychometrics and the challenges encountered in its estimation.</p><p class="ql-align-justify">Ed also introduces his blavaan package in R, which enhances researchers' capabilities in BSEM and has been instrumental in the dissemination of these methods. Additionally, he explores the role of Bayesian methods in forecasting and crowdsourcing wisdom.</p><p class="ql-align-justify">When he’s not thinking about stats and psychology, Ed can be found running, playing the piano, or playing 8-bit video games.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><p class="ql-align-justify"> - Bayesian SEM is a powerful framework in psychometrics that allows for the estimation of complex models involving multiple variables and causal relationships.</p><p class="ql-align-justify">- Understanding the principles of Bayesian inference is crucial for effectively applying Bayesian SEM in psychological research.</p><p class="ql-align-justify">- Informative priors play a key role in Bayesian modeling, providing valuable information and improving the accuracy of model estimates.</p><p class="ql-align-justify">- Challenges in BSEM estimation include specifying appropriate prior distributions, dealing with unidentified parameters, and ensuring convergence of the model. Incorporating prior information is crucial in Bayesian modeling, especially when dealing with large models and imperfect data.</p><p class="ql-align-justify">- The blavaan package enhances researchers' capabilities in Bayesian structural equation modeling, providing a user-friendly interface and compatibility with existing frequentist models.</p><p class="ql-align-justify">- Bayesian methods offer advantages in forecasting and subjective probability by allowing for the characterization of uncertainty and providing a range of predictions.</p><p class="ql-align-justify">- Interpreting Bayesian model results requires careful consideration of the entire posterior distribution, rather than focusing solely on point estimates.</p><p class="ql-align-justify">- Latent variable models, also known as structural equation models, play a crucial role in psychometrics, allowing for the estimation of unobserved variables and their influence on observed variables.</p><p class="ql-align-justify">- The speed of MCMC estimation and the need for a slower, more thoughtful workflow are common challenges in the Bayesian workflow.</p><p class="ql-align-justify">- The future of Bayesian psychometrics may involve advancements in parallel computing and GPU-accelerated MCMC algorithms.</p><p class="ql-align-justify"><strong>Chapters</strong>:</p><p class="ql-align-justify">00:00 Introduction to the Conversation</p><p class="ql-align-justify">02:17 Background and Work on Bayesian SEM</p><p class="ql-align-justify">04:12 Topics of Focus: Structural Equation Models</p><p class="ql-align-justify">05:16 Introduction to Bayesian Inference</p><p class="ql-align-justify">09:30 Importance of Bayesian SEM in Psychometrics</p><p class="ql-align-justify">10:28 Overview of Bayesian Structural Equation Modeling (BSEM)</p><p class="ql-align-justify">12:22 Relationship between BSEM and Causal Inference</p><p class="ql-align-justify">15:41 Advice for Learning BSEM</p><p class="ql-align-justify">21:57 Challenges in BSEM Estimation</p><p class="ql-align-justify">34:40 The Impact of Model Size and Data Quality</p><p class="ql-align-justify">37:07 The Development of the Blavaan Package</p><p class="ql-align-justify">42:16 Bayesian Methods in Forecasting and Subjective Probability</p><p class="ql-align-justify">46:27 Interpreting Bayesian Model Results</p><p class="ql-align-justify">51:13 Latent Variable Models in Psychometrics</p><p class="ql-align-justify">56:23 Challenges in the Bayesian Workflow</p><p class="ql-align-justify">01:01:13 The Future of Bayesian Psychometrics</p><p><strong>Links from the show:</strong></p><ul><li>Ed’s website: <a href="https://ecmerkle.github.io/" rel="noopener noreferrer" target="_blank">https://ecmerkle.github.io/</a></li><li>Ed on Mastodon: <a href="https://mastodon.sdf.org/@edgarmerkle" rel="noopener noreferrer" target="_blank">https://mastodon.sdf.org/@edgarmerkle</a></li><li>Ed on BlueSky: @edgarmerkle.bsky.social</li><li>Ed on GitHub: <a href="https://github.com/ecmerkle" rel="noopener noreferrer" target="_blank">https://github.com/ecmerkle</a></li><li>blaavan R package: <a href="https://ecmerkle.github.io/blavaan/" rel="noopener noreferrer" target="_blank">https://ecmerkle.github.io/blavaan/</a></li><li>Resources on how to use blaavan: <a href="https://ecmerkle.github.io/blavaan/articles/resources.html" rel="noopener noreferrer" target="_blank">https://ecmerkle.github.io/blavaan/articles/resources.html</a></li><li>Richard McElreath, Table 2 Fallacy: <a href="https://youtu.be/uanZZLlzKHw?si=vssrwJsvGO5HhH5H&amp;t=4323" rel="noopener noreferrer" target="_blank">https://youtu.be/uanZZLlzKHw?si=vssrwJsvGO5HhH5H&amp;t=4323</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/102-bayesian-structural-equation-modeling-causal-inference-psychometrics-ed-merkle]]></link><guid isPermaLink="false">66e532f5-0a0e-47c9-bb3d-b6d08e8dc69e</guid><itunes:image href="https://artwork.captivate.fm/0c51b5fe-216f-4352-8168-9ee46f64ee63/luST4D1p0qQucxhNg-ZpvcPb.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 20 Mar 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/161fd303-edff-4670-a521-1cb57ddb4691/102-emerkle-full.mp3" length="33067903" type="audio/mpeg"/><itunes:duration>01:08:53</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>102</itunes:episode><itunes:season>1</itunes:season><podcast:episode>102</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/b28010a4-be96-425a-a3e3-bb0215ceddc3/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/b28010a4-be96-425a-a3e3-bb0215ceddc3/index.html" type="text/html"/></item><item><title>How to find black holes with Bayesian inference</title><itunes:title>How to find black holes with Bayesian inference</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode:<a href="https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/ </a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZaZwCcrJlik" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZaZwCcrJlik</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode:<a href="https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/ </a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZaZwCcrJlik" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZaZwCcrJlik</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/how-to-find-black-holes-with-bayesian-inference]]></link><guid isPermaLink="false">97c6c1b4-3f66-486e-9c17-e6f9b20a61f7</guid><itunes:image href="https://artwork.captivate.fm/c734ca6f-fec4-48a3-babb-299eb3796e8c/0MUaWToyVRf2FDrNm7yyPYud.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Sat, 16 Mar 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/e12f9f04-eb25-4805-9d50-806995c8f689/Extract-02-converted.mp3" length="11703481" type="audio/mpeg"/><itunes:duration>12:13</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>How can we even hear gravitational waves?</title><itunes:title>How can we even hear gravitational waves?</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode:<a href="https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/ </a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZaZwCcrJlik" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZaZwCcrJlik</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode:<a href="https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch/ </a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZaZwCcrJlik" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZaZwCcrJlik</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/how-can-we-even-hear-gravitational-waves]]></link><guid isPermaLink="false">ebf511f3-fe25-49d5-a0ea-c029e1a147df</guid><itunes:image href="https://artwork.captivate.fm/0fba22bd-f46a-49d1-84de-b7278ab254ac/zVhrrRv7X2YxW5HXcoM61slY.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 14 Mar 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/2167c869-0e01-4554-9728-43fad17fd7e5/Extract-01-converted.mp3" length="8616430" type="audio/mpeg"/><itunes:duration>08:59</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>#101 Black Holes Collisions &amp; Gravitational Waves, with LIGO Experts Christopher Berry &amp; John Veitch</title><itunes:title>Black Holes Collisions &amp; Gravitational Waves, with LIGO Experts Christopher Berry &amp; John Veitch</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, we dive deep into gravitational wave astronomy, with Christopher Berry and John Veitch, two senior lecturers at the University of Glasgow and experts from the LIGO-VIRGO collaboration. They explain the significance of detecting gravitational waves, which are essential for understanding black holes and neutron stars collisions. This research not only sheds light on these distant events but also helps us grasp the fundamental workings of the universe.</p><p class="ql-align-justify">Our discussion focuses on the integral role of Bayesian statistics, detailing how they use nested sampling for extracting crucial information from the subtle signals of gravitational waves. This approach is vital for parameter estimation and understanding the distribution of cosmic sources through population inferences.</p><p class="ql-align-justify">Concluding the episode, Christopher and John highlight the latest advancements in black hole astrophysics and tests of general relativity, and touch upon the exciting prospects and challenges of the upcoming space-based LISA mission.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Takeaways: </strong></p><p class="ql-align-justify">&nbsp;⁃&nbsp; &nbsp; Gravitational wave analysis involves using Bayesian statistics for parameter estimation and population...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, we dive deep into gravitational wave astronomy, with Christopher Berry and John Veitch, two senior lecturers at the University of Glasgow and experts from the LIGO-VIRGO collaboration. They explain the significance of detecting gravitational waves, which are essential for understanding black holes and neutron stars collisions. This research not only sheds light on these distant events but also helps us grasp the fundamental workings of the universe.</p><p class="ql-align-justify">Our discussion focuses on the integral role of Bayesian statistics, detailing how they use nested sampling for extracting crucial information from the subtle signals of gravitational waves. This approach is vital for parameter estimation and understanding the distribution of cosmic sources through population inferences.</p><p class="ql-align-justify">Concluding the episode, Christopher and John highlight the latest advancements in black hole astrophysics and tests of general relativity, and touch upon the exciting prospects and challenges of the upcoming space-based LISA mission.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Takeaways: </strong></p><p class="ql-align-justify">&nbsp;⁃&nbsp; &nbsp; Gravitational wave analysis involves using Bayesian statistics for parameter estimation and population inference.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; Nested sampling is a powerful algorithm used in gravitational wave analysis to explore parameter space and calculate the evidence for model selection.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; Machine learning techniques, such as normalizing flows, can be integrated with nested sampling to improve efficiency and explore complex distributions.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; The LIGO-VIRGO collaboration operates gravitational wave detectors that measure distortions in space and time caused by black hole and neutron star collisions.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; Sources of noise in gravitational wave detection include laser noise, thermal noise, seismic motion, and gravitational coupling.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; The LISA mission is a space-based gravitational wave detector that aims to observe lower frequency gravitational waves and unlock new astrophysical phenomena.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; Space-based detectors like LISA can avoid the ground-based noise and observe a different part of the gravitational wave spectrum, providing new insights into the universe.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; The data analysis challenges for space-based detectors are complex, as they require fitting multiple sources simultaneously and dealing with overlapping signals.</p><p class="ql-align-justify">&nbsp;&nbsp;&nbsp;&nbsp;⁃&nbsp; &nbsp; Gravitational wave observations have the potential to test general relativity, study the astrophysics of black holes and neutron stars, and provide insights into cosmology.</p><p><strong>Links from the show:</strong></p><ul><li>Christopher’s’ website: <a href="https://cplberry.com/" rel="noopener noreferrer" target="_blank">https://cplberry.com/</a></li><li>John’s website: <a href="https://www.veitch.me.uk/" rel="noopener noreferrer" target="_blank">https://www.veitch.me.uk/</a></li><li>Christopher on GitHub: <a href="https://github.com/cplb/" rel="noopener noreferrer" target="_blank">https://github.com/cplb/</a>&nbsp;</li><li>John on GitHub: <a href="https://github.com/johnveitch" rel="noopener noreferrer" target="_blank">https://github.com/johnveitch</a></li><li>Christopher on Linkedin: <a href="http://www.linkedin.com/in/cplberry" rel="noopener noreferrer" target="_blank">http://www.linkedin.com/in/cplberry</a>&nbsp;</li><li>John on Linkedin: <a href="https://www.linkedin.com/in/john-veitch-56772225/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/john-veitch-56772225/</a></li><li>Christopher on Twitter: <a href="https://twitter.com/cplberry" rel="noopener noreferrer" target="_blank">https://twitter.com/cplberry</a></li><li>John on Twitter: <a href="https://twitter.com/johnveitch" rel="noopener noreferrer" target="_blank">https://twitter.com/johnveitch</a></li><li>Christopher on Mastodon: <a href="https://mastodon.scot/@cplberry@mastodon.online" rel="noopener noreferrer" target="_blank">https://mastodon.scot/@cplberry@mastodon.online</a>&nbsp;</li><li>John on Mastodon: <a href="https://mastodon.scot/@JohnVeitch" rel="noopener noreferrer" target="_blank">https://mastodon.scot/@JohnVeitch</a></li><li>LIGO website: <a href="https://www.ligo.org/" rel="noopener noreferrer" target="_blank">https://www.ligo.org/</a></li><li>LIGO Gitlab: <a href="https://git.ligo.org/users/sign_in" rel="noopener noreferrer" target="_blank">https://git.ligo.org/users/sign_in</a></li><li>Gravitational Wave Open Science Center: <a href="https://gwosc.org/" rel="noopener noreferrer" target="_blank">https://gwosc.org/</a></li><li>LIGO Caltech Lab: <a href="https://www.ligo.caltech.edu/page/ligo-data" rel="noopener noreferrer" target="_blank">https://www.ligo.caltech.edu/page/ligo-data</a></li><li>Exoplanet, python package for probabilistic modeling of time series data in astronomy: <a href="https://docs.exoplanet.codes/en/latest/" rel="noopener noreferrer" target="_blank">https://docs.exoplanet.codes/en/latest/</a></li><li>Dynamic Nested Sampling with dynesty: <a href="https://dynesty.readthedocs.io/en/latest/dynamic.html" rel="noopener noreferrer" target="_blank">https://dynesty.readthedocs.io/en/latest/dynamic.html</a></li><li>Nessai, Nested sampling with artificial intelligence: <a href="https://nessai.readthedocs.io/" rel="noopener noreferrer" target="_blank">https://nessai.readthedocs.io/</a></li><li>LBS #98 Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></li><li>bayeux, JAX models with state-of-the-art inference methods: <a href="https://jax-ml.github.io/bayeux/" rel="noopener noreferrer" target="_blank">https://jax-ml.github.io/bayeux/</a></li><li>LBS #51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li>Aubrey Clayton's Probability Theory Lectures based on E.T Jaynes book: <a href="https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/101-black-holes-collisions-gravitational-waves-ligo-experts-christopher-berry-john-veitch]]></link><guid isPermaLink="false">34a6786d-9e4d-47bd-ba55-893056dc8619</guid><itunes:image href="https://artwork.captivate.fm/10e32fcf-67c4-4f5a-8984-1d90d8782582/-5L7KoRNdPr-SVAt_xk5KMum.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Thu, 07 Mar 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/e7817d5f-f712-49d2-959f-97d2e8d3ad1b/Learning-Bayesian-Statistics-101-converted.mp3" length="66950257" type="audio/mpeg"/><itunes:duration>01:09:54</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>101</itunes:episode><itunes:season>1</itunes:season><podcast:episode>101</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/f9a686ad-fca8-4194-85cb-a50d828caf95/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/f9a686ad-fca8-4194-85cb-a50d828caf95/index.html" type="text/html"/></item><item><title>The Role of Variational Inference in Reactive Message Passing</title><itunes:title>The Role of Variational Inference in Reactive Message Passing</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZG3H0xxCXTQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZG3H0xxCXTQ</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZG3H0xxCXTQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZG3H0xxCXTQ</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/the-role-of-variational-inference-in-reactive-message-passing]]></link><guid isPermaLink="false">b1bd6362-d9d1-4ea1-bbcf-a340b8a5958c</guid><itunes:image href="https://artwork.captivate.fm/acc284fd-fb84-4d9f-bfcb-a720bcd58e92/-hh-RDXv_U7XP1iGDUuBoYmr.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 01 Mar 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/56bfc394-40a6-467c-a891-c70a8897a960/Extract-02-converted.mp3" length="10363356" type="audio/mpeg"/><itunes:duration>10:49</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>Reactive Message Passing in Bayesian Inference</title><itunes:title>Reactive Message Passing in Bayesian Inference</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZG3H0xxCXTQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZG3H0xxCXTQ</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=ZG3H0xxCXTQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZG3H0xxCXTQ</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/reactive-message-passing-in-bayesian-inference]]></link><guid isPermaLink="false">ce37f631-8257-4530-ac70-63aa5ce50ac7</guid><itunes:image href="https://artwork.captivate.fm/cab1229e-8065-47f0-baed-25279a98a132/DWkQ_InJe3k2y1SSTBWKAEpZ.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 28 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/e881fe29-7797-476c-9d91-430c2b6a9d64/Extract-01-converted.mp3" length="8443071" type="audio/mpeg"/><itunes:duration>08:49</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>#100 Reactive Message Passing &amp; Automated Inference in Julia, with Dmitry Bagaev</title><itunes:title>Reactive Message Passing &amp; Automated Inference in Julia, with Dmitry Bagaev</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Dmitry Bagaev discusses his work in Bayesian statistics and the development of RxInfer.jl, a reactive message passing toolbox for Bayesian inference.&nbsp;</p><p class="ql-align-justify">Dmitry explains the concept of reactive message passing and its applications in real-time signal processing and autonomous systems. He discusses the challenges and benefits of using RxInfer.jl, including its scalability and efficiency in large probabilistic models.&nbsp;</p><p class="ql-align-justify">Dmitry also shares insights into the trade-offs involved in Bayesian inference architecture and the role of variational inference in RxInfer.jl. Additionally, he discusses his startup Lazy Dynamics and its goal of commercializing research in Bayesian inference.&nbsp;</p><p class="ql-align-justify">Finally, we also discuss the user-friendliness and trade-offs of different inference methods, the future developments of RxInfer, and the future of automated Bayesian inference.&nbsp;</p><p class="ql-align-justify">Coming from a very small town in Russia called Nizhnekamsk, Dmitry currently lives in the Netherlands, where he did his PhD. Before that, he graduated from the Computational Science and Modeling department of Moscow State University.&nbsp;</p><p class="ql-align-justify">Beyond that, Dmitry is also a drummer (you’ll see his cool drums if you’re watching on YouTube), and an adept of extreme sports, like skydiving, wakeboarding and skiing!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Dmitry Bagaev discusses his work in Bayesian statistics and the development of RxInfer.jl, a reactive message passing toolbox for Bayesian inference.&nbsp;</p><p class="ql-align-justify">Dmitry explains the concept of reactive message passing and its applications in real-time signal processing and autonomous systems. He discusses the challenges and benefits of using RxInfer.jl, including its scalability and efficiency in large probabilistic models.&nbsp;</p><p class="ql-align-justify">Dmitry also shares insights into the trade-offs involved in Bayesian inference architecture and the role of variational inference in RxInfer.jl. Additionally, he discusses his startup Lazy Dynamics and its goal of commercializing research in Bayesian inference.&nbsp;</p><p class="ql-align-justify">Finally, we also discuss the user-friendliness and trade-offs of different inference methods, the future developments of RxInfer, and the future of automated Bayesian inference.&nbsp;</p><p class="ql-align-justify">Coming from a very small town in Russia called Nizhnekamsk, Dmitry currently lives in the Netherlands, where he did his PhD. Before that, he graduated from the Computational Science and Modeling department of Moscow State University.&nbsp;</p><p class="ql-align-justify">Beyond that, Dmitry is also a drummer (you’ll see his cool drums if you’re watching on YouTube), and an adept of extreme sports, like skydiving, wakeboarding and skiing!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie, Cory Kiser and Julio</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways:</strong></p><p class="ql-align-justify">- Reactive message passing is a powerful approach to Bayesian inference that allows for real-time updates and adaptivity in probabilistic models.</p><p class="ql-align-justify">- RxInfer.jl is a toolbox for reactive message passing in Bayesian inference, designed to be scalable, efficient, and adaptable.</p><p class="ql-align-justify">- Julia is a preferred language for RxInfer.jl due to its speed, macros, and multiple dispatch, which enable efficient and flexible implementation.</p><p class="ql-align-justify">- Variational inference plays a crucial role in RxInfer.jl, allowing for trade-offs between computational complexity and accuracy in Bayesian inference.</p><p class="ql-align-justify">- Lazy Dynamics is a startup focused on commercializing research in Bayesian inference, with the goal of making RxInfer.jl accessible and robust for industry applications.</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">LBS Physics &amp; Astrophysics playlist: <a href="https://learnbayesstats.com/physics-astrophysics/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/physics-astrophysics/</a></li><li class="ql-align-justify">LBS #51, Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li class="ql-align-justify">Dmitry on GitHub: <a href="https://github.com/bvdmitri" rel="noopener noreferrer" target="_blank">https://github.com/bvdmitri</a></li><li class="ql-align-justify">Dmitry on LinkedIn: <a href="https://www.linkedin.com/in/bvdmitri/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/bvdmitri/</a></li><li class="ql-align-justify">RxInfer.jl, Automatic Bayesian Inference through Reactive Message Passing: <a href="https://rxinfer.ml/" rel="noopener noreferrer" target="_blank">https://rxinfer.ml/</a></li><li class="ql-align-justify">Reactive Bayes, Open source software for reactive, efficient and scalable Bayesian inference: <a href="https://github.com/ReactiveBayes" rel="noopener noreferrer" target="_blank">https://github.com/ReactiveBayes</a></li><li class="ql-align-justify">LazyDynamics, Reactive Bayesian AI: <a href="https://lazydynamics.com/" rel="noopener noreferrer" target="_blank">https://lazydynamics.com/</a></li><li class="ql-align-justify">BIASlab, Natural Artificial Intelligence: <a href="https://biaslab.github.io/" rel="noopener noreferrer" target="_blank">https://biaslab.github.io/</a></li><li>Dmitry's PhD dissertation: <a href="https://research.tue.nl/en/publications/reactive-probabilistic-programming-for-scalable-bayesian-inferenc" rel="noopener noreferrer" target="_blank">https://research.tue.nl/en/publications/reactive-probabilistic-programming-for-scalable-bayesian-inferenc</a></li><li class="ql-align-justify"><em>Effortless Mastery</em>, by Kenny Werner: <a href="https://www.amazon.com/Effortless-Mastery-Liberating-Master-Musician/dp/156224003X" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Effortless-Mastery-Liberating-Master-Musician/dp/156224003X</a></li><li class="ql-align-justify">The Book of Why, by Judea Pearl: <a href="https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X</a></li><li class="ql-align-justify">Bernoulli’s Fallacy, by Aubrey Clayton: <a href="https://www.amazon.com/Bernoullis-Fallacy-Statistical-Illogic-Science/dp/0231199945" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Bernoullis-Fallacy-Statistical-Illogic-Science/dp/0231199945</a></li><li>Software Engineering for Science: <a href="https://www.amazon.com/Software-Engineering-Science-Chapman-Computational/dp/1498743854" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Software-Engineering-Science-Chapman-Computational/dp/1498743854</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/100-reactive-message-passing-automated-inference-in-julia-dmitry-bagaev]]></link><guid isPermaLink="false">44fa8ebd-2ed3-4323-87f4-ed9909f9b555</guid><itunes:image href="https://artwork.captivate.fm/ec08d66f-6e6e-4e6e-863e-8b15ffc0eaf6/iYc22nhFIhsCbaNwjxeC6j0E.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 21 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/e3751f36-14a7-467c-8a67-fd027e727a46/Learning-Bayesian-Statistics-100-converted.mp3" length="52385697" type="audio/mpeg"/><itunes:duration>54:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>100</itunes:episode><itunes:season>1</itunes:season><podcast:episode>100</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/0d9681ca-7900-4ea4-917b-07f097797db4/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/0d9681ca-7900-4ea4-917b-07f097797db4/index.html" type="text/html"/></item><item><title>The biggest misconceptions about Bayes &amp; Quantum Physics</title><itunes:title>The biggest misconceptions about Bayes &amp; Quantum Physics</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=pRaT6FLF7A8" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=pRaT6FLF7A8 </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=pRaT6FLF7A8" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=pRaT6FLF7A8 </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/the-biggest-misconceptions-about-bayes-quantum-physics]]></link><guid isPermaLink="false">5eda1d14-4aa8-4683-b6b1-0833dae33380</guid><itunes:image href="https://artwork.captivate.fm/c062a28d-6e52-4fcd-b53e-1638037c42f4/QcrEMuEQ4o6HqDqKGTjp9DXS.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 16 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/31b15d17-c696-4024-8b43-f3be825dd913/Extract-02-converted.mp3" length="9404256" type="audio/mpeg"/><itunes:duration>09:49</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>Why would you use Bayesian Statistics?</title><itunes:title>Why would you use Bayesian Statistics?</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=pRaT6FLF7A8" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=pRaT6FLF7A8 </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/99-exploring-quantum-physics-bayesian-stats-chris-ferrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=pRaT6FLF7A8" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=pRaT6FLF7A8 </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/why-would-you-use-bayesian-statistics]]></link><guid isPermaLink="false">d738744a-fc13-42c5-ba88-f09a029c30b1</guid><itunes:image href="https://artwork.captivate.fm/bbc31cbb-9cfb-4e3c-9a90-8f66a9e140e7/141N3Pz1iNBsWRDD9PYpf9GN.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 14 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b900c89f-620c-44d0-9fbf-7947c831056d/Extract-01-converted.mp3" length="10427991" type="audio/mpeg"/><itunes:duration>10:53</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>#99 Exploring Quantum Physics with Bayesian Stats, with Chris Ferrie</title><itunes:title>Exploring Quantum Physics with Bayesian Stats, with Chris Ferrie</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">You know I’m a big fan of everything physics. So when I heard that Bayesian stats was especially useful in quantum physics, I <em>had</em> to make an episode about it!</p><p class="ql-align-justify">You’ll hear from Chris Ferrie, an Associate Professor at the Centre for Quantum Software and Information of the University of Technology Sydney. Chris also has a foot in industry, as a co-founder of Eigensystems, an Australian start-up with a mission to democratize access to quantum computing.&nbsp;</p><p class="ql-align-justify">Of course, we talked about why Bayesian stats are helpful in quantum physics research, and about the burning challenges in this line of research.</p><p class="ql-align-justify">But Chris is also a renowned author — in addition to writing Bayesian Probability for Babies, he is the author of Quantum Physics for Babies and Quantum Bullsh*t: How to Ruin Your Life With Advice from Quantum Physics. So we ended up talking about science communication, science education, and a shocking revelation about Ant Man…</p><p class="ql-align-justify">A big thank you to one of my best Patrons, Stefan Lorenz, for recommending me an episode with Chris!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Quantum computing has the...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">You know I’m a big fan of everything physics. So when I heard that Bayesian stats was especially useful in quantum physics, I <em>had</em> to make an episode about it!</p><p class="ql-align-justify">You’ll hear from Chris Ferrie, an Associate Professor at the Centre for Quantum Software and Information of the University of Technology Sydney. Chris also has a foot in industry, as a co-founder of Eigensystems, an Australian start-up with a mission to democratize access to quantum computing.&nbsp;</p><p class="ql-align-justify">Of course, we talked about why Bayesian stats are helpful in quantum physics research, and about the burning challenges in this line of research.</p><p class="ql-align-justify">But Chris is also a renowned author — in addition to writing Bayesian Probability for Babies, he is the author of Quantum Physics for Babies and Quantum Bullsh*t: How to Ruin Your Life With Advice from Quantum Physics. So we ended up talking about science communication, science education, and a shocking revelation about Ant Man…</p><p class="ql-align-justify">A big thank you to one of my best Patrons, Stefan Lorenz, for recommending me an episode with Chris!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Takeaways</strong>:</p><ul><li class="ql-align-justify">Quantum computing has the potential to revolutionize various industries, but it requires specialized tools and education to fully harness its power.</li><li class="ql-align-justify">Bayesian inference plays a crucial role in understanding and solving problems in quantum physics, particularly in parameter estimation and model building.</li><li class="ql-align-justify">The field of quantum physics faces challenges in experimental design, data collection, and maintaining the state of isolated quantum systems.</li><li class="ql-align-justify">There is a need for specialized software that can accommodate the unique constraints and models in quantum physics, allowing for more efficient and accurate analysis.</li><li class="ql-align-justify">Common misconceptions in quantum physics include the idea of superposition as being in two places at once and the misinterpretation of quantum experiments. Misconceptions in quantum physics and Bayesian probability are common and can be addressed through clear explanations and analogies.</li><li class="ql-align-justify">Communicating scientific concepts to the general public requires bridging the gap between scientific papers and mainstream media.</li><li class="ql-align-justify">Simplifying complex topics for young minds involves providing relatable examples, analogies, and categories.</li><li class="ql-align-justify">Studying mathematics is essential for a deeper understanding of quantum physics and statistics.</li><li class="ql-align-justify">Taking risks and making mistakes is encouraged in the early stages of a scientific career.</li></ul><br/><p><strong>Links from the show:</strong></p><ul><li>Chris’ website: <a href="https://www.csferrie.com/" rel="noopener noreferrer" target="_blank">https://www.csferrie.com/</a></li><li>Chris on Linkedin: <a href="https://www.linkedin.com/in/christopher-ferrie-63993190/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/christopher-ferrie-63993190/</a></li><li>Chris on Twitter: <a href="https://twitter.com/csferrie" rel="noopener noreferrer" target="_blank">https://twitter.com/csferrie</a></li><li>Chris on Instagram: <a href="https://www.instagram.com/drchrisferrie/" rel="noopener noreferrer" target="_blank">https://www.instagram.com/drchrisferrie/</a></li><li>Chris’ YouTube channel: <a href="https://www.youtube.com/csferrie" rel="noopener noreferrer" target="_blank">https://www.youtube.com/csferrie</a></li><li>Chris’ children’s books: <a href="https://www.amazon.com/gp/product/149267043X" rel="noopener noreferrer" target="_blank">https://www.amazon.com/gp/product/149267043X</a></li><li>How quantum mechanics turned me into a Bayesian: <a href="https://csferrie.medium.com/how-quantum-mechanics-turned-me-into-a-bayesian-655ddf88051f" rel="noopener noreferrer" target="_blank">https://csferrie.medium.com/how-quantum-mechanics-turned-me-into-a-bayesian-655ddf88051f</a></li><li><em>Exoplanet</em>, a python package for probabilistic modeling of time series data in astronomy: <a href="https://docs.exoplanet.codes/en/latest/" rel="noopener noreferrer" target="_blank">https://docs.exoplanet.codes/en/latest/</a></li><li>Quantum Bullsh*t – How to Ruin Your Life with Advice from Quantum Physics : <a href="https://www.goodreads.com/en/book/show/61263731" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/en/book/show/61263731</a></li><li>LBS #93, A CERN Odyssey, with Kevin Greif: <a href="https://www.youtube.com/watch?v=rOaqIIEtdpI" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=rOaqIIEtdpI</a></li><li>LBS #72, Why the Universe is so Deliciously Crazy, with Daniel Whiteson: <a href="https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/</a></li><li>LBS #97, Probably Overthinking Statistical Paradoxes, with Allen Downey: <a href="https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/</a></li><li>LBS #51, Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li>LBS #50, Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/99-exploring-quantum-physics-bayesian-stats-chris-ferrie]]></link><guid isPermaLink="false">5d00e2be-5bae-48f0-ab74-0647608dd202</guid><itunes:image href="https://artwork.captivate.fm/f859a352-5f7e-41e5-b8b6-a54cce3aa5c4/nfzwcboNcyjmchc_tHoP7gPP.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Fri, 09 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/1bc696be-b28b-4bd9-b574-ebae046ed4da/Learning-Bayesian-Statistics-99-converted.mp3" length="64670934" type="audio/mpeg"/><itunes:duration>01:07:31</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>99</itunes:episode><itunes:season>1</itunes:season><podcast:episode>99</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/c7ab81f6-851b-40c6-a22e-3df428f9d726/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/c7ab81f6-851b-40c6-a22e-3df428f9d726/index.html" type="text/html"/></item><item><title>How do sampling algorithms scale?</title><itunes:title>How do sampling algorithms scale?</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=vVqZ0WWXX7g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=vVqZ0WWXX7g </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=vVqZ0WWXX7g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=vVqZ0WWXX7g </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/how-do-sampling-algorithms-scale]]></link><guid isPermaLink="false">89ede6c3-b950-441b-96f6-0f4314e1e9fd</guid><itunes:image href="https://artwork.captivate.fm/20c95112-5a5d-475a-bd9c-a5984045d0ae/H8VLkMS2pZeq-8SK9Kt48ows.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Mon, 05 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c00179f7-bc38-4331-905d-97c5338cd779/Extract-02-converted.mp3" length="9042300" type="audio/mpeg"/><itunes:duration>09:26</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>Why choose new algorithms instead of HMC?</title><itunes:title>Why choose new algorithms instead of HMC?</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=vVqZ0WWXX7g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=vVqZ0WWXX7g </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=vVqZ0WWXX7g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=vVqZ0WWXX7g </a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/why-choose-new-algorithms-instead-of-hmc]]></link><guid isPermaLink="false">a36fc270-4f34-4296-86f0-0c0bc73c075f</guid><itunes:image href="https://artwork.captivate.fm/c43078c3-f407-434f-b8c0-ce0b628967e6/QcMlVSvOCyiBuw1p8yqWQzdJ.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Sun, 04 Feb 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6c4a0a12-0c28-435e-b5bf-dd010625dd1c/Extract-01-converted.mp3" length="8340906" type="audio/mpeg"/><itunes:duration>08:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>#98 Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié</title><itunes:title>Fusing Statistical Physics, Machine Learning &amp; Adaptive MCMC, with Marylou Gabrié</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">How does the world of statistical physics intertwine with machine learning, and what groundbreaking insights can this fusion bring to the field of artificial intelligence?</p><p class="ql-align-justify">In this episode, we delve into these intriguing questions with Marylou Gabrié. an assistant professor at CMAP, Ecole Polytechnique in Paris. Having completed her PhD in physics at École Normale Supérieure, Marylou ventured to New York City for a joint postdoctoral appointment at New York University’s Center for Data Science and the Flatiron’s Center for Computational Mathematics.</p><p class="ql-align-justify">As you’ll hear, her research is not just about theoretical exploration; it also extends to the practical adaptation of machine learning techniques in scientific contexts, particularly where data is scarce.</p><p class="ql-align-justify">In this conversation, we’ll traverse the landscape of Marylou's research, discussing her recent publications and her innovative approaches to machine learning challenges, latest MCMC advances, and ML-assisted scientific computing.</p><p class="ql-align-justify">Beyond that, get ready to discover the person behind the science – her inspirations, aspirations, and maybe even what she does when not decoding the complexities of machine learning algorithms!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">How does the world of statistical physics intertwine with machine learning, and what groundbreaking insights can this fusion bring to the field of artificial intelligence?</p><p class="ql-align-justify">In this episode, we delve into these intriguing questions with Marylou Gabrié. an assistant professor at CMAP, Ecole Polytechnique in Paris. Having completed her PhD in physics at École Normale Supérieure, Marylou ventured to New York City for a joint postdoctoral appointment at New York University’s Center for Data Science and the Flatiron’s Center for Computational Mathematics.</p><p class="ql-align-justify">As you’ll hear, her research is not just about theoretical exploration; it also extends to the practical adaptation of machine learning techniques in scientific contexts, particularly where data is scarce.</p><p class="ql-align-justify">In this conversation, we’ll traverse the landscape of Marylou's research, discussing her recent publications and her innovative approaches to machine learning challenges, latest MCMC advances, and ML-assisted scientific computing.</p><p class="ql-align-justify">Beyond that, get ready to discover the person behind the science – her inspirations, aspirations, and maybe even what she does when not decoding the complexities of machine learning algorithms!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Takeaways</strong></p><ul><li>Developing methods that leverage machine learning for scientific computing can provide valuable insights into high-dimensional probabilistic models.</li><li>Generative models can be used to speed up Markov Chain Monte Carlo (MCMC) methods and improve the efficiency of sampling from complex distributions.</li><li>The Adaptive Monte Carlo algorithm augmented with normalizing flows offers a powerful approach for sampling from multimodal distributions.</li><li>Scaling the algorithm to higher dimensions and handling discrete parameters are ongoing challenges in the field.</li><li>Open-source packages, such as Flow MC, provide valuable tools for researchers and practitioners to adopt and contribute to the development of new algorithms. The scaling of algorithms depends on the quantity of parameters and data. While some methods work well with a few hundred parameters, larger quantities can lead to difficulties.</li><li>Generative models, such as normalizing flows, offer benefits in the Bayesian context, including amortization and the ability to adjust the model with new data.</li><li>Machine learning and MCMC are complementary and should be used together rather than replacing one another.</li><li>Machine learning can assist scientific computing in the context of scarce data, where expensive experiments or numerics are required.</li><li>The future of MCMC lies in the exploration of sampling multimodal distributions and understanding resource limitations in scientific research.</li></ul><br/><p><strong>Links from the show:</strong></p><ul><li>Marylou’s website: <a href="https://marylou-gabrie.github.io/" rel="noopener noreferrer" target="_blank">https://marylou-gabrie.github.io/</a></li><li>Marylou on Linkedin: <a href="https://www.linkedin.com/in/marylou-gabri%C3%A9-95366172/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/marylou-gabri%C3%A9-95366172/</a></li><li>Marylou on Twitter: <a href="https://twitter.com/marylougab" rel="noopener noreferrer" target="_blank">https://twitter.com/marylougab</a></li><li>Marylou on Github: <a href="https://github.com/marylou-gabrie" rel="noopener noreferrer" target="_blank">https://github.com/marylou-gabrie</a></li><li>Marylou on Google Scholar: <a href="https://scholar.google.fr/citations?hl=fr&amp;user=5m1DvLwAAAAJ" rel="noopener noreferrer" target="_blank">https://scholar.google.fr/citations?hl=fr&amp;user=5m1DvLwAAAAJ</a></li><li>Adaptive Monte Carlo augmented with normalizing flows: <a href="https://arxiv.org/abs/2105.12603" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2105.12603</a></li><li>Normalizing-flow enhanced sampling package for probabilistic inference: <a href="https://flowmc.readthedocs.io/en/main/" rel="noopener noreferrer" target="_blank">https://flowmc.readthedocs.io/en/main/</a></li><li>Flow-based generative models for Markov chain Monte Carlo in lattice field theory: <a href="https://journals.aps.org/prd/abstract/10.1103/PhysRevD.100.034515" rel="noopener noreferrer" target="_blank">https://journals.aps.org/prd/abstract/10.1103/PhysRevD.100.034515</a></li><li>Boltzmann generators – Sampling equilibrium states of many-body systems with deep learning: <a href="https://www.science.org/doi/10.1126/science.aaw1147" rel="noopener noreferrer" target="_blank">https://www.science.org/doi/10.1126/science.aaw1147</a></li><li>Solving Statistical Mechanics Using Variational Autoregressive Networks: <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.080602" rel="noopener noreferrer" target="_blank">https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.080602</a></li><li>An example of discrete version of similar algorithms:&nbsp; <a href="https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.3.L042024" rel="noopener noreferrer" target="_blank">https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.3.L042024</a></li><li class="ql-align-justify">Grothendieck's conference: <a href="https://www.youtube.com/watch?v=ZW9JpZXwGXc" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=ZW9JpZXwGXc</a></li></ul><br/><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/98-fusing-statistical-physics-machine-learning-adaptive-mcmc-marylou-gabrie]]></link><guid isPermaLink="false">8fdae55f-feac-4d12-b692-c2c030015f26</guid><itunes:image href="https://artwork.captivate.fm/6503c53e-2837-46f1-9ef9-95d25f086930/C18waCLMzLZg1HhTWHbTR7zz.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 24 Jan 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/35b7fa83-39f5-46d3-9219-1464045ddf8b/Learning-Bayesian-Statistics-98-converted.mp3" length="62362006" type="audio/mpeg"/><itunes:duration>01:05:07</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>98</itunes:episode><itunes:season>1</itunes:season><podcast:episode>98</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/c95e487b-9d1d-468c-8ce8-57e7b1d409a6/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/c95e487b-9d1d-468c-8ce8-57e7b1d409a6/index.html" type="text/html"/></item><item><title>Why Even Care About Science &amp; Rationality</title><itunes:title>Why Even Care About Science &amp; Rationality</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=KgesIe3hTe0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KgesIe3hTe0</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=KgesIe3hTe0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KgesIe3hTe0</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/why-even-care-about-science-rationality]]></link><guid isPermaLink="false">4315c544-d358-445f-831b-5eb5ddc3c044</guid><itunes:image href="https://artwork.captivate.fm/e00034d1-5f21-4297-a0a8-0b9c41fab6a2/NmVXAdg5TU1o54IOGEorSefm.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Sat, 20 Jan 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6828041f-b5e4-470b-b50d-56464a2c5881/extract2-why-care-science-converted.mp3" length="9304063" type="audio/mpeg"/><itunes:duration>09:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>How To Get Into Causal Inference</title><itunes:title>How To Get Into Causal Inference</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=KgesIe3hTe0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KgesIe3hTe0</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/97-probably-overthinking-statistical-paradoxes-allen-downey/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=KgesIe3hTe0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KgesIe3hTe0</a></p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/how-to-get-into-causal-inference]]></link><guid isPermaLink="false">6c0be59a-bd26-4c7a-8700-f7115764be30</guid><itunes:image href="https://artwork.captivate.fm/e88b977a-1b0a-43d5-9443-5cf102fff9cc/DxU0nArwPyI40CM9AP-ROttc.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 17 Jan 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/22044b1a-4bb7-4a8e-86eb-d96bafc62117/extract1-how-to-get-into-causal-inference-converted.mp3" length="9597214" type="audio/mpeg"/><itunes:duration>10:01</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre Andorra</itunes:author></item><item><title>#97 Probably Overthinking Statistical Paradoxes, with Allen Downey</title><itunes:title>Probably Overthinking Statistical Paradoxes, with Allen Downey</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, I had the pleasure of speaking with Allen Downey, a professor emeritus at Olin College and a curriculum designer at Brilliant.org. Allen is a renowned author in the fields of programming and data science, with books such as "Think Python" and "Think Bayes" to his credit. He also authors the blog "Probably Overthinking It" and has a new book by the same name, which he just released in December 2023.</p><p class="ql-align-justify">In this conversation, we tried to help you differentiate between right and wrong ways of looking at statistical data, discussed the Overton paradox and the role of Bayesian thinking in it, and detailed a mysterious Bayesian killer app!</p><p class="ql-align-justify">But that’s not all: we even addressed the claim that Bayesian and frequentist methods often yield the same results — and why it’s a false claim. If that doesn’t get you to listen, I don’t know what will!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>LBS #41, Thinking Bayes, with Allen Downey: <a href="https://learnbayesstats.com/episode/41-think-bayes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/41-think-bayes-allen-downey/</a></li><li>Allen’s blog: <a href="https://www.allendowney.com/blog/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, I had the pleasure of speaking with Allen Downey, a professor emeritus at Olin College and a curriculum designer at Brilliant.org. Allen is a renowned author in the fields of programming and data science, with books such as "Think Python" and "Think Bayes" to his credit. He also authors the blog "Probably Overthinking It" and has a new book by the same name, which he just released in December 2023.</p><p class="ql-align-justify">In this conversation, we tried to help you differentiate between right and wrong ways of looking at statistical data, discussed the Overton paradox and the role of Bayesian thinking in it, and detailed a mysterious Bayesian killer app!</p><p class="ql-align-justify">But that’s not all: we even addressed the claim that Bayesian and frequentist methods often yield the same results — and why it’s a false claim. If that doesn’t get you to listen, I don’t know what will!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas, Luke Gorrie and Cory Kiser</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>LBS #41, Thinking Bayes, with Allen Downey: <a href="https://learnbayesstats.com/episode/41-think-bayes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/41-think-bayes-allen-downey/</a></li><li>Allen’s blog: <a href="https://www.allendowney.com/blog/" rel="noopener noreferrer" target="_blank">https://www.allendowney.com/blog/</a></li><li>Allen on Twitter: <a href="https://twitter.com/allendowney" rel="noopener noreferrer" target="_blank">https://twitter.com/allendowney</a></li><li>Allen on GitHub: <a href="https://github.com/AllenDowney" rel="noopener noreferrer" target="_blank">https://github.com/AllenDowney</a></li><li>Order Allen’s book, <em>Probably Overthinking It</em>, at a 30% discount with the code UCPNEW: <a href="https://press.uchicago.edu/ucp/books/book/chicago/P/bo206532752.html" rel="noopener noreferrer" target="_blank">https://press.uchicago.edu/ucp/books/book/chicago/P/bo206532752.html</a></li><li>The Bayesian Killer App: <a href="https://www.allendowney.com/blog/2023/03/20/the-bayesian-killer-app/" rel="noopener noreferrer" target="_blank">https://www.allendowney.com/blog/2023/03/20/the-bayesian-killer-app/</a></li><li>Bayesian and Frequentist Results Are Not the Same, Ever: <a href="https://www.allendowney.com/blog/2021/04/25/bayesian-and-frequentist-results-are-not-the-same-ever/" rel="noopener noreferrer" target="_blank">https://www.allendowney.com/blog/2021/04/25/bayesian-and-frequentist-results-are-not-the-same-ever/</a></li><li>Allen’s presentation on the Overton paradox: <a href="https://docs.google.com/presentation/d/1-Uvby1Lfe1BTsxNv5R6PhXfwkLUgsyJgdkKtO8nUfJo/edit#slide=id.g291c5d4559e_0_0" rel="noopener noreferrer" target="_blank">https://docs.google.com/presentation/d/1-Uvby1Lfe1BTsxNv5R6PhXfwkLUgsyJgdkKtO8nUfJo/edit#slide=id.g291c5d4559e_0_0</a></li><li>Video on the Overton Paradox, from PyData NYC 2022: <a href="https://youtu.be/VpuWECpTxmM" rel="noopener noreferrer" target="_blank">https://youtu.be/VpuWECpTxmM</a></li><li>Thompson sampling as a dice game: <a href="https://allendowney.github.io/TheShakes/" rel="noopener noreferrer" target="_blank">https://allendowney.github.io/TheShakes/</a></li><li>Causal quartets – Different ways to attain the same average treatment effect: <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/causal_quartets.pdf" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/research/unpublished/causal_quartets.pdf</a></li><li>LBS #89, Unlocking the Science of Exercise, Nutrition &amp; Weight Management, with Eric Trexler: <a href="https://learnbayesstats.com/episode/89-unlocking-science-exercise-nutrition-weight-management-eric-trexler/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/89-unlocking-science-exercise-nutrition-weight-management-eric-trexler/</a></li><li><em>How Minds Change</em>, David McRaney: <a href="https://www.davidmcraney.com/howmindschangehome" rel="noopener noreferrer" target="_blank">https://www.davidmcraney.com/howmindschangehome</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>We are happy to welcome Allen Downey back to ur show and he has great news for us: His new book “Probably Overthinking It” is available now.&nbsp;</p><p>You might know Allen from his blog by the same name or his previous work. Or maybe you watched some of his educational videos which he produces in his new position at brilliant.org.</p><p>We delve right into exciting topics like collider bias and how it can explain the “low brith weight paradox” and other situations that only seem paradoxical at first, until you apply causal thinking to it.</p><p>Another classic Allen can unmystify for us is Simpson’s paradox. The problem is not the data, but your expectations of the data. We talk about some cases of Simpson’s paradox, for example from statistics on the Covid-19 pandemic, also featured in his book.</p><p>We also cover the “Overton paradox” - which Allen named himself - on how people report their ideologies as liberal or conservative over time.&nbsp;</p><p>Next to casual thinking and statistical paradoxes, we return to the common claim that frequentist statistics and Bayesian statistics often give the same results. Allen explains that they are fundamentally different and that Bayesian should not shy away from pointing that out and to emphasise the strengths of their methods.</p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/97-probably-overthinking-statistical-paradoxes-allen-downey]]></link><guid isPermaLink="false">17aea0dd-6a9e-4920-b23e-46c0e19dd403</guid><itunes:image href="https://artwork.captivate.fm/09b83844-889e-458d-b9ff-00673cc94685/_g7kMqyhA2ZqQ_6YtE27qNZE.jpg"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 09 Jan 2024 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/bb6bc5ba-c8f6-4ff5-aad4-daad815e34aa/Learning-Bayesian-Statistics-97-converted.mp3" length="69534709" type="audio/mpeg"/><itunes:duration>01:12:36</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>97</itunes:episode><itunes:season>1</itunes:season><podcast:episode>97</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/8c9d3285-4165-43a3-b997-3facc48dbb4b/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/8c9d3285-4165-43a3-b997-3facc48dbb4b/index.html" type="text/html"/></item><item><title>How to Choose &amp; Use Priors, with Daniel Lee</title><itunes:title>How to Choose &amp; Use Priors, with Daniel Lee</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=lnq5ZPlup0E" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=lnq5ZPlup0E</a></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=lnq5ZPlup0E" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=lnq5ZPlup0E</a></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/how-to-choose-priors-with-daniel-lee]]></link><guid isPermaLink="false">6ca171e1-b87a-4251-8842-41fb3d30b5d5</guid><itunes:image href="https://artwork.captivate.fm/3af1931a-c25d-43d4-8ba1-9f6a1f85d972/8xHI-8IwmfeX_eidyKBgWC-T.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 20 Dec 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/4bb276d5-2962-499e-912a-e4256d640983/how-to-choose-priors-converted.mp3" length="8713286" type="audio/mpeg"/><itunes:duration>09:06</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>Becoming a Good Bayesian &amp; Choosing Mentors, with Daniel Lee</title><itunes:title>Becoming a Good Bayesian &amp; Choosing Mentors, with Daniel Lee</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=lnq5ZPlup0E" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=lnq5ZPlup0E</a></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p>]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Listen to the full episode: <a href="https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/96-pharma-models-sports-analytics-stan-news-daniel-lee/</a></p><p>Watch the interview: <a href="https://www.youtube.com/watch?v=lnq5ZPlup0E" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=lnq5ZPlup0E</a></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/becoming-a-good-bayesian-choosing-mentors-with-daniel-lee]]></link><guid isPermaLink="false">6118508d-3560-48e1-af59-e919fc5a97f8</guid><itunes:image href="https://artwork.captivate.fm/269aaddf-1c05-46a0-8a1f-27d65a2d11b8/hGor-8XoM-FrzXhSsumnSvym.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 13 Dec 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/ea526457-4920-48fd-80d1-ce81cdf9620e/how-to-choose-mentors-converted.mp3" length="9529773" type="audio/mpeg"/><itunes:duration>09:57</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#96 Pharma Models, Sports Analytics &amp; Stan News, with Daniel Lee</title><itunes:title>Pharma Models, Sports Analytics &amp; Stan News, with Daniel Lee</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Getting Daniel Lee on the show is a real treat — with 20 years of experience in numeric computation; 10 years creating and working with Stan; 5 years working on pharma-related models, you can ask him virtually anything. And that I did…</p><p>From joint models for estimating oncology treatment efficacy to PK/PD models; from data fusion for U.S. Navy applications to baseball and football analytics, as well as common misconceptions or challenges in the Bayesian world&nbsp;— our conversation spans a wide range of topics that I’m sure you’ll appreciate!</p><p>Daniel studied Mathematics at MIT and Statistics at Cambridge University, and, when he’s not in front of his computer, is a savvy basketball player and… a hip hop DJ — you actually have his SoundCloud profile in the show notes if you’re curious!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Daniel on Linkedin: <a href="https://www.linkedin.com/in/syclik/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/syclik/</a></li><li>Daniel on Twitter: <a href="https://twitter.com/djsyclik" rel="noopener noreferrer" target="_blank">https://twitter.com/djsyclik</a></li><li>Daniel on GitHub: <a href="https://github.com/syclik" rel="noopener noreferrer" target="_blank">https://github.com/syclik</a></li><li>Daniel's DJ profile: <a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>Getting Daniel Lee on the show is a real treat — with 20 years of experience in numeric computation; 10 years creating and working with Stan; 5 years working on pharma-related models, you can ask him virtually anything. And that I did…</p><p>From joint models for estimating oncology treatment efficacy to PK/PD models; from data fusion for U.S. Navy applications to baseball and football analytics, as well as common misconceptions or challenges in the Bayesian world&nbsp;— our conversation spans a wide range of topics that I’m sure you’ll appreciate!</p><p>Daniel studied Mathematics at MIT and Statistics at Cambridge University, and, when he’s not in front of his computer, is a savvy basketball player and… a hip hop DJ — you actually have his SoundCloud profile in the show notes if you’re curious!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates, Matt Niccolls, Maksim Kuznecov, Michael Thomas and Luke Gorrie</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Daniel on Linkedin: <a href="https://www.linkedin.com/in/syclik/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/syclik/</a></li><li>Daniel on Twitter: <a href="https://twitter.com/djsyclik" rel="noopener noreferrer" target="_blank">https://twitter.com/djsyclik</a></li><li>Daniel on GitHub: <a href="https://github.com/syclik" rel="noopener noreferrer" target="_blank">https://github.com/syclik</a></li><li>Daniel's DJ profile: <a href="https://soundcloud.com/dj-syclik" rel="noopener noreferrer" target="_blank">https://soundcloud.com/dj-syclik</a></li><li>LBS #91, Exploring European Football Analytics, with Max Göbel: <a href="https://learnbayesstats.com/episode/91-exploring-european-football-analytics-max-gobel/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/91-exploring-european-football-analytics-max-gobel/</a></li><li>LBS #85, A Brief History of Sports Analytics, with Jim Albert: <a href="https://learnbayesstats.com/episode/85-brief-history-sports-analytics-jim-albert/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/85-brief-history-sports-analytics-jim-albert/</a></li><li>Daniel about GPTs in Probabilistic Programming: <a href="https://www.youtube.com/watch?v=KUuSwLMFPHM" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KUuSwLMFPHM</a></li><li>LBS #50, Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li>LBS #76, The Past, Present &amp; Future of Stan, with Bob Carpenter: <a href="https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/</a></li><li>LBS #27, Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns: <a href="https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/</a></li><li>LBS #20, Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>Our guest this week, Daniel Lee, is a real Bayesian allrounder and will give us new insights into a lot of Bayesian applications.&nbsp;</p><p>Daniel got introduced to Bayesian stats when trying to estimate the failure rate of satellite dishes as an undergraduate student. He was lucky to be mentored by Bayesian greats like David Spiegelhalter, Andrew Gelman and Bob Carpenter. He also sat in on reading groups at universities where he learned about cutting edge developments - something he would recommend anyone to really dive deep into the matter.</p><p>He used all this experience working on Pk/Pd (Pharmacokinetics/ Pharmacodynamics) models. We talk about the challenges in understanding individual responses to drugs based on the speed with which they move through the body. Bayesian statistics allows for incorporating more complexity into those models for more accurate estimation.</p><p>Daniel also worked on decision making and information fusing problems for the military, such as identifying a plane as friend or foe through the radar of several ships.</p><p>And to add even more diversity to his repertoire, Daniel now also works in the world of sports analytics, another popular topic on our show. We talk about the state of this emerging field and its challenges.</p><p class="ql-align-justify">Finally, we cover some STAN news, discuss common problems and misconceptions around Bayesian statistics and how to resolve them.</p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/96-pharma-models-sports-analytics-stan-news-daniel-lee]]></link><guid isPermaLink="false">376c3be6-2255-480e-ba7b-e1e62b43c763</guid><itunes:image href="https://artwork.captivate.fm/470257c6-ec6b-40e2-b766-4782e2c7366b/TUCjVk5xstP-4XRENTJqSC9q.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 28 Nov 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/1a96c53e-4167-42b8-a5f2-9ae3a5f4efb4/Learning-Bayesian-Statistics-96-converted.mp3" length="53494918" type="audio/mpeg"/><itunes:duration>55:51</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>96</itunes:episode><itunes:season>1</itunes:season><podcast:episode>96</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/f71c4d99-b45c-4ca9-9108-36275bbd8a46/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/f71c4d99-b45c-4ca9-9108-36275bbd8a46/index.html" type="text/html"/></item><item><title>#95 Unraveling Cosmic Mysteries, with Valerie Domcke</title><itunes:title>Unraveling Cosmic Mysteries, with Valerie Domcke</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Welcome to another installment of our LBS physics deep dive! After exploring the world of experimental physics at CERN in our first video documentary in episode 93, we’ll stay in Geneva for this one, but this time we’ll dive into theoretical physics.</p><p class="ql-align-justify">We’ll explore mysterious components of the universe, like dark matter and dark energy. We’ll also see how the study of gravity intersects with the study of particle physics, especially when considering black holes and the early universe. Even crazier, we’ll see that there are actual experiments and observational projects going on to answer these fundamental questions!</p><p class="ql-align-justify">Our guide for this episode is Valerie Domcke, permanent research staff member at CERN, who did her PhD in Hamburg, Germany, and postdocs in Trieste and Paris.</p><p class="ql-align-justify">When she’s not trying to decipher the mysteries of the universe, Valerie can be found on boats, as she’s a big sailing fan.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates</em>,<em> Matt Niccolls and Maksim Kuznecov</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Valerie’s webpage: <a href="https://theory.cern/roster/domcke-valerie" rel="noopener noreferrer" target="_blank">https://theory.cern/roster/domcke-valerie</a></li><li>Valerie on Google Scholar: <a href="https://scholar.google.com/citations?user=E3g0tn4AAAAJ" rel="noopener...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Welcome to another installment of our LBS physics deep dive! After exploring the world of experimental physics at CERN in our first video documentary in episode 93, we’ll stay in Geneva for this one, but this time we’ll dive into theoretical physics.</p><p class="ql-align-justify">We’ll explore mysterious components of the universe, like dark matter and dark energy. We’ll also see how the study of gravity intersects with the study of particle physics, especially when considering black holes and the early universe. Even crazier, we’ll see that there are actual experiments and observational projects going on to answer these fundamental questions!</p><p class="ql-align-justify">Our guide for this episode is Valerie Domcke, permanent research staff member at CERN, who did her PhD in Hamburg, Germany, and postdocs in Trieste and Paris.</p><p class="ql-align-justify">When she’s not trying to decipher the mysteries of the universe, Valerie can be found on boats, as she’s a big sailing fan.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca, Dante Gates</em>,<em> Matt Niccolls and Maksim Kuznecov</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Valerie’s webpage: <a href="https://theory.cern/roster/domcke-valerie" rel="noopener noreferrer" target="_blank">https://theory.cern/roster/domcke-valerie</a></li><li>Valerie on Google Scholar: <a href="https://scholar.google.com/citations?user=E3g0tn4AAAAJ" rel="noopener noreferrer" target="_blank">https://scholar.google.com/citations?user=E3g0tn4AAAAJ</a></li><li>LBS #93 A CERN Odyssey, with Kevin Greiff: <a href="https://www.youtube.com/watch?v=rOaqIIEtdpI" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=rOaqIIEtdpI</a></li><li>LBS #64, Modeling the Climate &amp; Gravity Waves, with Laura Mansfield: <a href="https://learnbayesstats.com/episode/64-modeling-climate-gravity-waves-laura-mansfield/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/64-modeling-climate-gravity-waves-laura-mansfield/</a></li><li>LBS Physics Playlist: <a href="https://learnbayesstats.com/physics-astrophysics/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/physics-astrophysics/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>Episode 95 is another instalment of our Deep Dive into Physics series. And this time we move away from the empirical side of this topic towards more theoretical questions.&nbsp;</p><p>There is no one better for this topic than Dr. Valerie Domcke. Valerie is the second&nbsp;researcher from the CERN we have on our show. She is located at the Department of Theoretical Physics there.</p><p>We mainly focus on the Standard Model of Physics, where it fails to explain observations, what proposals are discussed to update or replace it and what kind of evidence would be needed to make such a decision.</p><p>Valerie is particularly interested in situations in which the Standard Model brakes down, such as when trying to explain the excess gravitational pull observed that cannot be accounted for by visible stars.&nbsp;</p><p>Of course, we cover fascinating topics like dark matter, dark energy, black holes and gravitational waves that are places to look for evidence against the Standard Model.</p><p>Looking more at the practical side of things, we discuss the challenges in disentangling signal from noise, especially in such complex fields as astro- and quantum-physics.&nbsp;</p><p class="ql-align-justify">We also touch upon the challenges Valerie is currently tackling in working on a new observatory for gravitational waves, the Laser Interferometer Space Antenna, LISA.&nbsp;</p><p class="ql-align-justify"><strong>﻿Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/95-unraveling-cosmic-mysteries-valerie-domcke]]></link><guid isPermaLink="false">1065f48b-4fc6-47c9-aa91-0b6b51272a1d</guid><itunes:image href="https://artwork.captivate.fm/8829954c-4ba6-414a-88d4-a2dcce46f3c1/wkkMi_mku57WU1BXYHFNrZ3D.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 15 Nov 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/38e449bf-411b-4c74-9c61-884c577e4c1c/Learning-Bayesian-Statistics-95-converted.mp3" length="57742784" type="audio/mpeg"/><itunes:duration>01:00:17</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>95</itunes:episode><itunes:season>1</itunes:season><podcast:episode>95</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/bb59b17b-b6fb-40e3-b2c1-aa608c51df0d/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/bb59b17b-b6fb-40e3-b2c1-aa608c51df0d/index.html" type="text/html"/></item><item><title>#94 Psychometrics Models &amp; Choosing Priors, with Jonathan Templin</title><itunes:title>Psychometrics Models &amp; Choosing Priors, with Jonathan Templin</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Jonathan Templin, Professor of Psychological and Quantitative Foundations at the University of Iowa, shares insights into his journey in the world of psychometrics.</p><p class="ql-align-justify">Jonathan’s research focuses on diagnostic classification models — psychometric models that seek to provide multiple reliable scores from educational and psychological assessments. He also studies Bayesian statistics, as applied in psychometrics, broadly. So, naturally, we discuss the significance of psychometrics in psychological sciences, and how Bayesian methods are helpful in this field.</p><p class="ql-align-justify">We also talk about challenges in choosing appropriate prior distributions, best practices for model comparison, and how you can use the Multivariate Normal distribution to infer the correlations between the predictors of your linear regressions.</p><p class="ql-align-justify">This is a deep-reaching conversation that concludes with the future of Bayesian statistics in psychological, educational, and social sciences — hope you’ll enjoy it!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca and Dante Gates</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Jonathan’s website: <a href="https://jonathantemplin.com/" target="_blank">https://jonathantemplin.com/</a></li><li>Jonathan on Twitter: <a href="https://twitter.com/DrJTemplin" target="_blank">https://twitter.com/DrJTemplin</a></li><li>Jonathan on Linkedin: <a href="https://www.linkedin.com/in/jonathan-templin-0239b07/" target="_blank">https://www.linkedin.com/in/jonathan-templin-0239b07/</a></li><li>Jonathan on...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, Jonathan Templin, Professor of Psychological and Quantitative Foundations at the University of Iowa, shares insights into his journey in the world of psychometrics.</p><p class="ql-align-justify">Jonathan’s research focuses on diagnostic classification models — psychometric models that seek to provide multiple reliable scores from educational and psychological assessments. He also studies Bayesian statistics, as applied in psychometrics, broadly. So, naturally, we discuss the significance of psychometrics in psychological sciences, and how Bayesian methods are helpful in this field.</p><p class="ql-align-justify">We also talk about challenges in choosing appropriate prior distributions, best practices for model comparison, and how you can use the Multivariate Normal distribution to infer the correlations between the predictors of your linear regressions.</p><p class="ql-align-justify">This is a deep-reaching conversation that concludes with the future of Bayesian statistics in psychological, educational, and social sciences — hope you’ll enjoy it!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau, Luis Fonseca and Dante Gates</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Jonathan’s website: <a href="https://jonathantemplin.com/" target="_blank">https://jonathantemplin.com/</a></li><li>Jonathan on Twitter: <a href="https://twitter.com/DrJTemplin" target="_blank">https://twitter.com/DrJTemplin</a></li><li>Jonathan on Linkedin: <a href="https://www.linkedin.com/in/jonathan-templin-0239b07/" target="_blank">https://www.linkedin.com/in/jonathan-templin-0239b07/</a></li><li>Jonathan on GitHub: <a href="https://github.com/jonathantemplin" target="_blank">https://github.com/jonathantemplin</a></li><li>Jonathan on Google Scholar: <a href="https://scholar.google.com/citations?user=veeVxxMAAAAJ&amp;hl=en&amp;authuser=1" target="_blank">https://scholar.google.com/citations?user=veeVxxMAAAAJ&amp;hl=en&amp;authuser=1</a></li><li>Jonathan on Youtube: <a href="https://www.youtube.com/channel/UC6WctsOhVfGW1D9NZUH1xFg" target="_blank">https://www.youtube.com/channel/UC6WctsOhVfGW1D9NZUH1xFg</a></li><li>Jonathan’s book: <a href="https://jonathantemplin.com/diagnostic-measurement-theory-methods-applications/" target="_blank">https://jonathantemplin.com/diagnostic-measurement-theory-methods-applications/</a></li><li>Jonathan’s teaching: <a href="https://jonathantemplin.com/teaching/" target="_blank">https://jonathantemplin.com/teaching/</a></li><li>Vehtari et al. (2016), Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC: <a href="https://arxiv.org/abs/1507.04544" target="_blank">https://arxiv.org/abs/1507.04544</a></li><li>arviz.plot_compare: <a href="https://python.arviz.org/en/stable/api/generated/arviz.plot_compare.html" target="_blank">https://python.arviz.org/en/stable/api/generated/arviz.plot_compare.html</a></li><li>LBS #35, The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/" target="_blank">https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/</a></li><li>LBS #40, Bayesian Stats for the Speech &amp; Language Sciences, with Allison Hilger and Timo Roettger: <a href="https://learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger/" target="_blank">https://learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger/</a></li><li>Bayesian Model-Building Interface in Python: <a href="https://bambinos.github.io/bambi/" target="_blank">https://bambinos.github.io/bambi/</a></li></ul><br/><br><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>You have probably unknowingly already been exposed to this episode’s topic - psychometric testing - when taking a test at school or university. Our guest, Professor Jonathan Templin, tries to increase the meaningfulness of these tests by improving the underlying psychometric models, the bayesian way of course!</p><p>Jonathan explains that it is not easy to judge the ability of a student based on exams since they have errors and are only a snapshot. Bayesian statistics helps by naturally propagating this uncertainty to the results.</p><p>In the field of psychometric testing, Marginal Maximum Likelihood is commonly used. This approach quickly becomes unfeasible though when trying to marginalise over multidimensional test scores. Luckily, Bayesian probabilistic sampling does not suffer from this.</p><p>A further reason to prefer Bayesian statistics is that it provides a lot of information in the posterior. Imagine taking a test that tells you what profession you should pursue at the end of high school. The field with the best fit is of course interesting, but the second best fit may be as well. The posterior distribution can provide this kind of information.</p><p>After becoming convinced that Bayes is the right choice for psychometrics, we also talk about practical challenges like choosing a prior for the covariance in a multivariate normal distribution, model selection procedures and more.</p><p class="ql-align-justify">In the end we learn about a great Bayesian holiday destination, so make sure to listen till the end!</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/94-psychometrics-models-choosing-priors-jonathan-templin]]></link><guid isPermaLink="false">6cfe7413-749a-44f5-84c9-4e0e089b341a</guid><itunes:image href="https://artwork.captivate.fm/d01de90e-0161-4060-8329-d4ecc925af10/eido9nXHjvInNFWwrEcQe4Ej.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 24 Oct 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a63ca50a-e08f-4a76-94e2-4b9d80afd75e/Learning-Bayesian-Statistics-94-converted.mp3" length="63619565" type="audio/mpeg"/><itunes:duration>01:06:25</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>94</itunes:episode><itunes:season>1</itunes:season><podcast:episode>94</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/ca4c8ea2-ba7a-4773-8c17-e0782fe9f54a/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/ca4c8ea2-ba7a-4773-8c17-e0782fe9f54a/index.html" type="text/html"/></item><item><title>#93 A CERN Odyssey, with Kevin Greif</title><itunes:title>A CERN Odyssey, with Kevin Greif</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This is a very special episode. It is the first-ever LBS video episode, and it takes place in the heart of particle physics research -- the CERN 🍾</p><p class="ql-align-justify">I went onsite in Geneva, to visit Kevin Greif, a doctoral candidate in particle physics at UC Irvine, and we walked around the CERN campus, talking about particle physics, dark matter, dark energy, machine learning -- and a lot more!</p><p class="ql-align-justify">I still released the audio form of this episode, but I really thought and made it as a video-first episode, so I strongly recommend watching this one, as you’ll get a cool tour of the CERN campus and some of its experiments ;) I put the YouTube link in the show notes.</p><p class="ql-align-justify">I hope you'll enjoy this deep dive into all things physics. If you have any recommendations for other cool scientific places I should do a documentary about, please get in touch on Twitter @LearnBayesStats, or by email.</p><p class="ql-align-justify">This was literally a one-person endeavor — you may have noticed that I edited the video myself. So, if you liked it, please send this episode to your friends and colleagues -- and tell them to support the show on Patreon 😉&nbsp;</p><p class="ql-align-justify">With enough support, that means I'll be able to continue with such in-depth content, and maybe, maybe, even pay for a professional video editor next time 🙈&nbsp;</p><p class="ql-align-justify">Enjoy, my dear Bayesians, and best Bayesian wishes 🖖</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This is a very special episode. It is the first-ever LBS video episode, and it takes place in the heart of particle physics research -- the CERN 🍾</p><p class="ql-align-justify">I went onsite in Geneva, to visit Kevin Greif, a doctoral candidate in particle physics at UC Irvine, and we walked around the CERN campus, talking about particle physics, dark matter, dark energy, machine learning -- and a lot more!</p><p class="ql-align-justify">I still released the audio form of this episode, but I really thought and made it as a video-first episode, so I strongly recommend watching this one, as you’ll get a cool tour of the CERN campus and some of its experiments ;) I put the YouTube link in the show notes.</p><p class="ql-align-justify">I hope you'll enjoy this deep dive into all things physics. If you have any recommendations for other cool scientific places I should do a documentary about, please get in touch on Twitter @LearnBayesStats, or by email.</p><p class="ql-align-justify">This was literally a one-person endeavor — you may have noticed that I edited the video myself. So, if you liked it, please send this episode to your friends and colleagues -- and tell them to support the show on Patreon 😉&nbsp;</p><p class="ql-align-justify">With enough support, that means I'll be able to continue with such in-depth content, and maybe, maybe, even pay for a professional video editor next time 🙈&nbsp;</p><p class="ql-align-justify">Enjoy, my dear Bayesians, and best Bayesian wishes 🖖</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Video of the episode: <a href="https://www.youtube.com/watch?v=rOaqIIEtdpI" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=rOaqIIEtdpI</a></li><li>Kevin on Linkedin:<a href="https://www.linkedin.com/in/kevin-greif-824b091b4/" rel="noopener noreferrer" target="_blank"> https://www.linkedin.com/in/kevin-greif-824b091b4/</a>&nbsp;</li><li>Kevin on Twitter: <a href="https://twitter.com/greif_kevin" rel="noopener noreferrer" target="_blank">https://twitter.com/greif_kevin</a></li><li>ATLAS homepage: <a href="https://atlas.cern" rel="noopener noreferrer" target="_blank">https://atlas.cern</a></li><li>Kevin’s most recent paper on unfolding: <a href="https://arxiv.org/abs/2305.10399" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2305.10399</a></li><li>LBS on Twitter:<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbWFtTjJwZDNXNmo4WFJKSXUzaERIZEFoa1dhd3xBQ3Jtc0tsbzlFV3VxdkRjaXYxSTJLNUZGb01xcDBTbHFFamFKaHREX1dfRXlZOEtja3V1Qmh3V2l1bjdvSXZmbzk3UzJ5Y3J1azFSNDBhVXdXdTVqbWZOc3B2VWppVktmM3lMWTRIWkVLMm9pajZheWMtaWwzQQ&amp;q=https%3A%2F%2Ftwitter.com%2FLearnBayesStats&amp;v=rOaqIIEtdpI" rel="noopener noreferrer" target="_blank"> </a><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank">https://twitter.com/LearnBayesStats</a></li><li>LBS on Linkedin: <a href="https://www.linkedin.com/company/91594158/admin/feed/posts/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/company/91594158/admin/feed/posts/</a></li><li>LBS Physics Playlist:<a href="https://learnbayesstats.com/physics-astrophysics/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/physics-astrophysics/</a>&nbsp;</li><li>LBS #72, Why the Universe is so Deliciously Crazy, with Daniel Whiteson:<a href="https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/</a>&nbsp;</li><li>CERN Website:<a href="https://www.home.cern/" rel="noopener noreferrer" target="_blank"> https://www.home.cern/</a></li></ul><br/><p><strong>Some physics (and physics adjacent) books Kevin enjoys:</strong></p><ul><li>Copenhagen” by Michael Frayn: <a href="https://www.amazon.com/Copenhagen-Michael-Frayn/dp/0385720793" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Copenhagen-Michael-Frayn/dp/0385720793</a></li><li>“The Three Body Problem” by Cixin Liu <a href="https://www.goodreads.com/book/show/20518872-the-three-body-problem" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/20518872-the-three-body-problem</a></li><li>“The Aleph” by Jorge Luis Borges <a href="https://books.google.com.ar/books/about/The_Aleph_and_Other_Stories.html?id=XYZlAAAAMAAJ&amp;redir_esc=y" rel="noopener noreferrer" target="_blank">https://books.google.com.ar/books/about/The_Aleph_and_Other_Stories.html?id=XYZlAAAAMAAJ&amp;redir_esc=y</a></li><li>The NOVA special that started it all for Kevin <a href="https://www.youtube.com/watch?v=V64toYdH9hU" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=V64toYdH9hU</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/93-cern-odyssey-kevin-greif]]></link><guid isPermaLink="false">25b3337a-b6d1-407e-803c-6bb1107282b4</guid><itunes:image href="https://artwork.captivate.fm/ef14f44a-35fa-488f-a572-f7d7652f221f/2mYSmepB2ejtJopkANMfyLRs.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 18 Oct 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/52e77d91-31cf-4c8f-9952-851d63ec85e6/93-cern-odyssey-converted.mp3" length="209433611" type="audio/mpeg"/><itunes:duration>01:49:05</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>93</itunes:episode><itunes:season>1</itunes:season><podcast:episode>93</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#92 How to Make Decision Under Uncertainty, with Gerd Gigerenzer</title><itunes:title>How to Make Decision Under Uncertainty, with Gerd Gigerenzer</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">I love Bayesian modeling. Not only because it allows me to model interesting phenomena and learn about the world I live in. But because it’s part of a broader epistemological framework that confronts me with deep questions — how do you make decisions under uncertainty? How do you communicate risk and uncertainty? What does being rational even mean?</p><p class="ql-align-justify">Thankfully, Gerd Gigerenzer is there to help us navigate these fascinating topics. Gerd is the Director of the Harding Center for Risk Literacy of the University of Potsdam, Germany.</p><p class="ql-align-justify">Also Director emeritus at the Max Planck Institute for Human Development, he is a former Professor of Psychology at the University of Chicago and Distinguished Visiting Professor at the School of Law of the University of Virginia.&nbsp;</p><p class="ql-align-justify">Gerd has written numerous awarded articles and books, including Risk Savvy, Simple Heuristics That Make Us Smart, Rationality for Mortals, and How to Stay Smart in a Smart World.</p><p class="ql-align-justify">As you’ll hear, Gerd has trained U.S. federal judges, German physicians, and top managers to make better decisions under uncertainty.</p><p class="ql-align-justify">But Gerd is also a banjo player, has won a medal in Judo, and loves scuba diving, skiing, and, above all, reading.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">I love Bayesian modeling. Not only because it allows me to model interesting phenomena and learn about the world I live in. But because it’s part of a broader epistemological framework that confronts me with deep questions — how do you make decisions under uncertainty? How do you communicate risk and uncertainty? What does being rational even mean?</p><p class="ql-align-justify">Thankfully, Gerd Gigerenzer is there to help us navigate these fascinating topics. Gerd is the Director of the Harding Center for Risk Literacy of the University of Potsdam, Germany.</p><p class="ql-align-justify">Also Director emeritus at the Max Planck Institute for Human Development, he is a former Professor of Psychology at the University of Chicago and Distinguished Visiting Professor at the School of Law of the University of Virginia.&nbsp;</p><p class="ql-align-justify">Gerd has written numerous awarded articles and books, including Risk Savvy, Simple Heuristics That Make Us Smart, Rationality for Mortals, and How to Stay Smart in a Smart World.</p><p class="ql-align-justify">As you’ll hear, Gerd has trained U.S. federal judges, German physicians, and top managers to make better decisions under uncertainty.</p><p class="ql-align-justify">But Gerd is also a banjo player, has won a medal in Judo, and loves scuba diving, skiing, and, above all, reading.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</li><li class="ql-align-justify">Gerd’s website: <a href="https://www.mpib-berlin.mpg.de/staff/gerd-gigerenzer" target="_blank">https://www.mpib-berlin.mpg.de/staff/gerd-gigerenzer</a></li><li>Do children have Bayesian intuitions: <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fxge0000979" target="_blank">https://psycnet.apa.org/doiLanding?doi=10.1037%2Fxge0000979</a></li><li>What are natural frequencies: <a href="https://www.bmj.com/content/343/bmj.d6386" target="_blank">https://www.bmj.com/content/343/bmj.d6386</a></li><li>HIV screening: helping clinicians make sense of test results to patients: <a href="https://www.bmj.com/content/347/bmj.f5151" target="_blank">https://www.bmj.com/content/347/bmj.f5151</a></li><li>Teaching Bayesian Reasoning in Less Than Two Hours: <a href="https://www.apa.org/pubs/journals/releases/xge-1303380.pdf" target="_blank">https://www.apa.org/pubs/journals/releases/xge-1303380.pdf</a></li><li>How to Stay Smart in a Smart World – Why Human Intelligence Still Beats Algorithms: <a href="https://www.amazon.com/How-Stay-Smart-World-Intelligence/dp/0262046954" target="_blank">https://www.amazon.com/How-Stay-Smart-World-Intelligence/dp/0262046954</a></li><li>Gut Feelings – The Intelligence of the Unconscious: <a href="https://www.amazon.com/Gut-Feelings-Intelligence-Gerd-Gigerenzer/dp/0143113763" target="_blank">https://www.amazon.com/Gut-Feelings-Intelligence-Gerd-Gigerenzer/dp/0143113763</a></li><li>Better Doctors, Better Patients, Better Decisions: <a href="https://www.amazon.com/Better-Doctors-Patients-Decisions-Envisioning/dp/026251852X" target="_blank">https://www.amazon.com/Better-Doctors-Patients-Decisions-Envisioning/dp/026251852X</a></li><li>LBS #50, Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li>LBS #87, Unlocking the Power of Bayesian Causal Inference, with Ben Vincent: <a href="https://learnbayesstats.com/episode/87-unlocking-the-power-of-bayesian-causal-inference-ben-vincent/" target="_blank">https://learnbayesstats.com/episode/87-unlocking-the-power-of-bayesian-causal-inference-ben-vincent/</a></li><li>As a bonus, Gerd playing the banjo: <a href="https://www.youtube.com/watch?v=qBllveuj8RI" target="_blank">https://www.youtube.com/watch?v=qBllveuj8RI</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em> by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this episode, we have no other than Gerd Gigerenzer on the show, an expert in decision making, rationality and communicating risk and probabilities.&nbsp;</p><p>Gerd is a trained psychologist and worked at a number of distinguished institutes like the Max Planck Institute for Human Development in Berlin or the University of Chicago. He is director of the Harding Center for Risk Literacy in Potsdam.&nbsp;</p><p>One of his many topics of study are heuristics, a term often misunderstood, as he explains. We talk about the role of heuristics in a world of uncertainty, how it interacts with analysis and how it relates to intuition.</p><p>Another major topic of his work and this episode are natural frequencies and how they are a more natural way than conditional probabilities to express information&nbsp;such as the probability of having cancer after a positive screening.&nbsp;</p><p>Gerd studied the usefulness of natural frequencies in practice and contributed to them being taught in high school in Bavaria, Germany, as an important tool to navigate the real world.</p><p>In general, Gerd is passionate about not only researching these topics but also seeing them applied outside of academia. He taught thousands of medical doctors how to understand and communicate statistics and also worked on a number of economical decision making scenarios.</p><p class="ql-align-justify">In the end we discuss the benefits of simpler models for complex, uncertain situations, as for example in the case of predicting flu seasons.</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/92-how-to-make-decision-under-uncertainty-gerd-gigerenzer]]></link><guid isPermaLink="false">21b6879c-dd0e-4ebd-9833-915681520a77</guid><itunes:image href="https://artwork.captivate.fm/7d3660ac-32f6-4cdd-bc68-478608288e4e/i2jRkt0DkQ4r23EpVR520VM6.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 04 Oct 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/55141865-f885-4e4e-bf13-d65605a38e30/Learning-Bayesian-Statistics-92-converted.mp3" length="62023706" type="audio/mpeg"/><itunes:duration>01:04:45</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>92</itunes:episode><itunes:season>1</itunes:season><podcast:episode>92</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/3577855b-4d0a-4956-bcc3-d2c3fbdd23a2/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/3577855b-4d0a-4956-bcc3-d2c3fbdd23a2/index.html" type="text/html"/></item><item><title>#91, Exploring European Football Analytics, with Max Göbel</title><itunes:title>Exploring European Football Analytics, with Max Göbel</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">As you may know, I’m kind of a nerd. And I also love football — I've been a PSG fan since I’m 5 years old, so I’ve lived it all with this club.. And yet, I’ve never done a European-centered football analytics episode because, well, the US are much more advanced when it comes to sports analytics.</p><p class="ql-align-justify">But today, I’m happy to say this day has come: a sports analytics episode where we can actually talk about European football. And that is thanks to Maximilan Göbel.</p><p class="ql-align-justify">Max is a post-doctoral researcher in Economics and Finance at Bocconi University in Milan. Before that, he did his PhD in Economics at the Lisbon School of Economics and Management.&nbsp;</p><p class="ql-align-justify">Max is a very passionate football fan and played himself for almost 25 years in his local football club. Unfortunately, he had to give it up when starting his PhD — don’t worry, he still goes to the gym, or goes running and sometimes cycling.</p><p class="ql-align-justify">Max is also a great cook, inspired by all kinds of Italian food, and an avid podcast listener — from financial news, to health and fitness content, and even a mysterious and entertaining Bayesian podcast…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Max’s website: <a href="https://www.maximiliangoebel.com/home" rel="noopener...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">As you may know, I’m kind of a nerd. And I also love football — I've been a PSG fan since I’m 5 years old, so I’ve lived it all with this club.. And yet, I’ve never done a European-centered football analytics episode because, well, the US are much more advanced when it comes to sports analytics.</p><p class="ql-align-justify">But today, I’m happy to say this day has come: a sports analytics episode where we can actually talk about European football. And that is thanks to Maximilan Göbel.</p><p class="ql-align-justify">Max is a post-doctoral researcher in Economics and Finance at Bocconi University in Milan. Before that, he did his PhD in Economics at the Lisbon School of Economics and Management.&nbsp;</p><p class="ql-align-justify">Max is a very passionate football fan and played himself for almost 25 years in his local football club. Unfortunately, he had to give it up when starting his PhD — don’t worry, he still goes to the gym, or goes running and sometimes cycling.</p><p class="ql-align-justify">Max is also a great cook, inspired by all kinds of Italian food, and an avid podcast listener — from financial news, to health and fitness content, and even a mysterious and entertaining Bayesian podcast…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar, Matt Rosinski, Bart Trudeau and Luis Fonseca</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Max’s website: <a href="https://www.maximiliangoebel.com/home" rel="noopener noreferrer" target="_blank">https://www.maximiliangoebel.com/home</a></li><li>Max on GitHub: <a href="https://github.com/maxi-tb22" rel="noopener noreferrer" target="_blank">https://github.com/maxi-tb22</a></li><li>Max on LinkedIn: <a href="https://www.linkedin.com/in/maximilian-g%C3%B6bel-188b0413a/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/maximilian-g%C3%B6bel-188b0413a/</a></li><li>Max’s Soccer Analytics page: <a href="https://www.maximiliangoebel.com/soccer-analytics" rel="noopener noreferrer" target="_blank">https://www.maximiliangoebel.com/soccer-analytics</a></li><li>Soccer Factor Model on GitHub: <a href="https://github.com/maxi-tb22/SFM" rel="noopener noreferrer" target="_blank">https://github.com/maxi-tb22/SFM</a></li><li>Max webinar on his Soccer Factor Model: <a href="https://www.youtube.com/watch?v=2dGrN8JGd_w" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=2dGrN8JGd_w</a></li></ul><br/><p><strong>Max's paper using Bayesian inference</strong>:</p><ul><li>VARCTIC - A Baysian Vector Autoregression for the Arctic: “<em>Arctic Amplification of Anthropogenic Forcing: A Vector Autoregressive Analysis</em>”: <a href="https://journals.ametsoc.org/view/journals/clim/34/13/JCLI-D-20-0324.1.xml" rel="noopener noreferrer" target="_blank">https://journals.ametsoc.org/view/journals/clim/34/13/JCLI-D-20-0324.1.xml</a></li></ul><br/><p><strong>Forecasting Arctic Sea Ice:</strong></p><ul><li>Daily predictions of Arctic Sea Ice Extent: <a href="https://chairemacro.esg.uqam.ca/arctic-sea-ice-forecasting/?lang=en" rel="noopener noreferrer" target="_blank">https://chairemacro.esg.uqam.ca/arctic-sea-ice-forecasting/?lang=en</a></li><li>Sea Ice Outlook (SIO) Forecasting competition: <a href="https://www.arcus.org/sipn/sea-ice-outlook" rel="noopener noreferrer" target="_blank">https://www.arcus.org/sipn/sea-ice-outlook</a></li></ul><br/><p><strong>Some of Max’s coauthors:</strong></p><ul><li>Philippe Goulet Coulombe (UQAM): <a href="https://philippegouletcoulombe.com/" rel="noopener noreferrer" target="_blank">https://philippegouletcoulombe.com/</a></li><li>Francis X. Diebold (UPenn): <a href="https://www.sas.upenn.edu/~fdiebold/" rel="noopener noreferrer" target="_blank">https://www.sas.upenn.edu/~fdiebold/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>We already covered baseball analytics in the U.S.A. with Jim Albert in episode 85 and looked back at the decade long history of sports analytics there. How does it look like in Europe?&nbsp;</p><p>To talk about this we got Max Göbel on the show. Max is a post-doctoral researcher in Economics and Finance at Bocconi University in Milan and holds a PhD in Economics from the Lisbon School of Economics and Management.</p><p>What qualifies him to talk about the&nbsp;sports-side of sports analytics is his passion for football and decades of playing experience.&nbsp;</p><p>So, can sports analytics in Europe compete with analytics in the U.S.A.? Unfortunately, not yet. Many sports clubs do not use models in their hiring decisions, leading to suboptimal choices based on players’ reputation alone, as Max explains.</p><p>He designed a factor model for the performance of single players, borrowing from his econometrics expertise (check it out on his webpage, link in the show notes).&nbsp;</p><p>We talk about how to grow this model from a simple and straight-forward Bernoulli model for the rate of scored goals to a multilevel model, incorporating other players. And of course, we discuss the benefits for using Bayesian statistics for this modelling problem.</p><p>We also cover sport analytics more generally and why it may not be so widely used in European football clubs yet.&nbsp;</p><p class="ql-align-justify">Besides his interest in football analytics, Max worked and works on topics in econometrics such as regression forecasting in the U.S.A., asset pricing and applying econometric methods to climate change issues like climate change&nbsp;forecasting and&nbsp;sea ice disappearance.</p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/91-exploring-european-football-analytics-max-gobel]]></link><guid isPermaLink="false">45e9d7a2-d0c2-463f-ae20-74e33040ab13</guid><itunes:image href="https://artwork.captivate.fm/be64ec45-e370-48d7-a7df-f059e7f5b37b/Hg-Q-_BBB7DLhjOuANbn4vce.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Wed, 20 Sep 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/404f99e0-839e-4fba-a1a4-9da86affe91d/Learning-Bayesian-Statistics-91-converted.mp3" length="61519136" type="audio/mpeg"/><itunes:duration>01:04:13</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>91</itunes:episode><itunes:season>1</itunes:season><podcast:episode>91</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/88f3ae32-4136-4916-93e0-1270c04cc9f4/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/88f3ae32-4136-4916-93e0-1270c04cc9f4/index.html" type="text/html"/></item><item><title>#90, Demystifying MCMC &amp; Variational Inference, with Charles Margossian</title><itunes:title>Demystifying MCMC &amp; Variational Inference, with Charles Margossian</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">What’s the difference between MCMC and Variational Inference (VI)? Why is MCMC called an approximate method? When should we use VI instead of MCMC?</p><p class="ql-align-justify">These are some of the captivating (and practical) questions we’ll tackle in this episode. I had the chance to interview Charles Margossian, a research fellow in computational mathematics at the Flatiron Institute, and a core developer of the Stan software.</p><p class="ql-align-justify">Charles was born and raised in Paris, and then moved to the US to pursue a bachelor’s degree in physics at Yale university. After graduating, he worked for two years in biotech, and went on to do a PhD in statistics at Columbia University with someone named… Andrew Gelman — you may have heard of him.</p><p class="ql-align-justify">Charles is also specialized in pharmacometrics and epidemiology, so we also talked about some practical applications of Bayesian methods and algorithms in these fascinating fields.</p><p class="ql-align-justify">Oh, and Charles’ life doesn’t only revolve around computers: he practices ballroom dancing and pickup soccer, and used to do improvised musical comedy!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar and Matt Rosinski</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Charles’ website: <a href="https://charlesm93.github.io/" target="_blank">https://charlesm93.github.io/</a></li><li>Charles on Twitter: <a href="https://twitter.com/charlesm993" target="_blank">https://twitter.com/charlesm993</a></li><li>Charles on GitHub: <a href="https://github.com/charlesm93"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">What’s the difference between MCMC and Variational Inference (VI)? Why is MCMC called an approximate method? When should we use VI instead of MCMC?</p><p class="ql-align-justify">These are some of the captivating (and practical) questions we’ll tackle in this episode. I had the chance to interview Charles Margossian, a research fellow in computational mathematics at the Flatiron Institute, and a core developer of the Stan software.</p><p class="ql-align-justify">Charles was born and raised in Paris, and then moved to the US to pursue a bachelor’s degree in physics at Yale university. After graduating, he worked for two years in biotech, and went on to do a PhD in statistics at Columbia University with someone named… Andrew Gelman — you may have heard of him.</p><p class="ql-align-justify">Charles is also specialized in pharmacometrics and epidemiology, so we also talked about some practical applications of Bayesian methods and algorithms in these fascinating fields.</p><p class="ql-align-justify">Oh, and Charles’ life doesn’t only revolve around computers: he practices ballroom dancing and pickup soccer, and used to do improvised musical comedy!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar and Matt Rosinski</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Charles’ website: <a href="https://charlesm93.github.io/" target="_blank">https://charlesm93.github.io/</a></li><li>Charles on Twitter: <a href="https://twitter.com/charlesm993" target="_blank">https://twitter.com/charlesm993</a></li><li>Charles on GitHub: <a href="https://github.com/charlesm93" target="_blank">https://github.com/charlesm93</a></li><li>Charles on Google Scholar: <a href="https://scholar.google.com/citations?user=nPtLsvIAAAAJ&amp;hl=en" target="_blank">https://scholar.google.com/citations?user=nPtLsvIAAAAJ&amp;hl=en</a></li><li>Stan software: <a href="https://mc-stan.org/" target="_blank">https://mc-stan.org/</a></li><li>Torsten – Applications of Stan in Pharmacometrics: <a href="https://github.com/metrumresearchgroup/Torsten" target="_blank">https://github.com/metrumresearchgroup/Torsten</a></li><li>R̂ – Assessing the convergence of Markov chain Monte Carlo when running many short chains: <a href="https://arxiv.org/abs/2110.13017" target="_blank">https://arxiv.org/abs/2110.13017</a></li><li>Revisiting the Gelman-Rubin Diagnostic: <a href="https://arxiv.org/abs/1812.09384" target="_blank">https://arxiv.org/abs/1812.09384</a></li><li>An importance sampling approach for reliable and efficient inference in Bayesian ordinary differential equation models: <a href="https://arxiv.org/abs/2205.09059" target="_blank">https://arxiv.org/abs/2205.09059</a></li><li>Pathfinder – Parallel quasi-Newton variational inference: <a href="https://arxiv.org/pdf/2108.03782.pdf" target="_blank">https://arxiv.org/pdf/2108.03782.pdf</a></li><li>Bayesian workflow for disease transmission modeling in Stan: <a href="https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html" target="_blank">https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html</a></li><li>LBS #76 – The Past, Present &amp; Future of Stan, with Bob Carpenter: <a href="https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/" target="_blank">https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/</a></li><li>LBS #51 – Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li>Flatiron Institute: <a href="https://www.simonsfoundation.org/flatiron/" target="_blank">https://www.simonsfoundation.org/flatiron/</a></li><li>Simons Foundation: <a href="https://www.simonsfoundation.org/" target="_blank">https://www.simonsfoundation.org/</a></li></ul><br/><br><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 90 we cover both methodological advances and their application, namely variational inference and MCMC sampling and their application in pharmacometrics.&nbsp;</p><p>And we have just the right guest for this topic - Charles Margossian! You might know Charles from his work on STAN, his workshop teaching or his work at his current position at the Flatiron Institute.</p><p>His main focus now is on two topics: variational inference and MCMC sampling. When is variational inference (or approximate Bayesian methods) appropriate? And when does it fail? Charles answers these questions convincingly, clearing up some discussion around this topic.</p><p>In his work on MCMC, he tries to answer some fundamental questions: How much computational power should we invest? When is MCMC sampling more appropriate than approximate Bayesian methods? The short answer: when you care about quantifying uncertainty. We even talk about what the R-hat measure means and how to improve on it with nested R-hats.</p><p>After covering these two topics, we move to his practical work: pharmacometrics. For example, he worked on modelling the speed of drugs dissolving in the body or the role of genetics in the workings of drugs.&nbsp;</p><p>Charles also contributes to making Bayesian methods more accessible for pharmacologists: He co-developed the Torsten library for Stan that facilitates Bayesian analysis with pharmacometric data.&nbsp;</p><p>We discuss the nature of pharmacometric data and how it is usually modelled with Ordinary Differential Equations.&nbsp;</p><p>In the end we briefly cover one practical example of pharmacometric modelling: the Covid-19 pandemic.</p><p>All in all, episode 90 is another detailed one, covering many state-of-the-art techniques and their application.</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/90-demystifying-mcmc-variational-inference-charles-margossian]]></link><guid isPermaLink="false">ee1830ae-86ef-4a1f-a142-2dedada9d8da</guid><itunes:image href="https://artwork.captivate.fm/aa6ea5eb-71ec-4f78-988e-abfa22ca7e2f/k9dBveVLhkjubC6gqXTHzYlI.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 06 Sep 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/cc774932-c3ca-480c-a08a-4011151c8976/Copia-de-Learning-Bayesian-Statistics-90-converted.mp3" length="93482603" type="audio/mpeg"/><itunes:duration>01:37:36</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>90</itunes:episode><itunes:season>1</itunes:season><podcast:episode>90</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/2f6456f4-3bdc-45ac-bd14-de82dd2b8dc8/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/2f6456f4-3bdc-45ac-bd14-de82dd2b8dc8/index.html" type="text/html"/></item><item><title>#89 Unlocking the Science of Exercise, Nutrition &amp; Weight Management, with Eric Trexler</title><itunes:title>Unlocking the Science of Exercise, Nutrition &amp; Weight Management, with Eric Trexler</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">If you’ve ever tried to lose fat or gain muscle, you may have noticed… it’s not easy. But it’s precisely its complexity that makes the science of exercise and nutrition fascinating.</p><p class="ql-align-justify">This is the longest LBS episode so far, and you’ll understand why pretty quickly: we covered a very wide range of topics, starting with the concept of metabolic adaptation and how our physiology and brain react to caloric deficits or caloric surpluses.</p><p class="ql-align-justify">We also talked about the connection between metabolic adaptation and exercise energy compensation, shedding light on the interactions between the two, and how they make weight management more complex.</p><p class="ql-align-justify">Statistics are of utmost importance in these endeavors, so of course we touched on how Bayesian stats can help mitigate the challenges of low sample sizes and over-focus on average treatment effect.</p><p class="ql-align-justify">My guest for this marathon episode, is no other than Eric Trexler. Currently at the Department of Evolutionary Anthropology of Duke University, Eric conducts research on metabolism and cardiometabolic health. He has a PhD in Human Movement Science from UNC Chapel Hill, and has published dozens of peer-reviewed research papers related to exercise, nutrition, and metabolism.</p><p class="ql-align-justify">In addition, Eric is a former professional bodybuilder and has been coaching clients with goals related to health, fitness, and athletics since 2009.</p><p class="ql-align-justify">In other words, get comfy for a broad and nerdy conversation about the mysteries related to energy expenditure regulation, weight management, and evolutionary mechanisms underpinning current health challenges.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">If you’ve ever tried to lose fat or gain muscle, you may have noticed… it’s not easy. But it’s precisely its complexity that makes the science of exercise and nutrition fascinating.</p><p class="ql-align-justify">This is the longest LBS episode so far, and you’ll understand why pretty quickly: we covered a very wide range of topics, starting with the concept of metabolic adaptation and how our physiology and brain react to caloric deficits or caloric surpluses.</p><p class="ql-align-justify">We also talked about the connection between metabolic adaptation and exercise energy compensation, shedding light on the interactions between the two, and how they make weight management more complex.</p><p class="ql-align-justify">Statistics are of utmost importance in these endeavors, so of course we touched on how Bayesian stats can help mitigate the challenges of low sample sizes and over-focus on average treatment effect.</p><p class="ql-align-justify">My guest for this marathon episode, is no other than Eric Trexler. Currently at the Department of Evolutionary Anthropology of Duke University, Eric conducts research on metabolism and cardiometabolic health. He has a PhD in Human Movement Science from UNC Chapel Hill, and has published dozens of peer-reviewed research papers related to exercise, nutrition, and metabolism.</p><p class="ql-align-justify">In addition, Eric is a former professional bodybuilder and has been coaching clients with goals related to health, fitness, and athletics since 2009.</p><p class="ql-align-justify">In other words, get comfy for a broad and nerdy conversation about the mysteries related to energy expenditure regulation, weight management, and evolutionary mechanisms underpinning current health challenges.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar and Matt Rosinski</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Eric’s webpage:<a href="https://linktr.ee/trexlerfitness" target="_blank"> </a><a href="http://www.trexlerfitness.com" target="_blank">www.trexlerfitness.com</a></li><li>Monthly Applications in Strength Sport (MASS) research review:<a href="https://massresearchreview.com/" target="_blank"> https://massresearchreview.com/</a></li><li>Eric on Twitter:<a href="https://twitter.com/EricTrexler" target="_blank"> https://twitter.com/EricTrexler</a></li><li>Eric on Instagram:<a href="https://www.instagram.com/trexlerfitness/" target="_blank"> https://www.instagram.com/trexlerfitness/</a></li><li>Eric on YouTube:<a href="https://www.youtube.com/@erictrexler" target="_blank"> https://www.youtube.com/@erictrexler</a></li><li>Eric on Linkedin:<a href="https://www.linkedin.com/in/eric-trexler-19b8a9154/" target="_blank"> https://www.linkedin.com/in/eric-trexler-19b8a9154/</a></li><li>Eric’s research:<a href="https://www.researchgate.net/profile/Eric-Trexler" target="_blank"> https://www.researchgate.net/profile/Eric-Trexler</a></li><li>The Metabolic Adaptation Manual – Problems, Solutions, and Life After Weight Loss:<a href="https://www.strongerbyscience.com/metabolic-adaptation/" target="_blank"> https://www.strongerbyscience.com/metabolic-adaptation/</a></li><li>MASS on Instagram:<a href="https://www.instagram.com/massresearchreview/" target="_blank"> https://www.instagram.com/massresearchreview/</a></li><li>Burn – New Research Blows the Lid Off How We Really Burn Calories, Lose Weight, and Stay Healthy:<a href="https://www.amazon.com/Burn-Research-Really-Calories-Healthy/dp/0525541527" target="_blank"> https://www.amazon.com/Burn-Research-Really-Calories-Healthy/dp/0525541527</a></li><li>Causal quartets – Different ways to attain the same average treatment effect:<a href="http://www.stat.columbia.edu/~gelman/research/unpublished/causal_quartets.pdf" target="_blank"> http://www.stat.columbia.edu/~gelman/research/unpublished/causal_quartets.pdf</a></li><li>How to Change – The Science of Getting from Where You Are to Where You Want to Be: <a href="https://www.amazon.com/How-Change-Science-Getting-Where/dp/059308375X/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" target="_blank">https://www.amazon.com/How-Change-Science-Getting-Where/dp/059308375X/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=</a></li><li>The Sweet Spot – The Pleasures of Suffering and the Search for Meaning: <a href="https://www.amazon.com/Sweet-Spot-Pleasures-Suffering-Meaning/dp/0062910566" target="_blank">https://www.amazon.com/Sweet-Spot-Pleasures-Suffering-Meaning/dp/0062910566</a></li><li>The Stoic Challenge – A Philosopher's Guide to Becoming Tougher, Calmer, and More Resilient: <a href="https://www.amazon.com/Stoic-Challenge-Philosophers-Becoming-Resilient/dp/0393652491" target="_blank">https://www.amazon.com/Stoic-Challenge-Philosophers-Becoming-Resilient/dp/0393652491</a></li><li>LBS #61 Why we still use non-Bayesian methods, with EJ Wagenmakers: <a href="https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/" target="_blank">https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/</a></li><li>LBS #35 The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/" target="_blank">https://learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 89, we cover a so-far underrepresented topic on this podcast: Nutrition science, sports science, their relation and of course, the role of Bayesian statistics in that field.&nbsp;</p><p>Eric Trexler is the one introducing us to this topic. With his PhD in Human Movement Science from UNC Chapel Hill, previous career as professional bodybuilder and extensive experience as a health and fitness coach, he is perfectly suited for the job.</p><p>We cover a lot of ground in this episode, focusing on the science of weight-loss and the challenges to losing weight after a certain point due to an adapted energy expenditure.&nbsp;</p><p>We look at energy expenditure and changes in metabolism from several angles, including the evolutionary background for these adaptations and how they affect us in modern times.</p><p>We also discuss how individually people react to calorie restriction or surplus, different approaches to motivate oneself to loose weight and the overall complexity of this topic.</p><p>In the later half of the episode, we focus more on the scientific practices in sports science and how they can be improved.</p><p>One way forward is, of course, to use more Bayesian statistics, especially because of the oftentimes small sample sizes in Eric’s field.</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/89-unlocking-science-exercise-nutrition-weight-management-eric-trexler]]></link><guid isPermaLink="false">5ed2b4af-1a8f-4da3-b5a8-b620368d6744</guid><itunes:image href="https://artwork.captivate.fm/28831217-d3e8-4939-9926-1f1e8a61670a/Ek-KicdstDO6WU__Y_ZEMwfm.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 23 Aug 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/0ab29719-2b08-4505-9277-f5defc57309c/Learning-Bayesian-Statistics-89-converted.mp3" length="114785048" type="audio/mpeg"/><itunes:duration>01:59:50</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>89</itunes:episode><itunes:season>1</itunes:season><podcast:episode>89</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/128f314e-f6ce-480b-8815-7f11b7d63bbb/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/128f314e-f6ce-480b-8815-7f11b7d63bbb/index.html" type="text/html"/></item><item><title>#88 Bridging Computation &amp; Inference in Artificial Intelligent Systems, with Philipp Hennig</title><itunes:title>Bridging Computation &amp; Inference in Artificial Intelligent Systems, with Philipp Hennig</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com/" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Today, we’re gonna learn about probabilistic numerics — what they are, what they are good for, and how they relate computation and inference in artificial intelligent systems.</p><p class="ql-align-justify">To do this, I have the honor of hosting Philipp Hennig, a distinguished expert in this field, and the Chair for the Methods of Machine Learning at the University of Tübingen, Germany. Philipp studied in Heidelberg, also in Germany, and at Imperial College, London. Philipp received his PhD from the University of Cambridge, UK, under the supervision of David MacKay, before moving to Tübingen in 2011.&nbsp;</p><p class="ql-align-justify">Since his PhD, he has been interested in the connection between computation and inference. With international colleagues, he helped establish the idea of probabilistic numerics, which describes computation as Bayesian inference. His book, Probabilistic Numerics — Computation as Machine Learning, co-authored with Mike Osborne and Hans Kersting, was published by Cambridge University Press in 2022 and is also openly available online.&nbsp;</p><p class="ql-align-justify">So get comfy to explore the principles that underpin these algorithms, how they differ from traditional numerical methods, and how to incorporate uncertainty into the decision-making process of these algorithms.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar and Matt Rosinski</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Philipp on Twitter:...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com/" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Today, we’re gonna learn about probabilistic numerics — what they are, what they are good for, and how they relate computation and inference in artificial intelligent systems.</p><p class="ql-align-justify">To do this, I have the honor of hosting Philipp Hennig, a distinguished expert in this field, and the Chair for the Methods of Machine Learning at the University of Tübingen, Germany. Philipp studied in Heidelberg, also in Germany, and at Imperial College, London. Philipp received his PhD from the University of Cambridge, UK, under the supervision of David MacKay, before moving to Tübingen in 2011.&nbsp;</p><p class="ql-align-justify">Since his PhD, he has been interested in the connection between computation and inference. With international colleagues, he helped establish the idea of probabilistic numerics, which describes computation as Bayesian inference. His book, Probabilistic Numerics — Computation as Machine Learning, co-authored with Mike Osborne and Hans Kersting, was published by Cambridge University Press in 2022 and is also openly available online.&nbsp;</p><p class="ql-align-justify">So get comfy to explore the principles that underpin these algorithms, how they differ from traditional numerical methods, and how to incorporate uncertainty into the decision-making process of these algorithms.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Chad Scherrer, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony, Joshua Meehl, Javier Sabio, Kristian Higgins, Alex Jones, Gregorio Aguilar and Matt Rosinski</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Philipp on Twitter: <a href="https://twitter.com/PhilippHennig5" target="_blank">https://twitter.com/PhilippHennig5</a></li><li class="ql-align-justify">Philipp on Github: <a href="https://github.com/philipphennig" target="_blank">https://github.com/philipphennig</a></li><li class="ql-align-justify">Philipp on LinkedIn: <a href="https://www.linkedin.com/in/philipp-hennig-635832278/" target="_blank">https://www.linkedin.com/in/philipp-hennig-635832278/</a></li><li>An introductory course on Probabilistic Numerics, taught collaboratively by Philipp’s Group: <a href="https://youtube.com/playlist?list=PL05umP7R6ij2lwDdj7IkuHoP9vHlEcH0s" target="_blank">https://youtube.com/playlist?list=PL05umP7R6ij2lwDdj7IkuHoP9vHlEcH0s</a>&nbsp;</li><li>An introductory tutorial on Probabilistic Numerics: <a href="https://youtu.be/0Q1ZTLHULcw" target="_blank">https://youtu.be/0Q1ZTLHULcw</a>&nbsp;</li><li>Philipp’s book: <a href="https://www.probabilistic-numerics.org/textbooks/" target="_blank">https://www.probabilistic-numerics.org/textbooks/</a></li><li class="ql-align-justify">ProbNum python package: <a href="https://probnum.readthedocs.io/en/latest/" target="_blank">https://probnum.readthedocs.io/en/latest/</a></li><li class="ql-align-justify">Probabilistic solvers for differential equations in JAX: <a href="https://pnkraemer.github.io/probdiffeq/" target="_blank">https://pnkraemer.github.io/probdiffeq/</a></li><li class="ql-align-justify">Probabilistic Numerical Differential Equation Solvers in Julia: <a href="https://nathanaelbosch.github.io/ProbNumDiffEq.jl/stable/#Probabilistic-Numerical-Differential-Equation-Solvers" target="_blank">https://nathanaelbosch.github.io/ProbNumDiffEq.jl/stable/#Probabilistic-Numerical-Differential-Equation-Solvers</a></li><li>Philipp’s research: <a href="https://www.probabilistic-numerics.org/" target="_blank">https://www.probabilistic-numerics.org/</a></li><li>Philipp’s academic page: <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/methods-of-machine-learning/start/" target="_blank">https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/methods-of-machine-learning/start/</a>&nbsp;</li><li>Tübingen Machine Learning on YouTube: <a href="https://www.youtube.com/c/T%C3%BCbingenML" target="_blank">https://www.youtube.com/c/TübingenML</a>&nbsp;</li><li class="ql-align-justify">LBS #74 Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt: <a href="https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/" target="_blank">https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/</a></li><li class="ql-align-justify">LBS #12 Biostatistics and Differential Equations, with Demetri Pananos: <a href="https://learnbayesstats.com/episode/12-biostatistics-and-differential-equations-with-demetri-pananos/" target="_blank">https://learnbayesstats.com/episode/12-biostatistics-and-differential-equations-with-demetri-pananos/</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 88 with Philipp Henning, chair of Methods in Machine Learning at the Eberhard Karls University Tübingen, we learn about new, technical areas for the Bayesian way of thinking: Probabilistic numerics.</p><p>Philipp gives us a conceptual introduction to Machine Learning as “refining a model through data” and explains what challenges Machine Learning phases due to the intractable nature of data and the used computations.&nbsp;</p><p>The Bayesian approach, emphasising uncertainty over estimates and parameters, naturally lends itself for handling these issues.&nbsp;</p><p>In his research group, Philipp tries to find more general implementations of classically used algorithms, while maintaining computational efficiency. They successfully achieve this goal by bringing in the Bayesian approach to inferences.&nbsp;</p><p>Philipp explains probabilistic numerics as “redescrbiing everything a computer does as Bayesian inference” and how this approach is suitable for advancing Machine Learning.</p><p>We expand on how to handle uncertainty in machine learning and Philipp details his teams approach for handling this issue.</p><p class="ql-align-justify">We also collect many resources for those interested in probabilistic numerics and finally talk about the future of this field.</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>This is an automatic transcript and may therefore contain errors. Please </em><a href="http://twitter.com/LearnBayesStats" target="_blank"><em>get in touch</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/88-bridging-computation-inference-in-artificial-intelligent-systems-philipp-hennig]]></link><guid isPermaLink="false">e2777207-cf24-4a97-9bdf-d7fee0716b23</guid><itunes:image href="https://artwork.captivate.fm/e733d096-8faf-4b88-b977-11cd862e77e4/IsS1SiemdSqOqTZXGU1r6bk6.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 10 Aug 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/3846ee16-2b44-4e1b-9544-046c10968cf6/Learning-Bayesian-Statistics-88-converted.mp3" length="68805377" type="audio/mpeg"/><itunes:duration>01:11:50</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>88</itunes:episode><itunes:season>1</itunes:season><podcast:episode>88</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/bf7ae256-4f0c-4036-a599-77292f29625e/index.html" type="text/html"/></item><item><title>#87 Unlocking the Power of Bayesian Causal Inference, with Ben Vincent</title><itunes:title>Unlocking the Power of Bayesian Causal Inference, with Ben Vincent</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com/" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">I’ll be honest — this episode is long overdue. Not only because Ben Vincent is a friend, fellow PyMC Labs developer, and outstanding Bayesian modeler. But because he works on so many fascinating topics — so I’m all the happier to finally have him on the show!</p><p class="ql-align-justify">In this episode, we’re gonna focus on causal inference, how it naturally extends Bayesian modeling, and how you can use the CausalPy open-source package to supercharge your Bayesian causal inference. We’ll also touch on marketing models and the pymc-marketing package, because, well, Ben does a lot of stuff ;)</p><p class="ql-align-justify">Ben got his PhD in neuroscience at Sussex University, in the UK. After a postdoc at the University of Bristol, working on robots and active vision, as well as 15 years as a lecturer at the Scottish University of Dundee, he switched to the private sector, working with us full time at PyMC Labs — and that is a treat!</p><p class="ql-align-justify">When he’s not working, Ben loves running 5k’s, cycling in the forest, lifting weights, and… learning about modern monetary theory.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Ben’s website: <a href="https://drbenvincent.github.io/" target="_blank">https://drbenvincent.github.io/</a></li><li>Ben on GitHub: <a href="https://github.com/drbenvincent" target="_blank">https://github.com/drbenvincent</a></li><li>Ben on Twitter: <a href="https://twitter.com/inferencelab"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com/" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">I’ll be honest — this episode is long overdue. Not only because Ben Vincent is a friend, fellow PyMC Labs developer, and outstanding Bayesian modeler. But because he works on so many fascinating topics — so I’m all the happier to finally have him on the show!</p><p class="ql-align-justify">In this episode, we’re gonna focus on causal inference, how it naturally extends Bayesian modeling, and how you can use the CausalPy open-source package to supercharge your Bayesian causal inference. We’ll also touch on marketing models and the pymc-marketing package, because, well, Ben does a lot of stuff ;)</p><p class="ql-align-justify">Ben got his PhD in neuroscience at Sussex University, in the UK. After a postdoc at the University of Bristol, working on robots and active vision, as well as 15 years as a lecturer at the Scottish University of Dundee, he switched to the private sector, working with us full time at PyMC Labs — and that is a treat!</p><p class="ql-align-justify">When he’s not working, Ben loves running 5k’s, cycling in the forest, lifting weights, and… learning about modern monetary theory.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Ben’s website: <a href="https://drbenvincent.github.io/" target="_blank">https://drbenvincent.github.io/</a></li><li>Ben on GitHub: <a href="https://github.com/drbenvincent" target="_blank">https://github.com/drbenvincent</a></li><li>Ben on Twitter: <a href="https://twitter.com/inferencelab" target="_blank">https://twitter.com/inferencelab</a></li><li>Ben on LinkedIn: <a href="https://www.linkedin.com/in/dr-benjamin-vincent-503571127/" target="_blank">https://www.linkedin.com/in/dr-benjamin-vincent-503571127/</a></li><li>CausalPy – Causal inference for quasi-experiments: <a href="https://causalpy.readthedocs.io/en/latest/" target="_blank">https://causalpy.readthedocs.io/en/latest/</a></li><li>PyMC Marketing – Bayesian marketing toolbox in PyMC: <a href="https://www.pymc-marketing.io/en/stable/index.html" target="_blank">https://www.pymc-marketing.io/en/stable/index.html</a></li><li>PyMC Labs&nbsp;: <a href="https://www.pymc-labs.io/products/" target="_blank">https://www.pymc-labs.io/products/</a></li><li>LBS #23 – Bayesian Stats in Business and Marketing Analytics, with Elea McDonnel Feit: <a href="https://learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit/" target="_blank">https://learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit/</a></li><li class="ql-align-justify">LBS #63 – Media Mix Models &amp; Bayes for Marketing, with Luciano Paz: <a href="https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/" target="_blank">https://learnbayesstats.com/episode/63-media-mix-models-bayes-marketing-luciano-paz/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>written by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this podcast episode, our guest, Ben Vincent, a fellow member of PyMC Labs with a PhD in Neuroscience and extensive experience in teaching and data analysis of course, introduces us to CausalPy and PyMC Marketing.</p><p>During his academic career, Ben got introduced to Bayesian statistics but, like most academics, did not come across causal inference.&nbsp;</p><p>We discuss the importance of a systematic causal approach for important questions like health care interventions or marketing investments.&nbsp;</p><p>Although causality is somewhat orthogonal to the choice of statistical approach, Bayesian statistics is a good basis for causal analyses, for example in the for of Directed Acyclical Graphs.&nbsp;</p><p>To make causal inference more accessible, Ben developed a Python package called CausalPy, which allows you perform common causal inferences, e.g. working with natural experiments.</p><p>Ben was also involved in the development of PyMC Marketing, a package that conveniently bundles important analysis capacities for Marketing. The package focuses on Media Mix Modelling and customer lifetime analysis.&nbsp;</p><p>We also talked about his extensive experience teaching statistics at university and current teaching of Bayesian methods in industry. His advice to students is to really engage with your learning material, coding through examples, making the learning more pleasurable and practical.&nbsp;</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>Please note that this is an automated transcript that may contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/87-unlocking-the-power-of-bayesian-causal-inference-ben-vincent]]></link><guid isPermaLink="false">9581361b-0d52-4020-ac36-3c6f64e59f3d</guid><itunes:image href="https://artwork.captivate.fm/f2de7704-4838-48b8-adcb-ac922c02264e/-ON-FlFnfRXhkj0xMJYdGwG0.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sun, 30 Jul 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/0c6be4a6-ac60-4d1e-a6a1-4f4952eb5943/Learning-Bayesian-Statistics-87-1-converted.mp3" length="65743763" type="audio/mpeg"/><itunes:duration>01:08:38</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>87</itunes:episode><itunes:season>1</itunes:season><podcast:episode>87</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/665362fc-472c-47b0-a6a8-2c6a30bf971e/transcript.srt" type="application/srt" rel="captions"/><podcast:transcript url="https://transcripts.captivate.fm/transcript/665362fc-472c-47b0-a6a8-2c6a30bf971e/index.html" type="text/html"/></item><item><title>#86 Exploring Research Synchronous Languages &amp; Hybrid Systems, with Guillaume Baudart</title><itunes:title>Exploring Research Synchronous Languages &amp; Hybrid Systems, with Guillaume Baudart</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com" rel="noopener noreferrer" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This episode is unlike anything I’ve covered so far on the show. Let me ask you: Do you know what a research synchronous language is? What about hybrid systems? Last try: have you heard of Zelus, or ProbZelus?</p><p class="ql-align-justify">If you answered “no” to one of the above, then you’re just like me! And that’s why I invited Guillaume Baudart for this episode — to teach us about all these fascinating topics!</p><p>A researcher in the PARKAS team of Inria, Guillaume's research focuses on probabilistic and reactive programming languages. In particular, he works on ProbZelus, a probabilistic extension to Zelus, itself a research synchronous language to implement hybrid systems.</p><p>To simplify, Zelus is a modeling framework to simulate the dynamics of systems both smooth and subject to discrete dynamics — if you’ve ever worked with ODEs, you may be familiar with these terms.</p><p class="ql-align-justify">If you’re not — great, Guillaume will explain everything in the episode! And I know it might sound niche, but this kind of approach actually has very important applications — such as proving that there are no bugs in a program.</p><p class="ql-align-justify">Guillaume did his PhD at École Normale Supérieure, in Paris, working on reactive programming languages and quasi-periodic systems. He then worked in the AI programming team of IBM Research, before coming back to the École Normale Supérieure, working mostly on reactive and probabilistic programming.</p><p class="ql-align-justify">In his free time, Guillaume loves spending time with his family, playing the violin with friends, and… cooking!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p><a href="https://podurama.com" rel="noopener noreferrer" target="_blank"><em>Listen on Podurama</em></a></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This episode is unlike anything I’ve covered so far on the show. Let me ask you: Do you know what a research synchronous language is? What about hybrid systems? Last try: have you heard of Zelus, or ProbZelus?</p><p class="ql-align-justify">If you answered “no” to one of the above, then you’re just like me! And that’s why I invited Guillaume Baudart for this episode — to teach us about all these fascinating topics!</p><p>A researcher in the PARKAS team of Inria, Guillaume's research focuses on probabilistic and reactive programming languages. In particular, he works on ProbZelus, a probabilistic extension to Zelus, itself a research synchronous language to implement hybrid systems.</p><p>To simplify, Zelus is a modeling framework to simulate the dynamics of systems both smooth and subject to discrete dynamics — if you’ve ever worked with ODEs, you may be familiar with these terms.</p><p class="ql-align-justify">If you’re not — great, Guillaume will explain everything in the episode! And I know it might sound niche, but this kind of approach actually has very important applications — such as proving that there are no bugs in a program.</p><p class="ql-align-justify">Guillaume did his PhD at École Normale Supérieure, in Paris, working on reactive programming languages and quasi-periodic systems. He then worked in the AI programming team of IBM Research, before coming back to the École Normale Supérieure, working mostly on reactive and probabilistic programming.</p><p class="ql-align-justify">In his free time, Guillaume loves spending time with his family, playing the violin with friends, and… cooking!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Guillaume’s website: <a href="https://guillaume.baudart.eu/" rel="noopener noreferrer" target="_blank">https://guillaume.baudart.eu/</a></li><li>ProbZelus on GitHub: <a href="https://github.com/IBM/probzelus" rel="noopener noreferrer" target="_blank">https://github.com/IBM/probzelus</a></li><li>Zelus docs: <a href="https://zelus.di.ens.fr/" rel="noopener noreferrer" target="_blank">https://zelus.di.ens.fr/</a></li><li>Short Zelus introduction: <a href="https://www.di.ens.fr/~pouzet/bib/hscc13.pdf" rel="noopener noreferrer" target="_blank">https://www.di.ens.fr/~pouzet/bib/hscc13.pdf</a>&nbsp;</li><li>Guillaume’s course&nbsp;: <a href="https://wikimpri.dptinfo.ens-cachan.fr/doku.php?id=cours:c-2-40" rel="noopener noreferrer" target="_blank">https://wikimpri.dptinfo.ens-cachan.fr/doku.php?id=cours:c-2-40</a></li><li>LBS #74 – Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt: <a href="https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/</a></li><li>ProbZelus (design, semantics, delayed-sampling): <a href="https://dl.acm.org/doi/abs/10.1145/3385412.3386009" rel="noopener noreferrer" target="_blank">https://dl.acm.org/doi/abs/10.1145/3385412.3386009</a></li><li>Semi-symbolic inference: <a href="https://dl.acm.org/doi/abs/10.1145/3563347" rel="noopener noreferrer" target="_blank">https://dl.acm.org/doi/abs/10.1145/3563347</a></li><li class="ql-align-justify">Static analysis for bounded memory inference: <a href="https://dl.acm.org/doi/abs/10.1145/3485492" rel="noopener noreferrer" target="_blank">https://dl.acm.org/doi/abs/10.1145/3485492</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="http://christophbg.github.io/" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>Guillaume Baudart is researcher at Inria in the PARKAS team at the Département d'Informatique (DI) of the École normale supérieure. He joins us for episode 86 to tell us about ProbZelus, a synchronous probabilistic programming language, that he develops.</p><p>We have not covered synchronous languages yet, so, Guillaume gives us some context on this kind of programming approach and how ProbZelus adds probabilistic notions to it.</p><p>He explains the advantages of the probabilistic aspects of ProbZelus and what practitioners may profit from it.&nbsp;</p><p>For example, synchronous languages are used to program and test autopilots of planes and ensure that they do not have any bugs. ProbZelus may be useful here as Guillaume argues.</p><p class="ql-align-justify">Finally, we also touch upon his teaching work and what difficulties he encounters in teaching probabilistic programming.&nbsp;</p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>Please note that this is an automated transcript that may contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/86-exploring-research-synchronous-languages-hybrid-systems-guillaume-baudart]]></link><guid isPermaLink="false">0b949eee-5063-4b44-a974-dd08ca108f88</guid><itunes:image href="https://artwork.captivate.fm/47f745a4-39c5-4b42-ac07-8dd67dba4292/9vyFLbthGkL0nWsdugjU4zNX.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 14 Jul 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/7c87d40f-966f-4c57-9a8f-b861210fc879/Learning-Bayesian-Statistics-86-converted.mp3" length="56241167" type="audio/mpeg"/><itunes:duration>58:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>86</itunes:episode><itunes:season>1</itunes:season><podcast:episode>86</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/3074b9b7-6f4d-4d07-9af8-15f1633d7e99/index.html" type="text/html"/></item><item><title>#85 A Brief History of Sports Analytics, with Jim Albert</title><itunes:title>#85 A Brief History of Sports Analytics, with Jim Albert</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, I am honored to talk with a legend of sports analytics in general, and baseball analytics in particular. I am of course talking about Jim Albert.</p><p class="ql-align-justify">Jim grew up in the Philadelphia area and studied statistics at Purdue University. He then spent his entire 41-year academic career at Bowling Green State University, which gave him a wide diversity of classes to teach – from intro statistics through doctoral level.</p><p class="ql-align-justify">As you’ll hear, he’s always had a passion for Bayesian education, Bayesian modeling and learning about statistics through sports. I find that passion fascinating about Jim, and I suspect that’s one of the main reasons for his prolific career — really, the list of his writings and teachings is impressive; just go take a look at the show notes.</p><p class="ql-align-justify">Now an Emeritus Professor of Bowling Green, Jim is retired, but still an active tennis player and writer on sports analytics — his blog, “Exploring Baseball with R”, is nearing 400 posts!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Jim’s website: <a href="https://bayesball.github.io/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/</a></li><li>Jim’s baseball blog: <a href="https://baseballwithr.wordpress.com/" rel="noopener noreferrer" target="_blank">https://baseballwithr.wordpress.com/</a></li><li>Jim on...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">In this episode, I am honored to talk with a legend of sports analytics in general, and baseball analytics in particular. I am of course talking about Jim Albert.</p><p class="ql-align-justify">Jim grew up in the Philadelphia area and studied statistics at Purdue University. He then spent his entire 41-year academic career at Bowling Green State University, which gave him a wide diversity of classes to teach – from intro statistics through doctoral level.</p><p class="ql-align-justify">As you’ll hear, he’s always had a passion for Bayesian education, Bayesian modeling and learning about statistics through sports. I find that passion fascinating about Jim, and I suspect that’s one of the main reasons for his prolific career — really, the list of his writings and teachings is impressive; just go take a look at the show notes.</p><p class="ql-align-justify">Now an Emeritus Professor of Bowling Green, Jim is retired, but still an active tennis player and writer on sports analytics — his blog, “Exploring Baseball with R”, is nearing 400 posts!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Jim’s website: <a href="https://bayesball.github.io/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/</a></li><li>Jim’s baseball blog: <a href="https://baseballwithr.wordpress.com/" rel="noopener noreferrer" target="_blank">https://baseballwithr.wordpress.com/</a></li><li>Jim on GitHub: <a href="https://github.com/bayesball" rel="noopener noreferrer" target="_blank">https://github.com/bayesball</a></li><li>Jim on Twitter: <a href="https://twitter.com/albertbayes" rel="noopener noreferrer" target="_blank">https://twitter.com/albertbayes</a></li><li>Jim on Linkedin: <a href="https://www.linkedin.com/in/jim-albert-22846b41/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/jim-albert-22846b41/</a></li><li>Jim’s baseball research: <a href="https://bayesball.github.io/BLOG/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/BLOG/</a></li><li><em>Probability and Bayesian Modeling</em> book: <a href="https://monika76five.github.io/ProbBayes/" rel="noopener noreferrer" target="_blank">https://monika76five.github.io/ProbBayes/</a></li><li><em>Curve Ball -- Baseball, Statistics, and the Role of Chance in the Game</em>: <a href="https://bayesball.github.io/curveball/curveball.htm" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/curveball/curveball.htm</a></li><li><em>Visualizing Baseball</em>: <a href="https://bayesball.github.io/VB/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/VB/</a></li><li><em>Analyzing Baseball Data with R</em>: <a href="https://www.amazon.com/gp/product/0815353510?pf_rd_p=c2945051-950f-485c-b4df-15aac5223b10&amp;pf_rd_r=SFAV7QEGY9A2EDADZTJ5" rel="noopener noreferrer" target="_blank">https://www.amazon.com/gp/product/0815353510?pf_rd_p=c2945051-950f-485c-b4df-15aac5223b10&amp;pf_rd_r=SFAV7QEGY9A2EDADZTJ5</a></li><li class="ql-align-justify"><em>Teaching Statistics Using Baseball</em>: <a href="https://bayesball.github.io/TSUB2/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/TSUB2/</a></li><li class="ql-align-justify"><em>Ordinal Data Modeling</em>: <a href="https://link.springer.com/book/10.1007/b98832?changeHeader" rel="noopener noreferrer" target="_blank">https://link.springer.com/book/10.1007/b98832?changeHeader</a></li><li class="ql-align-justify"><em>Workshop Statistics</em> (an intro stats course taught from a Bayesian point of view):&nbsp;<a href="https://bayesball.github.io/nsf_web/main.htm" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/nsf_web/main.htm</a></li><li class="ql-align-justify">LBS #76, The Past, Present &amp; Future of Stan, with Bob Carpenter: <a href="https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/76-past-present-future-of-stan-bob-carpenter/</a></li><li>MCMC Interactive Gallery: <a href="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=HamiltonianMC&amp;target=banana" rel="noopener noreferrer" target="_blank">https://chi-feng.github.io/mcmc-demo/app.html?algorithm=HamiltonianMC&amp;target=banana</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>written by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this episode, Jim Albert, a legend of sports analytics, Emeritus Professor at Bowling Green university, is our guest.</p><p>We talk about a range of topics, including his early interest in math and sports, challenges in analysing sports data and his experience teaching statistics.</p><p>We trace back the history of baseball sport analytics to the 1960s and discuss how new, advanced ways to collect data change the possibilities of what can be modelled.</p><p>There are also statistical approaches to American football, soccer and basketball games. Jim explains why these team sports are more difficult to model than baseball.&nbsp;</p><p>The conversation then turns to Jim’s substantial experience teaching statistics ad the challenges he sees in that. Jim worked on several books on sports analytics and has many blog posts on this topic.</p><p>We also touch upon the challenges of prior elicitation, a topic that has come up frequently in recent podcasts, how different stakeholders such as coaches and managers think differently about the sport and how to extract priors from their information.</p><p>For more tune in to episode 85 with Jim Albert.</p><p><strong>Chapters</strong></p><p>[00:00:00] Episode Begins</p><p>[00:04:04] How did you get into the world of statistics?</p><p>[00:11:17] Baseball is more advanced on the analytics path compared to other sports</p><p>[00:17:02] How is the data collected?</p><p>[00:24:43] Why is sports analytics important and is it turning humans into robots?</p><p>[00:32:51] Loss in translation problem between modellers and domain experts...?</p><p>[00:41:43] Active learning and learning through workshops</p><p>[00:51:08] Principles before methods</p><p>[00:52:30] Your favorite sports analytics model</p><p>[01:02:07]  If you had unlimited time and resources which problem would you try to solve?</p><p><strong>Transcript</strong></p><p><em>Please note that this transcript is generated automatically and may contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>reach out</em></a><em> if you are willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/85-brief-history-sports-analytics-jim-albert]]></link><guid isPermaLink="false">e6c15dba-0536-4190-9cfd-9c2334f8d050</guid><itunes:image href="https://artwork.captivate.fm/2ff41fd9-4600-42f8-940c-8288e7faa44d/R1PXkkg4rixUXChLzvEriyc2.png"/><dc:creator><![CDATA[Alexandre Andorra]]></dc:creator><pubDate>Tue, 27 Jun 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/db62d8d2-fe48-4142-9f69-9f3fe0aaf1de/Learning-Bayesian-Statistics-85-converted.mp3" length="63389381" type="audio/mpeg"/><itunes:duration>01:06:11</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>85</itunes:episode><itunes:season>1</itunes:season><podcast:episode>85</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre Andorra</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/53b74b7f-e9d7-4833-b64e-d30b3b087d8b/index.html" type="text/html"/><podcast:chapters url="https://transcripts.captivate.fm/chapter-db62d8d2-fe48-4142-9f69-9f3fe0aaf1de.json" type="application/json+chapters"/></item><item><title>#84 Causality in Neuroscience &amp; Psychology, with Konrad Kording</title><itunes:title>Causality in Neuroscience &amp; Psychology, with Konrad Kording</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This is another installment in our neuroscience modeling series! This time, I talked with Konrad Kording, about the role of Bayesian stats in neuroscience and psychology, electrophysiological data to study what neurons do, and how this helps explain human behavior.</p><p class="ql-align-justify">Konrad studied at ETH Zurich, then went to UC London and MIT for his postdocs. After a decade at Northwestern University, he is now Penn Integrated Knowledge Professor at the University of Pennsylvania.</p><p class="ql-align-justify">As you’ll hear, Konrad is particularly interested in the question of how the brain solves the credit assignment problem and similarly how we should assign credit in the real world (through causality). Building on this, he is also interested in applications of causality in biomedical research.</p><p class="ql-align-justify">And… he’s also a big hiker, skier and salsa dancer!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Konrad’s lab: <a href="https://kordinglab.com/" target="_blank">https://kordinglab.com/</a></li><li>Konrad’s lab on GitHub: <a href="https://github.com/KordingLab" target="_blank">https://github.com/KordingLab</a></li><li>Konrad’s lab on Twitter: <a href="https://twitter.com/KordingLab" target="_blank">https://twitter.com/KordingLab</a></li><li>LBS #81, Neuroscience of Perception: Exploring the Brain, with Alan Stocker: <a href="https://learnbayesstats.com/episode/81-neuroscience-of-perception-exploring-the-brain-alan-stocker/"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">This is another installment in our neuroscience modeling series! This time, I talked with Konrad Kording, about the role of Bayesian stats in neuroscience and psychology, electrophysiological data to study what neurons do, and how this helps explain human behavior.</p><p class="ql-align-justify">Konrad studied at ETH Zurich, then went to UC London and MIT for his postdocs. After a decade at Northwestern University, he is now Penn Integrated Knowledge Professor at the University of Pennsylvania.</p><p class="ql-align-justify">As you’ll hear, Konrad is particularly interested in the question of how the brain solves the credit assignment problem and similarly how we should assign credit in the real world (through causality). Building on this, he is also interested in applications of causality in biomedical research.</p><p class="ql-align-justify">And… he’s also a big hiker, skier and salsa dancer!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh, Grant Pezzolesi, Avram Aelony and Joshua Meehl</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Konrad’s lab: <a href="https://kordinglab.com/" target="_blank">https://kordinglab.com/</a></li><li>Konrad’s lab on GitHub: <a href="https://github.com/KordingLab" target="_blank">https://github.com/KordingLab</a></li><li>Konrad’s lab on Twitter: <a href="https://twitter.com/KordingLab" target="_blank">https://twitter.com/KordingLab</a></li><li>LBS #81, Neuroscience of Perception: Exploring the Brain, with Alan Stocker: <a href="https://learnbayesstats.com/episode/81-neuroscience-of-perception-exploring-the-brain-alan-stocker/" target="_blank">https://learnbayesstats.com/episode/81-neuroscience-of-perception-exploring-the-brain-alan-stocker/</a></li><li>LBS #77, How a Simple Dress Helped Uncover Hidden Prejudices, with Pascal Wallisch: <a href="https://learnbayesstats.com/episode/77-how-a-simple-dress-helped-uncover-hidden-prejudices-pascal-wallisch/" target="_blank">https://learnbayesstats.com/episode/77-how-a-simple-dress-helped-uncover-hidden-prejudices-pascal-wallisch/</a></li><li><em>The Sports Gene, Inside the Science of Extraordinary Athletic Performance</em>: <a href="https://davidepstein.com/david-epstein-the-sports-gene/" target="_blank">https://davidepstein.com/david-epstein-the-sports-gene/</a></li><li>Decoding with good ML: <a href="https://github.com/KordingLab/Neural_Decoding" target="_blank">https://github.com/KordingLab/Neural_Decoding</a> and <a href="https://www.eneuro.org/content/7/4/ENEURO.0506-19.2020" target="_blank">https://www.eneuro.org/content/7/4/ENEURO.0506-19.2020</a></li><li>Bayesian decoding: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5578432/" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5578432/</a></li><li>Textbook on Bayesian modeling of behavior: <a href="http://bayesianmodeling.com/" target="_blank">bayesianmodeling.com</a></li><li>Bayesian philosophy: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3981868/" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3981868/</a></li><li>Konrad talking about Neuromatch Bayes day: <a href="https://www.youtube.com/watch?v=neDaPap_5Tg" target="_blank">https://www.youtube.com/watch?v=neDaPap_5Tg</a></li><li>The Neuromatch Bayes tutorials: <a href="http://compneuro.neuromatch.io/" target="_blank">compneuro.neuromatch.io</a></li></ul><br/><br><p><strong>Transcript</strong></p><p><em>Please note that this is an automatic transcript and may contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em> if you would like to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/84-causality-neuroscience-psychology-konrad-kording]]></link><guid isPermaLink="false">8ea1ce1b-c5db-48a1-a228-81bd1333a6bc</guid><itunes:image href="https://artwork.captivate.fm/f6fd8732-4457-44c9-ba25-de9500732c5c/4n-SVbHjYGocy9aBeXnXR5Bn.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 13 Jun 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a3786a55-18bf-41f5-a81c-6ab5f849b616/Learning-Bayesian-Statistics-84-converted.mp3" length="62939855" type="audio/mpeg"/><itunes:duration>01:05:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>84</itunes:episode><itunes:season>1</itunes:season><podcast:episode>84</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/81182949-8be3-496d-8fe6-130cc77f0b25/index.html" type="text/html"/></item><item><title>#83 Multilevel Regression, Post-Stratification &amp; Electoral Dynamics, with Tarmo Jüristo</title><itunes:title>Multilevel Regression, Post-Stratification &amp; Electoral Dynamics, with Tarmo Jüristo</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">One of the greatest features of this podcast, and my work in general, is that I keep getting surprised. Along the way, I keep learning, and I meet fascinating people, like Tarmo Jüristo.</p><p class="ql-align-justify">Tarmo is hard to describe. These days, he’s heading an NGO called Salk, in the Baltic state called Estonia. Among other things, they are studying and forecasting elections, which is how we met and ended up collaborating with PyMC Labs, our Bayesian consultancy.</p><p class="ql-align-justify">But Tarmo is much more than that. Born in 1971 in what was still the Soviet Union, he graduated in finance from Tartu University.&nbsp;He worked in finance and investment banking until the 2009 crisis, when he quit and started a doctorate in… cultural studies.&nbsp;He then went on to write for theater and TV, teaching literature, anthropology and philosophy. An avid world traveler, he also teaches kendo and Brazilian jiu-jitsu.</p><p class="ql-align-justify">As you’ll hear in the episode, after lots of adventures, he established Salk, and they just used a Bayesian hierarchical model with post-stratification to forecast the results of the 2023 Estonian parliamentary elections and target the campaign efforts to specific demographics.</p><p class="ql-align-justify">Oh, and let thing: Tarmo is a fan of the show — I told you he was a great guy ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh and Grant Pezzolesi.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Tarmo on GitHub: <a href="https://github.com/tarmojuristo" target="_blank">https://github.com/tarmojuristo</a></li><li class="ql-align-justify">Tarmo on...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">One of the greatest features of this podcast, and my work in general, is that I keep getting surprised. Along the way, I keep learning, and I meet fascinating people, like Tarmo Jüristo.</p><p class="ql-align-justify">Tarmo is hard to describe. These days, he’s heading an NGO called Salk, in the Baltic state called Estonia. Among other things, they are studying and forecasting elections, which is how we met and ended up collaborating with PyMC Labs, our Bayesian consultancy.</p><p class="ql-align-justify">But Tarmo is much more than that. Born in 1971 in what was still the Soviet Union, he graduated in finance from Tartu University.&nbsp;He worked in finance and investment banking until the 2009 crisis, when he quit and started a doctorate in… cultural studies.&nbsp;He then went on to write for theater and TV, teaching literature, anthropology and philosophy. An avid world traveler, he also teaches kendo and Brazilian jiu-jitsu.</p><p class="ql-align-justify">As you’ll hear in the episode, after lots of adventures, he established Salk, and they just used a Bayesian hierarchical model with post-stratification to forecast the results of the 2023 Estonian parliamentary elections and target the campaign efforts to specific demographics.</p><p class="ql-align-justify">Oh, and let thing: Tarmo is a fan of the show — I told you he was a great guy ;)</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady, Kurt TeKolste, Gergely Juhasz, Marcus Nölke, Maggi Mackintosh and Grant Pezzolesi.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Tarmo on GitHub: <a href="https://github.com/tarmojuristo" target="_blank">https://github.com/tarmojuristo</a></li><li class="ql-align-justify">Tarmo on Linkedin: <a href="https://www.linkedin.com/in/tarmo-j%C3%BCristo-7018bb7/" target="_blank">https://www.linkedin.com/in/tarmo-j%C3%BCristo-7018bb7/</a></li><li class="ql-align-justify">Tarmo on Twitter: <a href="https://twitter.com/tarmojuristo" target="_blank">https://twitter.com/tarmojuristo</a></li><li class="ql-align-justify">Salk website: <a href="https://salk.ee/" target="_blank">https://salk.ee/</a></li><li class="ql-align-justify">Hierarchical Bayesian Modeling of Survey Data with Post-stratification: <a href="https://www.youtube.com/watch?v=efID35XUQ3I" target="_blank">https://www.youtube.com/watch?v=efID35XUQ3I</a></li></ul><br/><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 83 of the podcast Tarmo Jüristo is our guest. He recently received media attention for his electoral forecasting in the Estonian election and potential positive role in aiding liberal parties gain more votes than expected.&nbsp;</p><p>Tarmo explains to us how he used Bayesian models with his NGO SALK to forecast the election and how he leveraged these models to unify the different liberal parties that participated in the election. So, we get a firsthand view of how to use Bayesian modelling smartly.</p><p>Furthermore, we talk about when to use Bayesian models, difficulties in modelling survey data and how post-stratification can help.</p><p>He also explains how he, with the help of PyMC Labs, added Gaussian Processes to his models to better model the time-series structure of their survey data.&nbsp;</p><p class="ql-align-justify">We close this episode by discussing the responsibility that comes with modelling data in politics.&nbsp;</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>please note that the transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out </em></a><em>if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/83-multilevel-regression-post-stratification-electoral-dynamics-tarmo-juristo]]></link><guid isPermaLink="false">a21eb085-7458-4777-a7f0-dca86ca5522d</guid><itunes:image href="https://artwork.captivate.fm/8a71b525-37df-40c0-a084-168a5566702b/blhQidFtomE2STWIkJAtfnv4.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 25 May 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5d39c781-66a0-46a9-83db-a7f3f38204ce/Learning-Bayesian-Statistics-83-converted.mp3" length="74087933" type="audio/mpeg"/><itunes:duration>01:17:21</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>83</itunes:episode><itunes:season>1</itunes:season><podcast:episode>83</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/ea66a43d-5e8b-4d3b-b462-77b2b41def34/index.html" type="text/html"/></item><item><title>#82 Sequential Monte Carlo &amp; Bayesian Computation Algorithms, with Nicolas Chopin</title><itunes:title>Sequential Monte Carlo &amp; Bayesian Computation Algorithms, with Nicolas Chopin</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>------------------------------------------------------------------------------</p><p>Max Kochurov’s State of Bayes Lecture Series: <a href="https://www.youtube.com/playlist?list=PL1iMFW7frOOsh5KOcfvKWM12bjh8zs9BQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL1iMFW7frOOsh5KOcfvKWM12bjh8zs9BQ</a></p><p>Sign up here for upcoming lessons: <a href="https://www.meetup.com/pymc-labs-online-meetup/events/293101751/" rel="noopener noreferrer" target="_blank">https://www.meetup.com/pymc-labs-online-meetup/events/293101751/</a></p><p class="ql-align-justify">------------------------------------------------------------------------------</p><p class="ql-align-justify">We talk a lot about different MCMC methods on this podcast, because they are the workhorses of the Bayesian models. But other methods exist to infer the posterior distributions of your models — like Sequential Monte Carlo (SMC) for instance. You’ve never heard of SMC? Well perfect, because Nicolas Chopin is gonna tell you all about it in this episode!</p><p class="ql-align-justify">A lecturer at the French university of ENSAE since 2006, Nicolas is one of the world experts on SMC. Before that, he graduated from Ecole Polytechnique and… ENSAE, where he did his PhD from 1999 to 2003.</p><p class="ql-align-justify">Outside of work, Nicolas enjoys spending time with his family, practicing aikido, and reading a lot of books.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady and Kurt TeKolste</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify"><strong>Old episodes...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" rel="noopener noreferrer" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p>------------------------------------------------------------------------------</p><p>Max Kochurov’s State of Bayes Lecture Series: <a href="https://www.youtube.com/playlist?list=PL1iMFW7frOOsh5KOcfvKWM12bjh8zs9BQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL1iMFW7frOOsh5KOcfvKWM12bjh8zs9BQ</a></p><p>Sign up here for upcoming lessons: <a href="https://www.meetup.com/pymc-labs-online-meetup/events/293101751/" rel="noopener noreferrer" target="_blank">https://www.meetup.com/pymc-labs-online-meetup/events/293101751/</a></p><p class="ql-align-justify">------------------------------------------------------------------------------</p><p class="ql-align-justify">We talk a lot about different MCMC methods on this podcast, because they are the workhorses of the Bayesian models. But other methods exist to infer the posterior distributions of your models — like Sequential Monte Carlo (SMC) for instance. You’ve never heard of SMC? Well perfect, because Nicolas Chopin is gonna tell you all about it in this episode!</p><p class="ql-align-justify">A lecturer at the French university of ENSAE since 2006, Nicolas is one of the world experts on SMC. Before that, he graduated from Ecole Polytechnique and… ENSAE, where he did his PhD from 1999 to 2003.</p><p class="ql-align-justify">Outside of work, Nicolas enjoys spending time with his family, practicing aikido, and reading a lot of books.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor,, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady and Kurt TeKolste</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify"><strong>Old episodes relevant to these topics:</strong></li><li class="ql-align-justify">LBS #14, Hidden Markov Models &amp; Statistical Ecology, with Vianey Leos-Barajas: <a href="https://learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas/</a></li><li class="ql-align-justify">LBS #41, Thinking Bayes, with Allen Downey: <a href="https://learnbayesstats.com/episode/41-think-bayes-allen-downey/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/41-think-bayes-allen-downey/</a></li><li class="ql-align-justify"><strong>Nicolas’ show notes:</strong></li><li class="ql-align-justify">Nicolas on Mastodon: nchopin@mathstodon.xyz</li><li>2-hour introduction to particle filters: <a href="https://www.youtube.com/watch?v=mE_PJ9ASc8Y" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=mE_PJ9ASc8Y</a></li><li>Nicolas’ website: <a href="https://nchopin.github.io/" rel="noopener noreferrer" target="_blank">https://nchopin.github.io/</a></li><li>Nicolas on GitHub: <a href="https://github.com/nchopin" rel="noopener noreferrer" target="_blank">https://github.com/nchopin</a></li><li>Nicolas on Linkedin: <a href="https://www.linkedin.com/in/nicolas-chopin-442a78102/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/nicolas-chopin-442a78102/</a></li><li>Nicolas’ blog (shared with others): <a href="https://statisfaction.wordpress.com/" rel="noopener noreferrer" target="_blank">https://statisfaction.wordpress.com/</a></li><li>INLA original paper: <a href="https://people.bath.ac.uk/man54/SAMBa/ITTs/ITT2/EDF/INLARueetal2009.pdf" rel="noopener noreferrer" target="_blank">https://people.bath.ac.uk/man54/SAMBa/ITTs/ITT2/EDF/INLARueetal2009.pdf</a></li><li class="ql-align-justify">Nicolas’ book, <em>An introduction to Sequential Monte Carlo</em>: <a href="https://nchopin.github.io/books.html" rel="noopener noreferrer" target="_blank">https://nchopin.github.io/books.html</a></li><li class="ql-align-justify">Laplace’s Demon, A Seminar Series about Bayesian Machine Learning at Scale: <a href="https://ailab.criteo.com/laplaces-demon-bayesian-machine-learning-at-scale/" rel="noopener noreferrer" target="_blank">https://ailab.criteo.com/laplaces-demon-bayesian-machine-learning-at-scale/</a></li><li>Paper about Expectation Propagation, <em>Leave Pima Indians Alone – Binary Regression as a Benchmark for Bayesian Computation</em>: <a href="https://projecteuclid.org/journals/statistical-science/volume-32/issue-1/Leave-Pima-Indians-Alone--Binary-Regression-as-a-Benchmark/10.1214/16-STS581.full" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/journals/statistical-science/volume-32/issue-1/Leave-Pima-Indians-Alone--Binary-Regression-as-a-Benchmark/10.1214/16-STS581.full</a></li><li>Blackjax website: <a href="https://blackjax-devs.github.io/blackjax/" rel="noopener noreferrer" target="_blank">https://blackjax-devs.github.io/blackjax/</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 82 Nicolas Chopin is our guest. He is a graduate from the Ecole Polytechnique and currently lectures at the French university of ENSAE.&nbsp;</p><p>He is a specialist for Sequential Monte Carlo (SMC) samplers and explains in detail what they are, clearing up some confusion about what SMC stands for and when to use them.&nbsp;</p><p>We discuss the advantages of SMC over other types of commonly used samplers for bayesian models such as MCMC or Gibbs samplers.&nbsp;</p><p>Besides a detailed look at SMC we also cover INLA. INLA stands for Integrated Nested LaPlace Approximation.&nbsp;</p><p>INLA can be a fast, approximate sampler for specific kinds of models. It works well for geographic data and relationships, such as for example relationships between regions in a country.</p><p>We discuss the difficulties with and future of SMC and INLA and probabilistic sampling in general.</p><p><strong>Transcript</strong></p><p><em>please note that the transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/82-sequential-monte-carlo-bayesian-computation-algorithms-nicolas-chopin]]></link><guid isPermaLink="false">c765554f-9e64-4b46-8182-32a155bf4181</guid><itunes:image href="https://artwork.captivate.fm/bd07c572-13c5-450c-9737-9cc7e47ae55b/IdHJ1U3bgcaDi7ss35Neq-UJ.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 05 May 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/4d27bac4-68ad-4e3b-b6e1-1de0a3077d89/Learning-Bayesian-Statistics-82-converted.mp3" length="63780222" type="audio/mpeg"/><itunes:duration>01:06:35</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>82</itunes:episode><itunes:season>1</itunes:season><podcast:episode>82</podcast:episode><podcast:season>1</podcast:season><itunes:summary>But other methods exist to infer the posterior distributions of your models — like Sequential Monte Carlo (SMC), INLA, Variational Bayes. Let&apos;s dive into those in this episode!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/ce98ef36-a8ae-470d-bcdb-a203189ac5f5/index.html" type="text/html"/></item><item><title>#81 Neuroscience of Perception: Exploring the Brain, with Alan Stocker</title><itunes:title>Neuroscience of Perception: Exploring the Brain, with Alan Stocker</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Did you know that the way your brain perceives speed depends on your priors? And it’s not the same at night? And it’s not the same for everybody?</p><p class="ql-align-justify">This is another of these episodes I love where we dive into neuroscience, how the brain works, and how it relates to Bayesian stats. It’s actually a follow-up to episode 77, where Pascal Wallisch told us how the famous black and blue dress tells a lot about our priors about how we perceive the world. So I strongly recommend listening to episode 77 first, and then come back here, to have your mind blown away again, this time by Alan Stocker.</p><p class="ql-align-justify">Alan was born and raised in Switzerland. After a PhD in physics at ETH Zurich, he somehow found himself doing neuroscience, during a postdoc at NYU. And then he never stopped — still leading the Computational Perception and Cognition Laboratory&nbsp;of the University of Pennsylvania.</p><p class="ql-align-justify">But Alan is also a man of music (playing the piano when he can), a man of coffee (he’ll never refuse an olympia cremina or a kafatek) and a man of the outdoors (he loves trashing through deep powder with his snowboard).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady and Kurt TeKolste</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Alan’s website: <a href="https://www.sas.upenn.edu/~astocker/lab/members-files/alan.php" target="_blank">https://www.sas.upenn.edu/~astocker/lab/members-files/alan.php</a></li><li>Noise characteristics and prior expectations in human visual speed perception: <a href="https://www.nature.com/articles/nn1669" target="_blank">https://www.nature.com/articles/nn1669</a></li><li>Combining efficient coding with]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><ul><li><a href="https://www.intuitivebayes.com/" target="_blank">My Intuitive Bayes Online Courses</a></li><li><a href="https://topmate.io/alex_andorra" target="_blank">1:1 Mentorship with me</a></li></ul><br/><p class="ql-align-justify">Did you know that the way your brain perceives speed depends on your priors? And it’s not the same at night? And it’s not the same for everybody?</p><p class="ql-align-justify">This is another of these episodes I love where we dive into neuroscience, how the brain works, and how it relates to Bayesian stats. It’s actually a follow-up to episode 77, where Pascal Wallisch told us how the famous black and blue dress tells a lot about our priors about how we perceive the world. So I strongly recommend listening to episode 77 first, and then come back here, to have your mind blown away again, this time by Alan Stocker.</p><p class="ql-align-justify">Alan was born and raised in Switzerland. After a PhD in physics at ETH Zurich, he somehow found himself doing neuroscience, during a postdoc at NYU. And then he never stopped — still leading the Computational Perception and Cognition Laboratory&nbsp;of the University of Pennsylvania.</p><p class="ql-align-justify">But Alan is also a man of music (playing the piano when he can), a man of coffee (he’ll never refuse an olympia cremina or a kafatek) and a man of the outdoors (he loves trashing through deep powder with his snowboard).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, Arkady and Kurt TeKolste</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Alan’s website: <a href="https://www.sas.upenn.edu/~astocker/lab/members-files/alan.php" target="_blank">https://www.sas.upenn.edu/~astocker/lab/members-files/alan.php</a></li><li>Noise characteristics and prior expectations in human visual speed perception: <a href="https://www.nature.com/articles/nn1669" target="_blank">https://www.nature.com/articles/nn1669</a></li><li>Combining efficient coding with Bayesian inference as a model of human perception:</li><li>Video: <a href="https://vimeo.com/138238753" target="_blank">https://vimeo.com/138238753</a></li><li>Paper: <a href="https://www.nature.com/articles/nn.4105" target="_blank">https://www.nature.com/articles/nn.4105</a></li><li class="ql-align-justify">LBS #77 How a Simple Dress Helped Uncover Hidden Prejudices, with Pascal Wallisch: <a href="https://learnbayesstats.com/episode/77-how-a-simple-dress-helped-uncover-hidden-prejudices-pascal-wallisch/" target="_blank">https://learnbayesstats.com/episode/77-how-a-simple-dress-helped-uncover-hidden-prejudices-pascal-wallisch/</a></li><li>LBS #72 Why the Universe is so Deliciously Crazy, with Daniel Whiteson: <a href="https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/" target="_blank">https://learnbayesstats.com/episode/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson/</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 81 of the podcast, Alan Stocker helps us update our priors of how the brain works. Alan, born in Switzerland, studied mechanical engineering and earned his PhD in physics before being introduced to the field of neuroscience through an internship. He is now Associate Professor at the University of Pennsylvania.&nbsp;</p><p>Our conversation covers various topics related to the human brain and whether it what it does can be characterised as a Bayesian inferences.&nbsp;</p><p>&nbsp;Low-level visual processing, such as identifying the orientation of moving grids, can be explained with reference to Bayesian priors and updating under uncertainty. We go through several examples of this such as driving a car in foggy conditions.&nbsp;</p><p>More abstract cognitive processes, such as reasoning about politics, may be more difficult to explain in Bayesian terms.</p><p>We also touch upon the question to what degree priors may be innate and how to educate people to change their priors.</p><p>In the end, Alan gives two recommendations for improving your Bayesian inferences in a political context: 1) Go out and get your own feedback and 2) try to give and receive true feedback. Listen to the episode for details.</p><br><p><strong>Transcript</strong></p><p><em>please note that the transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/81-neuroscience-of-perception-exploring-the-brain-alan-stocker]]></link><guid isPermaLink="false">dcefbacc-2386-4c3c-847f-7e2d4ef15d2e</guid><itunes:image href="https://artwork.captivate.fm/0ea025fe-c3e2-4c9b-b340-63cd5ebee77e/ba30ZHLmYf76c2Yv13jf5c47.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 24 Apr 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/75db0e0e-df97-44da-b9a1-2daae5ec3ed7/Learning-Bayesian-Statistics-81-converted.mp3" length="71767745" type="audio/mpeg"/><itunes:duration>01:14:55</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>81</itunes:episode><itunes:season>1</itunes:season><podcast:episode>81</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Did you know that the way your brain perceives speed depends on your priors? And it’s not the same at night? And it’s not the same for everybody?

This is another of these episodes I love where we dive into neuroscience, how the brain works, and how it relates to Bayesian stats.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/8be7829a-133f-42ce-8b19-5f7f56cb6141/index.html" type="text/html"/></item><item><title>#80 Bayesian Additive Regression Trees (BARTs), with Sameer Deshpande</title><itunes:title>Bayesian Additive Regression Trees (BARTs), with Sameer Deshpande</itunes:title><description><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m sure you know at least one Bart. Maybe you’ve even used one — but you’re not proud of it, because you didn’t know what you were doing. Thankfully, in this episode, we’ll go to the roots of regression trees — oh yeah, that’s what BART stands for. What were you thinking about?</p><p class="ql-align-justify">Our tree expert will be no one else than Sameer Deshpande. Sameer is an assistant professor of Statistics at the University of Wisconsin-Madison. Prior to that, he completed a postdoc at MIT and earned his Ph.D. in Statistics from UPenn.</p><p class="ql-align-justify">On the methodological front, he is interested in Bayesian hierarchical modeling, regression trees, model selection, and causal inference. Much of his applied work is motivated by an interest in understanding the long-term health consequences of playing American-style tackle football. He also enjoys modeling sports data and was a finalist in the 2019 NFL Big Data Bowl.</p><p class="ql-align-justify">Outside of Statistics, he enjoys cooking, making cocktails, and photography — sometimes doing all of those at the same time…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, and Arkady.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Sameer’s website: <a href="https://skdeshpande91.github.io/" target="_blank">https://skdeshpande91.github.io/</a></li><li class="ql-align-justify">Sameer on GitHub: <a href="https://github.com/skdeshpande91" target="_blank">https://github.com/skdeshpande91</a></li><li class="ql-align-justify">Sameer on Twitter: <a href="https://twitter.com/skdeshpande91" target="_blank">https://twitter.com/skdeshpande91</a>&nbsp;</li><li>Sameer on Google Scholar: <a href="https://scholar.google.com/citations?user=coVrnWIAAAAJ&amp;hl=en" target="_blank">https://scholar.google.com/citations?user=coVrnWIAAAAJ&amp;hl=en</a></li><li>LBS #50 Ta(l)king Risks &amp; Embracing...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m sure you know at least one Bart. Maybe you’ve even used one — but you’re not proud of it, because you didn’t know what you were doing. Thankfully, in this episode, we’ll go to the roots of regression trees — oh yeah, that’s what BART stands for. What were you thinking about?</p><p class="ql-align-justify">Our tree expert will be no one else than Sameer Deshpande. Sameer is an assistant professor of Statistics at the University of Wisconsin-Madison. Prior to that, he completed a postdoc at MIT and earned his Ph.D. in Statistics from UPenn.</p><p class="ql-align-justify">On the methodological front, he is interested in Bayesian hierarchical modeling, regression trees, model selection, and causal inference. Much of his applied work is motivated by an interest in understanding the long-term health consequences of playing American-style tackle football. He also enjoys modeling sports data and was a finalist in the 2019 NFL Big Data Bowl.</p><p class="ql-align-justify">Outside of Statistics, he enjoys cooking, making cocktails, and photography — sometimes doing all of those at the same time…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, and Arkady.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Sameer’s website: <a href="https://skdeshpande91.github.io/" target="_blank">https://skdeshpande91.github.io/</a></li><li class="ql-align-justify">Sameer on GitHub: <a href="https://github.com/skdeshpande91" target="_blank">https://github.com/skdeshpande91</a></li><li class="ql-align-justify">Sameer on Twitter: <a href="https://twitter.com/skdeshpande91" target="_blank">https://twitter.com/skdeshpande91</a>&nbsp;</li><li>Sameer on Google Scholar: <a href="https://scholar.google.com/citations?user=coVrnWIAAAAJ&amp;hl=en" target="_blank">https://scholar.google.com/citations?user=coVrnWIAAAAJ&amp;hl=en</a></li><li>LBS #50 Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li>LBS #51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/" target="_blank">https://learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton/</a></li><li>LBS #58 Bayesian Modeling and Computation, with Osvaldo Martin, Ravin Kumar and Junpeng Lao: <a href="https://learnbayesstats.com/episode/58-bayesian-modeling-computation-osvaldo-martin-ravin-kumar-junpeng-lao/" target="_blank">https://learnbayesstats.com/episode/58-bayesian-modeling-computation-osvaldo-martin-ravin-kumar-junpeng-lao/</a></li><li>Book <em>Bayesian Modeling and Computation in Python</em>: <a href="https://bayesiancomputationbook.com/welcome.html" target="_blank">https://bayesiancomputationbook.com/welcome.html</a></li><li>LBS #39 Survival Models &amp; Biostatistics for Cancer Research, with Jacki Buros: <a href="https://learnbayesstats.com/episode/39-survival-models-biostatistics-cancer-research-jacki-buros/" target="_blank">https://learnbayesstats.com/episode/39-survival-models-biostatistics-cancer-research-jacki-buros/</a></li><li>Original BART paper (Chipman, George, and McCulloch 2010): <a href="https://doi.org/10.1214/09-AOAS285" target="_blank">https://doi.org/10.1214/09-AOAS285</a></li><li>Hill (2011) on BART in causal inference: <a href="https://doi.org/10.1198/jcgs.2010.08162" target="_blank">https://doi.org/10.1198/jcgs.2010.08162</a></li><li>Hahn, Murray, and Carvalho on Bayesian causal forests: <a href="https://doi.org/10.1214/19-BA1195" target="_blank">https://doi.org/10.1214/19-BA1195</a></li><li>Main BART package in R: <a href="https://cran.r-project.org/web/packages/BART/index.html" target="_blank">https://cran.r-project.org/web/packages/BART/index.html</a></li><li>dbart R package: <a href="https://cran.r-project.org/web/packages/dbarts/index.html" target="_blank">https://cran.r-project.org/web/packages/dbarts/index.html</a></li><li>Sameer’s own re-implementation of BART: <a href="https://github.com/skdeshpande91/flexBART" target="_blank">https://github.com/skdeshpande91/flexBART</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In episode 80, Sameer Deshpande, assistant professor of Statistics at the University of Wisconsin-Madison is our guest.&nbsp;</p><p>He had a passion for math from a young age. And got into Bayesian statistics at university, teaching statistics now himself. We talk about the intricacies of teaching bayesian statistics, such as helping students accept that there are no objective answers.&nbsp;</p><p>Sameer’s current work focuses on Bayesian Additive Regression Trees (BARTs). He also works on prior specification, and numerous cool applied projects, for example on the effects of playing American football as an adolescent and its effects for later health</p><p>We primarily talk about BARTs as a way of approximating complex functions by using a collection of step functions. They work off the shelf pretty well and can be applied to various models such as survival models, linear models, and smooth models. BARTs are somewhat analogous to splines and can capture trajectories well over time. However, they are also a bit like a black box making them hard to interpret.</p><p>We further touch upon some of his work on practical problems, such as how cognitive processes change over time or models of baseball empires’ decision making.</p><p><strong>Transcript</strong></p><p><em>Please note that the following transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/80-bayesian-additive-regression-trees-sameer-deshpande]]></link><guid isPermaLink="false">196e49a7-4714-4bfa-ac47-a90ce39fc52c</guid><itunes:image href="https://artwork.captivate.fm/a07befe2-79b1-4b03-9713-c1c6c17326ac/nrl55jeaE1Tqb0fCZT4vM3s6.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 11 Apr 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/4d0967fa-3d59-4162-8326-b25e18dfec52/Learning-Bayesian-Statistics-80-converted.mp3" length="66169216" type="audio/mpeg"/><itunes:duration>01:09:05</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>80</itunes:episode><itunes:season>1</itunes:season><podcast:episode>80</podcast:episode><podcast:season>1</podcast:season><itunes:summary>In this episode, we’ll go to the roots of regression trees. Our tree expert will be no one else than Sameer Deshpande. Sameer is an assistant professor of Statistics at the University of Wisconsin-Madison. Prior to that, he completed a postdoc at MIT and earned his Ph.D. in Statistics from UPenn.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/4264a724-5108-4115-8bde-f58749fa81b6/index.html" type="text/html"/></item><item><title>#79 Decision-Making &amp; Cost Effectiveness Analysis for Health Economics, with Gianluca Baio</title><itunes:title>Decision-Making &amp; Cost Effectiveness Analysis for Health Economics, with Gianluca Baio</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Decision-making and cost effectiveness analyses rarely get as important as in the health systems — where matters of life and death are not a metaphor. Bayesian statistical modeling is extremely helpful in this field, with its ability to quantify uncertainty, include domain knowledge, and incorporate causal reasoning.</p><p class="ql-align-justify">Specialized in all these topics, Gianluca Baio was <em>the</em> person to talk to for this episode. He’ll tell us about this kind of models, and how to understand them.</p><p class="ql-align-justify">Gianluca is currently the head of the department of Statistical Science at University College London. He studied Statistics and Economics at the University of Florence (Italy), and completed a PhD in Applied Statistics, again at the beautiful University of Florence.</p><p class="ql-align-justify">He’s also a very skilled pizzaiolo — so now I have two reasons to come back to visit Tuscany…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, and Arkady.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Gianluca’s website: <a href="https://gianluca.statistica.it/" target="_blank">https://gianluca.statistica.it/</a></li><li class="ql-align-justify">Gianluca on GitHub: <a href="https://github.com/giabaio" target="_blank">https://github.com/giabaio</a>&nbsp;</li><li class="ql-align-justify">Gianluca on Mastodon: <a href="https://mas.to/@gianlubaio" target="_blank">https://mas.to/@gianlubaio</a></li><li class="ql-align-justify">Gianluca on Twitter: <a href="https://twitter.com/gianlubaio" target="_blank">https://twitter.com/gianlubaio</a></li><li class="ql-align-justify">Gianluca on Linkedin: <a href="https://www.linkedin.com/in/gianluca-baio-b893879/" target="_blank">https://www.linkedin.com/in/gianluca-baio-b893879/</a></li><li class="ql-align-justify">Gianluca’s articles on arXiv: <a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Decision-making and cost effectiveness analyses rarely get as important as in the health systems — where matters of life and death are not a metaphor. Bayesian statistical modeling is extremely helpful in this field, with its ability to quantify uncertainty, include domain knowledge, and incorporate causal reasoning.</p><p class="ql-align-justify">Specialized in all these topics, Gianluca Baio was <em>the</em> person to talk to for this episode. He’ll tell us about this kind of models, and how to understand them.</p><p class="ql-align-justify">Gianluca is currently the head of the department of Statistical Science at University College London. He studied Statistics and Economics at the University of Florence (Italy), and completed a PhD in Applied Statistics, again at the beautiful University of Florence.</p><p class="ql-align-justify">He’s also a very skilled pizzaiolo — so now I have two reasons to come back to visit Tuscany…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode, Gabriel Stechschulte, and Arkady.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Gianluca’s website: <a href="https://gianluca.statistica.it/" target="_blank">https://gianluca.statistica.it/</a></li><li class="ql-align-justify">Gianluca on GitHub: <a href="https://github.com/giabaio" target="_blank">https://github.com/giabaio</a>&nbsp;</li><li class="ql-align-justify">Gianluca on Mastodon: <a href="https://mas.to/@gianlubaio" target="_blank">https://mas.to/@gianlubaio</a></li><li class="ql-align-justify">Gianluca on Twitter: <a href="https://twitter.com/gianlubaio" target="_blank">https://twitter.com/gianlubaio</a></li><li class="ql-align-justify">Gianluca on Linkedin: <a href="https://www.linkedin.com/in/gianluca-baio-b893879/" target="_blank">https://www.linkedin.com/in/gianluca-baio-b893879/</a></li><li class="ql-align-justify">Gianluca’s articles on arXiv: <a href="https://arxiv.org/a/baio_g_1.html" target="_blank">https://arxiv.org/a/baio_g_1.html</a></li><li class="ql-align-justify">R for Health Technology Assessment (HTA) Consortium: <a href="https://r-hta.org/" target="_blank">https://r-hta.org/</a>&nbsp;</li><li>LBS #50 – Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li>LBS #45 – Biostats &amp; Clinical Trial Design, with Frank Harrell: <a href="https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell/" target="_blank">https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell/</a></li><li>How to find priors intuitively= <a href="https://www.youtube.com/watch?v=9shZeqKG3M0" target="_blank">https://www.youtube.com/watch?v=9shZeqKG3M0</a></li><li>Hierarchical Bayesian Modeling of Survey Data with Post-stratification: <a href="https://www.youtube.com/watch?v=efID35XUQ3I" target="_blank">https://www.youtube.com/watch?v=efID35XUQ3I</a></li><li class="ql-align-justify">LBS Topical Playlists (also available as RSS feeds on the website): <a href="https://www.youtube.com/@learningbayesianstatistics8147/playlists" target="_blank">https://www.youtube.com/@learningbayesianstatistics8147/playlists</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this week’s episode, I talk to Gianluca Baio. He is the head of the department of Statistical Science at University College London and earned a MA and PhD in Florence in Statistics and Economics.</p><p>His work primarily focuses on Bayesian modeling for decision making in healthcare, for example in case studies for novel drugs and whether this alternative treatment is worth the cost. Being a relatively young field, health economics seems more open to Bayesian statistics than more established fields.</p><p>While Bayesian statistics becomes more common in clinical trial research, many regulatory bodies still prefer classical p-values. Nonetheless, a lot of COVID modelling was done using Bayesian statistics.</p><p>We also talk about the purpose of statistics, which is not to prove things but to reduce uncertainty.</p><p>Gianluca explains that proper communication is important when eliciting priors and involving people in model building.&nbsp;</p><p class="ql-align-justify">The future of Bayesian statistics is that statistics should have more primacy, and he hopes that statistics will stay central rather than becoming embedded in other approaches like data science, notwithstanding, communication with other disciplines is crucial.</p><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Transcript</strong></p><p class="ql-align-justify"><em>Please note that the following transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out </em></a><em>if you're willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/79-decision-making-cost-effectiveness-analysis-health-economics-gianluca-baio]]></link><guid isPermaLink="false">145c9ebf-822b-4e01-b82d-a60b8704482c</guid><itunes:image href="https://artwork.captivate.fm/80e254dc-0f24-488a-bc97-59a805e99e1e/dHH0Vsna8IZ-9TXALAPTAbfZ.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 17 Mar 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/ad5b0d17-8003-4106-aa9c-d193893aecb5/Learning-Bayesian-Statistics-79.mp3" length="64944070" type="audio/mpeg"/><itunes:duration>01:07:48</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>79</itunes:episode><itunes:season>1</itunes:season><podcast:episode>79</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Decision-making and cost effectiveness analyses rarely get as important as in the health systems — where matters of life and death are not a metaphor. Bayesian statistical modeling is extremely helpful in this field, with its ability to quantify uncertainty, include domain knowledge, and incorporate causal reasoning.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/e8180ac8-cbed-445d-ad18-72245f21c6a5/index.html" type="text/html"/></item><item><title>#78 Exploring MCMC Sampler Algorithms, with Matt D. Hoffman</title><itunes:title>Exploring MCMC Sampler Algorithms, with Matt D. Hoffman</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Matt Hoffman has already worked on many topics in his life – music information retrieval, speech enhancement, user behavior modeling, social network analysis, astronomy, you name it.</p><p class="ql-align-justify">Obviously, picking questions for him was hard, so we ended up talking more or less freely — which is one of my favorite types of episodes, to be honest.</p><p class="ql-align-justify">You’ll hear about the circumstances Matt would advise picking up Bayesian stats, generalized HMC, blocked samplers, why do the samplers he works on have food-based names, etc.</p><p class="ql-align-justify">In case you don’t know him, Matt is a research scientist at Google. Before that, he did a postdoc in the Columbia Stats department, working with Andrew Gelman, and a Ph.D at Princeton, working with David Blei and Perry Cook.</p><p class="ql-align-justify">Matt is probably best known for his work in approximate Bayesian inference algorithms, such as stochastic variational inference and the no-U-turn sampler, but he’s also worked on a wide range of applications, and contributed to software such as Stan and TensorFlow Probability.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode and Gabriel Stechschulte</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Matt’s website: <a href="http://matthewdhoffman.com/" target="_blank">http://matthewdhoffman.com/</a></li><li>Matt on Google Scholar: <a href="https://scholar.google.com/citations?hl=en&amp;user=IeHKeGYAAAAJ&amp;view_op=list_works" target="_blank">https://scholar.google.com/citations?hl=en&amp;user=IeHKeGYAAAAJ&amp;view_op=list_works</a></li><li>The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo: <a href="https://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf" target="_blank">https://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf</a></li><li>Tuning-Free Generalized Hamiltonian Monte Carlo: <a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Matt Hoffman has already worked on many topics in his life – music information retrieval, speech enhancement, user behavior modeling, social network analysis, astronomy, you name it.</p><p class="ql-align-justify">Obviously, picking questions for him was hard, so we ended up talking more or less freely — which is one of my favorite types of episodes, to be honest.</p><p class="ql-align-justify">You’ll hear about the circumstances Matt would advise picking up Bayesian stats, generalized HMC, blocked samplers, why do the samplers he works on have food-based names, etc.</p><p class="ql-align-justify">In case you don’t know him, Matt is a research scientist at Google. Before that, he did a postdoc in the Columbia Stats department, working with Andrew Gelman, and a Ph.D at Princeton, working with David Blei and Perry Cook.</p><p class="ql-align-justify">Matt is probably best known for his work in approximate Bayesian inference algorithms, such as stochastic variational inference and the no-U-turn sampler, but he’s also worked on a wide range of applications, and contributed to software such as Stan and TensorFlow Probability.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R, Nicolas Rode and Gabriel Stechschulte</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Matt’s website: <a href="http://matthewdhoffman.com/" target="_blank">http://matthewdhoffman.com/</a></li><li>Matt on Google Scholar: <a href="https://scholar.google.com/citations?hl=en&amp;user=IeHKeGYAAAAJ&amp;view_op=list_works" target="_blank">https://scholar.google.com/citations?hl=en&amp;user=IeHKeGYAAAAJ&amp;view_op=list_works</a></li><li>The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo: <a href="https://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf" target="_blank">https://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf</a></li><li>Tuning-Free Generalized Hamiltonian Monte Carlo: <a href="https://proceedings.mlr.press/v151/hoffman22a/hoffman22a.pdf" target="_blank">https://proceedings.mlr.press/v151/hoffman22a/hoffman22a.pdf</a></li><li>Nested R-hat: Assessing the convergence of Markov chain Monte Carlo when running many short chain: <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/nestedRhat.pdf" target="_blank">http://www.stat.columbia.edu/~gelman/research/unpublished/nestedRhat.pdf</a></li><li>Automatic Reparameterisation of Probabilistic Programs: <a href="http://proceedings.mlr.press/v119/gorinova20a/gorinova20a.pdf" target="_blank">http://proceedings.mlr.press/v119/gorinova20a/gorinova20a.pdf</a></li></ul><br/><br><p><strong>Abstract</strong></p><p><em>written by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this episode, Matt D. Hoffman, a Google research scientist discussed his work on probabilistic sampling algorithms with me. Matt has a background in music information retrieval, speech enhancement, user behavior modeling, social network analysis, and astronomy.&nbsp;</p><p>He came to machine learning (ML) and computer science through his interest in synthetic music and later took a Bayesian modeling class during his PhD.&nbsp;</p><p>He mostly works on algorithms, including Markov Chain Monte Carlo (MCMC) methods that can take advantage of hardware acceleration, believing that running many small chains in parallel is better for handling autocorrelation than running a few longer chains.&nbsp;</p><p>Matt is interested in Bayesian neural networks but is also skeptical about their use in practice.&nbsp;</p><p>He recently contributed to a generalised Hamilton Monte Carlo (HMC) sampler, and previously worked on an alternative to the No-U-Turn-Sampler (NUTS) called MEADS. We discuss the applications for these samplers and how they differ from one another.&nbsp;</p><p>In addition, Matt introduces an improved R-hat diagnostic tool, nested R-hat, that he and colleagues developed.&nbsp;</p><br><p><strong>Automated Transcript</strong></p><p><strong><em>﻿</em></strong><em>Please note that the following transcript was generated automatically and may therefore contain errors. Feel free to&nbsp;</em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em>&nbsp;if you’re willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/78-exploring-mcmc-sampler-algorithms-matt-d-hoffman]]></link><guid isPermaLink="false">0ffcb1f3-59be-4322-b90e-6520fe9d6e3b</guid><itunes:image href="https://artwork.captivate.fm/4f85eafd-87f4-4e0c-876d-9da6fdc40495/0hESIS1gOhcC3d88ostwMAYA.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 01 Mar 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/0e6f8382-1d74-4a64-98b1-925d2c4b815f/Learning-Bayesian-Statistics-78.mp3" length="60036397" type="audio/mpeg"/><itunes:duration>01:02:41</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>78</itunes:episode><itunes:season>1</itunes:season><podcast:episode>78</podcast:episode><podcast:season>1</podcast:season><itunes:summary>You’ll hear about the circumstances Matt would advise picking up Bayesian stats, generalized HMC, blocked samplers, why do the samplers he works on have food-based names, etc.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/4b314168-9a2a-4e03-89c7-4b0eccf3a2bf/index.html" type="text/html"/></item><item><title>#77 How a Simple Dress Helped Uncover Hidden Prejudices, with Pascal Wallisch</title><itunes:title>How a Simple Dress Helped Uncover Hidden Prejudices, with Pascal Wallisch</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I love dresses. Not on me, of course — I’m not nearly elegant enough to pull it off. Nevertheless, to me, dresses are one of the most elegant pieces of clothing ever invented.</p><p class="ql-align-justify">And I like them even more when they change colors. Well, they don’t really change colors — it’s the way we perceive the colors that can change. You remember that dress that looked black and blue to some people, and white and gold to others? Well that’s exactly what we’ll dive into and explain in this episode.</p><p class="ql-align-justify">Why do we literally see the world differently? Why does that even happen beyond our consciousness, most of the time? And cherry on the cake: how on Earth could this be related to… priors?? Yes, as in Bayesian priors!</p><p class="ql-align-justify">Pascal Wallisch will shed light on all these topics in this episode. Pascal is a professor of Psychology and Data Science at New York University, where he studies a diverse range of topics including perception, cognitive diversity, the roots of disagreement and psychopathy.</p><p class="ql-align-justify">Originally from Germany, Pascal did his undergraduate studies at the Free University of Berlin. He then received his PhD from the University of Chicago, where he studied visual perception.</p><p class="ql-align-justify">In addition to scientific articles on psychology and neuroscience, he wrote multiple books on scientific computing and data science. As you’ll hear, Pascal is a wonderful science communicator, so it's only normal that he also writes for a general audience at Slate or the Creativity Post, and has given public talks at TedX and Think and Drink.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R and Nicolas Rode</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Pascal’s website: <a href="https://blog.pascallisch.net/about/" target="_blank">https://blog.pascallisch.net/about/</a></li><li>Pascal on Twitter: <a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I love dresses. Not on me, of course — I’m not nearly elegant enough to pull it off. Nevertheless, to me, dresses are one of the most elegant pieces of clothing ever invented.</p><p class="ql-align-justify">And I like them even more when they change colors. Well, they don’t really change colors — it’s the way we perceive the colors that can change. You remember that dress that looked black and blue to some people, and white and gold to others? Well that’s exactly what we’ll dive into and explain in this episode.</p><p class="ql-align-justify">Why do we literally see the world differently? Why does that even happen beyond our consciousness, most of the time? And cherry on the cake: how on Earth could this be related to… priors?? Yes, as in Bayesian priors!</p><p class="ql-align-justify">Pascal Wallisch will shed light on all these topics in this episode. Pascal is a professor of Psychology and Data Science at New York University, where he studies a diverse range of topics including perception, cognitive diversity, the roots of disagreement and psychopathy.</p><p class="ql-align-justify">Originally from Germany, Pascal did his undergraduate studies at the Free University of Berlin. He then received his PhD from the University of Chicago, where he studied visual perception.</p><p class="ql-align-justify">In addition to scientific articles on psychology and neuroscience, he wrote multiple books on scientific computing and data science. As you’ll hear, Pascal is a wonderful science communicator, so it's only normal that he also writes for a general audience at Slate or the Creativity Post, and has given public talks at TedX and Think and Drink.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin, Raphaël R and Nicolas Rode</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>Pascal’s website: <a href="https://blog.pascallisch.net/about/" target="_blank">https://blog.pascallisch.net/about/</a></li><li>Pascal on Twitter: <a href="https://twitter.com/pascallisch" target="_blank">https://twitter.com/pascallisch</a></li><li>Pascal on Linkedin: <a href="https://www.linkedin.com/in/pascal-wallisch-0109b77" target="_blank">https://www.linkedin.com/in/pascal-wallisch-0109b77</a></li><li>“Socks &amp; Crocs”, You Are Not So Smart podcast, Episode 200: <a href="https://youarenotsosmart.com/2021/02/22/yanss-200-how-a-divisive-photograph-of-a-perceptually-ambiguous-dress-led-two-researchers-to-build-the-nuclear-bomb-of-cognitive-science-out-of-socks-and-crocs/" target="_blank">https://youarenotsosmart.com/2021/02/22/yanss-200-how-a-divisive-photograph-of-a-perceptually-ambiguous-dress-led-two-researchers-to-build-the-nuclear-bomb-of-cognitive-science-out-of-socks-and-crocs/</a></li><li>You Are Not So Smart – Live in New York at The Bell House: <a href="https://www.youtube.com/watch?v=277HGgqrrUM&amp;t=1s" target="_blank">https://www.youtube.com/watch?v=277HGgqrrUM&amp;t=1s</a></li><li>Pascal’s paper – Illumination assumptions account for individual differences in the perceptual interpretation of a profoundly ambiguous stimulus in the color domain: <a href="https://jov.arvojournals.org/article.aspx?articleid=2617976" target="_blank">https://jov.arvojournals.org/article.aspx?articleid=2617976</a>&nbsp;</li><li>Neural Data Science – A Primer with MATLAB and Python: <a href="https://www.amazon.com/Neural-Data-Science-MATLAB%C2%AE-PythonTM/dp/0128040432" target="_blank">https://www.amazon.com/Neural-Data-Science-MATLAB%C2%AE-PythonTM/dp/0128040432</a></li><li>What Color Is The Dress? The Debate That Broke The Internet: <a href="https://www.nhpr.org/2015-02-27/what-color-is-the-dress-the-debate-that-broke-the-internet#stream/0" target="_blank">https://www.nhpr.org/2015-02-27/what-color-is-the-dress-the-debate-that-broke-the-internet#stream/0</a></li><li>The inside story of the ‘white dress, blue dress’ drama that divided a planet: <a href="https://www.washingtonpost.com/news/morning-mix/wp/2015/02/27/the-inside-story-of-the-white-dress-blue-dress-drama-that-divided-a-nation/" target="_blank">https://www.washingtonpost.com/news/morning-mix/wp/2015/02/27/the-inside-story-of-the-white-dress-blue-dress-drama-that-divided-a-nation/</a></li><li>Noise characteristics and prior expectations in human visual speed perception: <a href="https://www.nature.com/articles/nn1669" target="_blank">https://www.nature.com/articles/nn1669</a></li><li>Bayesian integration in sensorimotor learning: <a href="https://www.nature.com/articles/nature02169" target="_blank">https://www.nature.com/articles/nature02169</a></li></ul><br/><p><strong>Abstract</strong></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In our conversation, Pascal Wallisch, a professor of Psychology and Data Science at New York University, shared about his research on perception, cognitive diversity, the roots of disagreement, and psychopathy.&nbsp;</p><p>Pascal did his undergraduate studies at the Free University of Berlin and then received his PhD from the University of Chicago, where he studied visual perception. Pascal is also a TedX, Think and Drink speaker, and writer for Slate and Creativity Post.&nbsp;</p><p>We discussed Pascal's origin story, his current work on cognitive diversity, and the importance of priors in perception.&nbsp;</p><p>Pascal used the example of "the Dress" picture that went viral in 2015, where people saw either black and blue or white and gold. He explained how prior experience and knowledge can affect how people perceive colors and motion, and how priors can bias people for action.&nbsp;</p><p>We discussed to what extent the brain might be Bayesian and what functions are probably not so well described in bayesian terms.&nbsp;</p><p>Pascal also discussed how priors can be changed through experience and exposure.</p><p>Finally, Pascal emphasized that people have different priors and perspectives, and that understanding these differences is crucial for creating a more diverse and inclusive society.</p><p><strong>Automated Transcript</strong></p><p><strong><em>﻿</em></strong><em>Please note that the following transcript was generated automatically and may therefore contain errors. Feel free to&nbsp;</em><a href="https://twitter.com/LearnBayesStats" target="_blank"><em>reach out</em></a><em>&nbsp;if you’re willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/77-how-a-simple-dress-helped-uncover-hidden-prejudices-pascal-wallisch]]></link><guid isPermaLink="false">168b0031-a963-44c6-b068-3d33c2018dc7</guid><itunes:image href="https://artwork.captivate.fm/0e5e64ab-dd11-424e-b7cf-8ef03147ef01/GqQw-TjqMpST30FZha20Wiie.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 13 Feb 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/41bcce98-a42a-4c79-afc9-d904015fbdab/Learning-Bayesian-Statistics-77.mp3" length="66103747" type="audio/mpeg"/><itunes:duration>01:09:01</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>77</itunes:episode><itunes:season>1</itunes:season><podcast:episode>77</podcast:episode><podcast:season>1</podcast:season><itunes:summary>You remember that dress that looked black and blue to some people, and white and gold to others? Well that’s exactly what we’ll dive into and explain in this episode.
Why do we literally see the world differently? Why does that even happen beyond our consciousness, most of the time? And cherry on the cake: how on Earth could this be related to… priors?? Yes, as in Bayesian priors!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/6c5e32b9-b71f-47c2-b34b-ded61cc662f8/index.html" type="text/html"/></item><item><title>#76 The Past, Present &amp; Future of Stan, with Bob Carpenter</title><itunes:title>The Past, Present &amp; Future of Stan, with Bob Carpenter</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">How does it feel to switch careers and start a postdoc at age 47? How was it to be one of the people who created the probabilistic programming language Stan? What should the Bayesian community focus on in the coming years?</p><p class="ql-align-justify">These are just a few of the questions I had for my illustrious guest in this episode — Bob Carpenter. Bob is, of course, a Stan developer, and comes from a math background, with an emphasis on logic and computer science theory. He then did his PhD in cognitive and computer sciences, at the University of Edinburgh.</p><p class="ql-align-justify">He moved from a professor position at Carnegie Mellon to industry research at Bell Labs, to working with Andrew Gelman and Matt Hoffman at Columbia University. Since 2020, he's been working at Flatiron Institute, a non-profit focused on algorithms and software for science.</p><p class="ql-align-justify">In his free time, Bob loves to cook, see live music, and play role playing games — think Monster of the Week, Blades in Dark, and Fate.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin and Raphaël R.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Bob’s website:&nbsp;<a href="https://bob-carpenter.github.io" target="_blank">https://bob-carpenter.github.io</a></li><li class="ql-align-justify">Bob on GitHub:&nbsp;<a href="https://github.com/bob-carpenter" target="_blank">https://github.com/bob-carpenter</a></li><li class="ql-align-justify">Bob on Google Scholar:&nbsp;<a href="https://scholar.google.com.au/citations?user=kPtKWAwAAAAJ&amp;hl=en" target="_blank">https://scholar.google.com.au/citations?user=kPtKWAwAAAAJ&amp;hl=en</a></li><li class="ql-align-justify">Stat modeling blog:&nbsp;<a href="https://statmodeling.stat.columbia.edu" target="_blank">https://statmodeling.stat.columbia.edu</a></li><li class="ql-align-justify">Stan home page:&nbsp;<a href="https://mc-stan.org/"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">How does it feel to switch careers and start a postdoc at age 47? How was it to be one of the people who created the probabilistic programming language Stan? What should the Bayesian community focus on in the coming years?</p><p class="ql-align-justify">These are just a few of the questions I had for my illustrious guest in this episode — Bob Carpenter. Bob is, of course, a Stan developer, and comes from a math background, with an emphasis on logic and computer science theory. He then did his PhD in cognitive and computer sciences, at the University of Edinburgh.</p><p class="ql-align-justify">He moved from a professor position at Carnegie Mellon to industry research at Bell Labs, to working with Andrew Gelman and Matt Hoffman at Columbia University. Since 2020, he's been working at Flatiron Institute, a non-profit focused on algorithms and software for science.</p><p class="ql-align-justify">In his free time, Bob loves to cook, see live music, and play role playing games — think Monster of the Week, Blades in Dark, and Fate.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin and Raphaël R.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Bob’s website:&nbsp;<a href="https://bob-carpenter.github.io" target="_blank">https://bob-carpenter.github.io</a></li><li class="ql-align-justify">Bob on GitHub:&nbsp;<a href="https://github.com/bob-carpenter" target="_blank">https://github.com/bob-carpenter</a></li><li class="ql-align-justify">Bob on Google Scholar:&nbsp;<a href="https://scholar.google.com.au/citations?user=kPtKWAwAAAAJ&amp;hl=en" target="_blank">https://scholar.google.com.au/citations?user=kPtKWAwAAAAJ&amp;hl=en</a></li><li class="ql-align-justify">Stat modeling blog:&nbsp;<a href="https://statmodeling.stat.columbia.edu" target="_blank">https://statmodeling.stat.columbia.edu</a></li><li class="ql-align-justify">Stan home page:&nbsp;<a href="https://mc-stan.org/" target="_blank">https://mc-stan.org/</a></li><li class="ql-align-justify">BridgeStan home page:&nbsp;<a href="https://github.com/roualdes/bridgestan" target="_blank">https://github.com/roualdes/bridgestan</a></li><li class="ql-align-justify">bayes-infer home page:&nbsp;<a href="https://github.com/bob-carpenter/bayes-infer" target="_blank">https://github.com/bob-carpenter/bayes-infer</a></li><li class="ql-align-justify">Crowdsourcing with item difficulty:&nbsp;<a href="https://github.com/bob-carpenter/rater-difficulty-paper" target="_blank">https://github.com/bob-carpenter/rater-difficulty-paper</a></li><li class="ql-align-justify">Pathfinder VI system:&nbsp;<a href="https://www.jmlr.org/papers/v23/21-0889.html" target="_blank">https://www.jmlr.org/papers/v23/21-0889.html</a></li><li class="ql-align-justify">Flatiron Institute home page:&nbsp;<a href="https://www.simonsfoundation.org/flatiron/" target="_blank">https://www.simonsfoundation.org/flatiron/</a></li><li class="ql-align-justify">0 to 100K in 10 years – Nurturing an open-source software community: <a href="https://www.youtube.com/watch?v=P9gDFHl-Hss&amp;t=81s" target="_blank">https://www.youtube.com/watch?v=P9gDFHl-Hss&amp;t=81s</a></li><li class="ql-align-justify">Information Theory, Inference and Learning Algorithms: <a href="https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981" target="_blank">https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981</a></li><li class="ql-align-justify">LBS #20 – Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/" target="_blank">https://learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari/</a></li><li class="ql-align-justify">LBS #27 – Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns: <a href="https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/" target="_blank">https://learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns/</a></li><li class="ql-align-justify">LBS #17&nbsp;– Reparametrize Your Models Automatically, with Maria Gorinova: <a href="https://learnbayesstats.com/episode/17-reparametrize-your-models-automatically-with-maria-gorinova/" target="_blank">https://learnbayesstats.com/episode/17-reparametrize-your-models-automatically-with-maria-gorinova/</a></li><li class="ql-align-justify">LBS #36 – Bayesian Non-Parametrics &amp; Developing Turing.jl, with Martin Trapp: <a href="https://learnbayesstats.com/episode/36-bayesian-non-parametrics-developing-turing-julia-martin-trapp/" target="_blank">https://learnbayesstats.com/episode/36-bayesian-non-parametrics-developing-turing-julia-martin-trapp/</a></li><li class="ql-align-justify">LBS #19 – Turing, Julia and Bayes in Economics, with Cameron Pfiffer: <a href="https://learnbayesstats.com/episode/19-turing-julia-and-bayes-in-economics-with-cameron-pfiffer/" target="_blank">https://learnbayesstats.com/episode/19-turing-julia-and-bayes-in-economics-with-cameron-pfiffer/</a></li><li class="ql-align-justify">LBS #74 – Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt: <a href="https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/" target="_blank">https://learnbayesstats.com/episode/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt/</a></li><li class="ql-align-justify">Bayesian Workflow paper: <a href="https://arxiv.org/abs/2011.01808" target="_blank">https://arxiv.org/abs/2011.01808</a></li><li class="ql-align-justify">BAyesian Model-Building Interface (Bambi) in Python: <a href="https://bambinos.github.io/bambi/" target="_blank">https://bambinos.github.io/bambi/</a></li><li class="ql-align-justify">On Being Certain: Believing You Are Right Even When You're Not: <a href="https://www.amazon.com/Being-Certain-Believing-Right-Youre/dp/031254152X" target="_blank">https://www.amazon.com/Being-Certain-Believing-Right-Youre/dp/031254152X</a></li></ul><br/><p><u>Abstract</u></p><p><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p>In this episode, you meet the man behind the code. Namely, Bob Carpenter, one of the core developers of STAN, a popular statistical programming language.&nbsp;</p><p>After working in computational linguistic for some time, Bob became a PostDoc with Andrew Gellman to really learn Statistics and Modelling.</p><p>There he and a small team developed the first implementation of STAN. We talk about the challenges associated with the team growing and the Open Source conventions.&nbsp;</p><p>Besides the initial intention behind and the beginning of STAN, we talk about the future of probabilistic programming.</p><p>Creating a tool for people with different degrees of mathematics and programming knowledge is a big challenge and working with these tools may also be more difficult for the user.</p><p class="ql-align-justify">We discuss why Bayesian statistical programming is popular nonetheless and what makes it uniquely adequate for research.</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/76-past-present-future-of-stan-bob-carpenter]]></link><guid isPermaLink="false">f49be46c-1294-4ee5-b8e7-3bbbdabf3126</guid><itunes:image href="https://artwork.captivate.fm/49b0a571-d60f-4805-9f7d-cab55556c379/F_OAwqiKXbiGUOBVmnS4lcSe.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 01 Feb 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/357c5ec7-8a6e-417e-a01c-1f0a7f598329/Learning-Bayesian-Statistics-76.mp3" length="68162476" type="audio/mpeg"/><itunes:duration>01:11:10</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>76</itunes:episode><itunes:season>1</itunes:season><podcast:episode>76</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How does it feel to switch careers and start a postdoc at age 47? How was it to be one of the people who created the probabilistic programming language Stan? What should the Bayesian community focus on in the coming years?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/1750092f-ca4e-4e35-9d17-d9999363844f/index.html" type="text/html"/></item><item><title>#75 The Physics of Top Gun 2 Maverick, with Jason Berndt</title><itunes:title>The Physics of Top Gun 2 Maverick, with Jason Berndt</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">If you’re a nerd like me, you’re always curious about the physics of any situation. So, obviously, when I watched Top Gun 2, I became fascinated by the aerodynamics of fighters jets. And it so happens that one of my friends used to be a fighter pilot for the Canadian army… Immediately, I thought this would make for a cool episode — and here we are!</p><p class="ql-align-justify">Actually, Jason Berndt wanted to be a pilot from the age of 3. When he was 6, he went to an air show, and then specifically wanted to become a fighter pilot. In his teens, he learned how to fly saliplanes, small single engine aircrafts. At age 22, he got a bachelor’s in aero engineering from the royal military college, and then — well, he’ll tell you the rest in the episode.</p><p class="ql-align-justify">Now in his thirties, he owns real estate and created his own company, My Two Brows, selling temporary eyebrow tattoos — which, weirdly enough, is actually related to his time in the army…</p><p class="ql-align-justify">In his free time, Jason plays the guitar, travels around the world (that’s actually how we met), and loves chasing adrenaline however he can (paragliding, scuba diving, you name it!).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin and Raphaël R.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>My Two Brows website: <a href="https://mytwobrows.com/" target="_blank">https://mytwobrows.com/</a></li><li>My Two Brows on Instagram: <a href="https://www.instagram.com/my_two_brows/" target="_blank">https://www.instagram.com/my_two_brows/</a></li><li>My Two Brows on YouTube: <a href="https://www.youtube.com/channel/UC6eQgQ4qoGE2RStDJkumUGg" target="_blank">https://www.youtube.com/channel/UC6eQgQ4qoGE2RStDJkumUGg</a></li><li class="ql-align-justify">PyMC Labs Workshop –&nbsp;Hierarchical Bayesian Modeling of Survey Data with Post-stratification: <a href="https://www.youtube.com/watch?v=efID35XUQ3I"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">If you’re a nerd like me, you’re always curious about the physics of any situation. So, obviously, when I watched Top Gun 2, I became fascinated by the aerodynamics of fighters jets. And it so happens that one of my friends used to be a fighter pilot for the Canadian army… Immediately, I thought this would make for a cool episode — and here we are!</p><p class="ql-align-justify">Actually, Jason Berndt wanted to be a pilot from the age of 3. When he was 6, he went to an air show, and then specifically wanted to become a fighter pilot. In his teens, he learned how to fly saliplanes, small single engine aircrafts. At age 22, he got a bachelor’s in aero engineering from the royal military college, and then — well, he’ll tell you the rest in the episode.</p><p class="ql-align-justify">Now in his thirties, he owns real estate and created his own company, My Two Brows, selling temporary eyebrow tattoos — which, weirdly enough, is actually related to his time in the army…</p><p class="ql-align-justify">In his free time, Jason plays the guitar, travels around the world (that’s actually how we met), and loves chasing adrenaline however he can (paragliding, scuba diving, you name it!).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey, Andreas Kröpelin and Raphaël R.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li>My Two Brows website: <a href="https://mytwobrows.com/" target="_blank">https://mytwobrows.com/</a></li><li>My Two Brows on Instagram: <a href="https://www.instagram.com/my_two_brows/" target="_blank">https://www.instagram.com/my_two_brows/</a></li><li>My Two Brows on YouTube: <a href="https://www.youtube.com/channel/UC6eQgQ4qoGE2RStDJkumUGg" target="_blank">https://www.youtube.com/channel/UC6eQgQ4qoGE2RStDJkumUGg</a></li><li class="ql-align-justify">PyMC Labs Workshop –&nbsp;Hierarchical Bayesian Modeling of Survey Data with Post-stratification: <a href="https://www.youtube.com/watch?v=efID35XUQ3I" target="_blank">https://www.youtube.com/watch?v=efID35XUQ3I</a></li></ul><br/><p class="ql-align-justify"><br></p><p class="ql-align-justify"><strong>Abstract</strong></p><p><a href="https://christophbg.github.io" target="_blank"><em>written by Christoph Bamberg</em></a></p><p>In this episode of the Learning bayesian statistics podcast we do not talk about Bayesianism, let alone statistics. Instead we dive into the world of fighter jets and Top Gun pilots with Jason Berndt.&nbsp;</p><p>Jason is a former fighter jet pilot turned entrepreneur. He looks back at his time as a pilot, how he got there, the challenges and thrills of this job and how it influences him now in his new life.&nbsp;</p><p>We also touch upon physics and science related aspects like G-force, centrifugal power, automation in critical environments like flying a fighter jet and human-computer interaction.</p><p class="ql-align-justify">Jason discusses the recent movie Top Gun: Maverick and how realistic the flying was as well as the description of the fighter pilots’ lives.</p><p class="ql-align-justify"><br></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/75-the-physics-of-top-gun-2-maverick-jason-berndt]]></link><guid isPermaLink="false">0cb5baac-5d67-4e6a-9d62-1c8d3638c61a</guid><itunes:image href="https://artwork.captivate.fm/4556f3b1-0181-4cff-af18-94f5a15117cf/bALDO1B8nvNMp0wJLBIYqe1x.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 20 Jan 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/8cbe95c1-2a33-4a0d-995b-a9900388c842/Learning-Bayesian-Statistics-75.mp3" length="64591705" type="audio/mpeg"/><itunes:duration>01:07:26</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>75</itunes:episode><itunes:season>1</itunes:season><podcast:episode>75</podcast:episode><podcast:season>1</podcast:season><itunes:summary>If you’re a nerd like me, you’re always curious about the physics of any situation. So, obviously, when I watched Top Gun 2, I became fascinated by the aerodynamics of fighters jets. And it so happens that one of my friends used to be a fighter pilot for the Canadian army… Immediately, I thought this would make for a cool episode — and here we are!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/1f6ede32-450c-4c63-8459-db5a3f59b749/index.html" type="text/html"/></item><item><title>#74 Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt</title><itunes:title>Optimizing NUTS and Developing the ZeroSumNormal Distribution, with Adrian Seyboldt</itunes:title><description><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">We need to talk. I had trouble writing this introduction. Not because I didn’t know what to say (that’s hardly ever an issue for me), but because a conversation with Adrian Seyboldt always takes deliciously unexpected turns.</p><p class="ql-align-justify">Adrian is one of the most brilliant, interesting and open-minded person I know. It turns out he’s courageous too: although he’s not a fan of public speaking, he accepted my invitation on this show — and I’m really glad he did!</p><p class="ql-align-justify">Adrian studied math and bioinformatics in Germany and now lives in the US, where he enjoys doing maths, baking bread and hiking.</p><p class="ql-align-justify">We talked about the why and how of his new project, Nutpie, a more efficient implementation of the NUTS sampler in Rust. We also dived deep into the new ZeroSumNormal distribution he created and that’s available from PyMC 4.2 onwards — what is it? Why would you use it? And when?</p><p class="ql-align-justify">Adrian will also tell us about his favorite type of models, as well as what he currently sees as the biggest hurdles in the Bayesian workflow.</p><p class="ql-align-justify">Each time I talk with Adrian, I learn a lot and am filled with enthusiasm — and now I hope you will too!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey and Andreas Kröpelin</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">LBS on Twitter: <a href="https://twitter.com/LearnBayesStats" target="_blank">https://twitter.com/LearnBayesStats</a></li><li class="ql-align-justify">LBS on Linkedin: <a href="https://www.linkedin.com/company/learn-bayes-stats/" target="_blank">https://www.linkedin.com/company/learn-bayes-stats/</a></li><li class="ql-align-justify">Adrian on GitHub: <a href="https://github.com/aseyboldt" target="_blank">https://github.com/aseyboldt</a></li><li class="ql-align-justify">Nutpie repository: <a...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">We need to talk. I had trouble writing this introduction. Not because I didn’t know what to say (that’s hardly ever an issue for me), but because a conversation with Adrian Seyboldt always takes deliciously unexpected turns.</p><p class="ql-align-justify">Adrian is one of the most brilliant, interesting and open-minded person I know. It turns out he’s courageous too: although he’s not a fan of public speaking, he accepted my invitation on this show — and I’m really glad he did!</p><p class="ql-align-justify">Adrian studied math and bioinformatics in Germany and now lives in the US, where he enjoys doing maths, baking bread and hiking.</p><p class="ql-align-justify">We talked about the why and how of his new project, Nutpie, a more efficient implementation of the NUTS sampler in Rust. We also dived deep into the new ZeroSumNormal distribution he created and that’s available from PyMC 4.2 onwards — what is it? Why would you use it? And when?</p><p class="ql-align-justify">Adrian will also tell us about his favorite type of models, as well as what he currently sees as the biggest hurdles in the Bayesian workflow.</p><p class="ql-align-justify">Each time I talk with Adrian, I learn a lot and am filled with enthusiasm — and now I hope you will too!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox, Trey Causey and Andreas Kröpelin</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">LBS on Twitter: <a href="https://twitter.com/LearnBayesStats" target="_blank">https://twitter.com/LearnBayesStats</a></li><li class="ql-align-justify">LBS on Linkedin: <a href="https://www.linkedin.com/company/learn-bayes-stats/" target="_blank">https://www.linkedin.com/company/learn-bayes-stats/</a></li><li class="ql-align-justify">Adrian on GitHub: <a href="https://github.com/aseyboldt" target="_blank">https://github.com/aseyboldt</a></li><li class="ql-align-justify">Nutpie repository: <a href="https://github.com/pymc-devs/nutpie" target="_blank">https://github.com/pymc-devs/nutpie</a></li><li class="ql-align-justify">ZeroSumNormal distribution: <a href="https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.ZeroSumNormal.html" target="_blank">https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.ZeroSumNormal.html</a></li><li class="ql-align-justify">Pathfinder – A parallel quasi-Newton algorithm for reaching regions of high probability mass: <a href="https://statmodeling.stat.columbia.edu/2021/08/10/pathfinder-a-parallel-quasi-newton-algorithm-for-reaching-regions-of-high-probability-mass/" target="_blank">https://statmodeling.stat.columbia.edu/2021/08/10/pathfinder-a-parallel-quasi-newton-algorithm-for-reaching-regions-of-high-probability-mass/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p><a href="https://christophbg.github.io" target="_blank"><em>by Christoph Bamberg</em></a></p><p>Adrian Seyboldt, the guest of this week’s episode, is an active developer of the PyMC library in Python and his new tool nutpie in Rust. He is also a colleague at PyMC-Labs and friend. So naturally, this episode gets technical and nerdy.&nbsp;</p><p>We talk about parametrisation, a topic important for anyone trying to implement a Bayesian model and what to do or avoid (don't use the mean of the data!).&nbsp;</p><p>Adrian explains a new approach to setting categorical parameters, using the Zero Sum Normal Distribution that he developed. The approach is explained in an accessible way with examples, so everyone can understand and implement it themselves.</p><p class="ql-align-justify">We also talked about further technical topics like initialising a sampler, the use of warm-up samples, mass matrix adaptation and much more. The difference between probability theory and statistics as well as his view on the challenges in Bayesian statistics complete the episode.&nbsp;</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/74-optimizing-nuts-developing-zerosumnormal-distribution-adrian-seyboldt]]></link><guid isPermaLink="false">d73f36a3-1d36-48b6-8681-1f71c16b8fbc</guid><itunes:image href="https://artwork.captivate.fm/67af0560-0392-4b4d-8ab8-f99a791aa377/KLSDMp20lI0dIIIlt6xtAXe2.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 05 Jan 2023 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/bea67440-71ca-4385-b5d6-e791009a2a8b/Learning-Bayesian-Statistics-74.mp3" length="69217486" type="audio/mpeg"/><itunes:duration>01:12:16</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>74</itunes:episode><itunes:season>1</itunes:season><podcast:episode>74</podcast:episode><podcast:season>1</podcast:season><itunes:summary>We talked about the why and how of his new project, Nutpie, a more efficient implementation of the NUTS sampler in Rust. We also dived deep into the new ZeroSumNormal distribution he created and that’s available from PyMC 4.2 onwards — what is it? Why would you use it? And when?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/5d86b6aa-040b-4beb-ba97-22c6459da0ea/index.html" type="text/html"/></item><item><title>#73 A Guide to Plotting Inferences &amp; Uncertainties of Bayesian Models, with Jessica Hullman</title><itunes:title>A Guide to Plotting Inferences &amp; Uncertainties of Bayesian Models, with Jessica Hullman</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m guessing you already tried to communicate the results of a statistical model to non-stats people — it’s hard, right? I’ll be honest: sometimes, I even prefer to take notes during meetings than doing that… But shhh, that’s out secret.</p><p class="ql-align-justify">But all of this was before. Before I talked with Jessica Hullman. Jessica is the Ginny Rometty associate professor of computer science at Northwestern University.</p><p class="ql-align-justify">Her work revolves around how to design interfaces to help people draw inductive inferences from data. Her research has explored how to best align data-driven interfaces and representations of uncertainty with human reasoning capabilities, which is what we’ll mainly talk about in this episode.</p><p class="ql-align-justify">Jessica also tries to understand the role of interactive analysis across different stages of a statistical workflow, and how to evaluate data visualization interfaces.</p><p class="ql-align-justify">Her work has been awarded with multiple best paper and honorable mention awards, and she frequently speaks and blogs on topics related to visualization and reasoning about uncertainty — as usual, you’ll find the links in the show notes.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox and Trey Causey</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>General links from the show:</strong></p><ul><li class="ql-align-justify">Jessica’s website: <a href="http://users.eecs.northwestern.edu/~jhullman/" target="_blank">http://users.eecs.northwestern.edu/~jhullman/</a>&nbsp;</li><li class="ql-align-justify">Jessica on Twitter: <a href="https://twitter.com/JessicaHullman" target="_blank">https://twitter.com/JessicaHullman</a></li><li class="ql-align-justify">Midwest Uncertainty Collective: <a href="https://mucollective.northwestern.edu/" target="_blank">https://mucollective.northwestern.edu/</a></li><li class="ql-align-justify">Jessica’s posts on Andrew Gelman’s blog: <a...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m guessing you already tried to communicate the results of a statistical model to non-stats people — it’s hard, right? I’ll be honest: sometimes, I even prefer to take notes during meetings than doing that… But shhh, that’s out secret.</p><p class="ql-align-justify">But all of this was before. Before I talked with Jessica Hullman. Jessica is the Ginny Rometty associate professor of computer science at Northwestern University.</p><p class="ql-align-justify">Her work revolves around how to design interfaces to help people draw inductive inferences from data. Her research has explored how to best align data-driven interfaces and representations of uncertainty with human reasoning capabilities, which is what we’ll mainly talk about in this episode.</p><p class="ql-align-justify">Jessica also tries to understand the role of interactive analysis across different stages of a statistical workflow, and how to evaluate data visualization interfaces.</p><p class="ql-align-justify">Her work has been awarded with multiple best paper and honorable mention awards, and she frequently speaks and blogs on topics related to visualization and reasoning about uncertainty — as usual, you’ll find the links in the show notes.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek, Paul Cox and Trey Causey</em>.</p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>General links from the show:</strong></p><ul><li class="ql-align-justify">Jessica’s website: <a href="http://users.eecs.northwestern.edu/~jhullman/" target="_blank">http://users.eecs.northwestern.edu/~jhullman/</a>&nbsp;</li><li class="ql-align-justify">Jessica on Twitter: <a href="https://twitter.com/JessicaHullman" target="_blank">https://twitter.com/JessicaHullman</a></li><li class="ql-align-justify">Midwest Uncertainty Collective: <a href="https://mucollective.northwestern.edu/" target="_blank">https://mucollective.northwestern.edu/</a></li><li class="ql-align-justify">Jessica’s posts on Andrew Gelman’s blog: <a href="https://statmodeling.stat.columbia.edu/" target="_blank">https://statmodeling.stat.columbia.edu/</a></li><li class="ql-align-justify">Jessica’s posts on Medium: <a href="https://medium.com/multiple-views-visualization-research-explained" target="_blank">https://medium.com/multiple-views-visualization-research-explained</a></li><li class="ql-align-justify">LBS # 66, Uncertainty Visualization &amp; Usable Stats, with Matthew Kay: <a href="https://learnbayesstats.com/episode/66-uncertainty-visualization-usable-stats-matthew-kay/" target="_blank">https://learnbayesstats.com/episode/66-uncertainty-visualization-usable-stats-matthew-kay/</a></li></ul><br/><p class="ql-align-justify"><strong>Some of Jessica’s research that she mentioned:</strong></p><ul><li class="ql-align-justify">A Bayesian Model of Cognition to Improve Data Visualization: <a href="https://mucollective.northwestern.edu/files/2019-BayesianVis-CHI.pdf" target="_blank">https://mucollective.northwestern.edu/files/2019-BayesianVis-CHI.pdf</a></li><li class="ql-align-justify">Visual Reasoning Strategies for Effect Size Judgments and Decisions: <a href="https://mucollective.northwestern.edu/files/2020%20-%20Kale,%20Visual%20Reasoning%20Strategies%20for%20Effect%20Size%20Judgements.pdf" target="_blank">https://mucollective.northwestern.edu/files/2020%20-%20Kale,%20Visual%20Reasoning%20Strategies%20for%20Effect%20Size%20Judgements.pdf</a></li><li class="ql-align-justify">Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data: <a href="https://mucollective.northwestern.edu/files/2018-HOPsTrends-InfoVis.pdf" target="_blank">https://mucollective.northwestern.edu/files/2018-HOPsTrends-InfoVis.pdf</a></li></ul><br/><p class="ql-align-justify"><strong>Behavioral economics paper Jessica mentioned:</strong></p><ul><li class="ql-align-justify">A Model of Non-belief in the Law of Large Numbers: <a href="https://scholar.harvard.edu/files/rabin/files/barney2014.pdf" target="_blank">https://scholar.harvard.edu/files/rabin/files/barney2014.pdf</a></li></ul><br/><p class="ql-align-justify"><strong>More on David Blackwell:</strong></p><ul><li class="ql-align-justify">Summary of his career: <a href="https://stat.illinois.edu/news/2020-07-17/david-h-blackwell-profile-inspiration-and-perseverance" target="_blank">https://stat.illinois.edu/news/2020-07-17/david-h-blackwell-profile-inspiration-and-perseverance</a></li><li class="ql-align-justify">His original work on Blackwell ordering: <a href="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-24/issue-2/Equivalent-Comparisons-of-Experiments/10.1214/aoms/1177729032.pdf" target="_blank">https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-24/issue-2/Equivalent-Comparisons-of-Experiments/10.1214/aoms/1177729032.pdf</a></li><li class="ql-align-justify">Lectures on day 5 of this workshop covered his work on approachability: <a href="https://old.simons.berkeley.edu/workshops/schedule/16924" target="_blank">https://old.simons.berkeley.edu/workshops/schedule/16924</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract:</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p class="ql-align-justify">Professor Jessica Hullman from Northwestern University is an expert in designing visualisations that help people learn from data and not fall prey to biases.</p><p class="ql-align-justify">She focuses on the proper communication of uncertainty, both theoretically and empirically.</p><p class="ql-align-justify">She addresses questions like “Can a Bayesian model of reasoning explain apparently biased reasoning?”, “What kind of visualisation guides readers best to a valid inference?”, “How can biased reasoning be so prevalent - are there scenarios where not following the canonical reasoning steps is optimal?”.</p><p class="ql-align-justify">In this episode we talk about her experimental studies on communication of uncertainty through visualisation, in what scenarios it may not be optimal to focus too much on uncertainty and how we can design models of reasoning that can explain actual behaviour and not discard it as biased.&nbsp;</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/73-guide-plotting-inferences-uncertainties-bayesian-models-jessica-hullman]]></link><guid isPermaLink="false">6ae4d4cb-5b94-47a1-8e31-ada93f33484e</guid><itunes:image href="https://artwork.captivate.fm/4436dc61-972d-4561-b570-61ab18c894b9/XVTq6w0TDaY58ExJpm6GQybG.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 23 Dec 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/3bb9e913-9ae9-4ad6-aba4-427ccbb969f8/Learning-Bayesian-Statistics-73.mp3" length="58352134" type="audio/mpeg"/><itunes:duration>01:00:55</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>73</itunes:episode><itunes:season>1</itunes:season><podcast:episode>73</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How to best align data-driven interfaces and representations of uncertainty with human reasoning capabilities</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/4fc99698-9298-41f1-a13d-eb31d3b1cdba/index.html" type="text/html"/></item><item><title>#72 Why the Universe is so Deliciously Crazy, with Daniel Whiteson</title><itunes:title>Why the Universe is so Deliciously Crazy, with Daniel Whiteson</itunes:title><description><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">What happens inside a black hole? Can we travel back in time? Why is the Universe even here? This is the type of chill questions that we’re all asking ourselves from time to time — you know, when we’re sitting on the beach.</p><p class="ql-align-justify">This is also the kind of questions Daniel Whiteson loves to talk about in his podcast, “Daniel and Jorge Explain the Universe”, co-hosted with Jorge Cham, the author of PhD comics. Honestly, it’s one of my favorite shows ever, so I warmly recommend it. Actually, if you’ve ever hung out with me in person, there is a high chance I started nerding out about it…</p><p class="ql-align-justify">Daniel is, of course, a professor of physics, at the University of California, Irvine, and also a researcher at CERN, using the Large Hadron Collider to search for exotic new particles — yes, these are particles that put little umbrellas in their drinks and taste like coconut.</p><p class="ql-align-justify">On his free time, Daniel loves reading, sailing and baking — I can confirm that he makes a killer Nutella roll!</p><p class="ql-align-justify">Oh, I almost forgot: Daniel and Jorge wrote two books — We Have No Idea and FAQ about the Universe — which, again, I strongly recommend. They are among my all-time favorites.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek and Paul Cox.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">PyMC Labs Meetup, Dec 8th 2022, A Candle in the Dark – How to Use Hierarchical Post-Stratification with Noisy Data: <a href="https://www.meetup.com/pymc-labs-online-meetup/events/289949398/" target="_blank">https://www.meetup.com/pymc-labs-online-meetup/events/289949398/</a></li><li class="ql-align-justify">Daniel’s website:&nbsp;<a href="https://sites.uci.edu/daniel/" target="_blank">https://sites.uci.edu/daniel/</a></li><li class="ql-align-justify">Daniel on Twitter: <a...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">What happens inside a black hole? Can we travel back in time? Why is the Universe even here? This is the type of chill questions that we’re all asking ourselves from time to time — you know, when we’re sitting on the beach.</p><p class="ql-align-justify">This is also the kind of questions Daniel Whiteson loves to talk about in his podcast, “Daniel and Jorge Explain the Universe”, co-hosted with Jorge Cham, the author of PhD comics. Honestly, it’s one of my favorite shows ever, so I warmly recommend it. Actually, if you’ve ever hung out with me in person, there is a high chance I started nerding out about it…</p><p class="ql-align-justify">Daniel is, of course, a professor of physics, at the University of California, Irvine, and also a researcher at CERN, using the Large Hadron Collider to search for exotic new particles — yes, these are particles that put little umbrellas in their drinks and taste like coconut.</p><p class="ql-align-justify">On his free time, Daniel loves reading, sailing and baking — I can confirm that he makes a killer Nutella roll!</p><p class="ql-align-justify">Oh, I almost forgot: Daniel and Jorge wrote two books — We Have No Idea and FAQ about the Universe — which, again, I strongly recommend. They are among my all-time favorites.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bert≈rand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek and Paul Cox.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">PyMC Labs Meetup, Dec 8th 2022, A Candle in the Dark – How to Use Hierarchical Post-Stratification with Noisy Data: <a href="https://www.meetup.com/pymc-labs-online-meetup/events/289949398/" target="_blank">https://www.meetup.com/pymc-labs-online-meetup/events/289949398/</a></li><li class="ql-align-justify">Daniel’s website:&nbsp;<a href="https://sites.uci.edu/daniel/" target="_blank">https://sites.uci.edu/daniel/</a></li><li class="ql-align-justify">Daniel on Twitter: <a href="https://twitter.com/DanielWhiteson" target="_blank">https://twitter.com/DanielWhiteson</a></li><li class="ql-align-justify">“Daniel and Jorge Explain the Universe”: <a href="https://sites.uci.edu/danielandjorge/?pname=danielandjorge.com&amp;sc=dnsredirect" target="_blank">https://sites.uci.edu/danielandjorge/?pname=danielandjorge.com&amp;sc=dnsredirect</a></li><li class="ql-align-justify"><em>We Have No Idea – A Guide To The Unknown Universe</em>: <a href="https://phdcomics.com/noidea/" target="_blank">https://phdcomics.com/noidea/</a></li><li class="ql-align-justify"><em>Frequently Asked Questions About The Universe</em>: <a href="https://sites.uci.edu/universefaq/" target="_blank">https://sites.uci.edu/universefaq/</a></li><li class="ql-align-justify">Learning to Identify Semi-Visible Jets: <a href="https://arxiv.org/abs/2208.10062" target="_blank">https://arxiv.org/abs/2208.10062</a></li><li class="ql-align-justify">Twitter thread about the paper above: <a href="https://twitter.com/DanielWhiteson/status/1561929005653057536" target="_blank">https://twitter.com/DanielWhiteson/status/1561929005653057536</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" target="_blank"><em>Christoph Bamberg</em></a></p><p class="ql-align-justify">Big questions are tackled in episode 72 of the Learning Bayesian Statistics Podcast: “What is the nature of the universe?”, “What is the role of science?”, “How are findings in physics created and communicated?”, “What is randomness actually?”. This episode’s guest, Daniel Whitesun, is just the right person to address these questions.</p><p class="ql-align-justify">He is well-known for his own podcast “Daniel and Jorge Explain the Universe”, wrote several popular science books on physics and works as a particle physicist with data from the particle physics laboratory CERN.</p><p class="ql-align-justify">He manages to make sense of Astrology, although he is not much of a star-gazer himself. Daniel prefers to look for weird stuff in the data of colliding particles and ask unexpected questions.</p><p class="ql-align-justify">This comes with great statistical challenges that he tackles with Bayesian statistics and machine learning, while he also subscribes to the frequentist philosophy of statistics.</p><p class="ql-align-justify">In the episode, Alex and Daniel touch upon many of the great ideas in quantum physics, the Higgs boson, Schrödinger’s cat, John Bell’s quantum entanglement discoveries, true random processes and much more. Mixed in throughout are pieces of advice for anyone scientifically-minded and curious about the universe.</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/72-why-the-universe-is-so-deliciously-crazy-daniel-whiteson]]></link><guid isPermaLink="false">0de17aa2-ccc0-4b20-aad9-1a7c9cf3c18d</guid><itunes:image href="https://artwork.captivate.fm/441f8d53-4b88-4a7f-8641-1900fafcaf7e/W6CDhRXSbS9ctibYVK6JHvfM.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sat, 03 Dec 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f33bbbf0-3e3d-4044-8a60-8924fc171ab5/Learning-Bayesian-Statistics-72.mp3" length="70436377" type="audio/mpeg"/><itunes:duration>01:13:32</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>72</itunes:episode><itunes:season>1</itunes:season><podcast:episode>72</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/1ab4230f-32c8-40e9-a805-1d2ebb87f975/index.html" type="text/html"/></item><item><title>#71 Artificial Intelligence, Deepmind &amp; Social Change, with Julien Cornebise</title><itunes:title>Artificial Intelligence, Deepmind &amp; Social Change, with Julien Cornebise</itunes:title><description><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">This episode will show you different sides of the tech world. The one where you research and apply algorithms, where you get super excited about image recognition and AI-generated art. And the one where you support social change actors — aka the “AI for Good” movement.</p><p class="ql-align-justify">My guest for this episode is, quite naturally, Julien Cornebise. Julien is an Honorary Associate Professor at UCL. He was an early researcher at DeepMind where he designed its early algorithms. He then worked as a Director of Research at ElementAI, where he built and led the London office and “AI for Good” unit.</p><p class="ql-align-justify">After his theoretical work on Bayesian methods, he had the privilege to work with the NHS to diagnose eye diseases; with Amnesty International to quantify abuse on Twitter and find destroyed villages in Darfur; with Forensic Architecture to identify teargas canisters used against civilians.</p><p class="ql-align-justify">Other than that, Julien is an avid reader, and loves dark humor and picking up his son from school at the 'hour of the daddies and the mommies”.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek and Paul Cox.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Julien’s website: <a href="https://cornebise.com/julien/" rel="noopener noreferrer" target="_blank">https://cornebise.com/julien/</a></li><li class="ql-align-justify">Julien on Twitter: <a href="https://twitter.com/JCornebise" rel="noopener noreferrer" target="_blank">https://twitter.com/JCornebise</a></li><li class="ql-align-justify">Julien on LinkedIn: <a href="https://www.linkedin.com/in/juliencornebise/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">This episode will show you different sides of the tech world. The one where you research and apply algorithms, where you get super excited about image recognition and AI-generated art. And the one where you support social change actors — aka the “AI for Good” movement.</p><p class="ql-align-justify">My guest for this episode is, quite naturally, Julien Cornebise. Julien is an Honorary Associate Professor at UCL. He was an early researcher at DeepMind where he designed its early algorithms. He then worked as a Director of Research at ElementAI, where he built and led the London office and “AI for Good” unit.</p><p class="ql-align-justify">After his theoretical work on Bayesian methods, he had the privilege to work with the NHS to diagnose eye diseases; with Amnesty International to quantify abuse on Twitter and find destroyed villages in Darfur; with Forensic Architecture to identify teargas canisters used against civilians.</p><p class="ql-align-justify">Other than that, Julien is an avid reader, and loves dark humor and picking up his son from school at the 'hour of the daddies and the mommies”.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken, Or Duek, Pavel Dusek and Paul Cox.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Julien’s website: <a href="https://cornebise.com/julien/" rel="noopener noreferrer" target="_blank">https://cornebise.com/julien/</a></li><li class="ql-align-justify">Julien on Twitter: <a href="https://twitter.com/JCornebise" rel="noopener noreferrer" target="_blank">https://twitter.com/JCornebise</a></li><li class="ql-align-justify">Julien on LinkedIn: <a href="https://www.linkedin.com/in/juliencornebise/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/juliencornebise/</a>&nbsp;</li><li class="ql-align-justify">Julien on Scholar: <a href="https://scholar.google.co.uk/citations?user=6fkVVz4AAAAJ&amp;hl=en&amp;oi=ao" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/citations?user=6fkVVz4AAAAJ&amp;hl=en&amp;oi=ao</a></li><li class="ql-align-justify">Stable Diffusion is a really big deal:<a href="https://simonwillison.net/2022/Aug/29/stable-diffusion/" rel="noopener noreferrer" target="_blank"> https://simonwillison.net/2022/Aug/29/stable-diffusion/</a></li><li class="ql-align-justify">LBS #21, Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova: <a href="https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova/</a></li><li class="ql-align-justify">pymc.find_constrained_prior function: <a href="https://www.pymc.io/projects/docs/en/stable/api/generated/pymc.find_constrained_prior.html#pymc.find_constrained_prior" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/docs/en/stable/api/generated/pymc.find_constrained_prior.html#pymc.find_constrained_prior</a></li><li class="ql-align-justify">LBS #50, Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter/</a></li><li class="ql-align-justify">LBS #67 Exoplanets, Cool Worlds &amp; Life in the Universe, with David Kipping: <a href="https://learnbayesstats.com/episode/67-exoplanets-cool-worlds-life-in-universe-david-kipping/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/67-exoplanets-cool-worlds-life-in-universe-david-kipping/</a></li></ul><br/><p class="ql-align-justify"><strong>Abstract</strong></p><p class="ql-align-justify"><em>by </em><a href="https://christophbg.github.io" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p class="ql-align-justify">Julien Cornebise goes on a deep dive into deep learning with us in episode 71. He calls himself a “passionate, impact-driven scientist in Machine Learning and Artificial Intelligence”. He holds an Honorary Associate Professor position at UCL, was an early researcher at DeepMind, went on to become Director of Research at ElementAI and worked with institutions ranging from the NHS in Great-Britain to Amnesty International. </p><p class="ql-align-justify">He is a strong advocate for using Artificial Intelligence and computer engineering tools for good and cautions us to think carefully about who we develop models and tools for. Ask the question: What could go wrong? How could this be misused? The list of projects where he used his computing skills for good is long and divers: With the NHS he developed methods to measure and diagnose eye diseases. For Amnesty International he helped quantify the abuse female journalists receive on Twitter, based on a database of tweets labeled by volunteers. </p><p class="ql-align-justify">Beyond these applied projects, Julien and Alex muse about the future of structured models in times of more and more popular deep learning approaches and the fascinating potential of these new approaches. He advices anyone interested in these topics to be comfortable with experimenting by themselves and potentially breaking things in a non-consequential environment. </p><p class="ql-align-justify">And don’t be too intimidated by more seasoned professionals, he adds, because they probably have imposter-syndrome themselves which is a sign of being aware of ones own limitations.&nbsp;</p><p class="ql-align-justify"><strong>Automated Transcript</strong></p><p class="ql-align-justify"><em>Please note that the following transcript was generated automatically and may therefore contain errors. Feel free to </em><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>reach out</em></a><em> if you’re willing to correct them.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/71-artificial-intelligence-deepmind-social-change-julien-cornebise]]></link><guid isPermaLink="false">5c1c9f48-1ba9-498a-882f-64a065c1ec78</guid><itunes:image href="https://artwork.captivate.fm/8b85abc6-6c42-463b-b361-e4d9e75913e8/VzSDQhhRIEkZfkVSeocu8U0s.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 14 Nov 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/05963e2b-aa85-4785-9ba9-e14b02828b53/Learning-20Bayesian-20Statistics-2071-converted.mp3" length="62527573" type="audio/mpeg"/><itunes:duration>01:05:08</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>71</itunes:episode><itunes:season>1</itunes:season><podcast:episode>71</podcast:episode><podcast:season>1</podcast:season><itunes:summary>This episode knuckles down to different sides of the tech world, research, and application of algorithms where you get super excited about image recognition and AI-generated art.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author><podcast:transcript url="https://transcripts.captivate.fm/transcript/990aedee-74d0-4268-9dcd-25e6a1c17e98/index.html" type="text/html"/></item><item><title>#70 Teaching Bayes for Biology &amp; Biological Engineering, with Justin Bois</title><itunes:title>Teaching Bayes for Biology &amp; Biological Engineering, with Justin Bois</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Back in 2016, when I started dedicating my evenings and weekends to learning how to code and do serious stats, I was a bit lost… Where do I start? Which language do I pick? Why are all those languages just named with one single letter??</p><p class="ql-align-justify">Then I found some stats classes by Justin Bois — and it was a tremendous help to get out of that wood (and yes, this was a pun). I really loved Justin’s teaching because he was making the assumptions explicit, and also explained them — which was so much more satisfying to my nerdy brain, which always wonders why we’re making this assumption and not that one.</p><p class="ql-align-justify">So of course, I’m thrilled to be hosting Justin on the show today! Justin is a Teaching Professor in the Division of Biology and Biological Engineering at Caltech, California, where he also did his PhD. Before that, he was a postdoc in biochemistry at UCLA, as well as the Max Planck Institute in Dresden, Germany.</p><p class="ql-align-justify">Most importantly for the football fans, he’s a goalkeeper — actually, the day before recording, he saved two penalty kicks… and even scored a goal! A big fan of Los Angeles football club, Justin is a also a magic enthusiast — he is indeed a member of the Magic Castle…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken and Or Duek.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong class="ql-size-large">Links from the show:</strong></p><ul><li class="ql-align-justify">Justin’s website: <a href="http://bois.caltech.edu/index.html" rel="noopener noreferrer" target="_blank">http://bois.caltech.edu/index.html</a>&nbsp;</li><li class="ql-align-justify">Justin on GitHub: <a href="https://github.com/justinbois/" rel="noopener noreferrer" target="_blank">https://github.com/justinbois/</a></li><li...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Back in 2016, when I started dedicating my evenings and weekends to learning how to code and do serious stats, I was a bit lost… Where do I start? Which language do I pick? Why are all those languages just named with one single letter??</p><p class="ql-align-justify">Then I found some stats classes by Justin Bois — and it was a tremendous help to get out of that wood (and yes, this was a pun). I really loved Justin’s teaching because he was making the assumptions explicit, and also explained them — which was so much more satisfying to my nerdy brain, which always wonders why we’re making this assumption and not that one.</p><p class="ql-align-justify">So of course, I’m thrilled to be hosting Justin on the show today! Justin is a Teaching Professor in the Division of Biology and Biological Engineering at Caltech, California, where he also did his PhD. Before that, he was a postdoc in biochemistry at UCLA, as well as the Max Planck Institute in Dresden, Germany.</p><p class="ql-align-justify">Most importantly for the football fans, he’s a goalkeeper — actually, the day before recording, he saved two penalty kicks… and even scored a goal! A big fan of Los Angeles football club, Justin is a also a magic enthusiast — he is indeed a member of the Magic Castle…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas, Robert Yolken and Or Duek.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong class="ql-size-large">Links from the show:</strong></p><ul><li class="ql-align-justify">Justin’s website: <a href="http://bois.caltech.edu/index.html" rel="noopener noreferrer" target="_blank">http://bois.caltech.edu/index.html</a>&nbsp;</li><li class="ql-align-justify">Justin on GitHub: <a href="https://github.com/justinbois/" rel="noopener noreferrer" target="_blank">https://github.com/justinbois/</a></li><li class="ql-align-justify">Justin’s course on Data analysis with frequentist inference: <a href="https://bebi103a.github.io/" rel="noopener noreferrer" target="_blank">https://bebi103a.github.io/</a></li><li class="ql-align-justify">Justin’s course on Bayesian inference: <a href="https://bebi103b.github.io/" rel="noopener noreferrer" target="_blank">https://bebi103b.github.io/</a></li><li class="ql-align-justify">LBS #6, A principled Bayesian workflow, with Michael Betancourt:&nbsp; <a href="https://learnbayesstats.com/episode/6-a-principled-bayesian-workflow-with-michael-betancourt/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/6-a-principled-bayesian-workflow-with-michael-betancourt/</a></li><li class="ql-align-justify">Physical Biology of the Cell: <a href="https://www.routledge.com/Physical-Biology-of-the-Cell/Phillips-Kondev-Theriot-Garcia-Phillips-Kondev-Theriot-Garcia/p/book/9780815344506" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Physical-Biology-of-the-Cell/Phillips-Kondev-Theriot-Garcia-Phillips-Kondev-Theriot-Garcia/p/book/9780815344506</a></li><li class="ql-align-justify">Knowledge Illusion – Why We Never Think Alone: <a href="https://www.amazon.fr/Knowledge-Illusion-Never-Think-Alone/dp/039918435XThe" rel="noopener noreferrer" target="_blank">https://www.amazon.fr/Knowledge-Illusion-Never-Think-Alone/dp/039918435XThe</a></li><li class="ql-align-justify">Sustainable Energy – Without the Hot Air: <a href="https://www.amazon.com/Sustainable-Energy-Without-Hot-Air/dp/0954452933" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Sustainable-Energy-Without-Hot-Air/dp/0954452933</a></li><li class="ql-align-justify">Information Theory, Inference and Learning Algorithms: <a href="https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981</a></li></ul><br/><p class="ql-align-justify"><strong class="ql-size-large">Abstract</strong></p><p><em>By </em><a href="https://twitter.com/ChrisBrainberg" rel="noopener noreferrer" target="_blank"><em>Christoph Bamberg</em></a></p><p>Justin Bois did his Bachelor and PhD in Chemical Engineering before working as a Postdoctoral Researcher in Biological Physics, Chemistry and Biological Engineering. He now works as a Teaching Professor at the division of Biology and Biological Engineering at Caltech, USA. </p><p>He first got into Bayesian Statistics like many scientists in fields like biology or psychology, by wanting to understand what the statistics actually mean that he was using. His central question was “what is parameter estimation actually?”. After all, that’s a lot of what doing quantitative science is on a daily basis! </p><p>The Bayesian framework allowed him to find an answer and made him feel like a more complete scientist. As a teaching professor, he is now helping students of life sciences such as neuroscience or biological engineering to become true Bayesians. </p><p>His teaching covers what you need to become a proficient Bayesian analyst, from opening datasets to Bayesian inference. He emphasizes the importance of models implicit in quantitative research and shows that we do in most cases have a prior idea of an estimand’s magnitude. </p><p>Justin believes that we are naturally programmed to think in a Bayesian framework but still should mess up sometimes to learn that statistical techniques are fragile. You can find some of his teaching on <a href="http://bois.caltech.edu/teaching.html" rel="noopener noreferrer" target="_blank">his website</a>.</p><p class="ql-align-justify"><strong class="ql-size-large">Transcript</strong></p><p class="ql-align-justify"><em>This transcript was generated automatically. Some transcription errors may have remained. Feel free to </em><a href="https://twitter.com/LearnBayesStats" rel="noopener noreferrer" target="_blank"><em>reach out</em></a><em> if you're willing to correct them.</em></p><p>[00:00:00] In 2016, when I started dedicating my evenings and weekends to learning how to code and do serious stats, I was a bit lost, to be honest. Where do I start? Which language do I speak? Why are all those languages just named with one single letter, like R or C? Then I found some stats classes by just in voice.</p><p>And it was a tremendous help to get out of that wood. And yes, this was a pun. I really enjoyed Justine's teaching because he was making the assumptions explicit, and he also explained them, which was so much more satisfying to my minority brain, which always wonders why we're making this assumption and not that one.</p><p>So of course, I'm thrilled to be hosting Justin on the show today. Justin is a teaching professor in the division of biology and biological engineering at Caltech, California, where he also did his PhD. Before that, he was a postdoc in biochemistry at UCLA as well as the Max Plan Institute in Tris, Germany.</p><p>Most importantly, for the football fans, Justin is a goalkeeper. [00:01:00] Actually, the day before recording, he saved two penalty, penalty, kicks, and even scored a goal. Yes, a big fan of Los Angeles's football club. Justine is also a magic enthusiast. He is indeed a member of the Magic Castle. This is Learning Patient Statistics.</p><p>Ex episode 70, recorded September 2nd, 2022. Welcome to Learning Patient Statistics, a fortnightly podcast on Beijing Inference, The methods project in the People who Make Impossible. I'm your host, Alex Andora. You can follow me Twitter at ann underscore like the country. For any info about the podcast, learn base stats.com is lap less to be Show notes becoming corporate sponsor supporting lbs and Pat.</p><p>Unlocking base merge, everything is in there. That's learn base dance.com. If with all that info, a model is still resisting you, or if you find my voice special, smooth and [00:02:00] want me to come and teach patient stats in company, then reach out at alex.andorra@pymc-labs.io or book call with me at <a href="https://learnbayesstats.com/" rel="noopener noreferrer" target="_blank">learnbayesstats.com</a>.</p><p>Thanks a lot folks. And best patient wish shes to you old. Let me show you how to be a good bla and change your predictions after taking information and, and if you're thinking they'll be less than amazing, let's adjust those expectations. What's a basian is someone who cares about evidence and doesn't jump to assumptions based on intuitions and prejudice.</p><p>Abassian makes predictions on the best available info and adjusts the probability cuz every belief is provisional. And when I kick a flow, mostly I'm watching eyes widen. Maybe cuz my likeness lowers expectations of tight ryman. How would I know unless I'm Ryman in front of a bunch of blind men, drop in placebo controlled science like I'm Richard Feinman, just in boys.</p><p>Welcome to Learning Patient St Sticks. Thank you. Happy to be here. Yes. Very [00:03:00] happy to have you here because, well, you know that, but listeners do not. But you are actually one of the first people who introduced me back to, uh, statistics and programming in 2017 when I started my Carrie Shift. So it's awesome to have you here today.</p><p>I'm glad my stuff helped you get going. That's, that's the point. That's the goal. Yeah. Yeah, that's really cool. And also, I'm happy to have learned how you pronounce your last name because in French, you know, that's a French name. I dunno if you have some French origin, but in French it means, I know, I know it's a French name, but it's actually, as far as I understand, my family's from Northern Germany and there's a, a name there that's spelled b e u s s, like, and it's pronounced like in Germany, you say Boce.</p><p>And then it got anglicized, I think when I moved to the US but uh, I was actually recently, just this past summer in Luanne, Switzerland, and there was a giant wood recycling bin. With my name on it, , it said d i s. So I got my picture taken next to that. So yeah. Yeah. Lo Zen is in the French speaking part of Switzerland.[00:04:00] </p><p>That's right. Cool. So we're starting already with the origin story, so I love that cuz it's actually always my first question. So how did you jump to the stats in biology worlds and like how Senior of a Pass read it? Well, I think the path that I had toward really thinking carefully about statistical inferences is a very common path among scientists, meaning scientists outside of data scientists and, and maybe also outside of really data rich branches of sciences such as astronomy.</p><p>So I studied chemical engineering as an undergraduate. It was a standard program. I didn't really do any undergrad research or anything, but I got into a little bit of statistics when I had a job at Kraft Foods. After undergraduate where I worked at the statistician on doing some predictive modeling about, uh, some food safety issues.</p><p>And I thought it was interesting, but I sort of just, I was an engineer. I was making the product, I was implementing the stuff in the production facility and the statistician kind of took care of [00:05:00] everything else. I thought, I thought he was one of the coolest people in the company, . Um, but I didn't really, you know, it didn't really hook me in to really thinking about that.</p><p>But I went and did a PhD and my PhD really didn't involve really much experimentation at all. I was actually doing computational modeling of like how nucleic acids get their structure and shape and things. And that was, it just didn't really involve analysis of much data. Then in my post-doctoral studies, in my post-doctoral work, I was working with some experimentalists who had some data sets and they needed.</p><p>do estimates of parameters based on some theoretical models that I had derived or worked on. And I had done some stuff and you know, various lab classes and stuff, but it's your standard thing. It's like, ooh, I know how to do a cur fit. Meaning I can, I guess in the Python way I would do it, SciPi dot optimized dot cur fit.</p><p>Or you know, in MATLAB I could do at least squares or something like that. And, and I knew this idea of minimizing the sum of the square of the residuals and that's gonna get you [00:06:00] a line that looks close to what your data points are. But the inference problems, the theoretical curves were actually a little bit say for some of 'em.</p><p>There was no close to form solution. They were actually solutions to differential equations. And so the actual theoretical treatment I had was a little bit more complicated. And so I needed to start to think a little bit more carefully about exactly how we're going about estimating the parameters thereof.</p><p>Right? And so I kind of just started grabbing uh, books and I. Discovered quickly that I had no idea what I was doing, , and actually neither did anybody around me. And I don't mean that pejoratively, it's just, it's a very common thing among the scient. A lot of people in the sciences that aren't, that don't work as much with data.</p><p>And perhaps it's less common now, but it's definitely more common than, you know, 10, 15, uh, years ago. And so I just kind of started looking into how we should actually think about the estimates of [00:07:00] parameters given a data set. And really what happened was the problem became crystallized for me, the problem of parameter estimation.</p><p>And I had never actually heard that phrase, perimeter estimation. To me. It was find the best fit per. If your curve goes through your data point, that means that you're, the theory that you derived is probably pretty good. And of course, I didn't think about what the word probably meant there. I, I only knew it colloquially, right?</p><p>And so, cuz I was focused on deriving what the theory is. And of course that's a whole, hugely important part of, of the scientific enterprise. But once you get that theory arrived to try to estimate the parameters of that are present in that theory from measurement, that problem just became clear to me.</p><p>Once I had a clear problem statement, then I was able to start to think about how to solve it. And so the problem statement was, I have a theory that has a set of parameters. I want to try to figure out what the parameters are by taking [00:08:00] some measurements and checking for one set of parameters. The measurements would be different.</p><p>How do I find what parameters there are to, to give me this type, type of data that I observe. I intentionally just stated that awkwardly because that awkwardness there sort of made the, It's funny, it made it clear to me that the problem was unclear . And, and so I, that's what got me into a basian mode of thinking because it was hard for me to wrap my head around what it meant to do that thing that I've been doing all this time.</p><p>This minimizing some squares of residuals and trying to find the best fit parameter. And, you know, in retrospect now I've actually, you know, that I taught myself. Cause I didn't really ever have a course in statistical inference or anything like that, say Okay. I was essentially doing a maximum likelihood estimation, which is a f way of doing prime destination.</p><p>And I, and I hadn't actually thought about what that meant. I mean, I understand that now. We don't really need to talk [00:09:00] about that since we're talking about BA stuff now, but, and it was just harder for me to wrap my head around what that meant. And so I started reading. About the basing interpretation of probability, and it was really, it really just crystallized everything and made it clear, and then I could state the problem much more clearly.</p><p>The problem was I was trying to find a posterior probability density function for these parameters given the data, and that was just so much clearly stated in Baying framework, and then that kinda lit me on fire because I was like, Holy cow, this thing that we do so often in the scientific enterprise, I can actually state the question , right?</p><p>And I just thought that was such a profound moment, and then I was kind of hooked from there on out and I, I was concent trying to improve how I thought about these things. And yeah, so I did a lot of reading. I realized I just talked a lot. You probably have [00:10:00] some questions about some of the stuff I just said, so please.</p><p>Oh yeah, well wait. But, um, I mean, that's good to have a, an overview like that. And so I guess that's also like, it sounds like you were introduced to patient statistics at the same time as you were doing that deep dive into, wait, like, I'm not sure I understand what I'm using then. Oh, actually I don't understand anything and then I have to learn about that.</p><p>But it seems that you, you were also introduced to patient stats at that same time, Is that right? Yeah, I think so. And I think this is actually sort of a classic way in which scientists come up with what it is that they want to study. Because instead you start poking around, you kind of don't really know where the holes in your knowledge are.</p><p>And so what I saw was like just a giant hole in my knowledge and my toolbox, and I saw the hole and I said, All right, let's fill it . And um, and so then I just started feeling around on how to do that. I see. And I am also curious as [00:11:00] to, and what motivated you to dive into the Beijing way of doing things?</p><p>I really do think it was the clarity. I think that, Okay. I think that arguing about like what interpretation or probability you wanna use is not the most fruitful way to spend one's time. For me, it was really, it was just so much more intuitive. I felt like I could have this interpretation of probability that it's, it's a quantification of the plausibility of a logical conjecture of any logical conjecture gave me sort of the flexibility where I could think about like a...]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/70-teaching-bayes-biological-engineering-justin-bois]]></link><guid isPermaLink="false">fad5212c-0b11-4426-9be4-69919948f6ee</guid><itunes:image href="https://artwork.captivate.fm/1627c144-d84f-4286-8d46-bac303c8cc85/ZLrpMLSoVKNdylptorxlaq9w.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sat, 22 Oct 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/61205b86-6bf5-481c-92f0-9a3a209dc62f/Learning-20Bayesian-20Statistics-2070-converted.mp3" length="62897049" type="audio/mpeg"/><itunes:duration>01:05:31</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>70</itunes:episode><itunes:season>1</itunes:season><podcast:episode>70</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Justin bois, Professor of Biology at Caltech, tells us about why stats is helpful for biological studies, and how to best teach it</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#69 Why, When &amp; How to use Bayes Factors, with Jorge Tendeiro</title><itunes:title>Why, When &amp; How to use Bayes Factors, with Jorge Tendeiro</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">A great franchise comes with a great rivalry: Marvel has Iron Man and Captain America; physics has General Relativity and Quantum Physics; and Bayesian stats has Posterior Estimation and… Bayes Factors!</p><p class="ql-align-justify">A few months ago, I had the pleasure of hosting EJ Wagenmakers, to talk about these topics. This time, I’m talking with Jorge Tendeiro, who has a different perspective on Null Hypothesis Testing in the Bayesian framework, and its relationship with generative models and posterior estimation.</p><p class="ql-align-justify">But this is not your classic, click-baity podcast, and I’m not interested in pitching people against each other. Instead, you’ll hear Jorge talk about the other perspective fairly, before even giving his take on the topic. Jorge will also tell us about the difficulty of arguing through papers, and all the nuances you lose compared to casual discussions.</p><p class="ql-align-justify">But who is Jorge Tendeiro? He is a professor at Hiroshima University in Japan, and he was recommended to me by Pablo Bernabeu, a listener of this very podcast.</p><p class="ql-align-justify">Before moving to Japan, Jorge studied math and applied stats at the University of Porto, and did his PhD in the Netherlands. He focuses on item response theory (specifically person fit analysis), and, of course, Bayesian statistics, mostly Bayes factors.</p><p>He’s also passionate about privacy issues in the 21st century, an avid Linux user since 2006, and is trying to get the hang of the Japanese language.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Jorge’s website: <a href="https://www.jorgetendeiro.com/" rel="noopener noreferrer" target="_blank">https://www.jorgetendeiro.com/</a></li><li...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">A great franchise comes with a great rivalry: Marvel has Iron Man and Captain America; physics has General Relativity and Quantum Physics; and Bayesian stats has Posterior Estimation and… Bayes Factors!</p><p class="ql-align-justify">A few months ago, I had the pleasure of hosting EJ Wagenmakers, to talk about these topics. This time, I’m talking with Jorge Tendeiro, who has a different perspective on Null Hypothesis Testing in the Bayesian framework, and its relationship with generative models and posterior estimation.</p><p class="ql-align-justify">But this is not your classic, click-baity podcast, and I’m not interested in pitching people against each other. Instead, you’ll hear Jorge talk about the other perspective fairly, before even giving his take on the topic. Jorge will also tell us about the difficulty of arguing through papers, and all the nuances you lose compared to casual discussions.</p><p class="ql-align-justify">But who is Jorge Tendeiro? He is a professor at Hiroshima University in Japan, and he was recommended to me by Pablo Bernabeu, a listener of this very podcast.</p><p class="ql-align-justify">Before moving to Japan, Jorge studied math and applied stats at the University of Porto, and did his PhD in the Netherlands. He focuses on item response theory (specifically person fit analysis), and, of course, Bayesian statistics, mostly Bayes factors.</p><p>He’s also passionate about privacy issues in the 21st century, an avid Linux user since 2006, and is trying to get the hang of the Japanese language.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Jorge’s website: <a href="https://www.jorgetendeiro.com/" rel="noopener noreferrer" target="_blank">https://www.jorgetendeiro.com/</a></li><li class="ql-align-justify">Jorge on Twitter: <a href="https://twitter.com/jntendeiro" rel="noopener noreferrer" target="_blank">https://twitter.com/jntendeiro</a></li><li class="ql-align-justify">Jorge on GitHub: <a href="https://github.com/jorgetendeiro" rel="noopener noreferrer" target="_blank">https://github.com/jorgetendeiro</a></li><li class="ql-align-justify">A Review of Issues About Null Hypothesis Bayesian Testing:&nbsp; <a href="https://pure.rug.nl/ws/portalfiles/portal/159021509/2019_26880_001.pdf" rel="noopener noreferrer" target="_blank">https://pure.rug.nl/ws/portalfiles/portal/159021509/2019_26880_001.pdf</a></li><li class="ql-align-justify">Advantages Masquerading as ‘Issues’ in Bayesian Hypothesis Testing – A Commentary on Tendeiro and Kiers: <a href="https://psyarxiv.com/nf7rp" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/nf7rp</a></li><li class="ql-align-justify">On the white, the black, and the many shades of gray in between – Our reply to van Ravenzwaaij and Wagenmakers: <a href="https://psyarxiv.com/tjxvz/" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/tjxvz/</a></li><li class="ql-align-justify">LBS #61, Why we still use non-Bayesian methods, with EJ Wagenmakers:<a href="https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers/</a></li><li class="ql-align-justify">LBS #67, Exoplanets, Cool Worlds &amp; Life in the Universe, with David Kipping:<a href="https://learnbayesstats.com/episode/67-exoplanets-cool-worlds-life-in-universe-david-kipping/" rel="noopener noreferrer" target="_blank"> https://learnbayesstats.com/episode/67-exoplanets-cool-worlds-life-in-universe-david-kipping/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/69-why-when-how-to-use-bayes-factors-jorge-tendeiro]]></link><guid isPermaLink="false">7ce5251b-fa8c-42aa-a9df-9b65af6626a2</guid><itunes:image href="https://artwork.captivate.fm/59cf4123-7415-4333-8999-b8c149fa1c29/4I8vVUcaMgYeLVOa3rDS-kTp.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 05 Oct 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/0e0e4b44-ba38-4168-93bc-45b599268796/Learning-20Bayesian-20Statistics-2069-converted.mp3" length="51529395" type="audio/mpeg"/><itunes:duration>53:41</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>69</itunes:episode><itunes:season>1</itunes:season><podcast:episode>69</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A discussion about Bayes factors, Null Hypothesis Testing and the best ways to disagree</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#68 Probabilistic Machine Learning &amp; Generative Models, with Kevin Murphy</title><itunes:title>Probabilistic Machine Learning &amp; Generative Models, with Kevin Murphy</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Hosting someone like Kevin Murphy on your podcast is… complicated. Not because Kevin himself is complicated (he’s delightful, don’t make me say what I didn’t say!), but because all the questions I had for him amounted to a 12-hour show.</p><p class="ql-align-justify">Sooooo, brace yourselves folks!</p><p class="ql-align-justify">No, I'm kidding. Of course I didn’t do that folks, Kevin has a life! This life started in Ireland, where he was born. He grew up in England and got his BA from the University of Cambridge. After his PhD at UC Berkeley, he did a postdoc at MIT, and was an associate professor of computer science and statistics at the University of British Columbia in Vancouver, Canada, from 2004 to 2012. After getting tenure, he went to Google in California in 2011 on his sabbatical and then ended up staying.&nbsp;</p><p class="ql-align-justify">He currently runs a team of about 8 researchers inside of Google Brain working on generative models, optimization, and other, as Kevin puts it, “basic” research topics in AI/ML. He has published over 125 papers in refereed conferences and journals, as well 3 textbooks on machine learning published in 2012, 2022 and the last one coming in 2023. You may be familiar with his 2012 book, as it was awarded the DeGroot Prize for best book in the field of statistical science.</p><p class="ql-align-justify">Outside of work, Kevin enjoys traveling, outdoor sports (especially tennis, snowboarding and scuba diving), as well as reading, cooking, and spending time with his family.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Kevin’s website: <a href="https://www.cs.ubc.ca/~murphyk/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Hosting someone like Kevin Murphy on your podcast is… complicated. Not because Kevin himself is complicated (he’s delightful, don’t make me say what I didn’t say!), but because all the questions I had for him amounted to a 12-hour show.</p><p class="ql-align-justify">Sooooo, brace yourselves folks!</p><p class="ql-align-justify">No, I'm kidding. Of course I didn’t do that folks, Kevin has a life! This life started in Ireland, where he was born. He grew up in England and got his BA from the University of Cambridge. After his PhD at UC Berkeley, he did a postdoc at MIT, and was an associate professor of computer science and statistics at the University of British Columbia in Vancouver, Canada, from 2004 to 2012. After getting tenure, he went to Google in California in 2011 on his sabbatical and then ended up staying.&nbsp;</p><p class="ql-align-justify">He currently runs a team of about 8 researchers inside of Google Brain working on generative models, optimization, and other, as Kevin puts it, “basic” research topics in AI/ML. He has published over 125 papers in refereed conferences and journals, as well 3 textbooks on machine learning published in 2012, 2022 and the last one coming in 2023. You may be familiar with his 2012 book, as it was awarded the DeGroot Prize for best book in the field of statistical science.</p><p class="ql-align-justify">Outside of work, Kevin enjoys traveling, outdoor sports (especially tennis, snowboarding and scuba diving), as well as reading, cooking, and spending time with his family.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p>Thank you to my Patrons for making this episode possible!</p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Kevin’s website: <a href="https://www.cs.ubc.ca/~murphyk/" rel="noopener noreferrer" target="_blank">https://www.cs.ubc.ca/~murphyk/</a></li><li class="ql-align-justify">Kevin on Twitter: <a href="https://mobile.twitter.com/sirbayes" rel="noopener noreferrer" target="_blank">https://mobile.twitter.com/sirbayes</a></li><li class="ql-align-justify">Kevin’s books (free pdf) on GitHub (includes a link to places where you can buy the hard copy): <a href="https://probml.github.io/pml-book/" rel="noopener noreferrer" target="_blank">https://probml.github.io/pml-book/</a></li><li class="ql-align-justify">Book that inspired Kevin to get into AI: <a href="https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567" rel="noopener noreferrer" target="_blank">https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567</a></li><li class="ql-align-justify">State-space models library in JAX (WIP): <a href="https://github.com/probml/ssm-jax" rel="noopener noreferrer" target="_blank">https://github.com/probml/ssm-jax</a></li><li class="ql-align-justify">Other software for the book (also in JAX): <a href="https://github.com/probml/pyprobml" rel="noopener noreferrer" target="_blank">https://github.com/probml/pyprobml</a></li><li>Fun photo of Kevin’s hacked-up wearable camera system from 20 years ago: <a href="https://www.cs.ubc.ca/~murphyk/Vision/placeRecognition.html" rel="noopener noreferrer" target="_blank">https://www.cs.ubc.ca/~murphyk/Vision/placeRecognition.html</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/68-probabilistic-machine-learning-generative-models-kevin-murphy]]></link><guid isPermaLink="false">ad61580d-844c-423e-b79e-56d21830e3c4</guid><itunes:image href="https://artwork.captivate.fm/0d9d8618-0f8f-480e-8b8c-b05bdd85166c/kGYaW4Kj1M93v3MOUdHWg-Fi.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 14 Sep 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/9dd14ff2-3fda-4709-b07a-3d8bf6488c4c/Learning-20Bayesian-20Statistics-2068-converted.mp3" length="62966431" type="audio/mpeg"/><itunes:duration>01:05:35</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:episode>68</itunes:episode><podcast:episode>68</podcast:episode><itunes:summary>Kevin Murphy tells us what it&apos;s like working at Google Brain, and about his work on generative models, optimization and probabilistic machine learning</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#67 Exoplanets, Cool Worlds &amp; Life in the Universe, with David Kipping</title><itunes:title>Exoplanets, Cool Worlds &amp; Life in the Universe, with David Kipping</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Is there life in the Universe? It doesn’t get deeper than this, does it? And yet, why do we care about that? In the very small chance that there is other life in the Universe, we have even less chance to discover it, talk to it and meet it. So, why do we care?</p><p class="ql-align-justify">Well, it may surprise you but Bayesian statistics helps us think about these astronomical and — dare I say? — philosophical topics, as my guest, David Kipping, will brilliantly explain in this episode.</p><p class="ql-align-justify">David is an Associate Professor of Astronomy at Columbia University, where he leads the Cool Worlds Lab — I know, the name is awesome. His team’s research spans exoplanet discovery and characterization, the search for life in the Universe and developing novel approaches to our exploration of the cosmos.</p><p class="ql-align-justify">David also teaches astrostatistics, and his contributions to Bayesian statistics span astrobiology to exoplanet detection. He also hosts the Cool Worlds YouTube channel, with over half a million subscribers, that discusses his team’s work and broader topics within the field.</p><p class="ql-align-justify">Cool worlds, cool guest, cool episode.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">David’s website: <a href="http://user.astro.columbia.edu/~dkipping/" rel="noopener noreferrer" target="_blank">http://user.astro.columbia.edu/~dkipping/</a></li><li class="ql-align-justify">David on Twitter: <a href="https://twitter.com/david_kipping" rel="noopener noreferrer" target="_blank">https://twitter.com/david_kipping</a></li><li class="ql-align-justify">David’s YouTube channel: <a href="https://www.youtube.com/c/coolworldslab"...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Is there life in the Universe? It doesn’t get deeper than this, does it? And yet, why do we care about that? In the very small chance that there is other life in the Universe, we have even less chance to discover it, talk to it and meet it. So, why do we care?</p><p class="ql-align-justify">Well, it may surprise you but Bayesian statistics helps us think about these astronomical and — dare I say? — philosophical topics, as my guest, David Kipping, will brilliantly explain in this episode.</p><p class="ql-align-justify">David is an Associate Professor of Astronomy at Columbia University, where he leads the Cool Worlds Lab — I know, the name is awesome. His team’s research spans exoplanet discovery and characterization, the search for life in the Universe and developing novel approaches to our exploration of the cosmos.</p><p class="ql-align-justify">David also teaches astrostatistics, and his contributions to Bayesian statistics span astrobiology to exoplanet detection. He also hosts the Cool Worlds YouTube channel, with over half a million subscribers, that discusses his team’s work and broader topics within the field.</p><p class="ql-align-justify">Cool worlds, cool guest, cool episode.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha, Scott Anthony Robson, David Haas and Robert Yolken.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">David’s website: <a href="http://user.astro.columbia.edu/~dkipping/" rel="noopener noreferrer" target="_blank">http://user.astro.columbia.edu/~dkipping/</a></li><li class="ql-align-justify">David on Twitter: <a href="https://twitter.com/david_kipping" rel="noopener noreferrer" target="_blank">https://twitter.com/david_kipping</a></li><li class="ql-align-justify">David’s YouTube channel: <a href="https://www.youtube.com/c/coolworldslab" rel="noopener noreferrer" target="_blank">https://www.youtube.com/c/coolworldslab</a></li><li class="ql-align-justify">David’s research group: <a href="https://www.coolworldslab.com/" rel="noopener noreferrer" target="_blank">https://www.coolworldslab.com/</a></li><li class="ql-align-justify">Bayesian analysis of the astrobiological implications of life’s early emergence on Earth : <a href="https://www.pnas.org/doi/10.1073/pnas.1111694108" rel="noopener noreferrer" target="_blank">https://www.pnas.org/doi/10.1073/pnas.1111694108</a></li><li class="ql-align-justify">We Have No Idea – A Guide to the Unknown Universe : <a href="https://www.goodreads.com/book/show/31625636-we-have-no-idea" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/31625636-we-have-no-idea</a></li><li>Leonardo da Vinci’s biography by Walter Isaacson: <a href="https://www.amazon.com/Leonardo-Vinci-Walter-Isaacson/dp/1501139169/ref=sr_1_1?keywords=leonardo+da+vinci+book&amp;qid=1660142880&amp;sprefix=leonardo+%2Caps%2C219&amp;sr=8-1" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Leonardo-Vinci-Walter-Isaacson/dp/1501139169/ref=sr_1_1?keywords=leonardo+da+vinci+book&amp;qid=1660142880&amp;sprefix=leonardo+%2Caps%2C219&amp;sr=8-1</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/67-exoplanets-cool-worlds-life-in-universe-david-kipping]]></link><guid isPermaLink="false">3b8c98a3-fbec-4df9-86b3-2f7204b7689a</guid><itunes:image href="https://artwork.captivate.fm/eeb2ef02-9b64-4d94-80a8-62f4e75be91a/hVQHyGC4BjxnsNIO4ZPSvdSj.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 31 Aug 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/42ca02c8-4152-4953-8de4-158a7b6e83e0/Learning-20Bayesian-20Statistics-2067-converted.mp3" length="58282994" type="audio/mpeg"/><itunes:duration>01:00:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>67</itunes:episode><itunes:season>1</itunes:season><podcast:episode>67</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Is there life in the Universe? It doesn’t get deeper than this, does it? And yet, why do we care about that? In the very small chance that there is other life in the Universe, we have even less chance to discover it, talk to it and meet it. So, why do we care?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#66 Uncertainty Visualization &amp; Usable Stats, with Matthew Kay</title><itunes:title>Uncertainty Visualization &amp; Usable Stats, with Matthew Kay</itunes:title><description><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I have to confess something: I love challenges. And when you’re a podcaster, what’s a better challenge than dedicating an episode to… visualization? Impossible you say? Well, challenge accepted!</p><p class="ql-align-justify">Thankfully, I got the help of a visualization Avenger for this episode — namely, Matthew Kay. Matt is an Assistant Professor jointly appointed in Computer Science and Communications Studies at Northwestern University, where he co-directs the Midwest Uncertainty Collective — I know, it’s a pretty cool name for a lab.</p><p class="ql-align-justify">He works in human-computer interaction and information visualization, and especially in uncertainty visualization. He also builds tools to support uncertainty visualization in R. In particular, he’s the author of the tidybayes and ggdist R packages, and wrote the random variable interface in the posterior package.</p><p class="ql-align-justify">I promise, you won’t be uncertain about the importance of uncertainty visualization after that…</p><p class="ql-align-justify"><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Matt on Twitter: <a href="https://twitter.com/mjskay" rel="noopener noreferrer" target="_blank">https://twitter.com/mjskay</a></li><li class="ql-align-justify">Matt on GitHub: <a href="https://github.com/mjskay" rel="noopener noreferrer" target="_blank">https://github.com/mjskay</a>&nbsp;&nbsp;</li><li class="ql-align-justify">Matt’s website: <a href="https://www.mjskay.com/" rel="noopener noreferrer" target="_blank">https://www.mjskay.com/</a>&nbsp;</li><li class="ql-align-justify">Midwest Uncertainty Collective lab: <a href="https://mucollective.northwestern.edu/"...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I have to confess something: I love challenges. And when you’re a podcaster, what’s a better challenge than dedicating an episode to… visualization? Impossible you say? Well, challenge accepted!</p><p class="ql-align-justify">Thankfully, I got the help of a visualization Avenger for this episode — namely, Matthew Kay. Matt is an Assistant Professor jointly appointed in Computer Science and Communications Studies at Northwestern University, where he co-directs the Midwest Uncertainty Collective — I know, it’s a pretty cool name for a lab.</p><p class="ql-align-justify">He works in human-computer interaction and information visualization, and especially in uncertainty visualization. He also builds tools to support uncertainty visualization in R. In particular, he’s the author of the tidybayes and ggdist R packages, and wrote the random variable interface in the posterior package.</p><p class="ql-align-justify">I promise, you won’t be uncertain about the importance of uncertainty visualization after that…</p><p class="ql-align-justify"><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Matt on Twitter: <a href="https://twitter.com/mjskay" rel="noopener noreferrer" target="_blank">https://twitter.com/mjskay</a></li><li class="ql-align-justify">Matt on GitHub: <a href="https://github.com/mjskay" rel="noopener noreferrer" target="_blank">https://github.com/mjskay</a>&nbsp;&nbsp;</li><li class="ql-align-justify">Matt’s website: <a href="https://www.mjskay.com/" rel="noopener noreferrer" target="_blank">https://www.mjskay.com/</a>&nbsp;</li><li class="ql-align-justify">Midwest Uncertainty Collective lab: <a href="https://mucollective.northwestern.edu/" rel="noopener noreferrer" target="_blank">https://mucollective.northwestern.edu/</a>&nbsp;</li><li class="ql-align-justify">PyMC <em>find_constrained_priors</em> tutorial: <a href="https://www.youtube.com/watch?v=9shZeqKG3M0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=9shZeqKG3M0</a></li><li class="ql-align-justify">PyMC <em>find_constrained_priors</em> doc: <a href="https://www.pymc.io/projects/docs/en/latest/api/generated/pymc.find_constrained_prior.html?highlight=find_constrained_priors" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/docs/en/latest/api/generated/pymc.find_constrained_prior.html</a></li><li class="ql-align-justify">Tutorials / package documentation / videos:</li><li class="ql-align-justify">tidybayes: <a href="http://mjskay.github.io/tidybayes/" rel="noopener noreferrer" target="_blank">http://mjskay.github.io/tidybayes/</a>&nbsp;</li><li class="ql-align-justify">ggdist: <a href="https://mjskay.github.io/ggdist/" rel="noopener noreferrer" target="_blank">https://mjskay.github.io/ggdist/</a> (various visualizations in the slabinterval vignette: <a href="https://mjskay.github.io/ggdist/articles/slabinterval.html" rel="noopener noreferrer" target="_blank">https://mjskay.github.io/ggdist/articles/slabinterval.html</a> )&nbsp;</li><li class="ql-align-justify">Miscellaneous uncertainty visualizations examples: <a href="https://github.com/mjskay/uncertainty-examples" rel="noopener noreferrer" target="_blank">https://github.com/mjskay/uncertainty-examples</a>&nbsp;</li><li class="ql-align-justify">Talk on uncertainty visualization: <a href="https://www.youtube.com/watch?v=E1kSnWvqCw0" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=E1kSnWvqCw0</a>&nbsp;</li><li class="ql-align-justify">Biases in probability perception:</li><li class="ql-align-justify">A survey paper on the linear-in-log-odds model of probability perception: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3261445/" rel="noopener noreferrer" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3261445/</a></li><li class="ql-align-justify">Using the linear-in-log-odds model to "debias" uncertainty visualization: <a href="https://osf.io/6xcnw/" rel="noopener noreferrer" target="_blank">https://osf.io/6xcnw/</a>&nbsp;</li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/66-uncertainty-visualization-usable-stats-matthew-kay]]></link><guid isPermaLink="false">4a3695cd-333f-4b4c-856c-8c2684a236df</guid><itunes:image href="https://artwork.captivate.fm/a5c90d77-b8c1-4f48-8cd6-829bccec07ca/EzSD17B49oBj29FO3cNKQybR.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 17 Aug 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/91dc6332-4c63-46c0-947e-9022c61d354e/Learning-20Bayesian-20Statistics-2066-converted.mp3" length="59477725" type="audio/mpeg"/><itunes:duration>01:01:57</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>66</itunes:episode><itunes:season>1</itunes:season><podcast:episode>66</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A tour of human-computer interactions and information visualization, especially in uncertainty visualization.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#65 PyMC, Aeppl, &amp; Aesara: the new cool kids on the block, with Ricardo Vieira</title><itunes:title>PyMC, Aeppl, &amp; Aesara: the new cool kids on the block, with Ricardo Vieira</itunes:title><description><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Folks, there are some new cool kids on the block. They are called PyMC, Aeppl, and Aesara, and it’s high time we give us a proper welcome!</p><p class="ql-align-justify">To do that, who better than one of the architects of the new PyMC 4.0 — Ricardo Vieira! In this episode, he’ll walk us through the inner workings of the newly released version of PyMC, telling us why the Aesara backend and the brand new RandomVariable operators constitute such strong foundations for your beloved PyMC models. He will also tell us about a self-contained PPL project called Aeppl, dedicated to converting model graphs to probability functions — pretty cool, right?</p><p class="ql-align-justify">Oh, in case you didn’t guess yet, Ricardo is a PyMC developer and data scientist at PyMC Labs. He spent several years teaching himself Statistics and Computer Science at the expense of his official degrees in Psychology and Neuroscience.</p><p class="ql-align-justify">So, get ready for efficient random generator functions, better probability evaluation functions, and a fully-fledged modern Bayesian workflow!</p><p class="ql-align-justify"><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Ricardo on Twitter: <a href="https://twitter.com/RicardoV944" rel="noopener noreferrer" target="_blank">https://twitter.com/RicardoV944</a></li><li class="ql-align-justify">Ricardo on GitHub: <a href="https://github.com/ricardoV94/" rel="noopener noreferrer" target="_blank">https://github.com/ricardoV94/</a></li><li class="ql-align-justify">Ricardo’s website: <a href="https://ricardov94.github.io/posts/" rel="noopener noreferrer" target="_blank">https://ricardov94.github.io/posts/</a></li><li class="ql-align-justify">PyMC, Aesara and Aeppl: The New Kids on The Block (YouTube...]]></description><content:encoded><![CDATA[<p><em>Proudly sponsored by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Folks, there are some new cool kids on the block. They are called PyMC, Aeppl, and Aesara, and it’s high time we give us a proper welcome!</p><p class="ql-align-justify">To do that, who better than one of the architects of the new PyMC 4.0 — Ricardo Vieira! In this episode, he’ll walk us through the inner workings of the newly released version of PyMC, telling us why the Aesara backend and the brand new RandomVariable operators constitute such strong foundations for your beloved PyMC models. He will also tell us about a self-contained PPL project called Aeppl, dedicated to converting model graphs to probability functions — pretty cool, right?</p><p class="ql-align-justify">Oh, in case you didn’t guess yet, Ricardo is a PyMC developer and data scientist at PyMC Labs. He spent several years teaching himself Statistics and Computer Science at the expense of his official degrees in Psychology and Neuroscience.</p><p class="ql-align-justify">So, get ready for efficient random generator functions, better probability evaluation functions, and a fully-fledged modern Bayesian workflow!</p><p class="ql-align-justify"><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Ricardo on Twitter: <a href="https://twitter.com/RicardoV944" rel="noopener noreferrer" target="_blank">https://twitter.com/RicardoV944</a></li><li class="ql-align-justify">Ricardo on GitHub: <a href="https://github.com/ricardoV94/" rel="noopener noreferrer" target="_blank">https://github.com/ricardoV94/</a></li><li class="ql-align-justify">Ricardo’s website: <a href="https://ricardov94.github.io/posts/" rel="noopener noreferrer" target="_blank">https://ricardov94.github.io/posts/</a></li><li class="ql-align-justify">PyMC, Aesara and Aeppl: The New Kids on The Block (YouTube video): <a href="https://www.youtube.com/watch?v=_APNiXTfYJw" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=_APNiXTfYJw</a></li><li class="ql-align-justify">Bayesian Vector Autoregression in PyMC: <a href="https://www.pymc-labs.io/blog-posts/bayesian-vector-autoregression/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/blog-posts/bayesian-vector-autoregression/</a></li><li class="ql-align-justify">New PyMC website: <a href="https://www.pymc.io/projects/docs/en/stable/learn.html" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/docs/en/stable/learn.html</a></li><li class="ql-align-justify">Define, optimize, and evaluate mathematical expressions with Aesara: <a href="https://aesara.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://aesara.readthedocs.io/en/latest/</a></li><li class="ql-align-justify">Aeppl documentation: <a href="https://aeppl.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://aeppl.readthedocs.io/en/latest/</a></li><li class="ql-align-justify">PyMC’s YouTube channel: <a href="https://www.youtube.com/c/PyMCDevelopers" rel="noopener noreferrer" target="_blank">https://www.youtube.com/c/PyMCDevelopers</a></li><li class="ql-align-justify">PyMC on Twitter: <a href="https://twitter.com/pymc_devs" rel="noopener noreferrer" target="_blank">https://twitter.com/pymc_devs</a></li><li class="ql-align-justify">PyMC on LinkedIn: <a href="https://www.linkedin.com/company/pymc/mycompany/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/company/pymc/mycompany/</a></li><li class="ql-align-justify">LBS #61, Why we still use non-Bayesian methods, with EJ Wagenmakers: <a href="https://www.learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers</a></li><li class="ql-align-justify">LBS #31, Bayesian Cognitive Modeling &amp; Decision-Making, with Michael Lee:&nbsp; <a href="https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee</a></li><li class="ql-align-justify"><em>We Have No Idea</em>, A Guide to the Unknown Universe: <a href="https://www.amazon.com/We-Have-No-Idea-Universe/dp/0735211515" rel="noopener noreferrer" target="_blank">https://www.amazon.com/We-Have-No-Idea-Universe/dp/0735211515</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/65-pymc-aeppl-aesara-ricardo-vieira]]></link><guid isPermaLink="false">fcc4b091-449c-48e4-b094-9466b985b6a1</guid><itunes:image href="https://artwork.captivate.fm/d1d0eb58-2ad8-42a8-b782-06b4ca24f55a/mSwCBKgNAnKJaOM-gfD6BrV0.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 03 Aug 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/89ad4214-ff1b-409a-840f-abe91b44c011/Learning-20Bayesian-20Statistics-2065-converted.mp3" length="54994330" type="audio/mpeg"/><itunes:duration>01:05:28</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>65</itunes:episode><itunes:season>1</itunes:season><podcast:episode>65</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A (random) walk through the inner workings of the newly released version of PyMC, with one of its main core developers</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#64 Modeling the Climate &amp; Gravity Waves, with Laura Mansfield</title><itunes:title>Modeling the Climate &amp; Gravity Waves, with Laura Mansfield</itunes:title><description><![CDATA[<p class="ql-align-justify"><strong><em>Proudly sponsored by</em></strong><em> </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m sure you’ve already heard of gravitational waves, because my listeners are the coolest and smartest ever ;) But did you know about gravity waves? That’s right, waves in the sky due to gravity — sounds awesome, right?</p><p class="ql-align-justify">Well, I’m pretty sure that Laura Mansfield will confirm your prior. Currently a postdoc at Stanford University, Laura studies — guess what? — gravity waves and how they are represented in climate models. In particular, she uses Bayesian methods to estimate the uncertainty on the gravity wave components of the models.</p><p class="ql-align-justify">Holding a PhD from the University of Reading in the UK, her background is in atmospheric physics, but she’s interested in climate change and environmental issues.</p><p class="ql-align-justify">So seat back, chill out, and enjoy this physics-packed, aerial episode!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Laura on Twitter: <a href="https://twitter.com/lau_mansfield" rel="noopener noreferrer" target="_blank">https://twitter.com/lau_mansfield</a></li><li class="ql-align-justify">Laura’s webpage: <a href="https://profiles.stanford.edu/laura-mansfield" rel="noopener noreferrer" target="_blank">https://profiles.stanford.edu/laura-mansfield</a></li><li class="ql-align-justify">Julia package for Gaussian Processes: <a href="https://github.com/STOR-i/GaussianProcesses.jl" rel="noopener noreferrer" target="_blank">https://github.com/STOR-i/GaussianProcesses.jl</a>&nbsp;</li><li class="ql-align-justify">Julia implementation of the scikit-learn API: <a href="https://github.com/cstjean/ScikitLearn.jl" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><strong><em>Proudly sponsored by</em></strong><em> </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">I’m sure you’ve already heard of gravitational waves, because my listeners are the coolest and smartest ever ;) But did you know about gravity waves? That’s right, waves in the sky due to gravity — sounds awesome, right?</p><p class="ql-align-justify">Well, I’m pretty sure that Laura Mansfield will confirm your prior. Currently a postdoc at Stanford University, Laura studies — guess what? — gravity waves and how they are represented in climate models. In particular, she uses Bayesian methods to estimate the uncertainty on the gravity wave components of the models.</p><p class="ql-align-justify">Holding a PhD from the University of Reading in the UK, her background is in atmospheric physics, but she’s interested in climate change and environmental issues.</p><p class="ql-align-justify">So seat back, chill out, and enjoy this physics-packed, aerial episode!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh, Lin Yu Sha and Scott Anthony Robson.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Laura on Twitter: <a href="https://twitter.com/lau_mansfield" rel="noopener noreferrer" target="_blank">https://twitter.com/lau_mansfield</a></li><li class="ql-align-justify">Laura’s webpage: <a href="https://profiles.stanford.edu/laura-mansfield" rel="noopener noreferrer" target="_blank">https://profiles.stanford.edu/laura-mansfield</a></li><li class="ql-align-justify">Julia package for Gaussian Processes: <a href="https://github.com/STOR-i/GaussianProcesses.jl" rel="noopener noreferrer" target="_blank">https://github.com/STOR-i/GaussianProcesses.jl</a>&nbsp;</li><li class="ql-align-justify">Julia implementation of the scikit-learn API: <a href="https://github.com/cstjean/ScikitLearn.jl" rel="noopener noreferrer" target="_blank">https://github.com/cstjean/ScikitLearn.jl</a></li><li>Derivative-free Bayesian optimization techniques based on Ensemble Kalman Filters: <a href="https://github.com/CliMA/EnsembleKalmanProcesses.jl" rel="noopener noreferrer" target="_blank">https://github.com/CliMA/EnsembleKalmanProcesses.jl</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/64-modeling-climate-gravity-waves-laura-mansfield]]></link><guid isPermaLink="false">ccc4a0a7-eb60-4312-91f1-9ad7aada5b05</guid><itunes:image href="https://artwork.captivate.fm/80545696-34e5-41fa-ab3c-97eba2c13e65/XLT8nEehL01Q6gjVnsf5o8BB.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 20 Jul 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/df449aa8-734e-41bd-b63e-8e3a75b74f91/Learning-20Bayesian-20Statistics-2064.mp3" length="64773476" type="audio/mpeg"/><itunes:duration>01:07:28</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>64</itunes:episode><itunes:season>1</itunes:season><podcast:episode>64</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Did you know about gravity waves? That’s right, waves in the sky due to gravity — sounds awesome, right?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#63 Media Mix Models &amp; Bayes for Marketing, with Luciano Paz</title><itunes:title>Media Mix Models &amp; Bayes for Marketing, with Luciano Paz</itunes:title><description><![CDATA[<p><strong><em>Proudly sponsored</em></strong><em> by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Inviting someone like Luciano Paz on a stats podcast is both a pleasure and a challenge — he does so many things brilliantly that you have too many questions to ask him…</p><p class="ql-align-justify">In this episode, I’ve chosen — not without difficulty — to focus on the applications of Bayesian stats in the marketing industry, especially Media Mix Models. Ok, I also asked Luciano about other topics — but you know me, I like to talk…</p><p class="ql-align-justify">Originally, Luciano studied physics. He then did a PhD and postdoc in neuroscience, before transitioning into industry. During his time in academia, he used stats, machine learning and data science concepts here and there, but not in a very organized way.</p><p class="ql-align-justify">But at the end of his postdoc, he got into PyMC — and that’s when everything changed… He loved the community and decided to hop on board to exit academia into a better life. After leaving academia, he worked at a company that wanted to do data science but that, for privacy reasons, didn’t have a lot of data. And now, Luciano is one of the folks working full time at the PyMC Labs consultancy.</p><p class="ql-align-justify">But Luciano is not only one of the cool nerds building this crazy Bayesian adventures. He also did a lot of piano and ninjutsu. Sooooo, don’t provoke him — either in the streets or at a karaoke bar…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh and Lin Yu Sha.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Luciano’s website: <a href="https://lucianopaz.github.io/" rel="noopener noreferrer" target="_blank">https://lucianopaz.github.io/</a></li><li class="ql-align-justify">Luciano on GitHub: <a href="https://github.com/lucianopaz" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong><em>Proudly sponsored</em></strong><em> by </em><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><em>PyMC Labs</em></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">Inviting someone like Luciano Paz on a stats podcast is both a pleasure and a challenge — he does so many things brilliantly that you have too many questions to ask him…</p><p class="ql-align-justify">In this episode, I’ve chosen — not without difficulty — to focus on the applications of Bayesian stats in the marketing industry, especially Media Mix Models. Ok, I also asked Luciano about other topics — but you know me, I like to talk…</p><p class="ql-align-justify">Originally, Luciano studied physics. He then did a PhD and postdoc in neuroscience, before transitioning into industry. During his time in academia, he used stats, machine learning and data science concepts here and there, but not in a very organized way.</p><p class="ql-align-justify">But at the end of his postdoc, he got into PyMC — and that’s when everything changed… He loved the community and decided to hop on board to exit academia into a better life. After leaving academia, he worked at a company that wanted to do data science but that, for privacy reasons, didn’t have a lot of data. And now, Luciano is one of the folks working full time at the PyMC Labs consultancy.</p><p class="ql-align-justify">But Luciano is not only one of the cool nerds building this crazy Bayesian adventures. He also did a lot of piano and ninjutsu. Sooooo, don’t provoke him — either in the streets or at a karaoke bar…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton, Jeannine Sue, Omri Har Shemesh and Lin Yu Sha.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Luciano’s website: <a href="https://lucianopaz.github.io/" rel="noopener noreferrer" target="_blank">https://lucianopaz.github.io/</a></li><li class="ql-align-justify">Luciano on GitHub: <a href="https://github.com/lucianopaz" rel="noopener noreferrer" target="_blank">https://github.com/lucianopaz</a></li><li class="ql-align-justify">Luciano on LinkedIn: <a href="https://www.linkedin.com/in/luciano-paz-4139b5123/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/luciano-paz-4139b5123/</a></li><li class="ql-align-justify">Bayesian Media Mix Modeling for Marketing Optimization: <a href="https://www.pymc-labs.io/blog-posts/bayesian-media-mix-modeling-for-marketing-optimization/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/blog-posts/bayesian-media-mix-modeling-for-marketing-optimization/</a></li><li class="ql-align-justify">Improving the Speed and Accuracy of Bayesian Media Mix Models: <a href="https://www.pymc-labs.io/blog-posts/reducing-customer-acquisition-costs-how-we-helped-optimizing-hellofreshs-marketing-budget/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/blog-posts/reducing-customer-acquisition-costs-how-we-helped-optimizing-hellofreshs-marketing-budget/</a></li><li class="ql-align-justify">Speeding up HelloFresh's Bayesian AB tests by 60x: <a href="https://www.pymc-labs.io/blog-posts/bayes-is-slow-speeding-up-hellofreshs-bayesian-ab-tests-by-60x/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/blog-posts/bayes-is-slow-speeding-up-hellofreshs-bayesian-ab-tests-by-60x/</a></li><li class="ql-align-justify">PyMC Labs YouTube channel: <a href="https://www.youtube.com/c/PyMCLabs" rel="noopener noreferrer" target="_blank">https://www.youtube.com/c/PyMCLabs</a></li><li class="ql-align-justify">LBS #21 Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova: <a href="https://www.learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova</a></li><li class="ql-align-justify">Gaussian Processes approximations in PyMC: <a href="https://github.com/pymc-devs/pymc-experimental/pull/3" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc-experimental/pull/3</a></li><li class="ql-align-justify">Michael Betancourt, ​​Identifying Bayesian Mixture Models: <a href="https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html</a></li><li class="ql-align-justify">Identifying Bayesian Mixture Models in PyMC3: <a href="https://gist.github.com/junpenglao/4d65d1a9bf80e8d371446fadda9deb7a" rel="noopener noreferrer" target="_blank">https://gist.github.com/junpenglao/4d65d1a9bf80e8d371446fadda9deb7a</a></li><li class="ql-align-justify">Mixture Models in PyMC: <a href="https://www.pymc.io/projects/examples/en/latest/gallery.html#mixture-models" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gallery.html#mixture-models</a></li><li class="ql-align-justify">Osvaldo Martin’s <em>Bayesian Analysis with Python</em>: <a href="https://www.amazon.com/dp/B07HHBCR9G" rel="noopener noreferrer" target="_blank">https://www.amazon.com/dp/B07HHBCR9G</a></li><li class="ql-align-justify">LBS #4 Dirichlet Processes and Neurodegenerative Diseases, with Karin Knudson: <a href="https://www.learnbayesstats.com/episode/4-dirichlet-processes-and-neurodegenerative-diseases-with-karin-knudson" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/4-dirichlet-processes-and-neurodegenerative-diseases-with-karin-knudson</a></li><li class="ql-align-justify">Intuitive Bayes Introductory Course: <a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/63-media-mix-models-bayes-marketing-luciano-paz]]></link><guid isPermaLink="false">11da3fef-dce4-4162-8237-5c8861f5198e</guid><itunes:image href="https://artwork.captivate.fm/91411f4a-cc31-468e-bf7b-26e3785f8dbc/rm_26ESI8jqcYtxE7_3H10_R.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 28 Jun 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a2d92c14-ec6f-45c1-b8a3-be28cc66b2c8/Learning-20Bayesian-20Statistics-2063.mp3" length="71730287" type="audio/mpeg"/><itunes:duration>01:14:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>63</itunes:episode><itunes:season>1</itunes:season><podcast:episode>63</podcast:episode><podcast:season>1</podcast:season><itunes:summary>On the applications of Bayesian stats in the marketing industry, especially Media Mix Models.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#62 Bayesian Generative Modeling for Healthcare, with Maria Skoularidou</title><itunes:title>Bayesian Generative Modeling for Healthcare</itunes:title><description><![CDATA[<p class="ql-align-justify"><strong><em>Proudly sponsored by </em></strong><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><strong><em>PyMC Labs</em></strong></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">We talk a lot about generative modeling on this podcast — at least since episode 6, with Michael Betancourt! And an area where this way of modeling is particularly useful is healthcare, as Maria Skoularidou will tell us in this episode.</p><p class="ql-align-justify">Maria is a final year PhD student at the University of Cambridge. Her thesis is focused on probabilistic machine learning and, more precisely, towards using generative modeling in… you guessed it: healthcare!</p><p class="ql-align-justify">But her fields of interest are diverse: from theory and methodology of machine intelligence to Bayesian inference; from theoretical computer science to information theory — Maria is knowledgeable in a lot of topics! That’s why I also had to ask her about mixture models, a category of models that she uses frequently.</p><p class="ql-align-justify">Prior to her PhD, Maria studied Computer Science and Statistical Science at Athens University of Economics and Business. She’s also invested in several efforts to bring more diversity and accessibility in the data science world.</p><p class="ql-align-justify">When she’s not working on all this, you’ll find her playing the ney, trekking or rawing.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton and Jeannine Sue.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Maria on Twitter: <a href="https://twitter.com/skoularidou" rel="noopener noreferrer" target="_blank">https://twitter.com/skoularidou</a></li><li class="ql-align-justify">Maria on LinkedIn: <a href="https://www.linkedin.com/in/maria-skoularidou-1289b62a/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/maria-skoularidou-1289b62a/</a></li><li class="ql-align-justify">Maria’s webpage:</li><li...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><strong><em>Proudly sponsored by </em></strong><a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank"><strong><em>PyMC Labs</em></strong></a><em>, the Bayesian Consultancy. </em><a href="https://calendar.google.com/calendar/appointments/schedules/AcZssZ1nOI_SElJzSiQ2sXBDiaW9w98ErjnHVzmHcSilYNWeXxJgV870NGuWZUGo3W-8-gDG8jIXQhBf" rel="noopener noreferrer" target="_blank"><em>Book a call</em></a><em>, or </em><a href="mailto:alex.andorra@pymc-labs.io" rel="noopener noreferrer" target="_blank"><em>get in touch</em></a><em>!</em></p><p class="ql-align-justify">We talk a lot about generative modeling on this podcast — at least since episode 6, with Michael Betancourt! And an area where this way of modeling is particularly useful is healthcare, as Maria Skoularidou will tell us in this episode.</p><p class="ql-align-justify">Maria is a final year PhD student at the University of Cambridge. Her thesis is focused on probabilistic machine learning and, more precisely, towards using generative modeling in… you guessed it: healthcare!</p><p class="ql-align-justify">But her fields of interest are diverse: from theory and methodology of machine intelligence to Bayesian inference; from theoretical computer science to information theory — Maria is knowledgeable in a lot of topics! That’s why I also had to ask her about mixture models, a category of models that she uses frequently.</p><p class="ql-align-justify">Prior to her PhD, Maria studied Computer Science and Statistical Science at Athens University of Economics and Business. She’s also invested in several efforts to bring more diversity and accessibility in the data science world.</p><p class="ql-align-justify">When she’s not working on all this, you’ll find her playing the ney, trekking or rawing.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland, Aubrey Clayton and Jeannine Sue.</em></p><p class="ql-align-justify">Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p class="ql-align-justify"><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Maria on Twitter: <a href="https://twitter.com/skoularidou" rel="noopener noreferrer" target="_blank">https://twitter.com/skoularidou</a></li><li class="ql-align-justify">Maria on LinkedIn: <a href="https://www.linkedin.com/in/maria-skoularidou-1289b62a/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/maria-skoularidou-1289b62a/</a></li><li class="ql-align-justify">Maria’s webpage:</li><li class="ql-align-justify"><a href="https://www.mrc-bsu.cam.ac.uk/people/in-alphabetical-order/n-to-s/maria-skoularidou/" rel="noopener noreferrer" target="_blank">https://www.mrc-bsu.cam.ac.uk/people/in-alphabetical-order/n-to-s/maria-skoularidou/</a></li><li class="ql-align-justify">Mixture models in PyMC: <a href="https://www.pymc.io/projects/examples/en/latest/gallery.html#mixture-models" rel="noopener noreferrer" target="_blank">https://www.pymc.io/projects/examples/en/latest/gallery.html#mixture-models</a></li><li class="ql-align-justify">LBS #4 Dirichlet Processes and Neurodegenerative Diseases, with Karin Knudson: <a href="https://learnbayesstats.com/episode/4-dirichlet-processes-and-neurodegenerative-diseases-with-karin-knudson/" rel="noopener noreferrer" target="_blank">https://learnbayesstats.com/episode/4-dirichlet-processes-and-neurodegenerative-diseases-with-karin-knudson/</a></li><li class="ql-align-justify">Bayesian mixtures with an unknown number of components: <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00095" rel="noopener noreferrer" target="_blank">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00095</a></li><li>Markov Chain sampling methods for Dirichlet Processes: <a href="https://www.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879</a></li><li>Retrospective Markov chain Monte Carlo methods for Dirichlet process hierarchical models: <a href="https://academic.oup.com/biomet/article-abstract/95/1/169/219181" rel="noopener noreferrer" target="_blank">https://academic.oup.com/biomet/article-abstract/95/1/169/219181</a></li><li>Sampling Dirichlet mixture models with slices: <a href="https://www.tandfonline.com/doi/abs/10.1080/03610910601096262" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/03610910601096262</a></li><li>Label switching problem:</li><li><a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00265" rel="noopener noreferrer" target="_blank">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00265</a></li><li>Mixture Models With a Prior on the Number of Components: <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2016.1255636" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/01621459.2016.1255636</a></li><li>Approximate Bayesian inference for Gaussian models (R-INLA): <a href="https://www.r-inla.org" rel="noopener noreferrer" target="_blank">https://www.r-inla.org</a></li><li class="ql-align-justify">Intuitive Bayes Introductory Course: <a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/</a></li><li class="ql-align-justify">PyMC Labs corporate workshops: <a href="https://www.pymc-labs.io/workshops/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/workshops</a></li><li class="ql-align-justify">LBS #44 Building Bayesian Models at scale, with Rémi Louf: <a href="https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf</a></li><li class="ql-align-justify">Blackjax – Sampling library designed for ease of use, speed and modularity: <a href="https://blackjax-devs.github.io/blackjax/" rel="noopener noreferrer" target="_blank">https://blackjax-devs.github.io/blackjax/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/62-bayesian-generative-modeling-healthcare-maria-skoularidou]]></link><guid isPermaLink="false">4f276d72-19f5-4a20-94f5-b24bb0a7f63b</guid><itunes:image href="https://artwork.captivate.fm/c0dbef6f-068c-4d39-b2a4-b30aecdb4036/RmRnhXTd3IMQiUOAXA3cTIrG.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 08 Jun 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/af5245af-d545-4d98-9422-91c95efbd22c/Learning-20Bayesian-20Statistics-2062.mp3" length="54802589" type="audio/mpeg"/><itunes:duration>57:05</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>62</itunes:episode><itunes:season>1</itunes:season><podcast:episode>62</podcast:episode><podcast:season>1</podcast:season><itunes:summary>About the usefulness of Bayesian Generative Modeling in healthcare.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#61 Why we still use non-Bayesian methods, with EJ Wagenmakers</title><itunes:title>Why we still use non-Bayesian methods, with EJ Wagenmakers</itunes:title><description><![CDATA[<p class="ql-align-justify">The big problems with classic hypothesis testing are well-known. And yet, a huge majority of statistical analyses are still conducted this way. Why is it? Why are things so hard to change? Can you even do (and should you do) hypothesis testing in the Bayesian framework?</p><p class="ql-align-justify">I guess if you wanted to name this episode in a very Marvelian way, it would be “Bayes factors against the p-values of madness” — but we won’t do that, it wouldn’t be appropriate, would it?</p><p class="ql-align-justify">Anyways, in this episode, I’ll talk about all these very light and consensual topics with Eric-Jan Wagenmakers, a professor at the Psychological Methods Unit of the University of Amsterdam.</p><p class="ql-align-justify">For almost two decades, EJ has staunchly advocated the use of Bayesian inference in psychology. In order to lower the bar for the adoption of Bayesian methods, he is coordinating the development of JASP, an open-source software program that allows practitioners to conduct state-of-the-art Bayesian analyses with their mouse — the one from the computer, not the one from Disney.</p><p class="ql-align-justify">EJ has also written a children’s book on Bayesian inference with the title “Bayesian thinking for toddlers”. Rumor has it that he is also working on a multi-volume series for adults — but shhh, that’s a secret!</p><p class="ql-align-justify">EJ’s lab publishes regularly on a host of Bayesian topics, so check out his website, particularly when you are interested in Bayesian hypothesis testing. The same goes for his blog by the way, “BayesianSpectacles”.</p><p class="ql-align-justify">Wait, what’s that? EJ is telling me that he plays chess, squash, and that, most importantly, he enjoys watching arm wrestling videos on YouTube — yet another proof that, yes, you can find everything on YouTube.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">EJ’s website: <a href="http://ejwagenmakers.com/" rel="noopener noreferrer" target="_blank">http://ejwagenmakers.com/</a></li><li class="ql-align-justify">EJ on Twitter: <a href="https://twitter.com/EJWagenmakers" rel="noopener noreferrer" target="_blank">https://twitter.com/EJWagenmakers</a></li><li class="ql-align-justify">“Bayesian Cognitive Modeling” book website: <a href="https://bayesmodels.com/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p class="ql-align-justify">The big problems with classic hypothesis testing are well-known. And yet, a huge majority of statistical analyses are still conducted this way. Why is it? Why are things so hard to change? Can you even do (and should you do) hypothesis testing in the Bayesian framework?</p><p class="ql-align-justify">I guess if you wanted to name this episode in a very Marvelian way, it would be “Bayes factors against the p-values of madness” — but we won’t do that, it wouldn’t be appropriate, would it?</p><p class="ql-align-justify">Anyways, in this episode, I’ll talk about all these very light and consensual topics with Eric-Jan Wagenmakers, a professor at the Psychological Methods Unit of the University of Amsterdam.</p><p class="ql-align-justify">For almost two decades, EJ has staunchly advocated the use of Bayesian inference in psychology. In order to lower the bar for the adoption of Bayesian methods, he is coordinating the development of JASP, an open-source software program that allows practitioners to conduct state-of-the-art Bayesian analyses with their mouse — the one from the computer, not the one from Disney.</p><p class="ql-align-justify">EJ has also written a children’s book on Bayesian inference with the title “Bayesian thinking for toddlers”. Rumor has it that he is also working on a multi-volume series for adults — but shhh, that’s a secret!</p><p class="ql-align-justify">EJ’s lab publishes regularly on a host of Bayesian topics, so check out his website, particularly when you are interested in Bayesian hypothesis testing. The same goes for his blog by the way, “BayesianSpectacles”.</p><p class="ql-align-justify">Wait, what’s that? EJ is telling me that he plays chess, squash, and that, most importantly, he enjoys watching arm wrestling videos on YouTube — yet another proof that, yes, you can find everything on YouTube.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">EJ’s website: <a href="http://ejwagenmakers.com/" rel="noopener noreferrer" target="_blank">http://ejwagenmakers.com/</a></li><li class="ql-align-justify">EJ on Twitter: <a href="https://twitter.com/EJWagenmakers" rel="noopener noreferrer" target="_blank">https://twitter.com/EJWagenmakers</a></li><li class="ql-align-justify">“Bayesian Cognitive Modeling” book website: <a href="https://bayesmodels.com/" rel="noopener noreferrer" target="_blank">https://bayesmodels.com/</a></li><li class="ql-align-justify">Port of “Bayesian Cognitive Modeling” to PyMC: <a href="https://github.com/pymc-devs/pymc-resources/tree/main/BCM" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc-resources/tree/main/BCM</a></li><li class="ql-align-justify">EJ’s blog: <a href="http://www.bayesianspectacles.org/" rel="noopener noreferrer" target="_blank">http://www.bayesianspectacles.org/</a></li><li class="ql-align-justify">JASP software website: <a href="https://jasp-stats.org/" rel="noopener noreferrer" target="_blank">https://jasp-stats.org/</a></li><li class="ql-align-justify">Bayesian Thinking for Toddlers: <a href="https://psyarxiv.com/w5vbp/" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/w5vbp/</a></li><li class="ql-align-justify">LBS #31, Bayesian Cognitive Modeling &amp; Decision-Making with Michael Lee: <a href="https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee</a></li><li class="ql-align-justify">“You can't play 20 questions with nature and win”: <a href="https://www.coli.uni-saarland.de/~crocker/documents/Newell-1973.pdf" rel="noopener noreferrer" target="_blank">https://www.coli.uni-saarland.de/~crocker/documents/Newell-1973.pdf</a></li><li class="ql-align-justify">Applying Occam's razor in modeling cognition – A Bayesian approach: <a href="https://link.springer.com/article/10.3758/BF03210778" rel="noopener noreferrer" target="_blank">https://link.springer.com/article/10.3758/BF03210778</a></li><li class="ql-align-justify">Adjusting for publication bias in JASP &amp; R – Selection models, PET-PEESE, and robust Bayesian meta-analysis: <a href="https://psyarxiv.com/75bqn/" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/75bqn/</a></li><li class="ql-align-justify">Robust Bayesian meta-analysis – Addressing publication bias with model-averaging: <a href="https://psyarxiv.com/u4cns" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/u4cns</a></li><li class="ql-align-justify">A primer on Bayesian model-averaged meta-analysis: <a href="https://journals.sagepub.com/doi/full/10.1177/25152459211031256" rel="noopener noreferrer" target="_blank">https://journals.sagepub.com/doi/full/10.1177/25152459211031256</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/61-why-we-still-use-non-bayesian-methods-ej-wagenmakers]]></link><guid isPermaLink="false">0b1ea7ff-f517-4e66-af4f-fab4f171118a</guid><itunes:image href="https://artwork.captivate.fm/374d1304-1b16-4f9e-8ed1-cb956f2628db/q1cZj_HP0uJuuJ5yh5orpA2G.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 19 May 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/99f16080-0200-4be8-a262-bc7aa0d75a21/Learning-20Bayesian-20Statistics-2061.mp3" length="73674341" type="audio/mpeg"/><itunes:duration>01:16:45</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>61</itunes:episode><itunes:season>1</itunes:season><podcast:episode>61</podcast:episode><podcast:season>1</podcast:season><itunes:summary>The big problems with classic hypothesis testing are well-known. And yet, a huge majority of statistical analyses are still conducted this way. Why is it? Why are things so hard to change? Can you even do (and should you do) hypothesis testing in the Bayesian framework?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#60 Modeling Dialogues &amp; Languages, with J.P. de Ruiter</title><itunes:title>Modeling Dialogues &amp; Languages, with J.P. de Ruiter</itunes:title><description><![CDATA[<p class="ql-align-justify">Why do we, humans, communicate? And how? And isn’t that a problem that to study communication we have to… communicate?</p><p class="ql-align-justify">Did you ever ask yourself that? Because&nbsp;J.P. de Ruiter did — and does everyday. But he’s got good reasons: JP is a cognitive scientist whose primary research focus is on the cognitive foundations of human communication. He aims to improve our understanding of how humans and artificial agents use language, gesture and other types of signals to effectively communicate with each other.</p><p class="ql-align-justify">Currently he has one of the two Bridge Professorship at Tufts University, and has been appointed in both the Computer Science and Psychology departments.</p><p class="ql-align-justify">In this episode, we’ll look at why Bayes is helpful in dialogue research, what the future of the field looks like to JP, and how he uses PyMC in his own teaching.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>JP’s page: <a href="https://sites.tufts.edu/hilab/people/" rel="noopener noreferrer" target="_blank">https://sites.tufts.edu/hilab/people/</a></li><li>Projecting the End of a Speaker's Turn – A Cognitive Cornerstone of Conversation: <a href="https://www.researchgate.net/publication/236787756_Projecting_the_End_of_a_Speaker's_Turn_A_Cognitive_Cornerstone_of_Conversation" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/publication/236787756_Projecting_the_End_of_a_Speaker's_Turn_A_Cognitive_Cornerstone_of_Conversation</a></li><li>Cognitive and social delays in the initiation of conversational repair: <a href="https://journals.uic.edu/ojs/index.php/dad/article/view/11388" rel="noopener noreferrer" target="_blank">https://journals.uic.edu/ojs/index.php/dad/article/view/11388</a></li><li>Using uh and um in spontaneous speaking: <a href="http://www.columbia.edu/~rmk7/HC/HC_Readings/Clark_Fox.pdf" rel="noopener noreferrer" target="_blank">http://www.columbia.edu/~rmk7/HC/HC_Readings/Clark_Fox.pdf</a></li><li>Status of Frustrator as an Inhibitor of Horn-Honking Responses: <a href="https://www.tandfonline.com/doi/abs/10.1080/00224545.1968.9933615" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/00224545.1968.9933615</a></li><li>A Simplest Systematics for the Organization of Turn-Taking for Conversation: <a...]]></description><content:encoded><![CDATA[<p class="ql-align-justify">Why do we, humans, communicate? And how? And isn’t that a problem that to study communication we have to… communicate?</p><p class="ql-align-justify">Did you ever ask yourself that? Because&nbsp;J.P. de Ruiter did — and does everyday. But he’s got good reasons: JP is a cognitive scientist whose primary research focus is on the cognitive foundations of human communication. He aims to improve our understanding of how humans and artificial agents use language, gesture and other types of signals to effectively communicate with each other.</p><p class="ql-align-justify">Currently he has one of the two Bridge Professorship at Tufts University, and has been appointed in both the Computer Science and Psychology departments.</p><p class="ql-align-justify">In this episode, we’ll look at why Bayes is helpful in dialogue research, what the future of the field looks like to JP, and how he uses PyMC in his own teaching.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>JP’s page: <a href="https://sites.tufts.edu/hilab/people/" rel="noopener noreferrer" target="_blank">https://sites.tufts.edu/hilab/people/</a></li><li>Projecting the End of a Speaker's Turn – A Cognitive Cornerstone of Conversation: <a href="https://www.researchgate.net/publication/236787756_Projecting_the_End_of_a_Speaker's_Turn_A_Cognitive_Cornerstone_of_Conversation" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/publication/236787756_Projecting_the_End_of_a_Speaker's_Turn_A_Cognitive_Cornerstone_of_Conversation</a></li><li>Cognitive and social delays in the initiation of conversational repair: <a href="https://journals.uic.edu/ojs/index.php/dad/article/view/11388" rel="noopener noreferrer" target="_blank">https://journals.uic.edu/ojs/index.php/dad/article/view/11388</a></li><li>Using uh and um in spontaneous speaking: <a href="http://www.columbia.edu/~rmk7/HC/HC_Readings/Clark_Fox.pdf" rel="noopener noreferrer" target="_blank">http://www.columbia.edu/~rmk7/HC/HC_Readings/Clark_Fox.pdf</a></li><li>Status of Frustrator as an Inhibitor of Horn-Honking Responses: <a href="https://www.tandfonline.com/doi/abs/10.1080/00224545.1968.9933615" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/00224545.1968.9933615</a></li><li>A Simplest Systematics for the Organization of Turn-Taking for Conversation: <a href="https://www.jstor.org/stable/412243" rel="noopener noreferrer" target="_blank">https://www.jstor.org/stable/412243</a></li><li>Richard McElreath, Science Before Statistics – Intro to Causal Inference: <a href="https://www.youtube.com/watch?v=KNPYUVmY3NM" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=KNPYUVmY3NM</a></li><li>The Prosecutor's fallacy: <a href="https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></li><li>The Monty Hall problem: <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Monty_Hall_problem</a></li><li>LBS #50, Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://www.learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter</a></li><li>LBS #51, Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton:&nbsp;<a href="https://www.learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton</a></li><li>PyMC port of Lee and Wagenmakers' <em>Bayesian Cognitive Modeling</em>: <a href="https://github.com/pymc-devs/pymc-resources/tree/main/BCM" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc-resources/tree/main/BCM</a></li><li>ArviZ documentation: <a href="https://arviz-devs.github.io/arviz/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/60-modeling-dialogues-languages-jp-ruiter]]></link><guid isPermaLink="false">a0522f8b-a7fd-4436-b2d0-90ad1d4e1c43</guid><itunes:image href="https://artwork.captivate.fm/1fe0bb5d-b888-42bc-9f57-db36e0c65fe5/a6NTTTjT2Nygrux19kV2qc_m.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sat, 30 Apr 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5279f70a-8410-4af7-8c05-673fd6b57bec/Learning-20Bayesian-20Statistics-2060.mp3" length="69681149" type="audio/mpeg"/><itunes:duration>01:12:35</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>60</itunes:episode><itunes:season>1</itunes:season><podcast:episode>60</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Using Bayesian statistics to improve our understanding of how humans and artificial agents use language, gesture and other types of signals to effectively communicate with each other.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#59 Bayesian Modeling in Civil Engineering, with Michael Faber</title><itunes:title>Bayesian Modeling in Civil Engineering, with Michael Faber</itunes:title><description><![CDATA[<p>In large-scale one-off civil infrastructure, decision-making under uncertainty is part of the job, that’s just how it is. But, civil engineers don't get the luxury of building 10^6 versions of the bridge, offshore wind turbine or aeronautical structure to consider a relative frequency interpretation!</p><p>And as you’ll hear, challenges don’t stop there: you also have to consider natural hazards such as earthquakes, rockfall and typhoons — in case you were wondering, civil engineering is not among the boring jobs!</p><p>To talk about these original topics, I had the pleasure to host Michael Faber. Michael is a Professor at the Department of Built Environment at Aalborg University, Denmark, the President of the Joint Committee on Structural Safety and is a tremendously deep thinker on the Bayesian interpretation of probability as it pertains to the risk-informed management of big infrastructure.</p><p>His research interests are directed on governance and management of risks, resilience and sustainability in the built environment — doing all that with Bayesian probabilistic modeling and applied Bayesian decision analysis, as you’ll hear.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Michael's profile on Aalborg University: <a href="https://vbn.aau.dk/en/persons/100493" rel="noopener noreferrer" target="_blank">https://vbn.aau.dk/en/persons/100493</a></li><li>Michael's LinkedIn profile: <a href="https://www.linkedin.com/in/michael-havbro-faber-22898414/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/michael-havbro-faber-22898414/</a></li><li><em>Statistics and Probability Theory</em> - In Pursuit of Engineering Decision Support: <a href="https://link.springer.com/book/10.1007/978-94-007-4056-3" rel="noopener noreferrer" target="_blank">https://link.springer.com/book/10.1007/978-94-007-4056-3</a></li><li>Bayes in Civil Engineering - an abridged personal account of research and applications: <a href="https://www.linkedin.com/pulse/bayes-civil-engineering-michael-havbro-faber" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/pulse/bayes-civil-engineering-michael-havbro-faber</a></li><li>Website of the Joint Committee on Structural Safety (JCSS): <a href="https://www.jcss-lc.org/" rel="noopener noreferrer" target="_blank">https://www.jcss-lc.org/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>In large-scale one-off civil infrastructure, decision-making under uncertainty is part of the job, that’s just how it is. But, civil engineers don't get the luxury of building 10^6 versions of the bridge, offshore wind turbine or aeronautical structure to consider a relative frequency interpretation!</p><p>And as you’ll hear, challenges don’t stop there: you also have to consider natural hazards such as earthquakes, rockfall and typhoons — in case you were wondering, civil engineering is not among the boring jobs!</p><p>To talk about these original topics, I had the pleasure to host Michael Faber. Michael is a Professor at the Department of Built Environment at Aalborg University, Denmark, the President of the Joint Committee on Structural Safety and is a tremendously deep thinker on the Bayesian interpretation of probability as it pertains to the risk-informed management of big infrastructure.</p><p>His research interests are directed on governance and management of risks, resilience and sustainability in the built environment — doing all that with Bayesian probabilistic modeling and applied Bayesian decision analysis, as you’ll hear.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Michael's profile on Aalborg University: <a href="https://vbn.aau.dk/en/persons/100493" rel="noopener noreferrer" target="_blank">https://vbn.aau.dk/en/persons/100493</a></li><li>Michael's LinkedIn profile: <a href="https://www.linkedin.com/in/michael-havbro-faber-22898414/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/michael-havbro-faber-22898414/</a></li><li><em>Statistics and Probability Theory</em> - In Pursuit of Engineering Decision Support: <a href="https://link.springer.com/book/10.1007/978-94-007-4056-3" rel="noopener noreferrer" target="_blank">https://link.springer.com/book/10.1007/978-94-007-4056-3</a></li><li>Bayes in Civil Engineering - an abridged personal account of research and applications: <a href="https://www.linkedin.com/pulse/bayes-civil-engineering-michael-havbro-faber" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/pulse/bayes-civil-engineering-michael-havbro-faber</a></li><li>Website of the Joint Committee on Structural Safety (JCSS): <a href="https://www.jcss-lc.org/" rel="noopener noreferrer" target="_blank">https://www.jcss-lc.org/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/59-bayesian-modeling-civil-engineering-michael-faber]]></link><guid isPermaLink="false">549cb2e3-d400-4333-9434-aa0ac7540d46</guid><itunes:image href="https://artwork.captivate.fm/3f4b6a8c-780c-4098-a6aa-92035ce6f741/gbMB60fDi1EewM5ISn7bBrtK.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 14 Apr 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/27c99365-952f-4986-9dda-47055b9a9146/Learning-20Bayesian-20Statistics-2059.mp3" length="56853812" type="audio/mpeg"/><itunes:duration>59:13</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>59</itunes:episode><itunes:season>1</itunes:season><podcast:episode>59</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How to govern and manage risks, resilience and sustainability in the built environment... with Bayesian statistics!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#58 Bayesian Modeling and Computation, with Osvaldo Martin, Ravin Kumar and Junpeng Lao</title><itunes:title>Bayesian Modeling and Computation, with Osvaldo Martin, Ravin Kumar and Junpeng Lao</itunes:title><description><![CDATA[<p>You know when you have friends who wrote a book and pressure you to come on your podcast? That’s super annoying, right?</p><p>Well that’s not what happened with <a href="https://twitter.com/canyon289" rel="noopener noreferrer" target="_blank">Ravin Kumar</a>, <a href="https://twitter.com/aloctavodia" rel="noopener noreferrer" target="_blank">Osvaldo Martin</a> and <a href="https://twitter.com/junpenglao" rel="noopener noreferrer" target="_blank">Junpeng Lao</a> — I was the one who suggested doing a special episode about their new book, <a href="https://bayesiancomputationbook.com/welcome.html" rel="noopener noreferrer" target="_blank"><em>Bayesian Modeling and Computation in Python</em></a>. And since they cannot say no to my soothing French accent, well, they didn’t say no…</p><p>All of them were on the podcast already, so I’ll refer you to their solo episode for background on their background — aka backgroundception.</p><p>Junpeng is a Data Scientist at Google, living in Zurich, Switzerland. Previously, he was a post-doc in Psychology and Cognitive Neuroscience. His current obsessions are time series and state space models.&nbsp;</p><p>Osvaldo is a Researcher at CONICET in Argentina and the Department of Computer Science from Aalto University in Finland. He is especially motivated by the development and implementation of software tools for Bayesian statistics and probabilistic modeling.</p><p>Ravin is a data scientist at Google, living in Los Angeles. Previously he worked at Sweetgreen and SpaceX. He became interested in Bayesian statistics when trying to quantify uncertainty in operations. He is especially interested in decision science in business settings.</p><p>You’ll make your own opinion, but I like their book because uses a hands-on approach, focusing on the practice of applied statistics. And you get to see how to use diverse libraries, like PyMC, Tensorflow Probability, ArviZ, Bambi, and so on. You’ll see what I’m talking about in this episode.</p><p>To top it off, the book is fully available online at <a href="https://bayesiancomputationbook.com/welcome.html" rel="noopener noreferrer" target="_blank">bayesiancomputationbook.com</a>. If you want a physical copy (because you love those guys and wanna support them), <strong>go to CRC website and enter the code ASA18 at checkout for a 30% discount</strong>.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the...]]></description><content:encoded><![CDATA[<p>You know when you have friends who wrote a book and pressure you to come on your podcast? That’s super annoying, right?</p><p>Well that’s not what happened with <a href="https://twitter.com/canyon289" rel="noopener noreferrer" target="_blank">Ravin Kumar</a>, <a href="https://twitter.com/aloctavodia" rel="noopener noreferrer" target="_blank">Osvaldo Martin</a> and <a href="https://twitter.com/junpenglao" rel="noopener noreferrer" target="_blank">Junpeng Lao</a> — I was the one who suggested doing a special episode about their new book, <a href="https://bayesiancomputationbook.com/welcome.html" rel="noopener noreferrer" target="_blank"><em>Bayesian Modeling and Computation in Python</em></a>. And since they cannot say no to my soothing French accent, well, they didn’t say no…</p><p>All of them were on the podcast already, so I’ll refer you to their solo episode for background on their background — aka backgroundception.</p><p>Junpeng is a Data Scientist at Google, living in Zurich, Switzerland. Previously, he was a post-doc in Psychology and Cognitive Neuroscience. His current obsessions are time series and state space models.&nbsp;</p><p>Osvaldo is a Researcher at CONICET in Argentina and the Department of Computer Science from Aalto University in Finland. He is especially motivated by the development and implementation of software tools for Bayesian statistics and probabilistic modeling.</p><p>Ravin is a data scientist at Google, living in Los Angeles. Previously he worked at Sweetgreen and SpaceX. He became interested in Bayesian statistics when trying to quantify uncertainty in operations. He is especially interested in decision science in business settings.</p><p>You’ll make your own opinion, but I like their book because uses a hands-on approach, focusing on the practice of applied statistics. And you get to see how to use diverse libraries, like PyMC, Tensorflow Probability, ArviZ, Bambi, and so on. You’ll see what I’m talking about in this episode.</p><p>To top it off, the book is fully available online at <a href="https://bayesiancomputationbook.com/welcome.html" rel="noopener noreferrer" target="_blank">bayesiancomputationbook.com</a>. If you want a physical copy (because you love those guys and wanna support them), <strong>go to CRC website and enter the code ASA18 at checkout for a 30% discount</strong>.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Website of the book: <a href="https://bayesiancomputationbook.com/welcome.html" rel="noopener noreferrer" target="_blank">https://bayesiancomputationbook.com/welcome.html</a></li><li>LBS #1 -- Bayes, open-source and bioinformatics, with Osvaldo Martin: <a href="https://www.learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin</a></li><li>Osvaldo on Twitter: <a href="https://twitter.com/aloctavodia" rel="noopener noreferrer" target="_blank">https://twitter.com/aloctavodia</a></li><li>LBS #26 -- What you'll learn &amp; who you'll meet at the PyMC Conference, with Ravin Kumar &amp; Quan Nguyen: <a href="https://www.learnbayesstats.com/episode/26-what-youll-learn-who-youll-meet-at-the-pymc-conference-with-ravin-kumar-quan-nguyen" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/26-what-youll-learn-who-youll-meet-at-the-pymc-conference-with-ravin-kumar-quan-nguyen</a></li><li>Ravin's blog: <a href="https://ravinkumar.com/" rel="noopener noreferrer" target="_blank">https://ravinkumar.com/</a></li><li>Ravin on Twitter: <a href="https://twitter.com/canyon289" rel="noopener noreferrer" target="_blank">https://twitter.com/canyon289</a></li><li>LBS #7 -- Designing a Probabilistic Programming Language &amp; Debugging a Model, with Junpeng Lao: <a href="https://www.learnbayesstats.com/episode/7-designing-a-probabilistic-programming-language-debugging-a-model-with-junpeng-lao" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/7-designing-a-probabilistic-programming-language-debugging-a-model-with-junpeng-lao</a></li><li>Junpeng on Twitter: <a href="https://twitter.com/junpenglao" rel="noopener noreferrer" target="_blank">https://twitter.com/junpenglao</a></li><li>Matchmaking Dinner #1, with Will Kurt and Junpeng Lao: <a href="https://www.patreon.com/posts/48360540" rel="noopener noreferrer" target="_blank">https://www.patreon.com/posts/48360540</a></li><li>Donate to PyMC: <a href="https://numfocus.org/pymc-bayesian-book-form" rel="noopener noreferrer" target="_blank">https://numfocus.org/pymc-bayesian-book-form</a></li><li>Donate to ArviZ: <a href="https://numfocus.org/arviz-bayesian-book-form" rel="noopener noreferrer" target="_blank">https://numfocus.org/arviz-bayesian-book-form</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/58-bayesian-modeling-computation-osvaldo-martin-ravin-kumar-junpeng-lao]]></link><guid isPermaLink="false">9e54b1f2-3f1d-4107-b308-2e61c51a91c4</guid><itunes:image href="https://artwork.captivate.fm/e70989e2-ed57-43ab-bd5e-d6d360351c6a/5it5xAsmnYphHIqtrC8mOFGg.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 21 Mar 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6abcdb4f-8d67-45a9-ad71-781f2c74cefa/learning-bayesian-statistics-58.mp3" length="66655814" type="audio/mpeg"/><itunes:duration>01:09:26</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>58</itunes:episode><itunes:season>1</itunes:season><podcast:episode>58</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Get a hands-on approach, focusing on the practice of applied statistics. And you&apos;ll see how to use diverse libraries, like PyMC, Tensorflow Probability, ArviZ, Bambi, and so on!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#57 Forecasting French Elections, with… Mystery Guest</title><itunes:title>Forecasting French Elections, with... Mystery Guest</itunes:title><description><![CDATA[<p>No, no, don't leave! You did not click on the wrong button. You are indeed on Alex Andorra’s podcast. The podcast that took the Bayesian world by a storm: “Learning Bayesian Statistics”, and that Barack Obama deemed “the best podcast in the whole galaxy” – or maybe Alex said that, I don’t remember.</p><p>Alex made us discover new methods, new ideas, and mostly new people. But what do we <em>really</em> know about him? Does he even really <em>exist</em>? To find this out I put on my Frenchest beret, a baguette under my arm, and went undercover to try to find him.</p><p>And I did ! So today for a special episode I, <a href="https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf" rel="noopener noreferrer" target="_blank">Rémi Louf</a>, will be the one asking questions and making bad jokes with a French accent.</p><p>Before letting him in, here’s what I got on him so far.</p><p>By day, Alex is a Bayesian modeler at the <a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank">PyMC Labs</a> consultancy. By night, he doesn’t (yet) fight crime but he’s an open-source enthusiast and core contributor to <a href="https://docs.pymc.io/en/v3/" rel="noopener noreferrer" target="_blank">PyMC</a> and <a href="https://arviz-devs.github.io/" rel="noopener noreferrer" target="_blank">ArviZ</a>.</p><p>An always-learning statistician, Alex loves building models and <a href="https://github.com/pollsposition/models" rel="noopener noreferrer" target="_blank">studying elections</a> and human behavior.</p><p>When he’s not working, he loves hiking, exercising, meditating and reading nerdy books and novels. He also loves chocolate a bit too much, but he doesn’t like talking about it – he prefers eating it.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Alex on Twitter: <a href="https://twitter.com/alex_andorra" rel="noopener noreferrer" target="_blank">https://twitter.com/alex_andorra</a></li><li>Alex on GitHub: <a href="https://github.com/AlexAndorra" rel="noopener noreferrer" target="_blank">https://github.com/AlexAndorra</a></li><li>Alex on LinkedIn: <a href="https://www.linkedin.com/in/aandorra-pollsposition/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/aandorra-pollsposition/</a></li><li>Intuitive Bayes Introductory Course: <a href="https://www.intuitivebayes.com/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>No, no, don't leave! You did not click on the wrong button. You are indeed on Alex Andorra’s podcast. The podcast that took the Bayesian world by a storm: “Learning Bayesian Statistics”, and that Barack Obama deemed “the best podcast in the whole galaxy” – or maybe Alex said that, I don’t remember.</p><p>Alex made us discover new methods, new ideas, and mostly new people. But what do we <em>really</em> know about him? Does he even really <em>exist</em>? To find this out I put on my Frenchest beret, a baguette under my arm, and went undercover to try to find him.</p><p>And I did ! So today for a special episode I, <a href="https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf" rel="noopener noreferrer" target="_blank">Rémi Louf</a>, will be the one asking questions and making bad jokes with a French accent.</p><p>Before letting him in, here’s what I got on him so far.</p><p>By day, Alex is a Bayesian modeler at the <a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank">PyMC Labs</a> consultancy. By night, he doesn’t (yet) fight crime but he’s an open-source enthusiast and core contributor to <a href="https://docs.pymc.io/en/v3/" rel="noopener noreferrer" target="_blank">PyMC</a> and <a href="https://arviz-devs.github.io/" rel="noopener noreferrer" target="_blank">ArviZ</a>.</p><p>An always-learning statistician, Alex loves building models and <a href="https://github.com/pollsposition/models" rel="noopener noreferrer" target="_blank">studying elections</a> and human behavior.</p><p>When he’s not working, he loves hiking, exercising, meditating and reading nerdy books and novels. He also loves chocolate a bit too much, but he doesn’t like talking about it – he prefers eating it.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Alex on Twitter: <a href="https://twitter.com/alex_andorra" rel="noopener noreferrer" target="_blank">https://twitter.com/alex_andorra</a></li><li>Alex on GitHub: <a href="https://github.com/AlexAndorra" rel="noopener noreferrer" target="_blank">https://github.com/AlexAndorra</a></li><li>Alex on LinkedIn: <a href="https://www.linkedin.com/in/aandorra-pollsposition/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/aandorra-pollsposition/</a></li><li>Intuitive Bayes Introductory Course: <a href="https://www.intuitivebayes.com/" rel="noopener noreferrer" target="_blank">https://www.intuitivebayes.com/</a></li><li>PyMC Labs consultancy: <a href="https://www.pymc-labs.io/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/</a></li><li>PollsPosition GitHub repository: <a href="https://github.com/pollsposition" rel="noopener noreferrer" target="_blank">https://github.com/pollsposition</a></li><li>French Presidents' popularity dashboard: <a href="https://www.pollsposition.com/popularity" rel="noopener noreferrer" target="_blank">https://www.pollsposition.com/popularity</a></li><li><em>Learning Bayesian Statistics</em> YouTube channel: <a href="https://www.youtube.com/channel/UCAwVseuhVrpJFfik_cMHrhQ" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCAwVseuhVrpJFfik_cMHrhQ</a></li><li>Love the podcast? Leave a review on Podchaser: <a href="https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588" rel="noopener noreferrer" target="_blank">https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/57-forecasting-french-elections-alexandre-andorra]]></link><guid isPermaLink="false">2e1d49e5-89f6-4d0d-8d21-9e796ff668bf</guid><itunes:image href="https://artwork.captivate.fm/cd75552f-4b6c-458b-8d68-b59a1d4de821/U6XcknBlMnBbCqdTBFdiTZgq.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 03 Mar 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/35ec6570-2bd3-4df3-b496-825c8684d19e/learning-bayesian-statistics-57.mp3" length="78540731" type="audio/mpeg"/><itunes:duration>01:21:49</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>57</itunes:episode><itunes:season>1</itunes:season><podcast:episode>57</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Alex made us discover new methods, new ideas, and mostly new people. But what do we really know about him? Does he even really exist? To find this out I put on my Frenchest beret, a baguette under my arm, and went undercover to try to find him.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#56 Causal &amp; Probabilistic Machine Learning, with Robert Osazuwa Ness</title><itunes:title>Causal &amp; Probabilistic Machine Learning, with Robert Osazuwa Ness</itunes:title><description><![CDATA[<p>Did you know there is a relationship between the size of firetrucks and the amount of damage down to a flat during a fire? The bigger the truck sent to put out the fire, the bigger the damages tend to be. The solution is simple: just send smaller firetrucks!</p><p>Wait, that doesn’t sound right, does it? Our brain is a huge causal machine, so it can instinctively feel it’s not credible that size of truck and amount of damage done are <em>causally</em> related: there must be another variable explaining the correlation. Here, it’s of course the seriousness of the fire — even better, it’s the <em>common cause</em> of the two correlated variables.</p><p>Your brain does that automatically, but what about your computer? How do you make sure it doesn’t just happily (and mistakenly) report the correlation? That’s when causal inference and machine learning enter the stage, as Robert Osazuwa Ness will tell us.</p><p>Robert has a PhD in statistics from Purdue University. He currently works as a Research Scientist at Microsoft Research and a founder of altdeep.ai, which teaches live cohort-based courses on advanced topics in applied modeling.&nbsp;</p><p>As you’ll hear, his research focuses on the intersection of causal and probabilistic machine learning. Maybe that’s why I invited him on the show… Well, who knows, causal inference is very hard!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Robert's webpage: <a href="https://www.microsoft.com/en-us/research/people/robertness/" rel="noopener noreferrer" target="_blank">https://www.microsoft.com/en-us/research/people/robertness/</a></li><li>Robert on Twitter: <a href="https://twitter.com/osazuwa" rel="noopener noreferrer" target="_blank">https://twitter.com/osazuwa</a></li><li>Robert on GitHub: <a href="https://github.com/robertness" rel="noopener noreferrer" target="_blank">https://github.com/robertness</a></li><li>Robert on LinkedIn: <a href="https://www.linkedin.com/in/osazuwa/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/osazuwa/</a></li><li><em>Do-calculus enables causal reasoning with latent variable models</em>, Arxiv: <a href="https://arxiv.org/abs/2102.06626" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2102.06626</a></li><li><em>Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems</em>, NeurIPS...]]></description><content:encoded><![CDATA[<p>Did you know there is a relationship between the size of firetrucks and the amount of damage down to a flat during a fire? The bigger the truck sent to put out the fire, the bigger the damages tend to be. The solution is simple: just send smaller firetrucks!</p><p>Wait, that doesn’t sound right, does it? Our brain is a huge causal machine, so it can instinctively feel it’s not credible that size of truck and amount of damage done are <em>causally</em> related: there must be another variable explaining the correlation. Here, it’s of course the seriousness of the fire — even better, it’s the <em>common cause</em> of the two correlated variables.</p><p>Your brain does that automatically, but what about your computer? How do you make sure it doesn’t just happily (and mistakenly) report the correlation? That’s when causal inference and machine learning enter the stage, as Robert Osazuwa Ness will tell us.</p><p>Robert has a PhD in statistics from Purdue University. He currently works as a Research Scientist at Microsoft Research and a founder of altdeep.ai, which teaches live cohort-based courses on advanced topics in applied modeling.&nbsp;</p><p>As you’ll hear, his research focuses on the intersection of causal and probabilistic machine learning. Maybe that’s why I invited him on the show… Well, who knows, causal inference is very hard!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Yoshiyuki Hamajima, Sven De Maeyer, Michael DeCrescenzo, Fergal M, Mason Yahr, Naoya Kanai, Steven Rowland and Aubrey Clayton.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Robert's webpage: <a href="https://www.microsoft.com/en-us/research/people/robertness/" rel="noopener noreferrer" target="_blank">https://www.microsoft.com/en-us/research/people/robertness/</a></li><li>Robert on Twitter: <a href="https://twitter.com/osazuwa" rel="noopener noreferrer" target="_blank">https://twitter.com/osazuwa</a></li><li>Robert on GitHub: <a href="https://github.com/robertness" rel="noopener noreferrer" target="_blank">https://github.com/robertness</a></li><li>Robert on LinkedIn: <a href="https://www.linkedin.com/in/osazuwa/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/osazuwa/</a></li><li><em>Do-calculus enables causal reasoning with latent variable models</em>, Arxiv: <a href="https://arxiv.org/abs/2102.06626" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2102.06626</a></li><li><em>Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems</em>, NeurIPS Proceedings: <a href="https://proceedings.neurips.cc/paper/2019/hash/2d44e06a7038f2dd98f0f54c4be35e22-Abstract.html" rel="noopener noreferrer" target="_blank">https://proceedings.neurips.cc/paper/2019/hash/2d44e06a7038f2dd98f0f54c4be35e22-Abstract.html</a></li><li>Causality 101 with Robert Ness, <em>The TWIML AI Podcast</em>: <a href="https://www.youtube.com/watch?v=UNEZztT5lpk" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=UNEZztT5lpk</a></li><li><em>Causal Modeling in Machine Learning</em>, PyData Boston: <a href="https://www.youtube.com/watch?v=1BioSmE5m6s" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=1BioSmE5m6s</a></li><li>Pyro -- Deep Universal Probabilistic Programming: <a href="http://pyro.ai/" rel="noopener noreferrer" target="_blank">http://pyro.ai/</a></li><li><em>Statistical Rethinking</em> website: <a href="http://xcelab.net/rm/statistical-rethinking/" rel="noopener noreferrer" target="_blank">http://xcelab.net/rm/statistical-rethinking/</a></li><li><em>The Book of Why -- The New Science of Cause and Effect </em>: <a href="https://www.goodreads.com/book/show/36204378-the-book-of-why" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/36204378-the-book-of-why</a></li><li><em>The Theory That Would Not Die -- How Bayes' Rule Cracked the Enigma Code </em>: <a href="https://www.goodreads.com/book/show/10672848-the-theory-that-would-not-die" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/10672848-the-theory-that-would-not-die</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/56-causal-probabilistic-machine-learning-robert-ness]]></link><guid isPermaLink="false">50525d67-94a2-4077-ad55-e6d8bb3e5ae9</guid><itunes:image href="https://artwork.captivate.fm/ce046f43-300d-4bf5-b11c-82299c89de49/-RgnOi07fIU8BEZqAqJihoY3.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 16 Feb 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/10239000-5aa7-4db3-8d50-0f45cba2c287/learning-bayesian-statistics-56.mp3" length="66197948" type="audio/mpeg"/><itunes:duration>01:08:57</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>56</itunes:episode><itunes:season>1</itunes:season><podcast:episode>56</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How do you make sure your computer doesn’t just happily (and mistakenly) report correlations as causations? That’s when causal and probabilistic machine learning enter the stage, as Robert Ness will tell us...</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#55 Neuropsychology, Illusions &amp; Bending Reality, with Dominique Makowski</title><itunes:title>Neuropsychology, Illusions &amp; Bending Reality, with Dominique Makowski</itunes:title><description><![CDATA[<p>What’s the common point between fiction, fake news, illusions and meditation? They can all be studied with Bayesian statistics, of course!</p><p>In this mind-bending episode, Dominique Makowski will for sure expand your horizon. Trained as a clinical neuropsychologist, he is currently working as a postdoc at the Clinical Brain Lab in Singapore, in which he leads the Reality Bending Team. What’s reality-bending you ask? Well, you’ll have to listen to the episode, but I can already tell you we’ll go through a journey in scientific methodology, history of art, religion, and philosophy — what else?</p><p>Beyond that, Dominique tries to improve the access to advanced analysis techniques by developing open-source software and tools, like the NeuroKit Python package or the bayestestR package in R.</p><p>Even better, he looks a lot like his figures of reference. Like Marcus Aurelius, he plays the piano and guitar. Like Sisyphus, he loves history of art and comparative mythology. And like Yoda, he is a wakeboard master.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Daniel Lindroth, Yoshiyuki Hamajima, Sven De Maeyer and Michael DeCrescenzo.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li><strong>To follow:</strong></li><li class="ql-align-justify">Dominique's website: <a href="https://dominiquemakowski.github.io/" rel="noopener noreferrer" target="_blank">https://dominiquemakowski.github.io/</a></li><li class="ql-align-justify">Dominique on Twitter: <a href="https://twitter.com/Dom_Makowski" rel="noopener noreferrer" target="_blank">https://twitter.com/Dom_Makowski</a></li><li class="ql-align-justify">Dominique on GitHub: <a href="https://github.com/DominiqueMakowski" rel="noopener noreferrer" target="_blank">https://github.com/DominiqueMakowski</a></li><li class="ql-align-justify"><strong>Packages:</strong></li><li>NeuroKit -- Python Toolbox for Neurophysiological Signal Processing: <a href="https://github.com/neuropsychology/NeuroKit" rel="noopener noreferrer" target="_blank">https://github.com/neuropsychology/NeuroKit</a></li><li>bayestestR -- Become a Bayesian master you will: <a href="https://easystats.github.io/bayestestR/" rel="noopener noreferrer" target="_blank">https://easystats.github.io/bayestestR/</a></li><li>report -- From R to your manuscript: <a href="https://easystats.github.io/report/" rel="noopener noreferrer" target="_blank">https://easystats.github.io/report/</a></li><li class="ql-align-justify"><strong>Research:</strong></li><li class="ql-align-justify">The Reality Bending...]]></description><content:encoded><![CDATA[<p>What’s the common point between fiction, fake news, illusions and meditation? They can all be studied with Bayesian statistics, of course!</p><p>In this mind-bending episode, Dominique Makowski will for sure expand your horizon. Trained as a clinical neuropsychologist, he is currently working as a postdoc at the Clinical Brain Lab in Singapore, in which he leads the Reality Bending Team. What’s reality-bending you ask? Well, you’ll have to listen to the episode, but I can already tell you we’ll go through a journey in scientific methodology, history of art, religion, and philosophy — what else?</p><p>Beyond that, Dominique tries to improve the access to advanced analysis techniques by developing open-source software and tools, like the NeuroKit Python package or the bayestestR package in R.</p><p>Even better, he looks a lot like his figures of reference. Like Marcus Aurelius, he plays the piano and guitar. Like Sisyphus, he loves history of art and comparative mythology. And like Yoda, he is a wakeboard master.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones, Daniel Lindroth, Yoshiyuki Hamajima, Sven De Maeyer and Michael DeCrescenzo.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li><strong>To follow:</strong></li><li class="ql-align-justify">Dominique's website: <a href="https://dominiquemakowski.github.io/" rel="noopener noreferrer" target="_blank">https://dominiquemakowski.github.io/</a></li><li class="ql-align-justify">Dominique on Twitter: <a href="https://twitter.com/Dom_Makowski" rel="noopener noreferrer" target="_blank">https://twitter.com/Dom_Makowski</a></li><li class="ql-align-justify">Dominique on GitHub: <a href="https://github.com/DominiqueMakowski" rel="noopener noreferrer" target="_blank">https://github.com/DominiqueMakowski</a></li><li class="ql-align-justify"><strong>Packages:</strong></li><li>NeuroKit -- Python Toolbox for Neurophysiological Signal Processing: <a href="https://github.com/neuropsychology/NeuroKit" rel="noopener noreferrer" target="_blank">https://github.com/neuropsychology/NeuroKit</a></li><li>bayestestR -- Become a Bayesian master you will: <a href="https://easystats.github.io/bayestestR/" rel="noopener noreferrer" target="_blank">https://easystats.github.io/bayestestR/</a></li><li>report -- From R to your manuscript: <a href="https://easystats.github.io/report/" rel="noopener noreferrer" target="_blank">https://easystats.github.io/report/</a></li><li class="ql-align-justify"><strong>Research:</strong></li><li class="ql-align-justify">The Reality Bending League :<a href="https://realitybending.github.io/research/" rel="noopener noreferrer" target="_blank">https://realitybending.github.io/research/</a></li><li>What is Reality Bending: <a href="https://realitybending.github.io/post/2020-09-28-what_is_realitybending/" rel="noopener noreferrer" target="_blank">https://realitybending.github.io/post/2020-09-28-what_is_realitybending/</a></li><li><strong>Art:</strong></li><li class="ql-align-justify">NeuropsyXart -- Neuroimaging methods to obtain visual representations of neurophysiological processes: <a href="https://dominiquemakowski.github.io/NeuropsyXart/" rel="noopener noreferrer" target="_blank">https://dominiquemakowski.github.io/NeuropsyXart/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/55-neuropsychology-illusions-bending-reality-dominique-makowski]]></link><guid isPermaLink="false">bcf2ec64-fef8-44e3-a44b-a4be01085e97</guid><itunes:image href="https://artwork.captivate.fm/46eb2fed-e9f7-4e2d-b2f2-1ae37abfa957/sno54AN5CnvYbcyaovrSRnpq.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 31 Jan 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/aecbb9e9-4dc1-4214-8889-9f34d2e2b68f/learning-bayesian-statistics-55.mp3" length="70689455" type="audio/mpeg"/><itunes:duration>01:13:38</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>55</itunes:episode><itunes:season>1</itunes:season><podcast:episode>55</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A nerdy journey through scientific methodology, history of art, religion, and philosophy — what else?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#54 Bayes in Theoretical Ecology, with Florian Hartig</title><itunes:title>Bayes in Theoretical Ecology, with Florian Hartig</itunes:title><description><![CDATA[<p>Let’s be honest: evolution is awesome! I started reading <em>Improbable Destinies: Fate, Chance, and the Future of Evolution</em>, by&nbsp;Jonathan Losos, and I’m utterly fascinated.&nbsp;</p><p>So I’m thrilled to welcome Florian Hartig on the show. Florian is a professor of Theoretical Ecology at the University of Regensburg, Germany. His research concentrates on theory, computer simulations, statistical methods and machine learning in ecology &amp; evolution. He is also interested in open science and open software development, and maintains, among other projects, the R packages DHARMa and BayesianTools.</p><p>Among other things, we talked about approximate Bayesian computation, best practices when building models and the big pain points that remain in the Bayesian pipeline.</p><p>Most importantly, Florian’s main hobbies are whitewater kayaking, snowboarding, badminton and playing the guitar.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones and Daniel Lindroth</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Florian's website: <a href="https://theoreticalecology.wordpress.com/" rel="noopener noreferrer" target="_blank">https://theoreticalecology.wordpress.com/</a></li><li>Florian on Twitter: <a href="https://twitter.com/florianhartig" rel="noopener noreferrer" target="_blank">https://twitter.com/florianhartig</a></li><li>Florian on GitHub: <a href="https://github.com/florianhartig" rel="noopener noreferrer" target="_blank">https://github.com/florianhartig</a></li><li>DHARMa -- Residual Diagnostics for Hierarchical Regression Models: <a href="https://cran.r-project.org/web/packages/DHARMa/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/DHARMa/index.html</a></li><li>BayesianTools -- General-Purpose MCMC and SMC Samplers and Tools for Bayesian Statistics: <a href="https://cran.r-project.org/web/packages/BayesianTools/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/BayesianTools/index.html</a></li><li>Statistical inference for stochastic simulation inference -- theory and application: <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1461-0248.2011.01640.x" rel="noopener noreferrer" target="_blank">https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1461-0248.2011.01640.x</a></li><li>ArviZ plot rank function: <a href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_rank.html" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>Let’s be honest: evolution is awesome! I started reading <em>Improbable Destinies: Fate, Chance, and the Future of Evolution</em>, by&nbsp;Jonathan Losos, and I’m utterly fascinated.&nbsp;</p><p>So I’m thrilled to welcome Florian Hartig on the show. Florian is a professor of Theoretical Ecology at the University of Regensburg, Germany. His research concentrates on theory, computer simulations, statistical methods and machine learning in ecology &amp; evolution. He is also interested in open science and open software development, and maintains, among other projects, the R packages DHARMa and BayesianTools.</p><p>Among other things, we talked about approximate Bayesian computation, best practices when building models and the big pain points that remain in the Bayesian pipeline.</p><p>Most importantly, Florian’s main hobbies are whitewater kayaking, snowboarding, badminton and playing the guitar.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones and Daniel Lindroth</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Florian's website: <a href="https://theoreticalecology.wordpress.com/" rel="noopener noreferrer" target="_blank">https://theoreticalecology.wordpress.com/</a></li><li>Florian on Twitter: <a href="https://twitter.com/florianhartig" rel="noopener noreferrer" target="_blank">https://twitter.com/florianhartig</a></li><li>Florian on GitHub: <a href="https://github.com/florianhartig" rel="noopener noreferrer" target="_blank">https://github.com/florianhartig</a></li><li>DHARMa -- Residual Diagnostics for Hierarchical Regression Models: <a href="https://cran.r-project.org/web/packages/DHARMa/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/DHARMa/index.html</a></li><li>BayesianTools -- General-Purpose MCMC and SMC Samplers and Tools for Bayesian Statistics: <a href="https://cran.r-project.org/web/packages/BayesianTools/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/BayesianTools/index.html</a></li><li>Statistical inference for stochastic simulation inference -- theory and application: <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1461-0248.2011.01640.x" rel="noopener noreferrer" target="_blank">https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1461-0248.2011.01640.x</a></li><li>ArviZ plot rank function: <a href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_rank.html" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/api/generated/arviz.plot_rank.html</a></li><li>Rank-normalization, folding, and localization -- An improved R-hat for assessing convergence of MCMC: <a href="https://arxiv.org/abs/1903.08008" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1903.08008</a></li><li>LBS #51 Bernoulli's Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton: <a href="https://www.learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton</a></li><li>LBS #50 Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter: <a href="https://www.learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/50-talking-risks-embracing-uncertainty-david-spiegelhalter</a></li><li>LBS #44 Building Bayesian Models at scale, with Rémi Louf: <a href="https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/44-bayesian-models-at-scale-remi-louf</a></li><li>LBS #35 The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner</a></li><li>LBS #29 Model Assessment, Non-Parametric Models, And Much More, with Aki Vehtari: <a href="https://www.learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari</a></li><li>Improbable Destinies -- Fate, Chance, and the Future of Evolution: <a href="https://www.goodreads.com/book/show/33357463-improbable-destinies" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/33357463-improbable-destinies</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/54-bayes-theoretical-ecology-florian-hartig]]></link><guid isPermaLink="false">0212f7bb-37c3-437a-8dca-0a29b769279f</guid><itunes:image href="https://artwork.captivate.fm/b136a4d9-aabf-456e-81f4-000c3630560a/cpOLVVpOe5RhySeitqvZVCw2.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 14 Jan 2022 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/232bc772-685e-45ab-9860-21c6c1c81876/learning-bayesian-statistics-54.mp3" length="65893538" type="audio/mpeg"/><itunes:duration>01:08:38</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>54</itunes:episode><itunes:season>1</itunes:season><podcast:episode>54</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A discussion about theoretical ecology, computer simulations and machine learning in ecology and evolution</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#53 Bayesian Stats for the Behavioral &amp; Neural Sciences, with Todd Hudson</title><itunes:title>Bayesian Stats for the Behavioral &amp; Neural Sciences, with Todd Hudson</itunes:title><description><![CDATA[<p class="ql-align-justify"><strong><em>Get a </em></strong><a href="https://www.cambridge.org/it/academic/subjects/psychology/psychology-general-interest/bayesian-data-analysis-behavioral-and-neural-sciences-non-calculus-fundamentals?format=PB&amp;isbn=9781108812900" rel="noopener noreferrer" target="_blank"><strong><em>30% discount on Todd's book</em></strong></a><strong><em> by entering the code </em>BDABNS22<em> at checkout!</em></strong></p><p>The behavioral and neural sciences are a nerdy interest of mine, but I didn’t dedicate any episode to that topic yet. But life brings you gifts sometimes (especially around Christmas…), and here that gift is a book, <em>Bayesian Data Analysis for the Behavioral and Neural Sciences</em>, by Todd Hudson.</p><p>Todd is a part of the faculty at New York University Grossman School of Medicine and also the New York University Tandon School of Engineering. He is a computational neuroscientist working in several areas including: early detection and grading of neurological disease; computational models of movement planning and learning; development of new computational and experimental techniques.&nbsp;</p><p>He also co-founded Tactile Navigation Tools, which develops navigation aids for the visually impaired, and Third Eye Technologies, which develops low cost laboratory- and clinical-grade eyetracking technologies.</p><p>As you’ll hear, Todd wanted his book to bypass the need for advanced mathematics normally considered a prerequisite for this type of material. Basically, he wants students to be able to write code and models and understand equations, even they are not specialized in <em>writing</em> those equations.</p><p>We’ll also touch on some of the neural sciences examples he’s got in the book, as well as the two general algorithms he uses for model measurement and model selection.</p><p>Ow, I almost forgot the most important: Todd loves beekeeping and gardening — he’s got 25 apple trees, 4 cherry trees, nectarines, figs, strawberries, etc!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones and Daniel Lindroth</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li><strong>30% discount</strong> on Todd's book by entering <strong>BDABNS22</strong> at checkout: <a href="https://www.cambridge.org/it/academic/subjects/psychology/psychology-general-interest/bayesian-data-analysis-behavioral-and-neural-sciences-non-calculus-fundamentals?format=PB&amp;isbn=9781108812900" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p class="ql-align-justify"><strong><em>Get a </em></strong><a href="https://www.cambridge.org/it/academic/subjects/psychology/psychology-general-interest/bayesian-data-analysis-behavioral-and-neural-sciences-non-calculus-fundamentals?format=PB&amp;isbn=9781108812900" rel="noopener noreferrer" target="_blank"><strong><em>30% discount on Todd's book</em></strong></a><strong><em> by entering the code </em>BDABNS22<em> at checkout!</em></strong></p><p>The behavioral and neural sciences are a nerdy interest of mine, but I didn’t dedicate any episode to that topic yet. But life brings you gifts sometimes (especially around Christmas…), and here that gift is a book, <em>Bayesian Data Analysis for the Behavioral and Neural Sciences</em>, by Todd Hudson.</p><p>Todd is a part of the faculty at New York University Grossman School of Medicine and also the New York University Tandon School of Engineering. He is a computational neuroscientist working in several areas including: early detection and grading of neurological disease; computational models of movement planning and learning; development of new computational and experimental techniques.&nbsp;</p><p>He also co-founded Tactile Navigation Tools, which develops navigation aids for the visually impaired, and Third Eye Technologies, which develops low cost laboratory- and clinical-grade eyetracking technologies.</p><p>As you’ll hear, Todd wanted his book to bypass the need for advanced mathematics normally considered a prerequisite for this type of material. Basically, he wants students to be able to write code and models and understand equations, even they are not specialized in <em>writing</em> those equations.</p><p>We’ll also touch on some of the neural sciences examples he’s got in the book, as well as the two general algorithms he uses for model measurement and model selection.</p><p>Ow, I almost forgot the most important: Todd loves beekeeping and gardening — he’s got 25 apple trees, 4 cherry trees, nectarines, figs, strawberries, etc!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King, Aaron Jones and Daniel Lindroth</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li><strong>30% discount</strong> on Todd's book by entering <strong>BDABNS22</strong> at checkout: <a href="https://www.cambridge.org/it/academic/subjects/psychology/psychology-general-interest/bayesian-data-analysis-behavioral-and-neural-sciences-non-calculus-fundamentals?format=PB&amp;isbn=9781108812900" rel="noopener noreferrer" target="_blank">https://www.cambridge.org/it/academic/subjects/psychology/psychology-general-interest/bayesian-data-analysis-behavioral-and-neural-sciences-non-calculus-fundamentals?format=PB&amp;isbn=9781108812900</a></li><li>Book's webpage: <a href="https://www.hudsonlab.org/textbook" rel="noopener noreferrer" target="_blank">https://www.hudsonlab.org/textbook</a></li><li>For blurbs on each chapter: <a href="https://www.hudsonlab.org/textbookresources" rel="noopener noreferrer" target="_blank">https://www.hudsonlab.org/textbookresources</a></li><li>Code used in each chapter: <a href="https://www.hudsonlab.org/textbookresources" rel="noopener noreferrer" target="_blank">https://www.hudsonlab.org/textbook/f314a</a></li><li>For tutorials on Bayesian vs. classical frequentist data analysis: <a href="https://www.hudsonlab.org/datatutorials" rel="noopener noreferrer" target="_blank">https://www.hudsonlab.org/datatutorials</a></li><li>Todd's research: <a href="https://www.hudsonlab.org/research" rel="noopener noreferrer" target="_blank">https://www.hudsonlab.org/research</a></li><li>Todd's webpage: <a href="https://med.nyu.edu/faculty/todd-e-hudson" rel="noopener noreferrer" target="_blank">https://med.nyu.edu/faculty/todd-e-hudson</a></li><li>For information on Todd's assistive technology work:&nbsp;<a href="https://www.feeltnt.com/" rel="noopener noreferrer" target="_blank">feeltnt.com</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/53-bayesian-stats-behavioral-neural-sciences-todd-hudson]]></link><guid isPermaLink="false">5ac095f9-505e-4e51-a7b8-e31b57a46973</guid><itunes:image href="https://artwork.captivate.fm/cff0ea1e-c13c-4715-b41a-3303522e96f6/9RsYVdub7cow-GP4Y_bM7YjV.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 28 Dec 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/00633f14-7c95-47d7-9bb0-3fd130e8839c/learning-bayesian-statistics-53.mp3" length="53955245" type="audio/mpeg"/><itunes:duration>56:12</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>53</itunes:episode><itunes:season>1</itunes:season><podcast:episode>53</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Why is Bayes useful in the behavioral and neural sciences? How to model behavioral and neural data with Bayesian statistics? How to estimate measurement error and compare models?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#52 Election forecasting models in Germany, with Marcus Gross</title><itunes:title>Election forecasting models in Germany, with Marcus Gross</itunes:title><description><![CDATA[<p>Did I mention I like survey data, especially in the context of electoral forecasting? Probably not, as I’m a pretty shy and reserved man. Why are you laughing?? Yeah, that’s true, I’m not that shy… but I did mention my interest for electoral forecasting already!</p><p>And before doing a full episode where I’ll talk about French elections (yes, that’ll come at one point), let’s talk about one of France’s neighbors — Germany. Our German friends had federal elections a few weeks ago — consequential elections, since they had the hard task of replacing Angela Merkel, after 16 years in power.</p><p>To talk about this election, I invited Marcus Gross on the show, because he worked on a Bayesian forecasting model to try and predict the results of this election — who will get elected as Chancellor, by how much and with which coalition?</p><p>I was delighted to ask him about how the model works, how it accounts for the different sources of uncertainty — be it polling errors, unexpected turnout or media events — and, of course, how long it takes to sample (I think you’ll be surprised by the answer).&nbsp;</p><p>We also talked about the other challenge of this kind of work: communication — how do you communicate uncertainty effectively? How do you differentiate motivated reasoning from useful feedback? What were the most common misconceptions about the model?</p><p>Marcus studied statistics in Munich and Berlin, and did a PhD on survey statistics and measurement error models in economics and archeology. He worked as a data scientist at INWT, a consulting firm with projects in different business fields as well as the public sector. Now, he is working at FlixMobility.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King and Aaron Jones</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>German election forecast website: <a href="https://www.wer-gewinnt-die-wahl.de/en" rel="noopener noreferrer" target="_blank">https://www.wer-gewinnt-die-wahl.de/en</a></li><li>Twitter account of electoral model: <a href="https://twitter.com/GerElectionFcst" rel="noopener noreferrer" target="_blank">https://twitter.com/GerElectionFcst</a></li><li>German election model code: <a href="https://github.com/INWTlab/lsTerm-election-forecast" rel="noopener noreferrer" target="_blank">https://github.com/INWTlab/lsTerm-election-forecast</a></li><li>LBS #27 -- Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns: <a...]]></description><content:encoded><![CDATA[<p>Did I mention I like survey data, especially in the context of electoral forecasting? Probably not, as I’m a pretty shy and reserved man. Why are you laughing?? Yeah, that’s true, I’m not that shy… but I did mention my interest for electoral forecasting already!</p><p>And before doing a full episode where I’ll talk about French elections (yes, that’ll come at one point), let’s talk about one of France’s neighbors — Germany. Our German friends had federal elections a few weeks ago — consequential elections, since they had the hard task of replacing Angela Merkel, after 16 years in power.</p><p>To talk about this election, I invited Marcus Gross on the show, because he worked on a Bayesian forecasting model to try and predict the results of this election — who will get elected as Chancellor, by how much and with which coalition?</p><p>I was delighted to ask him about how the model works, how it accounts for the different sources of uncertainty — be it polling errors, unexpected turnout or media events — and, of course, how long it takes to sample (I think you’ll be surprised by the answer).&nbsp;</p><p>We also talked about the other challenge of this kind of work: communication — how do you communicate uncertainty effectively? How do you differentiate motivated reasoning from useful feedback? What were the most common misconceptions about the model?</p><p>Marcus studied statistics in Munich and Berlin, and did a PhD on survey statistics and measurement error models in economics and archeology. He worked as a data scientist at INWT, a consulting firm with projects in different business fields as well as the public sector. Now, he is working at FlixMobility.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen, Andreas Netti, Riley King and Aaron Jones</em>.</p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>German election forecast website: <a href="https://www.wer-gewinnt-die-wahl.de/en" rel="noopener noreferrer" target="_blank">https://www.wer-gewinnt-die-wahl.de/en</a></li><li>Twitter account of electoral model: <a href="https://twitter.com/GerElectionFcst" rel="noopener noreferrer" target="_blank">https://twitter.com/GerElectionFcst</a></li><li>German election model code: <a href="https://github.com/INWTlab/lsTerm-election-forecast" rel="noopener noreferrer" target="_blank">https://github.com/INWTlab/lsTerm-election-forecast</a></li><li>LBS #27 -- Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns: <a href="https://www.learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/52-election-forecasting-models-germany-marcus-gross]]></link><guid isPermaLink="false">6063dc86-2350-4ffd-8be8-671c2fda050d</guid><itunes:image href="https://artwork.captivate.fm/232c7961-ad85-4ab6-801d-13810ff47576/_0UUFsFzvVimLzxTc-8O6wyR.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 09 Dec 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/17ca53e5-d153-48b0-bbb4-4bdaf143d16d/learning-bayesian-statistics-52.mp3" length="55800887" type="audio/mpeg"/><itunes:duration>58:08</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>52</itunes:episode><itunes:season>1</itunes:season><podcast:episode>52</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How do you design a forecasting model that&apos;s tailored to Germany&apos;s electoral system? And then how do you communicate about what it can tell you... and cannot tell you?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#51 Bernoulli’s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton</title><itunes:title>Bernoulli&apos;s Fallacy &amp; the Crisis of Modern Science, with Aubrey Clayton</itunes:title><description><![CDATA[<p>You know I love epistemology — the study of how we know what we know. It was high time I dedicated a whole episode to this topic. And what better guest than Aubrey Clayton, the author of the book <em>Bernoulli's Fallacy: Statistical Illogic and the Crisis of Modern Science</em>. I’m in the middle of reading it, and it’s a really great read!</p><p>Aubrey is a mathematician in Boston who teaches the philosophy of probability and statistics at the Harvard Extension School. He holds a PhD in mathematics from the University of California, Berkeley, and his writing has appeared in Pacific Standard, Nautilus, and the Boston Globe.</p><p>We talked about what he deems “a catastrophic error in the logic of the standard statistical methods in almost all the sciences” and why this error manifests even outside of science, like in medicine, law, public policy, etc.</p><p>But don’t worry, we’re not doomed — we’ll also see where we go from there. As a big fan of E.T Jaynes, Aubrey will also tell us how this US scientist influenced his own thinking as well as the field of Bayesian inference in general.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen and Andreas Netti.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Aubrey's website: <a href="https://aubreyclayton.com/" rel="noopener noreferrer" target="_blank">https://aubreyclayton.com/</a></li><li>Aubrey on Twitter: <a href="https://twitter.com/aubreyclayton" rel="noopener noreferrer" target="_blank">https://twitter.com/aubreyclayton</a></li><li>Bernoulli's Fallacy: <a href="https://aubreyclayton.com/bernoulli" rel="noopener noreferrer" target="_blank">https://aubreyclayton.com/bernoulli</a></li><li>Aubrey's probability theory lectures based on E.T Jayne's work: <a href="https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_</a></li><li>What Society Gets Wrong About Statistics: <a href="https://www.youtube.com/watch?v=fDulF2MzsIU" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=fDulF2MzsIU</a></li><li>The Prosecutor's Fallacy: <a href="https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></li><li><em>The Theory That Would Not Die -- How Bayes' Rule Cracked the Enigma Code</em>: <a href="https://www.goodreads.com/book/show/10672848-the-theory-that-would-not-die" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>You know I love epistemology — the study of how we know what we know. It was high time I dedicated a whole episode to this topic. And what better guest than Aubrey Clayton, the author of the book <em>Bernoulli's Fallacy: Statistical Illogic and the Crisis of Modern Science</em>. I’m in the middle of reading it, and it’s a really great read!</p><p>Aubrey is a mathematician in Boston who teaches the philosophy of probability and statistics at the Harvard Extension School. He holds a PhD in mathematics from the University of California, Berkeley, and his writing has appeared in Pacific Standard, Nautilus, and the Boston Globe.</p><p>We talked about what he deems “a catastrophic error in the logic of the standard statistical methods in almost all the sciences” and why this error manifests even outside of science, like in medicine, law, public policy, etc.</p><p>But don’t worry, we’re not doomed — we’ll also see where we go from there. As a big fan of E.T Jaynes, Aubrey will also tell us how this US scientist influenced his own thinking as well as the field of Bayesian inference in general.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales, Tomáš Frýda, Ryan Wesslen and Andreas Netti.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Aubrey's website: <a href="https://aubreyclayton.com/" rel="noopener noreferrer" target="_blank">https://aubreyclayton.com/</a></li><li>Aubrey on Twitter: <a href="https://twitter.com/aubreyclayton" rel="noopener noreferrer" target="_blank">https://twitter.com/aubreyclayton</a></li><li>Bernoulli's Fallacy: <a href="https://aubreyclayton.com/bernoulli" rel="noopener noreferrer" target="_blank">https://aubreyclayton.com/bernoulli</a></li><li>Aubrey's probability theory lectures based on E.T Jayne's work: <a href="https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PL9v9IXDsJkktefQzX39wC2YG07vw7DsQ_</a></li><li>What Society Gets Wrong About Statistics: <a href="https://www.youtube.com/watch?v=fDulF2MzsIU" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=fDulF2MzsIU</a></li><li>The Prosecutor's Fallacy: <a href="https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></li><li><em>The Theory That Would Not Die -- How Bayes' Rule Cracked the Enigma Code</em>: <a href="https://www.goodreads.com/book/show/10672848-the-theory-that-would-not-die" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/10672848-the-theory-that-would-not-die</a></li><li>LBS #18, How to ask good Research Questions and encourage Open Science, with Daniel Lakens: <a href="https://www.learnbayesstats.com/episode/18-how-to-ask-good-research-questions-and-encourage-open-science-with-daniel-lakens" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/18-how-to-ask-good-research-questions-and-encourage-open-science-with-daniel-lakens</a></li><li>LBS #35, The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner</a></li><li>LBS #40, Bayesian Stats for the Speech &amp; Language Sciences, with Allison Hilger and Timo Roettger: <a href="https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/51-bernoullis-fallacy-crisis-modern-science-aubrey-clayton]]></link><guid isPermaLink="false">cbf59097-7fa6-4cd1-b632-23ad32d0ca4b</guid><itunes:image href="https://artwork.captivate.fm/27c7b023-255e-4067-84b9-d82b87382983/ALHQi67cCItIG0_3TINiNLs5.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 22 Nov 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/4beff6cb-1a2b-478d-850d-ccb61e379715/learning-bayesian-statistics-51.mp3" length="66639968" type="audio/mpeg"/><itunes:duration>01:09:25</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>51</itunes:episode><itunes:season>1</itunes:season><podcast:episode>51</podcast:episode><podcast:season>1</podcast:season><itunes:summary>About statistical illogic and the crisis of modern science. We talked about a catastrophic error in the logic of the standard statistical methods in almost all the sciences and why this error manifests even outside of science, like in medicine, law, public policy...</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#50 Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter</title><itunes:title>Ta(l)king Risks &amp; Embracing Uncertainty, with David Spiegelhalter</itunes:title><description><![CDATA[<p>Folks, this is the 50th episode of LBS — 50th! I never would have thought that there were so many Bayesian nerds in the world when I first interviewed Osvaldo Martin more than 2 years ago.&nbsp;</p><p>To celebrate that random, crazy adventure, I wanted to do a special episode at any random point, and so it looks like it’s gonna be #50! This episode is special by its guest, not its number — although my guest knows a thing or two about numbers. Most recently, he wrote the book <em>Covid by Numbers.</em></p><p>A mathematical statistician dedicated to helping the general public understand risk, uncertainty and decision-making, he’s the author of several books on the topic actually, including <em>The Art of Statistics</em>. You may also know him from his podcast, <em>Risky Talk</em>, or his numerous appearances in newspapers, radio and TV shows.</p><p>Did you guess who it is?</p><p>Maybe you just know him as the reigning World Champion in Loop – a version of pool played on an elliptical table – and are just discovering now that he is a fantastic science communicator – something that turns out to be especially important for stats education in times of, let’s say, global pandemic for instance.</p><p>He holds a PhD in Mathematical Statistics from the University of London and has been the Chair of the Winton Centre for Risk and Evidence Communication at Cambridge University since 2016. He was also the President of the famous Royal Statistical Society in 2017-2018.</p><p>Most importantly, he was featured in BBC1’s Winter Wipeout in 2011 – seriously, go check it out on his website; it’s hilarious.</p><p>So did you guess it yet? Yep, my guest for this episode is no other than Sir David Spiegelhalter — yes, there are Bayesian knights!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales and Tomáš Frýda.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>David's website: <a href="http://www.statslab.cam.ac.uk/~david/" rel="noopener noreferrer" target="_blank">http://www.statslab.cam.ac.uk/~david/</a></li><li>David on Twitter: <a href="https://twitter.com/d_spiegel" rel="noopener noreferrer" target="_blank">https://twitter.com/d_spiegel</a></li><li><em>The Art of Statistics</em>: <a href="https://dspiegel29.github.io/ArtofStatistics/" rel="noopener noreferrer" target="_blank">https://dspiegel29.github.io/ArtofStatistics/</a></li><li><em>Risky Talk</em> podcast: <a href="https://riskytalk.libsyn.com/" rel="noopener noreferrer" target="_blank">https://riskytalk.libsyn.com/</a></li><li>Winton Centre for Risk and Evidence Communication: <a]]></description><content:encoded><![CDATA[<p>Folks, this is the 50th episode of LBS — 50th! I never would have thought that there were so many Bayesian nerds in the world when I first interviewed Osvaldo Martin more than 2 years ago.&nbsp;</p><p>To celebrate that random, crazy adventure, I wanted to do a special episode at any random point, and so it looks like it’s gonna be #50! This episode is special by its guest, not its number — although my guest knows a thing or two about numbers. Most recently, he wrote the book <em>Covid by Numbers.</em></p><p>A mathematical statistician dedicated to helping the general public understand risk, uncertainty and decision-making, he’s the author of several books on the topic actually, including <em>The Art of Statistics</em>. You may also know him from his podcast, <em>Risky Talk</em>, or his numerous appearances in newspapers, radio and TV shows.</p><p>Did you guess who it is?</p><p>Maybe you just know him as the reigning World Champion in Loop – a version of pool played on an elliptical table – and are just discovering now that he is a fantastic science communicator – something that turns out to be especially important for stats education in times of, let’s say, global pandemic for instance.</p><p>He holds a PhD in Mathematical Statistics from the University of London and has been the Chair of the Winton Centre for Risk and Evidence Communication at Cambridge University since 2016. He was also the President of the famous Royal Statistical Society in 2017-2018.</p><p>Most importantly, he was featured in BBC1’s Winter Wipeout in 2011 – seriously, go check it out on his website; it’s hilarious.</p><p>So did you guess it yet? Yep, my guest for this episode is no other than Sir David Spiegelhalter — yes, there are Bayesian knights!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, Alejandro Morales and Tomáš Frýda.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>David's website: <a href="http://www.statslab.cam.ac.uk/~david/" rel="noopener noreferrer" target="_blank">http://www.statslab.cam.ac.uk/~david/</a></li><li>David on Twitter: <a href="https://twitter.com/d_spiegel" rel="noopener noreferrer" target="_blank">https://twitter.com/d_spiegel</a></li><li><em>The Art of Statistics</em>: <a href="https://dspiegel29.github.io/ArtofStatistics/" rel="noopener noreferrer" target="_blank">https://dspiegel29.github.io/ArtofStatistics/</a></li><li><em>Risky Talk</em> podcast: <a href="https://riskytalk.libsyn.com/" rel="noopener noreferrer" target="_blank">https://riskytalk.libsyn.com/</a></li><li>Winton Centre for Risk and Evidence Communication: <a href="https://wintoncentre.maths.cam.ac.uk/" rel="noopener noreferrer" target="_blank">https://wintoncentre.maths.cam.ac.uk/</a></li><li>Frank Ramsey -- A Sheer Excess of Powers: <a href="https://www.amazon.fr/Frank-Ramsey-Sheer-Excess-Powers/dp/019875535X" rel="noopener noreferrer" target="_blank">https://www.amazon.fr/Frank-Ramsey-Sheer-Excess-Powers/dp/019875535X</a></li><li>BBC Radio 4, David Spiegelhalter on Frank Ramsey: <a href="https://www.bbc.co.uk/programmes/m000q8pq" rel="noopener noreferrer" target="_blank">https://www.bbc.co.uk/programmes/m000q8pq</a></li><li>De Finetti's theorem: <a href="https://en.wikipedia.org/wiki/De_Finetti%27s_theorem" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/De_Finetti%27s_theorem</a></li><li>Laplace's demon: <a href="https://en.wikipedia.org/wiki/Laplace%27s_demon" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Laplace%27s_demon</a></li><li>Game of Loop: <a href="http://www.loop-the-game.com/scoop/" rel="noopener noreferrer" target="_blank">http://www.loop-the-game.com/scoop/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/50-talking-risks-embracing-uncertainty-david-spiegelhalter]]></link><guid isPermaLink="false">b8a3df8e-cd57-4d4f-a400-7ab588d121a6</guid><itunes:image href="https://artwork.captivate.fm/cd8c696f-a61f-4a30-b97d-851ddf35e4ef/UfaGaRgYTSIieBjzePEpv5In.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sat, 06 Nov 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/15b50177-4b5b-4ebd-ada8-c33f2d286489/learning-bayesian-statistics-50.mp3" length="61890338" type="audio/mpeg"/><itunes:duration>01:04:28</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>50</itunes:episode><itunes:season>1</itunes:season><podcast:episode>50</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Using statistics to help the general public understand risk, uncertainty and decision-making</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#49 The Present &amp; Future of Baseball Analytics, with Ehsan Bokhari</title><itunes:title>The Present &amp; Future of Baseball Analytics, with Ehsan Bokhari</itunes:title><description><![CDATA[<p>It’s been a while since I did an episode about sports analytics, right? And you know it’s a field I love, so… let’s do that!</p><p>For this episode, I was happy to host Ehsan Bokhari, not only because he’s a first-hour listener of the podcast and spread the word about it whenever he can, but mainly because he knows baseball analytics very well!</p><p>Currently Senior Director of Strategic Decision Making with the Houston Astros, he previously worked there as Senior Director of Player Evaluation and Director of R&amp;D. And before that, he was Senior Director at the Los Angeles Dodgers from the 2015 to the 2018 season.</p><p>Among other things, we talked about what his job looks like, how Bayesian the field is, which pushbacks he gets, and what the future of baseball analytics look like to him.</p><p>Ehsan also has an interesting background, coming from both psychology and mathematics. Indeed, he received a PhD in quantitative psychology and an MS in statistics at the University of Illinois in 2014.</p><p>Maybe most importantly, he loves reading non-fiction and spending time with his almost three-year-old son — who he read <em>Bayesian Probability for Babies</em> to, of course.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, and Alejandro Morales.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Ehsan on LinkedIn: <a href="https://www.linkedin.com/in/ebokhari/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/ebokhari/</a></li><li>Bayesian Bagging to Generate Uncertainty Intervals -- A Catcher Framing Story: <a href="https://www.baseballprospectus.com/news/article/38289/bayesian-bagging-generate-uncertainty-intervals-catcher-framing-story/" rel="noopener noreferrer" target="_blank">https://www.baseballprospectus.com/news/article/38289/bayesian-bagging-generate-uncertainty-intervals-catcher-framing-story/ </a></li><li>Jim Albert's <em>Bayesball</em> blog: <a href="https://bayesball.github.io/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/</a></li><li>Simulation of empirical Bayesian methods, using baseball statistics: <a href="http://varianceexplained.org/r/simulation-bayes-baseball/" rel="noopener noreferrer" target="_blank">http://varianceexplained.org/r/simulation-bayes-baseball/</a></li><li>Detection and Characterization of Cluster Substructure -- Fuzzy c-Lines: <a href="https://epubs.siam.org/doi/abs/10.1137/0140029" rel="noopener noreferrer" target="_blank">https://epubs.siam.org/doi/abs/10.1137/0140029</a></li><li>Tensor rank decomposition: <a...]]></description><content:encoded><![CDATA[<p>It’s been a while since I did an episode about sports analytics, right? And you know it’s a field I love, so… let’s do that!</p><p>For this episode, I was happy to host Ehsan Bokhari, not only because he’s a first-hour listener of the podcast and spread the word about it whenever he can, but mainly because he knows baseball analytics very well!</p><p>Currently Senior Director of Strategic Decision Making with the Houston Astros, he previously worked there as Senior Director of Player Evaluation and Director of R&amp;D. And before that, he was Senior Director at the Los Angeles Dodgers from the 2015 to the 2018 season.</p><p>Among other things, we talked about what his job looks like, how Bayesian the field is, which pushbacks he gets, and what the future of baseball analytics look like to him.</p><p>Ehsan also has an interesting background, coming from both psychology and mathematics. Indeed, he received a PhD in quantitative psychology and an MS in statistics at the University of Illinois in 2014.</p><p>Maybe most importantly, he loves reading non-fiction and spending time with his almost three-year-old son — who he read <em>Bayesian Probability for Babies</em> to, of course.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, Luis Iberico, and Alejandro Morales.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Ehsan on LinkedIn: <a href="https://www.linkedin.com/in/ebokhari/" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/in/ebokhari/</a></li><li>Bayesian Bagging to Generate Uncertainty Intervals -- A Catcher Framing Story: <a href="https://www.baseballprospectus.com/news/article/38289/bayesian-bagging-generate-uncertainty-intervals-catcher-framing-story/" rel="noopener noreferrer" target="_blank">https://www.baseballprospectus.com/news/article/38289/bayesian-bagging-generate-uncertainty-intervals-catcher-framing-story/ </a></li><li>Jim Albert's <em>Bayesball</em> blog: <a href="https://bayesball.github.io/" rel="noopener noreferrer" target="_blank">https://bayesball.github.io/</a></li><li>Simulation of empirical Bayesian methods, using baseball statistics: <a href="http://varianceexplained.org/r/simulation-bayes-baseball/" rel="noopener noreferrer" target="_blank">http://varianceexplained.org/r/simulation-bayes-baseball/</a></li><li>Detection and Characterization of Cluster Substructure -- Fuzzy c-Lines: <a href="https://epubs.siam.org/doi/abs/10.1137/0140029" rel="noopener noreferrer" target="_blank">https://epubs.siam.org/doi/abs/10.1137/0140029</a></li><li>Tensor rank decomposition: <a href="https://en.wikipedia.org/wiki/Tensor_rank_decomposition" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Tensor_rank_decomposition</a></li><li>Statistical Prediction versus Clinical Prediction -- Improving What Works: <a href="https://meehl.umn.edu/sites/meehl.umn.edu/files/files/155dfm1993.pdf" rel="noopener noreferrer" target="_blank">https://meehl.umn.edu/sites/meehl.umn.edu/files/files/155dfm1993.pdf</a></li><li>Clinical Versus Actuarial Judgment: <a href="https://meehl.umn.edu/sites/meehl.umn.edu/files/files/138cstixdawesfaustmeehl.pdf" rel="noopener noreferrer" target="_blank">https://meehl.umn.edu/sites/meehl.umn.edu/files/files/138cstixdawesfaustmeehl.pdf</a></li><li>Clinical Versus Statistical Prediction: <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.693.6031&amp;rep=rep1&amp;type=pdf" rel="noopener noreferrer" target="_blank">https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.693.6031&amp;rep=rep1&amp;type=pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/49-present-future-baseball-analytics-ehsan-bokhari]]></link><guid isPermaLink="false">6857a6da-ab41-4010-97ec-6c0ce58a1906</guid><itunes:image href="https://artwork.captivate.fm/f3eed286-7233-4ab3-8b3b-e39802b9bce1/-j28PvjHPlE4yLoRhukMwgF_.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 22 Oct 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/2dada383-6be9-486d-a70e-7faed5a25e94/learning-bayesian-statistics-49.mp3" length="69984308" type="audio/mpeg"/><itunes:duration>01:12:54</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>49</itunes:episode><itunes:season>1</itunes:season><podcast:episode>49</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What working in the stats department of a baseball team looks like, how Bayesian are baseball analytics, which pushbacks does Ehsan get, and what the future of baseball analytics look like to him</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#48 Mixed Effects Models &amp; Beautiful Plots, with TJ Mahr</title><itunes:title>Mixed Effects Models &amp; Beautiful Plots, with TJ Mahr</itunes:title><description><![CDATA[<p>In episode 40, we already got a glimpse of how useful Bayesian stats are in the speech and communication sciences. To talk about the frontiers of this field (and, as it happens, about best practices to make beautiful plots and pictures), I invited TJ Mahr on the show.</p><p>A speech pathologist turned data scientist, TJ earned his PhD in communication sciences and disorders in Madison, Wisconsin. On paper, he was studying speech development, word recognition and word learning in preschoolers, but over the course of his graduate training, he discovered that he really, <em>really</em> likes programming and working with data – we’ll of course talk about that in the show!</p><p>In short, TJ wrangles data, crunches numbers, plots pictures, and fits models to study how children learn to speak and communicate. On his website, he often writes about Bayesian models, mixed effects models, functional programming in R, or how to plot certain kinds of data.</p><p>He also got very into the deck-building game “Slay the Spire” this year, and his favorite youtube channel is a guy who restores paintings.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, and Luis Iberico.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>TJ's website: <a href="https://www.tjmahr.com/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/</a></li><li>TJ on Twitter: <a href="https://twitter.com/tjmahr" rel="noopener noreferrer" target="_blank">https://twitter.com/tjmahr</a></li><li>TJ on GitHub: <a href="https://github.com/tjmahr" rel="noopener noreferrer" target="_blank">https://github.com/tjmahr</a></li><li>LBS #40, Bayesian Stats for the Speech &amp; Language Sciences: <a href="https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger</a></li><li>Random Effects and Penalized Splines: <a href="https://www.tjmahr.com/random-effects-penalized-splines-same-thing/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</a></li><li>Bayes’s theorem in three panels: <a href="https://www.tjmahr.com/bayes-theorem-in-three-panels/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/bayes-theorem-in-three-panels/</a></li><li>Another mixed effects model visualization: <a href="https://www.tjmahr.com/another-mixed-effects-model-visualization/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>In episode 40, we already got a glimpse of how useful Bayesian stats are in the speech and communication sciences. To talk about the frontiers of this field (and, as it happens, about best practices to make beautiful plots and pictures), I invited TJ Mahr on the show.</p><p>A speech pathologist turned data scientist, TJ earned his PhD in communication sciences and disorders in Madison, Wisconsin. On paper, he was studying speech development, word recognition and word learning in preschoolers, but over the course of his graduate training, he discovered that he really, <em>really</em> likes programming and working with data – we’ll of course talk about that in the show!</p><p>In short, TJ wrangles data, crunches numbers, plots pictures, and fits models to study how children learn to speak and communicate. On his website, he often writes about Bayesian models, mixed effects models, functional programming in R, or how to plot certain kinds of data.</p><p>He also got very into the deck-building game “Slay the Spire” this year, and his favorite youtube channel is a guy who restores paintings.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin, Cameron Smith, and Luis Iberico.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>TJ's website: <a href="https://www.tjmahr.com/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/</a></li><li>TJ on Twitter: <a href="https://twitter.com/tjmahr" rel="noopener noreferrer" target="_blank">https://twitter.com/tjmahr</a></li><li>TJ on GitHub: <a href="https://github.com/tjmahr" rel="noopener noreferrer" target="_blank">https://github.com/tjmahr</a></li><li>LBS #40, Bayesian Stats for the Speech &amp; Language Sciences: <a href="https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger</a></li><li>Random Effects and Penalized Splines: <a href="https://www.tjmahr.com/random-effects-penalized-splines-same-thing/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</a></li><li>Bayes’s theorem in three panels: <a href="https://www.tjmahr.com/bayes-theorem-in-three-panels/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/bayes-theorem-in-three-panels/</a></li><li>Another mixed effects model visualization: <a href="https://www.tjmahr.com/another-mixed-effects-model-visualization/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/another-mixed-effects-model-visualization/</a></li><li>Anatomy of a logistic growth curve: <a href="https://www.tjmahr.com/anatomy-of-a-logistic-growth-curve/" rel="noopener noreferrer" target="_blank">https://www.tjmahr.com/anatomy-of-a-logistic-growth-curve/</a></li><li>R Users Will Now Inevitably Become Bayesians: <a href="https://thinkinator.com/2016/01/12/r-users-will-now-inevitably-become-bayesians/" rel="noopener noreferrer" target="_blank">https://thinkinator.com/2016/01/12/r-users-will-now-inevitably-become-bayesians/</a></li><li>Wisconsin Intelligibility, Speech, and Communication Laboratory: <a href="https://kidspeech.wisc.edu/" rel="noopener noreferrer" target="_blank">https://kidspeech.wisc.edu/</a></li><li>Longitudinal Growth in Intelligibility of Connected Speech From 2 to 8 Years in Children With Cerebral Palsy: <a href="https://pubs.asha.org/doi/abs/10.1044/2020_JSLHR-20-00181" rel="noopener noreferrer" target="_blank">https://pubs.asha.org/doi/abs/10.1044/2020_JSLHR-20-00181</a></li><li>Statistics for Hackers: <a href="https://speakerdeck.com/jakevdp/statistics-for-hackers" rel="noopener noreferrer" target="_blank">https://speakerdeck.com/jakevdp/statistics-for-hackers</a></li><li>Structure and interpretation of computer programs: <a href="https://mitpress.mit.edu/sites/default/files/sicp/index.html" rel="noopener noreferrer" target="_blank">https://mitpress.mit.edu/sites/default/files/sicp/index.html</a></li><li>Lectures for structure and interpretation of computer programs from 1986 (that are still very good): <a href="https://www.youtube.com/playlist?list=PLE18841CABEA24090" rel="noopener noreferrer" target="_blank">https://www.youtube.com/playlist?list=PLE18841CABEA24090</a></li><li>bayesplot: <a href="https://mc-stan.org/bayesplot/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/bayesplot/</a></li><li class="ql-align-justify">ggdist: <a href="https://mjskay.github.io/ggdist/" rel="noopener noreferrer" target="_blank">https://mjskay.github.io/ggdist/</a></li><li>brms: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>targets: <a href="https://books.ropensci.org/targets/" rel="noopener noreferrer" target="_blank">https://books.ropensci.org/targets/</a></li><li>mgcv: <a href="https://cran.r-project.org/web/packages/mgcv/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/mgcv/index.html</a></li><li>lme4: <a href="https://cran.r-project.org/web/packages/lme4/index.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/lme4/index.html</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/48-mixed-effects-models-beautiful-plots-tj-mahr]]></link><guid isPermaLink="false">d0cff005-651c-46e3-a133-f9642f9b67a4</guid><itunes:image href="https://artwork.captivate.fm/a51f492a-f77a-4d19-8bae-24159734782c/4BcWPw7uNn_fkf-L8aqZJbvd.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 08 Oct 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/d541bc11-ad6c-4418-be46-70b4d709d5bc/learning-bayesian-statistics-48.mp3" length="58946735" type="audio/mpeg"/><itunes:duration>01:01:24</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>48</itunes:episode><itunes:season>1</itunes:season><podcast:episode>48</podcast:episode><podcast:season>1</podcast:season><itunes:summary>In short, TJ wrangles data, crunches numbers, plots pictures, and fits models to study how children learn to speak and communicate. On his website, he often writes about Bayesian models, mixed effects models, functional programming in R, or how to plot certain kinds of data.</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#47 Bayes in Physics &amp; Astrophysics, with JJ Ruby</title><itunes:title>Bayes in Physics &amp; Astrophysics, with JJ Ruby</itunes:title><description><![CDATA[<p>The field of physics has brought tremendous advances to modern Bayesian statistics, especially inspiring the current algorithms enabling all of us to enjoy the Bayesian power on our own laptops.</p><p>I did receive some physicians already on the show, like Michael Betancourt in episode 6, but in my legendary ungratefulness I hadn’t dedicated a whole episode to talk about physics yet.</p><p>Well that’s now taken care of, thanks to JJ Ruby. Apart from having really good tastes (he’s indeed a fan of this very podcast), JJ is currently a postdoctoral fellow for the Center for Matter at Atomic Pressures at the University of Rochester, and will soon be starting as a Postdoctoral Scholar at Lawrence Livermore National Laboratory, a U.S. Department of Energy National Laboratory.</p><p>JJ did his undergraduate work in Astrophysics and Planetary Science at Villanova University, outside of Philadelphia, and completed his master’s degree and PhD in Physics at the University of Rochester, in New York.</p><p>JJ studies high energy density physics and focuses on using Bayesian techniques to extract information from large scale physics experiments with highly integrated measurements.</p><p>In his freetime, he enjoys playing sports including baseball, basketball, and golf.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin and Cameron Smith.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Center for Matter at Atomic Pressures: <a href="https://www.rochester.edu/cmap/" rel="noopener noreferrer" target="_blank">https://www.rochester.edu/cmap/</a></li><li>Laboratory for Laser Energetics: <a href="https://www.lle.rochester.edu/index.php/about-the-laboratory-for-laser-energetics/" rel="noopener noreferrer" target="_blank">https://www.lle.rochester.edu/index.php/about-the-laboratory-for-laser-energetics/</a></li><li>Lawrence Livermore National Laboratory: <a href="https://www.llnl.gov/" rel="noopener noreferrer" target="_blank">https://www.llnl.gov/</a></li><li>JJ's thesis -- Bayesian Inference of Fundamental Physics at Extreme Conditions: <a href="https://www.lle.rochester.edu/media/publications/documents/theses/Ruby.pdf" rel="noopener noreferrer" target="_blank">https://www.lle.rochester.edu/media/publications/documents/theses/Ruby.pdf</a></li><li>Recent Fusion Breakthrough: <a href="https://www.llnl.gov/news/national-ignition-facility-experiment-puts-researchers-threshold-fusion-ignition" rel="noopener noreferrer" target="_blank">https://www.llnl.gov/news/national-ignition-facility-experiment-puts-researchers-threshold-fusion-ignition</a></li><li>LBS #6, A principled Bayesian...]]></description><content:encoded><![CDATA[<p>The field of physics has brought tremendous advances to modern Bayesian statistics, especially inspiring the current algorithms enabling all of us to enjoy the Bayesian power on our own laptops.</p><p>I did receive some physicians already on the show, like Michael Betancourt in episode 6, but in my legendary ungratefulness I hadn’t dedicated a whole episode to talk about physics yet.</p><p>Well that’s now taken care of, thanks to JJ Ruby. Apart from having really good tastes (he’s indeed a fan of this very podcast), JJ is currently a postdoctoral fellow for the Center for Matter at Atomic Pressures at the University of Rochester, and will soon be starting as a Postdoctoral Scholar at Lawrence Livermore National Laboratory, a U.S. Department of Energy National Laboratory.</p><p>JJ did his undergraduate work in Astrophysics and Planetary Science at Villanova University, outside of Philadelphia, and completed his master’s degree and PhD in Physics at the University of Rochester, in New York.</p><p>JJ studies high energy density physics and focuses on using Bayesian techniques to extract information from large scale physics experiments with highly integrated measurements.</p><p>In his freetime, he enjoys playing sports including baseball, basketball, and golf.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin, Philippe Labonde, Matthew McAnear, Michael Hankin and Cameron Smith.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Center for Matter at Atomic Pressures: <a href="https://www.rochester.edu/cmap/" rel="noopener noreferrer" target="_blank">https://www.rochester.edu/cmap/</a></li><li>Laboratory for Laser Energetics: <a href="https://www.lle.rochester.edu/index.php/about-the-laboratory-for-laser-energetics/" rel="noopener noreferrer" target="_blank">https://www.lle.rochester.edu/index.php/about-the-laboratory-for-laser-energetics/</a></li><li>Lawrence Livermore National Laboratory: <a href="https://www.llnl.gov/" rel="noopener noreferrer" target="_blank">https://www.llnl.gov/</a></li><li>JJ's thesis -- Bayesian Inference of Fundamental Physics at Extreme Conditions: <a href="https://www.lle.rochester.edu/media/publications/documents/theses/Ruby.pdf" rel="noopener noreferrer" target="_blank">https://www.lle.rochester.edu/media/publications/documents/theses/Ruby.pdf</a></li><li>Recent Fusion Breakthrough: <a href="https://www.llnl.gov/news/national-ignition-facility-experiment-puts-researchers-threshold-fusion-ignition" rel="noopener noreferrer" target="_blank">https://www.llnl.gov/news/national-ignition-facility-experiment-puts-researchers-threshold-fusion-ignition</a></li><li>LBS #6, A principled Bayesian workflow, with Michael Betancourt: <a href="https://www.learnbayesstats.com/episode/6-a-principled-bayesian-workflow-with-michael-betancourt" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/6-a-principled-bayesian-workflow-with-michael-betancourt</a></li><li>20 Best Statistics Podcasts of 2021: <a href="https://welpmagazine.com/20-best-statistics-podcasts-of-2021/" rel="noopener noreferrer" target="_blank">https://welpmagazine.com/20-best-statistics-podcasts-of-2021/</a></li><li>E.T. Jaynes, Probability Theory -- The Logic of Science: <a href="https://www.goodreads.com/book/show/151848.Probability_Theory" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/151848.Probability_Theory</a></li><li>D.S. Sivia, Data Analysis -- A Bayesian Tutorial: <a href="http://aprsa.villanova.edu/files/sivia.pdf" rel="noopener noreferrer" target="_blank">http://aprsa.villanova.edu/files/sivia.pdf</a></li><li>S. Chandrasekhar -- An Introduction to the Study of Stellar Structure: <a href="https://www.amazon.com/Introduction-Study-Stellar-Structure-Astronomy/dp/0486604136" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Introduction-Study-Stellar-Structure-Astronomy/dp/0486604136</a></li><li>Fun quote (from preface in Jaynes' book):&nbsp;</li></ul><br/><blockquote>Therefore we think that in the future, workers in all the quantitative sciences will be obliged, as a matter of practical necessity, to use probability theory in the manner expounded here. This trend is already well under way in several fields, ranging from econometrics to astronomy to magnetic resonance spectroscopy; but to make progress in a new area it is necessary to develop a healthy disrespect for tradition and authority, which have retarded progress throughout the 20th century.</blockquote>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/47-bayes-physics-astrophysics-jj-ruby]]></link><guid isPermaLink="false">0f5ae4cc-b095-4148-b235-fe8869d7c203</guid><itunes:image href="https://artwork.captivate.fm/7845e6a5-6693-4637-8ccf-1690a1efde5f/QM-Fc8FVSC0vFK1wwXXX0xjP.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 21 Sep 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/e7fda92d-efb1-48ca-aa00-264170c00a0c/learning-bayesian-statistics-47.mp3" length="72756107" type="audio/mpeg"/><itunes:duration>01:15:47</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>47</itunes:episode><itunes:season>1</itunes:season><podcast:episode>47</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What Bayesian stats bring to physics, and what physics brings to Bayesian stats</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#46 Silly &amp; Empowering Statistics, with Chelsea Parlett-Pelleriti</title><itunes:title>Silly &amp; Empowering Statistics, with Chelsea Parlett-Pelleriti</itunes:title><description><![CDATA[<p>You wanna know something funny? A sentence from this episode became a meme. And people even made stickers out of it! Ok, that’s not true. But if someone could pull off something like that, it would surely be Chelsea Parlett-Pelleriti.</p><p>Indeed, Chelsea’s research focuses on using statistics and machine learning on behavioral data, but her more general goal is to empower people to be able to do their own statistical analyses, through consulting, education, and, as you may have seen, stats memes on Twitter.</p><p>A full-time teacher, researcher and statistical consultant, Chelsea earned an MsC and PhD in Computational and Data Science in 2021 from Chapman University. Her courses include R, intro to programming (in Python), and data science.</p><p>In a nutshell, Chelsea is, by her own admission, an avid lover of anything silly or statistical. Hopefully, this episode turned out to be both at once! I’ll let you be the judge of that…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Chelsea's website: <a href="https://cmparlettpelleriti.github.io/index.html" rel="noopener noreferrer" target="_blank">https://cmparlettpelleriti.github.io/index.html</a></li><li>Chelsea on Twitter: <a href="https://twitter.com/ChelseaParlett" rel="noopener noreferrer" target="_blank">https://twitter.com/ChelseaParlett</a></li><li>Michael Betancourt's sparsity case study: <a href="https://betanalpha.github.io/assets/case_studies/modeling_sparsity.html" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/assets/case_studies/modeling_sparsity.html</a></li><li>LBS #31 -- Bayesian Cognitive Modeling &amp; Decision-Making, with Michael Lee: <a href="https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee</a></li><li>Projection predictive variable selection R <a href="blank" rel="noopener noreferrer" target="_blank">package: https://mc-stan.org/projpred/</a></li><li>SelectiveInference R package: <a href="https://cran.r-project.org/web/packages/selectiveInference/selectiveInference.pdf" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/selectiveInference/selectiveInference.pdf</a></li><li>Statistical learning and selective inference: <a href="https://www.pnas.org/content/112/25/7629" rel="noopener noreferrer" target="_blank">https://www.pnas.org/content/112/25/7629</a></li><li>LBS #29 -- Model Assessment, Non-Parametric Models, with Aki Vehtari: <a...]]></description><content:encoded><![CDATA[<p>You wanna know something funny? A sentence from this episode became a meme. And people even made stickers out of it! Ok, that’s not true. But if someone could pull off something like that, it would surely be Chelsea Parlett-Pelleriti.</p><p>Indeed, Chelsea’s research focuses on using statistics and machine learning on behavioral data, but her more general goal is to empower people to be able to do their own statistical analyses, through consulting, education, and, as you may have seen, stats memes on Twitter.</p><p>A full-time teacher, researcher and statistical consultant, Chelsea earned an MsC and PhD in Computational and Data Science in 2021 from Chapman University. Her courses include R, intro to programming (in Python), and data science.</p><p>In a nutshell, Chelsea is, by her own admission, an avid lover of anything silly or statistical. Hopefully, this episode turned out to be both at once! I’ll let you be the judge of that…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Chelsea's website: <a href="https://cmparlettpelleriti.github.io/index.html" rel="noopener noreferrer" target="_blank">https://cmparlettpelleriti.github.io/index.html</a></li><li>Chelsea on Twitter: <a href="https://twitter.com/ChelseaParlett" rel="noopener noreferrer" target="_blank">https://twitter.com/ChelseaParlett</a></li><li>Michael Betancourt's sparsity case study: <a href="https://betanalpha.github.io/assets/case_studies/modeling_sparsity.html" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/assets/case_studies/modeling_sparsity.html</a></li><li>LBS #31 -- Bayesian Cognitive Modeling &amp; Decision-Making, with Michael Lee: <a href="https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/31-bayesian-cognitive-modeling-michael-lee</a></li><li>Projection predictive variable selection R <a href="blank" rel="noopener noreferrer" target="_blank">package: https://mc-stan.org/projpred/</a></li><li>SelectiveInference R package: <a href="https://cran.r-project.org/web/packages/selectiveInference/selectiveInference.pdf" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/selectiveInference/selectiveInference.pdf</a></li><li>Statistical learning and selective inference: <a href="https://www.pnas.org/content/112/25/7629" rel="noopener noreferrer" target="_blank">https://www.pnas.org/content/112/25/7629</a></li><li>LBS #29 -- Model Assessment, Non-Parametric Models, with Aki Vehtari: <a href="https://www.learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/model-assessment-non-parametric-models-aki-vehtari</a></li><li>LBS #35 -- The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner</a></li><li>BRMS R Package: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>Bayesian Item Response Modeling in R with BRMS and Stan: <a href="https://arxiv.org/pdf/1905.09501.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1905.09501.pdf</a></li><li>BAyesian Model-Building Interface (Bambi) in PythonBAyesian Model-Building Interface (Bambi) in Python: <a href="https://bambinos.github.io/bambi/main/index.html" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/main/index.html</a></li><li>Zero-one-inflated beta regression: <a href="https://twitter.com/SolomonKurz/status/1395056477459648521" rel="noopener noreferrer" target="_blank">https://twitter.com/SolomonKurz/status/1395056477459648521</a></li><li>Ordinal Regression Models in Psychology: <a href="https://www.researchgate.net/publication/331335573_Ordinal_Regression_Models_in_Psychology_A_Tutorial" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/publication/331335573_Ordinal_Regression_Models_in_Psychology_A_Tutorial</a></li><li>LBS #38 -- How to Become a Good Bayesian (&amp; Rap Artist), with Baba Brinkman: <a href="https://www.learnbayesstats.com/episode/38-how-to-become-good-bayesian-rap-artist-baba-brinkman" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/38-how-to-become-good-bayesian-rap-artist-baba-brinkman</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/46-silly-empowering-statistics-chelsea-parlett-pelleriti]]></link><guid isPermaLink="false">31054696-21ee-4f08-8953-5b070d670767</guid><itunes:image href="https://artwork.captivate.fm/cd1df4a0-6672-4142-875b-889761eaf811/jZtHxzXzlfCrbCRumUgN8IK-.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 30 Aug 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a39e139e-e1f4-45e9-a16a-ae2d9cee883f/learning-bayesian-statistics-46.mp3" length="70140266" type="audio/mpeg"/><itunes:duration>01:13:04</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>46</itunes:episode><itunes:season>1</itunes:season><podcast:episode>46</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How to empower people to do their own statistical analyses, and how to use statistics on behavioral data</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#45 Biostats &amp; Clinical Trial Design, with Frank Harrell</title><itunes:title>Biostats &amp; Clinical Trial Design, with Frank Harrell</itunes:title><description><![CDATA[<p>As a podcaster, I discovered that there are guests for which the hardest is to know when to stop the conversation. They could talk for hours and that would make for at least 10 fantastic episodes. Frank Harrell is one of those guests. To me, our conversation was both fascinating — thanks to Frank’s expertise and the width and depth of topics we touched on — and frustrating — I still had a gazillion questions for him!</p><p>But rest assured, we talked about intent to treat and randomization, proportional odds, clinical trial design, bio stats and covid19, and even which mistakes you should do to learn Bayes stats — yes, you heard right, which mistakes. Anyway, I can’t tell you everything here — you’ll just have to listen to the episode!</p><p>A long time Bayesian, Frank is a Professor of Biostatistics in the School of Medicine at Vanderbilt University. His numerous research interests include predictive models and model validation, Bayesian clinical trial design and Bayesian models, drug development, and clinical research.</p><p>He holds a PhD in biostatistics from the University of North Carolina, and did his Bachelor in mathematics at the University of Alabama in Birmingham.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Frank's website and courses: <a href="https://hbiostat.org/" rel="noopener noreferrer" target="_blank">https://hbiostat.org/</a></li><li>Frank's blog: <a href="https://www.fharrell.com/" rel="noopener noreferrer" target="_blank">https://www.fharrell.com/</a></li><li>Frank on Twitter: <a href="https://twitter.com/f2harrell" rel="noopener noreferrer" target="_blank">https://twitter.com/f2harrell</a></li><li>COVID-19 Randomized Clinical Trial Design: <a href="https://hbiostat.org/proj/covid19/" rel="noopener noreferrer" target="_blank">https://hbiostat.org/proj/covid19/</a></li><li>Frank on GitHub: <a href="https://github.com/harrelfe" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe</a></li><li>Regression Modeling Strategies repository: <a href="https://github.com/harrelfe/rms" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe/rms</a></li><li>Biostatistics for Biomedical Research repository: <a href="https://github.com/harrelfe/bbr" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe/bbr</a></li><li><em>Bayesian Approaches to Randomized Trials</em>, Spiegelhalter et al.: <a href="http://hbiostat.org/papers/Bayes/spi94bay.pdf" rel="noopener noreferrer" target="_blank">http://hbiostat.org/papers/Bayes/spi94bay.pdf</a></li><li><em>Statistical Rethinking</em>, Richard...]]></description><content:encoded><![CDATA[<p>As a podcaster, I discovered that there are guests for which the hardest is to know when to stop the conversation. They could talk for hours and that would make for at least 10 fantastic episodes. Frank Harrell is one of those guests. To me, our conversation was both fascinating — thanks to Frank’s expertise and the width and depth of topics we touched on — and frustrating — I still had a gazillion questions for him!</p><p>But rest assured, we talked about intent to treat and randomization, proportional odds, clinical trial design, bio stats and covid19, and even which mistakes you should do to learn Bayes stats — yes, you heard right, which mistakes. Anyway, I can’t tell you everything here — you’ll just have to listen to the episode!</p><p>A long time Bayesian, Frank is a Professor of Biostatistics in the School of Medicine at Vanderbilt University. His numerous research interests include predictive models and model validation, Bayesian clinical trial design and Bayesian models, drug development, and clinical research.</p><p>He holds a PhD in biostatistics from the University of North Carolina, and did his Bachelor in mathematics at the University of Alabama in Birmingham.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Frank's website and courses: <a href="https://hbiostat.org/" rel="noopener noreferrer" target="_blank">https://hbiostat.org/</a></li><li>Frank's blog: <a href="https://www.fharrell.com/" rel="noopener noreferrer" target="_blank">https://www.fharrell.com/</a></li><li>Frank on Twitter: <a href="https://twitter.com/f2harrell" rel="noopener noreferrer" target="_blank">https://twitter.com/f2harrell</a></li><li>COVID-19 Randomized Clinical Trial Design: <a href="https://hbiostat.org/proj/covid19/" rel="noopener noreferrer" target="_blank">https://hbiostat.org/proj/covid19/</a></li><li>Frank on GitHub: <a href="https://github.com/harrelfe" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe</a></li><li>Regression Modeling Strategies repository: <a href="https://github.com/harrelfe/rms" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe/rms</a></li><li>Biostatistics for Biomedical Research repository: <a href="https://github.com/harrelfe/bbr" rel="noopener noreferrer" target="_blank">https://github.com/harrelfe/bbr</a></li><li><em>Bayesian Approaches to Randomized Trials</em>, Spiegelhalter et al.: <a href="http://hbiostat.org/papers/Bayes/spi94bay.pdf" rel="noopener noreferrer" target="_blank">http://hbiostat.org/papers/Bayes/spi94bay.pdf</a></li><li><em>Statistical Rethinking</em>, Richard McElreath: <a href="http://xcelab.net/rm/statistical-rethinking/" rel="noopener noreferrer" target="_blank">http://xcelab.net/rm/statistical-rethinking/</a></li><li>LBS #20, <em>Regression and Other Stories</em>, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://www.learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari</a></li><li>David Spiegelhalter, <em>The Art of Statistics -- Learning from Data</em>: <a href="https://www.amazon.fr/Art-Statistics-Learning-Data/dp/0241398630" rel="noopener noreferrer" target="_blank">https://www.amazon.fr/Art-Statistics-Learning-Data/dp/0241398630</a></li><li><em>Confidence intervals vs. Bayesian intervals</em>, E.T. Jaynes: <a href="https://bayes.wustl.edu/etj/articles/confidence.pdf" rel="noopener noreferrer" target="_blank">https://bayes.wustl.edu/etj/articles/confidence.pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/45-biostats-clinical-trial-design-frank-harrell]]></link><guid isPermaLink="false">234eae42-c1f9-44e5-84ac-bfeeea08d5ef</guid><itunes:image href="https://artwork.captivate.fm/986ca0c5-c86a-4d99-b608-7549e8fd41da/kCcvRxVKEZKerDweM1FEX4Fp.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 10 Aug 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/04870c14-e386-432a-ac97-ffdc8349040a/learning-bayesian-statistics-45.mp3" length="66149576" type="audio/mpeg"/><itunes:duration>01:08:54</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>45</itunes:episode><itunes:season>1</itunes:season><podcast:episode>45</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A deep and broad conversation about predictive models, model validation, Bayesian clinical trial design and Bayesian models, drug development, and clinical research</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#44 Building Bayesian Models at scale, with Rémi Louf</title><itunes:title>Building Bayesian Models at scale, with Rémi Louf</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>Bonjour my dear Bayesians! Yes, it was bound to happen one day — and this day has finally come. Here is the first ever 100% French speaking ‘Learn Bayes Stats’ episode! Who is to blame, you ask? Well, who better than Rémi Louf?</p><p>Rémi currently works as a senior data scientist at Ampersand, a big media marketing company in the US. He is the author and maintainer of several open source libraries, including MCX and BlackJAX. He holds a PhD in statistical Physics, a Masters in physics from the Ecole Normale Supérieure and a Masters in Philosophy from Oxford University.</p><p>I think I know what you’re wondering: how the hell do you go from physics to philosophy to Bayesian stats?? Glad you asked, as it was my first question to Rémi! He’ll also tell us why he created MXC and BlackJax, what his main challenges are when working on open-source projects, and what the future of PPLs looks like to him.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Rémi on GitHub: <a href="https://github.com/rlouf" rel="noopener noreferrer" target="_blank">https://github.com/rlouf</a></li><li>Rémi on Twitter: <a href="https://twitter.com/remilouf" rel="noopener noreferrer" target="_blank">https://twitter.com/remilouf</a></li><li>Rémi's website: <a href="https://rlouf.github.io/" rel="noopener noreferrer" target="_blank">https://rlouf.github.io/</a></li><li>BlackJAX -- Fast &amp; modular sampling library: <a href="https://github.com/blackjax-devs/blackjax" rel="noopener noreferrer" target="_blank">https://github.com/blackjax-devs/blackjax</a></li><li>MCX -- Probabilistic programs on CPU &amp; GPU, powered by JAX: <a href="https://github.com/rlouf/mcx" rel="noopener noreferrer" target="_blank">https://github.com/rlouf/mcx</a></li><li>aeppl, Tools for a PPL in Aesara: <a href="https://github.com/aesara-devs/aeppl" rel="noopener noreferrer" target="_blank">https://github.com/aesara-devs/aeppl</a></li><li>French Presidents' popularity dashboard: <a href="https://www.pollsposition.com/popularity" rel="noopener noreferrer" target="_blank">https://www.pollsposition.com/popularity</a></li><li>How to model presidential approval (in French): <a href="https://anchor.fm/pollspolitics/episodes/10-Comment-Modliser-la-Popularit-e121jh2" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>Bonjour my dear Bayesians! Yes, it was bound to happen one day — and this day has finally come. Here is the first ever 100% French speaking ‘Learn Bayes Stats’ episode! Who is to blame, you ask? Well, who better than Rémi Louf?</p><p>Rémi currently works as a senior data scientist at Ampersand, a big media marketing company in the US. He is the author and maintainer of several open source libraries, including MCX and BlackJAX. He holds a PhD in statistical Physics, a Masters in physics from the Ecole Normale Supérieure and a Masters in Philosophy from Oxford University.</p><p>I think I know what you’re wondering: how the hell do you go from physics to philosophy to Bayesian stats?? Glad you asked, as it was my first question to Rémi! He’ll also tell us why he created MXC and BlackJax, what his main challenges are when working on open-source projects, and what the future of PPLs looks like to him.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode, Patrick Kelley, Rick Anderson, Casper de Bruin and Philippe Labonde.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Rémi on GitHub: <a href="https://github.com/rlouf" rel="noopener noreferrer" target="_blank">https://github.com/rlouf</a></li><li>Rémi on Twitter: <a href="https://twitter.com/remilouf" rel="noopener noreferrer" target="_blank">https://twitter.com/remilouf</a></li><li>Rémi's website: <a href="https://rlouf.github.io/" rel="noopener noreferrer" target="_blank">https://rlouf.github.io/</a></li><li>BlackJAX -- Fast &amp; modular sampling library: <a href="https://github.com/blackjax-devs/blackjax" rel="noopener noreferrer" target="_blank">https://github.com/blackjax-devs/blackjax</a></li><li>MCX -- Probabilistic programs on CPU &amp; GPU, powered by JAX: <a href="https://github.com/rlouf/mcx" rel="noopener noreferrer" target="_blank">https://github.com/rlouf/mcx</a></li><li>aeppl, Tools for a PPL in Aesara: <a href="https://github.com/aesara-devs/aeppl" rel="noopener noreferrer" target="_blank">https://github.com/aesara-devs/aeppl</a></li><li>French Presidents' popularity dashboard: <a href="https://www.pollsposition.com/popularity" rel="noopener noreferrer" target="_blank">https://www.pollsposition.com/popularity</a></li><li>How to model presidential approval (in French): <a href="https://anchor.fm/pollspolitics/episodes/10-Comment-Modliser-la-Popularit-e121jh2" rel="noopener noreferrer" target="_blank">https://anchor.fm/pollspolitics/episodes/10-Comment-Modliser-la-Popularit-e121jh2</a></li><li>LBS #23, Bayesian Stats in Business &amp; Marketing, with Elea McDonnel Feit: <a href="https://www.learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit</a></li><li>LBS #30, Symbolic Computation &amp; Dynamic Linear Models, with Brandon Willard: <a href="https://www.learnbayesstats.com/episode/symbolic-computation-dynamic-linear-models-brandon-willard" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/symbolic-computation-dynamic-linear-models-brandon-willard</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/44-bayesian-models-at-scale-remi-louf]]></link><guid isPermaLink="false">5de19d3e-bdc3-4016-b4ea-3c4bba53052c</guid><itunes:image href="https://artwork.captivate.fm/a03fc6e6-1fb6-4027-88c3-5e858bd3a6e2/Zb24UHYpclwTDRYgrmRQtnK-.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 22 Jul 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f735af0a-c7d9-461d-986f-913af9f5e462/learning-bayesian-statistics-44.mp3" length="72113927" type="audio/mpeg"/><itunes:duration>01:15:07</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>44</itunes:episode><itunes:season>1</itunes:season><podcast:episode>44</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Going from physics to philosophy to Bayes, working on open-source projects, and developing Bayesian models at scale</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#43 Modeling Covid19, with Michael Osthege &amp; Thomas Vladeck</title><itunes:title>Modeling Covid19, with Michael Osthege &amp; Thomas Vladeck</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>I don’t know if you’ve heard, but there is a virus that took over most of the world in the past year? I haven’t dedicated any episode to Covid yet. First because research was moving a lot — and fast. And second because modeling Covid is very, very hard.</p><p>But we know more about it now, so I thought it was a good time to pause and ponder — how does the virus circulate? How can we model it and, ultimately, defeat it? What are the challenges in doing so?</p><p>To talk about that, I had the chance to host Michael Osthege and Thomas Vladeck, who both were part of the team who developed the Rt-live model, a Bayesian model to infer the reproductive rate of Covid19 in the general population. As you’ll hear, modeling the evolution of this virus is challenging, fascinating, and a perfect fit for Bayesian modeling! It truly is a wonderful example of Bayesian generative modeling.</p><p>Tom is the Managing Director of Gradient Metrics, a quantitative market research firm, and a Co-Founder of Recast, a media mix model for modern brands.</p><p>Michael is a PhD student in laboratory automation and bioprocess optimization at the Forschungszentrum Jülich in Germany, and a fellow PyMC core-developer. As he works a lot on the coming brand new version 4, we’ll take this opportunity to talk about the current developments and where the project is headed.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode and Patrick Kelley.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Tom on Twitter: <a href="https://twitter.com/tvladeck" rel="noopener noreferrer" target="_blank">https://twitter.com/tvladeck</a></li><li>Tom's newsletter: <a href="https://tvladeck.substack.com/" rel="noopener noreferrer" target="_blank">https://tvladeck.substack.com/</a></li><li>Michael on Twitter: <a href="https://twitter.com/theCake" rel="noopener noreferrer" target="_blank">https://twitter.com/theCake</a></li><li>Michael on GitHub: <a href="https://github.com/michaelosthege" rel="noopener noreferrer" target="_blank">https://github.com/michaelosthege</a></li><li>Rt Live dashboard: <a href="https://rtlive.de/global.html" rel="noopener noreferrer" target="_blank">https://rtlive.de/global.html</a></li><li>Rt Live model tutorial: <a href="https://github.com/rtcovidlive/rtlive-global/blob/master/notebooks/Tutorial_model.ipynb" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>I don’t know if you’ve heard, but there is a virus that took over most of the world in the past year? I haven’t dedicated any episode to Covid yet. First because research was moving a lot — and fast. And second because modeling Covid is very, very hard.</p><p>But we know more about it now, so I thought it was a good time to pause and ponder — how does the virus circulate? How can we model it and, ultimately, defeat it? What are the challenges in doing so?</p><p>To talk about that, I had the chance to host Michael Osthege and Thomas Vladeck, who both were part of the team who developed the Rt-live model, a Bayesian model to infer the reproductive rate of Covid19 in the general population. As you’ll hear, modeling the evolution of this virus is challenging, fascinating, and a perfect fit for Bayesian modeling! It truly is a wonderful example of Bayesian generative modeling.</p><p>Tom is the Managing Director of Gradient Metrics, a quantitative market research firm, and a Co-Founder of Recast, a media mix model for modern brands.</p><p>Michael is a PhD student in laboratory automation and bioprocess optimization at the Forschungszentrum Jülich in Germany, and a fellow PyMC core-developer. As he works a lot on the coming brand new version 4, we’ll take this opportunity to talk about the current developments and where the project is headed.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode and Patrick Kelley.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Tom on Twitter: <a href="https://twitter.com/tvladeck" rel="noopener noreferrer" target="_blank">https://twitter.com/tvladeck</a></li><li>Tom's newsletter: <a href="https://tvladeck.substack.com/" rel="noopener noreferrer" target="_blank">https://tvladeck.substack.com/</a></li><li>Michael on Twitter: <a href="https://twitter.com/theCake" rel="noopener noreferrer" target="_blank">https://twitter.com/theCake</a></li><li>Michael on GitHub: <a href="https://github.com/michaelosthege" rel="noopener noreferrer" target="_blank">https://github.com/michaelosthege</a></li><li>Rt Live dashboard: <a href="https://rtlive.de/global.html" rel="noopener noreferrer" target="_blank">https://rtlive.de/global.html</a></li><li>Rt Live model tutorial: <a href="https://github.com/rtcovidlive/rtlive-global/blob/master/notebooks/Tutorial_model.ipynb" rel="noopener noreferrer" target="_blank">https://github.com/rtcovidlive/rtlive-global/blob/master/notebooks/Tutorial_model.ipynb</a></li><li>Rt Live model code: <a href="https://github.com/rtcovidlive/rtlive-global" rel="noopener noreferrer" target="_blank">https://github.com/rtcovidlive/rtlive-global</a></li><li>Estimating Rt: <a href="https://staff.math.su.se/hoehle/blog/2020/04/15/effectiveR0.html" rel="noopener noreferrer" target="_blank">https://staff.math.su.se/hoehle/blog/2020/04/15/effectiveR0.html</a></li><li>Great resource on terminology: <a href="https://royalsociety.org/-/media/policy/projects/set-c/set-covid-19-R-estimates.pdf?la=en-GB&amp;hash=FDFFC11968E5D247D8FF641930680BD6" rel="noopener noreferrer" target="_blank">https://royalsociety.org/-/media/policy/projects/set-c/set-covid-19-R-estimates.pdf?la=en-GB&amp;hash=FDFFC11968E5D247D8FF641930680BD6</a></li><li>Using Hierarchical Multinomial Regression to Predict Elections in Paris districts: <a href="https://www.youtube.com/watch?v=EYdIzSYwbSw" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=EYdIzSYwbSw</a></li><li>LBS #34, Multilevel Regression, Post-stratification &amp; Missing Data, with Lauren Kennedy: <a href="https://www.learnbayesstats.com/episode/34-multilevel-regression-post-stratification-missing-data-lauren-kennedy" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/34-multilevel-regression-post-stratification-missing-data-lauren-kennedy</a></li><li>mrmp - Multilevel Regression and Marginal Poststratification: <a href="https://rdrr.io/github/jwyatt85/MRmP/man/mrmp.html" rel="noopener noreferrer" target="_blank">https://rdrr.io/github/jwyatt85/MRmP/man/mrmp.html</a></li><li>Automating daily runs for rt.live’s COVID-19 data using Airflow &amp; ECS: <a href="https://medium.com/@mikekrieger/automating-daily-runs-for-rt-lives-covid-19-data-dcda26ed2e2e" rel="noopener noreferrer" target="_blank">https://medium.com/@mikekrieger/automating-daily-runs-for-rt-lives-covid-19-data-dcda26ed2e2e</a></li><li>LBS #23, Bayesian Stats in Business and Marketing Analytics, with Elea McDonnel Feit: <a href="https://www.learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/43-modeling-covid-michael-osthege-thomas-vladeck]]></link><guid isPermaLink="false">1e32ce42-8262-4651-af9f-d7c5e01de918</guid><itunes:image href="https://artwork.captivate.fm/bd467352-2374-48a6-b87a-ce7c83bf1d80/-p7xIheaKYUGddL5guXp0x6N.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 08 Jul 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/cba35fa1-7d8f-486b-8daa-2e5747b49be0/learning-bayesian-statistics-43.mp3" length="79024034" type="audio/mpeg"/><itunes:duration>01:22:19</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>43</itunes:episode><itunes:season>1</itunes:season><podcast:episode>43</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Why modeling Covid is so challenging, fascinating, and... a wonderful example of Bayesian generative modeling!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#42 How to Teach and Learn Bayesian Stats, with Mine Dogucu</title><itunes:title>How to Teach and Learn Bayesian Stats, with Mine Dogucu</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>We often talk about applying Bayesian statistics on this podcast. But how do we teach them? What’s the best way to introduce them from a young age and make sure the skills students learn in the stats class are transferable?</p><p>Well, lucky us, Mine Dogucu’s research tackles precisely those topics!</p><p>An Assistant Professor of Teaching in the Department of Statistics at University of California Irvine, Mine is both an educator with an interest in statistics, and an applied statistician with experience in educational research.</p><p>Her work focuses on modern pedagogical approaches in the statistics curriculum, making data science education more accessible. In particular, she teaches an undergraduate Bayesian course, and is the coauthor of the upcoming book Bayes Rules! An Introduction to Bayesian Modeling with R.</p><p>In other words, Mine is not only interested in teaching, but also in how best to teach statistics – how to engage students in remote classes, how to get to know them, how to best record and edit remote courses, etc. She writes about these topics on her blog, DataPedagogy.com.</p><p>She also works on accessibility and inclusion, as well as a study that investigates how popular Bayesian courses are at the undergraduate level in the US — that should be fun to talk about!</p><p>Mine did her Master’s at Bogazici University in Istanbul, Turkey, and then her PhD in Quantitative Research, Evaluation, and Measurement at Ohio State University.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, John Johnson, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode and Patrick Kelley.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Mine's website: <a href="https://mdogucu.ics.uci.edu/index.html" rel="noopener noreferrer" target="_blank">https://mdogucu.ics.uci.edu/index.html</a></li><li>Mine's blog: <a href="https://www.datapedagogy.com/" rel="noopener noreferrer" target="_blank">https://www.datapedagogy.com/</a></li><li>Mine on Twitter: <a href="https://twitter.com/MineDogucu" rel="noopener noreferrer" target="_blank">https://twitter.com/MineDogucu</a></li><li>Mine on GitHub: <a href="https://github.com/mdogucu" rel="noopener noreferrer" target="_blank">https://github.com/mdogucu</a></li><li><em>Bayes Rules! An Introduction to Bayesian Modeling with R</em>: <a href="https://www.bayesrulesbook.com/" rel="noopener noreferrer" target="_blank">https://www.bayesrulesbook.com/</a></li><li>R package for Supplemental Materials for the <em>Bayes Rules!</em> Book:]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Paperpile: </strong><a href="https://paperpile.com/" rel="noopener noreferrer" target="_blank"><strong>paperpile.com</strong></a></p><p><em>Get 20% off until December 31st with promo code GOODBAYESIAN21</em></p><p>We often talk about applying Bayesian statistics on this podcast. But how do we teach them? What’s the best way to introduce them from a young age and make sure the skills students learn in the stats class are transferable?</p><p>Well, lucky us, Mine Dogucu’s research tackles precisely those topics!</p><p>An Assistant Professor of Teaching in the Department of Statistics at University of California Irvine, Mine is both an educator with an interest in statistics, and an applied statistician with experience in educational research.</p><p>Her work focuses on modern pedagogical approaches in the statistics curriculum, making data science education more accessible. In particular, she teaches an undergraduate Bayesian course, and is the coauthor of the upcoming book Bayes Rules! An Introduction to Bayesian Modeling with R.</p><p>In other words, Mine is not only interested in teaching, but also in how best to teach statistics – how to engage students in remote classes, how to get to know them, how to best record and edit remote courses, etc. She writes about these topics on her blog, DataPedagogy.com.</p><p>She also works on accessibility and inclusion, as well as a study that investigates how popular Bayesian courses are at the undergraduate level in the US — that should be fun to talk about!</p><p>Mine did her Master’s at Bogazici University in Istanbul, Turkey, and then her PhD in Quantitative Research, Evaluation, and Measurement at Ohio State University.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, John Johnson, Hector Munoz, Marco Gorelli, Simon Kessell, Bradley Rode and Patrick Kelley.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Mine's website: <a href="https://mdogucu.ics.uci.edu/index.html" rel="noopener noreferrer" target="_blank">https://mdogucu.ics.uci.edu/index.html</a></li><li>Mine's blog: <a href="https://www.datapedagogy.com/" rel="noopener noreferrer" target="_blank">https://www.datapedagogy.com/</a></li><li>Mine on Twitter: <a href="https://twitter.com/MineDogucu" rel="noopener noreferrer" target="_blank">https://twitter.com/MineDogucu</a></li><li>Mine on GitHub: <a href="https://github.com/mdogucu" rel="noopener noreferrer" target="_blank">https://github.com/mdogucu</a></li><li><em>Bayes Rules! An Introduction to Bayesian Modeling with R</em>: <a href="https://www.bayesrulesbook.com/" rel="noopener noreferrer" target="_blank">https://www.bayesrulesbook.com/</a></li><li>R package for Supplemental Materials for the <em>Bayes Rules!</em> Book: <a href="https://github.com/bayes-rules/bayesrules" rel="noopener noreferrer" target="_blank">https://github.com/bayes-rules/bayesrules</a></li><li>Stats 115 - Introduction to Bayesian Data Analysis: <a href="https://www.stats115.com/" rel="noopener noreferrer" target="_blank">https://www.stats115.com/</a></li><li>Undergraduate Bayesian Education Network: <a href="https://undergrad-bayes.netlify.app/network.html" rel="noopener noreferrer" target="_blank">https://undergrad-bayes.netlify.app/network.html</a></li><li>Workshop "Teaching Bayesian Statistics at the Undergraduate Level": <a href="https://www.causeweb.org/cause/uscots/uscots21/workshop/4" rel="noopener noreferrer" target="_blank">https://www.causeweb.org/cause/uscots/uscots21/workshop/4</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/42-teach-bayesian-stats-mine-dogucu]]></link><guid isPermaLink="false">dcb448d0-ceaa-4e04-aa31-36276a533d42</guid><itunes:image href="https://artwork.captivate.fm/1f57441a-2d1e-49dd-b84a-b75c678c0fd2/pgYSnNg0mqyVoW99YTPr4Ens.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 24 Jun 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6498b478-6e9f-4248-9947-990a104cc6fe/ep-42-mixdown.mp3" length="158398170" type="audio/mpeg"/><itunes:duration>01:06:00</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>42</itunes:episode><itunes:season>1</itunes:season><podcast:episode>42</podcast:episode><podcast:season>1</podcast:season><itunes:summary>We often talk about applying Bayesian statistics on this podcast. But how do we teach them? What’s the best way to introduce them from a young age and make sure the skills students learn in the stats class are transferable?</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#41 Thinking Bayes, with Allen Downey</title><itunes:title>Thinking Bayes, with Allen Downey</itunes:title><description><![CDATA[<p>Let’s think Bayes, shall we? And who better to do that than the author of the well known book, <em>Think Bayes</em> — Allen Downey himself! Since the second edition was just released, the timing couldn’t be better!</p><p>Allen is a professor at Olin College and the author of books related to software and data science, including <em>Think Python</em>, <em>Think Bayes</em>, and <em>Think Complexity</em>. His blog, <em>Probably Overthinking It</em>, features articles on Bayesian probability and statistics. He holds a Ph.D. from U.C. Berkeley, and bachelors and masters degrees from MIT.</p><p>In this special episode, Allen and I talked about his background, how he came to the stats and teaching worlds, and why he wanted to write this book in the first place. He’ll tell us who this book is written for, what’s new in the second edition, and which mistakes his students most commonly make when starting to learn Bayesian stats. We also talked about some types of models, their usefulness and their weaknesses, but I’ll let you discover that.</p><p>Now for another good news: 5 Patrons of the show will get Think Bayes for free! To qualify, you just need to go the form I linked to in the 'Learn Bayes Stats' Slack channel or <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">the Patreon page</a> and enter your email address. That’s it. After a week or so, Allen and I will choose 5 winners at random, who will receive the book for free!</p><p>If you’re not a Patron yet, make sure to check out <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">patreon.com/learnbayesstats</a> if you don’t want to miss out on these goodies!</p><p>And even if you’re not a Patron, I love you dear listeners, so you all get a discount when you go buy the book at <a href="https://www.learnbayesstats.com/buy-think-bayes" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/buy-think-bayes</a> (unfortunately, this only applies for purchases in the US and Canada).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, John Johnson and Hector Munoz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Give LBS a 5-star rating on Podchaser: <a href="https://www.podchaser.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.podchaser.com/learnbayesstats</a></li><li class="ql-align-justify">Buy <em>Think Bayes</em> at a 40% discount with the code LBS40 (expires on July 31; only applies for purchases in the US and Canada): <a href="https://www.learnbayesstats.com/buy-think-bayes" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/buy-think-bayes</a></li><li><em>Think Bayes 2</em> online:...]]></description><content:encoded><![CDATA[<p>Let’s think Bayes, shall we? And who better to do that than the author of the well known book, <em>Think Bayes</em> — Allen Downey himself! Since the second edition was just released, the timing couldn’t be better!</p><p>Allen is a professor at Olin College and the author of books related to software and data science, including <em>Think Python</em>, <em>Think Bayes</em>, and <em>Think Complexity</em>. His blog, <em>Probably Overthinking It</em>, features articles on Bayesian probability and statistics. He holds a Ph.D. from U.C. Berkeley, and bachelors and masters degrees from MIT.</p><p>In this special episode, Allen and I talked about his background, how he came to the stats and teaching worlds, and why he wanted to write this book in the first place. He’ll tell us who this book is written for, what’s new in the second edition, and which mistakes his students most commonly make when starting to learn Bayesian stats. We also talked about some types of models, their usefulness and their weaknesses, but I’ll let you discover that.</p><p>Now for another good news: 5 Patrons of the show will get Think Bayes for free! To qualify, you just need to go the form I linked to in the 'Learn Bayes Stats' Slack channel or <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">the Patreon page</a> and enter your email address. That’s it. After a week or so, Allen and I will choose 5 winners at random, who will receive the book for free!</p><p>If you’re not a Patron yet, make sure to check out <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">patreon.com/learnbayesstats</a> if you don’t want to miss out on these goodies!</p><p>And even if you’re not a Patron, I love you dear listeners, so you all get a discount when you go buy the book at <a href="https://www.learnbayesstats.com/buy-think-bayes" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/buy-think-bayes</a> (unfortunately, this only applies for purchases in the US and Canada).</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt, Andrew Moskowitz, John Johnson and Hector Munoz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li class="ql-align-justify">Give LBS a 5-star rating on Podchaser: <a href="https://www.podchaser.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.podchaser.com/learnbayesstats</a></li><li class="ql-align-justify">Buy <em>Think Bayes</em> at a 40% discount with the code LBS40 (expires on July 31; only applies for purchases in the US and Canada): <a href="https://www.learnbayesstats.com/buy-think-bayes" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/buy-think-bayes</a></li><li><em>Think Bayes 2</em> online: <a href="http://allendowney.github.io/ThinkBayes2/index.html" rel="noopener noreferrer" target="_blank">http://allendowney.github.io/ThinkBayes2/index.html</a></li><li>Allen's blog: <a href="https://www.allendowney.com/blog/" rel="noopener noreferrer" target="_blank">https://www.allendowney.com/blog/</a></li><li>Allen on Twitter: <a href="https://twitter.com/allendowney" rel="noopener noreferrer" target="_blank">https://twitter.com/allendowney</a></li><li>Allen on GitHub: <a href="https://github.com/AllenDowney" rel="noopener noreferrer" target="_blank">https://github.com/AllenDowney</a></li><li><em>Information theory, inference and learning algorithms, </em>David MacKay: <a href="https://www.inference.org.uk/itila/" rel="noopener noreferrer" target="_blank">https://www.inference.org.uk/itila/</a></li><li><em>Statistical Rethinking</em>, Richard McElreath: <a href="http://xcelab.net/rm/statistical-rethinking/" rel="noopener noreferrer" target="_blank">http://xcelab.net/rm/statistical-rethinking/</a></li><li><em>Doing Bayesian Data Analysis</em>, John Kruschke: <a href="https://sites.google.com/site/doingbayesiandataanalysis/home" rel="noopener noreferrer" target="_blank">https://sites.google.com/site/doingbayesiandataanalysis/home</a></li><li><em>Probabilistic Programming &amp; Bayesian Methods for Hackers</em>, Cam Davidson-Pilon: <a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="noopener noreferrer" target="_blank">http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/</a></li><li>LBS #14, Hidden Markov Models &amp; Statistical Ecology, with Vianey Leos-Barajas: <a href="https://www.learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas</a></li><li>The Prosecutor's fallacy: <a href="https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></li><li><em>Confidence intervals vs. Bayesian intervals</em>, E.T. Jaynes: <a href="https://bayes.wustl.edu/etj/articles/confidence.pdf" rel="noopener noreferrer" target="_blank">https://bayes.wustl.edu/etj/articles/confidence.pdf</a></li><li><em>Superforecasting, The Art and Science of Prediction, </em>Philip Tetlock: <a href="https://en.wikipedia.org/wiki/Superforecasting:_The_Art_and_Science_of_Prediction" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Superforecasting:_The_Art_and_Science_of_Prediction</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/41-think-bayes-allen-downey]]></link><guid isPermaLink="false">c7264851-0cf9-4158-98c5-154de8b16418</guid><itunes:image href="https://artwork.captivate.fm/71ec9f4b-4055-4dd3-af50-c941bca07dce/bK0iYWNh0GyZednBt1SIlG4t.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 14 Jun 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5b7ad8a3-ad4c-4e1c-810b-814b301627f4/learning-bayesian-statistics-41.mp3" length="61487516" type="audio/mpeg"/><itunes:duration>01:04:03</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>41</itunes:episode><itunes:season>1</itunes:season><podcast:episode>41</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What’s new in the second edition, which mistakes Allen&apos;s students most commonly make, and... a surprise!</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#40 Bayesian Stats for the Speech &amp; Language Sciences, with Allison Hilger and Timo Roettger</title><itunes:title>Bayesian Stats for the Speech &amp; Language Sciences, with Allison Hilger and Timo Roettger</itunes:title><description><![CDATA[<p>We all know about these accidental discoveries — penicillin, the heating power of microwaves, or the famous (and delicious) tarte tatin. I don’t know why, but I just love serendipity. And, as you’ll hear, this episode is deliciously full of it…</p><p>Thanks to Allison Hilger and Timo Roettger, we’ll discover the world of linguistics, how Bayesian stats are helpful there, and how Paul Bürkner’s BRMS package has been instrumental in this field. To my surprise — and perhaps yours — the speech and language sciences are pretty quantitative and computational!</p><p>As she recently discovered Bayesian stats, Allison will also tell us about the challenges she’s faced from advisors and reviewers during her PhD at Northwestern University, and the advice she’d have for people in the same situation.</p><p>Allison is now an Assistant Professor at the University of Colorado Boulder. The overall goal in her research is to improve our understanding of motor speech control processes, in order to inform effective speech therapy treatments for improved speech naturalness and intelligibility. Allison also worked clinically as a speech-language pathologist in Chicago for a year. As a new Colorado resident, her new hobbies include hiking, skiing, and biking — and then reading or going to dog parks when she’s to tired.</p><p>Holding a PhD in linguistics from the University of Cologne, Germany, Timo is an Associate Professor for linguistics at the University of Oslo, Norway. Timo tries to understand how people communicate their intentions using speech – how are speech signals retrieved; how do people learn and generalize? Timo is also committed to improving methodologies across the language sciences in light of the replication crisis, with a strong emphasis on open science.</p><p>Most importantly, Timo loves hiking, watching movies or, even better, watching people play video games!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt and Andrew Moskowitz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Allison's website: <a href="https://allisonhilger.com/" rel="noopener noreferrer" target="_blank">https://allisonhilger.com/</a></li><li>Allison on Twitter: <a href="https://twitter.com/drahilger" rel="noopener noreferrer" target="_blank">https://twitter.com/drahilger</a></li><li>Allison's motor speech lab: <a href="https://www.colorado.edu/lab/motor-speech/" rel="noopener noreferrer" target="_blank">https://www.colorado.edu/lab/motor-speech/</a></li><li>Timo's website: <a href="https://www.simplpoints.com/" rel="noopener noreferrer" target="_blank">https://www.simplpoints.com/</a></li><li>Timo on Twitter: <a href="https://twitter.com/TimoRoettger" rel="noopener noreferrer" target="_blank">https://twitter.com/TimoRoettger</a></li><li>Bayesian...]]></description><content:encoded><![CDATA[<p>We all know about these accidental discoveries — penicillin, the heating power of microwaves, or the famous (and delicious) tarte tatin. I don’t know why, but I just love serendipity. And, as you’ll hear, this episode is deliciously full of it…</p><p>Thanks to Allison Hilger and Timo Roettger, we’ll discover the world of linguistics, how Bayesian stats are helpful there, and how Paul Bürkner’s BRMS package has been instrumental in this field. To my surprise — and perhaps yours — the speech and language sciences are pretty quantitative and computational!</p><p>As she recently discovered Bayesian stats, Allison will also tell us about the challenges she’s faced from advisors and reviewers during her PhD at Northwestern University, and the advice she’d have for people in the same situation.</p><p>Allison is now an Assistant Professor at the University of Colorado Boulder. The overall goal in her research is to improve our understanding of motor speech control processes, in order to inform effective speech therapy treatments for improved speech naturalness and intelligibility. Allison also worked clinically as a speech-language pathologist in Chicago for a year. As a new Colorado resident, her new hobbies include hiking, skiing, and biking — and then reading or going to dog parks when she’s to tired.</p><p>Holding a PhD in linguistics from the University of Cologne, Germany, Timo is an Associate Professor for linguistics at the University of Oslo, Norway. Timo tries to understand how people communicate their intentions using speech – how are speech signals retrieved; how do people learn and generalize? Timo is also committed to improving methodologies across the language sciences in light of the replication crisis, with a strong emphasis on open science.</p><p>Most importantly, Timo loves hiking, watching movies or, even better, watching people play video games!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt and Andrew Moskowitz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Allison's website: <a href="https://allisonhilger.com/" rel="noopener noreferrer" target="_blank">https://allisonhilger.com/</a></li><li>Allison on Twitter: <a href="https://twitter.com/drahilger" rel="noopener noreferrer" target="_blank">https://twitter.com/drahilger</a></li><li>Allison's motor speech lab: <a href="https://www.colorado.edu/lab/motor-speech/" rel="noopener noreferrer" target="_blank">https://www.colorado.edu/lab/motor-speech/</a></li><li>Timo's website: <a href="https://www.simplpoints.com/" rel="noopener noreferrer" target="_blank">https://www.simplpoints.com/</a></li><li>Timo on Twitter: <a href="https://twitter.com/TimoRoettger" rel="noopener noreferrer" target="_blank">https://twitter.com/TimoRoettger</a></li><li>Bayesian regression modeling (for factorial designs) -- A tutorial: <a href="https://psyarxiv.com/cdxv3" rel="noopener noreferrer" target="_blank">https://psyarxiv.com/cdxv3</a></li><li>An Introduction to Bayesian Multilevel Models Using brms -- A Case Study of Gender Effects on Vowel Variability in Standard Indonesian: <a href="https://biblio.ugent.be/publication/8624552/file/8624553.pdf" rel="noopener noreferrer" target="_blank">https://biblio.ugent.be/publication/8624552/file/8624553.pdf</a></li><li>Longitudinal Growth in Intelligibility of Connected Speech From 2 to 8 Years in Children With Cerebral Palsy -- A Novel Bayesian Approach: <a href="https://pubs.asha.org/doi/10.1044/2020_JSLHR-20-00181" rel="noopener noreferrer" target="_blank">https://pubs.asha.org/doi/10.1044/2020_JSLHR-20-00181</a></li><li>LBS #35 The Past, Present &amp; Future of BRMS, with Paul Bürkner: <a href="https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/35-past-present-future-brms-paul-burkner</a></li><li>LBS #16 Bayesian Statistics the Fun Way, with Will Kurt: <a href="https://www.learnbayesstats.com/episode/16-bayesian-statistics-the-fun-way-with-will-kurt" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/16-bayesian-statistics-the-fun-way-with-will-kurt</a></li><li>Will Kurt's <em>Bayesian Statistics The Fun Way</em>: <a href="https://nostarch.com/learnbayes" rel="noopener noreferrer" target="_blank">https://nostarch.com/learnbayes</a></li><li>LBS #20 Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari: <a href="https://www.learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/episode/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari</a></li><li><em>Regression and Other Stories</em> examples: <a href="https://avehtari.github.io/ROS-Examples/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/ROS-Examples/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/40-bayesian-stats-speech-language-sciences-allison-hilger-timo-roettger]]></link><guid isPermaLink="false">abee570e-325f-4d27-a3a7-dd2571f4befe</guid><itunes:image href="https://artwork.captivate.fm/d97b2f03-0668-4d44-af9b-005e04111f9b/-MriLkaIkV9zwSRnJrI6_3rI.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 28 May 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5a88e766-c50d-439f-8638-93ad14e4dcde/learning-bayesian-statistics-40.mp3" length="62924773" type="audio/mpeg"/><itunes:duration>01:05:32</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>40</itunes:episode><itunes:season>1</itunes:season><podcast:episode>40</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#39 Survival Models &amp; Biostatistics for Cancer Research, with Jacki Buros</title><itunes:title>Survival Models &amp; Biostatistics for Cancer Research, with Jacki Buros</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>It’s been a while since we talked about biostatistics and bioinformatics on this podcast, so I thought it could be interesting to talk to Jacki Buros — and that was a very good idea!</p><p>She’ll walk us through examples of Bayesian models she uses to, for instance, work on biomarker discovery for cancer immunotherapies. She’ll also introduce you to survival models — their usefulness, their powers and their challenges.</p><p>Interestingly, all of this will highlight a handful of skills that Jacki would try to instill in her students if she had to teach Bayesian methods.</p><p>The Head of Data and Analytics at Generable, a state-of-the-art Bayesian platform for oncology clinical trials, Jacki has been working in biostatistics and bioinformatics for over 15 years. She started in cardiology research at the TIMI Study Group at Harvard Medical School before working in Alzheimer’s Disease genetics at Boston University and in biomarker discovery for cancer immunotherapies at the Hammer Lab. Most recently she was the Lead Biostatistician at the Institute for Next Generation Health Care at Mount Sinai.</p><p>An open-source enthusiast, Jacki is also a contributor to Stan and rstanarm, and the author of the survivalstan package, a library of Stan models for survival analysis.</p><p>Last but not least, Jacki is an avid sailor and skier!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt and Andrew Moskowitz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Nominate "Learn Bayes Stats" as "Best Podcast of 2021" and "Best Tech Podcast" by entering its <a href="https://www.learnbayesstats.com/apple" rel="noopener noreferrer" target="_blank">Apple feed</a> in <a href="https://docs.google.com/forms/d/e/1FAIpQLSe60AOZu0FRvlX3GgLS1Ff8ztPgeJhVHTDhGNaTF3OLgA1Rxw/viewform" rel="noopener noreferrer" target="_blank">this form</a>!</li><li>Jacki on Twitter: <a href="https://twitter.com/jackiburos" rel="noopener noreferrer" target="_blank">https://twitter.com/jackiburos</a></li><li>Jacki on GitHub: <a href="https://github.com/jburos" rel="noopener noreferrer" target="_blank">https://github.com/jburos</a></li><li>Jacki on Orcid: <a href="https://orcid.org/0000-0001-9588-4889" rel="noopener noreferrer" target="_blank">https://orcid.org/0000-0001-9588-4889</a></li><li>survivalstan -- Survival Models in Stan: <a href="https://github.com/hammerlab/survivalstan" rel="noopener noreferrer" target="_blank">https://github.com/hammerlab/survivalstan</a></li><li>rstanarm -- R model-fitting functions using Stan: <a href="http://mc-stan.org/rstanarm/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>It’s been a while since we talked about biostatistics and bioinformatics on this podcast, so I thought it could be interesting to talk to Jacki Buros — and that was a very good idea!</p><p>She’ll walk us through examples of Bayesian models she uses to, for instance, work on biomarker discovery for cancer immunotherapies. She’ll also introduce you to survival models — their usefulness, their powers and their challenges.</p><p>Interestingly, all of this will highlight a handful of skills that Jacki would try to instill in her students if she had to teach Bayesian methods.</p><p>The Head of Data and Analytics at Generable, a state-of-the-art Bayesian platform for oncology clinical trials, Jacki has been working in biostatistics and bioinformatics for over 15 years. She started in cardiology research at the TIMI Study Group at Harvard Medical School before working in Alzheimer’s Disease genetics at Boston University and in biomarker discovery for cancer immunotherapies at the Hammer Lab. Most recently she was the Lead Biostatistician at the Institute for Next Generation Health Care at Mount Sinai.</p><p>An open-source enthusiast, Jacki is also a contributor to Stan and rstanarm, and the author of the survivalstan package, a library of Stan models for survival analysis.</p><p>Last but not least, Jacki is an avid sailor and skier!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski, Tim Radtke, Adam C. Smith, Will Kurt and Andrew Moskowitz.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Nominate "Learn Bayes Stats" as "Best Podcast of 2021" and "Best Tech Podcast" by entering its <a href="https://www.learnbayesstats.com/apple" rel="noopener noreferrer" target="_blank">Apple feed</a> in <a href="https://docs.google.com/forms/d/e/1FAIpQLSe60AOZu0FRvlX3GgLS1Ff8ztPgeJhVHTDhGNaTF3OLgA1Rxw/viewform" rel="noopener noreferrer" target="_blank">this form</a>!</li><li>Jacki on Twitter: <a href="https://twitter.com/jackiburos" rel="noopener noreferrer" target="_blank">https://twitter.com/jackiburos</a></li><li>Jacki on GitHub: <a href="https://github.com/jburos" rel="noopener noreferrer" target="_blank">https://github.com/jburos</a></li><li>Jacki on Orcid: <a href="https://orcid.org/0000-0001-9588-4889" rel="noopener noreferrer" target="_blank">https://orcid.org/0000-0001-9588-4889</a></li><li>survivalstan -- Survival Models in Stan: <a href="https://github.com/hammerlab/survivalstan" rel="noopener noreferrer" target="_blank">https://github.com/hammerlab/survivalstan</a></li><li>rstanarm -- R model-fitting functions using Stan: <a href="http://mc-stan.org/rstanarm/" rel="noopener noreferrer" target="_blank">http://mc-stan.org/rstanarm/</a></li><li>Generable -- Bayesian platform for oncology clinical trials: <a href="https://www.generable.com/" rel="noopener noreferrer" target="_blank">https://www.generable.com/</a></li><li>StanCon 2020 ArviZ presentation&nbsp;: <a href="https://github.com/arviz-devs/arviz_misc/tree/master/stancon_2020" rel="noopener noreferrer" target="_blank">https://github.com/arviz-devs/arviz_misc/tree/master/stancon_2020</a></li><li>Thinking in Bets -- Making Smarter Decisions When You Don't Have All the Facts : <a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets" rel="noopener noreferrer" target="_blank">https://www.goodreads.com/book/show/35957157-thinking-in-bets</a></li><li>Scott Kelly and his space travels (in French): <a href="https://www.franceculture.fr/emissions/la-methode-scientifique/la-methode-scientifique-mardi-30-janvier-2018" rel="noopener noreferrer" target="_blank">https://www.franceculture.fr/emissions/la-methode-scientifique/la-methode-scientifique-mardi-30-janvier-2018</a></li><li>Bayesian Workflow paper: <a href="https://arxiv.org/pdf/2011.01808v1.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/2011.01808v1.pdf</a></li><li>Bayesian Survival Analysis: <a href="https://www.springer.com/gp/book/9780387952772" rel="noopener noreferrer" target="_blank">https://www.springer.com/gp/book/9780387952772</a></li><li>Bayesian Survival Analysis Using the rstanarm R Package: <a href="https://arxiv.org/pdf/2002.09633.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/2002.09633.pdf</a></li><li>Survival Analysis, A Self-Learning Text: <a href="https://www.springer.com/gp/book/9781441966452" rel="noopener noreferrer" target="_blank">https://www.springer.com/gp/book/9781441966452</a></li><li>Survival and Event History Analysis, A Process Point of View: <a href="https://www.springer.com/gp/book/9780387202877" rel="noopener noreferrer" target="_blank">https://www.springer.com/gp/book/9780387202877</a></li><li>Prognostic Significance of Tumor-Infiltrating B Cells and Plasma Cells in Human Cancer: <a href="https://clincancerres.aacrjournals.org/content/24/24/6125" rel="noopener noreferrer" target="_blank">https://clincancerres.aacrjournals.org/content/24/24/6125</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/39-survival-models-biostatistics-cancer-research-jacki-buros]]></link><guid isPermaLink="false">53000a40-a11d-4248-899a-1fd3e3f3189f</guid><itunes:image href="https://artwork.captivate.fm/18120b8d-bcf5-461e-a13f-bb836109c72c/Uls2YFC6QpL6vkt8APJX3-Xb.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 14 May 2021 10:45:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f3bd6af9-d6d9-45e8-9433-5f303f89dbe7/ep-39-final-mix-2.mp3" length="143969174" type="audio/mpeg"/><itunes:duration>59:59</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>39</itunes:episode><itunes:season>1</itunes:season><podcast:episode>39</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#38 How to Become a Good Bayesian (&amp; Rap Artist), with Baba Brinkman</title><itunes:title>How to Become a Good Bayesian (&amp; Rap Artist), with Baba Brinkman</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>Imagine me rapping: "Let me show you how to be a good Bayesian. Change your predictions after taking information in, and if you’re thinking I’ll be less than amazing, let’s adjust those expectations!"</p><p>What?? Nah, you’re right, I’m not as good as Baba Brinkman. Actually, the best to perform «&nbsp;Good Bayesian&nbsp;» live on the podcast would just be to invite him for an episode… Wait, isn’t that what I did???</p><p>Well indeed! For this episode, I had the great pleasure of hosting rap artist, science communicator and revered author of «&nbsp;Good Bayesian&nbsp;»,&nbsp;Baba Brinkman!</p><p>We talked about his passion for oral poetry, his rap career, what being a good rapper means and the difficulties he encounters to establish himself as a proper rapper.</p><p>Baba began his rap career in 1998, freestyling and writing songs in his hometown of Vancouver, Canada.</p><p>In 2000 he started adapting Chaucer’s Canterbury Tales into original rap compositions, and in 2004 he premiered a one man show based on his Master’s thesis, The Rap Canterbury Tales, exploring parallels between hip-hop music and medieval poetry.</p><p>Over the years, Baba went on to create “Rap Guides” dedicated to scientific topics, like evolution, consciousness, medicine, religion, and climate change – and I encourage you to give them all a listen!</p><p>By the way, do you know the common point between rap and evolutionary biology? Well, you’ll have to tune in for the answer… And make sure you listen until the end: Baba has a very, very nice surprise for you!</p><p>A little tip: if you wanna enjoy it to the fullest, I put the unedited video version of this interview in the show notes ;) By the way, let me know if you like these video live streams — I might just do them again if you do!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski and Tim Radtke.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Video live-stream of the episode: <a href="https://www.youtube.com/watch?v=YkFXpP_SvHk" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=YkFXpP_SvHk</a></li><li>Baba on Twitter: <a href="https://twitter.com/bababrinkman" rel="noopener noreferrer" target="_blank">https://twitter.com/bababrinkman</a></li><li>Baba on YouTube: <a href="https://www.youtube.com/channel/UCz9Qm66ewnY0LAlZlL4HK9g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCz9Qm66ewnY0LAlZlL4HK9g</a></li><li>Baba on Spotify: <a href="https://open.spotify.com/artist/7DqKchcLvOIgR87RzJm3XH" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>Imagine me rapping: "Let me show you how to be a good Bayesian. Change your predictions after taking information in, and if you’re thinking I’ll be less than amazing, let’s adjust those expectations!"</p><p>What?? Nah, you’re right, I’m not as good as Baba Brinkman. Actually, the best to perform «&nbsp;Good Bayesian&nbsp;» live on the podcast would just be to invite him for an episode… Wait, isn’t that what I did???</p><p>Well indeed! For this episode, I had the great pleasure of hosting rap artist, science communicator and revered author of «&nbsp;Good Bayesian&nbsp;»,&nbsp;Baba Brinkman!</p><p>We talked about his passion for oral poetry, his rap career, what being a good rapper means and the difficulties he encounters to establish himself as a proper rapper.</p><p>Baba began his rap career in 1998, freestyling and writing songs in his hometown of Vancouver, Canada.</p><p>In 2000 he started adapting Chaucer’s Canterbury Tales into original rap compositions, and in 2004 he premiered a one man show based on his Master’s thesis, The Rap Canterbury Tales, exploring parallels between hip-hop music and medieval poetry.</p><p>Over the years, Baba went on to create “Rap Guides” dedicated to scientific topics, like evolution, consciousness, medicine, religion, and climate change – and I encourage you to give them all a listen!</p><p>By the way, do you know the common point between rap and evolutionary biology? Well, you’ll have to tune in for the answer… And make sure you listen until the end: Baba has a very, very nice surprise for you!</p><p>A little tip: if you wanna enjoy it to the fullest, I put the unedited video version of this interview in the show notes ;) By the way, let me know if you like these video live streams — I might just do them again if you do!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen, Raul Maldonado, Marcin Elantkowski and Tim Radtke.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Video live-stream of the episode: <a href="https://www.youtube.com/watch?v=YkFXpP_SvHk" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=YkFXpP_SvHk</a></li><li>Baba on Twitter: <a href="https://twitter.com/bababrinkman" rel="noopener noreferrer" target="_blank">https://twitter.com/bababrinkman</a></li><li>Baba on YouTube: <a href="https://www.youtube.com/channel/UCz9Qm66ewnY0LAlZlL4HK9g" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCz9Qm66ewnY0LAlZlL4HK9g</a></li><li>Baba on Spotify: <a href="https://open.spotify.com/artist/7DqKchcLvOIgR87RzJm3XH" rel="noopener noreferrer" target="_blank">https://open.spotify.com/artist/7DqKchcLvOIgR87RzJm3XH</a></li><li>Baba's website: <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a></li><li>Event Rap Kickstarter: <a href="https://www.kickstarter.com/projects/bababrinkman/event-rap-the-one-stop-custom-rap-shop" rel="noopener noreferrer" target="_blank">https://www.kickstarter.com/projects/bababrinkman/event-rap-the-one-stop-custom-rap-shop</a></li><li>Event Rap website: <a href="https://www.eventrap.com/" rel="noopener noreferrer" target="_blank">https://www.eventrap.com/</a></li><li>Anil Seth -- Your Brain Hallucinates your Conscious Reality: <a href="https://www.ted.com/talks/anil_seth_your_brain_hallucinates_your_conscious_reality" rel="noopener noreferrer" target="_blank">https://www.ted.com/talks/anil_seth_your_brain_hallucinates_your_conscious_reality</a></li><li>The Big Picture -- On the Origins of Life, Meaning, and the Universe Itself: <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/38-how-to-become-good-bayesian-rap-artist-baba-brinkman]]></link><guid isPermaLink="false">0b5982ec-6102-4d7d-97b2-fff65085f6b3</guid><itunes:image href="https://artwork.captivate.fm/22a5d6a3-828b-44e6-a5b4-52f5dfdf0d9d/SdSKMCh0L4H6GGW3k5Nx5urL.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 30 Apr 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c067eaf5-4fa3-4ad4-a659-1070c8702166/learning-bayesian-statistics-38.mp3" length="84201089" type="audio/mpeg"/><itunes:duration>01:27:43</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>38</itunes:episode><itunes:season>1</itunes:season><podcast:episode>38</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#37 Prophet, Time Series &amp; Causal Inference, with Sean Taylor</title><itunes:title>Prophet, Time Series &amp; Causal Inference, with Sean Taylor</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>I don’t know about you, but the notion of time is really intriguing to me: it’s a purely artificial notion; we humans invented it — as an experiment, I asked my cat what time it was one day; needless to say it wasn’t very conclusive… And yet, the notion of time is so central to our lives — our work, leisures and projects depend on it.</p><p>So much so that time series predictions represent a big part of the statistics and machine learning world. And to talk about all that, who better than a time master, namely Sean Taylor?</p><p>Sean is a co-creator of the Prophet time series package, available in R and Python. He’s a social scientist and statistician specialized in methods for solving causal inference and business decision problems. Sean is particularly interested in building tools for practitioners working on real-world problems, and likes to hang out with people from many fields — computer scientists, economists, political scientists, statisticians, machine learning researchers, business school scholars — although I guess he does that remotely these days…</p><p>Currently head of the Rideshare Labs team at Lyft, Sean was a research scientist and manager on Facebook’s Core Data Science Team and did a PhD in information systems at NYU’s Stern School of Business. He did his undergraduate at the University of Pennsylvania, studying economics, finance, and information systems. Last but not least, he grew up in Philadelphia, so, of course, he’s a huge Eagles fan! For my non US listeners, we’re talking about the football team here, not the bird!</p><p>We also talked about two of my favorite topics — science communication and epistemology — so I had a lot of fun talking with Sean, and I hope you’ll deem this episode a good investment of your time </p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen and Raul Maldonado.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Sean's website: <a href="https://seanjtaylor.com/" rel="noopener noreferrer" target="_blank">https://seanjtaylor.com/</a></li><li>Sean on GitHub: <a href="https://github.com/seanjtaylor" rel="noopener noreferrer" target="_blank">https://github.com/seanjtaylor</a></li><li>Sean on Twitter: <a href="https://twitter.com/seanjtaylor" rel="noopener noreferrer" target="_blank">https://twitter.com/seanjtaylor</a></li><li>Prophet docs: <a href="https://facebook.github.io/prophet/" rel="noopener noreferrer" target="_blank">https://facebook.github.io/prophet/</a></li><li>Forecasting at Scale -- How and why we developed Prophet for forecasting at Facebook: <a href="https://www.youtube.com/watch?v=OaTAe4W9IfA" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>I don’t know about you, but the notion of time is really intriguing to me: it’s a purely artificial notion; we humans invented it — as an experiment, I asked my cat what time it was one day; needless to say it wasn’t very conclusive… And yet, the notion of time is so central to our lives — our work, leisures and projects depend on it.</p><p>So much so that time series predictions represent a big part of the statistics and machine learning world. And to talk about all that, who better than a time master, namely Sean Taylor?</p><p>Sean is a co-creator of the Prophet time series package, available in R and Python. He’s a social scientist and statistician specialized in methods for solving causal inference and business decision problems. Sean is particularly interested in building tools for practitioners working on real-world problems, and likes to hang out with people from many fields — computer scientists, economists, political scientists, statisticians, machine learning researchers, business school scholars — although I guess he does that remotely these days…</p><p>Currently head of the Rideshare Labs team at Lyft, Sean was a research scientist and manager on Facebook’s Core Data Science Team and did a PhD in information systems at NYU’s Stern School of Business. He did his undergraduate at the University of Pennsylvania, studying economics, finance, and information systems. Last but not least, he grew up in Philadelphia, so, of course, he’s a huge Eagles fan! For my non US listeners, we’re talking about the football team here, not the bird!</p><p>We also talked about two of my favorite topics — science communication and epistemology — so I had a lot of fun talking with Sean, and I hope you’ll deem this episode a good investment of your time </p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen and Raul Maldonado.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Sean's website: <a href="https://seanjtaylor.com/" rel="noopener noreferrer" target="_blank">https://seanjtaylor.com/</a></li><li>Sean on GitHub: <a href="https://github.com/seanjtaylor" rel="noopener noreferrer" target="_blank">https://github.com/seanjtaylor</a></li><li>Sean on Twitter: <a href="https://twitter.com/seanjtaylor" rel="noopener noreferrer" target="_blank">https://twitter.com/seanjtaylor</a></li><li>Prophet docs: <a href="https://facebook.github.io/prophet/" rel="noopener noreferrer" target="_blank">https://facebook.github.io/prophet/</a></li><li>Forecasting at Scale -- How and why we developed Prophet for forecasting at Facebook: <a href="https://www.youtube.com/watch?v=OaTAe4W9IfA" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=OaTAe4W9IfA</a></li><li>&nbsp;Forecasting at Scale paper: <a href="https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1380080?journalCode=utas20&amp;" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1380080?journalCode=utas20&amp;</a></li><li>TimeSeers -- Hierarchical version of Prophet, written in PyMC3: <a href="https://github.com/MBrouns/timeseers" rel="noopener noreferrer" target="_blank">https://github.com/MBrouns/timeseers</a></li><li>The Art of Doing Science and Engineering -- Learning to Learn: <a href="https://www.amazon.com/Art-Doing-Science-Engineering-Learning/dp/1732265178" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Art-Doing-Science-Engineering-Learning/dp/1732265178</a></li><li>NeuralProphet -- Forecasting model based on Neural Networks in PyTorch: <a href="https://github.com/ourownstory/neural_prophet/" rel="noopener noreferrer" target="_blank">https://github.com/ourownstory/neural_prophet/</a></li><li>Introducing PyMC Labs: <a href="https://www.pymc-labs.io/blog-posts/saving-the-world/" rel="noopener noreferrer" target="_blank">https://www.pymc-labs.io/blog-posts/saving-the-world/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/37-prophet-time-series-causal-inference-sean-taylor]]></link><guid isPermaLink="false">f36f9ce2-25e5-4dab-937c-e7897e53a2e4</guid><itunes:image href="https://artwork.captivate.fm/257a3d31-f137-494b-8d47-9310d84a6f0f/zlzciQErUXL16DxLqfRTZXnQ.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 16 Apr 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/92378424-00db-43eb-8125-4655fc821f7c/ep-37-mixdown.mp3" length="158985403" type="audio/mpeg"/><itunes:duration>01:06:15</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>37</itunes:episode><itunes:season>1</itunes:season><podcast:episode>37</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#36 Bayesian Non-Parametrics &amp; Developing Turing.jl, with Martin Trapp</title><itunes:title>Bayesian Non-Parametrics &amp; Developing Turing.jl, with Martin Trapp</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>I bet you already heard of Bayesian nonparametric models, at least on this very podcast. We already talked about Dirichlet Processes with Karin Knudson on episode 4, and then about Gaussian Processes with Elizaveta Semenova on episode 21. Now we’re gonna dive into the mathematical properties of these objects, to understand them better — because, as you may know, Bayesian nonparametrics are quite powerful but also very hard to fit!</p><p>Along the way, you’ll learn about probabilistic circuits, sum-product networks and — what a delight — you’ll hear from the Julia community! Indeed, my guest for this episode is no other than… Martin Trapp!</p><p>Martin is a core developer of Turing.jl, an open-source framework for probabilistic programming in Julia, and a post-doc in probabilistic machine learning at Aalto University, Finland.</p><p>Martin loves working on sum-product networks and Bayesian non-parametrics. And indeed, his research interests focus on probabilistic models that exploit structural properties to allow efficient and exact computations while maintaining the capability to model complex relationships in data. In other words, Martin’s research is focused on tractable probabilistic models.</p><p>Martin did his MsC in computational intelligence at the Vienna University of Technology and just finished his PhD in machine learning at the Graz University of Technology. He doesn’t only like to study the tractability of probabilistic models — he also is very found of climbing!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen and Raul Maldonado.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Martin's website: <a href="https://trappmartin.github.io/" rel="noopener noreferrer" target="_blank">https://trappmartin.github.io/</a></li><li>Martin on GitHub: <a href="https://github.com/trappmartin" rel="noopener noreferrer" target="_blank">https://github.com/trappmartin</a></li><li>Martin on Twitter: <a href="https://twitter.com/martin_trapp" rel="noopener noreferrer" target="_blank">https://twitter.com/martin_trapp</a></li><li>Turing, Bayesian inference with Julia: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Hierarchical Dirichlet Processes: <a href="https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf" rel="noopener noreferrer" target="_blank">https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf</a></li><li>The Automatic Statistician: <a href="https://www.doc.ic.ac.uk/~mpd37/teaching/2014/ml_tutorials/2014-01-29-slides_zoubin2.pdf" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>I bet you already heard of Bayesian nonparametric models, at least on this very podcast. We already talked about Dirichlet Processes with Karin Knudson on episode 4, and then about Gaussian Processes with Elizaveta Semenova on episode 21. Now we’re gonna dive into the mathematical properties of these objects, to understand them better — because, as you may know, Bayesian nonparametrics are quite powerful but also very hard to fit!</p><p>Along the way, you’ll learn about probabilistic circuits, sum-product networks and — what a delight — you’ll hear from the Julia community! Indeed, my guest for this episode is no other than… Martin Trapp!</p><p>Martin is a core developer of Turing.jl, an open-source framework for probabilistic programming in Julia, and a post-doc in probabilistic machine learning at Aalto University, Finland.</p><p>Martin loves working on sum-product networks and Bayesian non-parametrics. And indeed, his research interests focus on probabilistic models that exploit structural properties to allow efficient and exact computations while maintaining the capability to model complex relationships in data. In other words, Martin’s research is focused on tractable probabilistic models.</p><p>Martin did his MsC in computational intelligence at the Vienna University of Technology and just finished his PhD in machine learning at the Graz University of Technology. He doesn’t only like to study the tractability of probabilistic models — he also is very found of climbing!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen, Jonathan Sedar, Hugo Botha, Vinh Nguyen and Raul Maldonado.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Martin's website: <a href="https://trappmartin.github.io/" rel="noopener noreferrer" target="_blank">https://trappmartin.github.io/</a></li><li>Martin on GitHub: <a href="https://github.com/trappmartin" rel="noopener noreferrer" target="_blank">https://github.com/trappmartin</a></li><li>Martin on Twitter: <a href="https://twitter.com/martin_trapp" rel="noopener noreferrer" target="_blank">https://twitter.com/martin_trapp</a></li><li>Turing, Bayesian inference with Julia: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Hierarchical Dirichlet Processes: <a href="https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf" rel="noopener noreferrer" target="_blank">https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf</a></li><li>The Automatic Statistician: <a href="https://www.doc.ic.ac.uk/~mpd37/teaching/2014/ml_tutorials/2014-01-29-slides_zoubin2.pdf" rel="noopener noreferrer" target="_blank">https://www.doc.ic.ac.uk/~mpd37/teaching/2014/ml_tutorials/2014-01-29-slides_zoubin2.pdf</a></li><li>Truncated Random Measures: <a href="https://arxiv.org/abs/1603.00861" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1603.00861</a></li><li>Deep Structured Mixtures of Gaussian Processes: <a href="https://arxiv.org/abs/1910.04536" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1910.04536</a></li><li>Probabilistic Circuits -- Representations, Inference, Learning and Theory: <a href="https://www.youtube.com/watch?v=2RAG5-L9R70" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=2RAG5-L9R70</a></li><li>Applied Stochastic Differential Equations, from Simo Särkkä and Arno Solin: <a href="https://users.aalto.fi/~asolin/sde-book/sde-book.pdf" rel="noopener noreferrer" target="_blank">https://users.aalto.fi/~asolin/sde-book/sde-book.pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/36-bayesian-non-parametrics-developing-turing-julia-martin-trapp]]></link><guid isPermaLink="false">231a188d-ec38-4124-b0d1-d772fbe85de9</guid><itunes:image href="https://artwork.captivate.fm/73b53c6b-2ceb-4c5f-89f2-5bfc3cba7faa/2YOz48L6CiGw7NdiWZoyYjLj.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 30 Mar 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/d9418157-3923-41d4-8473-bee296631137/learning-bayesian-statistics-36.mp3" length="66715049" type="audio/mpeg"/><itunes:duration>01:09:29</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>36</itunes:episode><itunes:season>1</itunes:season><podcast:episode>36</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#35 The Past, Present &amp; Future of BRMS, with Paul Bürkner</title><itunes:title>The Past, Present &amp; Future of BRMS, with Paul Bürkner</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>One of the most common guest suggestions that you dear listeners make is… inviting Paul Bürkner on the show! Why? Because he’s a member of the Stan development team and he created BRMS, a popular R package to make and sample from Bayesian regression models using Stan. And, as I like you, I did invite Paul on the show and, well, that was a good call: we had an amazing conversation, spanning so many topics that I can’t list them all here!</p><p>I asked him why he created BRMS, in which fields it’s mostly used, what its weaknesses are, and which improvements to the package he’s currently working on. But that’s not it! Paul also gave his advice to people realizing that Bayesian methods would be useful to their research, but who fear facing challenges from advisors or reviewers.</p><p>Besides being a Bayesian rockstar, Paul is a statistician working as an Independent Junior Research Group Leader at the Cluster of Excellence SimTech at the University of Stuttgart, Germany. Previously, he has studied Psychology and Mathematics at the Universities of Münster and Hagen and did his PhD in Münster about optimal design and Bayesian data analysis, and he also worked as a Postdoctoral researcher at the Department of Computer Science at Aalto University, Finland.</p><p>So, of course, I asked him about the software-assisted Bayesian workflow that he’s currently working on with Aki Vehtari, which led us to no less than the future of probabilistic programming languages…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen and Jonathan Sedar.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Paul's website: <a href="https://paul-buerkner.github.io/about/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/about/</a></li><li>Paul on Twitter: <a href="https://twitter.com/paulbuerkner" rel="noopener noreferrer" target="_blank">https://twitter.com/paulbuerkner</a></li><li>Paul on GitHub: <a href="https://github.com/paul-buerkner" rel="noopener noreferrer" target="_blank">https://github.com/paul-buerkner</a></li><li>BRMS docs: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>Stan docs: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Bayesian workflow paper: <a href="https://arxiv.org/pdf/2011.01808v1.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/2011.01808v1.pdf</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>One of the most common guest suggestions that you dear listeners make is… inviting Paul Bürkner on the show! Why? Because he’s a member of the Stan development team and he created BRMS, a popular R package to make and sample from Bayesian regression models using Stan. And, as I like you, I did invite Paul on the show and, well, that was a good call: we had an amazing conversation, spanning so many topics that I can’t list them all here!</p><p>I asked him why he created BRMS, in which fields it’s mostly used, what its weaknesses are, and which improvements to the package he’s currently working on. But that’s not it! Paul also gave his advice to people realizing that Bayesian methods would be useful to their research, but who fear facing challenges from advisors or reviewers.</p><p>Besides being a Bayesian rockstar, Paul is a statistician working as an Independent Junior Research Group Leader at the Cluster of Excellence SimTech at the University of Stuttgart, Germany. Previously, he has studied Psychology and Mathematics at the Universities of Münster and Hagen and did his PhD in Münster about optimal design and Bayesian data analysis, and he also worked as a Postdoctoral researcher at the Department of Computer Science at Aalto University, Finland.</p><p>So, of course, I asked him about the software-assisted Bayesian workflow that he’s currently working on with Aki Vehtari, which led us to no less than the future of probabilistic programming languages…</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege, Rémi Louf, Clive Edelsten, Henri Wallen and Jonathan Sedar.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Paul's website: <a href="https://paul-buerkner.github.io/about/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/about/</a></li><li>Paul on Twitter: <a href="https://twitter.com/paulbuerkner" rel="noopener noreferrer" target="_blank">https://twitter.com/paulbuerkner</a></li><li>Paul on GitHub: <a href="https://github.com/paul-buerkner" rel="noopener noreferrer" target="_blank">https://github.com/paul-buerkner</a></li><li>BRMS docs: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>Stan docs: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Bayesian workflow paper: <a href="https://arxiv.org/pdf/2011.01808v1.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/2011.01808v1.pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/35-past-present-future-brms-paul-burkner]]></link><guid isPermaLink="false">104202d3-72b4-47c1-8da4-ffafff293987</guid><itunes:image href="https://artwork.captivate.fm/f5cb2cfc-22f0-42a2-bcc0-4f71b70aa181/7NLTgmE5ixV8DHVxsXDXxNOL.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 12 Mar 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/a62e39da-3422-4be2-b500-ef5964464f08/ep-35-mixdown.mp3" length="160914284" type="audio/mpeg"/><itunes:duration>01:07:03</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>35</itunes:episode><itunes:season>1</itunes:season><podcast:episode>35</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#34 Multilevel Regression, Post-stratification &amp; Missing Data, with Lauren Kennedy</title><itunes:title>Multilevel Regression, Post-stratification &amp; Missing Data, with Lauren Kennedy</itunes:title><description><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>We already mentioned multilevel regression and post-stratification (MRP, or Mister P) on this podcast, but we didn’t dedicate a full episode to explaining how it works, why it’s useful to deal with non-representative data, and what its limits are. Well, let’s do that now, shall we?</p><p>To that end, I had the delight to talk with Lauren Kennedy! Lauren is a lecturer in Business Analytics at Monash University in Melbourne, Australia, where she develops new statistical methods to analyze social science data. Working mainly with R and Stan, Lauren studies non-representative data, multilevel modeling, post-stratification, causal inference, and, more generally, how to make inferences from the social sciences.</p><p>Needless to say that I asked her everything I could about MRP, including how to choose priors, why her recent paper about structured priors can improve MRP, and when MRP is not useful. We also talked about missing data imputation, and how all these methods relate to causal inference in the social sciences.</p><p>If you want a bit of background, Lauren did her Undergraduates in Psychological Sciences and Maths and Computer Sciences at Adelaide University, with Danielle Navarro and Andrew Perfors, and then did her PhD with the same advisors. She spent 3 years in NYC with Andrew Gelman’s Lab at Columbia University, and then moved back to Melbourne in 2020. Most importantly, Lauren is an adept of crochet — she’s already on her third blanket!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege and Rémi Louf.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Lauren's website: <a href="https://jazzystats.com/" rel="noopener noreferrer" target="_blank">https://jazzystats.com/</a></li><li>Lauren on Twitter: <a href="https://twitter.com/jazzystats" rel="noopener noreferrer" target="_blank">https://twitter.com/jazzystats</a></li><li>Lauren on GitHub: <a href="https://github.com/lauken13" rel="noopener noreferrer" target="_blank">https://github.com/lauken13</a></li><li>Improving multilevel regression and poststratification with structured priors: <a href="https://arxiv.org/abs/1908.06716" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1908.06716</a></li><li>Using model-based regression and poststratification to generalize findings beyond the observed sample: <a href="https://arxiv.org/abs/1906.11323" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1906.11323</a></li><li>Lauren's beginners Bayes workshop: <a href="https://github.com/lauken13/Beginners_Bayes_Workshop" rel="noopener noreferrer" target="_blank">https://github.com/lauken13/Beginners_Bayes_Workshop</a></li><li>MRP in RStanarm: <a href="https://github.com/lauken13/rstanarm/blob/master/vignettes/mrp.Rmd"...]]></description><content:encoded><![CDATA[<p><strong>Episode sponsored by Tidelift: </strong><a href="https://tidelift.com/" rel="noopener noreferrer" target="_blank"><strong>tidelift.com</strong></a></p><p>We already mentioned multilevel regression and post-stratification (MRP, or Mister P) on this podcast, but we didn’t dedicate a full episode to explaining how it works, why it’s useful to deal with non-representative data, and what its limits are. Well, let’s do that now, shall we?</p><p>To that end, I had the delight to talk with Lauren Kennedy! Lauren is a lecturer in Business Analytics at Monash University in Melbourne, Australia, where she develops new statistical methods to analyze social science data. Working mainly with R and Stan, Lauren studies non-representative data, multilevel modeling, post-stratification, causal inference, and, more generally, how to make inferences from the social sciences.</p><p>Needless to say that I asked her everything I could about MRP, including how to choose priors, why her recent paper about structured priors can improve MRP, and when MRP is not useful. We also talked about missing data imputation, and how all these methods relate to causal inference in the social sciences.</p><p>If you want a bit of background, Lauren did her Undergraduates in Psychological Sciences and Maths and Computer Sciences at Adelaide University, with Danielle Navarro and Andrew Perfors, and then did her PhD with the same advisors. She spent 3 years in NYC with Andrew Gelman’s Lab at Columbia University, and then moved back to Melbourne in 2020. Most importantly, Lauren is an adept of crochet — she’s already on her third blanket!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege and Rémi Louf.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Lauren's website: <a href="https://jazzystats.com/" rel="noopener noreferrer" target="_blank">https://jazzystats.com/</a></li><li>Lauren on Twitter: <a href="https://twitter.com/jazzystats" rel="noopener noreferrer" target="_blank">https://twitter.com/jazzystats</a></li><li>Lauren on GitHub: <a href="https://github.com/lauken13" rel="noopener noreferrer" target="_blank">https://github.com/lauken13</a></li><li>Improving multilevel regression and poststratification with structured priors: <a href="https://arxiv.org/abs/1908.06716" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1908.06716</a></li><li>Using model-based regression and poststratification to generalize findings beyond the observed sample: <a href="https://arxiv.org/abs/1906.11323" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1906.11323</a></li><li>Lauren's beginners Bayes workshop: <a href="https://github.com/lauken13/Beginners_Bayes_Workshop" rel="noopener noreferrer" target="_blank">https://github.com/lauken13/Beginners_Bayes_Workshop</a></li><li>MRP in RStanarm: <a href="https://github.com/lauken13/rstanarm/blob/master/vignettes/mrp.Rmd" rel="noopener noreferrer" target="_blank">https://github.com/lauken13/rstanarm/blob/master/vignettes/mrp.Rmd</a></li><li>Choosing your rstanarm prior with prior predictive checks: <a href="https://github.com/stan-dev/rstanarm/blob/vignette-prior-predictive/vignettes/prior-pred.Rmd" rel="noopener noreferrer" target="_blank">https://github.com/stan-dev/rstanarm/blob/vignette-prior-predictive/vignettes/prior-pred.Rmd</a></li><li>Mister P -- What’s its secret sauce?: <a href="https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/</a></li><li>Bayesian Multilevel Estimation with Poststratification -- State-Level Estimates from National Polls: <a href="https://pdfs.semanticscholar.org/2008/bee9f8c2d7e41ac9c5c54489f41989a0d7ba.pdf" rel="noopener noreferrer" target="_blank">https://pdfs.semanticscholar.org/2008/bee9f8c2d7e41ac9c5c54489f41989a0d7ba.pdf</a></li><li>MRPyMC3 - Multilevel Regression and Poststratification with PyMC3: <a href="https://austinrochford.com/posts/2017-07-09-mrpymc3.html" rel="noopener noreferrer" target="_blank">https://austinrochford.com/posts/2017-07-09-mrpymc3.html</a></li><li>Using Hierarchical Multinomial Regression to Predict Elections in Paris districts: <a href="https://www.youtube.com/watch?v=EYdIzSYwbSw" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=EYdIzSYwbSw</a></li><li><em>Regression and Other Stories</em> book: <a href="https://www.cambridge.org/fr/academic/subjects/statistics-probability/statistical-theory-and-methods/regression-and-other-stories?format=PB" rel="noopener noreferrer" target="_blank">https://www.cambridge.org/fr/academic/subjects/statistics-probability/statistical-theory-and-methods/regression-and-other-stories?format=PB</a></li><li>&nbsp;Bayesian Nonparametric Modeling for Causal Inference, by Jennifer Hill: <a href="https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162" rel="noopener noreferrer" target="_blank">https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162</a></li><li>Lauren's Data Ethics course: <a href="https://anastasiospanagiotelis.netlify.app/teaching/dataviza2019/lectures/04dataethics/ethicaldatascience#1" rel="noopener noreferrer" target="_blank">https://anastasiospanagiotelis.netlify.app/teaching/dataviza2019/lectures/04dataethics/ethicaldatascience#1</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/34-multilevel-regression-post-stratification-missing-data-lauren-kennedy]]></link><guid isPermaLink="false">3e09a82a-1395-4105-aeb8-d320bdef9b8b</guid><itunes:image href="https://artwork.captivate.fm/3a27bee9-3a67-4cc1-9130-0b7e75bc6aee/WD1mZwp5mjWPllClHbXLFyBZ.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 25 Feb 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/1e554abd-cb42-4e19-b1bf-212c52d59311/learning-bayesian-statistics-34.mp3" length="69758315" type="audio/mpeg"/><itunes:duration>01:12:39</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>34</itunes:episode><itunes:season>1</itunes:season><podcast:episode>34</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#33 Bayesian Structural Time Series, with Ben Zweig</title><itunes:title>Bayesian Structural Time Series, with Ben Zweig</itunes:title><description><![CDATA[<p>How do people choose their career? How do they change jobs? How do they even change careers? These are important questions that we don’t have great answers to. But structured data about the dynamics of labor markets are starting to emerge, and that’s what Ben Zweig is modeling at Revelio Labs.</p><p>An economist and data scientist, Ben is indeed the CEO of Revelio Labs, a data science company analyzing raw labor data contained in resumes, online profiles and job postings. In this episode, he’ll tell us about the Bayesian structural time series model they built to estimate inflows and outflows from companies, using LinkedIn data — a very challenging but fascinating endeavor, as you’ll hear!</p><p>As a lot of people, Ben has always used more traditional statistical models but had been intrigued by Bayesian methods for a long time. When they started working on this Bayesian time series model though, he had to learn a bunch of new methods really quickly. I think you’ll find interesting to hear how it went…</p><p>Ben also teaches data science and econometrics at the NYU Stern school of business, so he’ll reflect on his experience teaching Bayesian methods to economics students. Prior to that, Ben did a PhD in economics at the City University of New York, and has done research in occupational transformation and social mobility.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege and Rémi Louf.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Ben's bio: <a href="https://www.stern.nyu.edu/faculty/bio/benjamin-zweig" rel="noopener noreferrer" target="_blank">https://www.stern.nyu.edu/faculty/bio/benjamin-zweig</a></li><li>Revelio Labs blog: <a href="https://www.reveliolabs.com/blog/" rel="noopener noreferrer" target="_blank">https://www.reveliolabs.com/blog/</a></li><li><em>Predicting the Present with Bayesian Structural Time Series</em>: <a href="https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf" rel="noopener noreferrer" target="_blank">https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf</a></li><li><em>A Hierarchical Framework for CorrectingUnder-Reporting in Count Data</em>: <a href="https://arxiv.org/pdf/1809.00544.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1809.00544.pdf</a></li><li>TensorFlow Probability module for Bayesian structural time series models: <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/sts/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/api_docs/python/tfp/sts/</a></li><li>&nbsp;Fitting Bayesian structural time series with the bsts R package: <a href="https://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>How do people choose their career? How do they change jobs? How do they even change careers? These are important questions that we don’t have great answers to. But structured data about the dynamics of labor markets are starting to emerge, and that’s what Ben Zweig is modeling at Revelio Labs.</p><p>An economist and data scientist, Ben is indeed the CEO of Revelio Labs, a data science company analyzing raw labor data contained in resumes, online profiles and job postings. In this episode, he’ll tell us about the Bayesian structural time series model they built to estimate inflows and outflows from companies, using LinkedIn data — a very challenging but fascinating endeavor, as you’ll hear!</p><p>As a lot of people, Ben has always used more traditional statistical models but had been intrigued by Bayesian methods for a long time. When they started working on this Bayesian time series model though, he had to learn a bunch of new methods really quickly. I think you’ll find interesting to hear how it went…</p><p>Ben also teaches data science and econometrics at the NYU Stern school of business, so he’ll reflect on his experience teaching Bayesian methods to economics students. Prior to that, Ben did a PhD in economics at the City University of New York, and has done research in occupational transformation and social mobility.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll, Nathaniel Burbank, Michael Osthege and Rémi Louf.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Ben's bio: <a href="https://www.stern.nyu.edu/faculty/bio/benjamin-zweig" rel="noopener noreferrer" target="_blank">https://www.stern.nyu.edu/faculty/bio/benjamin-zweig</a></li><li>Revelio Labs blog: <a href="https://www.reveliolabs.com/blog/" rel="noopener noreferrer" target="_blank">https://www.reveliolabs.com/blog/</a></li><li><em>Predicting the Present with Bayesian Structural Time Series</em>: <a href="https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf" rel="noopener noreferrer" target="_blank">https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf</a></li><li><em>A Hierarchical Framework for CorrectingUnder-Reporting in Count Data</em>: <a href="https://arxiv.org/pdf/1809.00544.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1809.00544.pdf</a></li><li>TensorFlow Probability module for Bayesian structural time series models: <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/sts/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/api_docs/python/tfp/sts/</a></li><li>&nbsp;Fitting Bayesian structural time series with the bsts R package: <a href="https://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html" rel="noopener noreferrer" target="_blank">https://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html</a></li><li>CausalImpact, an R package for causal inference using Bayesian structural time-series models: <a href="https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html" rel="noopener noreferrer" target="_blank">https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/33-bayesian-structural-time-series-ben-zweig]]></link><guid isPermaLink="false">d6152cef-8ed1-45ba-b068-6ff644128e8d</guid><itunes:image href="https://artwork.captivate.fm/5db6cace-b292-47a1-bcc2-42d08c1cd91b/AA92Wr0BedU333RY7Z0a6o1L.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 12 Feb 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/7327c481-43ce-4388-b8e3-78db9b07fa17/learning-bayesian-statistics-33.mp3" length="55524020" type="audio/mpeg"/><itunes:duration>57:50</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>33</itunes:episode><itunes:season>1</itunes:season><podcast:episode>33</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#32 Getting involved into Bayesian Stats &amp; Open-Source Development, with Peadar Coyle</title><itunes:title>Getting involved into Bayesian Stats &amp; Open-Source Development, with Peadar Coyle</itunes:title><description><![CDATA[<p>When explaining Bayesian statistics to people who don’t know anything about stats, I often say that MCMC is about walking many different paths in lots of parallel universes, and then counting what happened in all these universes.</p><p>And in a sense, this whole podcast is dedicated to sampling the whole distribution of Bayesian practitioners. So, for this episode, I thought we’d take a break of pure, hard modeling and talk about how to get involved into Bayesian statistics and open-source development, how companies use Bayesian tools, and what common struggles and misperceptions the latter suffer from.</p><p>Quite the program, right? The good news is that Peadar Coyle, my guest for this episode, has done all of that! Coming to us from Armagh, Ireland, Peadar is a fellow PyMC core developer and was a data science and data engineer consultant until recently – a period during which he has covered all of modern startup data science, from AB testing to dashboards to data engineering to putting models into production.</p><p>From these experiences, Peadar has written a book consisting of numerous interviews with data scientists throughout the world – and do consider buying it, as money goes to the NumFOCUS organization, under which many Bayesian stats packages live, like Stan, ArviZ, PyMC, etc.</p><p>Now living in London, Peadar recently founded the start-up Aflorithmic, an AI solution that aims at developing personalized voice-first solutions for brands and enterprises. Their technology is also used to support children, families and elderly coping with the mental health challenges of COVID-19 confinements.</p><p>Before all that, Peadar studied physics, philosophy and mathematics at the universities of Bristol and Luxembourg. When he’s away from keyboard, he enjoys the outdoors, cooking and, of course, watching rugby!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll and Nathaniel Burbank.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>"Matchmaking Dinner" announcement: <a href="https://twitter.com/alex_andorra/status/1351136756087734272" rel="noopener noreferrer" target="_blank">https://twitter.com/alex_andorra/status/1351136756087734272</a></li><li>How to get acces to "Matchmaking Dinner" episodes: <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a></li><li>Peadar on Twitter: <a href="https://twitter.com/springcoil" rel="noopener noreferrer" target="_blank">https://twitter.com/springcoil</a></li><li>Peadar's website: <a href="https://peadarcoyle.com/" rel="noopener noreferrer" target="_blank">https://peadarcoyle.com/</a></li><li>Peadar on GitHub: <a href="https://github.com/springcoil" rel="noopener noreferrer" target="_blank">https://github.com/springcoil</a></li><li>Interviews with Data Scientists -- A discussion of the Industy and the current trends: <a...]]></description><content:encoded><![CDATA[<p>When explaining Bayesian statistics to people who don’t know anything about stats, I often say that MCMC is about walking many different paths in lots of parallel universes, and then counting what happened in all these universes.</p><p>And in a sense, this whole podcast is dedicated to sampling the whole distribution of Bayesian practitioners. So, for this episode, I thought we’d take a break of pure, hard modeling and talk about how to get involved into Bayesian statistics and open-source development, how companies use Bayesian tools, and what common struggles and misperceptions the latter suffer from.</p><p>Quite the program, right? The good news is that Peadar Coyle, my guest for this episode, has done all of that! Coming to us from Armagh, Ireland, Peadar is a fellow PyMC core developer and was a data science and data engineer consultant until recently – a period during which he has covered all of modern startup data science, from AB testing to dashboards to data engineering to putting models into production.</p><p>From these experiences, Peadar has written a book consisting of numerous interviews with data scientists throughout the world – and do consider buying it, as money goes to the NumFOCUS organization, under which many Bayesian stats packages live, like Stan, ArviZ, PyMC, etc.</p><p>Now living in London, Peadar recently founded the start-up Aflorithmic, an AI solution that aims at developing personalized voice-first solutions for brands and enterprises. Their technology is also used to support children, families and elderly coping with the mental health challenges of COVID-19 confinements.</p><p>Before all that, Peadar studied physics, philosophy and mathematics at the universities of Bristol and Luxembourg. When he’s away from keyboard, he enjoys the outdoors, cooking and, of course, watching rugby!</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll and Nathaniel Burbank.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>"Matchmaking Dinner" announcement: <a href="https://twitter.com/alex_andorra/status/1351136756087734272" rel="noopener noreferrer" target="_blank">https://twitter.com/alex_andorra/status/1351136756087734272</a></li><li>How to get acces to "Matchmaking Dinner" episodes: <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a></li><li>Peadar on Twitter: <a href="https://twitter.com/springcoil" rel="noopener noreferrer" target="_blank">https://twitter.com/springcoil</a></li><li>Peadar's website: <a href="https://peadarcoyle.com/" rel="noopener noreferrer" target="_blank">https://peadarcoyle.com/</a></li><li>Peadar on GitHub: <a href="https://github.com/springcoil" rel="noopener noreferrer" target="_blank">https://github.com/springcoil</a></li><li>Interviews with Data Scientists -- A discussion of the Industy and the current trends: <a href="https://leanpub.com/interviewswithdatascientists/" rel="noopener noreferrer" target="_blank">https://leanpub.com/interviewswithdatascientists/</a></li><li>Aflorithmic -- Personalized Audio SaaS Platform: <a href="https://www.aflorithmic.ai/" rel="noopener noreferrer" target="_blank">https://www.aflorithmic.ai/</a></li><li>Peadar's PyMC3 Primer: <a href="https://product.peadarcoyle.com/" rel="noopener noreferrer" target="_blank">https://product.peadarcoyle.com/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/32-getting-involved-bayesian-stats-opensource-development-peadar-coyle]]></link><guid isPermaLink="false">2e0a8e7d-a0f0-47ed-b57a-27114749d776</guid><itunes:image href="https://artwork.captivate.fm/f2af1bc1-4873-41d7-a908-6e293faaec99/-ocYAKZOhtb3LRqWL9ifm8rc.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 27 Jan 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/50e4dff4-72d2-45ee-968c-edcbcc3602b9/learning-bayesian-statistics-32.mp3" length="50962457" type="audio/mpeg"/><itunes:duration>53:05</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>32</itunes:episode><itunes:season>1</itunes:season><podcast:episode>32</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#31 Bayesian Cognitive Modeling &amp; Decision-Making, with Michael Lee</title><itunes:title>Bayesian Cognitive Modeling &amp; Decision-Making, with Michael Lee</itunes:title><description><![CDATA[<p>I don’t know if you noticed, but I have a fondness for any topic related to decision-making under uncertainty — when it’s studied scientifically of course. Understanding how and why people make decisions when they don’t have all the facts is fascinating to me. That’s why I like electoral forecasting and I love cognitive sciences.</p><p>So, for the first episode of 2021, I have a special treat: I had the great pleasure of hosting Michael Lee on the podcast! Yes, the Michael Lee who co-authored the book Bayesian Cognitive Modeling with Eric-Jan Wagenmakers in 2013 — by the way, the book was ported to PyMC3, I put the link in the show notes ;)</p><p>This book was inspired from Michael’s work as a professor of cognitive sciences at University of California, Irvine. He works a lot on representation, memory, learning, and decision making, with a special focus on individual differences and collective cognition.</p><p>Using naturally occurring behavioral data, he builds probabilistic generative models to try and answer hard real-world questions: how does memory impairment work (that’s modeled with multinomial processing trees)? How complex are simple decisions, and how do people change strategies?</p><p>Echoing episode 18 with Daniel Lakens, Michael and I also talked about the reproducibility crisis: how are cognitive sciences doing, which progress was made, and what is still to do?</p><p>Living now in California, Michael is originally from Australia, where he did his Bachelors of Psychology and Mathematics, and his PhD in psychology. But Michael is also found of the city of Amsterdam, which he sees as “the perfect antidote to southern California with old buildings, public transport, great bread and beer, and crappy weather”.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll and Nathaniel Burbank.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Michael's website: <a href="https://faculty.sites.uci.edu/mdlee/" rel="noopener noreferrer" target="_blank">https://faculty.sites.uci.edu/mdlee/</a></li><li>Michael on GitHub: <a href="https://twitter.com/mdlBayes" rel="noopener noreferrer" target="_blank">https://twitter.com/mdlBayes</a></li><li><em>Bayesian Cognitive Modeling</em> book: <a href="https://faculty.sites.uci.edu/mdlee/bgm/" rel="noopener noreferrer" target="_blank">https://faculty.sites.uci.edu/mdlee/bgm/</a></li><li><em>Bayesian Cognitive Modeling</em> in PyMC3: <a href="https://github.com/pymc-devs/resources/tree/master/BCM" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/resources/tree/master/BCM</a></li><li>An application of multinomial processing tree models and Bayesian methods to understanding memory impairment: <a href="https://drive.google.com/file/d/1NHml_YUsnpbUaqFhu0h8EiLeJCx6q403/view" rel="noopener noreferrer" target="_blank">https://drive.google.com/file/d/1NHml_YUsnpbUaqFhu0h8EiLeJCx6q403/view</a></li><li>Understanding the Complexity of Simple...]]></description><content:encoded><![CDATA[<p>I don’t know if you noticed, but I have a fondness for any topic related to decision-making under uncertainty — when it’s studied scientifically of course. Understanding how and why people make decisions when they don’t have all the facts is fascinating to me. That’s why I like electoral forecasting and I love cognitive sciences.</p><p>So, for the first episode of 2021, I have a special treat: I had the great pleasure of hosting Michael Lee on the podcast! Yes, the Michael Lee who co-authored the book Bayesian Cognitive Modeling with Eric-Jan Wagenmakers in 2013 — by the way, the book was ported to PyMC3, I put the link in the show notes ;)</p><p>This book was inspired from Michael’s work as a professor of cognitive sciences at University of California, Irvine. He works a lot on representation, memory, learning, and decision making, with a special focus on individual differences and collective cognition.</p><p>Using naturally occurring behavioral data, he builds probabilistic generative models to try and answer hard real-world questions: how does memory impairment work (that’s modeled with multinomial processing trees)? How complex are simple decisions, and how do people change strategies?</p><p>Echoing episode 18 with Daniel Lakens, Michael and I also talked about the reproducibility crisis: how are cognitive sciences doing, which progress was made, and what is still to do?</p><p>Living now in California, Michael is originally from Australia, where he did his Bachelors of Psychology and Mathematics, and his PhD in psychology. But Michael is also found of the city of Amsterdam, which he sees as “the perfect antidote to southern California with old buildings, public transport, great bread and beer, and crappy weather”.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho, Colin Carroll and Nathaniel Burbank.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Michael's website: <a href="https://faculty.sites.uci.edu/mdlee/" rel="noopener noreferrer" target="_blank">https://faculty.sites.uci.edu/mdlee/</a></li><li>Michael on GitHub: <a href="https://twitter.com/mdlBayes" rel="noopener noreferrer" target="_blank">https://twitter.com/mdlBayes</a></li><li><em>Bayesian Cognitive Modeling</em> book: <a href="https://faculty.sites.uci.edu/mdlee/bgm/" rel="noopener noreferrer" target="_blank">https://faculty.sites.uci.edu/mdlee/bgm/</a></li><li><em>Bayesian Cognitive Modeling</em> in PyMC3: <a href="https://github.com/pymc-devs/resources/tree/master/BCM" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/resources/tree/master/BCM</a></li><li>An application of multinomial processing tree models and Bayesian methods to understanding memory impairment: <a href="https://drive.google.com/file/d/1NHml_YUsnpbUaqFhu0h8EiLeJCx6q403/view" rel="noopener noreferrer" target="_blank">https://drive.google.com/file/d/1NHml_YUsnpbUaqFhu0h8EiLeJCx6q403/view</a></li><li>Understanding the Complexity of Simple Decisions -- Modeling Multiple Behaviors and Switching Strategies: <a href="https://webfiles.uci.edu/mdlee/LeeGluckWalsh2018.pdf" rel="noopener noreferrer" target="_blank">https://webfiles.uci.edu/mdlee/LeeGluckWalsh2018.pdf</a></li><li>Robust Modeling in Cognitive Science: <a href="https://link.springer.com/article/10.1007/s42113-019-00029-y" rel="noopener noreferrer" target="_blank">https://link.springer.com/article/10.1007/s42113-019-00029-y</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/31-bayesian-cognitive-modeling-michael-lee]]></link><guid isPermaLink="false">9b677b26-fda7-4dd1-9ec8-5e2120b011b7</guid><itunes:image href="https://artwork.captivate.fm/e0d5cbc1-84af-4de5-8591-d0597efe0cef/qeAinZzQKaJ01TVAz2w1qIVU.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 05 Jan 2021 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/faa7795f-044c-4202-9e67-f4db409d28ee/ep-31.mp3" length="166355068" type="audio/mpeg"/><itunes:duration>01:09:19</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>31</itunes:episode><itunes:season>1</itunes:season><podcast:episode>31</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#30 Symbolic Computation &amp; Dynamic Linear Models, with Brandon Willard</title><itunes:title>Symbolic Computation &amp; Dynamic Linear Models, with Brandon Willard</itunes:title><description><![CDATA[<p>It’s funny how powerful symbols are, right? The Eiffel Tower makes you think of Paris, the Statue of Liberty is New-York, and the Trevi Fountain… is Rome of course! Just with one symbol, you can invoke multiple concepts and ideas.</p><p>You probably know that symbols are omnipresent in mathematics — but did you know that they are also very important in statistics, especially probabilistic programming?</p><p>Rest assured, I didn’t really know either… until I talked with Brandon Willard! Brandon is indeed a big proponent of relational programming and symbolic computation, and he often promotes their use in research and industry. Actually, a few weeks after our recording, Brandon started spearheading the revival of Theano through the JAX backend that we’re currently working on for the future version of PyMC3!</p><p>As you guessed it, Brandon is a core developer of PyMC, and also a contributor to Airflow and IPython, just to name a few. His interests revolve around the means and methods of mathematical modeling and its automation. In a nutshell, he’s a Bayesian statistician: he likes to use the language and logic of probability to quantify uncertainty and frame problems.</p><p>After a Bachelor’s in physics and mathematics, Brandon got a Master’s degree in statistics from the University of Chicago. He’s worked in different areas in his career – from finance, transportation and energy to start-ups, gov-tech and academia. Brandon particularly loves projects where popular statistical libraries are inadequate, where sophisticated models must be combined in non-trivial ways, or when you have to deal with high-dimensional and discrete processes.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho and Colin Carroll.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Brandon's website: <a href="https://brandonwillard.github.io/" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/</a></li><li>Brandon on GitHub: <a href="https://github.com/brandonwillard" rel="noopener noreferrer" target="_blank">https://github.com/brandonwillard</a></li><li>The Future of PyMC3, or "Theano is Dead, Long Live Theano": <a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b" rel="noopener noreferrer" target="_blank">https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b</a></li><li>New Theano-PyMC library: <a href="https://github.com/pymc-devs/Theano-PyMC" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/Theano-PyMC</a></li><li>Symbolic PyMC: <a href="https://pymc-devs.github.io/symbolic-pymc/" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/symbolic-pymc/</a></li><li>A Role for Symbolic Computation in the General Estimation of Statistical Models: <a href="https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html"...]]></description><content:encoded><![CDATA[<p>It’s funny how powerful symbols are, right? The Eiffel Tower makes you think of Paris, the Statue of Liberty is New-York, and the Trevi Fountain… is Rome of course! Just with one symbol, you can invoke multiple concepts and ideas.</p><p>You probably know that symbols are omnipresent in mathematics — but did you know that they are also very important in statistics, especially probabilistic programming?</p><p>Rest assured, I didn’t really know either… until I talked with Brandon Willard! Brandon is indeed a big proponent of relational programming and symbolic computation, and he often promotes their use in research and industry. Actually, a few weeks after our recording, Brandon started spearheading the revival of Theano through the JAX backend that we’re currently working on for the future version of PyMC3!</p><p>As you guessed it, Brandon is a core developer of PyMC, and also a contributor to Airflow and IPython, just to name a few. His interests revolve around the means and methods of mathematical modeling and its automation. In a nutshell, he’s a Bayesian statistician: he likes to use the language and logic of probability to quantify uncertainty and frame problems.</p><p>After a Bachelor’s in physics and mathematics, Brandon got a Master’s degree in statistics from the University of Chicago. He’s worked in different areas in his career – from finance, transportation and energy to start-ups, gov-tech and academia. Brandon particularly loves projects where popular statistical libraries are inadequate, where sophisticated models must be combined in non-trivial ways, or when you have to deal with high-dimensional and discrete processes.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho and Colin Carroll.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Brandon's website: <a href="https://brandonwillard.github.io/" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/</a></li><li>Brandon on GitHub: <a href="https://github.com/brandonwillard" rel="noopener noreferrer" target="_blank">https://github.com/brandonwillard</a></li><li>The Future of PyMC3, or "Theano is Dead, Long Live Theano": <a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b" rel="noopener noreferrer" target="_blank">https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b</a></li><li>New Theano-PyMC library: <a href="https://github.com/pymc-devs/Theano-PyMC" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/Theano-PyMC</a></li><li>Symbolic PyMC: <a href="https://pymc-devs.github.io/symbolic-pymc/" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/symbolic-pymc/</a></li><li>A Role for Symbolic Computation in the General Estimation of Statistical Models: <a href="https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html</a></li><li>Symbolic Math in PyMC3: <a href="https://brandonwillard.github.io/symbolic-math-in-pymc3.html" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/symbolic-math-in-pymc3.html</a></li><li>Dynamic Linear Models in Theano: <a href="https://brandonwillard.github.io/dynamic-linear-models-in-theano.html" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/dynamic-linear-models-in-theano.html</a></li><li>Symbolic PyMC Radon Example in PyMC4: <a href="https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html" rel="noopener noreferrer" target="_blank">https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html</a></li><li>&nbsp;What I Wish Someone Had Told Me About Tensor Computation Libraries: <a href="https://eigenfoo.xyz/tensor-computation-libraries/" rel="noopener noreferrer" target="_blank">https://eigenfoo.xyz/tensor-computation-libraries/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/symbolic-computation-dynamic-linear-models-brandon-willard]]></link><guid isPermaLink="false">a675059c-6d93-4873-a02a-91a28f423687</guid><itunes:image href="https://artwork.captivate.fm/865de883-8666-4cbb-a3bb-f7dfcf75713f/uLToNZN6FVld3sJUMzHtVTn9.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 18 Dec 2020 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c832b42b-3c30-4482-b3a5-2b3ca25bc01c/ep-30-mixdown.mp3" length="144645294" type="audio/mpeg"/><itunes:duration>01:00:16</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>30</itunes:episode><itunes:season>1</itunes:season><podcast:episode>30</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#29 Model Assessment, Non-Parametric Models, And Much More, with Aki Vehtari</title><itunes:title>#29 Model Assessment, Non-Parametric Models, And Much More, with Aki Vehtari</itunes:title><description><![CDATA[<p>I’ll be honest here: I had a hard time summarizing this episode for you, and, let’s face it, it’s all my guest’s fault! Why? Because Aki Vehtari works on so many interesting projects that it’s hard to sum them all up, even more so because he was very generous with his time for this episode! But let’s try anyway, shall we?</p><p>So, Aki is an Associate professor in computational probabilistic modeling at Aalto University, Finland. You already heard his delightful Finnish accent on episode 20, with Andrew Gelman and Jennifer Hill, talking about their latest book, «&nbsp;Regression and other stories&nbsp;». He is also a co-author of the popular and awarded book «&nbsp;Bayesian Data Analysis&nbsp;», Third Edition, and a core-developer of the seminal probabilistic programming framework Stan.</p><p>An enthusiast of open-source software, Aki is a core-contributor to the ArviZ package and has been involved in many free software projects such as GPstuff for Gaussian processes and ELFI for likelihood inference.</p><p>His numerous research interests are Bayesian probability theory and methodology, especially model assessment and selection, non-parametric models (such as Gaussian processes), feature selection, dynamic models, and hierarchical models.</p><p>We talked about all that — and more — on this episode, in the context of his teaching at Aalto and the software-assisted Bayesian workflow he’s currently working on with a group of researchers.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho and Colin Carroll.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>New podcast website: <a href="https://www.learnbayesstats.com/" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/</a></li><li>Rate LBS on Podchaser: <a href="https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588" rel="noopener noreferrer" target="_blank">https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588</a></li><li>Aki's website: <a href="https://users.aalto.fi/~ave/" rel="noopener noreferrer" target="_blank">https://users.aalto.fi/~ave/</a></li><li>Aki's educational material: <a href="https://avehtari.github.io/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/</a></li><li>Aki on GitHub: <a href="https://github.com/avehtari" rel="noopener noreferrer" target="_blank">https://github.com/avehtari</a></li><li>Aki on Twitter: <a href="https://twitter.com/avehtari" rel="noopener noreferrer" target="_blank">https://twitter.com/avehtari</a></li><li>Bayesian Data Analysis, 3rd edition: <a href="https://www.routledge.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955</a></li><li>Bayesian Data Analysis course material: <a href="https://github.com/avehtari/BDA_course_Aalto" rel="noopener...]]></description><content:encoded><![CDATA[<p>I’ll be honest here: I had a hard time summarizing this episode for you, and, let’s face it, it’s all my guest’s fault! Why? Because Aki Vehtari works on so many interesting projects that it’s hard to sum them all up, even more so because he was very generous with his time for this episode! But let’s try anyway, shall we?</p><p>So, Aki is an Associate professor in computational probabilistic modeling at Aalto University, Finland. You already heard his delightful Finnish accent on episode 20, with Andrew Gelman and Jennifer Hill, talking about their latest book, «&nbsp;Regression and other stories&nbsp;». He is also a co-author of the popular and awarded book «&nbsp;Bayesian Data Analysis&nbsp;», Third Edition, and a core-developer of the seminal probabilistic programming framework Stan.</p><p>An enthusiast of open-source software, Aki is a core-contributor to the ArviZ package and has been involved in many free software projects such as GPstuff for Gaussian processes and ELFI for likelihood inference.</p><p>His numerous research interests are Bayesian probability theory and methodology, especially model assessment and selection, non-parametric models (such as Gaussian processes), feature selection, dynamic models, and hierarchical models.</p><p>We talked about all that — and more — on this episode, in the context of his teaching at Aalto and the software-assisted Bayesian workflow he’s currently working on with a group of researchers.</p><p><em>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at </em><a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank"><em>https://bababrinkman.com/</em></a><em> !</em></p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran, Paul Oreto, Colin Caprani, George Ho and Colin Carroll.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>New podcast website: <a href="https://www.learnbayesstats.com/" rel="noopener noreferrer" target="_blank">https://www.learnbayesstats.com/</a></li><li>Rate LBS on Podchaser: <a href="https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588" rel="noopener noreferrer" target="_blank">https://www.podchaser.com/podcasts/learning-bayesian-statistics-932588</a></li><li>Aki's website: <a href="https://users.aalto.fi/~ave/" rel="noopener noreferrer" target="_blank">https://users.aalto.fi/~ave/</a></li><li>Aki's educational material: <a href="https://avehtari.github.io/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/</a></li><li>Aki on GitHub: <a href="https://github.com/avehtari" rel="noopener noreferrer" target="_blank">https://github.com/avehtari</a></li><li>Aki on Twitter: <a href="https://twitter.com/avehtari" rel="noopener noreferrer" target="_blank">https://twitter.com/avehtari</a></li><li>Bayesian Data Analysis, 3rd edition: <a href="https://www.routledge.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Bayesian-Data-Analysis/Gelman-Carlin-Stern-Dunson-Vehtari-Rubin/p/book/9781439840955</a></li><li>Bayesian Data Analysis course material: <a href="https://github.com/avehtari/BDA_course_Aalto" rel="noopener noreferrer" target="_blank">https://github.com/avehtari/BDA_course_Aalto</a></li><li>Regression and Other Stories: <a href="https://avehtari.github.io/ROS-Examples/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/ROS-Examples/</a></li><li>Aki’s favorite scientific books (so far): <a href="https://statmodeling.stat.columbia.edu/2018/05/14/aki_books/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2018/05/14/aki_books/</a></li><li>Aki's talk on Agile Probabilistic Programming: <a href="https://www.youtube.com/watch?v=cHlPgHn6btg" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=cHlPgHn6btg</a></li><li>Aki's posts on Andrew Gelman's blog: <a href="https://statmodeling.stat.columbia.edu/author/aki/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/author/aki/</a></li><li>Stan software: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>GPstuff - Gaussian process models for Bayesian analysis: <a href="https://research.cs.aalto.fi/pml/software/gpstuff/" rel="noopener noreferrer" target="_blank">https://research.cs.aalto.fi/pml/software/gpstuff/</a></li><li>Projpred -- R package to perform projection predictive variable selection for GLMs: <a href="https://github.com/stan-dev/projpred" rel="noopener noreferrer" target="_blank">https://github.com/stan-dev/projpred</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/model-assessment-non-parametric-models-aki-vehtari]]></link><guid isPermaLink="false">7a3ff633-4a71-4af4-a5a6-2e578b48e9f4</guid><itunes:image href="https://artwork.captivate.fm/3b238976-1696-4a74-9986-1fe4edc56514/QcbVJcu-tjs2JVZ-z7qceA_s.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 02 Dec 2020 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/20e3e81d-d459-4f0b-ade6-56787897227b/ep-29-full.mp3" length="156162088" type="audio/mpeg"/><itunes:duration>01:05:04</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>29</itunes:episode><itunes:season>1</itunes:season><podcast:episode>29</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#28 Game Theory, Industrial Organization &amp; Policy Design, with Shosh Vasserman</title><itunes:title>#28 Game Theory, Industrial Organization &amp; Policy Design, with Shosh Vasserman</itunes:title><description><![CDATA[<p>In times of crisis, designing an efficient policy response is paramount. In case of natural disasters or pandemics, it can even determine the difference between life and death for a substantial number of people. But precisely, how do you design such policy responses, making sure that risks are optimally shared, people feel safe enough to reveal necessary information, and stakeholders commit to the policies?</p><p>That’s where a field of economics, industrial organization (IO), can help, as Shosh Vasserman will tell us in this episode. Shosh is an assistant professor of economics at the Stanford Graduate School of Business. Specialized in industrial organization, her interests span a number of policy settings, such as public procurement, pharmaceutical pricing and auto-insurance.</p><p>Her work leverages theory, empirics and modern computation (including the Stan software!) to better understand the equilibrium implications of policies and proposals involving information revelation, risk sharing and commitment.&nbsp;</p><p>In short, Shoshana uses theory and data to study how risk, commitment and information flows interplay with policy design. And she does a lot of this with… Bayesian models! Who said Bayes had no place in economics?</p><p>Prior to Stanford, Shoshana did her Bachelor’s in mathematics and economics at MIT, and then her PhD in economics at Harvard University.</p><p>This was a fascinating conversation where I learned a lot about Bayesian inference on large scale random utility logit models, socioeconomic network heterogeneity and pandemic policy response — and I’m sure you will too!</p><p>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Shosh's website: <a href="https://shoshanavasserman.com/" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/</a></li><li>Shosh on Twitter: <a href="https://twitter.com/shoshievass" rel="noopener noreferrer" target="_blank">https://twitter.com/shoshievass</a></li><li>How do different reopening strategies balance health <em>and</em> employment: <a href="https://reopenmappingproject.com/" rel="noopener noreferrer" target="_blank">https://reopenmappingproject.com/</a></li><li>Aggregate random coefficients logit—a generative approach: <a href="http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html" rel="noopener noreferrer" target="_blank">http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html</a></li><li>Voluntary Disclosure and Personalized Pricing: <a href="https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf</a></li><li>Socioeconomic Network Heterogeneity and Pandemic Policy Response: <a href="https://shoshanavasserman.com/files/2020/06/Network-Heterogeneity-Pandemic-Policy.pdf"...]]></description><content:encoded><![CDATA[<p>In times of crisis, designing an efficient policy response is paramount. In case of natural disasters or pandemics, it can even determine the difference between life and death for a substantial number of people. But precisely, how do you design such policy responses, making sure that risks are optimally shared, people feel safe enough to reveal necessary information, and stakeholders commit to the policies?</p><p>That’s where a field of economics, industrial organization (IO), can help, as Shosh Vasserman will tell us in this episode. Shosh is an assistant professor of economics at the Stanford Graduate School of Business. Specialized in industrial organization, her interests span a number of policy settings, such as public procurement, pharmaceutical pricing and auto-insurance.</p><p>Her work leverages theory, empirics and modern computation (including the Stan software!) to better understand the equilibrium implications of policies and proposals involving information revelation, risk sharing and commitment.&nbsp;</p><p>In short, Shoshana uses theory and data to study how risk, commitment and information flows interplay with policy design. And she does a lot of this with… Bayesian models! Who said Bayes had no place in economics?</p><p>Prior to Stanford, Shoshana did her Bachelor’s in mathematics and economics at MIT, and then her PhD in economics at Harvard University.</p><p>This was a fascinating conversation where I learned a lot about Bayesian inference on large scale random utility logit models, socioeconomic network heterogeneity and pandemic policy response — and I’m sure you will too!</p><p>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p><p>Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p><strong>Links from the show:</strong></p><ul><li>Shosh's website: <a href="https://shoshanavasserman.com/" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/</a></li><li>Shosh on Twitter: <a href="https://twitter.com/shoshievass" rel="noopener noreferrer" target="_blank">https://twitter.com/shoshievass</a></li><li>How do different reopening strategies balance health <em>and</em> employment: <a href="https://reopenmappingproject.com/" rel="noopener noreferrer" target="_blank">https://reopenmappingproject.com/</a></li><li>Aggregate random coefficients logit—a generative approach: <a href="http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html" rel="noopener noreferrer" target="_blank">http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html</a></li><li>Voluntary Disclosure and Personalized Pricing: <a href="https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf</a></li><li>Socioeconomic Network Heterogeneity and Pandemic Policy Response: <a href="https://shoshanavasserman.com/files/2020/06/Network-Heterogeneity-Pandemic-Policy.pdf" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/files/2020/06/Network-Heterogeneity-Pandemic-Policy.pdf</a></li><li>Buying Data from Consumers -- The Impact of Monitoring Programs in U.S. Auto Insurance: <a href="https://shoshanavasserman.com/files/2020/05/jinvass_0420.pdf" rel="noopener noreferrer" target="_blank">https://shoshanavasserman.com/files/2020/05/jinvass_0420.pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/28-game-theory-industrial-organization-policy-design-with-shosh-vasserman]]></link><guid isPermaLink="false">834483d1-b50b-4570-93eb-678a177e5670</guid><itunes:image href="https://artwork.captivate.fm/7d09b84d-5deb-4299-b3cc-04c26b924be4/kNeRKddY96yvo10tzGycYVd3.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 20 Nov 2020 10:50:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/eda16ec3-baed-47ad-871f-244de2581737/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-10.mp3" length="153480042" type="audio/mpeg"/><itunes:duration>01:03:57</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>28</itunes:episode><itunes:season>1</itunes:season><podcast:episode>28</podcast:episode><podcast:season>1</podcast:season><itunes:summary>In times of crisis, designing an efficient policy response is paramount. In case of natural disasters or pandemics, it can even determine the difference between life and death for a substantial number of people. But precisely, how do you design such policy responses, making sure that risks are optimally shared, people feel safe enough to reveal necessary information, and stakeholders commit to the policies?

That’s where a field of economics, industrial organization (IO), can help, as Shosh Vasserman will tell us in this episode. Shosh is an assistant professor of economics at the Stanford Graduate School of Business. Specialized in industrial organization, her interests span a number of policy settings, such as public procurement, pharmaceutical pricing and auto-insurance.

Her work leverages theory, empirics and modern computation (including the Stan software!) to better understand the equilibrium implications of policies and proposals involving information revelation, risk sharing and commitment. 

In short, Shoshana uses theory and data to study how risk, commitment and information flows interplay with policy design. And she does a lot of this with… Bayesian models! Who said Bayes had no place in economics?

Prior to Stanford, Shoshana did her Bachelor’s in mathematics and economics at MIT, and then her PhD in economics at Harvard University.

This was a fascinating conversation where I learned a lot about Bayesian inference on large scale random utility logit models, socioeconomic network heterogeneity and pandemic policy response — and I’m sure you will too!

Thank you to my Patrons for making this episode possible! Visit https://www.patreon.com/learnbayesstats (https://www.patreon.com/learnbayesstats) to unlock exclusive Bayesian swag ;)

Our  theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and  Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Shosh&apos;s website: https://shoshanavasserman.com/ (https://shoshanavasserman.com/)

 Shosh on Twitter: https://twitter.com/shoshievass (https://twitter.com/shoshievass)

  How do different reopening strategies balance health and employment: https://reopenmappingproject.com/ (https://reopenmappingproject.com/)

  Aggregate random coefficients logit—a generative approach: http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html (http://modernstatisticalworkflow.blogspot.com/2017/03/aggregate-random-coefficients-logita.html)

  Voluntary Disclosure and Personalized Pricing: https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf (https://shoshanavasserman.com/files/2020/08/Voluntary-Disclosure-and-Personalized-Pricing.pdf)

  Socioeconomic Network Heterogeneity and Pandemic Policy Response: https://shoshanavasserman.com/files/2020/06/Network-Heterogeneity-Pandemic-Policy.pdf (https://shoshanavasserman.com/files/2020/06/Network-Heterogeneity-Pandemic-Policy.pdf)

  Buying Data from Consumers -- The Impact of Monitoring Programs in U.S. Auto Insurance: https://shoshanavasserman.com/files/2020/05/jinvass_0420.pdf (https://shoshanavasserman.com/files/2020/05/jinvass_0420.pdf)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#27 Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns</title><itunes:title>#27 Modeling the US Presidential Elections, with Andrew Gelman &amp; Merlin Heidemanns</itunes:title><description><![CDATA[<p>In a few days, a consequential election will take place, as citizens of the United States will go to the polls and elect their president — in fact they already started voting. You probably know a few forecasting models that try to predict what will happen on Election Day — who will get elected, by how much and with which coalition of States?</p><p>But how do these statistical models work? How do you account for the different sources of uncertainty, be it polling errors, unexpected turnout or media events? How do you model covariation between States? How do you even communicate the model’s results and afterwards assess its performance? To talk about all this, I had the pleasure to talk to Andrew Gelman and Merlin Heidemanns.</p><p>Andrew was already on episode 20, to talk about his recent book with Jennifer Hill and Aki Vehtari, “Regression and Other Stories”. He’s a professor of statistics and political science at Columbia University and works on a lot of topics, including: why campaign polls are so variable while elections are so predictable, the statistical challenges of estimating small effects, and methods for surveys and experimental design.</p><p>Merlin is a PhD student in Political Science at Columbia University, and he specializes in political methodology. Prior to his PhD, he did a Bachelor's in Political Science at the Freie Universität Berlin.</p><p>I hope you’ll enjoy this episode where we dove into the Bayesian model they helped develop for <em>The Economist</em>, and talked more generally about how to forecast elections with statistical methods, and even about the incentives the forecasting industry has as a whole.</p><p>Thank you to my Patrons for making this episode possible! Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Andrew's website: <a href="http://www.stat.columbia.edu/~gelman/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/</a></li><li>Andrew's blog: <a href="https://statmodeling.stat.columbia.edu/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/</a></li><li>Andrew on Twitter: <a href="https://twitter.com/statmodeling" rel="noopener noreferrer" target="_blank">https://twitter.com/statmodeling</a></li><li>Merlin's website: <a href="https://merlinheidemanns.github.io/website/" rel="noopener noreferrer" target="_blank">https://merlinheidemanns.github.io/website/</a></li><li>Merlin on Twitter: <a href="https://twitter.com/MHeidemanns" rel="noopener noreferrer" target="_blank">https://twitter.com/MHeidemanns</a></li><li>The Economist POTUS forecast: <a href="https://projects.economist.com/us-2020-forecast/president" rel="noopener noreferrer" target="_blank">https://projects.economist.com/us-2020-forecast/president</a></li><li>How The Economist presidential forecast works: <a href="https://projects.economist.com/us-2020-forecast/president/how-this-works" rel="noopener noreferrer" target="_blank">https://projects.economist.com/us-2020-forecast/president/how-this-works</a></li><li>GitHub repo of the Economist model: <a href="https://github.com/TheEconomist/us-potus-model" rel="noopener noreferrer" target="_blank">https://github.com/TheEconomist/us-potus-model</a></li><li>Information, incentives, and goals in election forecasts (Gelman,&nbsp;Hullman &amp; Wlezien): <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf</a></li><li>How to think about extremely...]]></description><content:encoded><![CDATA[<p>In a few days, a consequential election will take place, as citizens of the United States will go to the polls and elect their president — in fact they already started voting. You probably know a few forecasting models that try to predict what will happen on Election Day — who will get elected, by how much and with which coalition of States?</p><p>But how do these statistical models work? How do you account for the different sources of uncertainty, be it polling errors, unexpected turnout or media events? How do you model covariation between States? How do you even communicate the model’s results and afterwards assess its performance? To talk about all this, I had the pleasure to talk to Andrew Gelman and Merlin Heidemanns.</p><p>Andrew was already on episode 20, to talk about his recent book with Jennifer Hill and Aki Vehtari, “Regression and Other Stories”. He’s a professor of statistics and political science at Columbia University and works on a lot of topics, including: why campaign polls are so variable while elections are so predictable, the statistical challenges of estimating small effects, and methods for surveys and experimental design.</p><p>Merlin is a PhD student in Political Science at Columbia University, and he specializes in political methodology. Prior to his PhD, he did a Bachelor's in Political Science at the Freie Universität Berlin.</p><p>I hope you’ll enjoy this episode where we dove into the Bayesian model they helped develop for <em>The Economist</em>, and talked more generally about how to forecast elections with statistical methods, and even about the incentives the forecasting industry has as a whole.</p><p>Thank you to my Patrons for making this episode possible! Visit <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a> to unlock exclusive Bayesian swag ;)</p><p>Our&nbsp;theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and&nbsp;Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Andrew's website: <a href="http://www.stat.columbia.edu/~gelman/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/</a></li><li>Andrew's blog: <a href="https://statmodeling.stat.columbia.edu/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/</a></li><li>Andrew on Twitter: <a href="https://twitter.com/statmodeling" rel="noopener noreferrer" target="_blank">https://twitter.com/statmodeling</a></li><li>Merlin's website: <a href="https://merlinheidemanns.github.io/website/" rel="noopener noreferrer" target="_blank">https://merlinheidemanns.github.io/website/</a></li><li>Merlin on Twitter: <a href="https://twitter.com/MHeidemanns" rel="noopener noreferrer" target="_blank">https://twitter.com/MHeidemanns</a></li><li>The Economist POTUS forecast: <a href="https://projects.economist.com/us-2020-forecast/president" rel="noopener noreferrer" target="_blank">https://projects.economist.com/us-2020-forecast/president</a></li><li>How The Economist presidential forecast works: <a href="https://projects.economist.com/us-2020-forecast/president/how-this-works" rel="noopener noreferrer" target="_blank">https://projects.economist.com/us-2020-forecast/president/how-this-works</a></li><li>GitHub repo of the Economist model: <a href="https://github.com/TheEconomist/us-potus-model" rel="noopener noreferrer" target="_blank">https://github.com/TheEconomist/us-potus-model</a></li><li>Information, incentives, and goals in election forecasts (Gelman,&nbsp;Hullman &amp; Wlezien): <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf</a></li><li>How to think about extremely unlikely events: <a href="https://bit.ly/3ejZYyZ" rel="noopener noreferrer" target="_blank">https://bit.ly/3ejZYyZ</a></li><li>Postal voting could put America’s Democrats at a disadvantage: <a href="https://econ.st/3mCxR0P" rel="noopener noreferrer" target="_blank">https://econ.st/3mCxR0P</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/27-modeling-the-us-presidential-elections-with-andrew-gelman-merlin-heidemanns]]></link><guid isPermaLink="false">d8eb519a-ba83-4b2c-bd87-68a9b4b9d4f7</guid><itunes:image href="https://artwork.captivate.fm/8a9f1e64-778d-475c-b755-ae5e1833df67/IciawekfEAiiiowZOQAoA8XA.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sun, 01 Nov 2020 16:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/639128dc-644c-4ff3-b95a-078f81a36d64/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-9-.mp3" length="146103901" type="audio/mpeg"/><itunes:duration>01:00:53</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>27</itunes:episode><itunes:season>1</itunes:season><podcast:episode>27</podcast:episode><podcast:season>1</podcast:season><itunes:summary>In a few days, a consequential election will take place, as citizens of the United States will go to the polls and elect their president — in fact they already started voting. You probably know a few forecasting models that try to predict what will happen on Election Day — who will get elected, by how much and with which coalition of States?

But how do these statistical models work? How do you account for the different sources of uncertainty, be it polling errors, unexpected turnout or media events? How do you model covariation between States? How do you even communicate the model’s results and afterwards assess its performance? To talk about all this, I had the pleasure to talk to Andrew Gelman and Merlin Heidemanns.

Andrew was already on episode 20, to talk about his recent book with Jennifer Hill and Aki Vehtari, “Regression and Other Stories”. He’s a professor of statistics and political science at Columbia University and works on a lot of topics, including: why campaign polls are so variable while elections are so predictable, the statistical challenges of estimating small effects, and methods for surveys and experimental design.

Merlin is a PhD student in Political Science at Columbia University, and he specializes in political methodology. Prior to his PhD, he did a Bachelor&apos;s in Political Science at the Freie Universität Berlin.

I hope you’ll enjoy this episode where we dove into the Bayesian model they helped develop for The Economist, and talked more generally about how to forecast elections with statistical methods, and even about the incentives the forecasting industry has as a whole.

Thank you to my Patrons for making this episode possible! Visit https://www.patreon.com/learnbayesstats (https://www.patreon.com/learnbayesstats) to unlock exclusive Bayesian swag ;)

Our  theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and  Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Andrew&apos;s website: http://www.stat.columbia.edu/~gelman/ (http://www.stat.columbia.edu/~gelman/)

 Andrew&apos;s blog: https://statmodeling.stat.columbia.edu/ (https://statmodeling.stat.columbia.edu/)

  Andrew on Twitter: https://twitter.com/statmodeling (https://twitter.com/statmodeling)

  Merlin&apos;s website: https://merlinheidemanns.github.io/website/ (https://merlinheidemanns.github.io/website/)

  Merlin on Twitter: https://twitter.com/MHeidemanns (https://twitter.com/MHeidemanns)

  The Economist POTUS forecast: https://projects.economist.com/us-2020-forecast/president (https://projects.economist.com/us-2020-forecast/president)

  How The Economist presidential forecast works: https://projects.economist.com/us-2020-forecast/president/how-this-works (https://projects.economist.com/us-2020-forecast/president/how-this-works)

  GitHub repo of the Economist model: https://github.com/TheEconomist/us-potus-model (https://github.com/TheEconomist/us-potus-model)

  Information, incentives, and goals in election forecasts (Gelman,  Hullman and Wlezien): http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf (http://www.stat.columbia.edu/~gelman/research/unpublished/forecast_incentives3.pdf)

  How to think about extremely unlikely events: https://bit.ly/3ejZYyZ (https://bit.ly/3ejZYyZ)

  Postal voting could put America’s Democrats at a disadvantage: https://econ.st/3mCxR0P (https://econ.st/3mCxR0P)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#26 What you’ll learn &amp; who you’ll meet at the PyMC Conference, with Ravin Kumar &amp; Quan Nguyen</title><itunes:title>#26 What you&apos;ll learn &amp; who you&apos;ll meet at the PyMC Conference, with Ravin Kumar &amp; Quan Nguyen</itunes:title><description><![CDATA[<p>I don’t know about you, but I’m starting to really miss traveling and just talking to people without having to think about masks, social distance and activating the covid tracking app on my phone. In the coming days, there is one event that, granted, won’t make all of that disappear, but will remind me how enriching it is to meet new people — this event is PyMCon, the first-ever conference about the PyMC ecosystem! To talk about the conference format, goals and program, I had the pleasure to host Ravin Kumar and Quan Nguyen on the show.</p><p>Quan is a PhD student in computer science at Washington University in St Louis, USA, researching Bayesian machine learning and one of the PyMCon program committee chairs. He is also the author of several programming books on Python and scientific computing.</p><p>Ravin is a core contributor to Arviz and PyMC, and is leading the PyMCon conference. He holds a Bachelors in Mechanical Engineering and a Masters in Manufacturing Engineering. As a Principal Data Scientist he has used Bayesian Statistics to characterize and aid decision making at organizations like SpaceX and Sweetgreen. Ravin is also currently co-authoring a book with Ari Hartikainen, Osvaldo Martin, and Junpeng Lao on Bayesian Statistics due for release in February.</p><p>We talked about why they became involved in the conference, parsed through the numerous, amazing talks that are planned, and detailed who the keynote speakers will be… So, If you’re interested the link to register is in the show notes, and there are even two ways to get a free ticket: either by applying to a diversity scholarship, or by being a community partner, which is anyone or any organization working towards diversity and inclusion in tech — all links are in the show notes.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>PyMCon speakers: <a href="https://pymc-devs.github.io/pymcon/speakers" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/pymcon/speakers</a></li><li>Register to PyMCon: <a href="https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829" rel="noopener noreferrer" target="_blank">https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829</a></li><li>PyMCon Diversity Scholarship: <a href="https://bit.ly/2J3Vb9d" rel="noopener noreferrer" target="_blank">https://bit.ly/2J3Vb9d</a></li><li>PyMCon Community Partner Form: <a href="https://bit.ly/35yq90L" rel="noopener noreferrer" target="_blank">https://bit.ly/35yq90L</a></li><li>PyMC3 -- Probabilistic Programming in Python: <a href="https://docs.pymc.io" rel="noopener noreferrer" target="_blank">https://docs.pymc.io</a></li><li>Donate to PyMC3: <a href="https://numfocus.org/donate-to-pymc3" rel="noopener noreferrer" target="_blank">https://numfocus.org/donate-to-pymc3</a></li><li>PyMC3 for enterprise: <a href="https://bit.ly/3jo9jq9" rel="noopener noreferrer" target="_blank">https://bit.ly/3jo9jq9</a></li><li>Ravin on Twitter: <a href="https://twitter.com/canyon289" rel="noopener noreferrer" target="_blank">https://twitter.com/canyon289</a></li><li>Quan on the web: <a href="https://krisnguyen135.github.io/" rel="noopener noreferrer" target="_blank">https://krisnguyen135.github.io/</a></li><li>Quan's author page: <a href="https://amzn.to/37JsB7r" rel="noopener noreferrer" target="_blank">https://amzn.to/37JsB7r</a></li><li>Alex talks about polls on the "Local Maximum" podcast: <a href="https://bit.ly/3e1Ro7O" rel="noopener noreferrer" target="_blank">https://bit.ly/3e1Ro7O</a></li><li>Support "Learning Bayesian Statistics" on Patreon: <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a></li></ul><br/><p><strong>Thank you to my Patrons for making...]]></description><content:encoded><![CDATA[<p>I don’t know about you, but I’m starting to really miss traveling and just talking to people without having to think about masks, social distance and activating the covid tracking app on my phone. In the coming days, there is one event that, granted, won’t make all of that disappear, but will remind me how enriching it is to meet new people — this event is PyMCon, the first-ever conference about the PyMC ecosystem! To talk about the conference format, goals and program, I had the pleasure to host Ravin Kumar and Quan Nguyen on the show.</p><p>Quan is a PhD student in computer science at Washington University in St Louis, USA, researching Bayesian machine learning and one of the PyMCon program committee chairs. He is also the author of several programming books on Python and scientific computing.</p><p>Ravin is a core contributor to Arviz and PyMC, and is leading the PyMCon conference. He holds a Bachelors in Mechanical Engineering and a Masters in Manufacturing Engineering. As a Principal Data Scientist he has used Bayesian Statistics to characterize and aid decision making at organizations like SpaceX and Sweetgreen. Ravin is also currently co-authoring a book with Ari Hartikainen, Osvaldo Martin, and Junpeng Lao on Bayesian Statistics due for release in February.</p><p>We talked about why they became involved in the conference, parsed through the numerous, amazing talks that are planned, and detailed who the keynote speakers will be… So, If you’re interested the link to register is in the show notes, and there are even two ways to get a free ticket: either by applying to a diversity scholarship, or by being a community partner, which is anyone or any organization working towards diversity and inclusion in tech — all links are in the show notes.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>PyMCon speakers: <a href="https://pymc-devs.github.io/pymcon/speakers" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/pymcon/speakers</a></li><li>Register to PyMCon: <a href="https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829" rel="noopener noreferrer" target="_blank">https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829</a></li><li>PyMCon Diversity Scholarship: <a href="https://bit.ly/2J3Vb9d" rel="noopener noreferrer" target="_blank">https://bit.ly/2J3Vb9d</a></li><li>PyMCon Community Partner Form: <a href="https://bit.ly/35yq90L" rel="noopener noreferrer" target="_blank">https://bit.ly/35yq90L</a></li><li>PyMC3 -- Probabilistic Programming in Python: <a href="https://docs.pymc.io" rel="noopener noreferrer" target="_blank">https://docs.pymc.io</a></li><li>Donate to PyMC3: <a href="https://numfocus.org/donate-to-pymc3" rel="noopener noreferrer" target="_blank">https://numfocus.org/donate-to-pymc3</a></li><li>PyMC3 for enterprise: <a href="https://bit.ly/3jo9jq9" rel="noopener noreferrer" target="_blank">https://bit.ly/3jo9jq9</a></li><li>Ravin on Twitter: <a href="https://twitter.com/canyon289" rel="noopener noreferrer" target="_blank">https://twitter.com/canyon289</a></li><li>Quan on the web: <a href="https://krisnguyen135.github.io/" rel="noopener noreferrer" target="_blank">https://krisnguyen135.github.io/</a></li><li>Quan's author page: <a href="https://amzn.to/37JsB7r" rel="noopener noreferrer" target="_blank">https://amzn.to/37JsB7r</a></li><li>Alex talks about polls on the "Local Maximum" podcast: <a href="https://bit.ly/3e1Ro7O" rel="noopener noreferrer" target="_blank">https://bit.ly/3e1Ro7O</a></li><li>Support "Learning Bayesian Statistics" on Patreon: <a href="https://www.patreon.com/learnbayesstats" rel="noopener noreferrer" target="_blank">https://www.patreon.com/learnbayesstats</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/26-what-youll-learn-who-youll-meet-at-the-pymc-conference-with-ravin-kumar-quan-nguyen]]></link><guid isPermaLink="false">afff6fe9-8011-42b3-b9a5-69012d2dc931</guid><itunes:image href="https://artwork.captivate.fm/7d942576-d94c-4645-8825-0d3f3ee6c7d5/5lrrEmDZtXBOHmUXaqRAhyYq.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Sat, 24 Oct 2020 17:49:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5ced4a89-e256-431b-9c1e-bf2164669c95/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-9-.mp3" length="111436805" type="audio/mpeg"/><itunes:duration>46:25</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>26</itunes:episode><itunes:season>1</itunes:season><podcast:episode>26</podcast:episode><podcast:season>1</podcast:season><itunes:summary>I don’t know about you, but I’m starting to really miss traveling and just talking to people without having to think about masks, social distance and activating the covid tracking app on my phone. In the coming days, there is one event that, granted, won’t make all of that disappear, but will remind me how enriching it is to meet new people — this event is PyMCon, the first-ever conference about the PyMC ecosystem! To talk about the conference format, goals and program, I had the pleasure to host Ravin Kumar and Quan Nguyen on the show.

Quan is a PhD student in computer science at Washington University in St Louis, USA, researching Bayesian machine learning and one of the PyMCon program committee chairs. He is also the author of several programming books on Python and scientific computing.

Ravin is a core contributor to Arviz and PyMC, and is leading the PyMCon conference. He holds a Bachelors in Mechanical Engineering and a Masters in Manufacturing Engineering. As a Principal Data Scientist he has used Bayesian Statistics to characterize and aid decision making at organizations like SpaceX and Sweetgreen. Ravin is also currently co-authoring a book with Ari Hartikainen, Osvaldo Martin, and Junpeng Lao on Bayesian Statistics due for release in February.

We talked about why they became involved in the conference, parsed through the numerous, amazing talks that are planned, and detailed who the keynote speakers will be… So, If you’re interested the link to register is in the show notes, and there are even two ways to get a free ticket: either by applying to a diversity scholarship, or by being a community partner, which is anyone or any organization working towards diversity and inclusion in tech — all links are in the show notes.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 PyMCon speakers: https://pymc-devs.github.io/pymcon/speakers (https://pymc-devs.github.io/pymcon/speakers)

 Register to PyMCon: https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829 (https://www.eventbrite.com/e/pymcon-2020-tickets-121404065829)

  PyMCon Diversity Scholarship: https://bit.ly/2J3Vb9d (https://bit.ly/2J3Vb9d)

  PyMCon Community Partner Form: https://bit.ly/35yq90L (https://bit.ly/35yq90L)

  PyMC3 -- Probabilistic Programming in Python: https://docs.pymc.io (https://docs.pymc.io)

  Donate to PyMC3: https://numfocus.org/donate-to-pymc3 (https://numfocus.org/donate-to-pymc3)

  PyMC3 for enterprise: https://bit.ly/3jo9jq9 (https://bit.ly/3jo9jq9)

  Ravin on Twitter: https://twitter.com/canyon289 (https://twitter.com/canyon289)

  Quan on the web: https://krisnguyen135.github.io/ (https://krisnguyen135.github.io/)

  Quan&apos;s author page: https://amzn.to/37JsB7r (https://amzn.to/37JsB7r)

  Alex talks about polls on the &quot;Local Maximum&quot; podcast: https://bit.ly/3e1Ro7O (https://bit.ly/3e1Ro7O)

  Support &quot;Learning Bayesian Statistics&quot; on Patreon: https://www.patreon.com/learnbayesstats (https://www.patreon.com/learnbayesstats)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#25 Bayesian Stats in Football Analytics, with Kevin Minkus</title><itunes:title>#25 Bayesian Stats in Football Analytics, with Kevin Minkus</itunes:title><description><![CDATA[<p>Have you watched the series «&nbsp;The English Game&nbsp;», on Netflix? Well, I think you should — it’s a fascinating dive into how football went from an aristocratic to a popular sport in the late 19th century England. Today it is so popular that it became a valuable business to do statistics on the game and its players!</p><p>To talk about that, I invited Kevin Minkus on the show — he’s a data scientist and soccer fan living in Philadelphia. Kevin’s currently working at Monetate on ecommerce problems, and prior to Monetate he worked on property and casualty insurance pricing.</p><p>He spends a lot of his spare time working on problems in football analytics and is a contributor at American Soccer Analysis, a website and podcast dedicated to… football made or played in the US (or “soccer”, as they say over there). Kevin is responsible for some of their data management and devops, and he recently wrote a guide to football analytics for the Major League Soccer’s website, entitled «&nbsp;Soccer Analytics 101&nbsp;».</p><p>To be honest, I had a great time talking for one hour about two of my passions — football and stats! Soooo, maybe 2020 isn’t that bad after all… Ow, and beyond football, Kevin is also into the digital humanities, web development, 3D animation, machine learning, and… the bassoon!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Kevin on Twitter: <a href="https://twitter.com/kevinminkus" rel="noopener noreferrer" target="_blank">https://twitter.com/kevinminkus</a></li><li>Kevin on GitHub: <a href="https://github.com/kcm30" rel="noopener noreferrer" target="_blank">https://github.com/kcm30</a></li><li>Soccer Analytics 101: <a href="https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101" rel="noopener noreferrer" target="_blank">https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101</a></li><li>American Soccer Analysis: <a href="https://www.americansocceranalysis.com/" rel="noopener noreferrer" target="_blank">https://www.americansocceranalysis.com/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></description><content:encoded><![CDATA[<p>Have you watched the series «&nbsp;The English Game&nbsp;», on Netflix? Well, I think you should — it’s a fascinating dive into how football went from an aristocratic to a popular sport in the late 19th century England. Today it is so popular that it became a valuable business to do statistics on the game and its players!</p><p>To talk about that, I invited Kevin Minkus on the show — he’s a data scientist and soccer fan living in Philadelphia. Kevin’s currently working at Monetate on ecommerce problems, and prior to Monetate he worked on property and casualty insurance pricing.</p><p>He spends a lot of his spare time working on problems in football analytics and is a contributor at American Soccer Analysis, a website and podcast dedicated to… football made or played in the US (or “soccer”, as they say over there). Kevin is responsible for some of their data management and devops, and he recently wrote a guide to football analytics for the Major League Soccer’s website, entitled «&nbsp;Soccer Analytics 101&nbsp;».</p><p>To be honest, I had a great time talking for one hour about two of my passions — football and stats! Soooo, maybe 2020 isn’t that bad after all… Ow, and beyond football, Kevin is also into the digital humanities, web development, 3D animation, machine learning, and… the bassoon!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Kevin on Twitter: <a href="https://twitter.com/kevinminkus" rel="noopener noreferrer" target="_blank">https://twitter.com/kevinminkus</a></li><li>Kevin on GitHub: <a href="https://github.com/kcm30" rel="noopener noreferrer" target="_blank">https://github.com/kcm30</a></li><li>Soccer Analytics 101: <a href="https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101" rel="noopener noreferrer" target="_blank">https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101</a></li><li>American Soccer Analysis: <a href="https://www.americansocceranalysis.com/" rel="noopener noreferrer" target="_blank">https://www.americansocceranalysis.com/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/25-bayesian-stats-in-football-analytics-with-kevin-minkus]]></link><guid isPermaLink="false">97105752-7e22-4566-8390-35a1fd38d058</guid><itunes:image href="https://artwork.captivate.fm/1db091a6-886f-418f-ba97-68efc3d23478/7elP-aPTN3oo2lTT6K7dD8ES.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 09 Oct 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b7298280-c9b2-4eac-9794-ec577407c7c2/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-9-.mp3" length="134344619" type="audio/mpeg"/><itunes:duration>55:59</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>25</itunes:episode><itunes:season>1</itunes:season><podcast:episode>25</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Have you watched the series « The English Game », on Netflix? Well, I think you should — it’s a fascinating dive into how football went from an aristocratic to a popular sport in the late 19th century England. Today it is so popular that it became a valuable business to do statistics on the game and its players!

To talk about that, I invited Kevin Minkus on the show — he’s a data scientist and soccer fan living in Philadelphia. Kevin’s currently working at Monetate on ecommerce problems, and prior to Monetate he worked on property and casualty insurance pricing.

He spends a lot of his spare time working on problems in football analytics and is a contributor at American Soccer Analysis, a website and podcast dedicated to… football made or played in the US (or “soccer”, as they say over there). Kevin is responsible for some of their data management and devops, and he recently wrote a guide to football analytics for the Major League Soccer’s website, entitled « Soccer Analytics 101 ».

To be honest, I had a great time talking for one hour about two of my passions — football and stats! Soooo, maybe 2020 isn’t that bad after all… Ow, and beyond football, Kevin is also into the digital humanities, web development, 3D animation, machine learning, and… the bassoon!

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Kevin on Twitter: https://twitter.com/kevinminkus (https://twitter.com/kevinminkus)

 Kevin on GitHub: https://github.com/kcm30 (https://github.com/kcm30)

  Soccer Analytics 101: https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101 (https://www.mlssoccer.com/soccer-analytics-guide/2020/soccer-analytics-101)

  American Soccer Analysis: https://www.americansocceranalysis.com/ (https://www.americansocceranalysis.com/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#24 Bayesian Computational Biology in Julia, with Seth Axen</title><itunes:title>#24 Bayesian Computational Biology in Julia, with Seth Axen</itunes:title><description><![CDATA[<p>Do you know what proteins are, what they do and why they are useful? Well, be prepared to be amazed! In this episode, Seth Axen will tell us about the fascinating world of protein structures and computational biology, and how his work of Bayesian modeler fits into that!</p><p>Passionate about mathematics and statistics, Seth is finishing a PhD in bioinformatics at the Sali Lab of the University of California, San Francisco (UCSF). His research interests span the broad field of computational biology: using computer science, mathematics, and statistics to understand biological systems. His current research focuses on inferring protein structural ensembles.&nbsp;</p><p>Open source development is also very dear to his heart, and indeed he contributes to many open source packages, especially in the Julia ecosystem. In particular, he develops and maintains ArviZ.jl, the Julia port of ArviZ, a platform-agnostic python package to visualize and diagnose your Bayesian models. Seth will tell us how he became involved in ArviZ.jl, what its strengths and weaknesses are, and how it fits into the Julia probabilistic programming landscape.</p><p>Ow, and as a bonus, you’ll discover why Seth is such a fan of automatic differentiation, aka «&nbsp;autodiff&nbsp;» — I actually wanted to edit this part out but Seth strongly insisted I kept it. Just kidding of course — or, am I… ?</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Seth website: <a href="http://sethaxen.com/" rel="noopener noreferrer" target="_blank">http://sethaxen.com/</a></li><li>Seth on Twitter: <a href="https://twitter.com/sethaxen" rel="noopener noreferrer" target="_blank">https://twitter.com/sethaxen</a></li><li>Seth on GitHub: <a href="https://github.com/sethaxen" rel="noopener noreferrer" target="_blank">https://github.com/sethaxen</a></li><li>ArviZ.jl -- Exploratory analysis of Bayesian models in Julia: <a href="https://arviz-devs.github.io/ArviZ.jl/dev/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/ArviZ.jl/dev/</a></li><li>PyCon2020 -- Colin Carroll -- Getting started with automatic differentiation: <a href="https://www.youtube.com/watch?v=NG21KWZSiok" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=NG21KWZSiok</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></description><content:encoded><![CDATA[<p>Do you know what proteins are, what they do and why they are useful? Well, be prepared to be amazed! In this episode, Seth Axen will tell us about the fascinating world of protein structures and computational biology, and how his work of Bayesian modeler fits into that!</p><p>Passionate about mathematics and statistics, Seth is finishing a PhD in bioinformatics at the Sali Lab of the University of California, San Francisco (UCSF). His research interests span the broad field of computational biology: using computer science, mathematics, and statistics to understand biological systems. His current research focuses on inferring protein structural ensembles.&nbsp;</p><p>Open source development is also very dear to his heart, and indeed he contributes to many open source packages, especially in the Julia ecosystem. In particular, he develops and maintains ArviZ.jl, the Julia port of ArviZ, a platform-agnostic python package to visualize and diagnose your Bayesian models. Seth will tell us how he became involved in ArviZ.jl, what its strengths and weaknesses are, and how it fits into the Julia probabilistic programming landscape.</p><p>Ow, and as a bonus, you’ll discover why Seth is such a fan of automatic differentiation, aka «&nbsp;autodiff&nbsp;» — I actually wanted to edit this part out but Seth strongly insisted I kept it. Just kidding of course — or, am I… ?</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Seth website: <a href="http://sethaxen.com/" rel="noopener noreferrer" target="_blank">http://sethaxen.com/</a></li><li>Seth on Twitter: <a href="https://twitter.com/sethaxen" rel="noopener noreferrer" target="_blank">https://twitter.com/sethaxen</a></li><li>Seth on GitHub: <a href="https://github.com/sethaxen" rel="noopener noreferrer" target="_blank">https://github.com/sethaxen</a></li><li>ArviZ.jl -- Exploratory analysis of Bayesian models in Julia: <a href="https://arviz-devs.github.io/ArviZ.jl/dev/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/ArviZ.jl/dev/</a></li><li>PyCon2020 -- Colin Carroll -- Getting started with automatic differentiation: <a href="https://www.youtube.com/watch?v=NG21KWZSiok" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=NG21KWZSiok</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/24-bayesian-computational-biology-in-julia-with-seth-axen]]></link><guid isPermaLink="false">1fc1f1ec-9d32-4e95-9846-6e560f1be0ea</guid><itunes:image href="https://artwork.captivate.fm/96157a34-c18f-4589-8277-a73e3aaa8442/nQrehq2B_zokRUVGN4ueW1q9.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 24 Sep 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6a4df131-09d5-4aa9-ac2c-d95ba9491f7e/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-8-.mp3" length="108481351" type="audio/mpeg"/><itunes:duration>56:30</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>24</itunes:episode><itunes:season>1</itunes:season><podcast:episode>24</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Do you know what proteins are, what they do and why they are useful? Well, be prepared to be amazed! In this episode, Seth Axen will tell us about the fascinating world of protein structures and computational biology, and how his work of Bayesian modeler fits into that!

Passionate about mathematics and statistics, Seth is finishing a PhD in bioinformatics at the Sali Lab of the University of California, San Francisco (UCSF). His research interests span the broad field of computational biology: using computer science, mathematics, and statistics to understand biological systems. His current research focuses on inferring protein structural ensembles. 

Open source development is also very dear to his heart, and indeed he contributes to many open source packages, especially in the Julia ecosystem. In particular, he develops and maintains ArviZ.jl, the Julia port of ArviZ, a platform-agnostic python package to visualize and diagnose your Bayesian models. Seth will tell us how he became involved in ArviZ.jl, what its strengths and weaknesses are, and how it fits into the Julia probabilistic programming landscape.

Ow, and as a bonus, you’ll discover why Seth is such a fan of automatic differentiation, aka « autodiff » — I actually wanted to edit this part out but Seth strongly insisted I kept it. Just kidding of course — or, am I… ?

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Seth website: http://sethaxen.com/ (http://sethaxen.com/)

 Seth on Twitter: https://twitter.com/sethaxen (https://twitter.com/sethaxen)

  Seth on GitHub: https://github.com/sethaxen (https://github.com/sethaxen)

  ArviZ.jl -- Exploratory analysis of Bayesian models in Julia: https://arviz-devs.github.io/ArviZ.jl/dev/ (https://arviz-devs.github.io/ArviZ.jl/dev/)

  PyCon2020 -- Colin Carroll -- Getting started with automatic differentiation: https://www.youtube.com/watch?v=NG21KWZSiok (https://www.youtube.com/watch?v=NG21KWZSiok)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#23 Bayesian Stats in Business and Marketing Analytics, with Elea McDonnel Feit</title><itunes:title>#23 Bayesian Stats in Business and Marketing Analytics, with Elea McDonnel Feit</itunes:title><description><![CDATA[<p>If you’ve studied at a business school, you probably didn’t attend any Bayesian stats course there. Well this isn’t like that in every business schools! Elea McDonnel Feit does integrate Bayesian methods into her teaching at the business school of Drexel University, in Philadelphia, US.&nbsp;</p><p>Elea is an Assistant Professor of Marketing at Drexel, and in this episode she’ll tell us which methods are the most useful in marketing analytics, and why.</p><p>Indeed, Elea develops data analysis methods to inform marketing decisions, such as designing new products and planning advertising campaigns. Often faced with missing, unmatched or aggregated data, she uses MCMC sampling, hierarchical models and decision theory to decipher all this.</p><p>After an MS in Industrial Engineering at Lehigh University and a PhD in Marketing at the University of Michigan, Elea worked on product design at General Motors and was most recently the Executive Director of the Wharton Customer Analytics Initiative.</p><p>Thanks to all these experiences, Elea loves teaching marketing analytics and Bayesian and causal inference at all levels. She even wrote the book <em>R for Marketing Research and Analytics with Chris Chapman</em>, at Springer Press.</p><p>In summary, I think you’ll be pretty surprised by how Bayesian the world of marketing is…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Elea's website: <a href="http://eleafeit.com/" rel="noopener noreferrer" target="_blank">http://eleafeit.com/</a></li><li><em>R for Marketing Research and Analytics</em>: <a href="http://r-marketing.r-forge.r-project.org/" rel="noopener noreferrer" target="_blank">http://r-marketing.r-forge.r-project.org/</a></li><li>Elea's Tutorials &amp; Online Courses: <a href="http://eleafeit.com/teaching/" rel="noopener noreferrer" target="_blank">http://eleafeit.com/teaching/</a></li><li>Elea on Twitter: <a href="https://twitter.com/eleafeit" rel="noopener noreferrer" target="_blank">https://twitter.com/eleafeit</a></li><li>Elea on GitHub: <a href="https://github.com/eleafeit" rel="noopener noreferrer" target="_blank">https://github.com/eleafeit</a></li><li>Tutorial on Conjoint Analysis in R: <a href="https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial" rel="noopener noreferrer" target="_blank">https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial</a></li><li>Test &amp; Roll app: <a href="https://testandroll.shinyapps.io/testandroll/" rel="noopener noreferrer" target="_blank">https://testandroll.shinyapps.io/testandroll/</a></li><li>Test &amp; Roll Paper -- Profit-Maximizing A/B Tests: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875" rel="noopener noreferrer" target="_blank">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875</a></li><li>Principal Stratification for Advertising Experiments: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631" rel="noopener noreferrer" target="_blank">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631</a></li><li>CausalImpact R package: <a href="https://google.github.io/CausalImpact/CausalImpact.html" rel="noopener noreferrer" target="_blank">https://google.github.io/CausalImpact/CausalImpact.html</a></li><li>Chapter on Data Fusion in marketing: <a href="https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1" rel="noopener noreferrer" target="_blank">https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1</a></li><li>Statistical Analysis with Missing Data (Little &amp; Rubin): <a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563" rel="noopener noreferrer" target="_blank">https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563</a></li><li>R-Ladies Philly YouTube channel: <a...]]></description><content:encoded><![CDATA[<p>If you’ve studied at a business school, you probably didn’t attend any Bayesian stats course there. Well this isn’t like that in every business schools! Elea McDonnel Feit does integrate Bayesian methods into her teaching at the business school of Drexel University, in Philadelphia, US.&nbsp;</p><p>Elea is an Assistant Professor of Marketing at Drexel, and in this episode she’ll tell us which methods are the most useful in marketing analytics, and why.</p><p>Indeed, Elea develops data analysis methods to inform marketing decisions, such as designing new products and planning advertising campaigns. Often faced with missing, unmatched or aggregated data, she uses MCMC sampling, hierarchical models and decision theory to decipher all this.</p><p>After an MS in Industrial Engineering at Lehigh University and a PhD in Marketing at the University of Michigan, Elea worked on product design at General Motors and was most recently the Executive Director of the Wharton Customer Analytics Initiative.</p><p>Thanks to all these experiences, Elea loves teaching marketing analytics and Bayesian and causal inference at all levels. She even wrote the book <em>R for Marketing Research and Analytics with Chris Chapman</em>, at Springer Press.</p><p>In summary, I think you’ll be pretty surprised by how Bayesian the world of marketing is…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Elea's website: <a href="http://eleafeit.com/" rel="noopener noreferrer" target="_blank">http://eleafeit.com/</a></li><li><em>R for Marketing Research and Analytics</em>: <a href="http://r-marketing.r-forge.r-project.org/" rel="noopener noreferrer" target="_blank">http://r-marketing.r-forge.r-project.org/</a></li><li>Elea's Tutorials &amp; Online Courses: <a href="http://eleafeit.com/teaching/" rel="noopener noreferrer" target="_blank">http://eleafeit.com/teaching/</a></li><li>Elea on Twitter: <a href="https://twitter.com/eleafeit" rel="noopener noreferrer" target="_blank">https://twitter.com/eleafeit</a></li><li>Elea on GitHub: <a href="https://github.com/eleafeit" rel="noopener noreferrer" target="_blank">https://github.com/eleafeit</a></li><li>Tutorial on Conjoint Analysis in R: <a href="https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial" rel="noopener noreferrer" target="_blank">https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial</a></li><li>Test &amp; Roll app: <a href="https://testandroll.shinyapps.io/testandroll/" rel="noopener noreferrer" target="_blank">https://testandroll.shinyapps.io/testandroll/</a></li><li>Test &amp; Roll Paper -- Profit-Maximizing A/B Tests: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875" rel="noopener noreferrer" target="_blank">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875</a></li><li>Principal Stratification for Advertising Experiments: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631" rel="noopener noreferrer" target="_blank">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631</a></li><li>CausalImpact R package: <a href="https://google.github.io/CausalImpact/CausalImpact.html" rel="noopener noreferrer" target="_blank">https://google.github.io/CausalImpact/CausalImpact.html</a></li><li>Chapter on Data Fusion in marketing: <a href="https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1" rel="noopener noreferrer" target="_blank">https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1</a></li><li>Statistical Analysis with Missing Data (Little &amp; Rubin): <a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563" rel="noopener noreferrer" target="_blank">https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563</a></li><li>R-Ladies Philly YouTube channel: <a href="https://www.youtube.com/channel/UCPque9BaFV9p0hcgImrYBzg" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCPque9BaFV9p0hcgImrYBzg</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/23-bayesian-stats-in-business-and-marketing-analytics-with-elea-mcdonnel-feit]]></link><guid isPermaLink="false">6225206f-b105-49b7-83ed-9628a4825eae</guid><itunes:image href="https://artwork.captivate.fm/7002a686-fbb3-48a5-a438-a537686bfcdf/9wDGXoVz__vLAZanz3vyco4v.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 10 Sep 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/4fd9f81f-4817-4a2a-99a3-8930cfeb6b20/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-8-.mp3" length="113465932" type="audio/mpeg"/><itunes:duration>59:06</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>23</itunes:episode><itunes:season>1</itunes:season><podcast:episode>23</podcast:episode><podcast:season>1</podcast:season><itunes:summary>If you’ve studied at a business school, you probably didn’t attend any Bayesian stats course there. Well this isn’t like that in every business schools! Elea McDonnel Feit does integrate Bayesian methods into her teaching at the business school of Drexel University, in Philadelphia, US. 

Elea is an Assistant Professor of Marketing at Drexel, and in this episode she’ll tell us which methods are the most useful in marketing analytics, and why.

Indeed, Elea develops data analysis methods to inform marketing decisions, such as designing new products and planning advertising campaigns. Often faced with missing, unmatched or aggregated data, she uses MCMC sampling, hierarchical models and decision theory to decipher all this.

After an MS in Industrial Engineering at Lehigh University and a PhD in Marketing at the University of Michigan, Elea worked on product design at General Motors and was most recently the Executive Director of the Wharton Customer Analytics Initiative.

Thanks to all these experiences, Elea loves teaching marketing analytics and Bayesian and causal inference at all levels. She even wrote the book R for Marketing Research and Analytics with Chris Chapman, at Springer Press.

In summary, I think you’ll be pretty surprised by how Bayesian the world of marketing is…

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Elea&apos;s website: http://eleafeit.com/ (http://eleafeit.com/)

 R for Marketing Research and Analytics: http://r-marketing.r-forge.r-project.org/ (http://r-marketing.r-forge.r-project.org/)

  Elea&apos;s Tutorials and Online Courses: http://eleafeit.com/teaching/ (http://eleafeit.com/teaching/)

  Elea on Twitter: https://twitter.com/eleafeit (https://twitter.com/eleafeit)

  Elea on GitHub: https://github.com/eleafeit (https://github.com/eleafeit)

  Tutorial on Conjoint Analysis in R: https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial (https://github.com/ksvanhorn/ART-Forum-2017-Stan-Tutorial)

  Test and Roll app: https://testandroll.shinyapps.io/testandroll/ (https://testandroll.shinyapps.io/testandroll/)

  Test and Roll Paper -- Profit-Maximizing A/B Tests: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875 (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875)

  Principal Stratification for Advertising Experiments: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631 (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140631)

  CausalImpact R package: https://google.github.io/CausalImpact/CausalImpact.html (https://google.github.io/CausalImpact/CausalImpact.html)

  Chapter on Data Fusion in marketing: https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1 (https://link.springer.com/referenceworkentry/10.1007/978-3-319-05542-8_9-1)

  Statistical Analysis with Missing Data (Little and Rubin): https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563 (https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563)

  R-Ladies Philly YouTube channel: https://www.youtube.com/channel/UCPque9BaFV9p0hcgImrYBzg (https://www.youtube.com/channel/UCPque9BaFV9p0hcgImrYBzg)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#22 Eliciting Priors and Doing Bayesian Inference at Scale, with Avi Bryant</title><itunes:title>#22 Eliciting Priors and Doing Bayesian Inference at Scale, with Avi Bryant</itunes:title><description><![CDATA[<p>If, like me, you’ve been stuck in a 40 square-meter apartment for two months, you’re going to be pretty jealous of Avi Bryant. Indeed, Avi lives on Galiano Island, Canada, not very far from Vancouver, surrounded by forest, overlooking the Salish Sea.&nbsp;</p><p>In this natural and beautiful — although slightly deer-infested — spot, Avi runs The Gradient Retreat Center, a place where writers, makers, and code writers can take a week away from their regular lives and focus on creative work. But it’s not only to envy him that I invited Avi on the show — it’s to talk about Bayesian inference in Scala, prior elicitation, how to deploy Bayesian methods at scale, and how to enable Bayesian inference for engineers.&nbsp;</p><p>While working at Stripe, Avi wrote Rainier, a Bayesian inference framework for Scala. Inference is based on variants of the Hamiltonian Monte Carlo sampler, and the implementation is similar to, and targets the same types of models as both Stan and PyMC3. As Avi says, depending on your background, you might think of Rainier as aspiring to be either "Stan, but on the JVM", or "TensorFlow, but for small data".</p><p>In this episode, Avi will tell us how Rainier came into life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Avi on Twitter: <a href="https://twitter.com/avibryant" rel="noopener noreferrer" target="_blank">https://twitter.com/avibryant</a></li><li>Avi on GitHub: <a href="https://github.com/avibryant" rel="noopener noreferrer" target="_blank">https://github.com/avibryant</a></li><li>Rainier -- Bayesian Inference in Scala: <a href="https://rainier.fit/" rel="noopener noreferrer" target="_blank">https://rainier.fit/</a></li><li>The Gradient Retreat: <a href="https://gradientretreat.com/" rel="noopener noreferrer" target="_blank">https://gradientretreat.com/</a></li><li>Facebook's Prophet: <a href="https://facebook.github.io/prophet/" rel="noopener noreferrer" target="_blank">https://facebook.github.io/prophet/</a></li><li>BAyesian Model-Building Interface (Bambi) in Python: <a href="https://bambinos.github.io/bambi/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/</a></li><li>BRMS -- Bayesian regression models using Stan: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>Using Bayesian Decision Making to Optimize Supply Chains -- Thomas Wiecki &amp; Ravin Kumar: <a href="https://twiecki.io/blog/2019/01/14/supply_chain/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2019/01/14/supply_chain/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></description><content:encoded><![CDATA[<p>If, like me, you’ve been stuck in a 40 square-meter apartment for two months, you’re going to be pretty jealous of Avi Bryant. Indeed, Avi lives on Galiano Island, Canada, not very far from Vancouver, surrounded by forest, overlooking the Salish Sea.&nbsp;</p><p>In this natural and beautiful — although slightly deer-infested — spot, Avi runs The Gradient Retreat Center, a place where writers, makers, and code writers can take a week away from their regular lives and focus on creative work. But it’s not only to envy him that I invited Avi on the show — it’s to talk about Bayesian inference in Scala, prior elicitation, how to deploy Bayesian methods at scale, and how to enable Bayesian inference for engineers.&nbsp;</p><p>While working at Stripe, Avi wrote Rainier, a Bayesian inference framework for Scala. Inference is based on variants of the Hamiltonian Monte Carlo sampler, and the implementation is similar to, and targets the same types of models as both Stan and PyMC3. As Avi says, depending on your background, you might think of Rainier as aspiring to be either "Stan, but on the JVM", or "TensorFlow, but for small data".</p><p>In this episode, Avi will tell us how Rainier came into life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Avi on Twitter: <a href="https://twitter.com/avibryant" rel="noopener noreferrer" target="_blank">https://twitter.com/avibryant</a></li><li>Avi on GitHub: <a href="https://github.com/avibryant" rel="noopener noreferrer" target="_blank">https://github.com/avibryant</a></li><li>Rainier -- Bayesian Inference in Scala: <a href="https://rainier.fit/" rel="noopener noreferrer" target="_blank">https://rainier.fit/</a></li><li>The Gradient Retreat: <a href="https://gradientretreat.com/" rel="noopener noreferrer" target="_blank">https://gradientretreat.com/</a></li><li>Facebook's Prophet: <a href="https://facebook.github.io/prophet/" rel="noopener noreferrer" target="_blank">https://facebook.github.io/prophet/</a></li><li>BAyesian Model-Building Interface (Bambi) in Python: <a href="https://bambinos.github.io/bambi/" rel="noopener noreferrer" target="_blank">https://bambinos.github.io/bambi/</a></li><li>BRMS -- Bayesian regression models using Stan: <a href="https://paul-buerkner.github.io/brms/" rel="noopener noreferrer" target="_blank">https://paul-buerkner.github.io/brms/</a></li><li>Using Bayesian Decision Making to Optimize Supply Chains -- Thomas Wiecki &amp; Ravin Kumar: <a href="https://twiecki.io/blog/2019/01/14/supply_chain/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2019/01/14/supply_chain/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/22-eliciting-priors-and-doing-bayesian-inference-at-scale-with-avi-bryant]]></link><guid isPermaLink="false">e8512de4-c244-454c-acdf-5fcd95bb027d</guid><itunes:image href="https://artwork.captivate.fm/481a55db-3a6f-418d-bfef-91be5ef2c11a/qIt-uGwN6AvbMQQkFOIpbtdO.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 26 Aug 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/6f8a4b9b-fb15-4008-9062-aac82ead77f9/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-7-.mp3" length="160623360" type="audio/mpeg"/><itunes:duration>01:06:56</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>22</itunes:episode><itunes:season>1</itunes:season><podcast:episode>22</podcast:episode><podcast:season>1</podcast:season><itunes:summary>If, like me, you’ve been stuck in a 40 square-meter apartment for two months, you’re going to be pretty jealous of Avi Bryant. Indeed, Avi lives on Galiano Island, Canada, not very far from Vancouver, surrounded by forest, overlooking the Salish Sea. 

In this natural and beautiful — although slightly deer-infested — spot, Avi runs The Gradient Retreat Center, a place where writers, makers, and code writers can take a week away from their regular lives and focus on creative work. But it’s not only to envy him that I invited Avi on the show — it’s to talk about Bayesian inference in Scala, prior elicitation, how to deploy Bayesian methods at scale, and how to enable Bayesian inference for engineers. 

While working at Stripe, Avi wrote Rainier, a Bayesian inference framework for Scala. Inference is based on variants of the Hamiltonian Monte Carlo sampler, and the implementation is similar to, and targets the same types of models as both Stan and PyMC3. As Avi says, depending on your background, you might think of Rainier as aspiring to be either &quot;Stan, but on the JVM&quot;, or &quot;TensorFlow, but for small data&quot;.

In this episode, Avi will tell us how Rainier came into life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Avi on Twitter: https://twitter.com/avibryant (https://twitter.com/avibryant)

 Avi on GitHub: https://github.com/avibryant (https://github.com/avibryant)

  Rainier -- Bayesian Inference in Scala: https://rainier.fit/ (https://rainier.fit/)

  The Gradient Retreat: https://gradientretreat.com/ (https://gradientretreat.com/)

  Facebook&apos;s Prophet: https://facebook.github.io/prophet/ (https://facebook.github.io/prophet/)

  BAyesian Model-Building Interface (Bambi) in Python: https://bambinos.github.io/bambi/ (https://bambinos.github.io/bambi/)

  BRMS -- Bayesian regression models using Stan: https://paul-buerkner.github.io/brms/ (https://paul-buerkner.github.io/brms/)

  Using Bayesian Decision Making to Optimize Supply Chains -- Thomas Wiecki and Ravin Kumar: https://twiecki.io/blog/2019/01/14/supply_chain/ (https://twiecki.io/blog/2019/01/14/supply_chain/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#21 Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova</title><itunes:title>#21 Gaussian Processes, Bayesian Neural Nets &amp; SIR Models, with Elizaveta Semenova</itunes:title><description><![CDATA[<p>I bet you heard a lot about epidemiological compartmental models such as SIR in the last few months? But what are they exactly? And why are they so useful for epidemiological modeling?&nbsp;</p><p>Elizaveta Semenova will tell you why in this episode, by walking us through the case study she recently wrote with the Stan team. She’ll also tell us how she used Gaussian Processes on spatio-temporal data, to study the spread of Malaria, or to fit dose-response curves in pharmaceutical tests.&nbsp;</p><p>And finally, she’ll tell us how she used Bayesian neural networks for drug toxicity prediction in her latest paper, and how Bayesian neural nets behave compared to classical neural nets. Ow, and you’ll also learn an interesting link between BNNs and Gaussian Processes…</p><p>I know: Liza works on _a lot_ of projects! But who is she? Well, she’s a postdoctorate in Bayesian Machine Learning at the pharmaceutical company AstraZeneca, in Cambridge, UK.&nbsp;</p><p>Elizaveta did her masters in theoretical mathematics in Moscow, Russia, and then worked in financial services as an actuary in various European countries. She then did a PhD in epidemiology at the University of Basel, Switzerland. This is where she got interested in health applications – be it epidemiology, global health or more small-scale biological questions. But she’ll tell you all that in the episode ;)</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Liza on Twitter: <a href="https://twitter.com/liza_p_semenova" rel="noopener noreferrer" target="_blank">https://twitter.com/liza_p_semenova</a></li><li>Liza on GitHub: <a href="https://github.com/elizavetasemenova" rel="noopener noreferrer" target="_blank">https://github.com/elizavetasemenova</a></li><li>Liza's blog: <a href="https://elizavetasemenova.github.io/blog/" rel="noopener noreferrer" target="_blank">https://elizavetasemenova.github.io/blog/</a></li><li>A Bayesian neural network for toxicity prediction: <a href="https://www.biorxiv.org/content/10.1101/2020.04.28.065532v2" rel="noopener noreferrer" target="_blank">https://www.biorxiv.org/content/10.1101/2020.04.28.065532v2</a></li><li>Bayesian Neural Networks for toxicity prediction -- Video presentation: <a href="https://www.youtube.com/watch?v=BCQ2oVlu_tY&amp;t=751s" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=BCQ2oVlu_tY&amp;t=751s</a></li><li>Bayesian workflow for disease transmission modeling in Stan: <a href="https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html</a></li><li>Andrew Gelman's comments on the SIR case-study: <a href="https://statmodeling.stat.columbia.edu/2020/06/02/this-ones-important-bayesian-workflow-for-disease-transmission-modeling-in-stan/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2020/06/02/this-ones-important-bayesian-workflow-for-disease-transmission-modeling-in-stan/</a></li><li>Determining organ weight toxicity with Bayesian causal models: https://www.biorxiv.org/content/10.1101/754853v1</li><li>Material for Applied Machine Learning Days ("Embracing uncertainty"): https://github.com/elizavetasemenova/EmbracingUncertainty</li><li>Predicting Drug-Induced Liver Injury with Bayesian Machine Learning: https://pubs.acs.org/doi/abs/10.1021/acs.chemrestox.9b00264</li><li>Ordered Logistic Regression in Stan, PyMC3 and Turing: https://medium.com/@liza_p_semenova/ordered-logistic-regression-and-probabilistic-programming-502d8235ad3f</li><li>PyMCon website: https://pymc-devs.github.io/pymcon/</li><li>PyMCon Call For Proposal: https://pymc-devs.github.io/pymcon/cfp</li><li>PyMCon...]]></description><content:encoded><![CDATA[<p>I bet you heard a lot about epidemiological compartmental models such as SIR in the last few months? But what are they exactly? And why are they so useful for epidemiological modeling?&nbsp;</p><p>Elizaveta Semenova will tell you why in this episode, by walking us through the case study she recently wrote with the Stan team. She’ll also tell us how she used Gaussian Processes on spatio-temporal data, to study the spread of Malaria, or to fit dose-response curves in pharmaceutical tests.&nbsp;</p><p>And finally, she’ll tell us how she used Bayesian neural networks for drug toxicity prediction in her latest paper, and how Bayesian neural nets behave compared to classical neural nets. Ow, and you’ll also learn an interesting link between BNNs and Gaussian Processes…</p><p>I know: Liza works on _a lot_ of projects! But who is she? Well, she’s a postdoctorate in Bayesian Machine Learning at the pharmaceutical company AstraZeneca, in Cambridge, UK.&nbsp;</p><p>Elizaveta did her masters in theoretical mathematics in Moscow, Russia, and then worked in financial services as an actuary in various European countries. She then did a PhD in epidemiology at the University of Basel, Switzerland. This is where she got interested in health applications – be it epidemiology, global health or more small-scale biological questions. But she’ll tell you all that in the episode ;)</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Liza on Twitter: <a href="https://twitter.com/liza_p_semenova" rel="noopener noreferrer" target="_blank">https://twitter.com/liza_p_semenova</a></li><li>Liza on GitHub: <a href="https://github.com/elizavetasemenova" rel="noopener noreferrer" target="_blank">https://github.com/elizavetasemenova</a></li><li>Liza's blog: <a href="https://elizavetasemenova.github.io/blog/" rel="noopener noreferrer" target="_blank">https://elizavetasemenova.github.io/blog/</a></li><li>A Bayesian neural network for toxicity prediction: <a href="https://www.biorxiv.org/content/10.1101/2020.04.28.065532v2" rel="noopener noreferrer" target="_blank">https://www.biorxiv.org/content/10.1101/2020.04.28.065532v2</a></li><li>Bayesian Neural Networks for toxicity prediction -- Video presentation: <a href="https://www.youtube.com/watch?v=BCQ2oVlu_tY&amp;t=751s" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=BCQ2oVlu_tY&amp;t=751s</a></li><li>Bayesian workflow for disease transmission modeling in Stan: <a href="https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html</a></li><li>Andrew Gelman's comments on the SIR case-study: <a href="https://statmodeling.stat.columbia.edu/2020/06/02/this-ones-important-bayesian-workflow-for-disease-transmission-modeling-in-stan/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2020/06/02/this-ones-important-bayesian-workflow-for-disease-transmission-modeling-in-stan/</a></li><li>Determining organ weight toxicity with Bayesian causal models: https://www.biorxiv.org/content/10.1101/754853v1</li><li>Material for Applied Machine Learning Days ("Embracing uncertainty"): https://github.com/elizavetasemenova/EmbracingUncertainty</li><li>Predicting Drug-Induced Liver Injury with Bayesian Machine Learning: https://pubs.acs.org/doi/abs/10.1021/acs.chemrestox.9b00264</li><li>Ordered Logistic Regression in Stan, PyMC3 and Turing: https://medium.com/@liza_p_semenova/ordered-logistic-regression-and-probabilistic-programming-502d8235ad3f</li><li>PyMCon website: https://pymc-devs.github.io/pymcon/</li><li>PyMCon Call For Proposal: https://pymc-devs.github.io/pymcon/cfp</li><li>PyMCon Sponsorship Form: https://docs.google.com/forms/d/e/1FAIpQLSdRDI1z0U0ZztONOFiZt2VdsBIZtAWB4JAUA415Iw8RYqNbXQ/viewform</li><li>PyMCon Volunteer Form: https://docs.google.com/forms/d/e/1FAIpQLScCLW5RkNtBz1u376xwelSsNpyWImFisSMjZGP35fYi2QHHXw/viewform</li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/21-gaussian-processes-bayesian-neural-nets-sir-models-with-elizaveta-semenova]]></link><guid isPermaLink="false">3c3cf38b-23da-4a2e-b5e6-db6332453d62</guid><itunes:image href="https://artwork.captivate.fm/e4e57792-c826-4232-826c-08d2586bd91a/FETlYgH5g-mPvgyWHrUQibY8.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 13 Aug 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5fd8168e-d6f2-4a18-b224-62cb2cc7735f/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-7-.mp3" length="149273280" type="audio/mpeg"/><itunes:duration>01:02:12</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>21</itunes:episode><itunes:season>1</itunes:season><podcast:episode>21</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#20 Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari</title><itunes:title>#20 Regression and Other Stories, with Andrew Gelman, Jennifer Hill &amp; Aki Vehtari</itunes:title><description><![CDATA[<p>Once upon a time, there was an enchanted book filled with hundreds of little plots, applied examples and linear regressions — the prettiest creature that was ever seen. Its authors were excessively fond of it, and its readers loved it even more. This magical book had a nice blue cover made for it, and everybody aptly called it «&nbsp;Regression and other Stories&nbsp;»!</p><p>As every good fairy tale, this one had its share of villains — the traps where statistical methods fall and fail you; the terrible confounders, lurking in the dark; the ill-measured data that haunt your inferences! But once you defeat these monsters, you’ll be able to think about, build and interpret regression models.</p><p>This episode will be filled with stories — stories about linear regressions! Here to narrate these marvelous statistical adventures are Andrew Gelman, Jennifer Hill and Aki Vehtari — the authors of the brand new <em>Regression and other Stories</em>.</p><p>Andrew is a professor of statistics and political science at Columbia University. Jennifer is a professor of applied statistics at NYU. She develops methods to answer causal questions related to policy research and scientific development. Aki is an associate professor in computational probabilistic modeling at Aalto University, Finland.</p><p>In this episode, they tell us why they wrote this book, who it is for and they also give us their 10 tips to improve your regression modeling! We also talked about the limits of regression and about going to Mars…</p><p>Other good news: until October 31st 2020, you can go to <a href="http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020" rel="noopener noreferrer" target="_blank">http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020</a> and <strong>buy the book with a 20% discount by entering the promo code “GoodBayesian2020” upon checkout</strong>!</p><p>That way, you’ll make up your own stories before going to sleep and dream of a world where we can easily generalize from sample to population, and where multilevel regression with poststratification is a bliss…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li><em>Regression and Other&nbsp;Stories</em> on Cambridge Press website: <a href="http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020" rel="noopener noreferrer" target="_blank">http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020</a></li><li>Amazon page (because of VAT laws, in some regions ordering from Amazon can be cheaper than from the editor directly, even with the discount): https://www.amazon.com/Regression-Stories-Analytical-Methods-Research/dp/110702398X</li><li>Code, data and examples for the book: <a href="https://avehtari.github.io/ROS-Examples/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/ROS-Examples/</a></li><li>Port of the book in Python and Bambi: <a href="https://github.com/bambinos/Bambi_resources/tree/master/ROS" rel="noopener noreferrer" target="_blank">https://github.com/bambinos/Bambi_resources/tree/master/ROS</a></li><li>Andrew's home page: <a href="http://www.stat.columbia.edu/~gelman/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/</a></li><li>Andrew's blog: <a href="https://statmodeling.stat.columbia.edu/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/</a></li><li>Andrew on Twitter: <a href="https://twitter.com/statmodeling" rel="noopener noreferrer" target="_blank">https://twitter.com/statmodeling</a></li><li>Jennifer's home page: <a href="https://steinhardt.nyu.edu/people/jennifer-hill" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>Once upon a time, there was an enchanted book filled with hundreds of little plots, applied examples and linear regressions — the prettiest creature that was ever seen. Its authors were excessively fond of it, and its readers loved it even more. This magical book had a nice blue cover made for it, and everybody aptly called it «&nbsp;Regression and other Stories&nbsp;»!</p><p>As every good fairy tale, this one had its share of villains — the traps where statistical methods fall and fail you; the terrible confounders, lurking in the dark; the ill-measured data that haunt your inferences! But once you defeat these monsters, you’ll be able to think about, build and interpret regression models.</p><p>This episode will be filled with stories — stories about linear regressions! Here to narrate these marvelous statistical adventures are Andrew Gelman, Jennifer Hill and Aki Vehtari — the authors of the brand new <em>Regression and other Stories</em>.</p><p>Andrew is a professor of statistics and political science at Columbia University. Jennifer is a professor of applied statistics at NYU. She develops methods to answer causal questions related to policy research and scientific development. Aki is an associate professor in computational probabilistic modeling at Aalto University, Finland.</p><p>In this episode, they tell us why they wrote this book, who it is for and they also give us their 10 tips to improve your regression modeling! We also talked about the limits of regression and about going to Mars…</p><p>Other good news: until October 31st 2020, you can go to <a href="http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020" rel="noopener noreferrer" target="_blank">http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020</a> and <strong>buy the book with a 20% discount by entering the promo code “GoodBayesian2020” upon checkout</strong>!</p><p>That way, you’ll make up your own stories before going to sleep and dream of a world where we can easily generalize from sample to population, and where multilevel regression with poststratification is a bliss…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li><em>Regression and Other&nbsp;Stories</em> on Cambridge Press website: <a href="http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020" rel="noopener noreferrer" target="_blank">http://www.cambridge.org/wm-ecommerce-web/academic/landingPage/GoodBayesian2020</a></li><li>Amazon page (because of VAT laws, in some regions ordering from Amazon can be cheaper than from the editor directly, even with the discount): https://www.amazon.com/Regression-Stories-Analytical-Methods-Research/dp/110702398X</li><li>Code, data and examples for the book: <a href="https://avehtari.github.io/ROS-Examples/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/ROS-Examples/</a></li><li>Port of the book in Python and Bambi: <a href="https://github.com/bambinos/Bambi_resources/tree/master/ROS" rel="noopener noreferrer" target="_blank">https://github.com/bambinos/Bambi_resources/tree/master/ROS</a></li><li>Andrew's home page: <a href="http://www.stat.columbia.edu/~gelman/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/</a></li><li>Andrew's blog: <a href="https://statmodeling.stat.columbia.edu/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/</a></li><li>Andrew on Twitter: <a href="https://twitter.com/statmodeling" rel="noopener noreferrer" target="_blank">https://twitter.com/statmodeling</a></li><li>Jennifer's home page: <a href="https://steinhardt.nyu.edu/people/jennifer-hill" rel="noopener noreferrer" target="_blank"><u>https://steinhardt.nyu.edu/people/jennifer-hill</u></a></li><li>Aki's teaching material: <a href="https://avehtari.github.io/" rel="noopener noreferrer" target="_blank">https://avehtari.github.io/</a></li><li>Aki's home page: <a href="https://users.aalto.fi/~ave/" rel="noopener noreferrer" target="_blank">https://users.aalto.fi/~ave/</a></li><li>Aki on Twitter: <a href="https://twitter.com/avehtari" rel="noopener noreferrer" target="_blank"><u>https://twitter.com/avehtari</u></a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/20-regression-and-other-stories-with-andrew-gelman-jennifer-hill-aki-vehtari]]></link><guid isPermaLink="false">198e2201-8795-43d8-a35b-2521b3b56123</guid><itunes:image href="https://artwork.captivate.fm/68f6a7c9-f746-4f53-af5e-8f7e3dec62cc/SPHkgV5mptHdUG8-RcsoskUK.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 30 Jul 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/eb851d0a-0ff3-4353-a63a-e85e447085f9/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fstaging-2f2020-6-.mp3" length="152972015" type="audio/mpeg"/><itunes:duration>01:03:44</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>20</itunes:episode><itunes:season>1</itunes:season><podcast:episode>20</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#19 Turing, Julia and Bayes in Economics, with Cameron Pfiffer</title><itunes:title>#19 Turing, Julia and Bayes in Economics, with Cameron Pfiffer</itunes:title><description><![CDATA[<p>Do you know Turing? Of course you do! With Soss and Gen, it’s one of the blockbusters to do probabilistic programming in Julia. And in this episode Cameron Pfiffer will tell us all about it — how it came to life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.</p><p>Cameron did some Rust, some Python, but he especially loves coding in Julia. That’s also why he’s one of the core-developers of Turing.jl. He’s also a PhD student in finance at the University of Oregon and did his master’s in finance at the University of Reading. His interests are pretty broad, from cryptocurrencies, algorithmic and high-frequency trading, to AI in financial markets and anomaly detection – in a nutshell he’s a fan of topics where technology is involved.</p><p>As he’s the first economist to come to the show, I also asked him how Bayesian the field of economics is, why he thinks economics is quite unique among the social sciences, and how economists think about causality — I later learned that this topic is pretty controversial!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Bayesian Econometrics on Cameron's Blog: <a href="http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/" rel="noopener noreferrer" target="_blank">http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/</a></li><li>Cameron on Twitter: <a href="https://twitter.com/cameron_pfiffer" rel="noopener noreferrer" target="_blank">https://twitter.com/cameron_pfiffer</a></li><li>Cameron on GitHub: <a href="https://github.com/cpfiffer" rel="noopener noreferrer" target="_blank">https://github.com/cpfiffer</a></li><li>Turing.jl -- Bayesian inference in Julia: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Gen.jl -- Programmable inference embedded in Julia: <a href="https://www.gen.dev/" rel="noopener noreferrer" target="_blank">https://www.gen.dev/</a></li><li>Soss.jl -- Probabilistic programming via source rewriting: <a href="https://github.com/cscherrer/Soss.jl" rel="noopener noreferrer" target="_blank">https://github.com/cscherrer/Soss.jl</a></li><li>The Julia Language -- A fresh approach to technical computing: <a href="https://julialang.org/" rel="noopener noreferrer" target="_blank">https://julialang.org/</a></li><li>What is Probabilistic Programming -- Cornell University: <a href="http://adriansampson.net/doc/ppl.html" rel="noopener noreferrer" target="_blank">http://adriansampson.net/doc/ppl.html</a></li><li>Mostly Harmless Econometrics Book: <a href="http://www.mostlyharmlesseconometrics.com/" rel="noopener noreferrer" target="_blank">http://www.mostlyharmlesseconometrics.com/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></description><content:encoded><![CDATA[<p>Do you know Turing? Of course you do! With Soss and Gen, it’s one of the blockbusters to do probabilistic programming in Julia. And in this episode Cameron Pfiffer will tell us all about it — how it came to life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.</p><p>Cameron did some Rust, some Python, but he especially loves coding in Julia. That’s also why he’s one of the core-developers of Turing.jl. He’s also a PhD student in finance at the University of Oregon and did his master’s in finance at the University of Reading. His interests are pretty broad, from cryptocurrencies, algorithmic and high-frequency trading, to AI in financial markets and anomaly detection – in a nutshell he’s a fan of topics where technology is involved.</p><p>As he’s the first economist to come to the show, I also asked him how Bayesian the field of economics is, why he thinks economics is quite unique among the social sciences, and how economists think about causality — I later learned that this topic is pretty controversial!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Bayesian Econometrics on Cameron's Blog: <a href="http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/" rel="noopener noreferrer" target="_blank">http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/</a></li><li>Cameron on Twitter: <a href="https://twitter.com/cameron_pfiffer" rel="noopener noreferrer" target="_blank">https://twitter.com/cameron_pfiffer</a></li><li>Cameron on GitHub: <a href="https://github.com/cpfiffer" rel="noopener noreferrer" target="_blank">https://github.com/cpfiffer</a></li><li>Turing.jl -- Bayesian inference in Julia: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Gen.jl -- Programmable inference embedded in Julia: <a href="https://www.gen.dev/" rel="noopener noreferrer" target="_blank">https://www.gen.dev/</a></li><li>Soss.jl -- Probabilistic programming via source rewriting: <a href="https://github.com/cscherrer/Soss.jl" rel="noopener noreferrer" target="_blank">https://github.com/cscherrer/Soss.jl</a></li><li>The Julia Language -- A fresh approach to technical computing: <a href="https://julialang.org/" rel="noopener noreferrer" target="_blank">https://julialang.org/</a></li><li>What is Probabilistic Programming -- Cornell University: <a href="http://adriansampson.net/doc/ppl.html" rel="noopener noreferrer" target="_blank">http://adriansampson.net/doc/ppl.html</a></li><li>Mostly Harmless Econometrics Book: <a href="http://www.mostlyharmlesseconometrics.com/" rel="noopener noreferrer" target="_blank">http://www.mostlyharmlesseconometrics.com/</a></li></ul><br/><p><strong>Thank you to my Patrons for making this episode possible!</strong></p><p><em>Yusuke Saito, Avi Bryant, Ero Carrera, Brian Huey, Giuliano Cruz, Tim Gasser, James Wade, Tradd Salvo, Adam Bartonicek, William Benton, Alan O'Donnell, Mark Ormsby, Demetri Pananos, James Ahloy, Jon Berezowski, Robin Taylor, Thomas Wiecki, Chad Scherrer, Vincent Arel-Bundock, Nathaniel Neitzke, Zwelithini Tunyiswa, Elea McDonnell Feit, Bertrand Wilden, James Thompson, Stephen Oates, Gian Luca Di Tanna, Jack Wells, Matthew Maldonado, Ian Costley, Ally Salim, Larry Gill, Joshua Duncan, Ian Moran and Paul Oreto.</em></p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/19-turing-julia-and-bayes-in-economics-with-cameron-pfiffer]]></link><guid isPermaLink="false">c857e16e-78f1-433a-9cae-751ffc84b364</guid><itunes:image href="https://artwork.captivate.fm/532982e3-8340-4506-a9db-14acb88b3c22/2YI9y75qAnSZAoyZGYvmoze7.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 03 Jul 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/380a7a81-fb62-444b-b648-42d519e262b7/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="145072586" type="audio/mpeg"/><itunes:duration>01:00:27</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>19</itunes:episode><itunes:season>1</itunes:season><podcast:episode>19</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Do you know Turing? Of course you do! With Soss and Gen, it’s one of the blockbusters to do probabilistic programming in Julia. And in this episode Cameron Pfiffer will tell us all about it — how it came to life, how it fits into the probabilistic programming landscape, and what its main strengths and weaknesses are.

Cameron did some Rust, some Python, but he especially loves coding in Julia. That’s also why he’s one of the core-developers of Turing.jl. He’s also a PhD student in finance at the University of Oregon and did his master’s in finance at the University of Reading. His interests are pretty broad, from cryptocurrencies, algorithmic and high-frequency trading, to AI in financial markets and anomaly detection – in a nutshell he’s a fan of topics where technology is involved.

As he’s the first economist to come to the show, I also asked him how Bayesian the field of economics is, why he thinks economics is quite unique among the social sciences, and how economists think about causality — I later learned that this topic is pretty controversial!

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Bayesian Econometrics on Cameron&apos;s Blog: http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/ (http://cameron.pfiffer.org/2020/03/24/bayesian-econometrics/)

 Cameron on Twitter: https://twitter.com/cameron_pfiffer (https://twitter.com/cameron_pfiffer)

  Cameron on GitHub: https://github.com/cpfiffer (https://github.com/cpfiffer)

  Turing.jl -- Bayesian inference in Julia: https://turing.ml/dev/ (https://turing.ml/dev/)

  Gen.jl -- Programmable inference embedded in Julia: https://www.gen.dev/ (https://www.gen.dev/)

  Soss.jl -- Probabilistic programming via source rewriting: https://github.com/cscherrer/Soss.jl (https://github.com/cscherrer/Soss.jl)

  The Julia Language -- A fresh approach to technical computing: https://julialang.org/ (https://julialang.org/)

  What is Probabilistic Programming -- Cornell University: http://adriansampson.net/doc/ppl.html (http://adriansampson.net/doc/ppl.html)

  Mostly Harmless Econometrics Book: http://www.mostlyharmlesseconometrics.com/ (http://www.mostlyharmlesseconometrics.com/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#SpecialAnnouncement: Patreon Launched!</title><itunes:title>#SpecialAnnouncement: Patreon Launched!</itunes:title><description><![CDATA[<p>I hope you’re all safe! Some of you also asked me if I had set up a Patreon so that they could help support the show, and that’s why I’m sending this short special episode your way today. I had thought about that, but I wasn’t sure there was a demand for this. Apparently, there is one — at least a small one — so, first, I wanna thank you and say how grateful I am to be in a community that values this kind of work!</p><p>The Patreon page is now live at <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a>. It starts as low as 3€ and you can pick from 4 different tiers:</p><ol><li>"<strong>Maximum A Posteriori</strong>" (3€): Join the Slack, where you can ask questions about the show, discuss with like-minded Bayesians and meet them in-person when you travel the world.</li><li>"<strong>Full Posterior</strong>" (5€): Previous tier + Your name in all the show notes, and I'll express my gratitude to you in the first episode to go out after your contribution. You also get early access to the special episodes. -- that I'll make at an irregular pace and will include panel discussions, book releases, live shows, etc.</li><li>"<strong>Principled Bayesian</strong>" (20€): Previous tiers + Every 2 months, I'll ask my guest two questions voted-on by "Principled Bayesians". I'll probably do that with a poll in the Slack channel, which will be only answered by the "Principled Bayesians" and of these questions, I will ask the top 2 every two months on the show.&nbsp;</li><li>"<strong>Good Bayesian</strong>" (200€, only 8 spots): Previous tiers + Every 2 months, you can come on the show and you ask one question to the guest without a vote. So that's why I can't have too many people in that tier.</li></ol><br/><p>Before telling you the best part: I already have a lot of ideas for exclusive content and options. I first need to see whether you're as excited as I am about it. If I see you are, I'll be able to add new perks to the tiers! So give me your feedback about the current tiers or any benefits you'd like to see there... but don't see yet! BTW, you have a new way to do that now: sending me voice messages at <a href="//anchor.fm/learn-bayes-stats/message" target="_blank">anchor.fm/learn-bayes-stats/message</a>!</p><p>Now, the icing on the cake: until July 31st, if you choose the "Full Posterior" tier (5$) or higher, you get early access to the very special episode I'm planning with Andrew Gelman, Jennifer Hill and Aki Vehtari about their upcoming book, "Regression and other stories". To top it off, there will be a promo code in the episode to buy the book at a discount price — now, that is an offer you can't turn down!</p><p>Alright, that is it for today — I hope you’re as excited as I am for this new stage in the podcast’s life! Please keep the emails, the tweets, the voice messages, the carrier pigeons coming with your feedback, questions and suggestions.</p><p>In the meantime, take care and I’ll see you in the next episode — episode 19, with Cameron Pfiffer, who’s the first economist to come on the show and who’s a core-developer of <a href="https://turing.ml/dev/" target="_blank">Turing.jl</a>. We’re gonna talk about the Julia probabilistic programming landscape, Bayes in economics and causality — it’s gonna be fun ;)&nbsp;</p><p>Again, <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a> if you want to support the show and unlock some nice perks. Thanks again, I am very grateful for any support you can bring me!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>LBS Patreon page: <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a></li><li>Send me voice messages: <a href="//anchor.fm/learn-bayes-stats/message"...]]></description><content:encoded><![CDATA[<p>I hope you’re all safe! Some of you also asked me if I had set up a Patreon so that they could help support the show, and that’s why I’m sending this short special episode your way today. I had thought about that, but I wasn’t sure there was a demand for this. Apparently, there is one — at least a small one — so, first, I wanna thank you and say how grateful I am to be in a community that values this kind of work!</p><p>The Patreon page is now live at <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a>. It starts as low as 3€ and you can pick from 4 different tiers:</p><ol><li>"<strong>Maximum A Posteriori</strong>" (3€): Join the Slack, where you can ask questions about the show, discuss with like-minded Bayesians and meet them in-person when you travel the world.</li><li>"<strong>Full Posterior</strong>" (5€): Previous tier + Your name in all the show notes, and I'll express my gratitude to you in the first episode to go out after your contribution. You also get early access to the special episodes. -- that I'll make at an irregular pace and will include panel discussions, book releases, live shows, etc.</li><li>"<strong>Principled Bayesian</strong>" (20€): Previous tiers + Every 2 months, I'll ask my guest two questions voted-on by "Principled Bayesians". I'll probably do that with a poll in the Slack channel, which will be only answered by the "Principled Bayesians" and of these questions, I will ask the top 2 every two months on the show.&nbsp;</li><li>"<strong>Good Bayesian</strong>" (200€, only 8 spots): Previous tiers + Every 2 months, you can come on the show and you ask one question to the guest without a vote. So that's why I can't have too many people in that tier.</li></ol><br/><p>Before telling you the best part: I already have a lot of ideas for exclusive content and options. I first need to see whether you're as excited as I am about it. If I see you are, I'll be able to add new perks to the tiers! So give me your feedback about the current tiers or any benefits you'd like to see there... but don't see yet! BTW, you have a new way to do that now: sending me voice messages at <a href="//anchor.fm/learn-bayes-stats/message" target="_blank">anchor.fm/learn-bayes-stats/message</a>!</p><p>Now, the icing on the cake: until July 31st, if you choose the "Full Posterior" tier (5$) or higher, you get early access to the very special episode I'm planning with Andrew Gelman, Jennifer Hill and Aki Vehtari about their upcoming book, "Regression and other stories". To top it off, there will be a promo code in the episode to buy the book at a discount price — now, that is an offer you can't turn down!</p><p>Alright, that is it for today — I hope you’re as excited as I am for this new stage in the podcast’s life! Please keep the emails, the tweets, the voice messages, the carrier pigeons coming with your feedback, questions and suggestions.</p><p>In the meantime, take care and I’ll see you in the next episode — episode 19, with Cameron Pfiffer, who’s the first economist to come on the show and who’s a core-developer of <a href="https://turing.ml/dev/" target="_blank">Turing.jl</a>. We’re gonna talk about the Julia probabilistic programming landscape, Bayes in economics and causality — it’s gonna be fun ;)&nbsp;</p><p>Again, <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a> if you want to support the show and unlock some nice perks. Thanks again, I am very grateful for any support you can bring me!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>LBS Patreon page: <a href="//patreon.com/learnbayesstats" target="_blank">patreon.com/learnbayesstats</a></li><li>Send me voice messages: <a href="//anchor.fm/learn-bayes-stats/message" target="_blank">anchor.fm/learn-bayes-stats/message</a></li></ul><br/><p>---</p><p>Send in a voice message: https://anchor.fm/learn-bayes-stats/message</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/specialannouncement-patreon-launched]]></link><guid isPermaLink="false">ca624099-1d0d-4373-9496-a9b2c1a6ef88</guid><itunes:image href="https://artwork.captivate.fm/57475e2b-9a77-42a2-ade9-103fa912bf18/2331893-1568966097324-58deab5a83dc6.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 26 Jun 2020 09:30:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/5949bd06-c3a6-4902-ad8c-6bcbd461f71c/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="18344298" type="audio/mpeg"/><itunes:duration>07:39</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:season>1</itunes:season><itunes:season>1</itunes:season><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#18 How to ask good Research Questions and encourage Open Science, with Daniel Lakens</title><itunes:title>#18 How to ask good Research Questions and encourage Open Science, with Daniel Lakens</itunes:title><description><![CDATA[<p>How do you design a good experimental study? How do you even know that you’re asking a good research question? Moreover, how can you align funding and publishing incentives with the principles of an open source science?</p><p>Let’s do another “big picture” episode to try and answer these questions! You know, these episodes that I want to do from time to time, with people who are not from the Bayesian world, to see what good practices there are out there. The first one, episode 15, was focused on programming and python, thanks to Michael Kennedy.&nbsp;</p><p>In this one, you’ll meet Daniel Lakens. Daniel is an experimental psychologist at the Human-Technology Interaction group at Eindhoven University of Technology, in the Netherlands. He’s worked there since 2010, when he received his PhD in social psychology.&nbsp;</p><p>His research focuses on how to design and interpret studies, applied meta-statistics, and reward structures in science. Daniel loves teaching about research methods and about how to ask good research questions. He even crafted free Coursera courses about these topics.&nbsp;</p><p>A fervent advocate of open science, he prioritizes scholar articles review requests based on how much the articles adhere to Open Science principles. On his blog, he describes himself as ‘the 20% Statistician’. Why? Well, he’ll tell you in the episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Daniel's website: <a href="https://sites.google.com/site/lakens2/Home?authuser=0 http://daniellakens.blogspot.com/ https://github.com/Lakens https://twitter.com/lakens?ref_src=twsrc%5Etfw https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl https://www.coursera.org/learn/statistical-inferences https://www.coursera.org/learn/improving-statistical-questions https://opennessinitiative.org/ https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/" rel="noopener noreferrer" target="_blank">https://sites.google.com/site/lakens2/Home</a></li><li>The 20% Statistician: <a href="http://daniellakens.blogspot.com/" rel="noopener noreferrer" target="_blank">http://daniellakens.blogspot.com/</a></li><li>Daniel on GitHub: <a href="https://github.com/Lakens" rel="noopener noreferrer" target="_blank">https://github.com/Lakens</a></li><li>Daniel on Twitter: <a href="https://twitter.com/lakens" rel="noopener noreferrer" target="_blank">https://twitter.com/lakens</a></li><li>Daniel on Google Scholar: <a href="https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl" rel="noopener noreferrer" target="_blank">https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl</a></li><li>Coursera Course -- Improving your statistical inferences: <a href="https://www.coursera.org/learn/statistical-inferences" rel="noopener noreferrer" target="_blank">https://www.coursera.org/learn/statistical-inferences</a></li><li>Coursera Course -- Improving Your Statistical Questions: <a href="https://www.coursera.org/learn/improving-statistical-questions" rel="noopener noreferrer" target="_blank">https://www.coursera.org/learn/improving-statistical-questions</a></li><li>Peer Reviewers' Openness Initiative: <a href="https://opennessinitiative.org/" rel="noopener noreferrer" target="_blank">https://opennessinitiative.org/</a></li><li>The Scientific Paper Is Obsolete -- Here’s what’s next: <a href="https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/" rel="noopener noreferrer" target="_blank">https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>How do you design a good experimental study? How do you even know that you’re asking a good research question? Moreover, how can you align funding and publishing incentives with the principles of an open source science?</p><p>Let’s do another “big picture” episode to try and answer these questions! You know, these episodes that I want to do from time to time, with people who are not from the Bayesian world, to see what good practices there are out there. The first one, episode 15, was focused on programming and python, thanks to Michael Kennedy.&nbsp;</p><p>In this one, you’ll meet Daniel Lakens. Daniel is an experimental psychologist at the Human-Technology Interaction group at Eindhoven University of Technology, in the Netherlands. He’s worked there since 2010, when he received his PhD in social psychology.&nbsp;</p><p>His research focuses on how to design and interpret studies, applied meta-statistics, and reward structures in science. Daniel loves teaching about research methods and about how to ask good research questions. He even crafted free Coursera courses about these topics.&nbsp;</p><p>A fervent advocate of open science, he prioritizes scholar articles review requests based on how much the articles adhere to Open Science principles. On his blog, he describes himself as ‘the 20% Statistician’. Why? Well, he’ll tell you in the episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Daniel's website: <a href="https://sites.google.com/site/lakens2/Home?authuser=0 http://daniellakens.blogspot.com/ https://github.com/Lakens https://twitter.com/lakens?ref_src=twsrc%5Etfw https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl https://www.coursera.org/learn/statistical-inferences https://www.coursera.org/learn/improving-statistical-questions https://opennessinitiative.org/ https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/" rel="noopener noreferrer" target="_blank">https://sites.google.com/site/lakens2/Home</a></li><li>The 20% Statistician: <a href="http://daniellakens.blogspot.com/" rel="noopener noreferrer" target="_blank">http://daniellakens.blogspot.com/</a></li><li>Daniel on GitHub: <a href="https://github.com/Lakens" rel="noopener noreferrer" target="_blank">https://github.com/Lakens</a></li><li>Daniel on Twitter: <a href="https://twitter.com/lakens" rel="noopener noreferrer" target="_blank">https://twitter.com/lakens</a></li><li>Daniel on Google Scholar: <a href="https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl" rel="noopener noreferrer" target="_blank">https://scholar.google.nl/citations?user=ZbqYyrsAAAAJ&amp;hl=nl</a></li><li>Coursera Course -- Improving your statistical inferences: <a href="https://www.coursera.org/learn/statistical-inferences" rel="noopener noreferrer" target="_blank">https://www.coursera.org/learn/statistical-inferences</a></li><li>Coursera Course -- Improving Your Statistical Questions: <a href="https://www.coursera.org/learn/improving-statistical-questions" rel="noopener noreferrer" target="_blank">https://www.coursera.org/learn/improving-statistical-questions</a></li><li>Peer Reviewers' Openness Initiative: <a href="https://opennessinitiative.org/" rel="noopener noreferrer" target="_blank">https://opennessinitiative.org/</a></li><li>The Scientific Paper Is Obsolete -- Here’s what’s next: <a href="https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/" rel="noopener noreferrer" target="_blank">https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/18-how-to-ask-good-research-questions-and-encourage-open-science-with-daniel-lakens]]></link><guid isPermaLink="false">a524e1e5-b08f-4956-b895-1d89755f7cd9</guid><itunes:image href="https://artwork.captivate.fm/f0ffe5da-98b3-49de-81ea-3bda9b10743d/LDWFS-WWfSjuTzm6z03XKvm6.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 18 Jun 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/71565b53-358f-4187-a29c-901863d4f491/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="140333957" type="audio/mpeg"/><itunes:duration>58:28</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>18</itunes:episode><itunes:season>1</itunes:season><podcast:episode>18</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How do you design a good experimental study? How do you even know that you’re asking a good research question? Moreover, how can you align funding and publishing incentives with the principles of an open source science?

Let’s do another “big picture” episode to try and answer these questions! You know, these episodes that I want to do from time to time, with people who are not from the Bayesian world, to see what good practices there are out there. The first one, episode 15, was focused on programming and python, thanks to Michael Kennedy. 

In this one, you’ll meet Daniel Lakens. Daniel is an experimental psychologist at the Human-Technology Interaction group at Eindhoven University of Technology, in the Netherlands. He’s worked there since 2010, when he received his PhD in social psychology. 

His research focuses on how to design and interpret studies, applied meta-statistics, and reward structures in science. Daniel loves teaching about research methods and about how to ask good research questions. He even crafted free Coursera courses about these topics. 

A fervent advocate of open science, he prioritizes scholar articles review requests based on how much the articles adhere to Open Science principles. On his blog, he describes himself as ‘the 20% Statistician’. Why? Well, he’ll tell you in the episode…

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Daniel&apos;s website: https://sites.google.com/site/lakens2/Home?authuser=0 http://daniellakens.blogspot.com/ https://github.com/Lakens https://twitter.com/lakens?ref_src=twsrc%5Etfw https://scholar.google.nl/citations?user=ZbqYyrsAAAAJandhl=nl https://www.coursera.org/learn/statistical-inferences https://www.coursera.org/learn/improving-statistical-questions https://opennessinitiative.org/ https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/ (https://sites.google.com/site/lakens2/Home)

 The 20% Statistician: http://daniellakens.blogspot.com/ (http://daniellakens.blogspot.com/)

  Daniel on GitHub: https://github.com/Lakens (https://github.com/Lakens)

  Daniel on Twitter: https://twitter.com/lakens (https://twitter.com/lakens)

  Daniel on Google Scholar: https://scholar.google.nl/citations?user=ZbqYyrsAAAAJandhl=nl (https://scholar.google.nl/citations?user=ZbqYyrsAAAAJandhl=nl)

  Coursera Course -- Improving your statistical inferences: https://www.coursera.org/learn/statistical-inferences (https://www.coursera.org/learn/statistical-inferences)

  Coursera Course -- Improving Your Statistical Questions: https://www.coursera.org/learn/improving-statistical-questions (https://www.coursera.org/learn/improving-statistical-questions)

  Peer Reviewers&apos; Openness Initiative: https://opennessinitiative.org/ (https://opennessinitiative.org/)

  The Scientific Paper Is Obsolete -- Here’s what’s next: https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/ (https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#17 Reparametrize Your Models Automatically, with Maria Gorinova</title><itunes:title>#17 Reparametrize Your Models Automatically, with Maria Gorinova</itunes:title><description><![CDATA[<p>Have you already encountered a model that you know is scientifically sound, but that MCMC just wouldn’t run? The model would take forever to run — if it ever ran — and you would be greeted with a lot of divergences in the end. Yeah, I know, my stress levels start raising too whenever I hear the word «&nbsp;divergences&nbsp;»…</p><p>Well, you’ll be glad to hear there are tricks to make these models run, and one of these tricks is called re-parametrization — I bet you already heard about the poorly-named non-centered parametrization?</p><p>Well fear no more! In this episode, Maria Gorinova will tell you all about these model re-parametrizations! Maria is a PhD student in Data Science &amp; AI at the University of Edinburgh. Her broad interests range from programming languages and verification, to machine learning and human-computer interaction.&nbsp;</p><p>More specifically, Maria is interested in probabilistic programming languages, and in exploring ways of applying program-analysis techniques to existing PPLs in order to improve usability of the language or efficiency of inference.</p><p>As you’ll hear in the episode, she thinks a lot about the language aspect of probabilistic programming, and works on the automation of various “tricks” in probabilistic programming: automatic re-parametrization, automatic marginalization, automatic and efficient model-specific inference.</p><p>As Maria also has experience with several PPLs like Stan, Edward2 and TensorFlow Probability, she’ll tell us what she thinks a good PPL design requires, and what the future of PPLs looks like to her.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Maria on the Web: <a href="http://homepages.inf.ed.ac.uk/s1207807/index.html" rel="noopener noreferrer" target="_blank">http://homepages.inf.ed.ac.uk/s1207807/index.html</a></li><li>Maria on Twitter: <a href="https://twitter.com/migorinova" rel="noopener noreferrer" target="_blank">https://twitter.com/migorinova</a></li><li>Maria on GitHub: <a href="https://github.com/mgorinova" rel="noopener noreferrer" target="_blank">https://github.com/mgorinova</a></li><li>Automatic Reparameterisation of Probabilistic Programs (Maria's paper with Dave Moore and Matthew Hoffman): <a href="https://arxiv.org/abs/1906.03028" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1906.03028</a></li><li>Stan User's Guide on Reparameterization: <a href="https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html</a></li><li>HMC for hierarchical models -- Background on reparameterization: <a href="https://arxiv.org/abs/1312.0906" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1312.0906</a></li><li>NeuTra -- Automatic reparameterization: <a href="https://arxiv.org/abs/1903.03704" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1903.03704</a></li><li>Edward2 -- A library for probabilistic modeling, inference, and criticism: <a href="http://edwardlib.org/" rel="noopener noreferrer" target="_blank">http://edwardlib.org/</a></li><li>Pyro -- Automatic reparameterization and marginalization: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>Gen -- Programmable inference: <a href="http://probcomp.csail.mit.edu/software/gen/" rel="noopener noreferrer" target="_blank">http://probcomp.csail.mit.edu/software/gen/</a></li><li>TensorFlow Probability: <a href="https://www.tensorflow.org/probability/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>Have you already encountered a model that you know is scientifically sound, but that MCMC just wouldn’t run? The model would take forever to run — if it ever ran — and you would be greeted with a lot of divergences in the end. Yeah, I know, my stress levels start raising too whenever I hear the word «&nbsp;divergences&nbsp;»…</p><p>Well, you’ll be glad to hear there are tricks to make these models run, and one of these tricks is called re-parametrization — I bet you already heard about the poorly-named non-centered parametrization?</p><p>Well fear no more! In this episode, Maria Gorinova will tell you all about these model re-parametrizations! Maria is a PhD student in Data Science &amp; AI at the University of Edinburgh. Her broad interests range from programming languages and verification, to machine learning and human-computer interaction.&nbsp;</p><p>More specifically, Maria is interested in probabilistic programming languages, and in exploring ways of applying program-analysis techniques to existing PPLs in order to improve usability of the language or efficiency of inference.</p><p>As you’ll hear in the episode, she thinks a lot about the language aspect of probabilistic programming, and works on the automation of various “tricks” in probabilistic programming: automatic re-parametrization, automatic marginalization, automatic and efficient model-specific inference.</p><p>As Maria also has experience with several PPLs like Stan, Edward2 and TensorFlow Probability, she’ll tell us what she thinks a good PPL design requires, and what the future of PPLs looks like to her.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Maria on the Web: <a href="http://homepages.inf.ed.ac.uk/s1207807/index.html" rel="noopener noreferrer" target="_blank">http://homepages.inf.ed.ac.uk/s1207807/index.html</a></li><li>Maria on Twitter: <a href="https://twitter.com/migorinova" rel="noopener noreferrer" target="_blank">https://twitter.com/migorinova</a></li><li>Maria on GitHub: <a href="https://github.com/mgorinova" rel="noopener noreferrer" target="_blank">https://github.com/mgorinova</a></li><li>Automatic Reparameterisation of Probabilistic Programs (Maria's paper with Dave Moore and Matthew Hoffman): <a href="https://arxiv.org/abs/1906.03028" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1906.03028</a></li><li>Stan User's Guide on Reparameterization: <a href="https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html</a></li><li>HMC for hierarchical models -- Background on reparameterization: <a href="https://arxiv.org/abs/1312.0906" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1312.0906</a></li><li>NeuTra -- Automatic reparameterization: <a href="https://arxiv.org/abs/1903.03704" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1903.03704</a></li><li>Edward2 -- A library for probabilistic modeling, inference, and criticism: <a href="http://edwardlib.org/" rel="noopener noreferrer" target="_blank">http://edwardlib.org/</a></li><li>Pyro -- Automatic reparameterization and marginalization: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>Gen -- Programmable inference: <a href="http://probcomp.csail.mit.edu/software/gen/" rel="noopener noreferrer" target="_blank">http://probcomp.csail.mit.edu/software/gen/</a></li><li>TensorFlow Probability: <a href="https://www.tensorflow.org/probability/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/17-reparametrize-your-models-automatically-with-maria-gorinova]]></link><guid isPermaLink="false">ed4746c8-1736-4fb9-a95f-1e3843ffa2fa</guid><itunes:image href="https://artwork.captivate.fm/427bf0b0-7c31-418d-9d40-b6a623c09e4b/ogk2w_WfdfSnvXu-k4Pzbf-M.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 04 Jun 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f8edb569-7aa9-49a3-a61d-64a19750f09a/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="123603068" type="audio/mpeg"/><itunes:duration>51:30</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>17</itunes:episode><itunes:season>1</itunes:season><podcast:episode>17</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Have you already encountered a model that you know is scientifically sound, but that MCMC just wouldn’t run? The model would take forever to run — if it ever ran — and you would be greeted with a lot of divergences in the end. Yeah, I know, my stress levels start raising too whenever I hear the word « divergences »…

Well, you’ll be glad to hear there are tricks to make these models run, and one of these tricks is called re-parametrization — I bet you already heard about the poorly-named non-centered parametrization?

Well fear no more! In this episode, Maria Gorinova will tell you all about these model re-parametrizations! Maria is a PhD student in Data Science and AI at the University of Edinburgh. Her broad interests range from programming languages and verification, to machine learning and human-computer interaction. 

More specifically, Maria is interested in probabilistic programming languages, and in exploring ways of applying program-analysis techniques to existing PPLs in order to improve usability of the language or efficiency of inference.

As you’ll hear in the episode, she thinks a lot about the language aspect of probabilistic programming, and works on the automation of various “tricks” in probabilistic programming: automatic re-parametrization, automatic marginalization, automatic and efficient model-specific inference.

As Maria also has experience with several PPLs like Stan, Edward2 and TensorFlow Probability, she’ll tell us what she thinks a good PPL design requires, and what the future of PPLs looks like to her.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Maria on the Web: http://homepages.inf.ed.ac.uk/s1207807/index.html (http://homepages.inf.ed.ac.uk/s1207807/index.html)

 Maria on Twitter: https://twitter.com/migorinova (https://twitter.com/migorinova)

  Maria on GitHub: https://github.com/mgorinova (https://github.com/mgorinova)

  Automatic Reparameterisation of Probabilistic Programs (Maria&apos;s paper with Dave Moore and Matthew Hoffman): https://arxiv.org/abs/1906.03028 (https://arxiv.org/abs/1906.03028)

  Stan User&apos;s Guide on Reparameterization: https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html (https://mc-stan.org/docs/2_23/stan-users-guide/reparameterization-section.html)

  HMC for hierarchical models -- Background on reparameterization: https://arxiv.org/abs/1312.0906 (https://arxiv.org/abs/1312.0906)

  NeuTra -- Automatic reparameterization: https://arxiv.org/abs/1903.03704 (https://arxiv.org/abs/1903.03704)

  Edward2 -- A library for probabilistic modeling, inference, and criticism: http://edwardlib.org/ (http://edwardlib.org/)

  Pyro -- Automatic reparameterization and marginalization: https://pyro.ai/ (https://pyro.ai/)

  Gen -- Programmable inference: http://probcomp.csail.mit.edu/software/gen/ (http://probcomp.csail.mit.edu/software/gen/)

  TensorFlow Probability: https://www.tensorflow.org/probability/ (https://www.tensorflow.org/probability/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#16 Bayesian Statistics the Fun Way, with Will Kurt</title><itunes:title>#16 Bayesian Statistics the Fun Way, with Will Kurt</itunes:title><description><![CDATA[<p>A librarian, a philosopher and a statistician walk into a bar — and they can’t find anybody to talk to; nobody seems to understand what they are talking about. Nobody? No! There is someone, and this someone is Will Kurt!&nbsp;</p><p>Will Kurt is the author of ‘Bayesian Statistics the Fun Way’ and ‘Get Programming With Haskell’. Currently the lead Data Scientist for the pricing and recommendations team at Hopper, he also blogs about stats and probability at <a href="https://www.countbayesie.com" rel="noopener noreferrer" target="_blank">countbayesie.com</a>.</p><p>In this episode, he’ll tell us how a Boston librarian can become a Data Scientist and work with Bayesian models everyday. He’ll also explain the value of Bayesian inference from a philosophical standpoint, why it’s useful in the travel industry and how his latest book came into life.</p><p>Finally, Will is also a big fan of the “mind projection fallacy”, an informal fallacy first described by physicist and Bayesian philosopher Edwin Thompson Jaynes. Does that intrigue you? Well, stay tuned, he’ll tell us more in the episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Will's Blog: <a href="https://www.countbayesie.com" rel="noopener noreferrer" target="_blank">https://www.countbayesie.com</a></li><li>Will on Twitter: <a href="https://twitter.com/willkurt" rel="noopener noreferrer" target="_blank">https://twitter.com/willkurt</a></li><li>Bayesian Statistics the Fun Way -- Understanding Statistics and Probability with Star Wars, LEGO, and Rubber Ducks: <a href="https://nostarch.com/learnbayes" rel="noopener noreferrer" target="_blank">https://nostarch.com/learnbayes</a></li><li>Get Programming with Haskell: <a href="https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768</a></li><li>The Mind Projection Fallacy: <a href="https://en.wikipedia.org/wiki/Mind_projection_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Mind_projection_fallacy</a></li><li>Probability Theory -- The Logic of Science by E.T. Jaynes: <a href="https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99" rel="noopener noreferrer" target="_blank">https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99</a></li><li>Wittgenstein's Lectures on the Foundations of Mathematics: <a href="https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>A librarian, a philosopher and a statistician walk into a bar — and they can’t find anybody to talk to; nobody seems to understand what they are talking about. Nobody? No! There is someone, and this someone is Will Kurt!&nbsp;</p><p>Will Kurt is the author of ‘Bayesian Statistics the Fun Way’ and ‘Get Programming With Haskell’. Currently the lead Data Scientist for the pricing and recommendations team at Hopper, he also blogs about stats and probability at <a href="https://www.countbayesie.com" rel="noopener noreferrer" target="_blank">countbayesie.com</a>.</p><p>In this episode, he’ll tell us how a Boston librarian can become a Data Scientist and work with Bayesian models everyday. He’ll also explain the value of Bayesian inference from a philosophical standpoint, why it’s useful in the travel industry and how his latest book came into life.</p><p>Finally, Will is also a big fan of the “mind projection fallacy”, an informal fallacy first described by physicist and Bayesian philosopher Edwin Thompson Jaynes. Does that intrigue you? Well, stay tuned, he’ll tell us more in the episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Will's Blog: <a href="https://www.countbayesie.com" rel="noopener noreferrer" target="_blank">https://www.countbayesie.com</a></li><li>Will on Twitter: <a href="https://twitter.com/willkurt" rel="noopener noreferrer" target="_blank">https://twitter.com/willkurt</a></li><li>Bayesian Statistics the Fun Way -- Understanding Statistics and Probability with Star Wars, LEGO, and Rubber Ducks: <a href="https://nostarch.com/learnbayes" rel="noopener noreferrer" target="_blank">https://nostarch.com/learnbayes</a></li><li>Get Programming with Haskell: <a href="https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768</a></li><li>The Mind Projection Fallacy: <a href="https://en.wikipedia.org/wiki/Mind_projection_fallacy" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Mind_projection_fallacy</a></li><li>Probability Theory -- The Logic of Science by E.T. Jaynes: <a href="https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99" rel="noopener noreferrer" target="_blank">https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99</a></li><li>Wittgenstein's Lectures on the Foundations of Mathematics: <a href="https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261" rel="noopener noreferrer" target="_blank">https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/16-bayesian-statistics-the-fun-way-with-will-kurt]]></link><guid isPermaLink="false">94742323-9b6e-4ee9-a9c5-2f99f1129681</guid><itunes:image href="https://artwork.captivate.fm/5c210e3c-0d80-47d5-af34-193f8afdb684/YVhBnaQlamPZdBes9G1IwfI7.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 21 May 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c061a432-b66a-4772-9a8f-8c56210c506f/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="97842572" type="audio/mpeg"/><itunes:duration>01:07:57</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>16</itunes:episode><itunes:season>1</itunes:season><podcast:episode>16</podcast:episode><podcast:season>1</podcast:season><itunes:summary>A librarian, a philosopher and a statistician walk into a bar — and they can’t find anybody to talk to; nobody seems to understand what they are talking about. Nobody? No! There is someone, and this someone is Will Kurt! 

Will Kurt is the author of ‘Bayesian Statistics the Fun Way’ and ‘Get Programming With Haskell’. Currently the lead Data Scientist for the pricing and recommendations team at Hopper, he also blogs about stats and probability at https://www.countbayesie.com (countbayesie.com).

In this episode, he’ll tell us how a Boston librarian can become a Data Scientist and work with Bayesian models everyday. He’ll also explain the value of Bayesian inference from a philosophical standpoint, why it’s useful in the travel industry and how his latest book came into life.

Finally, Will is also a big fan of the “mind projection fallacy”, an informal fallacy first described by physicist and Bayesian philosopher Edwin Thompson Jaynes. Does that intrigue you? Well, stay tuned, he’ll tell us more in the episode…

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Will&apos;s Blog: https://www.countbayesie.com (https://www.countbayesie.com)

 Will on Twitter: https://twitter.com/willkurt (https://twitter.com/willkurt)

  Bayesian Statistics the Fun Way -- Understanding Statistics and Probability with Star Wars, LEGO, and Rubber Ducks: https://nostarch.com/learnbayes (https://nostarch.com/learnbayes)

  Get Programming with Haskell: https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768 (https://www.amazon.com/Get-Programming-Haskell-Will-Kurt/dp/1617293768)

  The Mind Projection Fallacy: https://en.wikipedia.org/wiki/Mind_projection_fallacy (https://en.wikipedia.org/wiki/Mind_projection_fallacy)

  Probability Theory -- The Logic of Science by E.T. Jaynes: https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99 (https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99)

  Wittgenstein&apos;s Lectures on the Foundations of Mathematics: https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261 (https://www.amazon.com/Wittgensteins-Lectures-Foundations-Mathematics-Cambridge/dp/0226904261)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#15 The role of Python in Science and Education, with Michael Kennedy</title><itunes:title>#15 The role of Python in Science and Education, with Michael Kennedy</itunes:title><description><![CDATA[<p>This is it folks! This is the first of the special episodes I want to do from time to time, to expand our perspective and get inspired by what’s going on elsewhere. The guests will not come directly from the Bayesian world, but will still be related to science or programming.</p><p>For the first episode of the kind, I had the chance to chat with Michael Kennedy! Michael is not only a very knowledgeable and respected member of the Python community, he’s also the founder and host of Talk Python To Me, the most popular Python podcast. He’s the founder and chief author at Talk Python Training, where he develops many Python developer online courses.&nbsp;</p><p>And before that, Michael was a professional software trainer for over 10 years – he has taught numerous developers throughout the world! But Michael is not only an entrepreneur and teacher – he’s also a father, a husband, and a proud inhabitant of Portland, OR!&nbsp;</p><p>As you’ll hear, our conversation spanned a large array of topics — the role of Python in science and research; how it came to be so important in data science, and why; what are Python’s threats and weaknesses and how it should evolve to not become obsolete. Michael also has interesting thoughts on the role of programming in education and how it relates to geometry — but I’ll let you discover that one by yourself…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Michael on Twitter: <a href="https://twitter.com/mkennedy" rel="noopener noreferrer" target="_blank">https://twitter.com/mkennedy</a></li><li>The Talk Python Podcast: <a href="https://talkpython.fm/" rel="noopener noreferrer" target="_blank">https://talkpython.fm/</a></li><li>The Python Bytes Podcast: <a href="https://pythonbytes.fm/" rel="noopener noreferrer" target="_blank">https://pythonbytes.fm/</a></li><li>Michael's blog: <a href="https://blog.michaelckennedy.net/" rel="noopener noreferrer" target="_blank">https://blog.michaelckennedy.net/</a></li><li>Michael on Crowdcast: <a href="https://www.crowdcast.io/mkennedy" rel="noopener noreferrer" target="_blank">https://www.crowdcast.io/mkennedy</a></li><li>Jupytext -- Turn Jupyter Notebooks to scripts and (R) Markdown files: <a href="https://jupytext.readthedocs.io/en/latest/introduction.html" rel="noopener noreferrer" target="_blank">https://jupytext.readthedocs.io/en/latest/introduction.html</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>This is it folks! This is the first of the special episodes I want to do from time to time, to expand our perspective and get inspired by what’s going on elsewhere. The guests will not come directly from the Bayesian world, but will still be related to science or programming.</p><p>For the first episode of the kind, I had the chance to chat with Michael Kennedy! Michael is not only a very knowledgeable and respected member of the Python community, he’s also the founder and host of Talk Python To Me, the most popular Python podcast. He’s the founder and chief author at Talk Python Training, where he develops many Python developer online courses.&nbsp;</p><p>And before that, Michael was a professional software trainer for over 10 years – he has taught numerous developers throughout the world! But Michael is not only an entrepreneur and teacher – he’s also a father, a husband, and a proud inhabitant of Portland, OR!&nbsp;</p><p>As you’ll hear, our conversation spanned a large array of topics — the role of Python in science and research; how it came to be so important in data science, and why; what are Python’s threats and weaknesses and how it should evolve to not become obsolete. Michael also has interesting thoughts on the role of programming in education and how it relates to geometry — but I’ll let you discover that one by yourself…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Michael on Twitter: <a href="https://twitter.com/mkennedy" rel="noopener noreferrer" target="_blank">https://twitter.com/mkennedy</a></li><li>The Talk Python Podcast: <a href="https://talkpython.fm/" rel="noopener noreferrer" target="_blank">https://talkpython.fm/</a></li><li>The Python Bytes Podcast: <a href="https://pythonbytes.fm/" rel="noopener noreferrer" target="_blank">https://pythonbytes.fm/</a></li><li>Michael's blog: <a href="https://blog.michaelckennedy.net/" rel="noopener noreferrer" target="_blank">https://blog.michaelckennedy.net/</a></li><li>Michael on Crowdcast: <a href="https://www.crowdcast.io/mkennedy" rel="noopener noreferrer" target="_blank">https://www.crowdcast.io/mkennedy</a></li><li>Jupytext -- Turn Jupyter Notebooks to scripts and (R) Markdown files: <a href="https://jupytext.readthedocs.io/en/latest/introduction.html" rel="noopener noreferrer" target="_blank">https://jupytext.readthedocs.io/en/latest/introduction.html</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/15-the-role-of-python-in-science-and-education-with-michael-kennedy]]></link><guid isPermaLink="false">aba82a75-baf8-4161-a992-a2a17845b8e6</guid><itunes:image href="https://artwork.captivate.fm/af5ded7e-103e-424c-b12b-ae0971024621/7PKc2b5z6yAEqLXfsQyVr_rS.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 06 May 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/be68439e-93c1-4577-b2f3-ce1982c8376a/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="158116048" type="audio/mpeg"/><itunes:duration>01:05:53</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>15</itunes:episode><itunes:season>1</itunes:season><podcast:episode>15</podcast:episode><podcast:season>1</podcast:season><itunes:summary>This is it folks! This is the first of the special episodes I want to do from time to time, to expand our perspective and get inspired by what’s going on elsewhere. The guests will not come directly from the Bayesian world, but will still be related to science or programming.

For the first episode of the kind, I had the chance to chat with Michael Kennedy! Michael is not only a very knowledgeable and respected member of the Python community, he’s also the founder and host of Talk Python To Me, the most popular Python podcast. He’s the founder and chief author at Talk Python Training, where he develops many Python developer online courses. 

And before that, Michael was a professional software trainer for over 10 years – he has taught numerous developers throughout the world! But Michael is not only an entrepreneur and teacher – he’s also a father, a husband, and a proud inhabitant of Portland, OR! 

As you’ll hear, our conversation spanned a large array of topics — the role of Python in science and research; how it came to be so important in data science, and why; what are Python’s threats and weaknesses and how it should evolve to not become obsolete. Michael also has interesting thoughts on the role of programming in education and how it relates to geometry — but I’ll let you discover that one by yourself…

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Michael on Twitter: https://twitter.com/mkennedy (https://twitter.com/mkennedy)

 The Talk Python Podcast: https://talkpython.fm/ (https://talkpython.fm/)

  The Python Bytes Podcast: https://pythonbytes.fm/ (https://pythonbytes.fm/)

  Michael&apos;s blog: https://blog.michaelckennedy.net/ (https://blog.michaelckennedy.net/)

  Michael on Crowdcast: https://www.crowdcast.io/mkennedy (https://www.crowdcast.io/mkennedy)

  Jupytext -- Turn Jupyter Notebooks to scripts and (R) Markdown files: https://jupytext.readthedocs.io/en/latest/introduction.html (https://jupytext.readthedocs.io/en/latest/introduction.html)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#14 Hidden Markov Models &amp; Statistical Ecology, with Vianey Leos-Barajas</title><itunes:title>#14 Hidden Markov Models &amp; Statistical Ecology, with Vianey Leos-Barajas</itunes:title><description><![CDATA[<p>I bet you love penguins, right? The same goes for koalas, or puppies! But what about sharks? Well, my next guest loves sharks — she loves them so much that she works a lot with marine biologists, even though she’s a statistician!&nbsp;</p><p>Vianey Leos Barajas is indeed a statistician primarily working in the areas of statistical ecology, time series modeling, Bayesian inference and spatial modeling of environmental data. Vianey did her PhD in statistics at Iowa State University and is now a postdoctoral researcher at North Carolina State University.</p><p>In this episode, she’ll tell us what she’s working on that involves sharks, sheep and other animals! Trying to model animal movements, Vianey often encounters the dreaded multimodal posteriors. She’ll explain why these can be very tricky to estimate, and why ecological data are particularly suited for hidden Markov models and spatio-temporal models — don’t worry, Vianey will explain what these models are in the episode!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Vianey on Twitter: <a href="https://twitter.com/vianey_lb" rel="noopener noreferrer" target="_blank">https://twitter.com/vianey_lb</a></li><li>Hidden Markov Models in the Stan User's Guide: <a href="https://mc-stan.org/docs/2_18/stan-users-guide/hmms-section.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/docs/2_18/stan-users-guide/hmms-section.html</a></li><li>Tagging Basketball Events with HMM in Stan: <a href="https://mc-stan.org/users/documentation/case-studies/bball-hmm.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/users/documentation/case-studies/bball-hmm.html</a></li><li>HMMs with Python and PyMC3: https://ericmjl.github.io/bayesian-analysis-recipes/notebooks/markov-models/</li><li>The Discrete Adjoint Method -- Efficient Derivatives for Functions of Discrete Sequences (Betancourt, Margossian, Leos-Barajas): <a href="https://arxiv.org/abs/2002.00326" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2002.00326</a></li><li>Vianey will be doing an HMM 90-minute introduction at the International Statistical Ecology Conference in June 2020: <a href="http://www.isec2020.org/" rel="noopener noreferrer" target="_blank">http://www.isec2020.org/</a></li><li>Stan for Ecology -- a website for the ecology community in Stan: <a href="https://stanecology.github.io/" rel="noopener noreferrer" target="_blank">https://stanecology.github.io/</a></li><li>LatinR 2020 -- 7th to 9th October 2020: <a href="https://latin-r.com/" rel="noopener noreferrer" target="_blank">https://latin-r.com/</a></li><li>Migramar -- Science for the Conservation of Marine Migratory Species in the Eastern Pacific: <a href="http://migramar.org/hi/en/" rel="noopener noreferrer" target="_blank">http://migramar.org/hi/en/</a></li><li>Pelagios Kakunja -- Know, educate and conserve for a&nbsp;sustainable sea: <a href="https://www.pelagioskakunja.org/" rel="noopener noreferrer" target="_blank">https://www.pelagioskakunja.org/</a></li></ul><br/><p><strong>Book recommendations</strong>:</p><ul><li>Hidden Markov Models for Time Series: <a href="https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832</a></li><li>Handbook of Mixture Analysis: <a href="https://www.routledge.com/Handbook-of-Mixture-Analysis-1st-Edition/Fruhwirth-Schnatter-Celeux-Robert/p/book/9781498763813" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>I bet you love penguins, right? The same goes for koalas, or puppies! But what about sharks? Well, my next guest loves sharks — she loves them so much that she works a lot with marine biologists, even though she’s a statistician!&nbsp;</p><p>Vianey Leos Barajas is indeed a statistician primarily working in the areas of statistical ecology, time series modeling, Bayesian inference and spatial modeling of environmental data. Vianey did her PhD in statistics at Iowa State University and is now a postdoctoral researcher at North Carolina State University.</p><p>In this episode, she’ll tell us what she’s working on that involves sharks, sheep and other animals! Trying to model animal movements, Vianey often encounters the dreaded multimodal posteriors. She’ll explain why these can be very tricky to estimate, and why ecological data are particularly suited for hidden Markov models and spatio-temporal models — don’t worry, Vianey will explain what these models are in the episode!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Vianey on Twitter: <a href="https://twitter.com/vianey_lb" rel="noopener noreferrer" target="_blank">https://twitter.com/vianey_lb</a></li><li>Hidden Markov Models in the Stan User's Guide: <a href="https://mc-stan.org/docs/2_18/stan-users-guide/hmms-section.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/docs/2_18/stan-users-guide/hmms-section.html</a></li><li>Tagging Basketball Events with HMM in Stan: <a href="https://mc-stan.org/users/documentation/case-studies/bball-hmm.html" rel="noopener noreferrer" target="_blank">https://mc-stan.org/users/documentation/case-studies/bball-hmm.html</a></li><li>HMMs with Python and PyMC3: https://ericmjl.github.io/bayesian-analysis-recipes/notebooks/markov-models/</li><li>The Discrete Adjoint Method -- Efficient Derivatives for Functions of Discrete Sequences (Betancourt, Margossian, Leos-Barajas): <a href="https://arxiv.org/abs/2002.00326" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2002.00326</a></li><li>Vianey will be doing an HMM 90-minute introduction at the International Statistical Ecology Conference in June 2020: <a href="http://www.isec2020.org/" rel="noopener noreferrer" target="_blank">http://www.isec2020.org/</a></li><li>Stan for Ecology -- a website for the ecology community in Stan: <a href="https://stanecology.github.io/" rel="noopener noreferrer" target="_blank">https://stanecology.github.io/</a></li><li>LatinR 2020 -- 7th to 9th October 2020: <a href="https://latin-r.com/" rel="noopener noreferrer" target="_blank">https://latin-r.com/</a></li><li>Migramar -- Science for the Conservation of Marine Migratory Species in the Eastern Pacific: <a href="http://migramar.org/hi/en/" rel="noopener noreferrer" target="_blank">http://migramar.org/hi/en/</a></li><li>Pelagios Kakunja -- Know, educate and conserve for a&nbsp;sustainable sea: <a href="https://www.pelagioskakunja.org/" rel="noopener noreferrer" target="_blank">https://www.pelagioskakunja.org/</a></li></ul><br/><p><strong>Book recommendations</strong>:</p><ul><li>Hidden Markov Models for Time Series: <a href="https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832</a></li><li>Handbook of Mixture Analysis: <a href="https://www.routledge.com/Handbook-of-Mixture-Analysis-1st-Edition/Fruhwirth-Schnatter-Celeux-Robert/p/book/9781498763813" rel="noopener noreferrer" target="_blank">https://www.routledge.com/Handbook-of-Mixture-Analysis-1st-Edition/Fruhwirth-Schnatter-Celeux-Robert/p/book/9781498763813</a></li><li>Pattern Recognition and Machine Learning: <a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf" rel="noopener noreferrer" target="_blank">http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas]]></link><guid isPermaLink="false">a0879ce2-25a4-416b-833a-3d5f812b9416</guid><itunes:image href="https://artwork.captivate.fm/ad552544-73c9-49aa-b8c2-f873f89da04f/YOUb_9ouX-D-hUJE1E2zCQdi.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 22 Apr 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c4a7ac65-d3e7-4c2d-bfdf-fb72555245a5/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="70596345" type="audio/mpeg"/><itunes:duration>49:01</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>14</itunes:episode><itunes:season>1</itunes:season><podcast:episode>14</podcast:episode><podcast:season>1</podcast:season><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#13 Building a Probabilistic Programming Framework in Julia, with Chad Scherrer</title><itunes:title>#13 Building a Probabilistic Programming Framework in Julia, with Chad Scherrer</itunes:title><description><![CDATA[<p>How is Julia doing? I’m talking about the programming language, of course! What does the probabilistic programming landscape in Julia look like? What are Julia’s distinctive features, and when would it be interesting to use it?</p><p>To talk about that, I invited Chad Scherrer. Chad is a Senior Research Scientist at RelationalAI, a company that uses Artificial Intelligence technologies to solve business problems.</p><p>Coming from a mathematics background, Chad did his PhD at Indiana University of Bloomington and has been working in statistics and data science for a decade now. Through this experience, he’s been using and developing probabilistic programming languages – so he’s familiar with python, R, PyMC, Stan and all the blockbusters of the field.&nbsp;</p><p>But since 2018, he’s particularly interested in Julia and developed Soss, an open-source lightweight probabilistic programming package for Julia. In this episode, he’ll tell us why he decided to create this package, and which choices he made that made Soss what it is today. But we’ll also talk about other projects in Julia, like Turing or Gen for instance.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Chad's Website: <a href="https://cscherrer.github.io/" rel="noopener noreferrer" target="_blank">https://cscherrer.github.io/</a></li><li>Chad on Twitter: <a href="https://twitter.com/ChadScherrer" rel="noopener noreferrer" target="_blank">https://twitter.com/ChadScherrer</a></li><li>Soss Package: <a href="https://github.com/cscherrer/Soss.jl" rel="noopener noreferrer" target="_blank">https://github.com/cscherrer/Soss.jl</a></li><li>Soss Presentation at 2019 Strata NYC: <a href="https://slides.com/cscherrer/2019-09-26-strata#/" rel="noopener noreferrer" target="_blank">https://slides.com/cscherrer/2019-09-26-strata#/</a></li><li>Passage -- A Parallel Sampler Generator for Hierarchical Bayesian Modeling: <a href="https://bit.ly/2UTmaYB" rel="noopener noreferrer" target="_blank">https://bit.ly/2UTmaYB</a></li><li>Dynamic HMC in Julia: <a href="https://github.com/tpapp/DynamicHMC.jl" rel="noopener noreferrer" target="_blank">https://github.com/tpapp/DynamicHMC.jl</a></li><li>Advanced HMC in Julia: <a href="https://github.com/TuringLang/AdvancedHMC.jl" rel="noopener noreferrer" target="_blank">https://github.com/TuringLang/AdvancedHMC.jl</a></li><li>Monte Carlo Measurements in Julia: <a href="https://github.com/baggepinnen/MonteCarloMeasurements.jl" rel="noopener noreferrer" target="_blank">https://github.com/baggepinnen/MonteCarloMeasurements.jl</a></li><li>Turing.jl -- Bayesian inference with probabilistic programming: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Gen.jl -- Probabilistic modeling and inference in Julia: <a href="https://www.gen.dev/" rel="noopener noreferrer" target="_blank">https://www.gen.dev/</a></li><li>Etalumis -- Bringing Probabilistic Programming to Scientific Simulators at Scale: <a href="https://arxiv.org/abs/1907.03382" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1907.03382</a></li><li>Omega.jl -- A programming language for causal and probabilistic reasoning: <a href="http://www.zenna.org/Omega.jl/latest/" rel="noopener noreferrer" target="_blank">http://www.zenna.org/Omega.jl/latest/</a></li><li>JuliaLang -- The Ingredients for a Composable Programming Language: <a href="https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html" rel="noopener noreferrer" target="_blank">https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html</a></li><li>Simpy -- Discrete event simulation for Python: <a href="https://simpy.readthedocs.io/en/latest/" rel="noopener noreferrer"...]]></description><content:encoded><![CDATA[<p>How is Julia doing? I’m talking about the programming language, of course! What does the probabilistic programming landscape in Julia look like? What are Julia’s distinctive features, and when would it be interesting to use it?</p><p>To talk about that, I invited Chad Scherrer. Chad is a Senior Research Scientist at RelationalAI, a company that uses Artificial Intelligence technologies to solve business problems.</p><p>Coming from a mathematics background, Chad did his PhD at Indiana University of Bloomington and has been working in statistics and data science for a decade now. Through this experience, he’s been using and developing probabilistic programming languages – so he’s familiar with python, R, PyMC, Stan and all the blockbusters of the field.&nbsp;</p><p>But since 2018, he’s particularly interested in Julia and developed Soss, an open-source lightweight probabilistic programming package for Julia. In this episode, he’ll tell us why he decided to create this package, and which choices he made that made Soss what it is today. But we’ll also talk about other projects in Julia, like Turing or Gen for instance.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Chad's Website: <a href="https://cscherrer.github.io/" rel="noopener noreferrer" target="_blank">https://cscherrer.github.io/</a></li><li>Chad on Twitter: <a href="https://twitter.com/ChadScherrer" rel="noopener noreferrer" target="_blank">https://twitter.com/ChadScherrer</a></li><li>Soss Package: <a href="https://github.com/cscherrer/Soss.jl" rel="noopener noreferrer" target="_blank">https://github.com/cscherrer/Soss.jl</a></li><li>Soss Presentation at 2019 Strata NYC: <a href="https://slides.com/cscherrer/2019-09-26-strata#/" rel="noopener noreferrer" target="_blank">https://slides.com/cscherrer/2019-09-26-strata#/</a></li><li>Passage -- A Parallel Sampler Generator for Hierarchical Bayesian Modeling: <a href="https://bit.ly/2UTmaYB" rel="noopener noreferrer" target="_blank">https://bit.ly/2UTmaYB</a></li><li>Dynamic HMC in Julia: <a href="https://github.com/tpapp/DynamicHMC.jl" rel="noopener noreferrer" target="_blank">https://github.com/tpapp/DynamicHMC.jl</a></li><li>Advanced HMC in Julia: <a href="https://github.com/TuringLang/AdvancedHMC.jl" rel="noopener noreferrer" target="_blank">https://github.com/TuringLang/AdvancedHMC.jl</a></li><li>Monte Carlo Measurements in Julia: <a href="https://github.com/baggepinnen/MonteCarloMeasurements.jl" rel="noopener noreferrer" target="_blank">https://github.com/baggepinnen/MonteCarloMeasurements.jl</a></li><li>Turing.jl -- Bayesian inference with probabilistic programming: <a href="https://turing.ml/dev/" rel="noopener noreferrer" target="_blank">https://turing.ml/dev/</a></li><li>Gen.jl -- Probabilistic modeling and inference in Julia: <a href="https://www.gen.dev/" rel="noopener noreferrer" target="_blank">https://www.gen.dev/</a></li><li>Etalumis -- Bringing Probabilistic Programming to Scientific Simulators at Scale: <a href="https://arxiv.org/abs/1907.03382" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1907.03382</a></li><li>Omega.jl -- A programming language for causal and probabilistic reasoning: <a href="http://www.zenna.org/Omega.jl/latest/" rel="noopener noreferrer" target="_blank">http://www.zenna.org/Omega.jl/latest/</a></li><li>JuliaLang -- The Ingredients for a Composable Programming Language: <a href="https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html" rel="noopener noreferrer" target="_blank">https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html</a></li><li>Simpy -- Discrete event simulation for Python: <a href="https://simpy.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://simpy.readthedocs.io/en/latest/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/13-building-a-probabilistic-programming-framework-in-julia-with-chad-scherrer]]></link><guid isPermaLink="false">7d00ff2d-87c2-4c11-bb50-298bd8515a4d</guid><itunes:image href="https://artwork.captivate.fm/da778c9d-8c6f-4a0f-8e1f-0006bc148f24/SIx8VXWeI_tIydztFryhPDeS.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 08 Apr 2020 06:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/93ecd7a0-4854-42cc-81c0-c567fe195c80/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="63162589" type="audio/mpeg"/><itunes:duration>43:51</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>13</itunes:episode><itunes:season>1</itunes:season><podcast:episode>13</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How is Julia doing? I’m talking about the programming language, of course! What does the probabilistic programming landscape in Julia look like? What are Julia’s distinctive features, and when would it be interesting to use it?

To talk about that, I invited Chad Scherrer. Chad is a Senior Research Scientist at RelationalAI, a company that uses Artificial Intelligence technologies to solve business problems.

Coming from a mathematics background, Chad did his PhD at Indiana University of Bloomington and has been working in statistics and data science for a decade now. Through this experience, he’s been using and developing probabilistic programming languages – so he’s familiar with python, R, PyMC, Stan and all the blockbusters of the field. 

But since 2018, he’s particularly interested in Julia and developed Soss, an open-source lightweight probabilistic programming package for Julia. In this episode, he’ll tell us why he decided to create this package, and which choices he made that made Soss what it is today. But we’ll also talk about other projects in Julia, like Turing or Gen for instance.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Chad&apos;s Website: https://cscherrer.github.io/ (https://cscherrer.github.io/)

 Chad on Twitter: https://twitter.com/ChadScherrer (https://twitter.com/ChadScherrer)

  Soss Package: https://github.com/cscherrer/Soss.jl (https://github.com/cscherrer/Soss.jl)

  Soss Presentation at 2019 Strata NYC: https://slides.com/cscherrer/2019-09-26-strata#/ (https://slides.com/cscherrer/2019-09-26-strata#/)

  Passage -- A Parallel Sampler Generator for Hierarchical Bayesian Modeling: https://bit.ly/2UTmaYB (https://bit.ly/2UTmaYB)

  Dynamic HMC in Julia: https://github.com/tpapp/DynamicHMC.jl (https://github.com/tpapp/DynamicHMC.jl)

  Advanced HMC in Julia: https://github.com/TuringLang/AdvancedHMC.jl (https://github.com/TuringLang/AdvancedHMC.jl)

  Monte Carlo Measurements in Julia: https://github.com/baggepinnen/MonteCarloMeasurements.jl (https://github.com/baggepinnen/MonteCarloMeasurements.jl)

  Turing.jl -- Bayesian inference with probabilistic programming: https://turing.ml/dev/ (https://turing.ml/dev/)

  Gen.jl -- Probabilistic modeling and inference in Julia: https://www.gen.dev/ (https://www.gen.dev/)

  Etalumis -- Bringing Probabilistic Programming to Scientific Simulators at Scale: https://arxiv.org/abs/1907.03382 (https://arxiv.org/abs/1907.03382)

  Omega.jl -- A programming language for causal and probabilistic reasoning: http://www.zenna.org/Omega.jl/latest/ (http://www.zenna.org/Omega.jl/latest/)

  JuliaLang -- The Ingredients for a Composable Programming Language: https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html (https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html)

  Simpy -- Discrete event simulation for Python: https://simpy.readthedocs.io/en/latest/ (https://simpy.readthedocs.io/en/latest/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#12 Biostatistics and Differential Equations, with Demetri Pananos</title><itunes:title>#12 Biostatistics and Differential Equations, with Demetri Pananos</itunes:title><description><![CDATA[<p>Do you know Google Summer of Code? It’s a time of year when students can contribute to open-source software by developing and adding much needed functionalities to the open-source package of their choice. And Demetri Pananos did just that.</p><p>He did it in 2019 with PyMC3, for which he developed the API for ordinary differential equations. In this episode, he’ll tell us why and how he did that, what he learned from the experience, and what the strengths and weaknesses of the API are in his opinion.</p><p>Demetri is a Ph.D candidate in Biostatistics at Western University, in Ontario, Canada. His research interests surround machine learning and Bayesian statistics for personalized medicine. He earned his Master’s in Applied Mathematics from The University of Waterloo and is a firm believer in open science, interdisciplinary collaboration, and reproducible research.&nbsp;</p><p>Other than that, he loves plotting data and drinking IPA beer – well, who doesn’t?”</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Demetri on Twitter: <a href="https://twitter.com/PhDemetri" rel="noopener noreferrer" target="_blank">https://twitter.com/PhDemetri</a></li><li>Demetri on GitHub: <a href="https://github.com/Dpananos" rel="noopener noreferrer" target="_blank">https://github.com/Dpananos</a></li><li>Demetri's website: <a href="https://dpananos.github.io/" rel="noopener noreferrer" target="_blank">https://dpananos.github.io/</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Chris Bishop, Pattern Recognition and Machine Learning: <a href="https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738" rel="noopener noreferrer" target="_blank">https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738</a></li><li>Bayesian Data Analysis (Gelman, Carlin, Stern, Dunson, Vehtari, Rubin): <a href="http://www.stat.columbia.edu/~gelman/book/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/book/</a></li><li>Parallel Plots: <a href="https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>Do you know Google Summer of Code? It’s a time of year when students can contribute to open-source software by developing and adding much needed functionalities to the open-source package of their choice. And Demetri Pananos did just that.</p><p>He did it in 2019 with PyMC3, for which he developed the API for ordinary differential equations. In this episode, he’ll tell us why and how he did that, what he learned from the experience, and what the strengths and weaknesses of the API are in his opinion.</p><p>Demetri is a Ph.D candidate in Biostatistics at Western University, in Ontario, Canada. His research interests surround machine learning and Bayesian statistics for personalized medicine. He earned his Master’s in Applied Mathematics from The University of Waterloo and is a firm believer in open science, interdisciplinary collaboration, and reproducible research.&nbsp;</p><p>Other than that, he loves plotting data and drinking IPA beer – well, who doesn’t?”</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Demetri on Twitter: <a href="https://twitter.com/PhDemetri" rel="noopener noreferrer" target="_blank">https://twitter.com/PhDemetri</a></li><li>Demetri on GitHub: <a href="https://github.com/Dpananos" rel="noopener noreferrer" target="_blank">https://github.com/Dpananos</a></li><li>Demetri's website: <a href="https://dpananos.github.io/" rel="noopener noreferrer" target="_blank">https://dpananos.github.io/</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Chris Bishop, Pattern Recognition and Machine Learning: <a href="https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738" rel="noopener noreferrer" target="_blank">https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738</a></li><li>Bayesian Data Analysis (Gelman, Carlin, Stern, Dunson, Vehtari, Rubin): <a href="http://www.stat.columbia.edu/~gelman/book/" rel="noopener noreferrer" target="_blank">http://www.stat.columbia.edu/~gelman/book/</a></li><li>Parallel Plots: <a href="https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/12-biostatistics-and-differential-equations-with-demetri-pananos]]></link><guid isPermaLink="false">https://anchor.fm/learn-bayes-stats/episodes/12-Biostatistics-and-Differential-Equations--with-Demetri-Pananos-ebsl4n</guid><itunes:image href="https://artwork.captivate.fm/6d0b011b-6294-4a8a-95b0-5a5546c5ca89/v0AM3Yj6vnLGGdzJzZxHZCsI.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 25 Mar 2020 07:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/85498d61-5d51-4354-b615-872c88eaea8f/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="66973431" type="audio/mpeg"/><itunes:duration>46:31</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>12</itunes:episode><itunes:season>1</itunes:season><podcast:episode>12</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Do you know Google Summer of Code? It’s a time of year when students can contribute to open-source software by developing and adding much needed functionalities to the open-source package of their choice. And Demetri Pananos did just that.

He did it in 2019 with PyMC3, for which he developed the API for ordinary differential equations. In this episode, he’ll tell us why and how he did that, what he learned from the experience, and what the strengths and weaknesses of the API are in his opinion.

Demetri is a Ph.D candidate in Biostatistics at Western University, in Ontario, Canada. His research interests surround machine learning and Bayesian statistics for personalized medicine. He earned his Master’s in Applied Mathematics from The University of Waterloo and is a firm believer in open science, interdisciplinary collaboration, and reproducible research. 

Other than that, he loves plotting data and drinking IPA beer – well, who doesn’t?”

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Demetri on Twitter: https://twitter.com/PhDemetri (https://twitter.com/PhDemetri)

 Demetri on GitHub: https://github.com/Dpananos (https://github.com/Dpananos)

  Demetri&apos;s website: https://dpananos.github.io/ (https://dpananos.github.io/)

  PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Chris Bishop, Pattern Recognition and Machine Learning: https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738 (https://www.amazon.fr/Pattern-Recognition-Machine-Learning-Christopher/dp/0387310738)

  Bayesian Data Analysis (Gelman, Carlin, Stern, Dunson, Vehtari, Rubin): http://www.stat.columbia.edu/~gelman/book/ (http://www.stat.columbia.edu/~gelman/book/)

  Parallel Plots: https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html (https://arviz-devs.github.io/arviz/generated/arviz.plot_parallel.html)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#11 Taking care of your Hierarchical Models, with Thomas Wiecki</title><itunes:title>#11 Taking care of your Hierarchical Models, with Thomas Wiecki</itunes:title><description><![CDATA[<p>I bet you already heard about hierarchical models, or multilevel models, or varying-effects models — yeah this type of models has a lot of names! Many people even turn to Bayesian tools to build _exactly_ these models. But what are they? How do you build and use a hierarchical model? What are the tricks and classical traps? And even more important: how do you _interpret_ a hierarchical model?</p><p>In this episode, Thomas Wiecki will come to the rescue and explain what multilevel models are, how to build them, what their powers are… but also why you should be very careful when building them…</p><p>Does the name Thomas Wiecki ring a bell? Probably because he’s the host and creator of the PyData Deep Dive Podcast, where he interviews open-source contributors from the Python and Data Science worlds! Thomas is also the VP of Data Science at Quantopian, a crowd-sourced quantitative investment firm that encourages people everywhere to write investment algorithms.</p><p>Finally, Thomas is a longtime Bayesian and core-developer of PyMC3, a fantastic python package to do probabilistic programming in Python. On his blog, he publishes tutorial articles and explores new ideas such as Bayesian Deep Learning. Caring a lot about open-source software sustainability, he puts all he’s up to on his Patreon page, that you’ll find in the show notes.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Thomas’ series on Hierarchical Regression: <a href="https://twiecki.io/blog/2013/08/12/bayesian-glms-1/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2013/08/12/bayesian-glms-1/</a></li><li>Non-centered Parametrization with PyMC3: <a href="https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/</a></li><li>Using Bayesian Decision Making: <a href="https://twiecki.io/blog/2019/01/14/supply_chain/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2019/01/14/supply_chain/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Symbolic PyMC: <a href="https://pymc-devs.github.io/symbolic-pymc/" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/symbolic-pymc/</a></li><li>PyData Deep Dive Podcast: <a href="https://pydata-podcast.com" rel="noopener noreferrer" target="_blank">https://pydata-podcast.com</a></li><li>Thomas on Twitter: <a href="https://twitter.com/twiecki?lang=en" rel="noopener noreferrer" target="_blank">https://twitter.com/twiecki?lang=en</a></li><li>Thomas on Patreon: <a href="https://www.patreon.com/twiecki" rel="noopener noreferrer" target="_blank">https://www.patreon.com/twiecki</a></li><li>Thomas on GitHub: <a href="https://github.com/twiecki" rel="noopener noreferrer" target="_blank">https://github.com/twiecki</a></li><li>Alex’s Hierarchical Model of Elections in Paris: <a href="https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb" rel="noopener noreferrer" target="_blank">https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>I bet you already heard about hierarchical models, or multilevel models, or varying-effects models — yeah this type of models has a lot of names! Many people even turn to Bayesian tools to build _exactly_ these models. But what are they? How do you build and use a hierarchical model? What are the tricks and classical traps? And even more important: how do you _interpret_ a hierarchical model?</p><p>In this episode, Thomas Wiecki will come to the rescue and explain what multilevel models are, how to build them, what their powers are… but also why you should be very careful when building them…</p><p>Does the name Thomas Wiecki ring a bell? Probably because he’s the host and creator of the PyData Deep Dive Podcast, where he interviews open-source contributors from the Python and Data Science worlds! Thomas is also the VP of Data Science at Quantopian, a crowd-sourced quantitative investment firm that encourages people everywhere to write investment algorithms.</p><p>Finally, Thomas is a longtime Bayesian and core-developer of PyMC3, a fantastic python package to do probabilistic programming in Python. On his blog, he publishes tutorial articles and explores new ideas such as Bayesian Deep Learning. Caring a lot about open-source software sustainability, he puts all he’s up to on his Patreon page, that you’ll find in the show notes.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Thomas’ series on Hierarchical Regression: <a href="https://twiecki.io/blog/2013/08/12/bayesian-glms-1/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2013/08/12/bayesian-glms-1/</a></li><li>Non-centered Parametrization with PyMC3: <a href="https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/</a></li><li>Using Bayesian Decision Making: <a href="https://twiecki.io/blog/2019/01/14/supply_chain/" rel="noopener noreferrer" target="_blank">https://twiecki.io/blog/2019/01/14/supply_chain/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Symbolic PyMC: <a href="https://pymc-devs.github.io/symbolic-pymc/" rel="noopener noreferrer" target="_blank">https://pymc-devs.github.io/symbolic-pymc/</a></li><li>PyData Deep Dive Podcast: <a href="https://pydata-podcast.com" rel="noopener noreferrer" target="_blank">https://pydata-podcast.com</a></li><li>Thomas on Twitter: <a href="https://twitter.com/twiecki?lang=en" rel="noopener noreferrer" target="_blank">https://twitter.com/twiecki?lang=en</a></li><li>Thomas on Patreon: <a href="https://www.patreon.com/twiecki" rel="noopener noreferrer" target="_blank">https://www.patreon.com/twiecki</a></li><li>Thomas on GitHub: <a href="https://github.com/twiecki" rel="noopener noreferrer" target="_blank">https://github.com/twiecki</a></li><li>Alex’s Hierarchical Model of Elections in Paris: <a href="https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb" rel="noopener noreferrer" target="_blank">https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/11-taking-care-of-your-hierarchical-models-with-thomas-wiecki]]></link><guid isPermaLink="false">https://anchor.fm/learn-bayes-stats/episodes/11-Taking-care-of-your-Hierarchical-Models--with-Thomas-Wiecki-ebeg5q</guid><itunes:image href="https://artwork.captivate.fm/ef4922f9-c572-4541-8b30-73d3809419a1/Wb3BED74MDcwSnDYTKeW04Fs.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 11 Mar 2020 15:30:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b0ac1a96-ae7f-4ac7-84c4-ec391b661dcf/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="83602713" type="audio/mpeg"/><itunes:duration>58:02</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>11</itunes:episode><itunes:season>1</itunes:season><podcast:episode>11</podcast:episode><podcast:season>1</podcast:season><itunes:summary>I bet you already heard about hierarchical models, or multilevel models, or varying-effects models — yeah this type of models has a lot of names! Many people even turn to Bayesian tools to build _exactly_ these models. But what are they? How do you build and use a hierarchical model? What are the tricks and classical traps? And even more important: how do you _interpret_ a hierarchical model?

In this episode, Thomas Wiecki will come to the rescue and explain what multilevel models are, how to build them, what their powers are… but also why you should be very careful when building them…

Does the name Thomas Wiecki ring a bell? Probably because he’s the host and creator of the PyData Deep Dive Podcast, where he interviews open-source contributors from the Python and Data Science worlds! Thomas is also the VP of Data Science at Quantopian, a crowd-sourced quantitative investment firm that encourages people everywhere to write investment algorithms.

Finally, Thomas is a longtime Bayesian and core-developer of PyMC3, a fantastic python package to do probabilistic programming in Python. On his blog, he publishes tutorial articles and explores new ideas such as Bayesian Deep Learning. Caring a lot about open-source software sustainability, he puts all he’s up to on his Patreon page, that you’ll find in the show notes.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Thomas’ series on Hierarchical Regression: https://twiecki.io/blog/2013/08/12/bayesian-glms-1/ (https://twiecki.io/blog/2013/08/12/bayesian-glms-1/)

 Non-centered Parametrization with PyMC3: https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/ (https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/)

  Using Bayesian Decision Making: https://twiecki.io/blog/2019/01/14/supply_chain/ (https://twiecki.io/blog/2019/01/14/supply_chain/)

  PyMC3 - Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Symbolic PyMC: https://pymc-devs.github.io/symbolic-pymc/ (https://pymc-devs.github.io/symbolic-pymc/)

  PyData Deep Dive Podcast: https://pydata-podcast.com (https://pydata-podcast.com)

  Thomas on Twitter: https://twitter.com/twiecki?lang=en (https://twitter.com/twiecki?lang=en)

  Thomas on Patreon: https://www.patreon.com/twiecki (https://www.patreon.com/twiecki)

  Thomas on GitHub: https://github.com/twiecki (https://github.com/twiecki)

  Alex’s Hierarchical Model of Elections in Paris: https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb (https://mybinder.org/v2/gh/AlexAndorra/pollsposition_models/master?urlpath=%2Fvoila%2Frender%2Fdistrict-level%2Fmunic_model_analysis.ipynb)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#10 Exploratory Analysis of Bayesian Models, with ArviZ and Ari Hartikainen</title><itunes:title>#10 Exploratory Analysis of Bayesian Models, with ArviZ and Ari Hartikainen</itunes:title><description><![CDATA[<p>How do you handle your MCMC samples once your Bayesian model fit properly? Which diagnostics do you check to see if there was a computational problem? And isn’t that nice when you have beautiful and reliable plots to complement your analysis and better understand your model?</p><p>I know what you think: plotting can be long and complicated in these cases. Well, not with ArviZ, a platform-agnostic package to do exploratory analysis of your Bayesian models. And in this episode, Ari Hartikainen will tell you why.</p><p>Ari is a data-scientist in geophysics and a researcher at the Department of Civil Engineering of Aalto University in Finland. He mainly works on geophysics, Bayesian statistics and visualization.&nbsp;</p><p>Ari’s also a prolific open-source contributor, as he’s a core-developer of the popular Stan and ArviZ libraries. He’ll tell us how PyStan interacts with ArviZ, what he thinks ArviZ most useful features are, and which common difficulties he encounters with his models and data.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Ari on GitHub: <a href="https://github.com/ahartikainen" rel="noopener noreferrer" target="_blank">https://github.com/ahartikainen</a></li><li>Ari on Twitter: <a href="https://twitter.com/a_hartikainen" rel="noopener noreferrer" target="_blank">https://twitter.com/a_hartikainen</a></li><li>ArviZ -- Exploratory analysis of Bayesian models: <a href="https://arviz-devs.github.io/arviz/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/</a></li><li>Introductory paper of ArviZ in <em>The Journal of Open Source Software</em>: <a href="https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python</a></li><li>Stan -- Statistical Modeling Platform: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>GPflow -- Gaussian processes in TensorFlow: <a href="https://www.gpflow.org/" rel="noopener noreferrer" target="_blank">https://www.gpflow.org/</a></li><li>GPy -- Gaussian processes framework in Python: <a href="https://sheffieldml.github.io/GPy/" rel="noopener noreferrer" target="_blank">https://sheffieldml.github.io/GPy/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>How do you handle your MCMC samples once your Bayesian model fit properly? Which diagnostics do you check to see if there was a computational problem? And isn’t that nice when you have beautiful and reliable plots to complement your analysis and better understand your model?</p><p>I know what you think: plotting can be long and complicated in these cases. Well, not with ArviZ, a platform-agnostic package to do exploratory analysis of your Bayesian models. And in this episode, Ari Hartikainen will tell you why.</p><p>Ari is a data-scientist in geophysics and a researcher at the Department of Civil Engineering of Aalto University in Finland. He mainly works on geophysics, Bayesian statistics and visualization.&nbsp;</p><p>Ari’s also a prolific open-source contributor, as he’s a core-developer of the popular Stan and ArviZ libraries. He’ll tell us how PyStan interacts with ArviZ, what he thinks ArviZ most useful features are, and which common difficulties he encounters with his models and data.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Ari on GitHub: <a href="https://github.com/ahartikainen" rel="noopener noreferrer" target="_blank">https://github.com/ahartikainen</a></li><li>Ari on Twitter: <a href="https://twitter.com/a_hartikainen" rel="noopener noreferrer" target="_blank">https://twitter.com/a_hartikainen</a></li><li>ArviZ -- Exploratory analysis of Bayesian models: <a href="https://arviz-devs.github.io/arviz/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/</a></li><li>Introductory paper of ArviZ in <em>The Journal of Open Source Software</em>: <a href="https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python" rel="noopener noreferrer" target="_blank">https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python</a></li><li>Stan -- Statistical Modeling Platform: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>GPflow -- Gaussian processes in TensorFlow: <a href="https://www.gpflow.org/" rel="noopener noreferrer" target="_blank">https://www.gpflow.org/</a></li><li>GPy -- Gaussian processes framework in Python: <a href="https://sheffieldml.github.io/GPy/" rel="noopener noreferrer" target="_blank">https://sheffieldml.github.io/GPy/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/10-exploratory-analysis-of-bayesian-models-with-arviz-and-ari-hartikainen]]></link><guid isPermaLink="false">640e9026-ef22-4f52-9724-e7fe58ba1b55</guid><itunes:image href="https://artwork.captivate.fm/3dfe64a8-35e0-4a6d-8a9d-1fac45e878e7/h9aX7mFiwVm4E0co6Y_FUvAW.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 26 Feb 2020 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/077cd9ef-1aaa-46a3-9580-f8162e79458f/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="63510236" type="audio/mpeg"/><itunes:duration>44:06</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>10</itunes:episode><itunes:season>1</itunes:season><podcast:episode>10</podcast:episode><podcast:season>1</podcast:season><itunes:summary>How do you handle your MCMC samples once your Bayesian model fit properly? Which diagnostics do you check to see if there was a computational problem? And isn’t that nice when you have beautiful and reliable plots to complement your analysis and better understand your model?

I know what you think: plotting can be long and complicated in these cases. Well, not with ArviZ, a platform-agnostic package to do exploratory analysis of your Bayesian models. And in this episode, Ari Hartikainen will tell you why.

Ari is a data-scientist in geophysics and a researcher at the Department of Civil Engineering of Aalto University in Finland. He mainly works on geophysics, Bayesian statistics and visualization. 

Ari’s also a prolific open-source contributor, as he’s a core-developer of the popular Stan and ArviZ libraries. He’ll tell us how PyStan interacts with ArviZ, what he thinks ArviZ most useful features are, and which common difficulties he encounters with his models and data.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Ari on GitHub: https://github.com/ahartikainen (https://github.com/ahartikainen)

 Ari on Twitter: https://twitter.com/a_hartikainen (https://twitter.com/a_hartikainen)

  ArviZ -- Exploratory analysis of Bayesian models: https://arviz-devs.github.io/arviz/ (https://arviz-devs.github.io/arviz/)

  Introductory paper of ArviZ in The Journal of Open Source Software: https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python (https://www.researchgate.net/publication/330402908_ArviZ_a_unified_library_for_exploratory_analysis_of_Bayesian_models_in_Python)

  Stan -- Statistical Modeling Platform: https://mc-stan.org/ (https://mc-stan.org/)

  GPflow -- Gaussian processes in TensorFlow: https://www.gpflow.org/ (https://www.gpflow.org/)

  GPy -- Gaussian processes framework in Python: https://sheffieldml.github.io/GPy/ (https://sheffieldml.github.io/GPy/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#9 Exploring the Cosmos with Bayes and Maggie Lieu</title><itunes:title>#9 Exploring the Cosmos with Bayes and Maggie Lieu</itunes:title><description><![CDATA[<p>Have you always wondered what dark matter is? Can we even see it — let alone measure it? And what would discover it imply for our understanding of the Universe?</p><p>In this episode, we’ll take look at the cosmos with Maggie Lieu. She’ll tell us what research in astrophysics is made of, what model she worked on at the European Space Agency, and how Bayesian the world of space science is.</p><p>Maggie Lieu did her PhD in the Astronomy &amp; Space Department of the University of Birmingham. She’s now a Research Fellow of Machine Learning &amp; Cosmology at the University of Nottingham and is working on projects in preparation for Euclid, a space-based telescope whose goal is to map the dark Universe and help us learn about the nature of dark matter and dark energy.</p><p>In a nutshell, she tries to help us better understand the entire cosmos. Even more amazing, she uses the Stan library and applies Bayesian statistical methods to decipher her astronomical data! But Maggie is not just a Bayesian astrophysicist: she also loves photography and rock-climbing!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Maggie's Website: <a href="https://maggielieu.com/" rel="noopener noreferrer" target="_blank">https://maggielieu.com/</a></li><li>Maggie's Google Scholar Page: <a href="https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJ&amp;hl=en</a></li><li>Maggie on Twitter: <a href="https://twitter.com/Space_Mog" rel="noopener noreferrer" target="_blank">https://twitter.com/Space_Mog</a></li><li>Maggie on GitHub: <a href="https://github.com/MaggieLieu" rel="noopener noreferrer" target="_blank">https://github.com/MaggieLieu</a></li><li>Maggie on YouTube: <a href="https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A</a></li><li>Stan -- Statistical Modeling Platform: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Stan's YouTube Channel: <a href="https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>Have you always wondered what dark matter is? Can we even see it — let alone measure it? And what would discover it imply for our understanding of the Universe?</p><p>In this episode, we’ll take look at the cosmos with Maggie Lieu. She’ll tell us what research in astrophysics is made of, what model she worked on at the European Space Agency, and how Bayesian the world of space science is.</p><p>Maggie Lieu did her PhD in the Astronomy &amp; Space Department of the University of Birmingham. She’s now a Research Fellow of Machine Learning &amp; Cosmology at the University of Nottingham and is working on projects in preparation for Euclid, a space-based telescope whose goal is to map the dark Universe and help us learn about the nature of dark matter and dark energy.</p><p>In a nutshell, she tries to help us better understand the entire cosmos. Even more amazing, she uses the Stan library and applies Bayesian statistical methods to decipher her astronomical data! But Maggie is not just a Bayesian astrophysicist: she also loves photography and rock-climbing!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Maggie's Website: <a href="https://maggielieu.com/" rel="noopener noreferrer" target="_blank">https://maggielieu.com/</a></li><li>Maggie's Google Scholar Page: <a href="https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJ&amp;hl=en" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJ&amp;hl=en</a></li><li>Maggie on Twitter: <a href="https://twitter.com/Space_Mog" rel="noopener noreferrer" target="_blank">https://twitter.com/Space_Mog</a></li><li>Maggie on GitHub: <a href="https://github.com/MaggieLieu" rel="noopener noreferrer" target="_blank">https://github.com/MaggieLieu</a></li><li>Maggie on YouTube: <a href="https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A</a></li><li>Stan -- Statistical Modeling Platform: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Stan's YouTube Channel: <a href="https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA" rel="noopener noreferrer" target="_blank">https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/9-exploring-the-cosmos-with-bayes-and-maggie-lieu]]></link><guid isPermaLink="false">7f06b4ce-fa39-4bd3-bffe-c6ed37a1f759</guid><itunes:image href="https://artwork.captivate.fm/79056687-d1d1-4251-8ba2-cc446ed3bd34/oU96pSZzxBlCMEcjTPPWfbuy.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 12 Feb 2020 11:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/c326d955-cbb4-4dba-99f2-d1c4f69e4ec2/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="77524113" type="audio/mpeg"/><itunes:duration>53:50</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>9</itunes:episode><itunes:season>1</itunes:season><podcast:episode>9</podcast:episode><podcast:season>1</podcast:season><itunes:summary>Have you always wondered what dark matter is? Can we even see it — let alone measure it? And what would discover it imply for our understanding of the Universe?

In this episode, we’ll take look at the cosmos with Maggie Lieu. She’ll tell us what research in astrophysics is made of, what model she worked on at the European Space Agency, and how Bayesian the world of space science is.

Maggie Lieu did her PhD in the Astronomy and Space Department of the University of Birmingham. She’s now a Research Fellow of Machine Learning and Cosmology at the University of Nottingham and is working on projects in preparation for Euclid, a space-based telescope whose goal is to map the dark Universe and help us learn about the nature of dark matter and dark energy.

In a nutshell, she tries to help us better understand the entire cosmos. Even more amazing, she uses the Stan library and applies Bayesian statistical methods to decipher her astronomical data! But Maggie is not just a Bayesian astrophysicist: she also loves photography and rock-climbing!

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Maggie&apos;s Website: https://maggielieu.com/ (https://maggielieu.com/)

 Maggie&apos;s Google Scholar Page: https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJandhl=en (https://scholar.google.co.uk/citations?user=ilfwfuUAAAAJandhl=en)

  Maggie on Twitter: https://twitter.com/Space_Mog (https://twitter.com/Space_Mog)

  Maggie on GitHub: https://github.com/MaggieLieu (https://github.com/MaggieLieu)

  Maggie on YouTube: https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A (https://www.youtube.com/channel/UClO6TuRE6XLzbMBmQ_KY38A)

  Stan -- Statistical Modeling Platform: https://mc-stan.org/ (https://mc-stan.org/)

  Stan&apos;s YouTube Channel: https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA (https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#8 Bayesian Inference for Software Engineers, with Max Sklar</title><itunes:title>#8 Bayesian Inference for Software Engineers, with Max Sklar</itunes:title><description><![CDATA[<p>What is it like using Bayesian tools when you’re a software engineer or computer scientist? How do you apply these tools in the online ad industry?&nbsp;</p><p>More generally, what is Bayesian thinking, philosophically? And is it really useful in every day life? Because, well you can’t fire up MCMC each time you need to make a quick decision under uncertainty… So how do you do that in practice, when you have at most a pen and paper?</p><p>In this episode, you’ll hear Max Sklar’s take on these questions. Max is a software engineer with a focus on machine learning and Bayesian inference. Now working at Foursquare’s innovation lab, he recently led the development of a causality model for Foursquare’s Ad Attribution product and taught a course on Bayesian Thinking at the Lviv Data Science Summer School.</p><p>Max is also an open-source enthusiast and a fellow podcaster – he’s the host of the Local Maximum podcast, where you can hear every week about the latest trends in AI, machine learning and technology from an engineering perspective.</p><p>Ow, and if you liked the movie «&nbsp;Her&nbsp;», with Joaquin Phoenix, well you’re in for a treat at the end of this episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p>Links from the show:</p><ul><li>Local Maximum podcast website: <a href="https://www.localmaxradio.com" rel="noopener noreferrer" target="_blank">https://www.localmaxradio.com</a></li><li>Max on Twitter: <a href="https://twitter.com/maxsklar" rel="noopener noreferrer" target="_blank">https://twitter.com/maxsklar</a></li><li>Bayesian linear models: <a href="https://github.com/maxsklar/BayesPy/tree/master/LinearModels" rel="noopener noreferrer" target="_blank">https://github.com/maxsklar/BayesPy/tree/master/LinearModels</a></li><li>Bayesian Dirichlet-Multinomial estimation: <a href="https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation" rel="noopener noreferrer" target="_blank">https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation</a></li><li>Bayesian Thinking for Applied Machine Learning slides: <a href="https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing" rel="noopener noreferrer" target="_blank">https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>What is it like using Bayesian tools when you’re a software engineer or computer scientist? How do you apply these tools in the online ad industry?&nbsp;</p><p>More generally, what is Bayesian thinking, philosophically? And is it really useful in every day life? Because, well you can’t fire up MCMC each time you need to make a quick decision under uncertainty… So how do you do that in practice, when you have at most a pen and paper?</p><p>In this episode, you’ll hear Max Sklar’s take on these questions. Max is a software engineer with a focus on machine learning and Bayesian inference. Now working at Foursquare’s innovation lab, he recently led the development of a causality model for Foursquare’s Ad Attribution product and taught a course on Bayesian Thinking at the Lviv Data Science Summer School.</p><p>Max is also an open-source enthusiast and a fellow podcaster – he’s the host of the Local Maximum podcast, where you can hear every week about the latest trends in AI, machine learning and technology from an engineering perspective.</p><p>Ow, and if you liked the movie «&nbsp;Her&nbsp;», with Joaquin Phoenix, well you’re in for a treat at the end of this episode…</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p>Links from the show:</p><ul><li>Local Maximum podcast website: <a href="https://www.localmaxradio.com" rel="noopener noreferrer" target="_blank">https://www.localmaxradio.com</a></li><li>Max on Twitter: <a href="https://twitter.com/maxsklar" rel="noopener noreferrer" target="_blank">https://twitter.com/maxsklar</a></li><li>Bayesian linear models: <a href="https://github.com/maxsklar/BayesPy/tree/master/LinearModels" rel="noopener noreferrer" target="_blank">https://github.com/maxsklar/BayesPy/tree/master/LinearModels</a></li><li>Bayesian Dirichlet-Multinomial estimation: <a href="https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation" rel="noopener noreferrer" target="_blank">https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation</a></li><li>Bayesian Thinking for Applied Machine Learning slides: <a href="https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing" rel="noopener noreferrer" target="_blank">https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/8-bayesian-inference-for-software-engineers-with-max-sklar]]></link><guid isPermaLink="false">5fba14c7-77e3-451c-88a4-eb4edfde7f75</guid><itunes:image href="https://artwork.captivate.fm/d7f5456d-c94c-4cfd-8f3c-c40e6ab2b002/6Bac2qNrHHba5-rJouOtkq8V.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 29 Jan 2020 08:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b8031399-1df2-4cf2-be71-1d2dd16f4a79/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="70154560" type="audio/mpeg"/><itunes:duration>48:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>8</itunes:episode><itunes:season>1</itunes:season><podcast:episode>8</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What is it like using Bayesian tools when you’re a software engineer or computer scientist? How do you apply these tools in the online ad industry? 

More generally, what is Bayesian thinking, philosophically? And is it really useful in every day life? Because, well you can’t fire up MCMC each time you need to make a quick decision under uncertainty… So how do you do that in practice, when you have at most a pen and paper?

In this episode, you’ll hear Max Sklar’s take on these questions. Max is a software engineer with a focus on machine learning and Bayesian inference. Now working at Foursquare’s innovation lab, he recently led the development of a causality model for Foursquare’s Ad Attribution product and taught a course on Bayesian Thinking at the Lviv Data Science Summer School.

Max is also an open-source enthusiast and a fellow podcaster – he’s the host of the Local Maximum podcast, where you can hear every week about the latest trends in AI, machine learning and technology from an engineering perspective.

Ow, and if you liked the movie « Her », with Joaquin Phoenix, well you’re in for a treat at the end of this episode…

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

 

Links from the show:


 Local Maximum podcast website: https://www.localmaxradio.com (https://www.localmaxradio.com)

 Max on Twitter: https://twitter.com/maxsklar (https://twitter.com/maxsklar)

 Bayesian linear models: https://github.com/maxsklar/BayesPy/tree/master/LinearModels (https://github.com/maxsklar/BayesPy/tree/master/LinearModels)

 Bayesian Dirichlet-Multinomial estimation: https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation (https://github.com/maxsklar/BayesPy/tree/master/DirichletEstimation)

  Bayesian Thinking for Applied Machine Learning slides: https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing (https://docs.google.com/presentation/d/1eiceuvXlsoFKoHdqjF3qXBkyht7vR0YXQPG82ady-TU/edit?usp=sharing)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#7 Designing a Probabilistic Programming Language &amp; Debugging a Model, with Junpeng Lao</title><itunes:title>#7 Designing a Probabilistic Programming Language &amp; Debugging a Model, with Junpeng Lao</itunes:title><description><![CDATA[<p>You can’t study psychology up until your PhD and end-up doing very mathematical and computational data science at Google right? It’s too hard of a U-turn — some would even say it’s NUTS, just because they like bad puns… Well think again, because Junpeng Lao did just that!</p><p>Before doing data science at Google, Junpeng was a cognitive psychology researcher at the University of Fribourg, Switzerland. Working in Python, Matlab and occasionally in R, Junpeng is a prolific open-source contributor, particularly to the popular TensorFlow and PyMC3 libraries. He also maintains the PyMC Discourse on his free time, where he amazingly answers all kinds of various and very specific questions!</p><p>In this episode, he’ll tell you what the core characteristics of TensorFlow Probability are, and when you would use TFP instead of another probabilistic programming framework, like Stan or PyMC3. He’ll also explain why PyMC4 will be based on TensorFlow Probability itself, and what future contributions he has in mind for these two amazing libraries. Finally, Junpeng will share with you his workflow for debugging a model, or just for better understanding your models.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:&nbsp;</strong></p><ul><li>Junpeng's blog: <a href="https://junpenglao.xyz/" rel="noopener noreferrer" target="_blank">https://junpenglao.xyz/</a></li><li>Junpeng on Twitter: <a href="https://twitter.com/junpenglao" rel="noopener noreferrer" target="_blank">https://twitter.com/junpenglao</a></li><li>Junpeng on GitHub: <a href="https://github.com/junpenglao" rel="noopener noreferrer" target="_blank">https://github.com/junpenglao</a></li><li>Advanced Bayesian Modeling Tutorial: <a href="https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439" rel="noopener noreferrer" target="_blank">https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439</a></li><li>Stan Devs' Prior Choice Recommendations: <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations" rel="noopener noreferrer" target="_blank">https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations</a></li><li>PyMC Discourse: <a href="https://discourse.pymc.io/" rel="noopener noreferrer" target="_blank">https://discourse.pymc.io/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Tensor Flow Probability: <a href="https://www.tensorflow.org/probability/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>You can’t study psychology up until your PhD and end-up doing very mathematical and computational data science at Google right? It’s too hard of a U-turn — some would even say it’s NUTS, just because they like bad puns… Well think again, because Junpeng Lao did just that!</p><p>Before doing data science at Google, Junpeng was a cognitive psychology researcher at the University of Fribourg, Switzerland. Working in Python, Matlab and occasionally in R, Junpeng is a prolific open-source contributor, particularly to the popular TensorFlow and PyMC3 libraries. He also maintains the PyMC Discourse on his free time, where he amazingly answers all kinds of various and very specific questions!</p><p>In this episode, he’ll tell you what the core characteristics of TensorFlow Probability are, and when you would use TFP instead of another probabilistic programming framework, like Stan or PyMC3. He’ll also explain why PyMC4 will be based on TensorFlow Probability itself, and what future contributions he has in mind for these two amazing libraries. Finally, Junpeng will share with you his workflow for debugging a model, or just for better understanding your models.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:&nbsp;</strong></p><ul><li>Junpeng's blog: <a href="https://junpenglao.xyz/" rel="noopener noreferrer" target="_blank">https://junpenglao.xyz/</a></li><li>Junpeng on Twitter: <a href="https://twitter.com/junpenglao" rel="noopener noreferrer" target="_blank">https://twitter.com/junpenglao</a></li><li>Junpeng on GitHub: <a href="https://github.com/junpenglao" rel="noopener noreferrer" target="_blank">https://github.com/junpenglao</a></li><li>Advanced Bayesian Modeling Tutorial: <a href="https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439" rel="noopener noreferrer" target="_blank">https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439</a></li><li>Stan Devs' Prior Choice Recommendations: <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations" rel="noopener noreferrer" target="_blank">https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations</a></li><li>PyMC Discourse: <a href="https://discourse.pymc.io/" rel="noopener noreferrer" target="_blank">https://discourse.pymc.io/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Tensor Flow Probability: <a href="https://www.tensorflow.org/probability/" rel="noopener noreferrer" target="_blank">https://www.tensorflow.org/probability/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/7-designing-a-probabilistic-programming-language-debugging-a-model-with-junpeng-lao]]></link><guid isPermaLink="false">b4cfe3f8-df98-45b7-9e93-905656fa6e59</guid><itunes:image href="https://artwork.captivate.fm/4fb10f96-423b-473f-a71c-214e0ab2befb/bE-Yv5oqo5KZADAmotLljZih.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Thu, 16 Jan 2020 15:59:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/7419b96b-783f-4cc8-929b-4f4e0d92bf26/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2020.mp3" length="65819166" type="audio/mpeg"/><itunes:duration>45:42</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>7</itunes:episode><itunes:season>1</itunes:season><podcast:episode>7</podcast:episode><podcast:season>1</podcast:season><itunes:summary>You can’t study psychology up until your PhD and end-up doing very mathematical and computational data science at Google right? It’s too hard of a U-turn — some would even say it’s NUTS, just because they like bad puns… Well think again, because Junpeng Lao did just that!

Before doing data science at Google, Junpeng was a cognitive psychology researcher at the University of Fribourg, Switzerland. Working in Python, Matlab and occasionally in R, Junpeng is a prolific open-source contributor, particularly to the popular TensorFlow and PyMC3 libraries. He also maintains the PyMC Discourse on his free time, where he amazingly answers all kinds of various and very specific questions!

In this episode, he’ll tell you what the core characteristics of TensorFlow Probability are, and when you would use TFP instead of another probabilistic programming framework, like Stan or PyMC3. He’ll also explain why PyMC4 will be based on TensorFlow Probability itself, and what future contributions he has in mind for these two amazing libraries. Finally, Junpeng will share with you his workflow for debugging a model, or just for better understanding your models.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show: 


 Junpeng&apos;s blog: https://junpenglao.xyz/ (https://junpenglao.xyz/)

 Junpeng on Twitter: https://twitter.com/junpenglao (https://twitter.com/junpenglao)

  Junpeng on GitHub: https://github.com/junpenglao (https://github.com/junpenglao)

  Advanced Bayesian Modeling Tutorial: https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439 (https://discourse.pymc.io/t/advance-bayesian-modelling-with-pymc3/1439)

  Stan Devs&apos; Prior Choice Recommendations: https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)

  PyMC Discourse: https://discourse.pymc.io/ (https://discourse.pymc.io/)

  PyMC3 - Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Tensor Flow Probability: https://www.tensorflow.org/probability/ (https://www.tensorflow.org/probability/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#6 A principled Bayesian workflow, with Michael Betancourt</title><itunes:title>#6 A principled Bayesian workflow, with Michael Betancourt</itunes:title><description><![CDATA[<p>If you’re there, it’s probably because you’re interested in Bayesian&nbsp;inference, right? But don’t you feel lost sometimes when building a&nbsp;model? Or you ask yourself why what you’re trying to do is so damn hard… and you conclude that YOU are the problem, that YOU must be doing something wrong!</p><p>Well, rest assured, as you’ll hear from Michael Betancourt himself: it’s hard for everybody! That’s why over the years&nbsp;he developed and tries to popularize what he calls a «&nbsp;principled&nbsp;Bayesian workflow&nbsp;» — in a nutshell, think about what could have&nbsp;generated your data; and always question default settings!</p><p>With&nbsp;that workflow, you’ll probably feel less alone when modeling, but expect&nbsp;to fail often. That’s ok — as Michael says: if you don’t fail, you don’t&nbsp;learn!</p><p>Who is Michael Betancourt you ask? He is a physicist and&nbsp;statistician, whose research focuses on the development of robust statistical workflows, computational tools, and pedagogical resources that help bridge the gap between statistical theory and scientific practice.</p><p>Michael works a lot on differential geometry and&nbsp;probability theory, and he often lives in high-dimensional spaces, where&nbsp;he meets with a good friend of his -- Hamiltonian Monte Carlo. Then, you won’t be surprised to learn that Michael is one of the core&nbsp;developers of the seminal probabilistic programming language Stan.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Michael's upcoming course: <a href="https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860" rel="noopener noreferrer" target="_blank">https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860</a></li><li>Michael's website (the “Writing” page collects the case studies and pedagogical material, and the “Speaking” page links to the recorded talks): <a href="https://betanalpha.github.io/" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/</a></li><li>Support Michael's work on Patreon: <a href="https://patreon.com/betanalpha" rel="noopener noreferrer" target="_blank">https://patreon.com/betanalpha</a></li><li>Michael on Twitter: <a href="https://twitter.com/betanalpha" rel="noopener noreferrer" target="_blank">https://twitter.com/betanalpha</a></li><li>Michael on GitHub: <a href="https://github.com/betanalpha" rel="noopener noreferrer" target="_blank">https://github.com/betanalpha</a></li><li>Stan probabilistic programming langage: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>If you’re there, it’s probably because you’re interested in Bayesian&nbsp;inference, right? But don’t you feel lost sometimes when building a&nbsp;model? Or you ask yourself why what you’re trying to do is so damn hard… and you conclude that YOU are the problem, that YOU must be doing something wrong!</p><p>Well, rest assured, as you’ll hear from Michael Betancourt himself: it’s hard for everybody! That’s why over the years&nbsp;he developed and tries to popularize what he calls a «&nbsp;principled&nbsp;Bayesian workflow&nbsp;» — in a nutshell, think about what could have&nbsp;generated your data; and always question default settings!</p><p>With&nbsp;that workflow, you’ll probably feel less alone when modeling, but expect&nbsp;to fail often. That’s ok — as Michael says: if you don’t fail, you don’t&nbsp;learn!</p><p>Who is Michael Betancourt you ask? He is a physicist and&nbsp;statistician, whose research focuses on the development of robust statistical workflows, computational tools, and pedagogical resources that help bridge the gap between statistical theory and scientific practice.</p><p>Michael works a lot on differential geometry and&nbsp;probability theory, and he often lives in high-dimensional spaces, where&nbsp;he meets with a good friend of his -- Hamiltonian Monte Carlo. Then, you won’t be surprised to learn that Michael is one of the core&nbsp;developers of the seminal probabilistic programming language Stan.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show</strong>:</p><ul><li>Michael's upcoming course: <a href="https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860" rel="noopener noreferrer" target="_blank">https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860</a></li><li>Michael's website (the “Writing” page collects the case studies and pedagogical material, and the “Speaking” page links to the recorded talks): <a href="https://betanalpha.github.io/" rel="noopener noreferrer" target="_blank">https://betanalpha.github.io/</a></li><li>Support Michael's work on Patreon: <a href="https://patreon.com/betanalpha" rel="noopener noreferrer" target="_blank">https://patreon.com/betanalpha</a></li><li>Michael on Twitter: <a href="https://twitter.com/betanalpha" rel="noopener noreferrer" target="_blank">https://twitter.com/betanalpha</a></li><li>Michael on GitHub: <a href="https://github.com/betanalpha" rel="noopener noreferrer" target="_blank">https://github.com/betanalpha</a></li><li>Stan probabilistic programming langage: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/6-a-principled-bayesian-workflow-with-michael-betancourt]]></link><guid isPermaLink="false">81a86787-0305-4cd3-b8ce-6af4e64537e6</guid><itunes:image href="https://artwork.captivate.fm/5dd38bed-6a61-47c6-a44f-f34c07f5dfe0/b1AL4Q4h0w57VAclTJQ-bKv.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 03 Jan 2020 09:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b6992c25-5b23-4f13-9d55-457b5f768337/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="91992606" type="audio/mpeg"/><itunes:duration>01:03:53</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>6</itunes:episode><itunes:season>1</itunes:season><podcast:episode>6</podcast:episode><podcast:season>1</podcast:season><itunes:summary>If you’re there, it’s probably because you’re interested in Bayesian inference, right? But don’t you feel lost sometimes when building a  model? Or you ask yourself why what you’re trying to do is so damn hard… and you conclude that YOU are the problem, that YOU must be doing something wrong!

Well, rest assured, as you’ll hear from Michael Betancourt himself: it’s hard for everybody! That’s why over the years  he developed and tries to popularize what he calls a « principled  Bayesian workflow » — in a nutshell, think about what could have  generated your data; and always question default settings!

With  that workflow, you’ll probably feel less alone when modeling, but expect to fail often. That’s ok — as Michael says: if you don’t fail, you don’t learn!

Who is Michael Betancourt you ask? He is a physicist and  statistician, whose research focuses on the development of robust statistical workflows, computational tools, and pedagogical resources that help bridge the gap between statistical theory and scientific practice.

Michael works a lot on differential geometry and  probability theory, and he often lives in high-dimensional spaces, where  he meets with a good friend of his -- Hamiltonian Monte Carlo. Then, you won’t be surprised to learn that Michael is one of the core developers of the seminal probabilistic programming language Stan.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !



Links from the show:


 Michael&apos;s upcoming course: https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860 (https://events.eventzilla.net/e/introduction-to-bayesian-inference-with-stan-with-michael-betancourt-2138756860)

 Michael&apos;s website (the “Writing” page collects the case studies and pedagogical material, and the “Speaking” page links to the recorded talks): https://betanalpha.github.io/ (https://betanalpha.github.io/)

  Support Michael&apos;s work on Patreon: https://patreon.com/betanalpha (https://patreon.com/betanalpha)

  Michael on Twitter: https://twitter.com/betanalpha (https://twitter.com/betanalpha)

  Michael on GitHub: https://github.com/betanalpha (https://github.com/betanalpha)

  Stan probabilistic programming langage: https://mc-stan.org/ (https://mc-stan.org/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#5 How to use Bayes in the biomedical industry, with Eric Ma</title><itunes:title>#5 How to use Bayes in the biomedical industry, with Eric Ma</itunes:title><description><![CDATA[<p>I have two questions for you: Are you a self-learner? Then how do&nbsp;you stay up to date? What should you focus on if you’re a beginner, or if you’re more advanced?</p><p>And here is my second question: Are you working in biomedicine? And if you do, are you using Bayesian tools?&nbsp;Then how do you get your co-workers more used to posterior distributions&nbsp;than p-values? In other words, how do you change behaviors in a large organization?</p><p>In this episode, Eric Ma will answer all these&nbsp;questions and even tell us his favorite modeling techniques, which&nbsp;problems he encountered with these models, and how he solved them. He’ll also share with us the software-engineering workflow he uses at Novartis to share his work with colleagues.</p><p>Eric is a data&nbsp;scientist at the Novartis Institutes for Biomedical Research, where he focuses on Bayesian statistical methods to make medicines for patients. Eric is also a prolific open source developer: he led the development of pyjanitor, an API for cleaning data in Python, and nxviz, a&nbsp;visualization package for NetworkX. He also contributes to PyMC3, matplotlib and bokeh.</p><p>This is «&nbsp;Learning Bayesian Statistics&nbsp;», episode 5, recorded October 21, 2019.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Eric's website: <a href="https://ericmjl.github.io/" rel="noopener noreferrer" target="_blank">https://ericmjl.github.io/</a></li><li>Eric on Twitter: <a href="https://twitter.com/ericmjl" rel="noopener noreferrer" target="_blank">https://twitter.com/ericmjl</a></li><li>Bayesian analysis recipes: <a href="https://github.com/ericmjl/bayesian-analysis-recipes" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/bayesian-analysis-recipes</a></li><li>Bayesian deep learning demystified: <a href="bayesian-deep-learning-demystified" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/bayesian-deep-learning-demystified</a></li><li>Causality repo: <a href="https://github.com/ericmjl/causality" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/causality</a></li><li>Pyjanitor - Convenient data cleaning routines for repetitive tasks: <a href="https://pyjanitor.readthedocs.io/" rel="noopener noreferrer" target="_blank">https://pyjanitor.readthedocs.io/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Panel - A high-level app and dashboarding solution for Python: <a href="https://panel.pyviz.org/" rel="noopener noreferrer" target="_blank">https://panel.pyviz.org/</a></li><li>Nxviz - Visualization Package for NetworkX: <a href="https://nxviz.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://nxviz.readthedocs.io/en/latest/</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>I have two questions for you: Are you a self-learner? Then how do&nbsp;you stay up to date? What should you focus on if you’re a beginner, or if you’re more advanced?</p><p>And here is my second question: Are you working in biomedicine? And if you do, are you using Bayesian tools?&nbsp;Then how do you get your co-workers more used to posterior distributions&nbsp;than p-values? In other words, how do you change behaviors in a large organization?</p><p>In this episode, Eric Ma will answer all these&nbsp;questions and even tell us his favorite modeling techniques, which&nbsp;problems he encountered with these models, and how he solved them. He’ll also share with us the software-engineering workflow he uses at Novartis to share his work with colleagues.</p><p>Eric is a data&nbsp;scientist at the Novartis Institutes for Biomedical Research, where he focuses on Bayesian statistical methods to make medicines for patients. Eric is also a prolific open source developer: he led the development of pyjanitor, an API for cleaning data in Python, and nxviz, a&nbsp;visualization package for NetworkX. He also contributes to PyMC3, matplotlib and bokeh.</p><p>This is «&nbsp;Learning Bayesian Statistics&nbsp;», episode 5, recorded October 21, 2019.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !</p><p><strong>Links from the show:</strong></p><ul><li>Eric's website: <a href="https://ericmjl.github.io/" rel="noopener noreferrer" target="_blank">https://ericmjl.github.io/</a></li><li>Eric on Twitter: <a href="https://twitter.com/ericmjl" rel="noopener noreferrer" target="_blank">https://twitter.com/ericmjl</a></li><li>Bayesian analysis recipes: <a href="https://github.com/ericmjl/bayesian-analysis-recipes" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/bayesian-analysis-recipes</a></li><li>Bayesian deep learning demystified: <a href="bayesian-deep-learning-demystified" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/bayesian-deep-learning-demystified</a></li><li>Causality repo: <a href="https://github.com/ericmjl/causality" rel="noopener noreferrer" target="_blank">https://github.com/ericmjl/causality</a></li><li>Pyjanitor - Convenient data cleaning routines for repetitive tasks: <a href="https://pyjanitor.readthedocs.io/" rel="noopener noreferrer" target="_blank">https://pyjanitor.readthedocs.io/</a></li><li>PyMC3 - Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Panel - A high-level app and dashboarding solution for Python: <a href="https://panel.pyviz.org/" rel="noopener noreferrer" target="_blank">https://panel.pyviz.org/</a></li><li>Nxviz - Visualization Package for NetworkX: <a href="https://nxviz.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank">https://nxviz.readthedocs.io/en/latest/</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/5-how-to-use-bayes-in-the-biomedical-industry-with-eric-ma]]></link><guid isPermaLink="false">a08887c5-7723-74a7-7258-711f86272e04</guid><itunes:image href="https://artwork.captivate.fm/fd9bbb84-519d-42c8-8e51-8f7760b39ecc/KL_UUBcFjOa2UIL14wJyCeMR.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 17 Dec 2019 16:18:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/b05a916b-54a1-466d-bf85-423fcaf88373/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="67168742" type="audio/mpeg"/><itunes:duration>46:38</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>5</itunes:episode><itunes:season>1</itunes:season><podcast:episode>5</podcast:episode><podcast:season>1</podcast:season><itunes:summary>I have two questions for you: Are you a self-learner? Then how do  you stay up to date? What should you focus on if you’re a beginner, or if you’re more advanced?

And here is my second question: Are you working in biomedicine? And if you do, are you using Bayesian tools?  Then how do you get your co-workers more used to posterior distributions  than p-values? In other words, how do you change behaviors in a large organization?

In this episode, Eric Ma will answer all these  questions and even tell us his favorite modeling techniques, which  problems he encountered with these models, and how he solved them. He’ll also share with us the software-engineering workflow he uses at Novartis to share his work with colleagues.

Eric is a data  scientist at the Novartis Institutes for Biomedical Research, where he focuses on Bayesian statistical methods to make medicines for patients. Eric is also a prolific open source developer: he led the development of pyjanitor, an API for cleaning data in Python, and nxviz, a  visualization package for NetworkX. He also contributes to PyMC3, matplotlib and bokeh.

This is « Learning Bayesian Statistics », episode 5, recorded October 21, 2019.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !

Links from the show:


 Eric&apos;s website: https://ericmjl.github.io/ (https://ericmjl.github.io/)

 Eric on Twitter: https://twitter.com/ericmjl (https://twitter.com/ericmjl)

 Bayesian analysis recipes: https://github.com/ericmjl/bayesian-analysis-recipes (https://github.com/ericmjl/bayesian-analysis-recipes)

 Bayesian deep learning demystified: https://github.com/ericmjl/bayesian-deep-learning-demystified

  Causality repo: https://github.com/ericmjl/causality (https://github.com/ericmjl/causality)

  Pyjanitor - Convenient data cleaning routines for repetitive tasks: https://pyjanitor.readthedocs.io/ (https://pyjanitor.readthedocs.io/)

  PyMC3 - Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Panel - A high-level app and dashboarding solution for Python: https://panel.pyviz.org/ (https://panel.pyviz.org/)

  Nxviz - Visualization Package for NetworkX: https://nxviz.readthedocs.io/en/latest/ (https://nxviz.readthedocs.io/en/latest/)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#4 Dirichlet Processes and Neurodegenerative Diseases, with Karin Knudson</title><itunes:title>#4 Dirichlet Processes and Neurodegenerative Diseases, with Karin Knudson</itunes:title><description><![CDATA[<p>What do neurodegenerative diseases, gerrymandering and ecological inference all have in common? Well, they can all be studied with Bayesian methods — and that’s exactly what Karin Knudson is doing.</p><p>In this episode, Karin will share with us the vital and essential work she does to understand aspects of neurodegenerative diseases. She’ll also tell us more about computational neuroscience and Dirichlet processes — what they are, what they do, and when you should use them.</p><p>Karin did her doctorate in mathematics, with a focus on compressive sensing and computational neuroscience at the University of Texas at Austin. Her doctoral work included applying hierarchical Dirichlet processes in the setting of neural data and focused on one-bit compressive sensing and spike-sorting.</p><p>Formerly the chair of the math and computer science department of Phillips Academy Andover, she started a postdoc at Mass General Hospital and Harvard Medical in Fall 2019. Most importantly, rock climbing and hiking have no secrets for her!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !&nbsp;</p><p><strong>Links from the show, personally curated by Karin Knudson:</strong></p><ul><li>Karin on Twitter: <a href="https://twitter.com/karinknudson" rel="noopener noreferrer" target="_blank">https://twitter.com/karinknudson</a></li><li>Spike train entropy-rate estimation using hierarchical Dirichlet process priors (Knudson and Pillow): <a href="https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html" rel="noopener noreferrer" target="_blank">https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html</a></li><li>Fighting Gerrymandering with PyMC3, PyCon 2018, Colin Carroll and Karin Knudson: <a href="https://www.youtube.com/watch?v=G9I5ZnkWR0A" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=G9I5ZnkWR0A</a></li><li>Expository resources on Dirichlet Processes: Chapter 23 of Bayesian Data Analysis (Gelman et al.) and <a href="http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf" rel="noopener noreferrer" target="_blank">http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf</a></li><li>Hierarchical Dirichlet Processes (introduced the HDP and included applications in topic modeling and for working with time-series data and Hidden Markov Models): <a href="https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf" rel="noopener noreferrer" target="_blank">https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf</a></li><li>A Sticky HDP-HMM with applications to speaker diarization (a nice example of how the HDP can be used with HMM, in this case cleverly adapted so that states have more persistence): <a href="https://arxiv.org/abs/0905.2592" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/0905.2592</a></li><li>If you want to get deeper into the weeds and also get a sense of the history: Dirichlet Processes with Applications to Bayesian Nonparametric Problems (<a href="https://projecteuclid.org/euclid.aos/1176342871" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/euclid.aos/1176342871</a>) and A Bayesian Analysis of Some Nonparametric Problems (<a href="https://projecteuclid.org/euclid.aos/1176342360" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/euclid.aos/1176342360</a>)</li></ul><br/>]]></description><content:encoded><![CDATA[<p>What do neurodegenerative diseases, gerrymandering and ecological inference all have in common? Well, they can all be studied with Bayesian methods — and that’s exactly what Karin Knudson is doing.</p><p>In this episode, Karin will share with us the vital and essential work she does to understand aspects of neurodegenerative diseases. She’ll also tell us more about computational neuroscience and Dirichlet processes — what they are, what they do, and when you should use them.</p><p>Karin did her doctorate in mathematics, with a focus on compressive sensing and computational neuroscience at the University of Texas at Austin. Her doctoral work included applying hierarchical Dirichlet processes in the setting of neural data and focused on one-bit compressive sensing and spike-sorting.</p><p>Formerly the chair of the math and computer science department of Phillips Academy Andover, she started a postdoc at Mass General Hospital and Harvard Medical in Fall 2019. Most importantly, rock climbing and hiking have no secrets for her!</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a> !&nbsp;</p><p><strong>Links from the show, personally curated by Karin Knudson:</strong></p><ul><li>Karin on Twitter: <a href="https://twitter.com/karinknudson" rel="noopener noreferrer" target="_blank">https://twitter.com/karinknudson</a></li><li>Spike train entropy-rate estimation using hierarchical Dirichlet process priors (Knudson and Pillow): <a href="https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html" rel="noopener noreferrer" target="_blank">https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html</a></li><li>Fighting Gerrymandering with PyMC3, PyCon 2018, Colin Carroll and Karin Knudson: <a href="https://www.youtube.com/watch?v=G9I5ZnkWR0A" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=G9I5ZnkWR0A</a></li><li>Expository resources on Dirichlet Processes: Chapter 23 of Bayesian Data Analysis (Gelman et al.) and <a href="http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf" rel="noopener noreferrer" target="_blank">http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf</a></li><li>Hierarchical Dirichlet Processes (introduced the HDP and included applications in topic modeling and for working with time-series data and Hidden Markov Models): <a href="https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf" rel="noopener noreferrer" target="_blank">https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf</a></li><li>A Sticky HDP-HMM with applications to speaker diarization (a nice example of how the HDP can be used with HMM, in this case cleverly adapted so that states have more persistence): <a href="https://arxiv.org/abs/0905.2592" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/0905.2592</a></li><li>If you want to get deeper into the weeds and also get a sense of the history: Dirichlet Processes with Applications to Bayesian Nonparametric Problems (<a href="https://projecteuclid.org/euclid.aos/1176342871" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/euclid.aos/1176342871</a>) and A Bayesian Analysis of Some Nonparametric Problems (<a href="https://projecteuclid.org/euclid.aos/1176342360" rel="noopener noreferrer" target="_blank">https://projecteuclid.org/euclid.aos/1176342360</a>)</li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/4-dirichlet-processes-and-neurodegenerative-diseases-with-karin-knudson]]></link><guid isPermaLink="false">77b963f9-5adc-8a51-6725-d2ef232e8267</guid><itunes:image href="https://artwork.captivate.fm/c9cad705-0e24-4689-b43c-bd02958bb545/xd77sSb7KEfU9dpx40-i7twk.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 04 Dec 2019 11:00:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/ab0e0b10-4072-4eb5-8bab-471853fea644/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="71260742" type="audio/mpeg"/><itunes:duration>49:29</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>4</itunes:episode><itunes:season>1</itunes:season><podcast:episode>4</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What do neurodegenerative diseases, gerrymandering and ecological inference all have in common? Well, they can all be studied with Bayesian methods — and that’s exactly what Karin Knudson is doing.

In this episode, Karin will share with us the vital and essential work she does to understand aspects of neurodegenerative diseases. She’ll also tell us more about computational neuroscience and Dirichlet processes — what they are, what they do, and when you should use them.

Karin did her doctorate in mathematics, with a focus on compressive sensing and computational neuroscience at the University of Texas at Austin. Her doctoral work included applying hierarchical Dirichlet processes in the setting of neural data and focused on one-bit compressive sensing and spike-sorting.

Formerly the chair of the math and computer science department of Phillips Academy Andover, she started a postdoc at Mass General Hospital and Harvard Medical in Fall 2019. Most importantly, rock climbing and hiking have no secrets for her!

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/) !  

Links from the show, personally curated by Karin Knudson:


 Karin on Twitter: https://twitter.com/karinknudson (https://twitter.com/karinknudson)

 Spike train entropy-rate estimation using hierarchical Dirichlet process priors (Knudson and Pillow): https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html (https://pillowlab.princeton.edu/pubs/abs_Knudson_HDPentropy_NIPS13.html)

  Fighting Gerrymandering with PyMC3, PyCon 2018, Colin Carroll and Karin Knudson: https://www.youtube.com/watch?v=G9I5ZnkWR0A (https://www.youtube.com/watch?v=G9I5ZnkWR0A)

  Expository resources on Dirichlet Processes: Chapter 23 of Bayesian Data Analysis (Gelman et al.) and http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf (http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf)

  Hierarchical Dirichlet Processes (introduced the HDP and included applications in topic modeling and for working with time-series data and Hidden Markov Models): https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf (https://www.stat.berkeley.edu/~aldous/206-Exch/Papers/hierarchical_dirichlet.pdf)

  A Sticky HDP-HMM with applications to speaker diarization (a nice example of how the HDP can be used with HMM, in this case cleverly adapted so that states have more persistence): https://arxiv.org/abs/0905.2592 (https://arxiv.org/abs/0905.2592)

  If you want to get deeper into the weeds and also get a sense of the history: Dirichlet Processes with Applications to Bayesian Nonparametric Problems (https://projecteuclid.org/euclid.aos/1176342871 (https://projecteuclid.org/euclid.aos/1176342871)) and A Bayesian Analysis of Some Nonparametric Problems (https://projecteuclid.org/euclid.aos/1176342360 (https://projecteuclid.org/euclid.aos/1176342360))</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#3.2 How to use Bayes in industry, with Colin Carroll</title><itunes:title>#3.2 How to use Bayes in industry, with Colin Carroll</itunes:title><description><![CDATA[<p>How can you use Bayesian tools and optimize your models in industry? What are the best ways to communicate and visualize your models with non-technical and executive people? And what are the most common pitfalls?</p><p>In this episode, Colin Carroll will tell us how he did all that in finance and the airline industry. He’ll also share with us what the future of probabilistic programming looks like to him.</p><p>You already heard from Colin two weeks ago — so, if you didn’t catch this episode, go back in your feed’s history and enjoy the first part!&nbsp;</p><p>As a reminder, Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://github.com/stripe/rainier" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a>!</p><p><strong>Links from the show:</strong></p><ul><li>&nbsp;&nbsp;&nbsp;&nbsp;Colin's blog: <a href="https://colindcarroll.com/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Gelman’s putting model in PyMC3: <a href="https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Matthew Kay’s quantile dotplots: <a href="https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md" rel="noopener noreferrer" target="_blank">https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Jax, Composable transformations of Python+NumPy programs: <a href="https://github.com/google/jax" rel="noopener noreferrer" target="_blank">https://github.com/google/jax</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;NumPyro, Probabilistic programming with NumPy: <a href="https://github.com/pyro-ppl/numpyro" rel="noopener noreferrer" target="_blank">https://github.com/pyro-ppl/numpyro</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Pyro, Deep Universal Probabilistic Programming: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Rainier, Bayesian inference in Scala: <a href="https://github.com/stripe/rainier" rel="noopener noreferrer" target="_blank">https://github.com/stripe/rainier</a></li></ul><br/><p>---</p><p>Send in a voice message: https://anchor.fm/learn-bayes-stats/message</p>]]></description><content:encoded><![CDATA[<p>How can you use Bayesian tools and optimize your models in industry? What are the best ways to communicate and visualize your models with non-technical and executive people? And what are the most common pitfalls?</p><p>In this episode, Colin Carroll will tell us how he did all that in finance and the airline industry. He’ll also share with us what the future of probabilistic programming looks like to him.</p><p>You already heard from Colin two weeks ago — so, if you didn’t catch this episode, go back in your feed’s history and enjoy the first part!&nbsp;</p><p>As a reminder, Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://github.com/stripe/rainier" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a>!</p><p><strong>Links from the show:</strong></p><ul><li>&nbsp;&nbsp;&nbsp;&nbsp;Colin's blog: <a href="https://colindcarroll.com/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Gelman’s putting model in PyMC3: <a href="https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb" rel="noopener noreferrer" target="_blank">https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Matthew Kay’s quantile dotplots: <a href="https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md" rel="noopener noreferrer" target="_blank">https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Jax, Composable transformations of Python+NumPy programs: <a href="https://github.com/google/jax" rel="noopener noreferrer" target="_blank">https://github.com/google/jax</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;NumPyro, Probabilistic programming with NumPy: <a href="https://github.com/pyro-ppl/numpyro" rel="noopener noreferrer" target="_blank">https://github.com/pyro-ppl/numpyro</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Pyro, Deep Universal Probabilistic Programming: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>&nbsp;&nbsp;&nbsp;&nbsp;Rainier, Bayesian inference in Scala: <a href="https://github.com/stripe/rainier" rel="noopener noreferrer" target="_blank">https://github.com/stripe/rainier</a></li></ul><br/><p>---</p><p>Send in a voice message: https://anchor.fm/learn-bayes-stats/message</p>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/3-2-how-to-use-bayes-in-industry-with-colin-carroll]]></link><guid isPermaLink="false">1cef31ba-2b89-b3b9-590c-bd31db95e3a3</guid><itunes:image href="https://artwork.captivate.fm/a2f05bf5-80ba-4fbb-9ed9-42db06f13147/-VligBDMQBBQCN8NOxXbFzfa.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Mon, 18 Nov 2019 20:59:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/310cadf4-3d93-4e85-9dc4-221502ad8602/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="46227002" type="audio/mpeg"/><itunes:duration>32:06</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>bonus</itunes:episodeType><itunes:season>1</itunes:season><itunes:season>1</itunes:season><podcast:season>1</podcast:season><itunes:summary>How can you use Bayesian tools and optimize your models in industry? What are the best ways to communicate and visualize your models with non-technical and executive people? And what are the most common pitfalls?

In this episode, Colin Carroll will tell us how he did all that in finance and the airline industry. He’ll also share with us what the future of probabilistic programming looks like to him.

You already heard from Colin two weeks ago — so, if you didn’t catch this episode, go back in your feed’s history and enjoy the first part! 

As a reminder, Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://github.com/stripe/rainier (https://bababrinkman.com/)!

Links from the show:


     Colin&apos;s blog: https://colindcarroll.com/ (https://colindcarroll.com/)

     Gelman’s putting model in PyMC3: https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb (https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/putting_workflow.ipynb)

      Matthew Kay’s quantile dotplots: https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md (https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md)

      Jax, Composable transformations of Python+NumPy programs: https://github.com/google/jax (https://github.com/google/jax)

      NumPyro, Probabilistic programming with NumPy: https://github.com/pyro-ppl/numpyro (https://github.com/pyro-ppl/numpyro)

      Pyro, Deep Universal Probabilistic Programming: https://pyro.ai/ (https://pyro.ai/)

      Rainier, Bayesian inference in Scala: https://github.com/stripe/rainier (https://github.com/stripe/rainier)



--- 

Send in a voice message: https://anchor.fm/learn-bayes-stats/message</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#3.1 What is Probabilistic Programming &amp; Why use it, with Colin Carroll</title><itunes:title>#3.1 What is Probabilistic Programming &amp; Why use it, with Colin Carroll</itunes:title><description><![CDATA[<p>When speaking about Bayesian statistics, we often hear about «&nbsp;probabilistic programming&nbsp;» — but what is it? Which languages and libraries allow you to program probabilistically? When is Stan, PyMC, Pyro or any other probabilistic programming language most appropriate for your project? And when should you even use Bayesian libraries instead of non-bayesian tools, like Statsmodels or Scikit-learn?</p><p>Colin Carroll will answer all these questions for you. Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.</p><p>Having studied geometric measure theory at Rice University, Colin was bound to walk in the woods with Pete the pup – who was there when we recorded by the way – and to launch balloons into near-space in his spare time.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a>!</p><p><strong>Links from the show:</strong></p><ul><li>Colin's blog: <a href="https://colindcarroll.com/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/</a></li><li>Colin on Twitter: <a href="https://twitter.com/colindcarroll" rel="noopener noreferrer" target="_blank">https://twitter.com/colindcarroll</a></li><li>Colin on GitHub: <a href="https://github.com/ColCarroll" rel="noopener noreferrer" target="_blank">https://github.com/ColCarroll</a></li><li>Very parallel MCMC sampling: <a href="https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/</a></li><li>A tour of probabilistic programming APIs: <a href="https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Stan: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Pyro, Deep Universal Probabilistic Programming: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>ArviZ, Exploratory analysis of Bayesian models: <a href="https://arviz-devs.github.io/arviz/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/</a>&nbsp;</li><li>PyMC-Learn, Probabilistic models for machine learning: <a href="https://www.pymc-learn.org/" rel="noopener noreferrer" target="_blank">https://www.pymc-learn.org/</a></li><li>Facebook’s Prophet uses Stan: <a href="https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/</a></li><li>Prophet in PyMC3: <a href="https://github.com/luke14free/pm-prophet" rel="noopener noreferrer" target="_blank">https://github.com/luke14free/pm-prophet</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>When speaking about Bayesian statistics, we often hear about «&nbsp;probabilistic programming&nbsp;» — but what is it? Which languages and libraries allow you to program probabilistically? When is Stan, PyMC, Pyro or any other probabilistic programming language most appropriate for your project? And when should you even use Bayesian libraries instead of non-bayesian tools, like Statsmodels or Scikit-learn?</p><p>Colin Carroll will answer all these questions for you. Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.</p><p>Having studied geometric measure theory at Rice University, Colin was bound to walk in the woods with Pete the pup – who was there when we recorded by the way – and to launch balloons into near-space in his spare time.</p><p>Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com/</a>!</p><p><strong>Links from the show:</strong></p><ul><li>Colin's blog: <a href="https://colindcarroll.com/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/</a></li><li>Colin on Twitter: <a href="https://twitter.com/colindcarroll" rel="noopener noreferrer" target="_blank">https://twitter.com/colindcarroll</a></li><li>Colin on GitHub: <a href="https://github.com/ColCarroll" rel="noopener noreferrer" target="_blank">https://github.com/ColCarroll</a></li><li>Very parallel MCMC sampling: <a href="https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/</a></li><li>A tour of probabilistic programming APIs: <a href="https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/" rel="noopener noreferrer" target="_blank">https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Stan: <a href="https://mc-stan.org/" rel="noopener noreferrer" target="_blank">https://mc-stan.org/</a></li><li>Pyro, Deep Universal Probabilistic Programming: <a href="https://pyro.ai/" rel="noopener noreferrer" target="_blank">https://pyro.ai/</a></li><li>ArviZ, Exploratory analysis of Bayesian models: <a href="https://arviz-devs.github.io/arviz/" rel="noopener noreferrer" target="_blank">https://arviz-devs.github.io/arviz/</a>&nbsp;</li><li>PyMC-Learn, Probabilistic models for machine learning: <a href="https://www.pymc-learn.org/" rel="noopener noreferrer" target="_blank">https://www.pymc-learn.org/</a></li><li>Facebook’s Prophet uses Stan: <a href="https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/" rel="noopener noreferrer" target="_blank">https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/</a></li><li>Prophet in PyMC3: <a href="https://github.com/luke14free/pm-prophet" rel="noopener noreferrer" target="_blank">https://github.com/luke14free/pm-prophet</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/3-1-what-is-probabilistic-programming-why-use-it-with-colin-carroll]]></link><guid isPermaLink="false">db40099d-ba04-7488-1b62-f12195deaffe</guid><itunes:image href="https://artwork.captivate.fm/38268e23-babf-48a4-a05b-bc7a6bef7611/lNdcgPanBbG-XGEmY9dRMN3X.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 05 Nov 2019 20:58:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/31d55fbf-548a-4f40-9b1e-2cb526b733dc/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="46907780" type="audio/mpeg"/><itunes:duration>32:34</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>3</itunes:episode><itunes:season>1</itunes:season><podcast:episode>3</podcast:episode><podcast:season>1</podcast:season><itunes:summary>When speaking about Bayesian statistics, we often hear about « probabilistic programming » — but what is it? Which languages and libraries allow you to program probabilistically? When is Stan, PyMC, Pyro or any other probabilistic programming language most appropriate for your project? And when should you even use Bayesian libraries instead of non-bayesian tools, like Statsmodels or Scikit-learn?

Colin Carroll will answer all these questions for you. Colin is a machine learning researcher and software engineer who’s notably worked on modeling risk in the airline industry and building NLP-powered search infrastructure for finance. He’s also an active contributor to open source, particularly to the popular PyMC3 and ArviZ libraries.

Having studied geometric measure theory at Rice University, Colin was bound to walk in the woods with Pete the pup – who was there when we recorded by the way – and to launch balloons into near-space in his spare time.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com/)!

Links from the show:


 Colin&apos;s blog: https://colindcarroll.com/ (https://colindcarroll.com/)

 Colin on Twitter: https://twitter.com/colindcarroll (https://twitter.com/colindcarroll)

  Colin on GitHub: https://github.com/ColCarroll (https://github.com/ColCarroll)

  Very parallel MCMC sampling: https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/ (https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/)

  A tour of probabilistic programming APIs: https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/ (https://colindcarroll.com/2019/07/23/a-tour-of-probabilistic-programming-apis/)

  PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Stan: https://mc-stan.org/ (https://mc-stan.org/)

  Pyro, Deep Universal Probabilistic Programming: https://pyro.ai/ (https://pyro.ai/)

  ArviZ, Exploratory analysis of Bayesian models: https://arviz-devs.github.io/arviz/ (https://arviz-devs.github.io/arviz/) 

  PyMC-Learn, Probabilistic models for machine learning: https://www.pymc-learn.org/ (https://www.pymc-learn.org/)

  Facebook’s Prophet uses Stan: https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/ (https://statmodeling.stat.columbia.edu/2017/03/01/facebooks-prophet-uses-stan/)

  Prophet in PyMC3: https://github.com/luke14free/pm-prophet (https://github.com/luke14free/pm-prophet)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#2 When should you use Bayesian tools, and Bayes in sports analytics, with Chris Fonnesbeck</title><itunes:title>#2 When should you use Bayesian tools, and Bayes in sports analytics, with Chris Fonnesbeck</itunes:title><description><![CDATA[<p>When are Bayesian methods most useful? Conversely, when should you NOT use them? How do you teach them? What are the most important skills to pick-up when learning Bayes? And what are the most difficult topics, the ones you should maybe save for later?</p><p>In this episode, you’ll hear Chris Fonnesbeck answer these questions from the perspective of marine biology and sports analytics. Chris is indeed the New York Yankees’ senior quantitative analyst and an associate professor at Vanderbilt University School of Medicine.&nbsp;</p><p>He specializes in computational statistics, Bayesian methods, meta-analysis, and applied decision analysis. He also created PyMC, a library to do probabilistic programming in python, and is the author of several tutorials at PyCon and PyData conferences.</p><p>Our theme music is «&nbsp;Good Bayesian&nbsp;», by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com</a>!</p><p><strong>Links from the show</strong>:</p><ul><li>Chris on Twitter: <a href="https://twitter.com/fonnesbeck" rel="noopener noreferrer" target="_blank">https://twitter.com/fonnesbeck</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Chris on GitHub: <a href="https://github.com/fonnesbeck" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck</a></li><li>An introduction to Markov Chain Monte Carlo using PyMC3 - PyData London 2019: <a href="https://www.youtube.com/watch?v=SS_pqgFziAg" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=SS_pqgFziAg</a></li><li>Introduction to Statistical Modeling with Python - PyCon 2017 - video: <a href="https://www.youtube.com/watch?v=TMmSESkhRtI" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=TMmSESkhRtI</a></li><li>Introduction to Statistical Modeling with Python - PyCon 2017 - code repo: <a href="https://github.com/fonnesbeck/intro_stat_modeling_2017" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck/intro_stat_modeling_2017</a></li><li>Bayesian Non-parametric Models for Data Science using PyMC3 - PyCon 2018: <a href="https://www.youtube.com/watch?v=-sIOMs4MSuA" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=-sIOMs4MSuA</a></li><li>Statistical Data Analysis in Python: <a href="https://github.com/fonnesbeck/statistical-analysis-python-tutorial" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck/statistical-analysis-python-tutorial</a></li></ul><br/>]]></description><content:encoded><![CDATA[<p>When are Bayesian methods most useful? Conversely, when should you NOT use them? How do you teach them? What are the most important skills to pick-up when learning Bayes? And what are the most difficult topics, the ones you should maybe save for later?</p><p>In this episode, you’ll hear Chris Fonnesbeck answer these questions from the perspective of marine biology and sports analytics. Chris is indeed the New York Yankees’ senior quantitative analyst and an associate professor at Vanderbilt University School of Medicine.&nbsp;</p><p>He specializes in computational statistics, Bayesian methods, meta-analysis, and applied decision analysis. He also created PyMC, a library to do probabilistic programming in python, and is the author of several tutorials at PyCon and PyData conferences.</p><p>Our theme music is «&nbsp;Good Bayesian&nbsp;», by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at <a href="https://bababrinkman.com/" rel="noopener noreferrer" target="_blank">https://bababrinkman.com</a>!</p><p><strong>Links from the show</strong>:</p><ul><li>Chris on Twitter: <a href="https://twitter.com/fonnesbeck" rel="noopener noreferrer" target="_blank">https://twitter.com/fonnesbeck</a></li><li>PyMC3, Probabilistic Programming in Python: <a href="https://docs.pymc.io/" rel="noopener noreferrer" target="_blank">https://docs.pymc.io/</a></li><li>Chris on GitHub: <a href="https://github.com/fonnesbeck" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck</a></li><li>An introduction to Markov Chain Monte Carlo using PyMC3 - PyData London 2019: <a href="https://www.youtube.com/watch?v=SS_pqgFziAg" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=SS_pqgFziAg</a></li><li>Introduction to Statistical Modeling with Python - PyCon 2017 - video: <a href="https://www.youtube.com/watch?v=TMmSESkhRtI" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=TMmSESkhRtI</a></li><li>Introduction to Statistical Modeling with Python - PyCon 2017 - code repo: <a href="https://github.com/fonnesbeck/intro_stat_modeling_2017" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck/intro_stat_modeling_2017</a></li><li>Bayesian Non-parametric Models for Data Science using PyMC3 - PyCon 2018: <a href="https://www.youtube.com/watch?v=-sIOMs4MSuA" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=-sIOMs4MSuA</a></li><li>Statistical Data Analysis in Python: <a href="https://github.com/fonnesbeck/statistical-analysis-python-tutorial" rel="noopener noreferrer" target="_blank">https://github.com/fonnesbeck/statistical-analysis-python-tutorial</a></li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/2-when-should-you-use-bayesian-tools-and-bayes-in-sports-analytics-with-chris-fonnesbeck]]></link><guid isPermaLink="false">eb2c8ceb-3383-3e9a-8a8b-1c874bf2a9df</guid><itunes:image href="https://artwork.captivate.fm/07da3ca1-43fd-4eea-b97b-ad71dd656a5a/l1jyWkJpA-nxHepXeRXZlb7-.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Wed, 23 Oct 2019 02:03:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/2af3cfb5-0fda-44fc-af3a-b61694bfc6f8/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="62849626" type="audio/mpeg"/><itunes:duration>43:38</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>2</itunes:episode><itunes:season>1</itunes:season><podcast:episode>2</podcast:episode><podcast:season>1</podcast:season><itunes:summary>When are Bayesian methods most useful? Conversely, when should you NOT use them? How do you teach them? What are the most important skills to pick-up when learning Bayes? And what are the most difficult topics, the ones you should maybe save for later?

In this episode, you’ll hear Chris Fonnesbeck answer these questions from the perspective of marine biology and sports analytics. Chris is indeed the New York Yankees’ senior quantitative analyst and an associate professor at Vanderbilt University School of Medicine. 

He specializes in computational statistics, Bayesian methods, meta-analysis, and applied decision analysis. He also created PyMC, a library to do probabilistic programming in python, and is the author of several tutorials at PyCon and PyData conferences.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com/ (https://bababrinkman.com)!

Links from the show:


 Chris on Twitter: https://twitter.com/fonnesbeck (https://twitter.com/fonnesbeck)

 PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/ (https://docs.pymc.io/)

  Chris on GitHub: https://github.com/fonnesbeck (https://github.com/fonnesbeck)

  An introduction to Markov Chain Monte Carlo using PyMC3 - PyData London 2019: https://www.youtube.com/watch?v=SS_pqgFziAg (https://www.youtube.com/watch?v=SS_pqgFziAg)

  Introduction to Statistical Modeling with Python - PyCon 2017 - video: https://www.youtube.com/watch?v=TMmSESkhRtI (https://www.youtube.com/watch?v=TMmSESkhRtI)

  Introduction to Statistical Modeling with Python - PyCon 2017 - code repo: https://github.com/fonnesbeck/intro_stat_modeling_2017 (https://github.com/fonnesbeck/intro_stat_modeling_2017)

  Bayesian Non-parametric Models for Data Science using PyMC3 - PyCon 2018: https://www.youtube.com/watch?v=-sIOMs4MSuA (https://www.youtube.com/watch?v=-sIOMs4MSuA)

  Statistical Data Analysis in Python: https://github.com/fonnesbeck/statistical-analysis-python-tutorial (https://github.com/fonnesbeck/statistical-analysis-python-tutorial)</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#1 Bayes, open-source and bioinformatics, with Osvaldo Martin</title><itunes:title>#1 Bayes, open-source and bioinformatics, with Osvaldo Martin</itunes:title><description><![CDATA[<p>What do you get when you put a physicist, a biologist and a data scientist in the same body? Well, you’re about to find out…&nbsp;</p><p>In this episode you’ll meet Osvaldo Martin. Osvaldo is a researcher at the National Scientific and Technical Research Council in Argentina and is notably the author of the book Bayesian Analysis with Python, whose second edition was published in December 2018.&nbsp;</p><p>He also teaches bioinformatics, data science and Bayesian data analysis, and is a core developer of PyMC3 and ArviZ, and recently started contributing to Bambi. Originally a biologist and physicist, Osvaldo trained himself to python and Bayesian methods – and what he’s doing with it is pretty amazing!</p><p>We also touch on how accepted are Bayesian methods in his field, which models he’s currently working on, and what it’s like to be an open-source developer.</p><p>Our theme music is «&nbsp;Good Bayesian&nbsp;», by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com!</p><p><strong>Links from the show:</strong></p><ul><li>Bayesian Analysis with Python, 2nd edition: https://www.amazon.com/dp/B07HHBCR9G</li><li>Bayesian Analysis with Python, code repository; https://github.com/aloctavodia/BAP</li><li>Osvaldo on Twitter: https://twitter.com/aloctavodia</li><li>PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/</li><li>ArviZ, Exploratory analysis of Bayesian models: https://arviz-devs.github.io/arviz/</li><li>BAyesian Model-Building Interface (BAMBI) in Python: https://bambinos.github.io/bambi/</li></ul><br/>]]></description><content:encoded><![CDATA[<p>What do you get when you put a physicist, a biologist and a data scientist in the same body? Well, you’re about to find out…&nbsp;</p><p>In this episode you’ll meet Osvaldo Martin. Osvaldo is a researcher at the National Scientific and Technical Research Council in Argentina and is notably the author of the book Bayesian Analysis with Python, whose second edition was published in December 2018.&nbsp;</p><p>He also teaches bioinformatics, data science and Bayesian data analysis, and is a core developer of PyMC3 and ArviZ, and recently started contributing to Bambi. Originally a biologist and physicist, Osvaldo trained himself to python and Bayesian methods – and what he’s doing with it is pretty amazing!</p><p>We also touch on how accepted are Bayesian methods in his field, which models he’s currently working on, and what it’s like to be an open-source developer.</p><p>Our theme music is «&nbsp;Good Bayesian&nbsp;», by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com!</p><p><strong>Links from the show:</strong></p><ul><li>Bayesian Analysis with Python, 2nd edition: https://www.amazon.com/dp/B07HHBCR9G</li><li>Bayesian Analysis with Python, code repository; https://github.com/aloctavodia/BAP</li><li>Osvaldo on Twitter: https://twitter.com/aloctavodia</li><li>PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/</li><li>ArviZ, Exploratory analysis of Bayesian models: https://arviz-devs.github.io/arviz/</li><li>BAyesian Model-Building Interface (BAMBI) in Python: https://bambinos.github.io/bambi/</li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/1-bayes-open-source-and-bioinformatics-with-osvaldo-martin]]></link><guid isPermaLink="false">99bd1984-4a72-ca3c-5858-5467c542737d</guid><itunes:image href="https://artwork.captivate.fm/c783f861-ff98-4abd-8a69-416fc32c532b/f0kUzahJXY1J8Ara0jhPO-3P.png"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Tue, 08 Oct 2019 18:53:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/bd776941-58d1-41bb-a0b9-8df11d2206b8/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="119245138" type="audio/mpeg"/><itunes:duration>49:41</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>full</itunes:episodeType><itunes:season>1</itunes:season><itunes:episode>1</itunes:episode><itunes:season>1</itunes:season><podcast:episode>1</podcast:episode><podcast:season>1</podcast:season><itunes:summary>What do you get when you put a physicist, a biologist and a data scientist in the same body? Well, you’re about to find out… 

In this episode you’ll meet Osvaldo Martin. Osvaldo is a researcher at the National Scientific and Technical Research Council in Argentina and is notably the author of the book Bayesian Analysis with Python, whose second edition was published in December 2018. 

He also teaches bioinformatics, data science and Bayesian data analysis, and is a core developer of PyMC3 and ArviZ, and recently started contributing to Bambi. Originally a biologist and physicist, Osvaldo trained himself to python and Bayesian methods – and what he’s doing with it is pretty amazing!

We also touch on how accepted are Bayesian methods in his field, which models he’s currently working on, and what it’s like to be an open-source developer.

Our theme music is « Good Bayesian », by Baba Brinkman (feat MC Lars and Mega Ran). Check out his awesome work at https://bababrinkman.com!

Links from the show:


 Bayesian Analysis with Python, 2nd edition: https://www.amazon.com/dp/B07HHBCR9G

 Bayesian Analysis with Python, code repository; https://github.com/aloctavodia/BAP

 Osvaldo on Twitter: https://twitter.com/aloctavodia

 PyMC3, Probabilistic Programming in Python: https://docs.pymc.io/

  ArviZ, Exploratory analysis of Bayesian models: https://arviz-devs.github.io/arviz/

  BAyesian Model-Building Interface (BAMBI) in Python: https://bambinos.github.io/bambi/</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item><item><title>#0 What is this podcast?</title><itunes:title>#0 What is this podcast?</itunes:title><description><![CDATA[<p>Are you a researcher or data scientist / analyst / ninja? Do you want to learn Bayesian inference, stay up to date or simply want to understand what Bayesian inference is?&nbsp;</p><p>Well I'm just like you! When I started learning Bayesian methods, I really wished there were a podcast out there that could introduce me to the methods, the projects and the people who make all that possible.</p><p>So I created "Learning Bayesian Statistics", a fortnightly podcast where I interview researchers and practitioners of all fields about why and how they use Bayesian statistics, and how in turn YOU, as a learner, can apply these methods in YOUR modeling workflow. Now the thing is, I’m not a beginner, but I’m not an expert either. The people I’ll interview will definitely be. So I’ll be learning alongside you. I won’t pretend to know everything in this podcast, and I WILL make mistakes. But thanks to the guests’ feedback, we’ll be able to learn from those mistakes, and I think this will help you (and me!) become better, faster, stronger Bayesians.</p><p>So, whether you want to learn Bayesian statistics or hear about the latest libraries, books and applications, this podcast is for you. In this very first episode - well actually it’s episode 0, because 0-indexing rules! - I will introduce you to the genesis of this podcast, tell you why you should listen and reveal some of the guests for the coming episodes.</p><p>Come join us!</p><p><strong>Links from the show</strong>:</p><ul><li><strong>Podcast website</strong>: https://learnbayesstats.anvil.app/</li><li><strong>Alex Twitter feed</strong>: https://twitter.com/alex_andorra</li></ul><br/>]]></description><content:encoded><![CDATA[<p>Are you a researcher or data scientist / analyst / ninja? Do you want to learn Bayesian inference, stay up to date or simply want to understand what Bayesian inference is?&nbsp;</p><p>Well I'm just like you! When I started learning Bayesian methods, I really wished there were a podcast out there that could introduce me to the methods, the projects and the people who make all that possible.</p><p>So I created "Learning Bayesian Statistics", a fortnightly podcast where I interview researchers and practitioners of all fields about why and how they use Bayesian statistics, and how in turn YOU, as a learner, can apply these methods in YOUR modeling workflow. Now the thing is, I’m not a beginner, but I’m not an expert either. The people I’ll interview will definitely be. So I’ll be learning alongside you. I won’t pretend to know everything in this podcast, and I WILL make mistakes. But thanks to the guests’ feedback, we’ll be able to learn from those mistakes, and I think this will help you (and me!) become better, faster, stronger Bayesians.</p><p>So, whether you want to learn Bayesian statistics or hear about the latest libraries, books and applications, this podcast is for you. In this very first episode - well actually it’s episode 0, because 0-indexing rules! - I will introduce you to the genesis of this podcast, tell you why you should listen and reveal some of the guests for the coming episodes.</p><p>Come join us!</p><p><strong>Links from the show</strong>:</p><ul><li><strong>Podcast website</strong>: https://learnbayesstats.anvil.app/</li><li><strong>Alex Twitter feed</strong>: https://twitter.com/alex_andorra</li></ul><br/>]]></content:encoded><link><![CDATA[https://learnbayesstats.com/all-episodes/0-what-is-this-podcast]]></link><guid isPermaLink="false">9a7bfeda-f59b-ade0-b534-99a1d6f74463</guid><itunes:image href="https://artwork.captivate.fm/c02a0d9a-468b-4ff3-91fb-dec4758a7bbb/2331893-1568965566684-c5deffdd1481e.jpg"/><dc:creator><![CDATA[Alexandre ANDORRA]]></dc:creator><pubDate>Fri, 20 Sep 2019 07:45:00 -0300</pubDate><enclosure url="https://podcasts.captivate.fm/media/f30fdb5a-1aaa-435d-acc8-6f6b928863d4/https-3a-2f-2fd3ctxlq1ktw2nl-cloudfront-net-2fproduction-2f2019.mp3" length="17723552" type="audio/mpeg"/><itunes:duration>12:18</itunes:duration><itunes:explicit>false</itunes:explicit><itunes:episodeType>trailer</itunes:episodeType><itunes:season>1</itunes:season><itunes:season>1</itunes:season><podcast:season>1</podcast:season><itunes:summary>Are you a researcher or data scientist / analyst / ninja? Do you want to learn Bayesian inference, stay up to date or simply want to understand what Bayesian inference is? 

Well I&apos;m just like you! When I started learning Bayesian methods, I really wished there were a podcast out there that could introduce me to the methods, the projects and the people who make all that possible.

So I created &quot;Learning Bayesian Statistics&quot;, a fortnightly podcast where I interview researchers and practitioners of all fields about why and how they use Bayesian statistics, and how in turn YOU, as a learner, can apply these methods in YOUR modeling workflow. Now the thing is, I’m not a beginner, but I’m not an expert either. The people I’ll interview will definitely be. So I’ll be learning alongside you. I won’t pretend to know everything in this podcast, and I WILL make mistakes. But thanks to the guests’ feedback, we’ll be able to learn from those mistakes, and I think this will help you (and me!) become better, faster, stronger Bayesians.

So, whether you want to learn Bayesian statistics or hear about the latest libraries, books and applications, this podcast is for you. In this very first episode - well actually it’s episode 0, because 0-indexing rules! - I will introduce you to the genesis of this podcast, tell you why you should listen and reveal some of the guests for the coming episodes.

Come join us!

Links from the show:


 Podcast website: https://learnbayesstats.anvil.app/

 Alex Twitter feed: https://twitter.com/alex_andorra</itunes:summary><itunes:author>Alexandre ANDORRA</itunes:author></item></channel></rss>