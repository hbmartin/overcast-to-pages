<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="stylesheet.xsl" type="text/xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:podcast="https://podcastindex.org/namespace/1.0">
  <channel>
    <atom:link rel="self" type="application/atom+xml" href="https://feeds.transistor.fm/how-ai-is-built" title="MP3 Audio"/>
    <atom:link rel="hub" href="https://pubsubhubbub.appspot.com/"/>
    <podcast:podping usesPodping="true"/>
    <title>How AI Is Built </title>
    <generator>Transistor (https://transistor.fm)</generator>
    <itunes:new-feed-url>https://feeds.transistor.fm/how-ai-is-built</itunes:new-feed-url>
    <description>Real engineers. Real deployments. Zero hype. We interview the top engineers who actually put AI in production. Learn what the best engineers have figured out through years of experience. Hosted by Nicolay Gerold, CEO of Aisbach and CTO at Proxdeal and Multiply Content. </description>
    <copyright>Nicolay Gerold</copyright>
    <podcast:guid>c0b72da8-65c9-5856-b5ef-7c2942e43fe7</podcast:guid>
    <podcast:locked owner="nicolay.gerold@gmail.com">no</podcast:locked>
    <podcast:trailer pubdate="Thu, 08 Aug 2024 04:56:49 -0400" url="https://media.transistor.fm/67703f0f/4f603413.mp3" length="4131858" type="audio/mpeg" season="2">Season 2 Trailer: Mastering Search</podcast:trailer>
    <language>en</language>
    <pubDate>Mon, 09 Jun 2025 12:09:29 -0400</pubDate>
    <lastBuildDate>Mon, 09 Jun 2025 12:11:14 -0400</lastBuildDate>
    <link>https://www.howaiisbuilt.fm/</link>
    <image>
      <url>https://img.transistor.fm/vjUdKSCS_pypL9yIAm_uGljytDQbKyzqvBLx9jNLwF4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84MTFl/Y2UwN2FkNDJjNGJk/ZWJkOTQwMTYyYWNh/ODQ4Mi5wbmc.jpg</url>
      <title>How AI Is Built </title>
      <link>https://www.howaiisbuilt.fm/</link>
    </image>
    <itunes:category text="Technology"/>
    <itunes:category text="Technology"/>
    <itunes:type>episodic</itunes:type>
    <itunes:author>Nicolay Gerold</itunes:author>
    <itunes:image href="https://img.transistor.fm/vjUdKSCS_pypL9yIAm_uGljytDQbKyzqvBLx9jNLwF4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84MTFl/Y2UwN2FkNDJjNGJk/ZWJkOTQwMTYyYWNh/ODQ4Mi5wbmc.jpg"/>
    <itunes:summary>Real engineers. Real deployments. Zero hype. We interview the top engineers who actually put AI in production. Learn what the best engineers have figured out through years of experience. Hosted by Nicolay Gerold, CEO of Aisbach and CTO at Proxdeal and Multiply Content. </itunes:summary>
    <itunes:subtitle>Real engineers.</itunes:subtitle>
    <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
    <itunes:owner>
      <itunes:name>Nicolay Gerold</itunes:name>
      <itunes:email>nicolay.gerold@gmail.com</itunes:email>
    </itunes:owner>
    <itunes:complete>No</itunes:complete>
    <itunes:explicit>No</itunes:explicit>
    <item>
      <title>#050 Bringing LLMs to Production: Delete Frameworks, Avoid Finetuning, Ship Faster</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:title>#050 Bringing LLMs to Production: Delete Frameworks, Avoid Finetuning, Ship Faster</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">13218616-d250-4a59-962c-61ad92682a7a</guid>
      <link>https://share.transistor.fm/s/ea1f11c1</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Tue, 27 May 2025 07:13:59 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/ea1f11c1/410464c1.mp3" length="64338520" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/YIq_-5xk01Fz8z1v_BPTD8ygMUU6vAJOqFhc45zDfJA/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jMzdh/NDZjZmU1Y2EyMTdl/ZGY5YjZhZTBkOWEx/MWMxMi5wbmc.jpg"/>
      <itunes:duration>4018</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, llm, rag</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#050 TAKEAWAYS Bringing LLMs to Production: Delete Frameworks, Avoid Finetuning, Ship Faster</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:title>#050 TAKEAWAYS Bringing LLMs to Production: Delete Frameworks, Avoid Finetuning, Ship Faster</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">49454fbc-6aae-4a40-a411-f89f44fb2b93</guid>
      <link>https://share.transistor.fm/s/be6022b7</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Tue, 27 May 2025 07:08:13 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/be6022b7/8ca3a843.mp3" length="10617400" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/Ch0qp3cR6IcwimgLFc5R6QBQ8NexgAngQ-qBqC9qy9A/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84N2Iy/YmUxZTkzMTY5OWE5/ZmI3OWJiYmZkYWVk/ZjY0Yi5wbmc.jpg"/>
      <itunes:duration>661</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>Most AI developers are drowning in frameworks and hype. This conversation is about cutting through the noise and actually getting something into production.</p><p>Today I have the chance to talk to Paul Iusztin, who's spent 8 years in AI - from writing CUDA kernels in C++ to building modern LLM applications. He currently writes about production AI systems and is building his own AI writing assistant.</p><p>His philosophy is refreshingly simple: stop overthinking, start building, and let patterns emerge through use.</p><p>The key insight that stuck with me: "If you don't feel the algorithm - like have a strong intuition about how components should work together - you can't innovate, you just copy paste stuff." This hits hard because so much of current AI development is exactly that - copy-pasting from tutorials without understanding the why.</p><p>Paul's approach to frameworks is particularly controversial. He uses LangChain and similar tools for quick prototyping - maybe an hour or two to validate an idea - then throws them away completely. "They're low-code tools," he says. "Not good frameworks to build on top of."</p><p>Instead, he advocates for writing your own database layers and using industrial-grade orchestration tools. Yes, it's more work upfront. But when you need to debug or scale, you'll thank yourself.</p><p>In the podcast, we also cover:</p><ul><li>Why fine-tuning is almost always the wrong choice</li><li>The "just-in-time" learning approach for staying sane in AI</li><li>Building writing assistants that actually preserve your voice</li><li>Why robots, not chatbots, are the real endgame</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Agentic Patterns:</strong> These patterns seem complex but are actually straightforward to implement once you understand the core loop.¬†<ul><li><strong>React</strong>: Agents that Reason, Act, and Observe in a loop</li><li><strong>Reflection</strong>: Agents that review and improve their own outputs</li></ul></li><li><strong>Fine-tuning vs Base Model + Prompting:</strong> Fine-tuning involves taking a pre-trained model and training it further on your specific data. The alternative is using base models with careful prompting and context engineering. <strong>Paul's take</strong>: "Fine-tuning adds so much complexity... if you add fine-tuning to create a new feature, it's just from one day to one week."</li><li><strong>RAG:</strong> A technique where you retrieve relevant documents/information and include them in the LLM's context to generate better responses. <strong>Paul's approach</strong>: "In the beginning I also want to avoid RAG and just introduce a more guided research approach. Like I say, hey, these are the resources that I want to use in this article."</li></ul><p>üì∂ <strong>Connect with Paul:</strong></p><ul><li><a href="https://www.linkedin.com/in/pauliusztin/">LinkedIn</a></li><li><a href="https://x.com/iusztinpaul">X / Twitter</a></li><li><a href="https://t.co/6tzvO5MUOV">Newsletter</a></li><li><a href="https://github.com/iusztinpaul">GitHub</a></li><li><a href="https://decodingml.substack.com/p/llm-engineers-handbook-is-finally?open=false#%C2%A7get-your-copy">Book</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>From CUDA to LLMs</strong>: [02:20] Paul's journey from writing CUDA kernels and 3D object detection to modern AI applications.</li><li><strong>AI Content Is Natural Evolution</strong>: [11:19] Why AI writing tools are like the internet transition for artists - tools change, creativity remains.</li><li><strong>The Framework Trap</strong>: [36:41] "I see them as no code or low code tools... not good frameworks to build on top of."</li><li><strong>Fine-Tuning Complexity Bomb</strong>: [27:41] How fine-tuning turns 1-day features into 1-week experiments.</li><li><strong>End-to-End First</strong>: [22:44] "I don't focus on accuracy, performance, or latency initially. I just want an end-to-end process that works."</li><li><strong>The Orchestration Solution</strong>: [40:04] Why Temporal, D-Boss, and Restate beat LLM-specific orchestrators.</li><li><strong>Hype Filtering System</strong>: [54:06] Paul's approach: read about new tools, wait 2-3 months, only adopt if still relevant.</li><li><strong>Just-in-Time vs Just-in-Case</strong>: [57:50] The crucial difference between learning for potential needs vs immediate application.</li><li><strong>Robot Vision</strong>: [50:29] Why LLMs are just stepping stones to embodied AI and the unsolved challenges ahead.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://python.langchain.com/docs/langgraph">LangGraph</a> (for prototyping only)</li><li><a href="https://temporal.io/">Temporal</a> (durable execution)</li><li><a href="https://www.dbos.dev/">DBOS</a> (simpler orchestration)</li><li><a href="https://restate.dev/">Restate</a> (developer-friendly orchestration)</li><li><a href="https://www.ray.io/">Ray</a> (distributed compute)</li><li><a href="https://github.com/astral-sh/uv">UV</a> (Python packaging)</li><li><a href="https://www.prefect.io/">Prefect</a> (workflow orchestration)</li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://www.amazon.de/-/en/Economist-Style-Guide-12th/dp/1781258317">The Economist Style Guide</a> (for writing)</li><li><a href="https://www.brandonsanderson.com/">Brandon Sanderson's Writing Approach</a> (worldbuilding first)</li><li><a href="https://academy.langchain.com/">LangGraph Academy</a> (free, covers agent patterns)</li><li><a href="https://docs.ray.io/">Ray Documentation</a> (Paul's next deep dive)</li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will take a detour and go into the networking behind voice AI with Russell D‚ÄôSa from Livekit.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. Pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, llm, agent</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#049 BAML: The Programming Language That Turns LLMs into Predictable Functions</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>2</itunes:episode>
      <podcast:episode>2</podcast:episode>
      <itunes:title>#049 BAML: The Programming Language That Turns LLMs into Predictable Functions</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">57eb3cc5-a2f0-4ed3-b7bc-03d9252b3bbc</guid>
      <link>https://share.transistor.fm/s/2f7eb95f</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Tue, 20 May 2025 06:10:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/2f7eb95f/1f8bfdf0.mp3" length="60195467" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/7w37JQtQoS5kyuBYmk8IlCLCS77uFahYYVVROmvtcYg/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9iN2Ix/YTA1Zjg5NTA3OWU4/N2UwYzRhMDYzMGVh/Y2IyMi5wbmc.jpg"/>
      <itunes:duration>3759</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/2f7eb95f/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#049 TAKEAWAYS BAML: The Programming Language That Turns LLMs into Predictable Functions</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>2</itunes:episode>
      <podcast:episode>2</podcast:episode>
      <itunes:title>#049 TAKEAWAYS BAML: The Programming Language That Turns LLMs into Predictable Functions</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">ef55c5ff-c035-49ad-9b9e-84651496b92b</guid>
      <link>https://share.transistor.fm/s/772b4174</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Tue, 20 May 2025 06:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/772b4174/d088c850.mp3" length="69723446" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/5X0Qo_f7rn9U0bhfE0PHtoyk3YkExwk2wkrECFWnNSE/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS80Y2Jj/YTUwY2U3MzQ2MzI4/N2Q3MTBiOWM2ZWEw/OWRiOS5wbmc.jpg"/>
      <itunes:duration>4355</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>I think by now we are done with marveling at the latest benchmark scores of the models. It doesn‚Äôt tell us much anymore that the latest generation outscores the previous by a few basis points.</p><p>If you don‚Äôt know how the LLM performs on your task, you are just duct taping LLMs into your systems.</p><p>If your LLM-powered app can‚Äôt survive a malformed emoji, you‚Äôre shipping liability, not software.</p><p>Today, I sat down with <strong>Vaibhav</strong> (co-founder of Boundary) to dissect <strong>BAML</strong>‚Äîa DSL that treats every LLM call as a typed function.</p><p>It‚Äôs like swapping duct-taped Python scripts for a purpose-built compiler.</p><p>Vaibhav advocates for building first principle based primitives.</p><p>One principle stood out: <strong>LLMs are just functions; build like that from day 1.</strong> Wrap them, test them, and let a human only where it counts.</p><p>Once you adopt that frame, reliability patterns fall into place: fallback heuristics, model swaps, classifiers‚Äîsame playbook we already use for flaky APIs.</p><p>We also cover:</p><ul><li>Why JSON constraints are the wrong hammer‚Äîand how Schema-Aligned Parsing fixes it</li><li>Whether ‚Äúdurable‚Äù should be a first-class keyword (think async/await for crash-safety)</li><li>Shipping multi-language AI pipelines without forcing a Python microservice</li><li>Token-bloat surgery, symbol tuning, and the myth of magic prompts</li><li>How to keep humans sharp when 98 % of agent outputs are already correct</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Schema-Aligned Parsing (SAP)</strong></li><li>Parse first, panic later. The model can handle Markdown, half-baked YAML, or rogue quotes‚ÄîSAP puts it into your declared type or raises. No silent corruption.</li><li><strong>Symbol Tuning</strong></li><li>Labels eat up tokens and often don‚Äôt help with your accuracy (in some cases they even hurt). Rename PasswordReset to C7, keep the description human-readable.</li><li><strong>Durable Execution</strong></li><li>Durable execution refers to a computing paradigm where program execution state persists despite failures, interruptions, or crashes. It ensures that operations resume exactly where they left off, maintaining progress even when systems go down.</li><li><strong>Prompt Compression</strong></li><li>Every extra token is latency, cost, and entropy. Axe filler words until the prompt reads like assembly. If output degrades, you cut too deep‚Äîback off one line.</li></ul><p>üì∂ <strong>Connect with Vaibhav:</strong></p><ul><li><a href="https://www.linkedin.com/in/vaigup/">LinkedIn</a></li><li><a href="https://x.com/hellovai">X / Twitter</a></li><li><a href="https://github.com/boundaryml/baml">BAML</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://nicolaygerold.substack.com/subscribe">Newsletter</a></li><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>New DSL vs. Python Glue</strong> [00:54]</li><li>Why bolting yet another microservice onto your stack is cowardice; BAML compiles instead of copies.</li><li><strong>Three-Nines on Flaky Models</strong> [04:27]</li><li>Designing retries, fallbacks, and human overrides when GPT eats dirt 5 % of the time.</li><li><strong>Native Go SDK &amp; OpenAPI Fatigue</strong> [06:32]</li><li>Killing thousand-line generated clients; typing go get instead.</li><li><strong>‚ÄúLLM = Pure Function‚Äù Mental Model</strong> [15:58]</li><li>Replace mysticism with f(input) ‚Üí output; unit-test like any other function.</li><li><strong>Tool-Calling as a Switch Statement</strong> [18:19]</li><li>Multi-tool orchestration boils down to switch(action) {‚Ä¶}‚Äîno cosmic ‚Äúagent‚Äù needed.</li><li><strong>Sneak Peek‚Äîdurable Keyword</strong> [24:49]</li><li>Crash-safe workflows without shoving state into S3 and praying.</li><li><strong>Symbol Tuning Demo</strong> [31:35]</li><li>Swapping verbose labels for C0,C1 slashes token cost and bias in one shot.</li><li><strong>Inside SAP Coercion Logic</strong> [47:31]</li><li>Int arrays to ints, scalars to lists, bad casts raise‚Äîdeterministic, no LLM in the loop.</li><li><strong>Frameworks vs. Primitives Rant</strong> [52:32]</li><li>Why BAML ships primitives and leaves the ‚Äúbatteries‚Äù to you‚Äîless magic, more control.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML DSL</a> &amp; <a href="https://www.promptfiddle.com/">Playground</a></li><li><a href="https://temporal.io/">Temporal</a> ‚Ä¢ <a href="https://www.prefect.io/">Prefect</a> ‚Ä¢ <a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://github.com/dottxt-ai/outlines">outlines</a> ‚Ä¢ <a href="https://python.useinstructor.com/">Instructor</a> ‚Ä¢ <a href="https://www.langchain.com/">LangChain</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://www.boundaryml.com/blog/schema-aligned-parsing">Schema-Aligned Parsing (SAP)</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Paul Iusztin.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è Here's the deal: I'm committed to bringing you detailed, practical insights about AI development and implementation. In return, I have two simple requests:</p><ul><li><strong>Hit subscribe right now</strong> to help me understand what content resonates with you</li><li>If you found value in this post, <strong>share it with one other developer</strong> or tech professional who's working with AI</li></ul><p>That's our agreement - I deliver actionable AI insights, you help grow this. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#048 TAKEAWAYS Why Your AI Agents Need Permission to Act, Not Just Read</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:title>#048 TAKEAWAYS Why Your AI Agents Need Permission to Act, Not Just Read</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">06744cbe-808b-4d97-ade4-aca466b9d1e7</guid>
      <link>https://share.transistor.fm/s/bffb3a62</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Tue, 13 May 2025 06:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/bffb3a62/e9ce6287.mp3" length="6876240" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/kzVgRW3OW45fted_a915sfwQCMe-vHDSIW_kAGygO7M/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS80NTU1/YjdmMWM2ODMzNjRi/NzZlMGFjMjY4MjEz/NTIyYy5wbmc.jpg"/>
      <itunes:duration>427</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#048 Why Your AI Agents Need Permission to Act, Not Just Read</title>
      <itunes:season>3</itunes:season>
      <podcast:season>3</podcast:season>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:title>#048 Why Your AI Agents Need Permission to Act, Not Just Read</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">037308e7-ab84-48c4-8412-a1a9bbf365c6</guid>
      <link>https://share.transistor.fm/s/5c027c15</link>
      <description>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?¬†</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?¬†</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </content:encoded>
      <pubDate>Sun, 11 May 2025 06:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/5c027c15/d70081bc.mp3" length="54805477" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/It1A36FxpXzvQ9v1MPEZUIvEuzQPywegmymumivticQ/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS85YzY5/OTlhNjg3NTg0ODAw/NGZjYzJiMDU2ZmVh/MjViNS5wbmc.jpg"/>
      <itunes:duration>3423</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Nicolay here,</p><p>most AI conversations obsess over capabilities. This one focuses on constraints - the right ones that make AI actually useful rather than just impressive demos.</p><p>Today I have the chance to talk to Dexter Horthy, who recently put out a long piece called the ‚Äú12-factor agents‚Äù.</p><p>It‚Äôs like the 10 commandments, but for building agents.</p><p>One of it is ‚ÄúContact human with tool calls‚Äù: the LLM can call humans for high-stakes decisions or ‚Äúwrites‚Äù.</p><p>The key insight is brutally simple. AI can get to 90% accuracy on most tasks - good enough for spam-like activities but disastrous for anything that requires trust. The solution isn't to wait for models to get smarter; it's to add a human approval layer for critical actions.</p><p>Imagine you are writing to a database or sending an email. Each ‚Äúwrite‚Äù has to be approved by a human. So you post the email in a Slack channel and in most cases, your sales people will approve. In the 10%, it‚Äôs stopped in its tracks and the human can take over. You stop the slop and get good training data in the mean time.</p><p>Dexter‚Äôs company is building exactly this: an approval mechanism that lets AI agents send requests to humans before executing.</p><p>In the podcast, we also touch on a bunch of other things:</p><ul><li>MCP and that they are (atm) just a thin client</li><li>Are we training LLMs toward mediocrity?</li><li>What infrastructure do we need for human in the loop (e.g. DBOS)?¬†</li><li>and more</li></ul><p><strong>üí° Core Concepts</strong></p><ul><li><strong>Context Engineering</strong>: Crafting the information representation for LLMs - selecting optimal data structures, metadata, and formats to ensure models receive precisely what they need to perform effectively.</li><li><strong>Token Bloat Prevention</strong>: Ruthlessly eliminating irrelevant information from context windows to maintain agent focus during complex tasks, preventing the pattern of repeating failed approaches.</li><li><strong>Human-in-the-loop Approval Flows</strong>: Achieving 99% reliability through a "90% AI + 10% human oversight" framework where agents analyze data and suggest actions but request explicit permission before execution.</li><li><strong>Rubric Engineering</strong>: Systematically evaluating AI outputs through dimension-specific scoring criteria to provide precise feedback and identify exceptional results, helping escape the trap of models converging toward mediocrity.</li></ul><p>üì∂ <strong>Connect with Dexter:</strong></p><ul><li><a href="https://www.linkedin.com/in/dexterihorthy/">LinkedIn</a></li><li><a href="https://x.com/dexhorthy?lang=en">X / Twitter</a></li><li><a href="https://www.humanlayer.dev/">Company</a></li></ul><p>üì∂ <strong>Connect with Nicolay:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://x.com/nicolaygerold">X / Twitter</a></li><li><a href="https://bsky.app/profile/nicolaygerold.com">Bluesky</a></li><li><a href="https://www.nicolaygerold.com/">Website</a></li><li><a href="https://www.aisbach.com/">My Agency Aisbach</a> (for ai implementations / strategy)</li></ul><p><strong>‚è±Ô∏è Important Moments</strong></p><ul><li><strong>MCP Servers as Clients</strong>: [03:07] Dexter explains why what many call "MCP servers" actually function more like clients when examining the underlying code.</li><li><strong>Authentication Challenges</strong>: [04:45] The discussion shifts to how authentication should be handled in MCP implementations and whether it belongs in the protocol.</li><li><strong>Asynchronous Agent Execution</strong>: [08:18] Exploring how to handle agents that need to pause for human input without wasting tokens on continuous polling.</li><li><strong>Token Bloat Prevention</strong>: [14:41] Strategies for keeping context windows focused and efficient, moving beyond standard chat formats.</li><li><strong>Context Engineering</strong>: [29:06] The concept that everything in AI agent development ultimately comes down to effective context engineering.</li><li><strong>Fine-tuning vs. RAG for Writing Style</strong>: [20:05] Contrasting personal writing style fine-tuning versus context window examples.</li><li><strong>Generating Options vs. Deterministic Outputs</strong>: [19:44] The unexplored potential of having AI generate diverse creative options for human selection.</li><li><strong>The "Mediocrity Convergence" Question</strong>: [37:11] The philosophical concern that popular LLMs may inevitably trend toward average quality.</li><li><strong>Data Labeling Interfaces</strong>: [35:25] Discussion about the need for better, lower-friction interfaces to collect human feedback on AI outputs.</li><li><strong>Human-in-the-loop Approval Flows</strong>: [42:46] The core approach of HumanLayer, allowing agents to ask permission before taking action.</li></ul><p><strong>üõ†Ô∏è Tools &amp; Tech Mentioned</strong></p><ul><li><a href="https://github.com/modelcontextprotocol">MCP</a></li><li><a href="https://opencontrol.ai/">OpenControl</a></li><li><a href="https://www.dbos.dev/">DBOS</a></li><li><a href="https://temporal.io/">Temporal</a></li><li><a href="https://www.cursor.com/">Cursor</a></li></ul><p><strong>üìö Recommended Resources</strong></p><ul><li><a href="https://github.com/humanlayer/12-factor-agents/tree/main/content">12 Factor Agents</a></li><li><a href="https://docs.boundaryml.com/home">BAML Docs</a></li><li><a href="https://x.com/willccbb/status/1883611121577517092">Rubric Engineering</a></li></ul><p><strong>üîÆ What's Next</strong></p><p>Next week, we will continue going more into getting generative AI into production talking to Vibhav from BAML.</p><p><strong>üí¨ Join The Conversation</strong></p><p>Follow How AI Is Built on <a href="https://www.youtube.com/@howaiisbuilt">YouTube</a>, <a href="https://bsky.app/profile/howaiisbuilt.fm">Bluesky</a>, or <a href="https://open.spotify.com/show/3hhSTyHSgKPVC4sw3H0NUc?_authfailed=1">Spotify</a>.</p><p>If you have any suggestions for future guests, feel free to leave it in the comments or write me (Nicolay) directly on <a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a>, <a href="https://x.com/nicolaygerold">X</a>, or <a href="https://bsky.app/">Bluesky</a>. Or at <a href="mailto:nicolay.gerold@gmail.com">nicolay.gerold@gmail.com</a>.</p><p>I will be opening a Discord soon to get you guys more involved in the episodes! Stay tuned for that.</p><p>‚ôªÔ∏è I am trying to build the new platform for engineers to share their experience that they have earned after building and deploying stuff into production. I am trying to produce the best content possible - informative, actionable, and engaging. I'm asking for two things: hit subscribe now to show me what content you like (so I can do more of it), and if this episode helped you, pay it forward by sharing with one engineer who's facing similar challenges. That's the agreement - I deliver practical value, you help grow this resource for everyone. ‚ôªÔ∏è</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/5c027c15/transcription.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/5c027c15/transcription.srt" type="application/x-subrip" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/5c027c15/transcription.json" type="application/json" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/5c027c15/transcription.txt" type="text/plain"/>
      <podcast:transcript url="https://share.transistor.fm/s/5c027c15/transcription" type="text/html"/>
    </item>
    <item>
      <title>#047 Architecting Information for Search, Humans, and Artificial Intelligence </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>30</itunes:episode>
      <podcast:episode>30</podcast:episode>
      <itunes:title>#047 Architecting Information for Search, Humans, and Artificial Intelligence </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">23e549a0-3369-4cec-93b4-d5e8c73c8985</guid>
      <link>https://share.transistor.fm/s/3cce0a3f</link>
      <description>
        <![CDATA[<p>Today on <strong>How AI Is Built</strong>, Nicolay Gerold sits down with Jorge Arango, an expert in information architecture. Jorge emphasizes that aligning systems with users' mental models is more important than optimizing backend logic alone. He shares a clear framework with four practical steps:</p><p><strong>Key Points:</strong></p><ul><li>Information architecture should bridge user mental models with system data models</li><li>Information's purpose is to help people make better choices and act more skillfully</li><li>Well-designed systems create learnable (not just "intuitive") interfaces</li><li>Context and domain boundaries significantly impact user understanding</li><li>Progressive disclosure helps accommodate users with varying expertise levels</li></ul><p><strong>Chapters</strong></p><ul><li>00:00 Introduction to Backend Systems</li><li>00:36 Guest Introduction: Jorge Arango</li><li>01:12 Podcast Dynamics and Guest Experiences</li><li>01:53 Timeless Principles in Technology</li><li>02:08 Interesting Conversations and Learnings</li><li>04:04 Physical vs. Digital Organization</li><li>04:21 Smart Defaults and System Maintenance</li><li>07:20 Data Models and Conceptual Structures</li><li>08:53 Designing User-Centric Systems</li><li>10:20 Challenges in Information Systems</li><li>10:35 Understanding Information and Choices</li><li>15:49 Clarity and Context in Design</li><li>26:36 Progressive Disclosure and User Research</li><li>37:05 The Role of Large Language Models</li><li>54:59 Future Directions and New Series (MLOps)</li></ul><p><strong>Information Architecture Fundamentals</strong></p><p><strong>What Is Information?</strong></p><ul><li>Information helps people make better choices to act more skillfully</li><li>Example: "No dog pooping" signs help predict consequences of actions</li><li>Poor information systems fail to provide relevant guidance for users' needs</li></ul><p><strong>Mental Models vs. Data Models</strong></p><ul><li>Systems have underlying conceptual structures that should reflect user mental models</li><li>Data models make these conceptual models "normative" in the infrastructure</li><li>Designers serve as translators between user needs and technical implementation</li><li>Goal: Users should think "the person who designed this really gets me"</li></ul><p><strong>Design Strategies for Complex Systems</strong></p><p><strong>Progressive Disclosure</strong></p><ul><li>Present simple interfaces by default with clear paths to advanced functionality</li><li>Example: HyperCard - visual interface for beginners with programming layer for experts</li><li>Allows both novice and expert users to use the same system effectively</li></ul><p><strong>Context Setting and Domain Boundaries</strong></p><ul><li>All interactions happen within a context that influences understanding</li><li>Words acquire different meanings in different contexts (e.g., "save" in computing vs. banking)</li><li>Clearer domain boundaries make information architecture design easier</li><li>Hardest systems to design: those serving many purposes for diverse audiences</li></ul><p><strong>Conceptual Modeling (Underrated Practice)</strong></p><ul><li>Should precede UI sketching but often skipped by designers</li><li>Defines concepts needed in the system and their relationships</li><li>Creates more cohesive and coherent systems, especially for complex projects</li><li>More valuable than sitemaps, which imply rigid hierarchies</li></ul><p><strong>LLMs and Information Architecture</strong></p><p><strong>Current and Future Applications</strong></p><ul><li>Transforming search experiences (e.g., Perplexity providing answers vs. link lists)</li><li>Improving intent parsing in traditional search</li><li>Helping information architects with content analysis and navigation structure design</li><li>Enabling faster, better analysis of large content repositories</li></ul><p><strong>Implementation Advice</strong></p><p><strong>For Engineers and Designers</strong></p><ul><li>Designers should understand how systems are built (materials of construction)</li><li>Engineers benefit from understanding user perspectives and mental models</li><li>Both disciplines have much to teach each other</li></ul><p><strong>For Complex Applications</strong></p><ul><li>Map conceptual models before writing code</li><li>Test naming with real users</li><li>Implement progressive disclosure with good defaults</li><li>Remember: "If the user can't find it, it doesn't exist"</li></ul><p><strong>Notable Quotes:</strong></p><p>"People only understand things relative to things they already understand." - Richard Saul Wurman</p><p>"The hardest systems to design are the ones that are meant to do a lot of things for a lot of different people." - Jorge Arango</p><p>"Very few things are intuitive. There's a long running joke in the industry that the only intuitive interface for humans is the nipple. Everything else is learned." - Jorge Arango</p><p><strong>Jorge Arango</strong></p><ul><li><a href="https://www.linkedin.com/in/jarango/">LinkedIn</a></li><li><a href="https://jarango.com/">Website</a></li><li><a href="https://x.com/jarango">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today on <strong>How AI Is Built</strong>, Nicolay Gerold sits down with Jorge Arango, an expert in information architecture. Jorge emphasizes that aligning systems with users' mental models is more important than optimizing backend logic alone. He shares a clear framework with four practical steps:</p><p><strong>Key Points:</strong></p><ul><li>Information architecture should bridge user mental models with system data models</li><li>Information's purpose is to help people make better choices and act more skillfully</li><li>Well-designed systems create learnable (not just "intuitive") interfaces</li><li>Context and domain boundaries significantly impact user understanding</li><li>Progressive disclosure helps accommodate users with varying expertise levels</li></ul><p><strong>Chapters</strong></p><ul><li>00:00 Introduction to Backend Systems</li><li>00:36 Guest Introduction: Jorge Arango</li><li>01:12 Podcast Dynamics and Guest Experiences</li><li>01:53 Timeless Principles in Technology</li><li>02:08 Interesting Conversations and Learnings</li><li>04:04 Physical vs. Digital Organization</li><li>04:21 Smart Defaults and System Maintenance</li><li>07:20 Data Models and Conceptual Structures</li><li>08:53 Designing User-Centric Systems</li><li>10:20 Challenges in Information Systems</li><li>10:35 Understanding Information and Choices</li><li>15:49 Clarity and Context in Design</li><li>26:36 Progressive Disclosure and User Research</li><li>37:05 The Role of Large Language Models</li><li>54:59 Future Directions and New Series (MLOps)</li></ul><p><strong>Information Architecture Fundamentals</strong></p><p><strong>What Is Information?</strong></p><ul><li>Information helps people make better choices to act more skillfully</li><li>Example: "No dog pooping" signs help predict consequences of actions</li><li>Poor information systems fail to provide relevant guidance for users' needs</li></ul><p><strong>Mental Models vs. Data Models</strong></p><ul><li>Systems have underlying conceptual structures that should reflect user mental models</li><li>Data models make these conceptual models "normative" in the infrastructure</li><li>Designers serve as translators between user needs and technical implementation</li><li>Goal: Users should think "the person who designed this really gets me"</li></ul><p><strong>Design Strategies for Complex Systems</strong></p><p><strong>Progressive Disclosure</strong></p><ul><li>Present simple interfaces by default with clear paths to advanced functionality</li><li>Example: HyperCard - visual interface for beginners with programming layer for experts</li><li>Allows both novice and expert users to use the same system effectively</li></ul><p><strong>Context Setting and Domain Boundaries</strong></p><ul><li>All interactions happen within a context that influences understanding</li><li>Words acquire different meanings in different contexts (e.g., "save" in computing vs. banking)</li><li>Clearer domain boundaries make information architecture design easier</li><li>Hardest systems to design: those serving many purposes for diverse audiences</li></ul><p><strong>Conceptual Modeling (Underrated Practice)</strong></p><ul><li>Should precede UI sketching but often skipped by designers</li><li>Defines concepts needed in the system and their relationships</li><li>Creates more cohesive and coherent systems, especially for complex projects</li><li>More valuable than sitemaps, which imply rigid hierarchies</li></ul><p><strong>LLMs and Information Architecture</strong></p><p><strong>Current and Future Applications</strong></p><ul><li>Transforming search experiences (e.g., Perplexity providing answers vs. link lists)</li><li>Improving intent parsing in traditional search</li><li>Helping information architects with content analysis and navigation structure design</li><li>Enabling faster, better analysis of large content repositories</li></ul><p><strong>Implementation Advice</strong></p><p><strong>For Engineers and Designers</strong></p><ul><li>Designers should understand how systems are built (materials of construction)</li><li>Engineers benefit from understanding user perspectives and mental models</li><li>Both disciplines have much to teach each other</li></ul><p><strong>For Complex Applications</strong></p><ul><li>Map conceptual models before writing code</li><li>Test naming with real users</li><li>Implement progressive disclosure with good defaults</li><li>Remember: "If the user can't find it, it doesn't exist"</li></ul><p><strong>Notable Quotes:</strong></p><p>"People only understand things relative to things they already understand." - Richard Saul Wurman</p><p>"The hardest systems to design are the ones that are meant to do a lot of things for a lot of different people." - Jorge Arango</p><p>"Very few things are intuitive. There's a long running joke in the industry that the only intuitive interface for humans is the nipple. Everything else is learned." - Jorge Arango</p><p><strong>Jorge Arango</strong></p><ul><li><a href="https://www.linkedin.com/in/jarango/">LinkedIn</a></li><li><a href="https://jarango.com/">Website</a></li><li><a href="https://x.com/jarango">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </content:encoded>
      <pubDate>Thu, 27 Mar 2025 06:12:58 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/3cce0a3f/ff71aa0f.mp3" length="55114574" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/SxXLgCI44BKfuly1ovwol7jRMLT_fSkB9UzdyFMRM0w/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9lNjQw/Y2MzNzRkNzY5NGU1/NTUwYjk3MjQyZWI5/ZmU0Yi5wbmc.jpg"/>
      <itunes:duration>3442</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today on <strong>How AI Is Built</strong>, Nicolay Gerold sits down with Jorge Arango, an expert in information architecture. Jorge emphasizes that aligning systems with users' mental models is more important than optimizing backend logic alone. He shares a clear framework with four practical steps:</p><p><strong>Key Points:</strong></p><ul><li>Information architecture should bridge user mental models with system data models</li><li>Information's purpose is to help people make better choices and act more skillfully</li><li>Well-designed systems create learnable (not just "intuitive") interfaces</li><li>Context and domain boundaries significantly impact user understanding</li><li>Progressive disclosure helps accommodate users with varying expertise levels</li></ul><p><strong>Chapters</strong></p><ul><li>00:00 Introduction to Backend Systems</li><li>00:36 Guest Introduction: Jorge Arango</li><li>01:12 Podcast Dynamics and Guest Experiences</li><li>01:53 Timeless Principles in Technology</li><li>02:08 Interesting Conversations and Learnings</li><li>04:04 Physical vs. Digital Organization</li><li>04:21 Smart Defaults and System Maintenance</li><li>07:20 Data Models and Conceptual Structures</li><li>08:53 Designing User-Centric Systems</li><li>10:20 Challenges in Information Systems</li><li>10:35 Understanding Information and Choices</li><li>15:49 Clarity and Context in Design</li><li>26:36 Progressive Disclosure and User Research</li><li>37:05 The Role of Large Language Models</li><li>54:59 Future Directions and New Series (MLOps)</li></ul><p><strong>Information Architecture Fundamentals</strong></p><p><strong>What Is Information?</strong></p><ul><li>Information helps people make better choices to act more skillfully</li><li>Example: "No dog pooping" signs help predict consequences of actions</li><li>Poor information systems fail to provide relevant guidance for users' needs</li></ul><p><strong>Mental Models vs. Data Models</strong></p><ul><li>Systems have underlying conceptual structures that should reflect user mental models</li><li>Data models make these conceptual models "normative" in the infrastructure</li><li>Designers serve as translators between user needs and technical implementation</li><li>Goal: Users should think "the person who designed this really gets me"</li></ul><p><strong>Design Strategies for Complex Systems</strong></p><p><strong>Progressive Disclosure</strong></p><ul><li>Present simple interfaces by default with clear paths to advanced functionality</li><li>Example: HyperCard - visual interface for beginners with programming layer for experts</li><li>Allows both novice and expert users to use the same system effectively</li></ul><p><strong>Context Setting and Domain Boundaries</strong></p><ul><li>All interactions happen within a context that influences understanding</li><li>Words acquire different meanings in different contexts (e.g., "save" in computing vs. banking)</li><li>Clearer domain boundaries make information architecture design easier</li><li>Hardest systems to design: those serving many purposes for diverse audiences</li></ul><p><strong>Conceptual Modeling (Underrated Practice)</strong></p><ul><li>Should precede UI sketching but often skipped by designers</li><li>Defines concepts needed in the system and their relationships</li><li>Creates more cohesive and coherent systems, especially for complex projects</li><li>More valuable than sitemaps, which imply rigid hierarchies</li></ul><p><strong>LLMs and Information Architecture</strong></p><p><strong>Current and Future Applications</strong></p><ul><li>Transforming search experiences (e.g., Perplexity providing answers vs. link lists)</li><li>Improving intent parsing in traditional search</li><li>Helping information architects with content analysis and navigation structure design</li><li>Enabling faster, better analysis of large content repositories</li></ul><p><strong>Implementation Advice</strong></p><p><strong>For Engineers and Designers</strong></p><ul><li>Designers should understand how systems are built (materials of construction)</li><li>Engineers benefit from understanding user perspectives and mental models</li><li>Both disciplines have much to teach each other</li></ul><p><strong>For Complex Applications</strong></p><ul><li>Map conceptual models before writing code</li><li>Test naming with real users</li><li>Implement progressive disclosure with good defaults</li><li>Remember: "If the user can't find it, it doesn't exist"</li></ul><p><strong>Notable Quotes:</strong></p><p>"People only understand things relative to things they already understand." - Richard Saul Wurman</p><p>"The hardest systems to design are the ones that are meant to do a lot of things for a lot of different people." - Jorge Arango</p><p>"Very few things are intuitive. There's a long running joke in the industry that the only intuitive interface for humans is the nipple. Everything else is learned." - Jorge Arango</p><p><strong>Jorge Arango</strong></p><ul><li><a href="https://www.linkedin.com/in/jarango/">LinkedIn</a></li><li><a href="https://jarango.com/">Website</a></li><li><a href="https://x.com/jarango">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/3cce0a3f/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/3cce0a3f/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#046 Building a Search Database From First Principles </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>29</itunes:episode>
      <podcast:episode>29</podcast:episode>
      <itunes:title>#046 Building a Search Database From First Principles </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">89a301af-2743-4b1b-9c10-a67053372d57</guid>
      <link>https://share.transistor.fm/s/c4833908</link>
      <description>
        <![CDATA[<p>Modern search is broken. There are too many pieces that are glued together.</p><ul><li>Vector databases for semantic search</li><li>Text engines for keywords</li><li>Rerankers to fix the results</li><li>LLMs to understand queries</li><li>Metadata filters for precision</li></ul><p>Each piece works well alone.</p><p>Together, they often become a mess.</p><p>When you glue these systems together, you create:</p><ul><li><strong>Data Consistency Gaps</strong> Your vector store knows about documents your text engine doesn't. Which is right?</li><li><strong>Timing Mismatches</strong> New content appears in one system before another. Users see different results depending on which path their query takes.</li><li><strong>Complexity Explosion</strong> Every new component doubles your integration points. Three components means three connections. Five means ten.</li><li><strong>Performance Bottlenecks</strong> Each hop between systems adds latency. A 200ms search becomes 800ms after passing through four components.</li><li><strong>Brittle Chains</strong> When one system fails, your entire search breaks. More pieces mean more breaking points.</li></ul><p>I recently built a system where we had query specific post-filters but the requirement to deliver a fixed number of results to the user.</p><p>A lot of times, the query had to be run multiple times to achieve the desired amount.</p><p>So we had an unpredictable latency. A high load on the backend, where some queries hammered the database 10+ times. A relevance cliff, where results 1-6 look great, but the later ones were poor matches.</p><p>Today on How AI Is Built, we are talking to Marek Galovic from TopK.</p><p>We talk about how they built a new search database with modern components. "How would search work if we built it today?‚Äù</p><p>Cloud storage is cheap. Compute is fast. Memory is plentiful.</p><p>One system that handles vectors, text, and filters together - not three systems duct-taped into one.</p><p>One pass handles everything:</p>Vector search + Text search + Filters ‚Üí Single sorted result
<br><p>Built with hand-optimized Rust kernels for both x86 and ARM, the system scales to 100M documents with 200ms P99 latency.</p><p>The goal is to do search in 5 lines of code.</p><p><strong>Marek Galovic:</strong></p><ul><li><a href="https://www.linkedin.com/in/marek-galovic/">LinkedIn</a></li><li><a href="https://marekgalovic.com/">Website</a></li><li><a href="https://www.topk.io/">TopK Website</a></li><li><a href="https://docs.topk.io/introduction">TopK Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to TopK and Snowflake Comparison</p><p>00:35 Architectural Patterns and Custom Formats</p><p>01:30 Query Execution Engine Explained</p><p>02:56 Distributed Systems and Rust</p><p>04:12 Query Execution Process</p><p>06:56 Custom File Formats for Search</p><p>11:45 Handling Distributed Queries</p><p>16:28 Consistency Models and Use Cases</p><p>26:47 Exploring Database Versioning and Snapshots</p><p>27:27 Performance Benchmarks: Rust vs. C/C++</p><p>29:02 Scaling and Latency in Large Datasets</p><p>29:39 GPU Acceleration and Use Cases</p><p>31:04 Optimizing Search Relevance and Hybrid Search</p><p>34:39 Advanced Search Features and Custom Scoring</p><p>38:43 Future Directions and Research in AI</p><p>47:11 Takeaways for Building AI Applications</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Modern search is broken. There are too many pieces that are glued together.</p><ul><li>Vector databases for semantic search</li><li>Text engines for keywords</li><li>Rerankers to fix the results</li><li>LLMs to understand queries</li><li>Metadata filters for precision</li></ul><p>Each piece works well alone.</p><p>Together, they often become a mess.</p><p>When you glue these systems together, you create:</p><ul><li><strong>Data Consistency Gaps</strong> Your vector store knows about documents your text engine doesn't. Which is right?</li><li><strong>Timing Mismatches</strong> New content appears in one system before another. Users see different results depending on which path their query takes.</li><li><strong>Complexity Explosion</strong> Every new component doubles your integration points. Three components means three connections. Five means ten.</li><li><strong>Performance Bottlenecks</strong> Each hop between systems adds latency. A 200ms search becomes 800ms after passing through four components.</li><li><strong>Brittle Chains</strong> When one system fails, your entire search breaks. More pieces mean more breaking points.</li></ul><p>I recently built a system where we had query specific post-filters but the requirement to deliver a fixed number of results to the user.</p><p>A lot of times, the query had to be run multiple times to achieve the desired amount.</p><p>So we had an unpredictable latency. A high load on the backend, where some queries hammered the database 10+ times. A relevance cliff, where results 1-6 look great, but the later ones were poor matches.</p><p>Today on How AI Is Built, we are talking to Marek Galovic from TopK.</p><p>We talk about how they built a new search database with modern components. "How would search work if we built it today?‚Äù</p><p>Cloud storage is cheap. Compute is fast. Memory is plentiful.</p><p>One system that handles vectors, text, and filters together - not three systems duct-taped into one.</p><p>One pass handles everything:</p>Vector search + Text search + Filters ‚Üí Single sorted result
<br><p>Built with hand-optimized Rust kernels for both x86 and ARM, the system scales to 100M documents with 200ms P99 latency.</p><p>The goal is to do search in 5 lines of code.</p><p><strong>Marek Galovic:</strong></p><ul><li><a href="https://www.linkedin.com/in/marek-galovic/">LinkedIn</a></li><li><a href="https://marekgalovic.com/">Website</a></li><li><a href="https://www.topk.io/">TopK Website</a></li><li><a href="https://docs.topk.io/introduction">TopK Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to TopK and Snowflake Comparison</p><p>00:35 Architectural Patterns and Custom Formats</p><p>01:30 Query Execution Engine Explained</p><p>02:56 Distributed Systems and Rust</p><p>04:12 Query Execution Process</p><p>06:56 Custom File Formats for Search</p><p>11:45 Handling Distributed Queries</p><p>16:28 Consistency Models and Use Cases</p><p>26:47 Exploring Database Versioning and Snapshots</p><p>27:27 Performance Benchmarks: Rust vs. C/C++</p><p>29:02 Scaling and Latency in Large Datasets</p><p>29:39 GPU Acceleration and Use Cases</p><p>31:04 Optimizing Search Relevance and Hybrid Search</p><p>34:39 Advanced Search Features and Custom Scoring</p><p>38:43 Future Directions and Research in AI</p><p>47:11 Takeaways for Building AI Applications</p>]]>
      </content:encoded>
      <pubDate>Thu, 13 Mar 2025 03:53:43 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/c4833908/08a1e92c.mp3" length="51375070" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/FHp_YMQIO-vvpnQTaQjv82Ksskqnh3Or4jL_77cmu-4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9kY2M4/NTNhMzlkMjc1NzYz/MGI3YzYwMzNmZDc1/M2I5OC5wbmc.jpg"/>
      <itunes:duration>3209</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Modern search is broken. There are too many pieces that are glued together.</p><ul><li>Vector databases for semantic search</li><li>Text engines for keywords</li><li>Rerankers to fix the results</li><li>LLMs to understand queries</li><li>Metadata filters for precision</li></ul><p>Each piece works well alone.</p><p>Together, they often become a mess.</p><p>When you glue these systems together, you create:</p><ul><li><strong>Data Consistency Gaps</strong> Your vector store knows about documents your text engine doesn't. Which is right?</li><li><strong>Timing Mismatches</strong> New content appears in one system before another. Users see different results depending on which path their query takes.</li><li><strong>Complexity Explosion</strong> Every new component doubles your integration points. Three components means three connections. Five means ten.</li><li><strong>Performance Bottlenecks</strong> Each hop between systems adds latency. A 200ms search becomes 800ms after passing through four components.</li><li><strong>Brittle Chains</strong> When one system fails, your entire search breaks. More pieces mean more breaking points.</li></ul><p>I recently built a system where we had query specific post-filters but the requirement to deliver a fixed number of results to the user.</p><p>A lot of times, the query had to be run multiple times to achieve the desired amount.</p><p>So we had an unpredictable latency. A high load on the backend, where some queries hammered the database 10+ times. A relevance cliff, where results 1-6 look great, but the later ones were poor matches.</p><p>Today on How AI Is Built, we are talking to Marek Galovic from TopK.</p><p>We talk about how they built a new search database with modern components. "How would search work if we built it today?‚Äù</p><p>Cloud storage is cheap. Compute is fast. Memory is plentiful.</p><p>One system that handles vectors, text, and filters together - not three systems duct-taped into one.</p><p>One pass handles everything:</p>Vector search + Text search + Filters ‚Üí Single sorted result
<br><p>Built with hand-optimized Rust kernels for both x86 and ARM, the system scales to 100M documents with 200ms P99 latency.</p><p>The goal is to do search in 5 lines of code.</p><p><strong>Marek Galovic:</strong></p><ul><li><a href="https://www.linkedin.com/in/marek-galovic/">LinkedIn</a></li><li><a href="https://marekgalovic.com/">Website</a></li><li><a href="https://www.topk.io/">TopK Website</a></li><li><a href="https://docs.topk.io/introduction">TopK Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to TopK and Snowflake Comparison</p><p>00:35 Architectural Patterns and Custom Formats</p><p>01:30 Query Execution Engine Explained</p><p>02:56 Distributed Systems and Rust</p><p>04:12 Query Execution Process</p><p>06:56 Custom File Formats for Search</p><p>11:45 Handling Distributed Queries</p><p>16:28 Consistency Models and Use Cases</p><p>26:47 Exploring Database Versioning and Snapshots</p><p>27:27 Performance Benchmarks: Rust vs. C/C++</p><p>29:02 Scaling and Latency in Large Datasets</p><p>29:39 GPU Acceleration and Use Cases</p><p>31:04 Optimizing Search Relevance and Hybrid Search</p><p>34:39 Advanced Search Features and Custom Scoring</p><p>38:43 Future Directions and Research in AI</p><p>47:11 Takeaways for Building AI Applications</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, embeddings, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/c4833908/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/c4833908/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#045 RAG As Two Things - Prompt Engineering and Search </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>28</itunes:episode>
      <podcast:episode>28</podcast:episode>
      <itunes:title>#045 RAG As Two Things - Prompt Engineering and Search </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">2afd875f-435a-4e9f-a1f2-a49088662b84</guid>
      <link>https://share.transistor.fm/s/7eb9804c</link>
      <description>
        <![CDATA[<p>John Berryman moved from aerospace engineering to search, then to ML and LLMs. His path: Eventbrite search ‚Üí GitHub code search ‚Üí data science ‚Üí GitHub Copilot. He was drawn to more math and ML throughout his career.</p><p><strong>RAG Explained</strong></p><p>"RAG is not a thing. RAG is two things." It breaks into:</p><ol><li>Search - finding relevant information</li><li>Prompt engineering - presenting that information to the model</li></ol><p>These should be treated as separate problems to optimize.</p><p><strong>The Little Red Riding Hood Principle</strong></p><p>When prompting LLMs, stay on the path of what models have seen in training. Use formats, structures, and patterns they recognize from their training data:</p><ul><li>For code, use docstrings and proper formatting</li><li>For financial data, use SEC report structures</li><li>Use Markdown for better formatting</li></ul><p>Models respond better to familiar structures.</p><p><strong>Testing Prompts</strong></p><p>Testing strategies:</p><ul><li>Start with "vibe testing" - human evaluation of outputs</li><li>Develop systematic tests based on observed failure patterns</li><li>Use token probabilities to measure model confidence</li><li>For few-shot prompts, watch for diminishing returns as examples increase</li></ul><p><strong>Managing Token Limits</strong></p><p>When designing prompts, divide content into:</p><ul><li>Static elements (boilerplate, instructions)</li><li>Dynamic elements (user inputs, context)</li></ul><p>Prioritize content by:</p><ol><li>Must-have information</li><li>Nice-to-have information</li><li>Optional if space allows</li></ol><p>Even with larger context windows, efficiency remains important for cost and latency.</p><p><strong>Completion vs. Chat Models</strong></p><p>Chat models are winning despite initial concerns about their constraints:</p><ul><li>Completion models allow more flexibility in document format</li><li>Chat models are more reliable and aligned with common use cases</li><li>Most applications now use chat models, even for completion-like tasks</li></ul><p><strong>Applications: Workflows vs. Assistants</strong></p><p>Two main LLM application patterns:</p><ul><li><strong>Assistants</strong>: Human-in-the-loop interactions where users guide and correct</li><li><strong>Workflows</strong>: Decomposed tasks where LLMs handle well-defined steps with safeguards</li></ul><p><strong>Breaking Down Complex Problems</strong></p><p>Two approaches:</p><ul><li><strong>Horizontal</strong>: Split into sequential steps with clear inputs/outputs</li><li><strong>Vertical</strong>: Divide by case type, with specialized handling for each scenario</li></ul><p>Example: For SOX compliance, break horizontally (understand control, find evidence, extract data, compile report) and vertically (different audit types).</p><p><strong>On Agents</strong></p><p>Agents exist on a spectrum from assistants to workflows, characterized by:</p><ul><li>Having some autonomy to make decisions</li><li>Using tools to interact with the environment</li><li>Usually requiring human oversight</li></ul><p><strong>Best Practices</strong></p><p>For building with LLMs:</p><ol><li>Start simple: API key + Jupyter notebook</li><li>Build prototypes and iterate quickly</li><li>Add evaluation as you scale</li><li>Keep users in the loop until models prove reliability</li></ol><p><strong>John Berryman:</strong></p><ul><li><a href="https://www.linkedin.com/in/john-berryman-864b1713/">LinkedIn</a></li><li><a href="https://x.com/JnBrymn">X (Twitter)</a></li><li><a href="https://arcturus-labs.com/">Arcturus Labs</a></li><li><a href="https://www.amazon.de/-/en/John-Berryman-ebook/dp/B0DM3VLNSK/ref=sr_1_1?crid=1DYT2Q98IMLVS&amp;dib=eyJ2IjoiMSJ9.v0f-Y12RTIShwCHImj9g8pzG3cDhXhgln1v6dKvX-ZnUGP67Ned--Ry0_d1Surk48QFpHgGbkhOgGw3jrj09bbXDDK4YCNVMGonsbB09NlE8AhdjmCI4RN-M24AaGSwRgjiThMQym3iqJIkPWp_fTiREzW0NMBHshO2QddeWw_KuEVFFfmq3Q203LK0DjFQdlUvxFhCxDTLMK490SPit-X7MQGRrt-wwmofEGiLUSAE.MjUWoivUthTYo6wqPxfYMqDcgB3l1BBb_raeQngH5S8&amp;dib_tag=se&amp;keywords=john.+berryman+prompt+engineering&amp;qid=1740663682&amp;s=digital-text&amp;sprefix=john.+berryman+prompt+engineering%2Cdigital-text%2C77&amp;sr=1-1">Prompt Engineering for LLMs (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a><p>00:00 Introduction to RAG: Retrieval and Generation<br>00:19 Optimizing Retrieval Systems<br>01:11 Introducing John Berryman<br>02:31 John's Journey from Search to Prompt Engineering<br>04:05 Understanding RAG: Search and Prompt Engineering<br>05:39 The Little Red Riding Hood Principle in Prompt Engineering<br>14:14 Balancing Static and Dynamic Elements in Prompts<br>25:52 Assistants vs. Workflows: Choosing the Right Approach<br>30:15 Defining Agency in AI<br>30:35 Spectrum of Assistance and Workflows<br>34:35 Breaking Down Problems Horizontally and Vertically<br>37:57 SOX Compliance Case Study<br>40:56 Integrating LLMs into Existing Applications<br>44:37 Favorite Tools and Missing Features<br>46:37 Exploring Niche Technologies in AI<br>52:52 Key Takeaways and Future Directions</p></li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>John Berryman moved from aerospace engineering to search, then to ML and LLMs. His path: Eventbrite search ‚Üí GitHub code search ‚Üí data science ‚Üí GitHub Copilot. He was drawn to more math and ML throughout his career.</p><p><strong>RAG Explained</strong></p><p>"RAG is not a thing. RAG is two things." It breaks into:</p><ol><li>Search - finding relevant information</li><li>Prompt engineering - presenting that information to the model</li></ol><p>These should be treated as separate problems to optimize.</p><p><strong>The Little Red Riding Hood Principle</strong></p><p>When prompting LLMs, stay on the path of what models have seen in training. Use formats, structures, and patterns they recognize from their training data:</p><ul><li>For code, use docstrings and proper formatting</li><li>For financial data, use SEC report structures</li><li>Use Markdown for better formatting</li></ul><p>Models respond better to familiar structures.</p><p><strong>Testing Prompts</strong></p><p>Testing strategies:</p><ul><li>Start with "vibe testing" - human evaluation of outputs</li><li>Develop systematic tests based on observed failure patterns</li><li>Use token probabilities to measure model confidence</li><li>For few-shot prompts, watch for diminishing returns as examples increase</li></ul><p><strong>Managing Token Limits</strong></p><p>When designing prompts, divide content into:</p><ul><li>Static elements (boilerplate, instructions)</li><li>Dynamic elements (user inputs, context)</li></ul><p>Prioritize content by:</p><ol><li>Must-have information</li><li>Nice-to-have information</li><li>Optional if space allows</li></ol><p>Even with larger context windows, efficiency remains important for cost and latency.</p><p><strong>Completion vs. Chat Models</strong></p><p>Chat models are winning despite initial concerns about their constraints:</p><ul><li>Completion models allow more flexibility in document format</li><li>Chat models are more reliable and aligned with common use cases</li><li>Most applications now use chat models, even for completion-like tasks</li></ul><p><strong>Applications: Workflows vs. Assistants</strong></p><p>Two main LLM application patterns:</p><ul><li><strong>Assistants</strong>: Human-in-the-loop interactions where users guide and correct</li><li><strong>Workflows</strong>: Decomposed tasks where LLMs handle well-defined steps with safeguards</li></ul><p><strong>Breaking Down Complex Problems</strong></p><p>Two approaches:</p><ul><li><strong>Horizontal</strong>: Split into sequential steps with clear inputs/outputs</li><li><strong>Vertical</strong>: Divide by case type, with specialized handling for each scenario</li></ul><p>Example: For SOX compliance, break horizontally (understand control, find evidence, extract data, compile report) and vertically (different audit types).</p><p><strong>On Agents</strong></p><p>Agents exist on a spectrum from assistants to workflows, characterized by:</p><ul><li>Having some autonomy to make decisions</li><li>Using tools to interact with the environment</li><li>Usually requiring human oversight</li></ul><p><strong>Best Practices</strong></p><p>For building with LLMs:</p><ol><li>Start simple: API key + Jupyter notebook</li><li>Build prototypes and iterate quickly</li><li>Add evaluation as you scale</li><li>Keep users in the loop until models prove reliability</li></ol><p><strong>John Berryman:</strong></p><ul><li><a href="https://www.linkedin.com/in/john-berryman-864b1713/">LinkedIn</a></li><li><a href="https://x.com/JnBrymn">X (Twitter)</a></li><li><a href="https://arcturus-labs.com/">Arcturus Labs</a></li><li><a href="https://www.amazon.de/-/en/John-Berryman-ebook/dp/B0DM3VLNSK/ref=sr_1_1?crid=1DYT2Q98IMLVS&amp;dib=eyJ2IjoiMSJ9.v0f-Y12RTIShwCHImj9g8pzG3cDhXhgln1v6dKvX-ZnUGP67Ned--Ry0_d1Surk48QFpHgGbkhOgGw3jrj09bbXDDK4YCNVMGonsbB09NlE8AhdjmCI4RN-M24AaGSwRgjiThMQym3iqJIkPWp_fTiREzW0NMBHshO2QddeWw_KuEVFFfmq3Q203LK0DjFQdlUvxFhCxDTLMK490SPit-X7MQGRrt-wwmofEGiLUSAE.MjUWoivUthTYo6wqPxfYMqDcgB3l1BBb_raeQngH5S8&amp;dib_tag=se&amp;keywords=john.+berryman+prompt+engineering&amp;qid=1740663682&amp;s=digital-text&amp;sprefix=john.+berryman+prompt+engineering%2Cdigital-text%2C77&amp;sr=1-1">Prompt Engineering for LLMs (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a><p>00:00 Introduction to RAG: Retrieval and Generation<br>00:19 Optimizing Retrieval Systems<br>01:11 Introducing John Berryman<br>02:31 John's Journey from Search to Prompt Engineering<br>04:05 Understanding RAG: Search and Prompt Engineering<br>05:39 The Little Red Riding Hood Principle in Prompt Engineering<br>14:14 Balancing Static and Dynamic Elements in Prompts<br>25:52 Assistants vs. Workflows: Choosing the Right Approach<br>30:15 Defining Agency in AI<br>30:35 Spectrum of Assistance and Workflows<br>34:35 Breaking Down Problems Horizontally and Vertically<br>37:57 SOX Compliance Case Study<br>40:56 Integrating LLMs into Existing Applications<br>44:37 Favorite Tools and Missing Features<br>46:37 Exploring Niche Technologies in AI<br>52:52 Key Takeaways and Future Directions</p></li></ul>]]>
      </content:encoded>
      <pubDate>Thu, 06 Mar 2025 06:10:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/7eb9804c/ddff9269.mp3" length="60252131" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/Ytxz830xgWDLuCFmWvtLP27pyRGPMuQma9GdeW_BJTA/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mMDc3/MDUwMTE1NzJhMDJl/ZTA5MWU2MjgwODRi/MDI5MS5wbmc.jpg"/>
      <itunes:duration>3764</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>John Berryman moved from aerospace engineering to search, then to ML and LLMs. His path: Eventbrite search ‚Üí GitHub code search ‚Üí data science ‚Üí GitHub Copilot. He was drawn to more math and ML throughout his career.</p><p><strong>RAG Explained</strong></p><p>"RAG is not a thing. RAG is two things." It breaks into:</p><ol><li>Search - finding relevant information</li><li>Prompt engineering - presenting that information to the model</li></ol><p>These should be treated as separate problems to optimize.</p><p><strong>The Little Red Riding Hood Principle</strong></p><p>When prompting LLMs, stay on the path of what models have seen in training. Use formats, structures, and patterns they recognize from their training data:</p><ul><li>For code, use docstrings and proper formatting</li><li>For financial data, use SEC report structures</li><li>Use Markdown for better formatting</li></ul><p>Models respond better to familiar structures.</p><p><strong>Testing Prompts</strong></p><p>Testing strategies:</p><ul><li>Start with "vibe testing" - human evaluation of outputs</li><li>Develop systematic tests based on observed failure patterns</li><li>Use token probabilities to measure model confidence</li><li>For few-shot prompts, watch for diminishing returns as examples increase</li></ul><p><strong>Managing Token Limits</strong></p><p>When designing prompts, divide content into:</p><ul><li>Static elements (boilerplate, instructions)</li><li>Dynamic elements (user inputs, context)</li></ul><p>Prioritize content by:</p><ol><li>Must-have information</li><li>Nice-to-have information</li><li>Optional if space allows</li></ol><p>Even with larger context windows, efficiency remains important for cost and latency.</p><p><strong>Completion vs. Chat Models</strong></p><p>Chat models are winning despite initial concerns about their constraints:</p><ul><li>Completion models allow more flexibility in document format</li><li>Chat models are more reliable and aligned with common use cases</li><li>Most applications now use chat models, even for completion-like tasks</li></ul><p><strong>Applications: Workflows vs. Assistants</strong></p><p>Two main LLM application patterns:</p><ul><li><strong>Assistants</strong>: Human-in-the-loop interactions where users guide and correct</li><li><strong>Workflows</strong>: Decomposed tasks where LLMs handle well-defined steps with safeguards</li></ul><p><strong>Breaking Down Complex Problems</strong></p><p>Two approaches:</p><ul><li><strong>Horizontal</strong>: Split into sequential steps with clear inputs/outputs</li><li><strong>Vertical</strong>: Divide by case type, with specialized handling for each scenario</li></ul><p>Example: For SOX compliance, break horizontally (understand control, find evidence, extract data, compile report) and vertically (different audit types).</p><p><strong>On Agents</strong></p><p>Agents exist on a spectrum from assistants to workflows, characterized by:</p><ul><li>Having some autonomy to make decisions</li><li>Using tools to interact with the environment</li><li>Usually requiring human oversight</li></ul><p><strong>Best Practices</strong></p><p>For building with LLMs:</p><ol><li>Start simple: API key + Jupyter notebook</li><li>Build prototypes and iterate quickly</li><li>Add evaluation as you scale</li><li>Keep users in the loop until models prove reliability</li></ol><p><strong>John Berryman:</strong></p><ul><li><a href="https://www.linkedin.com/in/john-berryman-864b1713/">LinkedIn</a></li><li><a href="https://x.com/JnBrymn">X (Twitter)</a></li><li><a href="https://arcturus-labs.com/">Arcturus Labs</a></li><li><a href="https://www.amazon.de/-/en/John-Berryman-ebook/dp/B0DM3VLNSK/ref=sr_1_1?crid=1DYT2Q98IMLVS&amp;dib=eyJ2IjoiMSJ9.v0f-Y12RTIShwCHImj9g8pzG3cDhXhgln1v6dKvX-ZnUGP67Ned--Ry0_d1Surk48QFpHgGbkhOgGw3jrj09bbXDDK4YCNVMGonsbB09NlE8AhdjmCI4RN-M24AaGSwRgjiThMQym3iqJIkPWp_fTiREzW0NMBHshO2QddeWw_KuEVFFfmq3Q203LK0DjFQdlUvxFhCxDTLMK490SPit-X7MQGRrt-wwmofEGiLUSAE.MjUWoivUthTYo6wqPxfYMqDcgB3l1BBb_raeQngH5S8&amp;dib_tag=se&amp;keywords=john.+berryman+prompt+engineering&amp;qid=1740663682&amp;s=digital-text&amp;sprefix=john.+berryman+prompt+engineering%2Cdigital-text%2C77&amp;sr=1-1">Prompt Engineering for LLMs (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a><p>00:00 Introduction to RAG: Retrieval and Generation<br>00:19 Optimizing Retrieval Systems<br>01:11 Introducing John Berryman<br>02:31 John's Journey from Search to Prompt Engineering<br>04:05 Understanding RAG: Search and Prompt Engineering<br>05:39 The Little Red Riding Hood Principle in Prompt Engineering<br>14:14 Balancing Static and Dynamic Elements in Prompts<br>25:52 Assistants vs. Workflows: Choosing the Right Approach<br>30:15 Defining Agency in AI<br>30:35 Spectrum of Assistance and Workflows<br>34:35 Breaking Down Problems Horizontally and Vertically<br>37:57 SOX Compliance Case Study<br>40:56 Integrating LLMs into Existing Applications<br>44:37 Favorite Tools and Missing Features<br>46:37 Exploring Niche Technologies in AI<br>52:52 Key Takeaways and Future Directions</p></li></ul>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/7eb9804c/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/7eb9804c/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#044 Graphs Aren't Just For Specialists Anymore</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>27</itunes:episode>
      <podcast:episode>27</podcast:episode>
      <itunes:title>#044 Graphs Aren't Just For Specialists Anymore</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">98ae9aba-0736-4aea-8c3a-6d150ae76b7e</guid>
      <link>https://share.transistor.fm/s/ceca984b</link>
      <description>
        <![CDATA[<p>Kuzu is an embedded graph database that implements Cypher as a library.</p><p>It can be easily integrated into various environments‚Äîfrom scripts and Android apps to serverless platforms.</p><p>Its design supports both ephemeral, in-memory graphs (ideal for temporary computations) and large-scale persistent graphs where traditional systems struggle with performance and scalability.</p><p><strong>Key Architectural Decisions:</strong></p><ul><li><strong>Columnar Storage:</strong></li><li>Kuzu stores node and relationship properties in separate, contiguous columns. This design reduces I/O by allowing queries to scan only the needed columns, unlike row-based systems (e.g., Neo4j) that read full records even when only a subset of properties is required.</li><li><strong>Efficient Join Indexing with CSR:</strong></li><li>The join index is maintained using a Compressed Sparse Row (CSR) format. By sorting and compressing relationship data, Kuzu ensures that adjacent node relationships are stored contiguously, minimizing random I/O and speeding up traversals.</li><li><strong>Vectorized Query Processing:</strong></li><li>Instead of processing one tuple at a time, Kuzu processes blocks (vectors) of tuples. This block-based (or vectorized) approach reduces function-call overhead and improves cache locality, boosting performance for analytic queries.</li><li><strong>Factorization and ASP Join:</strong></li><li>For many-to-many queries that can generate enormous intermediate results, Kuzu uses factorization to represent data compactly. Its ASP join algorithm integrates factorization, sequential scanning, and sideways information passing to avoid unnecessary full scans and materializations.</li></ul><p>Kuzu is optimized for read-heavy, analytic workloads. While batched writes are efficient, the system is less tuned for high-frequency, small transactions. Upcoming features include:</p><ul><li>A WebAssembly (Wasm) version for running in browsers.</li><li>Enhanced vector and full-text search indices.</li><li>Built-in graph data science algorithms for tasks like PageRank and centrality analysis.</li></ul><p>Kuzu can be a powerful backend for AI applications in several ways:</p><ul><li><strong>Knowledge Graphs:</strong></li><li>Store and query complex relationships between entities to support natural language understanding, semantic search, and reasoning tasks.</li><li><strong>Graph Data Science:</strong></li><li>Run built-in graph algorithms (like PageRank, centrality, or community detection) that help uncover patterns and insights, which can improve recommendation systems, fraud detection, and other AI-driven analyses.</li><li><strong>Retrieval-Augmented Generation (RAG):</strong></li><li>Integrate with large language models by efficiently retrieving relevant, structured graph data. Kuzu‚Äôs vector search capabilities and fast query processing make it ideal for augmenting AI responses with contextual information.</li><li><strong>Graph Embeddings &amp; ML Pipelines:</strong></li><li>Serve as the foundation for generating graph embeddings, which are used in downstream machine learning tasks‚Äîsuch as clustering, classification, or link prediction‚Äîto enhance model performance.</li></ul><p><strong>Semih Salihoƒülu:</strong></p><ul><li><a href="https://www.linkedin.com/in/semih-saliho%C4%9Flu-0512612a/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://github.com/kuzudb/kuzu">Kuzu GitHub</a></li><li><a href="https://kuzudb.com/">Kuzu Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Graph Databases<br>00:18 Introducing Kuzu: A Modern Graph Database<br>01:48 Use Cases and Applications of Kuzu<br>03:03 Kuzu's Research Origins and Scalability<br>06:18 Columnar Storage vs. Row-Oriented Storage<br>10:27 Query Processing Techniques in Kuzu<br>22:22 Compressed Sparse Row (CSR) Storage<br>27:25 Vectorization in Graph Databases<br>31:24 Optimizing Query Processors with Vectorization<br>33:25 Common Wisdom in Graph Databases<br>35:13 Introducing ASP Join in Kuzu<br>35:55 Factorization and Efficient Query Processing<br>39:49 Challenges and Solutions in Graph Databases<br>45:26 Write Path Optimization in Kuzu<br>54:10 Future Developments in Kuzu<br>57:51 Key Takeaways and Final Thoughts</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Kuzu is an embedded graph database that implements Cypher as a library.</p><p>It can be easily integrated into various environments‚Äîfrom scripts and Android apps to serverless platforms.</p><p>Its design supports both ephemeral, in-memory graphs (ideal for temporary computations) and large-scale persistent graphs where traditional systems struggle with performance and scalability.</p><p><strong>Key Architectural Decisions:</strong></p><ul><li><strong>Columnar Storage:</strong></li><li>Kuzu stores node and relationship properties in separate, contiguous columns. This design reduces I/O by allowing queries to scan only the needed columns, unlike row-based systems (e.g., Neo4j) that read full records even when only a subset of properties is required.</li><li><strong>Efficient Join Indexing with CSR:</strong></li><li>The join index is maintained using a Compressed Sparse Row (CSR) format. By sorting and compressing relationship data, Kuzu ensures that adjacent node relationships are stored contiguously, minimizing random I/O and speeding up traversals.</li><li><strong>Vectorized Query Processing:</strong></li><li>Instead of processing one tuple at a time, Kuzu processes blocks (vectors) of tuples. This block-based (or vectorized) approach reduces function-call overhead and improves cache locality, boosting performance for analytic queries.</li><li><strong>Factorization and ASP Join:</strong></li><li>For many-to-many queries that can generate enormous intermediate results, Kuzu uses factorization to represent data compactly. Its ASP join algorithm integrates factorization, sequential scanning, and sideways information passing to avoid unnecessary full scans and materializations.</li></ul><p>Kuzu is optimized for read-heavy, analytic workloads. While batched writes are efficient, the system is less tuned for high-frequency, small transactions. Upcoming features include:</p><ul><li>A WebAssembly (Wasm) version for running in browsers.</li><li>Enhanced vector and full-text search indices.</li><li>Built-in graph data science algorithms for tasks like PageRank and centrality analysis.</li></ul><p>Kuzu can be a powerful backend for AI applications in several ways:</p><ul><li><strong>Knowledge Graphs:</strong></li><li>Store and query complex relationships between entities to support natural language understanding, semantic search, and reasoning tasks.</li><li><strong>Graph Data Science:</strong></li><li>Run built-in graph algorithms (like PageRank, centrality, or community detection) that help uncover patterns and insights, which can improve recommendation systems, fraud detection, and other AI-driven analyses.</li><li><strong>Retrieval-Augmented Generation (RAG):</strong></li><li>Integrate with large language models by efficiently retrieving relevant, structured graph data. Kuzu‚Äôs vector search capabilities and fast query processing make it ideal for augmenting AI responses with contextual information.</li><li><strong>Graph Embeddings &amp; ML Pipelines:</strong></li><li>Serve as the foundation for generating graph embeddings, which are used in downstream machine learning tasks‚Äîsuch as clustering, classification, or link prediction‚Äîto enhance model performance.</li></ul><p><strong>Semih Salihoƒülu:</strong></p><ul><li><a href="https://www.linkedin.com/in/semih-saliho%C4%9Flu-0512612a/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://github.com/kuzudb/kuzu">Kuzu GitHub</a></li><li><a href="https://kuzudb.com/">Kuzu Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Graph Databases<br>00:18 Introducing Kuzu: A Modern Graph Database<br>01:48 Use Cases and Applications of Kuzu<br>03:03 Kuzu's Research Origins and Scalability<br>06:18 Columnar Storage vs. Row-Oriented Storage<br>10:27 Query Processing Techniques in Kuzu<br>22:22 Compressed Sparse Row (CSR) Storage<br>27:25 Vectorization in Graph Databases<br>31:24 Optimizing Query Processors with Vectorization<br>33:25 Common Wisdom in Graph Databases<br>35:13 Introducing ASP Join in Kuzu<br>35:55 Factorization and Efficient Query Processing<br>39:49 Challenges and Solutions in Graph Databases<br>45:26 Write Path Optimization in Kuzu<br>54:10 Future Developments in Kuzu<br>57:51 Key Takeaways and Final Thoughts</p>]]>
      </content:encoded>
      <pubDate>Fri, 28 Feb 2025 06:00:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/ceca984b/16fe4b31.mp3" length="61079274" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/NQDok09X_ETw8KfegqBeEukdGpbFiFbdxW7X-Z_u-KE/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS82ZGRl/M2QzMzFhZDcwNWJj/YzZhMzhjMDZkNTNi/NTNhMy5wbmc.jpg"/>
      <itunes:duration>3815</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Kuzu is an embedded graph database that implements Cypher as a library.</p><p>It can be easily integrated into various environments‚Äîfrom scripts and Android apps to serverless platforms.</p><p>Its design supports both ephemeral, in-memory graphs (ideal for temporary computations) and large-scale persistent graphs where traditional systems struggle with performance and scalability.</p><p><strong>Key Architectural Decisions:</strong></p><ul><li><strong>Columnar Storage:</strong></li><li>Kuzu stores node and relationship properties in separate, contiguous columns. This design reduces I/O by allowing queries to scan only the needed columns, unlike row-based systems (e.g., Neo4j) that read full records even when only a subset of properties is required.</li><li><strong>Efficient Join Indexing with CSR:</strong></li><li>The join index is maintained using a Compressed Sparse Row (CSR) format. By sorting and compressing relationship data, Kuzu ensures that adjacent node relationships are stored contiguously, minimizing random I/O and speeding up traversals.</li><li><strong>Vectorized Query Processing:</strong></li><li>Instead of processing one tuple at a time, Kuzu processes blocks (vectors) of tuples. This block-based (or vectorized) approach reduces function-call overhead and improves cache locality, boosting performance for analytic queries.</li><li><strong>Factorization and ASP Join:</strong></li><li>For many-to-many queries that can generate enormous intermediate results, Kuzu uses factorization to represent data compactly. Its ASP join algorithm integrates factorization, sequential scanning, and sideways information passing to avoid unnecessary full scans and materializations.</li></ul><p>Kuzu is optimized for read-heavy, analytic workloads. While batched writes are efficient, the system is less tuned for high-frequency, small transactions. Upcoming features include:</p><ul><li>A WebAssembly (Wasm) version for running in browsers.</li><li>Enhanced vector and full-text search indices.</li><li>Built-in graph data science algorithms for tasks like PageRank and centrality analysis.</li></ul><p>Kuzu can be a powerful backend for AI applications in several ways:</p><ul><li><strong>Knowledge Graphs:</strong></li><li>Store and query complex relationships between entities to support natural language understanding, semantic search, and reasoning tasks.</li><li><strong>Graph Data Science:</strong></li><li>Run built-in graph algorithms (like PageRank, centrality, or community detection) that help uncover patterns and insights, which can improve recommendation systems, fraud detection, and other AI-driven analyses.</li><li><strong>Retrieval-Augmented Generation (RAG):</strong></li><li>Integrate with large language models by efficiently retrieving relevant, structured graph data. Kuzu‚Äôs vector search capabilities and fast query processing make it ideal for augmenting AI responses with contextual information.</li><li><strong>Graph Embeddings &amp; ML Pipelines:</strong></li><li>Serve as the foundation for generating graph embeddings, which are used in downstream machine learning tasks‚Äîsuch as clustering, classification, or link prediction‚Äîto enhance model performance.</li></ul><p><strong>Semih Salihoƒülu:</strong></p><ul><li><a href="https://www.linkedin.com/in/semih-saliho%C4%9Flu-0512612a/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://github.com/kuzudb/kuzu">Kuzu GitHub</a></li><li><a href="https://kuzudb.com/">Kuzu Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Graph Databases<br>00:18 Introducing Kuzu: A Modern Graph Database<br>01:48 Use Cases and Applications of Kuzu<br>03:03 Kuzu's Research Origins and Scalability<br>06:18 Columnar Storage vs. Row-Oriented Storage<br>10:27 Query Processing Techniques in Kuzu<br>22:22 Compressed Sparse Row (CSR) Storage<br>27:25 Vectorization in Graph Databases<br>31:24 Optimizing Query Processors with Vectorization<br>33:25 Common Wisdom in Graph Databases<br>35:13 Introducing ASP Join in Kuzu<br>35:55 Factorization and Efficient Query Processing<br>39:49 Challenges and Solutions in Graph Databases<br>45:26 Write Path Optimization in Kuzu<br>54:10 Future Developments in Kuzu<br>57:51 Key Takeaways and Final Thoughts</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/ceca984b/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/ceca984b/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#043 Knowledge Graphs Won't Fix Bad Data</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>26</itunes:episode>
      <podcast:episode>26</podcast:episode>
      <itunes:title>#043 Knowledge Graphs Won't Fix Bad Data</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">d7909be3-5587-4994-a88b-9932661d391c</guid>
      <link>https://share.transistor.fm/s/1b874e17</link>
      <description>
        <![CDATA[<p>Metadata is the foundation of any enterprise knowledge graph.</p><p>By organizing both technical and business metadata, organizations create a ‚Äúbrain‚Äù that supports advanced applications like AI-driven data assistants.</p><p>The goal is to achieve economies of scale‚Äîmaking data reusable, traceable, and ultimately more valuable.</p><p>Juan Sequeda is a leading expert in enterprise knowledge graphs and metadata management. He has spent years solving the challenges of integrating diverse data sources into coherent, accessible knowledge graphs. As Principal Scientist at data.world, Juan provides concrete strategies for improving data quality, streamlining feature extraction, and enhancing model explainability. If you want to build AI systems on a solid data foundation‚Äîone that cuts through the noise and delivers reliable, high-performance insights‚Äîyou need to listen to Juan‚Äôs proven methods and real-world examples.</p><p>Terms like ontologies, taxonomies, and knowledge graphs aren‚Äôt new inventions. Ontologies and taxonomies have been studied for decades‚Äîeven since ancient Greece. Google popularized ‚Äúknowledge graphs‚Äù in 2012 by building on decades of semantic web research. Despite current buzz, these concepts build on established work.</p><p>Traditionally, data lives in siloed applications‚Äîeach with its own relational databases, ETL processes, and dashboards. When cross-application queries and consistent definitions become painful, organizations face metadata management challenges. The first step is to integrate technical metadata (table names, columns, code lineage) into a unified knowledge graph. Then, add business metadata by mapping business glossaries and definitions to that technical layer.</p><p>A modern data catalog should:</p><ul><li><strong>Integrate Multiple Sources:</strong> Automatically ingest metadata from databases, ETL tools (e.g., dbt, Fivetran), and BI tools.</li><li><strong>Bridge Technical and Business Views:</strong> Link technical definitions (e.g., table ‚ÄúCUST_123‚Äù) with business concepts (e.g., ‚ÄúCustomer‚Äù).</li><li><strong>Enable Reuse and Governance:</strong> Support data discovery, impact analysis, and proper governance while facilitating reuse across teams.</li></ul><p><strong>Practical Approaches &amp; Use Cases:</strong></p><ul><li><strong>Start with a Clear Problem:</strong> Whether it‚Äôs reducing churn, improving operational efficiency, or meeting compliance needs, begin by solving a specific pain point.</li><li><strong>Iron Thread Method:</strong> Follow one query end-to-end‚Äîfrom identifying a business need to tracing it back to source systems‚Äîto gradually build and refine the graph.</li><li><strong>Automation vs. Manual Oversight:</strong> Technical metadata extraction is largely automated. For business definitions or text-based entity extraction (e.g., via LLMs), human oversight is key to ensuring accuracy and consistency.</li></ul><p><strong>Technical Considerations:</strong></p><ul><li><strong>Entity vs. Property:</strong> If you need to attach additional details or reuse an element across contexts, model it as an entity (with a unique identifier). Otherwise, keep it as a simple property.</li><li><strong>Storage Options:</strong> The market offers various graph databases‚ÄîNeo4j, Amazon Neptune, Cosmos DB, TigerGraph, Apache Jena (for RDF), etc. Future trends point toward multimodel systems that allow querying in SQL, Cypher, or SPARQL over the same underlying data.</li></ul><p><strong>Juan Sequeda:</strong></p><ul><li><a href="https://www.linkedin.com/in/juansequeda/">LinkedIn</a></li><li><a href="https://data.world/">data.world</a></li><li><a href="https://www.amazon.de/-/en/Semantic-Web-Working-Ontologist-Effective/dp/0123859654">Semantic Web for the Working Ontologist</a></li><li><a href="https://www.amazon.de/-/en/Designing-Enterprise-Knowledge-Synthesis-Semantics/dp/3031007883/ref=sr_1_1?crid=2FAWHKL5U4UAC&amp;dib=eyJ2IjoiMSJ9.qHtuAcPNcE2MJtTf-I6_mBjTNyXIT_PJWrm5XNc0De0.N-KR6cVBfIEnRy5GomUIPiB7oHoWhfgn2UfQHz0CsCc&amp;dib_tag=se&amp;keywords=Designing+and+Building+Enterprise+Knowledge+Graphs&amp;qid=1739717245&amp;sprefix=designing+and+building+enterprise+knowledge+graphs%2Caps%2C77&amp;sr=8-1">Designing and Building Enterprise Knowledge Graphs</a> (before you buy, send Juan a message, he is happy to send you a copy)</li><li><a href="https://open.spotify.com/show/2fkOqtpxNieWbvBRlPi0ml">Catalog &amp; Cocktails (Juan‚Äôs podcast)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Knowledge Graphs 00:45 The Role of Metadata in AI 01:06 Building Knowledge Graphs: First Steps 01:42 Interview with Juan Sequira 02:04 Understanding Buzzwords: Ontologies, Taxonomies, and More 05:05 Challenges and Solutions in Data Management 08:04 Practical Applications of Knowledge Graphs 15:38 Governance and Data Engineering 34:42 Setting the Stage for Data-Driven Problem Solving 34:58 Understanding Consumer Needs and Data Challenges 35:33 Foundations and Advanced Capabilities in Data Management 36:01 The Role of AI and Metadata in Data Maturity 37:56 The Iron Thread Approach to Problem Solving 40:12 Constructing and Utilizing Knowledge Graphs 54:38 Trends and Future Directions in Knowledge Graphs 59:17 Practical Advice for Building Knowledge Graphs</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Metadata is the foundation of any enterprise knowledge graph.</p><p>By organizing both technical and business metadata, organizations create a ‚Äúbrain‚Äù that supports advanced applications like AI-driven data assistants.</p><p>The goal is to achieve economies of scale‚Äîmaking data reusable, traceable, and ultimately more valuable.</p><p>Juan Sequeda is a leading expert in enterprise knowledge graphs and metadata management. He has spent years solving the challenges of integrating diverse data sources into coherent, accessible knowledge graphs. As Principal Scientist at data.world, Juan provides concrete strategies for improving data quality, streamlining feature extraction, and enhancing model explainability. If you want to build AI systems on a solid data foundation‚Äîone that cuts through the noise and delivers reliable, high-performance insights‚Äîyou need to listen to Juan‚Äôs proven methods and real-world examples.</p><p>Terms like ontologies, taxonomies, and knowledge graphs aren‚Äôt new inventions. Ontologies and taxonomies have been studied for decades‚Äîeven since ancient Greece. Google popularized ‚Äúknowledge graphs‚Äù in 2012 by building on decades of semantic web research. Despite current buzz, these concepts build on established work.</p><p>Traditionally, data lives in siloed applications‚Äîeach with its own relational databases, ETL processes, and dashboards. When cross-application queries and consistent definitions become painful, organizations face metadata management challenges. The first step is to integrate technical metadata (table names, columns, code lineage) into a unified knowledge graph. Then, add business metadata by mapping business glossaries and definitions to that technical layer.</p><p>A modern data catalog should:</p><ul><li><strong>Integrate Multiple Sources:</strong> Automatically ingest metadata from databases, ETL tools (e.g., dbt, Fivetran), and BI tools.</li><li><strong>Bridge Technical and Business Views:</strong> Link technical definitions (e.g., table ‚ÄúCUST_123‚Äù) with business concepts (e.g., ‚ÄúCustomer‚Äù).</li><li><strong>Enable Reuse and Governance:</strong> Support data discovery, impact analysis, and proper governance while facilitating reuse across teams.</li></ul><p><strong>Practical Approaches &amp; Use Cases:</strong></p><ul><li><strong>Start with a Clear Problem:</strong> Whether it‚Äôs reducing churn, improving operational efficiency, or meeting compliance needs, begin by solving a specific pain point.</li><li><strong>Iron Thread Method:</strong> Follow one query end-to-end‚Äîfrom identifying a business need to tracing it back to source systems‚Äîto gradually build and refine the graph.</li><li><strong>Automation vs. Manual Oversight:</strong> Technical metadata extraction is largely automated. For business definitions or text-based entity extraction (e.g., via LLMs), human oversight is key to ensuring accuracy and consistency.</li></ul><p><strong>Technical Considerations:</strong></p><ul><li><strong>Entity vs. Property:</strong> If you need to attach additional details or reuse an element across contexts, model it as an entity (with a unique identifier). Otherwise, keep it as a simple property.</li><li><strong>Storage Options:</strong> The market offers various graph databases‚ÄîNeo4j, Amazon Neptune, Cosmos DB, TigerGraph, Apache Jena (for RDF), etc. Future trends point toward multimodel systems that allow querying in SQL, Cypher, or SPARQL over the same underlying data.</li></ul><p><strong>Juan Sequeda:</strong></p><ul><li><a href="https://www.linkedin.com/in/juansequeda/">LinkedIn</a></li><li><a href="https://data.world/">data.world</a></li><li><a href="https://www.amazon.de/-/en/Semantic-Web-Working-Ontologist-Effective/dp/0123859654">Semantic Web for the Working Ontologist</a></li><li><a href="https://www.amazon.de/-/en/Designing-Enterprise-Knowledge-Synthesis-Semantics/dp/3031007883/ref=sr_1_1?crid=2FAWHKL5U4UAC&amp;dib=eyJ2IjoiMSJ9.qHtuAcPNcE2MJtTf-I6_mBjTNyXIT_PJWrm5XNc0De0.N-KR6cVBfIEnRy5GomUIPiB7oHoWhfgn2UfQHz0CsCc&amp;dib_tag=se&amp;keywords=Designing+and+Building+Enterprise+Knowledge+Graphs&amp;qid=1739717245&amp;sprefix=designing+and+building+enterprise+knowledge+graphs%2Caps%2C77&amp;sr=8-1">Designing and Building Enterprise Knowledge Graphs</a> (before you buy, send Juan a message, he is happy to send you a copy)</li><li><a href="https://open.spotify.com/show/2fkOqtpxNieWbvBRlPi0ml">Catalog &amp; Cocktails (Juan‚Äôs podcast)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Knowledge Graphs 00:45 The Role of Metadata in AI 01:06 Building Knowledge Graphs: First Steps 01:42 Interview with Juan Sequira 02:04 Understanding Buzzwords: Ontologies, Taxonomies, and More 05:05 Challenges and Solutions in Data Management 08:04 Practical Applications of Knowledge Graphs 15:38 Governance and Data Engineering 34:42 Setting the Stage for Data-Driven Problem Solving 34:58 Understanding Consumer Needs and Data Challenges 35:33 Foundations and Advanced Capabilities in Data Management 36:01 The Role of AI and Metadata in Data Maturity 37:56 The Iron Thread Approach to Problem Solving 40:12 Constructing and Utilizing Knowledge Graphs 54:38 Trends and Future Directions in Knowledge Graphs 59:17 Practical Advice for Building Knowledge Graphs</p>]]>
      </content:encoded>
      <pubDate>Thu, 20 Feb 2025 07:00:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/1b874e17/9b35e294.mp3" length="68180778" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/V3o34sU4YZQirZ1JhYX-qDhTxBCW3dppKqBobOuV-hM/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9iNGUy/N2U4MTNkZDJjODA0/MWQ1OTVjYWI5Mzhj/NWU4YS5wbmc.jpg"/>
      <itunes:duration>4259</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Metadata is the foundation of any enterprise knowledge graph.</p><p>By organizing both technical and business metadata, organizations create a ‚Äúbrain‚Äù that supports advanced applications like AI-driven data assistants.</p><p>The goal is to achieve economies of scale‚Äîmaking data reusable, traceable, and ultimately more valuable.</p><p>Juan Sequeda is a leading expert in enterprise knowledge graphs and metadata management. He has spent years solving the challenges of integrating diverse data sources into coherent, accessible knowledge graphs. As Principal Scientist at data.world, Juan provides concrete strategies for improving data quality, streamlining feature extraction, and enhancing model explainability. If you want to build AI systems on a solid data foundation‚Äîone that cuts through the noise and delivers reliable, high-performance insights‚Äîyou need to listen to Juan‚Äôs proven methods and real-world examples.</p><p>Terms like ontologies, taxonomies, and knowledge graphs aren‚Äôt new inventions. Ontologies and taxonomies have been studied for decades‚Äîeven since ancient Greece. Google popularized ‚Äúknowledge graphs‚Äù in 2012 by building on decades of semantic web research. Despite current buzz, these concepts build on established work.</p><p>Traditionally, data lives in siloed applications‚Äîeach with its own relational databases, ETL processes, and dashboards. When cross-application queries and consistent definitions become painful, organizations face metadata management challenges. The first step is to integrate technical metadata (table names, columns, code lineage) into a unified knowledge graph. Then, add business metadata by mapping business glossaries and definitions to that technical layer.</p><p>A modern data catalog should:</p><ul><li><strong>Integrate Multiple Sources:</strong> Automatically ingest metadata from databases, ETL tools (e.g., dbt, Fivetran), and BI tools.</li><li><strong>Bridge Technical and Business Views:</strong> Link technical definitions (e.g., table ‚ÄúCUST_123‚Äù) with business concepts (e.g., ‚ÄúCustomer‚Äù).</li><li><strong>Enable Reuse and Governance:</strong> Support data discovery, impact analysis, and proper governance while facilitating reuse across teams.</li></ul><p><strong>Practical Approaches &amp; Use Cases:</strong></p><ul><li><strong>Start with a Clear Problem:</strong> Whether it‚Äôs reducing churn, improving operational efficiency, or meeting compliance needs, begin by solving a specific pain point.</li><li><strong>Iron Thread Method:</strong> Follow one query end-to-end‚Äîfrom identifying a business need to tracing it back to source systems‚Äîto gradually build and refine the graph.</li><li><strong>Automation vs. Manual Oversight:</strong> Technical metadata extraction is largely automated. For business definitions or text-based entity extraction (e.g., via LLMs), human oversight is key to ensuring accuracy and consistency.</li></ul><p><strong>Technical Considerations:</strong></p><ul><li><strong>Entity vs. Property:</strong> If you need to attach additional details or reuse an element across contexts, model it as an entity (with a unique identifier). Otherwise, keep it as a simple property.</li><li><strong>Storage Options:</strong> The market offers various graph databases‚ÄîNeo4j, Amazon Neptune, Cosmos DB, TigerGraph, Apache Jena (for RDF), etc. Future trends point toward multimodel systems that allow querying in SQL, Cypher, or SPARQL over the same underlying data.</li></ul><p><strong>Juan Sequeda:</strong></p><ul><li><a href="https://www.linkedin.com/in/juansequeda/">LinkedIn</a></li><li><a href="https://data.world/">data.world</a></li><li><a href="https://www.amazon.de/-/en/Semantic-Web-Working-Ontologist-Effective/dp/0123859654">Semantic Web for the Working Ontologist</a></li><li><a href="https://www.amazon.de/-/en/Designing-Enterprise-Knowledge-Synthesis-Semantics/dp/3031007883/ref=sr_1_1?crid=2FAWHKL5U4UAC&amp;dib=eyJ2IjoiMSJ9.qHtuAcPNcE2MJtTf-I6_mBjTNyXIT_PJWrm5XNc0De0.N-KR6cVBfIEnRy5GomUIPiB7oHoWhfgn2UfQHz0CsCc&amp;dib_tag=se&amp;keywords=Designing+and+Building+Enterprise+Knowledge+Graphs&amp;qid=1739717245&amp;sprefix=designing+and+building+enterprise+knowledge+graphs%2Caps%2C77&amp;sr=8-1">Designing and Building Enterprise Knowledge Graphs</a> (before you buy, send Juan a message, he is happy to send you a copy)</li><li><a href="https://open.spotify.com/show/2fkOqtpxNieWbvBRlPi0ml">Catalog &amp; Cocktails (Juan‚Äôs podcast)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Knowledge Graphs 00:45 The Role of Metadata in AI 01:06 Building Knowledge Graphs: First Steps 01:42 Interview with Juan Sequira 02:04 Understanding Buzzwords: Ontologies, Taxonomies, and More 05:05 Challenges and Solutions in Data Management 08:04 Practical Applications of Knowledge Graphs 15:38 Governance and Data Engineering 34:42 Setting the Stage for Data-Driven Problem Solving 34:58 Understanding Consumer Needs and Data Challenges 35:33 Foundations and Advanced Capabilities in Data Management 36:01 The Role of AI and Metadata in Data Maturity 37:56 The Iron Thread Approach to Problem Solving 40:12 Constructing and Utilizing Knowledge Graphs 54:38 Trends and Future Directions in Knowledge Graphs 59:17 Practical Advice for Building Knowledge Graphs</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/1b874e17/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/1b874e17/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#042 Temporal RAG, Embracing Time for Smarter, Reliable Knowledge Graphs</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>25</itunes:episode>
      <podcast:episode>25</podcast:episode>
      <itunes:title>#042 Temporal RAG, Embracing Time for Smarter, Reliable Knowledge Graphs</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">58784a68-9d6f-4e41-9d61-8b8b369871e4</guid>
      <link>https://share.transistor.fm/s/28ab3738</link>
      <description>
        <![CDATA[<p>Daniel Davis is an expert on knowledge graphs. He has a background in risk assessment and complex systems‚Äîfrom aerospace to cybersecurity. Now he is working on ‚ÄúTemporal RAG‚Äù in TrustGraph.</p><p>Time is a critical‚Äîbut often ignored‚Äîdimension in data. Whether it‚Äôs threat intelligence, legal contracts, or API documentation, every data point has a temporal context that affects its reliability and usefulness. To manage this, systems must track when data is created, updated, or deleted, and ideally, preserve versions over time.</p><p><strong>Three Types of Data:</strong></p><ol><li><strong>Observations:</strong><ul><li><strong>Definition:</strong> Measurable, verifiable recordings (e.g., ‚Äúthe hat reads ‚ÄòSunday Running Club‚Äô‚Äù).</li><li><strong>Characteristics:</strong> Require supporting evidence and may be updated as new data becomes available.</li></ul></li><li><strong>Assertions:</strong><ul><li><strong>Definition:</strong> Subjective interpretations (e.g., ‚Äúthe hat is greenish‚Äù).</li><li><strong>Characteristics:</strong> Involve human judgment and come with confidence levels; they may change over time.</li></ul></li><li><strong>Facts:</strong><ul><li><strong>Definition:</strong> Immutable, verified information that remains constant.</li><li><strong>Characteristics:</strong> Rare in dynamic environments because most data evolves; serve as the ‚Äúbedrock‚Äù of trust.</li></ul></li></ol><p>By clearly categorizing data into these buckets, systems can monitor freshness, detect staleness, and better manage dependencies between components (like code and its documentation).</p><p><strong>Integrating Temporal Data into Knowledge Graphs:</strong></p><ul><li><strong>Challenge:</strong></li><li>Traditional knowledge graphs and schemas (e.g., <a href="http://schema.org">schema.org</a>) rarely integrate time beyond basic metadata. Long documents may only provide a single timestamp, leaving the context of internal details untracked.</li><li><strong>Solution:</strong></li><li>Attach detailed temporal metadata (such as creation, update, and deletion timestamps) during data ingestion. Use versioning to maintain historical context. This allows systems to:<ul><li>Assess whether data is current or stale.</li><li>Detect conflicts when updates occur.</li><li>Employ Bayesian methods to adjust trust metrics as more information accumulates.</li></ul></li></ul><p><strong>Key Takeaways:</strong></p><ul><li><strong>Focus on Specialization:</strong></li><li>Build tools that do one thing well. For example, design a simple yet extensible knowledge graph rather than relying on overly complex ontologies.</li><li><strong>Integrate Temporal Metadata:</strong></li><li>Always timestamp data operations and version records. This is key to understanding data freshness and evolution.</li><li><strong>Adopt Robust Infrastructure:</strong></li><li>Use scalable, proven technologies to connect specialized modules via APIs. This reduces maintenance overhead compared to systems overloaded with connectors and extra features.</li><li><strong>Leverage Bayesian Updates:</strong></li><li>Start with initial trust metrics based on observed data and refine them as new evidence arrives.</li><li><strong>Mind the Big Picture:</strong></li><li>Avoid working in isolated silos. Emphasize a holistic system design that maintains in situ context and promotes collaboration across teams.</li></ul><p><strong>Daniel Davis</strong></p><ul><li><a href="https://github.com/trustgraph-ai/trustgraph">Cognitive Core</a></li><li><a href="https://trustgraph.ai/">TrustGraph</a></li><li><a href="https://www.youtube.com/@TrustGraphAI?sub_confirmation=1">YouTube</a></li><li><a href="https://www.linkedin.com/in/graphrag/">LinkedIn</a></li><li><a href="https://discord.gg/sQMwkRz5GX">Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Temporal Dimensions in Data 00:53 Timestamping and Versioning Data 01:35 Introducing Daniel Davis and Temporal RAG 01:58 Three Buckets of Data: Observations, Assertions, and Facts 03:22 Dynamic Data and Data Freshness 05:14 Challenges in Integrating Time in Knowledge Graphs 09:41 Defining Observations, Assertions, and Facts 12:57 The Role of Time in Data Trustworthiness 46:58 Chasing White Whales in AI 47:58 The Problem with Feature Overload 48:43 Connector Maintenance Challenges 50:02 The Swiss Army Knife Analogy 51:16 API Meshes and Glue Code 54:14 The Importance of Software Infrastructure 01:00:10 The Need for Specialized Tools 01:13:25 Outro and Future Plans</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Daniel Davis is an expert on knowledge graphs. He has a background in risk assessment and complex systems‚Äîfrom aerospace to cybersecurity. Now he is working on ‚ÄúTemporal RAG‚Äù in TrustGraph.</p><p>Time is a critical‚Äîbut often ignored‚Äîdimension in data. Whether it‚Äôs threat intelligence, legal contracts, or API documentation, every data point has a temporal context that affects its reliability and usefulness. To manage this, systems must track when data is created, updated, or deleted, and ideally, preserve versions over time.</p><p><strong>Three Types of Data:</strong></p><ol><li><strong>Observations:</strong><ul><li><strong>Definition:</strong> Measurable, verifiable recordings (e.g., ‚Äúthe hat reads ‚ÄòSunday Running Club‚Äô‚Äù).</li><li><strong>Characteristics:</strong> Require supporting evidence and may be updated as new data becomes available.</li></ul></li><li><strong>Assertions:</strong><ul><li><strong>Definition:</strong> Subjective interpretations (e.g., ‚Äúthe hat is greenish‚Äù).</li><li><strong>Characteristics:</strong> Involve human judgment and come with confidence levels; they may change over time.</li></ul></li><li><strong>Facts:</strong><ul><li><strong>Definition:</strong> Immutable, verified information that remains constant.</li><li><strong>Characteristics:</strong> Rare in dynamic environments because most data evolves; serve as the ‚Äúbedrock‚Äù of trust.</li></ul></li></ol><p>By clearly categorizing data into these buckets, systems can monitor freshness, detect staleness, and better manage dependencies between components (like code and its documentation).</p><p><strong>Integrating Temporal Data into Knowledge Graphs:</strong></p><ul><li><strong>Challenge:</strong></li><li>Traditional knowledge graphs and schemas (e.g., <a href="http://schema.org">schema.org</a>) rarely integrate time beyond basic metadata. Long documents may only provide a single timestamp, leaving the context of internal details untracked.</li><li><strong>Solution:</strong></li><li>Attach detailed temporal metadata (such as creation, update, and deletion timestamps) during data ingestion. Use versioning to maintain historical context. This allows systems to:<ul><li>Assess whether data is current or stale.</li><li>Detect conflicts when updates occur.</li><li>Employ Bayesian methods to adjust trust metrics as more information accumulates.</li></ul></li></ul><p><strong>Key Takeaways:</strong></p><ul><li><strong>Focus on Specialization:</strong></li><li>Build tools that do one thing well. For example, design a simple yet extensible knowledge graph rather than relying on overly complex ontologies.</li><li><strong>Integrate Temporal Metadata:</strong></li><li>Always timestamp data operations and version records. This is key to understanding data freshness and evolution.</li><li><strong>Adopt Robust Infrastructure:</strong></li><li>Use scalable, proven technologies to connect specialized modules via APIs. This reduces maintenance overhead compared to systems overloaded with connectors and extra features.</li><li><strong>Leverage Bayesian Updates:</strong></li><li>Start with initial trust metrics based on observed data and refine them as new evidence arrives.</li><li><strong>Mind the Big Picture:</strong></li><li>Avoid working in isolated silos. Emphasize a holistic system design that maintains in situ context and promotes collaboration across teams.</li></ul><p><strong>Daniel Davis</strong></p><ul><li><a href="https://github.com/trustgraph-ai/trustgraph">Cognitive Core</a></li><li><a href="https://trustgraph.ai/">TrustGraph</a></li><li><a href="https://www.youtube.com/@TrustGraphAI?sub_confirmation=1">YouTube</a></li><li><a href="https://www.linkedin.com/in/graphrag/">LinkedIn</a></li><li><a href="https://discord.gg/sQMwkRz5GX">Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Temporal Dimensions in Data 00:53 Timestamping and Versioning Data 01:35 Introducing Daniel Davis and Temporal RAG 01:58 Three Buckets of Data: Observations, Assertions, and Facts 03:22 Dynamic Data and Data Freshness 05:14 Challenges in Integrating Time in Knowledge Graphs 09:41 Defining Observations, Assertions, and Facts 12:57 The Role of Time in Data Trustworthiness 46:58 Chasing White Whales in AI 47:58 The Problem with Feature Overload 48:43 Connector Maintenance Challenges 50:02 The Swiss Army Knife Analogy 51:16 API Meshes and Glue Code 54:14 The Importance of Software Infrastructure 01:00:10 The Need for Specialized Tools 01:13:25 Outro and Future Plans</p>]]>
      </content:encoded>
      <pubDate>Thu, 13 Feb 2025 06:00:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/28ab3738/6cd2804f.mp3" length="90026234" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/DfTkY6qX2AE0TT8hOIy9L-xX_ugQ03-HNqFXA4FEMbw/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mMTVh/YmQ3OTI3ZmMwNzZh/MTNlNzY3NTUwYzFj/NTc4NS5wbmc.jpg"/>
      <itunes:duration>5624</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Daniel Davis is an expert on knowledge graphs. He has a background in risk assessment and complex systems‚Äîfrom aerospace to cybersecurity. Now he is working on ‚ÄúTemporal RAG‚Äù in TrustGraph.</p><p>Time is a critical‚Äîbut often ignored‚Äîdimension in data. Whether it‚Äôs threat intelligence, legal contracts, or API documentation, every data point has a temporal context that affects its reliability and usefulness. To manage this, systems must track when data is created, updated, or deleted, and ideally, preserve versions over time.</p><p><strong>Three Types of Data:</strong></p><ol><li><strong>Observations:</strong><ul><li><strong>Definition:</strong> Measurable, verifiable recordings (e.g., ‚Äúthe hat reads ‚ÄòSunday Running Club‚Äô‚Äù).</li><li><strong>Characteristics:</strong> Require supporting evidence and may be updated as new data becomes available.</li></ul></li><li><strong>Assertions:</strong><ul><li><strong>Definition:</strong> Subjective interpretations (e.g., ‚Äúthe hat is greenish‚Äù).</li><li><strong>Characteristics:</strong> Involve human judgment and come with confidence levels; they may change over time.</li></ul></li><li><strong>Facts:</strong><ul><li><strong>Definition:</strong> Immutable, verified information that remains constant.</li><li><strong>Characteristics:</strong> Rare in dynamic environments because most data evolves; serve as the ‚Äúbedrock‚Äù of trust.</li></ul></li></ol><p>By clearly categorizing data into these buckets, systems can monitor freshness, detect staleness, and better manage dependencies between components (like code and its documentation).</p><p><strong>Integrating Temporal Data into Knowledge Graphs:</strong></p><ul><li><strong>Challenge:</strong></li><li>Traditional knowledge graphs and schemas (e.g., <a href="http://schema.org">schema.org</a>) rarely integrate time beyond basic metadata. Long documents may only provide a single timestamp, leaving the context of internal details untracked.</li><li><strong>Solution:</strong></li><li>Attach detailed temporal metadata (such as creation, update, and deletion timestamps) during data ingestion. Use versioning to maintain historical context. This allows systems to:<ul><li>Assess whether data is current or stale.</li><li>Detect conflicts when updates occur.</li><li>Employ Bayesian methods to adjust trust metrics as more information accumulates.</li></ul></li></ul><p><strong>Key Takeaways:</strong></p><ul><li><strong>Focus on Specialization:</strong></li><li>Build tools that do one thing well. For example, design a simple yet extensible knowledge graph rather than relying on overly complex ontologies.</li><li><strong>Integrate Temporal Metadata:</strong></li><li>Always timestamp data operations and version records. This is key to understanding data freshness and evolution.</li><li><strong>Adopt Robust Infrastructure:</strong></li><li>Use scalable, proven technologies to connect specialized modules via APIs. This reduces maintenance overhead compared to systems overloaded with connectors and extra features.</li><li><strong>Leverage Bayesian Updates:</strong></li><li>Start with initial trust metrics based on observed data and refine them as new evidence arrives.</li><li><strong>Mind the Big Picture:</strong></li><li>Avoid working in isolated silos. Emphasize a holistic system design that maintains in situ context and promotes collaboration across teams.</li></ul><p><strong>Daniel Davis</strong></p><ul><li><a href="https://github.com/trustgraph-ai/trustgraph">Cognitive Core</a></li><li><a href="https://trustgraph.ai/">TrustGraph</a></li><li><a href="https://www.youtube.com/@TrustGraphAI?sub_confirmation=1">YouTube</a></li><li><a href="https://www.linkedin.com/in/graphrag/">LinkedIn</a></li><li><a href="https://discord.gg/sQMwkRz5GX">Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Temporal Dimensions in Data 00:53 Timestamping and Versioning Data 01:35 Introducing Daniel Davis and Temporal RAG 01:58 Three Buckets of Data: Observations, Assertions, and Facts 03:22 Dynamic Data and Data Freshness 05:14 Challenges in Integrating Time in Knowledge Graphs 09:41 Defining Observations, Assertions, and Facts 12:57 The Role of Time in Data Trustworthiness 46:58 Chasing White Whales in AI 47:58 The Problem with Feature Overload 48:43 Connector Maintenance Challenges 50:02 The Swiss Army Knife Analogy 51:16 API Meshes and Glue Code 54:14 The Importance of Software Infrastructure 01:00:10 The Need for Specialized Tools 01:13:25 Outro and Future Plans</p>]]>
      </itunes:summary>
      <itunes:keywords>rag, knowledge graphs, ai, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/28ab3738/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/28ab3738/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#041 Context Engineering, How Knowledge Graphs Help LLMs Reason </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>24</itunes:episode>
      <podcast:episode>24</podcast:episode>
      <itunes:title>#041 Context Engineering, How Knowledge Graphs Help LLMs Reason </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">44c5a05f-c49f-44de-a0b2-5f87b877325d</guid>
      <link>https://share.transistor.fm/s/62f6f747</link>
      <description>
        <![CDATA[<p>Robert Caulk runs Emergent Methods, a research lab building news knowledge graphs. With a Ph.D. in computational mechanics, he spent 12 years creating open-source tools for machine learning and data analysis. His work on projects like Flowdapt (model serving) and FreqAI (adaptive modeling) has earned over 1,000 academic citations.</p><p>His team built AskNews, which he calls "the largest news knowledge graph in production." It's a system that doesn't just collect news - it understands how events, people, and places connect.</p><p>Current AI systems struggle to connect information across sources and domains. Simple vector search misses crucial relationships. But building knowledge graphs at scale brings major technical hurdles around entity extraction, relationship mapping, and query performance.</p><p>Emergent Methods built a hybrid system combining vector search and knowledge graphs:</p><ul><li>Vector DB (Quadrant) handles initial broad retrieval</li><li>Custom knowledge graph processes relationships</li><li>Translation pipeline normalizes multi-language content</li><li>Entity extraction model identifies key elements</li><li>Context engineering pipeline structures data for LLMs</li></ul><p><strong>Implementation Details:</strong></p><p>Data Pipeline:</p><ul><li>All content normalized to English for consistent embeddings</li><li>Entity names preserved in original language when untranslatable</li><li>Custom Gleiner News model handles entity extraction</li><li>Retrained every 6 months on fresh data</li><li>Human review validates entity accuracy</li></ul><p>Entity Management:</p><ul><li>Base extraction uses BERT-based Gleiner architecture</li><li>Trained on diverse data across topics/regions</li><li>Disambiguation system merges duplicate entities</li><li>Manual override options for analysts</li><li>Metadata tracking preserves relationship context</li></ul><p>Knowledge Graph:</p><ul><li>Selective graph construction from vector results</li><li>On-demand relationship processing</li><li>Graph queries via standard Cypher</li><li>Built for specific use cases vs general coverage</li><li>Integration with S3 and other data stores</li></ul><p>System Validation:</p><ul><li>Custom "Context is King" benchmark suite</li><li>RAGAS metrics track retrieval accuracy</li><li>Time-split validation prevents data leakage</li><li>Manual review of entity extraction</li><li>Production monitoring of query patterns</li></ul><p><strong>Engineering Insights:<br></strong><br></p><p>Key Technical Decisions:</p><ul><li>English normalization enables consistent embeddings</li><li>Hybrid vector + graph approach balances speed/depth</li><li>Selective graph construction keeps costs down</li><li>Human-in-loop validation maintains quality</li></ul><p>Dead Ends Hit:</p><ul><li>Full multi-language entity system too complex</li><li>Real-time graph updates not feasible at scale</li><li>Pure vector or pure graph approaches insufficient</li></ul><p><strong>Top Quotes:</strong></p><ul><li>"At its core, context engineering is about how we feed information to AI. We want clear, focused inputs for better outputs. Think of it like talking to a smart friend - you'd give them the key facts in a way they can use, not dump raw data on them." - Robert</li><li>"Strong metadata paints a high-fidelity picture. If we're trying to understand what's happening in Ukraine, we need to know not just what was said, but who said it, when they said it, and what voice they used to say it. Each piece adds color to the picture." - Robert</li><li>"Clean data beats clever models. You can throw noise at an LLM and get something that looks good, but if you want real accuracy, you need to strip away the clutter first. Every piece of noise pulls the model in a different direction." - Robert</li><li>"Think about how the answer looks in the real world. If you're comparing apartments, you'd want a table. If you're tracking events, you'd want a timeline. Match your data structure to how humans naturally process that kind of information." - Nico</li><li>"Building knowledge graphs isn't about collecting everything - it's about finding the relationships that matter. Most applications don't need a massive graph. They need the right connections for their specific problem." - Robert</li><li>"The quality of your context sets the ceiling for what your AI can do. You can have the best model in the world, but if you feed it noisy, unclear data, you'll get noisy, unclear answers. Garbage in, garbage out still applies." - Robert</li><li>"When handling multiple languages, it's better to normalize everything to one language than to try juggling many. Yes, you lose some nuance, but you gain consistency. And consistency is what makes these systems reliable." - Robert</li><li>"The hard part isn't storing the data - it's making it useful. Anyone can build a database. The trick is structuring information so an AI can actually reason with it. That's where context engineering makes the difference." - Robert</li><li>"Start simple, then add complexity only when you need it. Most teams jump straight to sophisticated solutions when they could get better results by just cleaning their data and thinking carefully about how they structure it." - Nico</li><li>"Every token in your context window is precious. Don't waste them on HTML tags or formatting noise. Save that space for the actual signal - the facts, relationships, and context that help the AI understand what you're asking." - Nico</li></ul><p><strong>Robert Caulk:</strong></p><ul><li><a href="https://www.linkedin.com/in/rcaulk/">LinkedIn</a></li><li><a href="https://emergentmethods.ai/">Emergent Methods</a></li><li><a href="https://docs.asknews.app/en">Asknews</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Context Engineering 00:24 Curating Input Signals 01:01 Structuring Raw Data 03:05 Refinement and Iteration 04:08 Balancing Breadth and Precision 06:10 Interview Start 08:02 Challenges in Context Engineering 20:25 Optimizing Context for LLMs 45:44 Advanced Cypher Queries and Graphs 46:43 Enrichment Pipeline Flexibility 47:16 Combining Graph and Semantic Search 49:23 Handling Multilingual Entities 52:57 Disambiguation and Deduplication Challenges 55:37 Training Models for Diverse Domains 01:04:43 Dealing with AI-Generated Content 01:17:32 Future Developments and Final Thoughts</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Robert Caulk runs Emergent Methods, a research lab building news knowledge graphs. With a Ph.D. in computational mechanics, he spent 12 years creating open-source tools for machine learning and data analysis. His work on projects like Flowdapt (model serving) and FreqAI (adaptive modeling) has earned over 1,000 academic citations.</p><p>His team built AskNews, which he calls "the largest news knowledge graph in production." It's a system that doesn't just collect news - it understands how events, people, and places connect.</p><p>Current AI systems struggle to connect information across sources and domains. Simple vector search misses crucial relationships. But building knowledge graphs at scale brings major technical hurdles around entity extraction, relationship mapping, and query performance.</p><p>Emergent Methods built a hybrid system combining vector search and knowledge graphs:</p><ul><li>Vector DB (Quadrant) handles initial broad retrieval</li><li>Custom knowledge graph processes relationships</li><li>Translation pipeline normalizes multi-language content</li><li>Entity extraction model identifies key elements</li><li>Context engineering pipeline structures data for LLMs</li></ul><p><strong>Implementation Details:</strong></p><p>Data Pipeline:</p><ul><li>All content normalized to English for consistent embeddings</li><li>Entity names preserved in original language when untranslatable</li><li>Custom Gleiner News model handles entity extraction</li><li>Retrained every 6 months on fresh data</li><li>Human review validates entity accuracy</li></ul><p>Entity Management:</p><ul><li>Base extraction uses BERT-based Gleiner architecture</li><li>Trained on diverse data across topics/regions</li><li>Disambiguation system merges duplicate entities</li><li>Manual override options for analysts</li><li>Metadata tracking preserves relationship context</li></ul><p>Knowledge Graph:</p><ul><li>Selective graph construction from vector results</li><li>On-demand relationship processing</li><li>Graph queries via standard Cypher</li><li>Built for specific use cases vs general coverage</li><li>Integration with S3 and other data stores</li></ul><p>System Validation:</p><ul><li>Custom "Context is King" benchmark suite</li><li>RAGAS metrics track retrieval accuracy</li><li>Time-split validation prevents data leakage</li><li>Manual review of entity extraction</li><li>Production monitoring of query patterns</li></ul><p><strong>Engineering Insights:<br></strong><br></p><p>Key Technical Decisions:</p><ul><li>English normalization enables consistent embeddings</li><li>Hybrid vector + graph approach balances speed/depth</li><li>Selective graph construction keeps costs down</li><li>Human-in-loop validation maintains quality</li></ul><p>Dead Ends Hit:</p><ul><li>Full multi-language entity system too complex</li><li>Real-time graph updates not feasible at scale</li><li>Pure vector or pure graph approaches insufficient</li></ul><p><strong>Top Quotes:</strong></p><ul><li>"At its core, context engineering is about how we feed information to AI. We want clear, focused inputs for better outputs. Think of it like talking to a smart friend - you'd give them the key facts in a way they can use, not dump raw data on them." - Robert</li><li>"Strong metadata paints a high-fidelity picture. If we're trying to understand what's happening in Ukraine, we need to know not just what was said, but who said it, when they said it, and what voice they used to say it. Each piece adds color to the picture." - Robert</li><li>"Clean data beats clever models. You can throw noise at an LLM and get something that looks good, but if you want real accuracy, you need to strip away the clutter first. Every piece of noise pulls the model in a different direction." - Robert</li><li>"Think about how the answer looks in the real world. If you're comparing apartments, you'd want a table. If you're tracking events, you'd want a timeline. Match your data structure to how humans naturally process that kind of information." - Nico</li><li>"Building knowledge graphs isn't about collecting everything - it's about finding the relationships that matter. Most applications don't need a massive graph. They need the right connections for their specific problem." - Robert</li><li>"The quality of your context sets the ceiling for what your AI can do. You can have the best model in the world, but if you feed it noisy, unclear data, you'll get noisy, unclear answers. Garbage in, garbage out still applies." - Robert</li><li>"When handling multiple languages, it's better to normalize everything to one language than to try juggling many. Yes, you lose some nuance, but you gain consistency. And consistency is what makes these systems reliable." - Robert</li><li>"The hard part isn't storing the data - it's making it useful. Anyone can build a database. The trick is structuring information so an AI can actually reason with it. That's where context engineering makes the difference." - Robert</li><li>"Start simple, then add complexity only when you need it. Most teams jump straight to sophisticated solutions when they could get better results by just cleaning their data and thinking carefully about how they structure it." - Nico</li><li>"Every token in your context window is precious. Don't waste them on HTML tags or formatting noise. Save that space for the actual signal - the facts, relationships, and context that help the AI understand what you're asking." - Nico</li></ul><p><strong>Robert Caulk:</strong></p><ul><li><a href="https://www.linkedin.com/in/rcaulk/">LinkedIn</a></li><li><a href="https://emergentmethods.ai/">Emergent Methods</a></li><li><a href="https://docs.asknews.app/en">Asknews</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Context Engineering 00:24 Curating Input Signals 01:01 Structuring Raw Data 03:05 Refinement and Iteration 04:08 Balancing Breadth and Precision 06:10 Interview Start 08:02 Challenges in Context Engineering 20:25 Optimizing Context for LLMs 45:44 Advanced Cypher Queries and Graphs 46:43 Enrichment Pipeline Flexibility 47:16 Combining Graph and Semantic Search 49:23 Handling Multilingual Entities 52:57 Disambiguation and Deduplication Challenges 55:37 Training Models for Diverse Domains 01:04:43 Dealing with AI-Generated Content 01:17:32 Future Developments and Final Thoughts</p>]]>
      </content:encoded>
      <pubDate>Thu, 06 Feb 2025 06:00:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/62f6f747/d30cefbc.mp3" length="89882490" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/4Qko2y85LOiEEeRe0VWP6t5TBb7HIWbIbeB71QZB-_8/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9hZGY1/ZjY2ZTI1Y2Q0N2U4/ODk1YTNiYmY0MjFl/YmRkYi5wbmc.jpg"/>
      <itunes:duration>5615</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Robert Caulk runs Emergent Methods, a research lab building news knowledge graphs. With a Ph.D. in computational mechanics, he spent 12 years creating open-source tools for machine learning and data analysis. His work on projects like Flowdapt (model serving) and FreqAI (adaptive modeling) has earned over 1,000 academic citations.</p><p>His team built AskNews, which he calls "the largest news knowledge graph in production." It's a system that doesn't just collect news - it understands how events, people, and places connect.</p><p>Current AI systems struggle to connect information across sources and domains. Simple vector search misses crucial relationships. But building knowledge graphs at scale brings major technical hurdles around entity extraction, relationship mapping, and query performance.</p><p>Emergent Methods built a hybrid system combining vector search and knowledge graphs:</p><ul><li>Vector DB (Quadrant) handles initial broad retrieval</li><li>Custom knowledge graph processes relationships</li><li>Translation pipeline normalizes multi-language content</li><li>Entity extraction model identifies key elements</li><li>Context engineering pipeline structures data for LLMs</li></ul><p><strong>Implementation Details:</strong></p><p>Data Pipeline:</p><ul><li>All content normalized to English for consistent embeddings</li><li>Entity names preserved in original language when untranslatable</li><li>Custom Gleiner News model handles entity extraction</li><li>Retrained every 6 months on fresh data</li><li>Human review validates entity accuracy</li></ul><p>Entity Management:</p><ul><li>Base extraction uses BERT-based Gleiner architecture</li><li>Trained on diverse data across topics/regions</li><li>Disambiguation system merges duplicate entities</li><li>Manual override options for analysts</li><li>Metadata tracking preserves relationship context</li></ul><p>Knowledge Graph:</p><ul><li>Selective graph construction from vector results</li><li>On-demand relationship processing</li><li>Graph queries via standard Cypher</li><li>Built for specific use cases vs general coverage</li><li>Integration with S3 and other data stores</li></ul><p>System Validation:</p><ul><li>Custom "Context is King" benchmark suite</li><li>RAGAS metrics track retrieval accuracy</li><li>Time-split validation prevents data leakage</li><li>Manual review of entity extraction</li><li>Production monitoring of query patterns</li></ul><p><strong>Engineering Insights:<br></strong><br></p><p>Key Technical Decisions:</p><ul><li>English normalization enables consistent embeddings</li><li>Hybrid vector + graph approach balances speed/depth</li><li>Selective graph construction keeps costs down</li><li>Human-in-loop validation maintains quality</li></ul><p>Dead Ends Hit:</p><ul><li>Full multi-language entity system too complex</li><li>Real-time graph updates not feasible at scale</li><li>Pure vector or pure graph approaches insufficient</li></ul><p><strong>Top Quotes:</strong></p><ul><li>"At its core, context engineering is about how we feed information to AI. We want clear, focused inputs for better outputs. Think of it like talking to a smart friend - you'd give them the key facts in a way they can use, not dump raw data on them." - Robert</li><li>"Strong metadata paints a high-fidelity picture. If we're trying to understand what's happening in Ukraine, we need to know not just what was said, but who said it, when they said it, and what voice they used to say it. Each piece adds color to the picture." - Robert</li><li>"Clean data beats clever models. You can throw noise at an LLM and get something that looks good, but if you want real accuracy, you need to strip away the clutter first. Every piece of noise pulls the model in a different direction." - Robert</li><li>"Think about how the answer looks in the real world. If you're comparing apartments, you'd want a table. If you're tracking events, you'd want a timeline. Match your data structure to how humans naturally process that kind of information." - Nico</li><li>"Building knowledge graphs isn't about collecting everything - it's about finding the relationships that matter. Most applications don't need a massive graph. They need the right connections for their specific problem." - Robert</li><li>"The quality of your context sets the ceiling for what your AI can do. You can have the best model in the world, but if you feed it noisy, unclear data, you'll get noisy, unclear answers. Garbage in, garbage out still applies." - Robert</li><li>"When handling multiple languages, it's better to normalize everything to one language than to try juggling many. Yes, you lose some nuance, but you gain consistency. And consistency is what makes these systems reliable." - Robert</li><li>"The hard part isn't storing the data - it's making it useful. Anyone can build a database. The trick is structuring information so an AI can actually reason with it. That's where context engineering makes the difference." - Robert</li><li>"Start simple, then add complexity only when you need it. Most teams jump straight to sophisticated solutions when they could get better results by just cleaning their data and thinking carefully about how they structure it." - Nico</li><li>"Every token in your context window is precious. Don't waste them on HTML tags or formatting noise. Save that space for the actual signal - the facts, relationships, and context that help the AI understand what you're asking." - Nico</li></ul><p><strong>Robert Caulk:</strong></p><ul><li><a href="https://www.linkedin.com/in/rcaulk/">LinkedIn</a></li><li><a href="https://emergentmethods.ai/">Emergent Methods</a></li><li><a href="https://docs.asknews.app/en">Asknews</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Context Engineering 00:24 Curating Input Signals 01:01 Structuring Raw Data 03:05 Refinement and Iteration 04:08 Balancing Breadth and Precision 06:10 Interview Start 08:02 Challenges in Context Engineering 20:25 Optimizing Context for LLMs 45:44 Advanced Cypher Queries and Graphs 46:43 Enrichment Pipeline Flexibility 47:16 Combining Graph and Semantic Search 49:23 Handling Multilingual Entities 52:57 Disambiguation and Deduplication Challenges 55:37 Training Models for Diverse Domains 01:04:43 Dealing with AI-Generated Content 01:17:32 Future Developments and Final Thoughts</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, llm, knowledge graph, rag</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/62f6f747/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/62f6f747/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#040 Vector Database Quantization, Product, Binary, and Scalar</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>23</itunes:episode>
      <podcast:episode>23</podcast:episode>
      <itunes:title>#040 Vector Database Quantization, Product, Binary, and Scalar</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">c865d58b-549c-4100-a4df-3a499b24f100</guid>
      <link>https://share.transistor.fm/s/2a207905</link>
      <description>
        <![CDATA[<p>When you store vectors, each number takes up 32 bits.</p><p>With 1000 numbers per vector and millions of vectors, costs explode.</p><p>A simple chatbot can cost thousands per month just to store and search through vectors.</p><p>The Fix: Quantization</p><p>Think of it like image compression. JPEGs look almost as good as raw photos but take up far less space. Quantization does the same for vectors.</p><p><br>Today we are back continuing our series on search with Zain Hasan, a former ML engineer at Weaviate and now a Senior AI/ ML Engineer at Together. We talk about the different types of quantization, when to use them, how to use them, and their tradeoff.¬†</p><p>Three Ways to Quantize:</p><ol><li>Binary Quantization¬†<ul><li>Turn each number into just 0 or 1</li><li>Ask: "Is this dimension positive or negative?"</li><li>Works great for 1000+ dimensions</li><li>Cuts memory by 97%</li><li>Best for normally distributed data</li></ul></li><li>Product Quantization¬†<ul><li>Split vector into chunks</li><li>Group similar chunks</li><li>Store cluster IDs instead of full numbers</li><li>Good when binary quantization fails</li><li>More complex but flexible</li></ul></li><li>Scalar Quantization¬†<ul><li>Use 8 bits instead of 32</li><li>Simple middle ground</li><li>Keeps more precision than binary</li><li>Less savings than binary<p></p></li></ul></li></ol><p><br><strong>Key Quotes:</strong></p><ul><li>"Vector databases are pretty much the commercialization and the productization of representation learning."</li><li>"I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."</li><li>"Going from text to multimedia in vector databases is really simple."</li><li>"Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."</li></ul><p><strong>Zain Hasan:</strong></p><ul><li><a href="https://www.linkedin.com/in/zainhas">LinkedIn</a></li><li><a href="https://x.com/zainhasan6">X (Twitter)</a></li><li><a href="https://weaviate.io/">Weaviate</a></li><li><a href="https://www.together.ai/">Together</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>When you store vectors, each number takes up 32 bits.</p><p>With 1000 numbers per vector and millions of vectors, costs explode.</p><p>A simple chatbot can cost thousands per month just to store and search through vectors.</p><p>The Fix: Quantization</p><p>Think of it like image compression. JPEGs look almost as good as raw photos but take up far less space. Quantization does the same for vectors.</p><p><br>Today we are back continuing our series on search with Zain Hasan, a former ML engineer at Weaviate and now a Senior AI/ ML Engineer at Together. We talk about the different types of quantization, when to use them, how to use them, and their tradeoff.¬†</p><p>Three Ways to Quantize:</p><ol><li>Binary Quantization¬†<ul><li>Turn each number into just 0 or 1</li><li>Ask: "Is this dimension positive or negative?"</li><li>Works great for 1000+ dimensions</li><li>Cuts memory by 97%</li><li>Best for normally distributed data</li></ul></li><li>Product Quantization¬†<ul><li>Split vector into chunks</li><li>Group similar chunks</li><li>Store cluster IDs instead of full numbers</li><li>Good when binary quantization fails</li><li>More complex but flexible</li></ul></li><li>Scalar Quantization¬†<ul><li>Use 8 bits instead of 32</li><li>Simple middle ground</li><li>Keeps more precision than binary</li><li>Less savings than binary<p></p></li></ul></li></ol><p><br><strong>Key Quotes:</strong></p><ul><li>"Vector databases are pretty much the commercialization and the productization of representation learning."</li><li>"I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."</li><li>"Going from text to multimedia in vector databases is really simple."</li><li>"Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."</li></ul><p><strong>Zain Hasan:</strong></p><ul><li><a href="https://www.linkedin.com/in/zainhas">LinkedIn</a></li><li><a href="https://x.com/zainhasan6">X (Twitter)</a></li><li><a href="https://weaviate.io/">Weaviate</a></li><li><a href="https://www.together.ai/">Together</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</p>]]>
      </content:encoded>
      <pubDate>Fri, 31 Jan 2025 07:26:35 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/2a207905/199bf63e.mp3" length="50141269" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/J70eQNQ6LfSXnp3dp4a-FhjDSh6pvbSZ1G407EBWH_Y/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8zMmRh/MTJhYjU0NjU5MTFj/NGFlNjg2NzlkM2Q1/MDQyNi5wbmc.jpg"/>
      <itunes:duration>3132</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>When you store vectors, each number takes up 32 bits.</p><p>With 1000 numbers per vector and millions of vectors, costs explode.</p><p>A simple chatbot can cost thousands per month just to store and search through vectors.</p><p>The Fix: Quantization</p><p>Think of it like image compression. JPEGs look almost as good as raw photos but take up far less space. Quantization does the same for vectors.</p><p><br>Today we are back continuing our series on search with Zain Hasan, a former ML engineer at Weaviate and now a Senior AI/ ML Engineer at Together. We talk about the different types of quantization, when to use them, how to use them, and their tradeoff.¬†</p><p>Three Ways to Quantize:</p><ol><li>Binary Quantization¬†<ul><li>Turn each number into just 0 or 1</li><li>Ask: "Is this dimension positive or negative?"</li><li>Works great for 1000+ dimensions</li><li>Cuts memory by 97%</li><li>Best for normally distributed data</li></ul></li><li>Product Quantization¬†<ul><li>Split vector into chunks</li><li>Group similar chunks</li><li>Store cluster IDs instead of full numbers</li><li>Good when binary quantization fails</li><li>More complex but flexible</li></ul></li><li>Scalar Quantization¬†<ul><li>Use 8 bits instead of 32</li><li>Simple middle ground</li><li>Keeps more precision than binary</li><li>Less savings than binary<p></p></li></ul></li></ol><p><br><strong>Key Quotes:</strong></p><ul><li>"Vector databases are pretty much the commercialization and the productization of representation learning."</li><li>"I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."</li><li>"Going from text to multimedia in vector databases is really simple."</li><li>"Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."</li></ul><p><strong>Zain Hasan:</strong></p><ul><li><a href="https://www.linkedin.com/in/zainhas">LinkedIn</a></li><li><a href="https://x.com/zainhasan6">X (Twitter)</a></li><li><a href="https://weaviate.io/">Weaviate</a></li><li><a href="https://www.together.ai/">Together</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</p>]]>
      </itunes:summary>
      <itunes:keywords>search, ai, llm, embedding, vectors</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/2a207905/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/2a207905/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#039 Local-First Search, How to Push Search To End-Devices</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>22</itunes:episode>
      <podcast:episode>22</podcast:episode>
      <itunes:title>#039 Local-First Search, How to Push Search To End-Devices</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">7a50f88d-e50f-482a-84c9-3d797748f2c4</guid>
      <link>https://share.transistor.fm/s/48421b05</link>
      <description>
        <![CDATA[<p>Alex Garcia is a developer focused on making vector search accessible and practical. As he puts it: "I'm a SQLite guy. I use SQLite for a lot of projects... I want an easier vector search thing that I don't have to install 10,000 dependencies to use.‚Äù</p><p><strong>Core Mantra: "Simple, Local, Scalable"<br></strong><br></p><p><strong>Why SQLite Vec?</strong></p><p>"I didn't go along thinking, 'Oh, I want to build vector search, let me find a database for it.' It was much more like: I use SQLite for a lot of projects, I want something lightweight that works in my current workflow."</p><p>SQLiteVec uses row-oriented storage with some key design choices:</p><ul><li>Vectors are stored in large chunks (megabytes) as blobs</li><li>Data is split across 4KB SQLite pages, which affects analytical performance</li><li>Currently uses brute force linear search without ANN indexing</li><li>Supports binary quantization for 32x size reduction</li><li>Handles tens to hundreds of thousands of vectors efficiently</li></ul><p>Practical limits:</p><ul><li>500ms search time for 500K vectors (768 dimensions)</li><li>Best performance under 100ms for user experience</li><li>Binary quantization enables scaling to ~1M vectors</li><li>Metadata filtering and partitioning coming soon</li></ul><p>Key advantages:</p><ul><li>Fast writes for transactional workloads</li><li>Simple single-file database</li><li>Easy integration with existing SQLite applications</li><li>Leverages SQLite's mature storage engine</li></ul><p>Garcia's preferred tools for local AI:</p><ul><li>Sentence Transformers models converted to GGUF format</li><li>Llama.cpp for inference</li><li>Small models (30MB) for basic embeddings</li><li>Larger models like Arctic Embed (hundreds of MB) for recent topics</li><li>SQLite L-Embed extension for text embeddings</li><li>Transformers.js for browser-based implementations</li></ul><p><strong>1. Choose Your Storage</strong></p><p>"There's two ways of storing vectors within SQLiteVec. One way is a manual way where you just store a JSON array... [second is] using a virtual table."</p><ul><li>Traditional row storage: Simple, flexible, good for small vectors</li><li>Virtual table storage: Optimized chunks, better for large datasets</li><li>Performance sweet spot: Up to 500K vectors with 500ms search time</li></ul><p><strong>2. Optimize Performance</strong></p><p>"With binary quantization it's 1/32 of the space... and holds up at 95 percent quality"</p><ul><li>Binary quantization reduces storage 32x with 95% quality</li><li>Default page size is 4KB - plan your vector storage accordingly</li><li>Metadata filtering dramatically improves search speed</li></ul><p><strong>3. Integration Patterns</strong></p><p>"It's a single file, right? So you can like copy and paste it if you want to make a backup."</p><ul><li>Two storage approaches: manual columns or virtual tables</li><li>Easy backups: single file database</li><li>Cross-platform: desktop, mobile, IoT, browser (via WASM)</li></ul><p><strong>4. Real-World Tips</strong></p><p>"I typically choose the really small model... it's 30 megabytes. It quantizes very easily... I like it because it's very small, quick and easy."</p><ul><li>Start with smaller, efficient models (30MB range)</li><li>Use binary quantization before trying complex solutions</li><li>Plan for partitioning when scaling beyond 100K vectors</li></ul><p><strong>Alex Garcia</strong></p><ul><li><a href="https://www.linkedin.com/in/alex-sebastian-garcia/">LinkedIn</a></li><li><a href="https://x.com/agarcia_me">X (Twitter)</a></li><li><a href="https://github.com/asg017">GitHub</a></li><li><a href="https://github.com/asg017/sqlite-vec">sqlite-vec</a></li><li><a href="https://alexgarcia.xyz/sqlite-vss/">sqllite-vss</a></li><li><a href="https://alexgarcia.xyz/">Website</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Alex Garcia is a developer focused on making vector search accessible and practical. As he puts it: "I'm a SQLite guy. I use SQLite for a lot of projects... I want an easier vector search thing that I don't have to install 10,000 dependencies to use.‚Äù</p><p><strong>Core Mantra: "Simple, Local, Scalable"<br></strong><br></p><p><strong>Why SQLite Vec?</strong></p><p>"I didn't go along thinking, 'Oh, I want to build vector search, let me find a database for it.' It was much more like: I use SQLite for a lot of projects, I want something lightweight that works in my current workflow."</p><p>SQLiteVec uses row-oriented storage with some key design choices:</p><ul><li>Vectors are stored in large chunks (megabytes) as blobs</li><li>Data is split across 4KB SQLite pages, which affects analytical performance</li><li>Currently uses brute force linear search without ANN indexing</li><li>Supports binary quantization for 32x size reduction</li><li>Handles tens to hundreds of thousands of vectors efficiently</li></ul><p>Practical limits:</p><ul><li>500ms search time for 500K vectors (768 dimensions)</li><li>Best performance under 100ms for user experience</li><li>Binary quantization enables scaling to ~1M vectors</li><li>Metadata filtering and partitioning coming soon</li></ul><p>Key advantages:</p><ul><li>Fast writes for transactional workloads</li><li>Simple single-file database</li><li>Easy integration with existing SQLite applications</li><li>Leverages SQLite's mature storage engine</li></ul><p>Garcia's preferred tools for local AI:</p><ul><li>Sentence Transformers models converted to GGUF format</li><li>Llama.cpp for inference</li><li>Small models (30MB) for basic embeddings</li><li>Larger models like Arctic Embed (hundreds of MB) for recent topics</li><li>SQLite L-Embed extension for text embeddings</li><li>Transformers.js for browser-based implementations</li></ul><p><strong>1. Choose Your Storage</strong></p><p>"There's two ways of storing vectors within SQLiteVec. One way is a manual way where you just store a JSON array... [second is] using a virtual table."</p><ul><li>Traditional row storage: Simple, flexible, good for small vectors</li><li>Virtual table storage: Optimized chunks, better for large datasets</li><li>Performance sweet spot: Up to 500K vectors with 500ms search time</li></ul><p><strong>2. Optimize Performance</strong></p><p>"With binary quantization it's 1/32 of the space... and holds up at 95 percent quality"</p><ul><li>Binary quantization reduces storage 32x with 95% quality</li><li>Default page size is 4KB - plan your vector storage accordingly</li><li>Metadata filtering dramatically improves search speed</li></ul><p><strong>3. Integration Patterns</strong></p><p>"It's a single file, right? So you can like copy and paste it if you want to make a backup."</p><ul><li>Two storage approaches: manual columns or virtual tables</li><li>Easy backups: single file database</li><li>Cross-platform: desktop, mobile, IoT, browser (via WASM)</li></ul><p><strong>4. Real-World Tips</strong></p><p>"I typically choose the really small model... it's 30 megabytes. It quantizes very easily... I like it because it's very small, quick and easy."</p><ul><li>Start with smaller, efficient models (30MB range)</li><li>Use binary quantization before trying complex solutions</li><li>Plan for partitioning when scaling beyond 100K vectors</li></ul><p><strong>Alex Garcia</strong></p><ul><li><a href="https://www.linkedin.com/in/alex-sebastian-garcia/">LinkedIn</a></li><li><a href="https://x.com/agarcia_me">X (Twitter)</a></li><li><a href="https://github.com/asg017">GitHub</a></li><li><a href="https://github.com/asg017/sqlite-vec">sqlite-vec</a></li><li><a href="https://alexgarcia.xyz/sqlite-vss/">sqllite-vss</a></li><li><a href="https://alexgarcia.xyz/">Website</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </content:encoded>
      <pubDate>Thu, 23 Jan 2025 08:04:34 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/48421b05/97dbbe54.mp3" length="51055871" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/4x0zSKluRdfQIYnHgaRl0ocJBKRl2iYt3StScjDpNr4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84ZmM5/YjBiMTkxZjRjZDNi/OGUyNTA5MjY3YjYz/NWY4NS5wbmc.jpg"/>
      <itunes:duration>3189</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Alex Garcia is a developer focused on making vector search accessible and practical. As he puts it: "I'm a SQLite guy. I use SQLite for a lot of projects... I want an easier vector search thing that I don't have to install 10,000 dependencies to use.‚Äù</p><p><strong>Core Mantra: "Simple, Local, Scalable"<br></strong><br></p><p><strong>Why SQLite Vec?</strong></p><p>"I didn't go along thinking, 'Oh, I want to build vector search, let me find a database for it.' It was much more like: I use SQLite for a lot of projects, I want something lightweight that works in my current workflow."</p><p>SQLiteVec uses row-oriented storage with some key design choices:</p><ul><li>Vectors are stored in large chunks (megabytes) as blobs</li><li>Data is split across 4KB SQLite pages, which affects analytical performance</li><li>Currently uses brute force linear search without ANN indexing</li><li>Supports binary quantization for 32x size reduction</li><li>Handles tens to hundreds of thousands of vectors efficiently</li></ul><p>Practical limits:</p><ul><li>500ms search time for 500K vectors (768 dimensions)</li><li>Best performance under 100ms for user experience</li><li>Binary quantization enables scaling to ~1M vectors</li><li>Metadata filtering and partitioning coming soon</li></ul><p>Key advantages:</p><ul><li>Fast writes for transactional workloads</li><li>Simple single-file database</li><li>Easy integration with existing SQLite applications</li><li>Leverages SQLite's mature storage engine</li></ul><p>Garcia's preferred tools for local AI:</p><ul><li>Sentence Transformers models converted to GGUF format</li><li>Llama.cpp for inference</li><li>Small models (30MB) for basic embeddings</li><li>Larger models like Arctic Embed (hundreds of MB) for recent topics</li><li>SQLite L-Embed extension for text embeddings</li><li>Transformers.js for browser-based implementations</li></ul><p><strong>1. Choose Your Storage</strong></p><p>"There's two ways of storing vectors within SQLiteVec. One way is a manual way where you just store a JSON array... [second is] using a virtual table."</p><ul><li>Traditional row storage: Simple, flexible, good for small vectors</li><li>Virtual table storage: Optimized chunks, better for large datasets</li><li>Performance sweet spot: Up to 500K vectors with 500ms search time</li></ul><p><strong>2. Optimize Performance</strong></p><p>"With binary quantization it's 1/32 of the space... and holds up at 95 percent quality"</p><ul><li>Binary quantization reduces storage 32x with 95% quality</li><li>Default page size is 4KB - plan your vector storage accordingly</li><li>Metadata filtering dramatically improves search speed</li></ul><p><strong>3. Integration Patterns</strong></p><p>"It's a single file, right? So you can like copy and paste it if you want to make a backup."</p><ul><li>Two storage approaches: manual columns or virtual tables</li><li>Easy backups: single file database</li><li>Cross-platform: desktop, mobile, IoT, browser (via WASM)</li></ul><p><strong>4. Real-World Tips</strong></p><p>"I typically choose the really small model... it's 30 megabytes. It quantizes very easily... I like it because it's very small, quick and easy."</p><ul><li>Start with smaller, efficient models (30MB range)</li><li>Use binary quantization before trying complex solutions</li><li>Plan for partitioning when scaling beyond 100K vectors</li></ul><p><strong>Alex Garcia</strong></p><ul><li><a href="https://www.linkedin.com/in/alex-sebastian-garcia/">LinkedIn</a></li><li><a href="https://x.com/agarcia_me">X (Twitter)</a></li><li><a href="https://github.com/asg017">GitHub</a></li><li><a href="https://github.com/asg017/sqlite-vec">sqlite-vec</a></li><li><a href="https://alexgarcia.xyz/sqlite-vss/">sqllite-vss</a></li><li><a href="https://alexgarcia.xyz/">Website</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, sqllite</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/48421b05/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/48421b05/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#038 AI-Powered Search, Context Is King, But Your RAG System Ignores Two-Thirds of It</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>21</itunes:episode>
      <podcast:episode>21</podcast:episode>
      <itunes:title>#038 AI-Powered Search, Context Is King, But Your RAG System Ignores Two-Thirds of It</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">9dbda8d7-c80d-42a6-8f8d-a2617037825a</guid>
      <link>https://share.transistor.fm/s/38d05034</link>
      <description>
        <![CDATA[<p>Today, I (Nicolay Gerold) sit down with Trey Grainger, author of the book AI-Powered Search. We discuss the different techniques for search and recommendations and how to combine them.</p><p>While RAG (Retrieval-Augmented Generation) has become a buzzword in AI, Trey argues that the current understanding of "RAG" is overly simplified ‚Äì it's actually a bidirectional process he calls "GARRAG," where retrieval and generation continuously enhance each other.</p><p>Trey uses a three context framework for search architecture:</p><ul><li>Content Context: Traditional document understanding and retrieval</li><li>User Context: Behavioral signals driving personalization and recommendations</li><li>Domain Context: Knowledge graphs and semantic understanding</li></ul><p>Trey shares insights on:</p><ul><li>Why collecting and properly using user behavior signals is crucial yet often overlooked</li><li>How to implement "light touch" personalization without trapping users in filter bubbles</li><li>The evolution from simple vector similarity to sophisticated late interaction models</li><li>Why treating search as a non-linear pipeline with feedback loops leads to better results</li></ul><p>For engineers building search systems, Trey offers practical advice on choosing the right tools and techniques, from traditional search engines like Solr and Elasticsearch to modern approaches like ColBERT.</p><p>Also how to layer different techniques to make search tunable and debuggable.</p><p><strong>Quotes:</strong></p><ul><li><em>"I think of whether it's search or generative AI, I think of all of these systems as nonlinear pipelines."</em></li><li><em>"The reason we use retrieval when we're working with generative AI is because A generative AI model these LLMs will take your query, your request, whatever you're asking for. They will then try to interpret them and without access to up to date information, without access to correct information, they will generate a response from their highly compressed understanding of the world. And so we use retrieval to augment them with information."</em></li><li><em>"I think the misconception is that, oh, hey, for RAG I can just, plug in a vector database and a couple of libraries and, a day or two later everything's magically working and I'm off to solve the next problem. Because search and information retrieval is one of those problems that you never really solve. You get it, good enough and quit, or you find so much value in it, you just continue investing to constantly make it better."</em></li><li><em>"To me, they're, search and recommendations are fundamentally the same problem. They're just using different contexts."</em></li><li><em>"Anytime you're building a search system, whether it's traditional search, whether it's RAG for generative AI, you need to have all three of those contexts in order to effectively get the most relevant results to solve solve the problem."</em></li><li><em>"There's no better way to make your users really angry with you than to stick them in a bucket and get them stuck in that bucket, which is not their actual intent."</em></li></ul><p><strong>Trey Grainger:</strong></p><ul><li><a href="https://www.linkedin.com/in/treygrainger/">LinkedIn</a></li><li><a href="https://community.aipoweredsearch.com/">AI Powered Search (Community)</a></li><li><a href="https://www.manning.com/books/ai-powered-search?a_aid=1&amp;a_bid=e47ada24&amp;chan=aips">AI Powered Search (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Challenges 00:50 Layered Approach to Ranking 01:00 Personalization and Signal Boosting 02:25 Broader Principles in Software Engineering 02:51 Interview with Trey Greinger 03:32 Understanding RAG and Retrieval 04:35 Nonlinear Pipelines in Search 06:01 Generative AI and Retrieval 08:10 Search Renaissance and AI 10:27 Misconceptions in AI-Powered Search 18:12 Search vs. Recommendation Systems 22:26 Three Buckets of Relevance 38:19 Traditional Learning to Rank 39:11 Semantic Relevance and User Behavior 39:53 Layered Ranking Algorithms 41:40 Personalization in Search 43:44 Technological Setup for Query Understanding 48:21 Personalization and User Behavior Vectors 52:10 Choosing the Right Search Engine 56:35 Future of AI-Powered Search 01:00:48 Building Effective Search Applications 01:06:50 Three Critical Context Frameworks 01:12:08 Modern Search Systems and Contextual Understanding 01:13:37 Conclusion and Recommendations</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today, I (Nicolay Gerold) sit down with Trey Grainger, author of the book AI-Powered Search. We discuss the different techniques for search and recommendations and how to combine them.</p><p>While RAG (Retrieval-Augmented Generation) has become a buzzword in AI, Trey argues that the current understanding of "RAG" is overly simplified ‚Äì it's actually a bidirectional process he calls "GARRAG," where retrieval and generation continuously enhance each other.</p><p>Trey uses a three context framework for search architecture:</p><ul><li>Content Context: Traditional document understanding and retrieval</li><li>User Context: Behavioral signals driving personalization and recommendations</li><li>Domain Context: Knowledge graphs and semantic understanding</li></ul><p>Trey shares insights on:</p><ul><li>Why collecting and properly using user behavior signals is crucial yet often overlooked</li><li>How to implement "light touch" personalization without trapping users in filter bubbles</li><li>The evolution from simple vector similarity to sophisticated late interaction models</li><li>Why treating search as a non-linear pipeline with feedback loops leads to better results</li></ul><p>For engineers building search systems, Trey offers practical advice on choosing the right tools and techniques, from traditional search engines like Solr and Elasticsearch to modern approaches like ColBERT.</p><p>Also how to layer different techniques to make search tunable and debuggable.</p><p><strong>Quotes:</strong></p><ul><li><em>"I think of whether it's search or generative AI, I think of all of these systems as nonlinear pipelines."</em></li><li><em>"The reason we use retrieval when we're working with generative AI is because A generative AI model these LLMs will take your query, your request, whatever you're asking for. They will then try to interpret them and without access to up to date information, without access to correct information, they will generate a response from their highly compressed understanding of the world. And so we use retrieval to augment them with information."</em></li><li><em>"I think the misconception is that, oh, hey, for RAG I can just, plug in a vector database and a couple of libraries and, a day or two later everything's magically working and I'm off to solve the next problem. Because search and information retrieval is one of those problems that you never really solve. You get it, good enough and quit, or you find so much value in it, you just continue investing to constantly make it better."</em></li><li><em>"To me, they're, search and recommendations are fundamentally the same problem. They're just using different contexts."</em></li><li><em>"Anytime you're building a search system, whether it's traditional search, whether it's RAG for generative AI, you need to have all three of those contexts in order to effectively get the most relevant results to solve solve the problem."</em></li><li><em>"There's no better way to make your users really angry with you than to stick them in a bucket and get them stuck in that bucket, which is not their actual intent."</em></li></ul><p><strong>Trey Grainger:</strong></p><ul><li><a href="https://www.linkedin.com/in/treygrainger/">LinkedIn</a></li><li><a href="https://community.aipoweredsearch.com/">AI Powered Search (Community)</a></li><li><a href="https://www.manning.com/books/ai-powered-search?a_aid=1&amp;a_bid=e47ada24&amp;chan=aips">AI Powered Search (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Challenges 00:50 Layered Approach to Ranking 01:00 Personalization and Signal Boosting 02:25 Broader Principles in Software Engineering 02:51 Interview with Trey Greinger 03:32 Understanding RAG and Retrieval 04:35 Nonlinear Pipelines in Search 06:01 Generative AI and Retrieval 08:10 Search Renaissance and AI 10:27 Misconceptions in AI-Powered Search 18:12 Search vs. Recommendation Systems 22:26 Three Buckets of Relevance 38:19 Traditional Learning to Rank 39:11 Semantic Relevance and User Behavior 39:53 Layered Ranking Algorithms 41:40 Personalization in Search 43:44 Technological Setup for Query Understanding 48:21 Personalization and User Behavior Vectors 52:10 Choosing the Right Search Engine 56:35 Future of AI-Powered Search 01:00:48 Building Effective Search Applications 01:06:50 Three Critical Context Frameworks 01:12:08 Modern Search Systems and Contextual Understanding 01:13:37 Conclusion and Recommendations</p>]]>
      </content:encoded>
      <pubDate>Thu, 09 Jan 2025 08:39:07 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/38d05034/65fdc190.mp3" length="71459839" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/ZRB_gxbnNITfdOU5-Mn4NE6jcsXaIbl3wvwR8zIT0Ew/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8wYTRh/NGE5MTczZTRlN2Mx/ZjNmZDc5ZGUxNjc0/MmViZC5wbmc.jpg"/>
      <itunes:duration>4464</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today, I (Nicolay Gerold) sit down with Trey Grainger, author of the book AI-Powered Search. We discuss the different techniques for search and recommendations and how to combine them.</p><p>While RAG (Retrieval-Augmented Generation) has become a buzzword in AI, Trey argues that the current understanding of "RAG" is overly simplified ‚Äì it's actually a bidirectional process he calls "GARRAG," where retrieval and generation continuously enhance each other.</p><p>Trey uses a three context framework for search architecture:</p><ul><li>Content Context: Traditional document understanding and retrieval</li><li>User Context: Behavioral signals driving personalization and recommendations</li><li>Domain Context: Knowledge graphs and semantic understanding</li></ul><p>Trey shares insights on:</p><ul><li>Why collecting and properly using user behavior signals is crucial yet often overlooked</li><li>How to implement "light touch" personalization without trapping users in filter bubbles</li><li>The evolution from simple vector similarity to sophisticated late interaction models</li><li>Why treating search as a non-linear pipeline with feedback loops leads to better results</li></ul><p>For engineers building search systems, Trey offers practical advice on choosing the right tools and techniques, from traditional search engines like Solr and Elasticsearch to modern approaches like ColBERT.</p><p>Also how to layer different techniques to make search tunable and debuggable.</p><p><strong>Quotes:</strong></p><ul><li><em>"I think of whether it's search or generative AI, I think of all of these systems as nonlinear pipelines."</em></li><li><em>"The reason we use retrieval when we're working with generative AI is because A generative AI model these LLMs will take your query, your request, whatever you're asking for. They will then try to interpret them and without access to up to date information, without access to correct information, they will generate a response from their highly compressed understanding of the world. And so we use retrieval to augment them with information."</em></li><li><em>"I think the misconception is that, oh, hey, for RAG I can just, plug in a vector database and a couple of libraries and, a day or two later everything's magically working and I'm off to solve the next problem. Because search and information retrieval is one of those problems that you never really solve. You get it, good enough and quit, or you find so much value in it, you just continue investing to constantly make it better."</em></li><li><em>"To me, they're, search and recommendations are fundamentally the same problem. They're just using different contexts."</em></li><li><em>"Anytime you're building a search system, whether it's traditional search, whether it's RAG for generative AI, you need to have all three of those contexts in order to effectively get the most relevant results to solve solve the problem."</em></li><li><em>"There's no better way to make your users really angry with you than to stick them in a bucket and get them stuck in that bucket, which is not their actual intent."</em></li></ul><p><strong>Trey Grainger:</strong></p><ul><li><a href="https://www.linkedin.com/in/treygrainger/">LinkedIn</a></li><li><a href="https://community.aipoweredsearch.com/">AI Powered Search (Community)</a></li><li><a href="https://www.manning.com/books/ai-powered-search?a_aid=1&amp;a_bid=e47ada24&amp;chan=aips">AI Powered Search (Book)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Challenges 00:50 Layered Approach to Ranking 01:00 Personalization and Signal Boosting 02:25 Broader Principles in Software Engineering 02:51 Interview with Trey Greinger 03:32 Understanding RAG and Retrieval 04:35 Nonlinear Pipelines in Search 06:01 Generative AI and Retrieval 08:10 Search Renaissance and AI 10:27 Misconceptions in AI-Powered Search 18:12 Search vs. Recommendation Systems 22:26 Three Buckets of Relevance 38:19 Traditional Learning to Rank 39:11 Semantic Relevance and User Behavior 39:53 Layered Ranking Algorithms 41:40 Personalization in Search 43:44 Technological Setup for Query Understanding 48:21 Personalization and User Behavior Vectors 52:10 Choosing the Right Search Engine 56:35 Future of AI-Powered Search 01:00:48 Building Effective Search Applications 01:06:50 Three Critical Context Frameworks 01:12:08 Modern Search Systems and Contextual Understanding 01:13:37 Conclusion and Recommendations</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, llm, rag, recsys, recommendations</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/38d05034/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/38d05034/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#037 Chunking for RAG: Stop Breaking Your Documents Into Meaningless Pieces</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>20</itunes:episode>
      <podcast:episode>20</podcast:episode>
      <itunes:title>#037 Chunking for RAG: Stop Breaking Your Documents Into Meaningless Pieces</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">fd47f91e-9c47-4d93-bd68-40d7a61ad342</guid>
      <link>https://share.transistor.fm/s/3fc28b22</link>
      <description>
        <![CDATA[<p>Today we are back continuing our series on search. We are talking to Brandon Smith, about his work for Chroma. He led one of the largest studies in the field on different chunking techniques. So today we will look at how we can unfuck our RAG systems from badly chosen chunking hyperparameters.</p><p>The biggest lie in RAG is that semantic search is simple. The reality is that it's easy to build, it's easy to get up and running, but it's really hard to get right. And if you don't have a good setup, it's near impossible to debug. One of the reasons it's really hard is actually chunking. And there are a lot of things you can get wrong.</p><p>And even OpenAI boggled it a little bit, in my opinion, using an 800 token length for the chunks. And this might work for legal, where you have a lot of boilerplate that carries little semantic meaning, but often you have the opposite. You have very information dense content and imagine fitting an entire Wikipedia page into the size of a tweet There will be a lot of information that's actually lost and that's what happens with long chunks The next is overlap openai uses a foreign token overlap or used to And what this does is actually we try to bring the important context into the chunk, but in reality, we don't really know where the context is coming from.</p><p>It could be from a few pages prior, not just the 400 tokens before. It could also be from a definition that's not even in the document at all. There is a really interesting solution actually from Anthropic Contextual Retrieval, where you basically pre process all the chunks to see whether there is any missing information and you basically try to reintroduce it.</p><p><strong>Brandon Smith:</strong></p><ul><li><a href="https://www.linkedin.com/in/brandon-abreu-smith/">LinkedIn</a></li><li><a href="https://x.com/brandonstarxel">X (Twitter)</a></li><li><a href="https://brandonsmith.co.uk/">Website</a></li><li><a href="https://research.trychroma.com/evaluating-chunking">Chunking Article</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://nicolay.fyi/">Website</a></li></ul><p>00:00 The Biggest Lie in RAG: Semantic Search Simplified 00:43 Challenges in Chunking and Overlap 01:38 Introducing Brandon Smith and His Research 02:05 The Motivation and Mechanics of Chunking 04:40 Issues with Current Chunking Methods 07:04 Optimizing Chunking Strategies 23:04 Introduction to Chunk Overlap 24:23 Exploring LLM-Based Chunking 24:56 Challenges with Initial Approaches 28:17 Alternative Chunking Methods 36:13 Language-Specific Considerations 38:41 Future Directions and Best Practices</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today we are back continuing our series on search. We are talking to Brandon Smith, about his work for Chroma. He led one of the largest studies in the field on different chunking techniques. So today we will look at how we can unfuck our RAG systems from badly chosen chunking hyperparameters.</p><p>The biggest lie in RAG is that semantic search is simple. The reality is that it's easy to build, it's easy to get up and running, but it's really hard to get right. And if you don't have a good setup, it's near impossible to debug. One of the reasons it's really hard is actually chunking. And there are a lot of things you can get wrong.</p><p>And even OpenAI boggled it a little bit, in my opinion, using an 800 token length for the chunks. And this might work for legal, where you have a lot of boilerplate that carries little semantic meaning, but often you have the opposite. You have very information dense content and imagine fitting an entire Wikipedia page into the size of a tweet There will be a lot of information that's actually lost and that's what happens with long chunks The next is overlap openai uses a foreign token overlap or used to And what this does is actually we try to bring the important context into the chunk, but in reality, we don't really know where the context is coming from.</p><p>It could be from a few pages prior, not just the 400 tokens before. It could also be from a definition that's not even in the document at all. There is a really interesting solution actually from Anthropic Contextual Retrieval, where you basically pre process all the chunks to see whether there is any missing information and you basically try to reintroduce it.</p><p><strong>Brandon Smith:</strong></p><ul><li><a href="https://www.linkedin.com/in/brandon-abreu-smith/">LinkedIn</a></li><li><a href="https://x.com/brandonstarxel">X (Twitter)</a></li><li><a href="https://brandonsmith.co.uk/">Website</a></li><li><a href="https://research.trychroma.com/evaluating-chunking">Chunking Article</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://nicolay.fyi/">Website</a></li></ul><p>00:00 The Biggest Lie in RAG: Semantic Search Simplified 00:43 Challenges in Chunking and Overlap 01:38 Introducing Brandon Smith and His Research 02:05 The Motivation and Mechanics of Chunking 04:40 Issues with Current Chunking Methods 07:04 Optimizing Chunking Strategies 23:04 Introduction to Chunk Overlap 24:23 Exploring LLM-Based Chunking 24:56 Challenges with Initial Approaches 28:17 Alternative Chunking Methods 36:13 Language-Specific Considerations 38:41 Future Directions and Best Practices</p>]]>
      </content:encoded>
      <pubDate>Fri, 03 Jan 2025 05:16:14 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/3fc28b22/37696521.mp3" length="47289191" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/dWN8Ckw2HlYEsjLqDE_UeG0aMKBxJi2cdj0UBLK15kY/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS81YmRj/ZDA4ZDUyNzY1NzE2/Mjk1OWU3MmY5MzU3/YmQzNC5wbmc.jpg"/>
      <itunes:duration>2953</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today we are back continuing our series on search. We are talking to Brandon Smith, about his work for Chroma. He led one of the largest studies in the field on different chunking techniques. So today we will look at how we can unfuck our RAG systems from badly chosen chunking hyperparameters.</p><p>The biggest lie in RAG is that semantic search is simple. The reality is that it's easy to build, it's easy to get up and running, but it's really hard to get right. And if you don't have a good setup, it's near impossible to debug. One of the reasons it's really hard is actually chunking. And there are a lot of things you can get wrong.</p><p>And even OpenAI boggled it a little bit, in my opinion, using an 800 token length for the chunks. And this might work for legal, where you have a lot of boilerplate that carries little semantic meaning, but often you have the opposite. You have very information dense content and imagine fitting an entire Wikipedia page into the size of a tweet There will be a lot of information that's actually lost and that's what happens with long chunks The next is overlap openai uses a foreign token overlap or used to And what this does is actually we try to bring the important context into the chunk, but in reality, we don't really know where the context is coming from.</p><p>It could be from a few pages prior, not just the 400 tokens before. It could also be from a definition that's not even in the document at all. There is a really interesting solution actually from Anthropic Contextual Retrieval, where you basically pre process all the chunks to see whether there is any missing information and you basically try to reintroduce it.</p><p><strong>Brandon Smith:</strong></p><ul><li><a href="https://www.linkedin.com/in/brandon-abreu-smith/">LinkedIn</a></li><li><a href="https://x.com/brandonstarxel">X (Twitter)</a></li><li><a href="https://brandonsmith.co.uk/">Website</a></li><li><a href="https://research.trychroma.com/evaluating-chunking">Chunking Article</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://nicolay.fyi/">Website</a></li></ul><p>00:00 The Biggest Lie in RAG: Semantic Search Simplified 00:43 Challenges in Chunking and Overlap 01:38 Introducing Brandon Smith and His Research 02:05 The Motivation and Mechanics of Chunking 04:40 Issues with Current Chunking Methods 07:04 Optimizing Chunking Strategies 23:04 Introduction to Chunk Overlap 24:23 Exploring LLM-Based Chunking 24:56 Challenges with Initial Approaches 28:17 Alternative Chunking Methods 36:13 Language-Specific Considerations 38:41 Future Directions and Best Practices</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/3fc28b22/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/3fc28b22/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#036 How AI Can Start Teaching Itself - Synthetic Data Deep Dive</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>19</itunes:episode>
      <podcast:episode>19</podcast:episode>
      <itunes:title>#036 How AI Can Start Teaching Itself - Synthetic Data Deep Dive</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">75bba2e4-5a41-4117-8f09-041708e6cdc9</guid>
      <link>https://share.transistor.fm/s/01a06f55</link>
      <description>
        <![CDATA[<p>Most LLMs you use today already use synthetic data.</p><p>It‚Äôs not a thing of the future.</p><p>The large labs use a large model (e.g. gpt-4o) to generate training data for a smaller one (gpt-4o-mini).</p><p>This lets you build fast, cheap models that do one thing well.</p><p>This is ‚Äúdistillation‚Äù.</p><p>But the vision for synthetic data is much bigger.</p><p>Enable people to train specialized AI systems without having a lot of training data.</p><p>Today we are talking to Adrien Morisot, an ML engineer at Cohere.</p><p>We talk about how Cohere uses synthetic data to train their models, their learnings, and how you can use synthetic data in your training.</p><p>We are slightly diverging from our search focus, but I wanted to create a deeper dive into synthetic data after our episode with Saahil.</p><p>You could use it in a lot of places: generate hard negatives, generate training samples for classifiers and rerankers and much more.</p><p>Scaling Synthetic Data Creation: <a href="https://arxiv.org/abs/2406.20094">https://arxiv.org/abs/2406.20094</a></p><p><strong>Adrien Morisot:</strong></p><ul><li><a href="https://www.linkedin.com/in/baedrien/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://x.com/adrien_morisot">X (Twitter)</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Synthetic Data in LLMs 00:18 Distillation and Specialized AI Systems 00:39 Interview with Adrien Morisot 02:00 Early Challenges with Synthetic Data 02:36 Breakthroughs and Rediscovery 03:54 The Evolution of AI and Synthetic Data 07:51 Data Harvesting and Internet Scraping 09:28 Generating Diverse Synthetic Data 15:37 Manual Review and Quality Control 17:28 Automating Data Evaluation 18:54 Fine-Tuning Models with Synthetic Data 21:45 Avoiding Behavioral Cloning 23:47 Ensuring Model Accuracy with Verification 24:31 Adapting Models to Specific Domains 26:41 Challenges in Financial and Legal Domains 28:10 Improving Synthetic Data Sets 30:45 Evaluating Model Performance 32:21 Using LLMs as Judges 35:42 Practical Tips for AI Practitioners 41:26 Synthetic Data in Training Processes 43:51 Quality Control in Synthetic Data 45:41 Domain Adaptation Strategies 46:51 Future of Synthetic Data Generation 47:30 Conclusion and Next Steps</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Most LLMs you use today already use synthetic data.</p><p>It‚Äôs not a thing of the future.</p><p>The large labs use a large model (e.g. gpt-4o) to generate training data for a smaller one (gpt-4o-mini).</p><p>This lets you build fast, cheap models that do one thing well.</p><p>This is ‚Äúdistillation‚Äù.</p><p>But the vision for synthetic data is much bigger.</p><p>Enable people to train specialized AI systems without having a lot of training data.</p><p>Today we are talking to Adrien Morisot, an ML engineer at Cohere.</p><p>We talk about how Cohere uses synthetic data to train their models, their learnings, and how you can use synthetic data in your training.</p><p>We are slightly diverging from our search focus, but I wanted to create a deeper dive into synthetic data after our episode with Saahil.</p><p>You could use it in a lot of places: generate hard negatives, generate training samples for classifiers and rerankers and much more.</p><p>Scaling Synthetic Data Creation: <a href="https://arxiv.org/abs/2406.20094">https://arxiv.org/abs/2406.20094</a></p><p><strong>Adrien Morisot:</strong></p><ul><li><a href="https://www.linkedin.com/in/baedrien/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://x.com/adrien_morisot">X (Twitter)</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Synthetic Data in LLMs 00:18 Distillation and Specialized AI Systems 00:39 Interview with Adrien Morisot 02:00 Early Challenges with Synthetic Data 02:36 Breakthroughs and Rediscovery 03:54 The Evolution of AI and Synthetic Data 07:51 Data Harvesting and Internet Scraping 09:28 Generating Diverse Synthetic Data 15:37 Manual Review and Quality Control 17:28 Automating Data Evaluation 18:54 Fine-Tuning Models with Synthetic Data 21:45 Avoiding Behavioral Cloning 23:47 Ensuring Model Accuracy with Verification 24:31 Adapting Models to Specific Domains 26:41 Challenges in Financial and Legal Domains 28:10 Improving Synthetic Data Sets 30:45 Evaluating Model Performance 32:21 Using LLMs as Judges 35:42 Practical Tips for AI Practitioners 41:26 Synthetic Data in Training Processes 43:51 Quality Control in Synthetic Data 45:41 Domain Adaptation Strategies 46:51 Future of Synthetic Data Generation 47:30 Conclusion and Next Steps</p>]]>
      </content:encoded>
      <pubDate>Thu, 19 Dec 2024 07:01:13 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/01a06f55/fbc21045.mp3" length="46297413" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/ovtW9uAzgnD3-2HiXIpeyEUFdUjRSIaMbxedu_t7fYc/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9iZTgw/M2M5OGYxZWI0NmQ2/MTZjMmFmZTg0MDE5/MTEwMS5wbmc.jpg"/>
      <itunes:duration>2891</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Most LLMs you use today already use synthetic data.</p><p>It‚Äôs not a thing of the future.</p><p>The large labs use a large model (e.g. gpt-4o) to generate training data for a smaller one (gpt-4o-mini).</p><p>This lets you build fast, cheap models that do one thing well.</p><p>This is ‚Äúdistillation‚Äù.</p><p>But the vision for synthetic data is much bigger.</p><p>Enable people to train specialized AI systems without having a lot of training data.</p><p>Today we are talking to Adrien Morisot, an ML engineer at Cohere.</p><p>We talk about how Cohere uses synthetic data to train their models, their learnings, and how you can use synthetic data in your training.</p><p>We are slightly diverging from our search focus, but I wanted to create a deeper dive into synthetic data after our episode with Saahil.</p><p>You could use it in a lot of places: generate hard negatives, generate training samples for classifiers and rerankers and much more.</p><p>Scaling Synthetic Data Creation: <a href="https://arxiv.org/abs/2406.20094">https://arxiv.org/abs/2406.20094</a></p><p><strong>Adrien Morisot:</strong></p><ul><li><a href="https://www.linkedin.com/in/baedrien/?originalSubdomain=ca">LinkedIn</a></li><li><a href="https://x.com/adrien_morisot">X (Twitter)</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Synthetic Data in LLMs 00:18 Distillation and Specialized AI Systems 00:39 Interview with Adrien Morisot 02:00 Early Challenges with Synthetic Data 02:36 Breakthroughs and Rediscovery 03:54 The Evolution of AI and Synthetic Data 07:51 Data Harvesting and Internet Scraping 09:28 Generating Diverse Synthetic Data 15:37 Manual Review and Quality Control 17:28 Automating Data Evaluation 18:54 Fine-Tuning Models with Synthetic Data 21:45 Avoiding Behavioral Cloning 23:47 Ensuring Model Accuracy with Verification 24:31 Adapting Models to Specific Domains 26:41 Challenges in Financial and Legal Domains 28:10 Improving Synthetic Data Sets 30:45 Evaluating Model Performance 32:21 Using LLMs as Judges 35:42 Practical Tips for AI Practitioners 41:26 Synthetic Data in Training Processes 43:51 Quality Control in Synthetic Data 45:41 Domain Adaptation Strategies 46:51 Future of Synthetic Data Generation 47:30 Conclusion and Next Steps</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/01a06f55/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/01a06f55/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#035 A Search System That Learns As You Use It (Agentic RAG)</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>18</itunes:episode>
      <podcast:episode>18</podcast:episode>
      <itunes:title>#035 A Search System That Learns As You Use It (Agentic RAG)</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">44554d5b-9028-4a89-b1cf-bf518b62220d</guid>
      <link>https://share.transistor.fm/s/58e82e25</link>
      <description>
        <![CDATA[<p>Modern RAG systems build on flexibility.</p><p>At their core, they match each query with the best tool for the job.</p><p>They know which tool fits each task. When you ask about sales numbers, they reach for SQL. When you need to company policies, they use vector search or BM25. The key is switching tools smoothly.</p><p>A question about sales figures might need SQL, while a search through policy documents works better with vector search. The key is building systems that can switch between these tools smoothly.</p><p>But all types of retrieval start with metadata. By tagging documents with key details during processing, we narrow the search space before diving in.</p><p>The best systems use a mix of approaches: they might keep full documents for context, summaries for quick scanning, and metadata for filtering. They cast a wide net at first, then use neural ranking to zero in on the most relevant results.</p><p>The quality of embeddings can make or break a system. General-purpose models often fall short in specialized fields. Testing different embedding models on your specific data pays off - what works for general text might fail for legal documents or technical manuals. Sometimes, fine-tuning a model for your domain is worth the effort.</p><p>When building search systems, think modular. Start with pieces that can be swapped out as needs change or better tools emerge. Add metadata processing early - it's harder to add later. Break the retrieval process into steps: first find possible matches quickly, then rank them carefully. For complex documents with tables or images, add tools that can handle different types of content.</p><p>The best systems also check their work. They ask: "Did I actually answer the question?" If not, they try a different approach. But they also know when to stop - endless loops help no one. In the end, RAG isn't just about finding information. It's about finding the right information, in the right way, at the right time.</p><p><strong>Stephen Batifol:</strong></p><ul><li><a href="https://x.com/stephenbtl">X (Twitter)</a></li><li><a href="https://zilliz.com/authors/Stephen_Batifol">Zilliz</a></li><li><a href="https://www.linkedin.com/in/stephen-batifol/?originalSubdomain=de">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Agentic RAG 00:04 Understanding Control Flow in Agentic RAG 00:33 Decision Making with LLMs 01:11 Exploring Agentic RAG with Stephen Batifol 03:35 Comparing RAG and GAR 06:31 Implementing Agentic RAG Workflows 22:36 Filtering with Prefix, Suffix, and Midfix 24:15 Breaking Mechanisms in Workflows 28:00 Evaluating Agentic Workflows 30:31 Multimodal and VLLMs in Document Processing 33:51 Challenges and Innovations in Parsing 34:51 Overrated and Underrated Aspects in LLMs 39:52 Building Effective Search Applications</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Modern RAG systems build on flexibility.</p><p>At their core, they match each query with the best tool for the job.</p><p>They know which tool fits each task. When you ask about sales numbers, they reach for SQL. When you need to company policies, they use vector search or BM25. The key is switching tools smoothly.</p><p>A question about sales figures might need SQL, while a search through policy documents works better with vector search. The key is building systems that can switch between these tools smoothly.</p><p>But all types of retrieval start with metadata. By tagging documents with key details during processing, we narrow the search space before diving in.</p><p>The best systems use a mix of approaches: they might keep full documents for context, summaries for quick scanning, and metadata for filtering. They cast a wide net at first, then use neural ranking to zero in on the most relevant results.</p><p>The quality of embeddings can make or break a system. General-purpose models often fall short in specialized fields. Testing different embedding models on your specific data pays off - what works for general text might fail for legal documents or technical manuals. Sometimes, fine-tuning a model for your domain is worth the effort.</p><p>When building search systems, think modular. Start with pieces that can be swapped out as needs change or better tools emerge. Add metadata processing early - it's harder to add later. Break the retrieval process into steps: first find possible matches quickly, then rank them carefully. For complex documents with tables or images, add tools that can handle different types of content.</p><p>The best systems also check their work. They ask: "Did I actually answer the question?" If not, they try a different approach. But they also know when to stop - endless loops help no one. In the end, RAG isn't just about finding information. It's about finding the right information, in the right way, at the right time.</p><p><strong>Stephen Batifol:</strong></p><ul><li><a href="https://x.com/stephenbtl">X (Twitter)</a></li><li><a href="https://zilliz.com/authors/Stephen_Batifol">Zilliz</a></li><li><a href="https://www.linkedin.com/in/stephen-batifol/?originalSubdomain=de">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Agentic RAG 00:04 Understanding Control Flow in Agentic RAG 00:33 Decision Making with LLMs 01:11 Exploring Agentic RAG with Stephen Batifol 03:35 Comparing RAG and GAR 06:31 Implementing Agentic RAG Workflows 22:36 Filtering with Prefix, Suffix, and Midfix 24:15 Breaking Mechanisms in Workflows 28:00 Evaluating Agentic Workflows 30:31 Multimodal and VLLMs in Document Processing 33:51 Challenges and Innovations in Parsing 34:51 Overrated and Underrated Aspects in LLMs 39:52 Building Effective Search Applications</p>]]>
      </content:encoded>
      <pubDate>Fri, 13 Dec 2024 06:45:20 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/58e82e25/88241ec5.mp3" length="43722361" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/7Ies8DgaH4_TA_VBkj9_-4rVxN9IIbPqmvXV-nyCAQc/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mZTJh/MzliMDFkMDdkM2E0/YTE5MWU0YmFiMDQy/NzkzZS5wbmc.jpg"/>
      <itunes:duration>2730</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Modern RAG systems build on flexibility.</p><p>At their core, they match each query with the best tool for the job.</p><p>They know which tool fits each task. When you ask about sales numbers, they reach for SQL. When you need to company policies, they use vector search or BM25. The key is switching tools smoothly.</p><p>A question about sales figures might need SQL, while a search through policy documents works better with vector search. The key is building systems that can switch between these tools smoothly.</p><p>But all types of retrieval start with metadata. By tagging documents with key details during processing, we narrow the search space before diving in.</p><p>The best systems use a mix of approaches: they might keep full documents for context, summaries for quick scanning, and metadata for filtering. They cast a wide net at first, then use neural ranking to zero in on the most relevant results.</p><p>The quality of embeddings can make or break a system. General-purpose models often fall short in specialized fields. Testing different embedding models on your specific data pays off - what works for general text might fail for legal documents or technical manuals. Sometimes, fine-tuning a model for your domain is worth the effort.</p><p>When building search systems, think modular. Start with pieces that can be swapped out as needs change or better tools emerge. Add metadata processing early - it's harder to add later. Break the retrieval process into steps: first find possible matches quickly, then rank them carefully. For complex documents with tables or images, add tools that can handle different types of content.</p><p>The best systems also check their work. They ask: "Did I actually answer the question?" If not, they try a different approach. But they also know when to stop - endless loops help no one. In the end, RAG isn't just about finding information. It's about finding the right information, in the right way, at the right time.</p><p><strong>Stephen Batifol:</strong></p><ul><li><a href="https://x.com/stephenbtl">X (Twitter)</a></li><li><a href="https://zilliz.com/authors/Stephen_Batifol">Zilliz</a></li><li><a href="https://www.linkedin.com/in/stephen-batifol/?originalSubdomain=de">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Agentic RAG 00:04 Understanding Control Flow in Agentic RAG 00:33 Decision Making with LLMs 01:11 Exploring Agentic RAG with Stephen Batifol 03:35 Comparing RAG and GAR 06:31 Implementing Agentic RAG Workflows 22:36 Filtering with Prefix, Suffix, and Midfix 24:15 Breaking Mechanisms in Workflows 28:00 Evaluating Agentic Workflows 30:31 Multimodal and VLLMs in Document Processing 33:51 Challenges and Innovations in Parsing 34:51 Overrated and Underrated Aspects in LLMs 39:52 Building Effective Search Applications</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, agent</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/58e82e25/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/58e82e25/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#034 Rethinking Search Inside Postgres, From Lexemes to BM25 </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>17</itunes:episode>
      <podcast:episode>17</podcast:episode>
      <itunes:title>#034 Rethinking Search Inside Postgres, From Lexemes to BM25 </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">241753b1-2fe5-45e1-89b7-f988a61075f8</guid>
      <link>https://share.transistor.fm/s/a6e22dc4</link>
      <description>
        <![CDATA[<p>Many companies use Elastic or OpenSearch and use 10% of the capacity.</p><p>They have to build ETL pipelines.</p><p>Get data Normalized.</p><p>Worry about race conditions.</p><p>All in all. At the moment, when you want to do search on top of your transactional data, you are forced to build a distributed systems.</p><p>Not anymore.</p><p>ParadeDB is building an open-source PostgreSQL extension to enable search within your database.</p><p>Today, I am talking to Philippe No√´l, the founder and CEO of ParadeDB.</p><p>We talk about how they build it, how they integrate into the Postgres Query engines, and how you can build search on top of Postgres.</p><p><strong>Key Insights:</strong></p><p>Search is changing. We're moving from separate search clusters to search inside databases. Simpler architecture, stronger guarantees, lower costs up to a certain scale.</p><p>Most search engines force you to duplicate data. ParadeDB doesn't. You keep data normalized and join at query time. It hooks deep into Postgres's query planner. It doesn't just bolt on search - it lets Postgres optimize search queries alongside SQL ones.</p><p>Search indices can work with ACID. ParadeDB's BM25 index keeps Lucene-style components (term frequency, normalization) but adds Postgres metadata for transactions. Search + ACID is possible.</p><p>Two storage types matter: inverted indices for text, columnar "fast fields" for analytics. Pick the right one or queries get slow. Integers now default to columnar to prevent common mistakes.</p><p>Mixing query engines looks tempting but fails. The team tried using DuckDB and DataFusion inside Postgres. Both were fast but broke ACID compliance. They had to rebuild features natively.</p><p><strong>Philippe No√´l:</strong></p><ul><li><a href="https://www.linkedin.com/in/philippemnoel/">LinkedIn</a></li><li><a href="https://bsky.app/profile/philippemnoel.bsky.social">Bluesky</a></li><li><a href="https://www.paradedb.com/">ParadeDB</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to ParadeDB 00:53 Building ParadeDB with Rust 01:43 Integrating Search in Postgres 03:04 ParadeDB vs. Elastic 05:48 Technical Deep Dive: Postgres Integration 07:27 Challenges and Solutions 09:35 Transactional Safety and Performance 11:06 Composable Data Systems 15:26 Columnar Storage and Analytics 20:54 Case Study: Alibaba Cloud 21:57 Data Warehouse Context 23:24 Custom Indexing with BM25 24:01 Postgres Indexing Overview 24:17 Fast Fields and Columnar Format 24:52 Lucene Inspiration and Data Storage 26:06 Setting Up and Managing Indexes 27:43 Query Building and Complex Searches 30:21 Scaling and Sharding Strategies 35:27 Query Optimization and Common Mistakes 38:39 Future Developments and Integrations 39:24 Building a Full-Fledged Search Application 42:53 Challenges and Advantages of Using ParadeDB 46:43 Final Thoughts and Recommendations</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Many companies use Elastic or OpenSearch and use 10% of the capacity.</p><p>They have to build ETL pipelines.</p><p>Get data Normalized.</p><p>Worry about race conditions.</p><p>All in all. At the moment, when you want to do search on top of your transactional data, you are forced to build a distributed systems.</p><p>Not anymore.</p><p>ParadeDB is building an open-source PostgreSQL extension to enable search within your database.</p><p>Today, I am talking to Philippe No√´l, the founder and CEO of ParadeDB.</p><p>We talk about how they build it, how they integrate into the Postgres Query engines, and how you can build search on top of Postgres.</p><p><strong>Key Insights:</strong></p><p>Search is changing. We're moving from separate search clusters to search inside databases. Simpler architecture, stronger guarantees, lower costs up to a certain scale.</p><p>Most search engines force you to duplicate data. ParadeDB doesn't. You keep data normalized and join at query time. It hooks deep into Postgres's query planner. It doesn't just bolt on search - it lets Postgres optimize search queries alongside SQL ones.</p><p>Search indices can work with ACID. ParadeDB's BM25 index keeps Lucene-style components (term frequency, normalization) but adds Postgres metadata for transactions. Search + ACID is possible.</p><p>Two storage types matter: inverted indices for text, columnar "fast fields" for analytics. Pick the right one or queries get slow. Integers now default to columnar to prevent common mistakes.</p><p>Mixing query engines looks tempting but fails. The team tried using DuckDB and DataFusion inside Postgres. Both were fast but broke ACID compliance. They had to rebuild features natively.</p><p><strong>Philippe No√´l:</strong></p><ul><li><a href="https://www.linkedin.com/in/philippemnoel/">LinkedIn</a></li><li><a href="https://bsky.app/profile/philippemnoel.bsky.social">Bluesky</a></li><li><a href="https://www.paradedb.com/">ParadeDB</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to ParadeDB 00:53 Building ParadeDB with Rust 01:43 Integrating Search in Postgres 03:04 ParadeDB vs. Elastic 05:48 Technical Deep Dive: Postgres Integration 07:27 Challenges and Solutions 09:35 Transactional Safety and Performance 11:06 Composable Data Systems 15:26 Columnar Storage and Analytics 20:54 Case Study: Alibaba Cloud 21:57 Data Warehouse Context 23:24 Custom Indexing with BM25 24:01 Postgres Indexing Overview 24:17 Fast Fields and Columnar Format 24:52 Lucene Inspiration and Data Storage 26:06 Setting Up and Managing Indexes 27:43 Query Building and Complex Searches 30:21 Scaling and Sharding Strategies 35:27 Query Optimization and Common Mistakes 38:39 Future Developments and Integrations 39:24 Building a Full-Fledged Search Application 42:53 Challenges and Advantages of Using ParadeDB 46:43 Final Thoughts and Recommendations</p>]]>
      </content:encoded>
      <pubDate>Thu, 05 Dec 2024 07:23:32 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/a6e22dc4/ac160264.mp3" length="45417186" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/K9NMQPGQnbQA9NW8Mj0fursk5LRg3UK2sEa0DFNIAKM/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84N2Jk/OWI5M2VjZGM2NGY5/NTAwNTU5ZWI0ODI5/YTYxZi5wbmc.jpg"/>
      <itunes:duration>2836</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Many companies use Elastic or OpenSearch and use 10% of the capacity.</p><p>They have to build ETL pipelines.</p><p>Get data Normalized.</p><p>Worry about race conditions.</p><p>All in all. At the moment, when you want to do search on top of your transactional data, you are forced to build a distributed systems.</p><p>Not anymore.</p><p>ParadeDB is building an open-source PostgreSQL extension to enable search within your database.</p><p>Today, I am talking to Philippe No√´l, the founder and CEO of ParadeDB.</p><p>We talk about how they build it, how they integrate into the Postgres Query engines, and how you can build search on top of Postgres.</p><p><strong>Key Insights:</strong></p><p>Search is changing. We're moving from separate search clusters to search inside databases. Simpler architecture, stronger guarantees, lower costs up to a certain scale.</p><p>Most search engines force you to duplicate data. ParadeDB doesn't. You keep data normalized and join at query time. It hooks deep into Postgres's query planner. It doesn't just bolt on search - it lets Postgres optimize search queries alongside SQL ones.</p><p>Search indices can work with ACID. ParadeDB's BM25 index keeps Lucene-style components (term frequency, normalization) but adds Postgres metadata for transactions. Search + ACID is possible.</p><p>Two storage types matter: inverted indices for text, columnar "fast fields" for analytics. Pick the right one or queries get slow. Integers now default to columnar to prevent common mistakes.</p><p>Mixing query engines looks tempting but fails. The team tried using DuckDB and DataFusion inside Postgres. Both were fast but broke ACID compliance. They had to rebuild features natively.</p><p><strong>Philippe No√´l:</strong></p><ul><li><a href="https://www.linkedin.com/in/philippemnoel/">LinkedIn</a></li><li><a href="https://bsky.app/profile/philippemnoel.bsky.social">Bluesky</a></li><li><a href="https://www.paradedb.com/">ParadeDB</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to ParadeDB 00:53 Building ParadeDB with Rust 01:43 Integrating Search in Postgres 03:04 ParadeDB vs. Elastic 05:48 Technical Deep Dive: Postgres Integration 07:27 Challenges and Solutions 09:35 Transactional Safety and Performance 11:06 Composable Data Systems 15:26 Columnar Storage and Analytics 20:54 Case Study: Alibaba Cloud 21:57 Data Warehouse Context 23:24 Custom Indexing with BM25 24:01 Postgres Indexing Overview 24:17 Fast Fields and Columnar Format 24:52 Lucene Inspiration and Data Storage 26:06 Setting Up and Managing Indexes 27:43 Query Building and Complex Searches 30:21 Scaling and Sharding Strategies 35:27 Query Optimization and Common Mistakes 38:39 Future Developments and Integrations 39:24 Building a Full-Fledged Search Application 42:53 Challenges and Advantages of Using ParadeDB 46:43 Final Thoughts and Recommendations</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/a6e22dc4/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/a6e22dc4/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#033 RAG's Biggest Problems &amp; How to Fix It (ft. Synthetic Data)</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>16</itunes:episode>
      <podcast:episode>16</podcast:episode>
      <itunes:title>#033 RAG's Biggest Problems &amp; How to Fix It (ft. Synthetic Data)</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">0a62066a-7426-4ee6-98d9-c739e3ee8a43</guid>
      <link>https://share.transistor.fm/s/7dfe4734</link>
      <description>
        <![CDATA[<p>RAG isn't a magic fix for search problems. While it works well at first, most teams find it's not good enough for production out of the box. The key is to make it better step by step, using good testing and smart data creation.</p><p>Today, we are talking to Saahil Ognawala from Jina AI to start to understand RAG.</p><p>To build a good RAG system, you need three things: ways to test it, methods to create training data, and plans to make it better over time. Testing starts with a set of example searches that users might make. These should include common searches that happen often, medium-rare searches, and rare searches that only happen now and then. This mix helps you measure if changes make your system better or worse.</p><p>Creating synthetic data helps make the system stronger, especially in spotting wrong answers that look right. Think of someone searching for a "gluten-free chocolate cake." A "sugar-free chocolate cake" might look like a good answer because it shares many words, but it's wrong.¬†</p><p>These tricky examples help the system learn the difference between similar but different things.</p><p>When creating synthetic data, you need rules. The best way is to show the AI a few real examples and give it a list of topics to work with. Most teams find that using half real data and half synthetic data works best. This gives you enough variety while keeping things real.</p><p>Getting user feedback is hard with RAG. In normal search, you can see if users click on results. But with RAG, the system creates an answer from many pieces. A good answer might come from both good and bad pieces, making it hard to know which parts helped. This means you need smart ways to track which pieces of information actually helped make good answers.</p><p>One key rule: don't make things harder than they need to be. If simple keyword search (called BM25) works well enough, adding fancy AI search might not be worth the extra work.</p><p>Success with RAG comes from good testing, careful data creation, and steady improvements based on real use. It's not about using the newest AI models. It's about building good systems and processes that work reliably.</p><p><em>"It isn‚Äôt a magic wand you can place on your catalog and expect results you didn‚Äôt get before."<br></em><br></p><p>‚ÄúMost of our users are enterprise users who have seen the most success in their RAG systems are the ones that very early implemented a continuous feedback mechanism.‚Äú</p><p>‚ÄúIf you can't tell in real time usage whether an answer is a bad answer or a right answer because the LLM just makes it look like the right answer then you only have your retrieval dataset to blame‚Äù</p><p><strong>Saahil Ognawala:</strong></p><ul><li><a href="https://www.linkedin.com/in/saahilognawala/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://jina.ai/">Jina AI</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Retrieval Augmented Generation (RAG) 00:29 Interview with Saahil Ognawala 00:52 Synthetic Data in Language Generation 01:14 Understanding the E5 Mistral Instructor Embeddings Paper 03:15 Challenges and Evolution in Synthetic Data 05:03 User Intent and Retrieval Systems 11:26 Evaluating RAG Systems 14:46 Setting Up Evaluation Frameworks 20:37 Fine-Tuning and Embedding Models 22:25 Negative and Positive Examples in Retrieval 26:10 Synthetic Data for Hard Negatives 29:20 Case Study: Marine Biology Project 29:54 Addressing Errors in Marine Biology Queries 31:28 Ensuring Query Relevance with Human Intervention 31:47 Few Shot Prompting vs Zero Shot Prompting 35:09 Balancing Synthetic and Real World Data 37:17 Improving RAG Systems with User Feedback 39:15 Future Directions for Jina and Synthetic Data 40:44 Building and Evaluating Embedding Models 41:24 Getting Started with Jina and Open Source Tools 51:25 The Importance of Hard Negatives in Embedding Models</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>RAG isn't a magic fix for search problems. While it works well at first, most teams find it's not good enough for production out of the box. The key is to make it better step by step, using good testing and smart data creation.</p><p>Today, we are talking to Saahil Ognawala from Jina AI to start to understand RAG.</p><p>To build a good RAG system, you need three things: ways to test it, methods to create training data, and plans to make it better over time. Testing starts with a set of example searches that users might make. These should include common searches that happen often, medium-rare searches, and rare searches that only happen now and then. This mix helps you measure if changes make your system better or worse.</p><p>Creating synthetic data helps make the system stronger, especially in spotting wrong answers that look right. Think of someone searching for a "gluten-free chocolate cake." A "sugar-free chocolate cake" might look like a good answer because it shares many words, but it's wrong.¬†</p><p>These tricky examples help the system learn the difference between similar but different things.</p><p>When creating synthetic data, you need rules. The best way is to show the AI a few real examples and give it a list of topics to work with. Most teams find that using half real data and half synthetic data works best. This gives you enough variety while keeping things real.</p><p>Getting user feedback is hard with RAG. In normal search, you can see if users click on results. But with RAG, the system creates an answer from many pieces. A good answer might come from both good and bad pieces, making it hard to know which parts helped. This means you need smart ways to track which pieces of information actually helped make good answers.</p><p>One key rule: don't make things harder than they need to be. If simple keyword search (called BM25) works well enough, adding fancy AI search might not be worth the extra work.</p><p>Success with RAG comes from good testing, careful data creation, and steady improvements based on real use. It's not about using the newest AI models. It's about building good systems and processes that work reliably.</p><p><em>"It isn‚Äôt a magic wand you can place on your catalog and expect results you didn‚Äôt get before."<br></em><br></p><p>‚ÄúMost of our users are enterprise users who have seen the most success in their RAG systems are the ones that very early implemented a continuous feedback mechanism.‚Äú</p><p>‚ÄúIf you can't tell in real time usage whether an answer is a bad answer or a right answer because the LLM just makes it look like the right answer then you only have your retrieval dataset to blame‚Äù</p><p><strong>Saahil Ognawala:</strong></p><ul><li><a href="https://www.linkedin.com/in/saahilognawala/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://jina.ai/">Jina AI</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Retrieval Augmented Generation (RAG) 00:29 Interview with Saahil Ognawala 00:52 Synthetic Data in Language Generation 01:14 Understanding the E5 Mistral Instructor Embeddings Paper 03:15 Challenges and Evolution in Synthetic Data 05:03 User Intent and Retrieval Systems 11:26 Evaluating RAG Systems 14:46 Setting Up Evaluation Frameworks 20:37 Fine-Tuning and Embedding Models 22:25 Negative and Positive Examples in Retrieval 26:10 Synthetic Data for Hard Negatives 29:20 Case Study: Marine Biology Project 29:54 Addressing Errors in Marine Biology Queries 31:28 Ensuring Query Relevance with Human Intervention 31:47 Few Shot Prompting vs Zero Shot Prompting 35:09 Balancing Synthetic and Real World Data 37:17 Improving RAG Systems with User Feedback 39:15 Future Directions for Jina and Synthetic Data 40:44 Building and Evaluating Embedding Models 41:24 Getting Started with Jina and Open Source Tools 51:25 The Importance of Hard Negatives in Embedding Models</p>]]>
      </content:encoded>
      <pubDate>Thu, 28 Nov 2024 06:00:00 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/7dfe4734/8e0a8d2e.mp3" length="49424272" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/jLij65nPqxQYnrlwSWsZTujFDwwAZKq8S4gFjS8x9oM/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS80NzYz/YTZjM2Y0MmUyMzE4/YjkxNTUxNTg2ZmZl/NmM1NC5wbmc.jpg"/>
      <itunes:duration>3086</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>RAG isn't a magic fix for search problems. While it works well at first, most teams find it's not good enough for production out of the box. The key is to make it better step by step, using good testing and smart data creation.</p><p>Today, we are talking to Saahil Ognawala from Jina AI to start to understand RAG.</p><p>To build a good RAG system, you need three things: ways to test it, methods to create training data, and plans to make it better over time. Testing starts with a set of example searches that users might make. These should include common searches that happen often, medium-rare searches, and rare searches that only happen now and then. This mix helps you measure if changes make your system better or worse.</p><p>Creating synthetic data helps make the system stronger, especially in spotting wrong answers that look right. Think of someone searching for a "gluten-free chocolate cake." A "sugar-free chocolate cake" might look like a good answer because it shares many words, but it's wrong.¬†</p><p>These tricky examples help the system learn the difference between similar but different things.</p><p>When creating synthetic data, you need rules. The best way is to show the AI a few real examples and give it a list of topics to work with. Most teams find that using half real data and half synthetic data works best. This gives you enough variety while keeping things real.</p><p>Getting user feedback is hard with RAG. In normal search, you can see if users click on results. But with RAG, the system creates an answer from many pieces. A good answer might come from both good and bad pieces, making it hard to know which parts helped. This means you need smart ways to track which pieces of information actually helped make good answers.</p><p>One key rule: don't make things harder than they need to be. If simple keyword search (called BM25) works well enough, adding fancy AI search might not be worth the extra work.</p><p>Success with RAG comes from good testing, careful data creation, and steady improvements based on real use. It's not about using the newest AI models. It's about building good systems and processes that work reliably.</p><p><em>"It isn‚Äôt a magic wand you can place on your catalog and expect results you didn‚Äôt get before."<br></em><br></p><p>‚ÄúMost of our users are enterprise users who have seen the most success in their RAG systems are the ones that very early implemented a continuous feedback mechanism.‚Äú</p><p>‚ÄúIf you can't tell in real time usage whether an answer is a bad answer or a right answer because the LLM just makes it look like the right answer then you only have your retrieval dataset to blame‚Äù</p><p><strong>Saahil Ognawala:</strong></p><ul><li><a href="https://www.linkedin.com/in/saahilognawala/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://jina.ai/">Jina AI</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Retrieval Augmented Generation (RAG) 00:29 Interview with Saahil Ognawala 00:52 Synthetic Data in Language Generation 01:14 Understanding the E5 Mistral Instructor Embeddings Paper 03:15 Challenges and Evolution in Synthetic Data 05:03 User Intent and Retrieval Systems 11:26 Evaluating RAG Systems 14:46 Setting Up Evaluation Frameworks 20:37 Fine-Tuning and Embedding Models 22:25 Negative and Positive Examples in Retrieval 26:10 Synthetic Data for Hard Negatives 29:20 Case Study: Marine Biology Project 29:54 Addressing Errors in Marine Biology Queries 31:28 Ensuring Query Relevance with Human Intervention 31:47 Few Shot Prompting vs Zero Shot Prompting 35:09 Balancing Synthetic and Real World Data 37:17 Improving RAG Systems with User Feedback 39:15 Future Directions for Jina and Synthetic Data 40:44 Building and Evaluating Embedding Models 41:24 Getting Started with Jina and Open Source Tools 51:25 The Importance of Hard Negatives in Embedding Models</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/7dfe4734/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/7dfe4734/transcript.json" type="application/json"/>
      <podcast:chapters url="https://share.transistor.fm/s/7dfe4734/chapters.json" type="application/json+chapters"/>
    </item>
    <item>
      <title>#032 Improving Documentation Quality for RAG Systems</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>15</itunes:episode>
      <podcast:episode>15</podcast:episode>
      <itunes:title>#032 Improving Documentation Quality for RAG Systems</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">13c37065-2920-4805-b905-3dcfb54efb55</guid>
      <link>https://share.transistor.fm/s/c310424a</link>
      <description>
        <![CDATA[<p>Documentation quality is the silent killer of RAG systems. A single ambiguous sentence might corrupt an entire set of responses. But the hardest part isn't fixing errors - it's finding them.</p><p>Today we are talking to Max Buckley on how to find and fix these errors.</p><p>Max works at Google and has built a lot of interesting experiments with LLMs on using them to improve knowledge bases for generation.</p><p>We talk about identifying ambiguities, fixing errors, creating improvement loops in the documents and a lot more.</p><p>Some Insights:</p><ul><li>A single ambiguous sentence can systematically corrupt an entire knowledge base's responses. Fixing these "documentation poisons" often requires minimal changes but identifying them is challenging.</li><li>Large organizations develop their own linguistic ecosystems that evolve over time. This creates unique challenges for both embedding models and retrieval systems that need to bridge external and internal vocabularies.</li><li>Multiple feedback loops are crucial - expert testing, user feedback, and system monitoring each catch different types of issues.</li></ul><p><strong>Max Buckley: (All opinions are his own and not of Google)</strong></p><ul><li><a href="https://www.linkedin.com/in/maxbuckley/?originalSubdomain=ch">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Understanding LLM Hallucinations 00:02 Challenges with Temporal Inconsistencies 00:43 Issues with Document Structure and Terminology 01:05 Introduction to Retrieval Augmented Generation (RAG) 01:49 Interview with Max Buckley 02:27 Anthropic's Approach to Document Chunking 02:55 Contextualizing Chunks for Better Retrieval 06:29 Challenges in Chunking and Search 07:35 LLMs in Internal Knowledge Management 08:45 Identifying and Fixing Documentation Errors 10:58 Using LLMs for Error Detection 15:35 Improving Documentation with User Feedback 24:42 Running Processes on Retrieved Context 25:19 Challenges of Terminology Consistency 26:07 Handling Definitions and Glossaries 30:10 Addressing Context Misinterpretation 31:13 Improving Documentation Quality 36:00 Future of AI and Search Technologies 42:29 Ensuring Documentation Readiness for AI</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Documentation quality is the silent killer of RAG systems. A single ambiguous sentence might corrupt an entire set of responses. But the hardest part isn't fixing errors - it's finding them.</p><p>Today we are talking to Max Buckley on how to find and fix these errors.</p><p>Max works at Google and has built a lot of interesting experiments with LLMs on using them to improve knowledge bases for generation.</p><p>We talk about identifying ambiguities, fixing errors, creating improvement loops in the documents and a lot more.</p><p>Some Insights:</p><ul><li>A single ambiguous sentence can systematically corrupt an entire knowledge base's responses. Fixing these "documentation poisons" often requires minimal changes but identifying them is challenging.</li><li>Large organizations develop their own linguistic ecosystems that evolve over time. This creates unique challenges for both embedding models and retrieval systems that need to bridge external and internal vocabularies.</li><li>Multiple feedback loops are crucial - expert testing, user feedback, and system monitoring each catch different types of issues.</li></ul><p><strong>Max Buckley: (All opinions are his own and not of Google)</strong></p><ul><li><a href="https://www.linkedin.com/in/maxbuckley/?originalSubdomain=ch">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Understanding LLM Hallucinations 00:02 Challenges with Temporal Inconsistencies 00:43 Issues with Document Structure and Terminology 01:05 Introduction to Retrieval Augmented Generation (RAG) 01:49 Interview with Max Buckley 02:27 Anthropic's Approach to Document Chunking 02:55 Contextualizing Chunks for Better Retrieval 06:29 Challenges in Chunking and Search 07:35 LLMs in Internal Knowledge Management 08:45 Identifying and Fixing Documentation Errors 10:58 Using LLMs for Error Detection 15:35 Improving Documentation with User Feedback 24:42 Running Processes on Retrieved Context 25:19 Challenges of Terminology Consistency 26:07 Handling Definitions and Glossaries 30:10 Addressing Context Misinterpretation 31:13 Improving Documentation Quality 36:00 Future of AI and Search Technologies 42:29 Ensuring Documentation Readiness for AI</p>]]>
      </content:encoded>
      <pubDate>Thu, 21 Nov 2024 06:48:24 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/c310424a/3b807025.mp3" length="44793193" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/hahCRaUWcH8nyDHDaeiadV7cPma89LOvAAGnbGsV4fs/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS82MWE3/NzA2ZDU1NmQ0NWEx/ZjBhYzljMjU5NDZh/ZjkzNi5wbmc.jpg"/>
      <itunes:duration>2797</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Documentation quality is the silent killer of RAG systems. A single ambiguous sentence might corrupt an entire set of responses. But the hardest part isn't fixing errors - it's finding them.</p><p>Today we are talking to Max Buckley on how to find and fix these errors.</p><p>Max works at Google and has built a lot of interesting experiments with LLMs on using them to improve knowledge bases for generation.</p><p>We talk about identifying ambiguities, fixing errors, creating improvement loops in the documents and a lot more.</p><p>Some Insights:</p><ul><li>A single ambiguous sentence can systematically corrupt an entire knowledge base's responses. Fixing these "documentation poisons" often requires minimal changes but identifying them is challenging.</li><li>Large organizations develop their own linguistic ecosystems that evolve over time. This creates unique challenges for both embedding models and retrieval systems that need to bridge external and internal vocabularies.</li><li>Multiple feedback loops are crucial - expert testing, user feedback, and system monitoring each catch different types of issues.</li></ul><p><strong>Max Buckley: (All opinions are his own and not of Google)</strong></p><ul><li><a href="https://www.linkedin.com/in/maxbuckley/?originalSubdomain=ch">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Understanding LLM Hallucinations 00:02 Challenges with Temporal Inconsistencies 00:43 Issues with Document Structure and Terminology 01:05 Introduction to Retrieval Augmented Generation (RAG) 01:49 Interview with Max Buckley 02:27 Anthropic's Approach to Document Chunking 02:55 Contextualizing Chunks for Better Retrieval 06:29 Challenges in Chunking and Search 07:35 LLMs in Internal Knowledge Management 08:45 Identifying and Fixing Documentation Errors 10:58 Using LLMs for Error Detection 15:35 Improving Documentation with User Feedback 24:42 Running Processes on Retrieved Context 25:19 Challenges of Terminology Consistency 26:07 Handling Definitions and Glossaries 30:10 Addressing Context Misinterpretation 31:13 Improving Documentation Quality 36:00 Future of AI and Search Technologies 42:29 Ensuring Documentation Readiness for AI</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, embeddings, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/c310424a/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/c310424a/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#031 BM25 As The Workhorse Of Search; Vectors Are Its Visionary Cousin</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>14</itunes:episode>
      <podcast:episode>14</podcast:episode>
      <itunes:title>#031 BM25 As The Workhorse Of Search; Vectors Are Its Visionary Cousin</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">2bf68b77-568c-4d24-9b48-f6e18e760733</guid>
      <link>https://share.transistor.fm/s/436f373e</link>
      <description>
        <![CDATA[<p>Ever wondered why vector search isn't always the best path for information retrieval?</p><p>Join us as we dive deep into BM25 and its unmatched efficiency in our latest podcast episode with David Tippett from GitHub.</p><p>Discover how BM25 transforms search efficiency, even at GitHub's immense scale.</p><p>BM25, short for Best Match 25, use term frequency (TF) and inverse document frequency (IDF) to score document-query matches. It addresses limitations in TF-IDF, such as term saturation and document length normalization.</p><p><strong>Search Is About User Expectations</strong></p><ul><li>Search isn't just about relevance but aligning with what users expect:¬†<ul><li>GitHub users, for example, have diverse use cases‚Äîfinding security vulnerabilities, exploring codebases, or managing repositories. Each requires a different prioritization of fields, boosting strategies, and possibly even distinct search workflows.</li></ul></li><li><strong>Key Insight</strong>: Search is deeply contextual and use-case driven. Understanding your users' intent and tailoring search behavior to their expectations matters more than chasing state-of-the-art technology.</li></ul><p><strong>The Challenge of Vector Search at Scale</strong></p><ul><li>Vector search systems require in-memory storage of vectorized data, making them costly for datasets with billions of documents (e.g., GitHub‚Äôs 100 billion documents).</li><li>IVF and HNSW offer trade-offs:¬†<ul><li><strong>IVF</strong>: Reduces memory requirements by bucketing vectors but risks losing relevance due to bucket misclassification.</li><li><strong>HNSW</strong>: Offers high relevance but demands high memory, making it impractical for massive datasets.</li></ul></li><li><strong>Architectural Insight</strong>: When considering vector search, focus on niche applications or subdomains with manageable dataset sizes or use hybrid approaches combining BM25 with sparse/dense vectors.</li></ul><p><strong>Vector Search vs. BM25: A Trade-off of Precision vs. Cost</strong></p><ul><li>Vector search is more precise and effective for semantic similarity, but its operational costs and memory requirements make it prohibitive for massive datasets like GitHub‚Äôs corpus of over 100 billion documents.</li><li>BM25‚Äôs scaling challenges (e.g., reliance on disk IOPS) are manageable compared to the memory-bound nature of vector search engines like HNSW and IVF.</li><li><strong>Key Insight</strong>: BM25‚Äôs scalability allows for broader adoption, while vector search is still a niche solution requiring high specialization and infrastructure.</li></ul><p><strong>David Tippett:</strong></p><ul><li><a href="https://www.linkedin.com/in/david-tippett/">LinkedIn</a></li><li><a href="https://open.spotify.com/episode/3Nf7UaS2X7ZqwWQiEKYF45?si=13d5a84fd7ab4312&amp;nd=1&amp;dlsi=325b5df64ca243b1">Podcast (For the Sake of Search)</a></li><li><a href="https://x.com/dtaivpp">X (Twitter)</a></li><li><a href="https://tippybits.com/">Tippybits.com</a></li><li><a href="https://bsky.app/profile/taidesu.bsky.social">Bluesky</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to RAG and Vector Search Challenges 00:28 Introducing BM25: The Efficient Search Solution 00:43 Guest Introduction: David Tippett 01:16 Comparing Search Engines: Vespa, Weaviate, and More 07:53 Understanding BM25 and Its Importance 09:10 Deep Dive into BM25 Mechanics 23:46 Field-Based Scoring and BM25F 25:49 Introduction to Zero Shot Retrieval 26:03 Vector Search vs BM25 26:22 Combining Search Techniques 26:56 Favorite BM25 Adaptations 27:38 Postgres Search and Term Proximity 31:49 Challenges in GitHub Search 33:59 BM25 in Large Scale Systems 40:00 Technical Deep Dive into BM25 45:30 Future of Search and Learning to Rank 47:18 Conclusion and Future Plans</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Ever wondered why vector search isn't always the best path for information retrieval?</p><p>Join us as we dive deep into BM25 and its unmatched efficiency in our latest podcast episode with David Tippett from GitHub.</p><p>Discover how BM25 transforms search efficiency, even at GitHub's immense scale.</p><p>BM25, short for Best Match 25, use term frequency (TF) and inverse document frequency (IDF) to score document-query matches. It addresses limitations in TF-IDF, such as term saturation and document length normalization.</p><p><strong>Search Is About User Expectations</strong></p><ul><li>Search isn't just about relevance but aligning with what users expect:¬†<ul><li>GitHub users, for example, have diverse use cases‚Äîfinding security vulnerabilities, exploring codebases, or managing repositories. Each requires a different prioritization of fields, boosting strategies, and possibly even distinct search workflows.</li></ul></li><li><strong>Key Insight</strong>: Search is deeply contextual and use-case driven. Understanding your users' intent and tailoring search behavior to their expectations matters more than chasing state-of-the-art technology.</li></ul><p><strong>The Challenge of Vector Search at Scale</strong></p><ul><li>Vector search systems require in-memory storage of vectorized data, making them costly for datasets with billions of documents (e.g., GitHub‚Äôs 100 billion documents).</li><li>IVF and HNSW offer trade-offs:¬†<ul><li><strong>IVF</strong>: Reduces memory requirements by bucketing vectors but risks losing relevance due to bucket misclassification.</li><li><strong>HNSW</strong>: Offers high relevance but demands high memory, making it impractical for massive datasets.</li></ul></li><li><strong>Architectural Insight</strong>: When considering vector search, focus on niche applications or subdomains with manageable dataset sizes or use hybrid approaches combining BM25 with sparse/dense vectors.</li></ul><p><strong>Vector Search vs. BM25: A Trade-off of Precision vs. Cost</strong></p><ul><li>Vector search is more precise and effective for semantic similarity, but its operational costs and memory requirements make it prohibitive for massive datasets like GitHub‚Äôs corpus of over 100 billion documents.</li><li>BM25‚Äôs scaling challenges (e.g., reliance on disk IOPS) are manageable compared to the memory-bound nature of vector search engines like HNSW and IVF.</li><li><strong>Key Insight</strong>: BM25‚Äôs scalability allows for broader adoption, while vector search is still a niche solution requiring high specialization and infrastructure.</li></ul><p><strong>David Tippett:</strong></p><ul><li><a href="https://www.linkedin.com/in/david-tippett/">LinkedIn</a></li><li><a href="https://open.spotify.com/episode/3Nf7UaS2X7ZqwWQiEKYF45?si=13d5a84fd7ab4312&amp;nd=1&amp;dlsi=325b5df64ca243b1">Podcast (For the Sake of Search)</a></li><li><a href="https://x.com/dtaivpp">X (Twitter)</a></li><li><a href="https://tippybits.com/">Tippybits.com</a></li><li><a href="https://bsky.app/profile/taidesu.bsky.social">Bluesky</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to RAG and Vector Search Challenges 00:28 Introducing BM25: The Efficient Search Solution 00:43 Guest Introduction: David Tippett 01:16 Comparing Search Engines: Vespa, Weaviate, and More 07:53 Understanding BM25 and Its Importance 09:10 Deep Dive into BM25 Mechanics 23:46 Field-Based Scoring and BM25F 25:49 Introduction to Zero Shot Retrieval 26:03 Vector Search vs BM25 26:22 Combining Search Techniques 26:56 Favorite BM25 Adaptations 27:38 Postgres Search and Term Proximity 31:49 Challenges in GitHub Search 33:59 BM25 in Large Scale Systems 40:00 Technical Deep Dive into BM25 45:30 Future of Search and Learning to Rank 47:18 Conclusion and Future Plans</p>]]>
      </content:encoded>
      <pubDate>Fri, 15 Nov 2024 07:01:15 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/436f373e/fe665855.mp3" length="51951579" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/5Mt1R_jezGH0JUqTcU0MnKfTKBT-gzIjVCsdP3ah78w/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mZGFi/N2E2NzliNjFkYmQ0/YmFlYmMxYTQ5N2Nm/MTYwNS5wbmc.jpg"/>
      <itunes:duration>3245</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Ever wondered why vector search isn't always the best path for information retrieval?</p><p>Join us as we dive deep into BM25 and its unmatched efficiency in our latest podcast episode with David Tippett from GitHub.</p><p>Discover how BM25 transforms search efficiency, even at GitHub's immense scale.</p><p>BM25, short for Best Match 25, use term frequency (TF) and inverse document frequency (IDF) to score document-query matches. It addresses limitations in TF-IDF, such as term saturation and document length normalization.</p><p><strong>Search Is About User Expectations</strong></p><ul><li>Search isn't just about relevance but aligning with what users expect:¬†<ul><li>GitHub users, for example, have diverse use cases‚Äîfinding security vulnerabilities, exploring codebases, or managing repositories. Each requires a different prioritization of fields, boosting strategies, and possibly even distinct search workflows.</li></ul></li><li><strong>Key Insight</strong>: Search is deeply contextual and use-case driven. Understanding your users' intent and tailoring search behavior to their expectations matters more than chasing state-of-the-art technology.</li></ul><p><strong>The Challenge of Vector Search at Scale</strong></p><ul><li>Vector search systems require in-memory storage of vectorized data, making them costly for datasets with billions of documents (e.g., GitHub‚Äôs 100 billion documents).</li><li>IVF and HNSW offer trade-offs:¬†<ul><li><strong>IVF</strong>: Reduces memory requirements by bucketing vectors but risks losing relevance due to bucket misclassification.</li><li><strong>HNSW</strong>: Offers high relevance but demands high memory, making it impractical for massive datasets.</li></ul></li><li><strong>Architectural Insight</strong>: When considering vector search, focus on niche applications or subdomains with manageable dataset sizes or use hybrid approaches combining BM25 with sparse/dense vectors.</li></ul><p><strong>Vector Search vs. BM25: A Trade-off of Precision vs. Cost</strong></p><ul><li>Vector search is more precise and effective for semantic similarity, but its operational costs and memory requirements make it prohibitive for massive datasets like GitHub‚Äôs corpus of over 100 billion documents.</li><li>BM25‚Äôs scaling challenges (e.g., reliance on disk IOPS) are manageable compared to the memory-bound nature of vector search engines like HNSW and IVF.</li><li><strong>Key Insight</strong>: BM25‚Äôs scalability allows for broader adoption, while vector search is still a niche solution requiring high specialization and infrastructure.</li></ul><p><strong>David Tippett:</strong></p><ul><li><a href="https://www.linkedin.com/in/david-tippett/">LinkedIn</a></li><li><a href="https://open.spotify.com/episode/3Nf7UaS2X7ZqwWQiEKYF45?si=13d5a84fd7ab4312&amp;nd=1&amp;dlsi=325b5df64ca243b1">Podcast (For the Sake of Search)</a></li><li><a href="https://x.com/dtaivpp">X (Twitter)</a></li><li><a href="https://tippybits.com/">Tippybits.com</a></li><li><a href="https://bsky.app/profile/taidesu.bsky.social">Bluesky</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li><li><a href="https://bsky.app/profile/nicolay.fyi">Bluesky</a></li></ul><p>00:00 Introduction to RAG and Vector Search Challenges 00:28 Introducing BM25: The Efficient Search Solution 00:43 Guest Introduction: David Tippett 01:16 Comparing Search Engines: Vespa, Weaviate, and More 07:53 Understanding BM25 and Its Importance 09:10 Deep Dive into BM25 Mechanics 23:46 Field-Based Scoring and BM25F 25:49 Introduction to Zero Shot Retrieval 26:03 Vector Search vs BM25 26:22 Combining Search Techniques 26:56 Favorite BM25 Adaptations 27:38 Postgres Search and Term Proximity 31:49 Challenges in GitHub Search 33:59 BM25 in Large Scale Systems 40:00 Technical Deep Dive into BM25 45:30 Future of Search and Learning to Rank 47:18 Conclusion and Future Plans</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/436f373e/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/436f373e/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#030 Vector Search at Scale, Why One Size Doesn't Fit All</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>13</itunes:episode>
      <podcast:episode>13</podcast:episode>
      <itunes:title>#030 Vector Search at Scale, Why One Size Doesn't Fit All</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">1b4d4985-1c97-4b36-b90a-bdb2fea4f11e</guid>
      <link>https://share.transistor.fm/s/dd31560a</link>
      <description>
        <![CDATA[<p>Ever wondered why your vector search becomes painfully slow after scaling past a million vectors? You're not alone - even tech giants struggle with this.</p><p>Charles Xie, founder of Zilliz (company behind Milvus), shares how they solved vector database scaling challenges at 100B+ vector scale:</p><p>Key Insights:</p><ul><li>Multi-tier storage strategy:¬†<ul><li>GPU memory (1% of data, fastest)</li><li>RAM (10% of data)</li><li>Local SSD</li><li>Object storage (slowest but cheapest)</li></ul></li><li>Real-time search solution:¬†<ul><li>New data goes to buffer (searchable immediately)</li><li>Index builds in background when buffer fills</li><li>Combines buffer &amp; main index results</li></ul></li><li>Performance optimization:¬†<ul><li>GPU acceleration for 10k-50k queries/second</li><li>Customizable trade-offs between:¬†<ul><li>Cost</li><li>Latency</li><li>Search relevance</li></ul></li></ul></li><li>Future developments:¬†<ul><li>Self-learning indices</li><li>Hybrid search methods (dense + sparse)</li><li>Graph embedding support</li><li>Colbert integration</li></ul></li></ul><p>Perfect for teams hitting scaling walls with their current vector search implementation or planning for future growth.</p><p>Worth watching if you're building production search systems or need to optimize costs vs performance.</p><p><strong>Charles Xie:</strong></p><ul><li><a href="https://www.linkedin.com/in/chaoxie/">LinkedIn</a></li><li><a href="https://zilliz.com/">Zilliz</a></li><li><a href="https://github.com/milvus-io/milvus">Milvus</a></li><li><a href="https://discord.com/invite/8uyFbECzPX">Milvus Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search System Challenges 00:26 Introducing Milvus: The Open Source Vector Database 00:58 Interview with Charles: Founder of Zilliz 02:20 Scalability and Performance in Vector Databases 03:35 Challenges in Distributed Systems 05:46 Data Consistency and Real-Time Search 12:12 Hierarchical Storage and GPU Acceleration 18:34 Emerging Technologies in Vector Search 23:21 Self-Learning Indexes and Future Innovations 28:44 Key Takeaways and Conclusion</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Ever wondered why your vector search becomes painfully slow after scaling past a million vectors? You're not alone - even tech giants struggle with this.</p><p>Charles Xie, founder of Zilliz (company behind Milvus), shares how they solved vector database scaling challenges at 100B+ vector scale:</p><p>Key Insights:</p><ul><li>Multi-tier storage strategy:¬†<ul><li>GPU memory (1% of data, fastest)</li><li>RAM (10% of data)</li><li>Local SSD</li><li>Object storage (slowest but cheapest)</li></ul></li><li>Real-time search solution:¬†<ul><li>New data goes to buffer (searchable immediately)</li><li>Index builds in background when buffer fills</li><li>Combines buffer &amp; main index results</li></ul></li><li>Performance optimization:¬†<ul><li>GPU acceleration for 10k-50k queries/second</li><li>Customizable trade-offs between:¬†<ul><li>Cost</li><li>Latency</li><li>Search relevance</li></ul></li></ul></li><li>Future developments:¬†<ul><li>Self-learning indices</li><li>Hybrid search methods (dense + sparse)</li><li>Graph embedding support</li><li>Colbert integration</li></ul></li></ul><p>Perfect for teams hitting scaling walls with their current vector search implementation or planning for future growth.</p><p>Worth watching if you're building production search systems or need to optimize costs vs performance.</p><p><strong>Charles Xie:</strong></p><ul><li><a href="https://www.linkedin.com/in/chaoxie/">LinkedIn</a></li><li><a href="https://zilliz.com/">Zilliz</a></li><li><a href="https://github.com/milvus-io/milvus">Milvus</a></li><li><a href="https://discord.com/invite/8uyFbECzPX">Milvus Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search System Challenges 00:26 Introducing Milvus: The Open Source Vector Database 00:58 Interview with Charles: Founder of Zilliz 02:20 Scalability and Performance in Vector Databases 03:35 Challenges in Distributed Systems 05:46 Data Consistency and Real-Time Search 12:12 Hierarchical Storage and GPU Acceleration 18:34 Emerging Technologies in Vector Search 23:21 Self-Learning Indexes and Future Innovations 28:44 Key Takeaways and Conclusion</p>]]>
      </content:encoded>
      <pubDate>Thu, 07 Nov 2024 08:22:44 -0500</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/dd31560a/78dff6ab.mp3" length="35012516" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/zL5iVWeN3jP4B18L0CYvEOx42k-0NU0j6wvjEOVbaCs/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jYTVj/NzAxZDQ4NzlhMzU5/MzZiMTc0NGFmM2Vi/NDdmZi5wbmc.jpg"/>
      <itunes:duration>2186</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Ever wondered why your vector search becomes painfully slow after scaling past a million vectors? You're not alone - even tech giants struggle with this.</p><p>Charles Xie, founder of Zilliz (company behind Milvus), shares how they solved vector database scaling challenges at 100B+ vector scale:</p><p>Key Insights:</p><ul><li>Multi-tier storage strategy:¬†<ul><li>GPU memory (1% of data, fastest)</li><li>RAM (10% of data)</li><li>Local SSD</li><li>Object storage (slowest but cheapest)</li></ul></li><li>Real-time search solution:¬†<ul><li>New data goes to buffer (searchable immediately)</li><li>Index builds in background when buffer fills</li><li>Combines buffer &amp; main index results</li></ul></li><li>Performance optimization:¬†<ul><li>GPU acceleration for 10k-50k queries/second</li><li>Customizable trade-offs between:¬†<ul><li>Cost</li><li>Latency</li><li>Search relevance</li></ul></li></ul></li><li>Future developments:¬†<ul><li>Self-learning indices</li><li>Hybrid search methods (dense + sparse)</li><li>Graph embedding support</li><li>Colbert integration</li></ul></li></ul><p>Perfect for teams hitting scaling walls with their current vector search implementation or planning for future growth.</p><p>Worth watching if you're building production search systems or need to optimize costs vs performance.</p><p><strong>Charles Xie:</strong></p><ul><li><a href="https://www.linkedin.com/in/chaoxie/">LinkedIn</a></li><li><a href="https://zilliz.com/">Zilliz</a></li><li><a href="https://github.com/milvus-io/milvus">Milvus</a></li><li><a href="https://discord.com/invite/8uyFbECzPX">Milvus Discord</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search System Challenges 00:26 Introducing Milvus: The Open Source Vector Database 00:58 Interview with Charles: Founder of Zilliz 02:20 Scalability and Performance in Vector Databases 03:35 Challenges in Distributed Systems 05:46 Data Consistency and Real-Time Search 12:12 Hierarchical Storage and GPU Acceleration 18:34 Emerging Technologies in Vector Search 23:21 Self-Learning Indexes and Future Innovations 28:44 Key Takeaways and Conclusion</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/dd31560a/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/dd31560a/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#029 Search Systems at Scale, Avoiding Local Maxima and Other Engineering Lessons</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>12</itunes:episode>
      <podcast:episode>12</podcast:episode>
      <itunes:title>#029 Search Systems at Scale, Avoiding Local Maxima and Other Engineering Lessons</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">21ca10a4-13dd-4c48-9bf5-b05a28b2b953</guid>
      <link>https://share.transistor.fm/s/80d9d655</link>
      <description>
        <![CDATA[<p>Modern search systems face a complex balancing act between performance, relevancy, and cost, requiring careful architectural decisions at each layer.</p><p>While vector search generates buzz, hybrid approaches combining traditional text search with vector capabilities yield better results.</p><p>The architecture typically splits into three core components:</p><ol><li>ingestion/indexing (requiring decisions between batch vs streaming)</li><li>query processing (balancing understanding vs performance)</li><li>analytics/feedback loops for continuous improvement.</li></ol><p>Critical but often overlooked aspects include query understanding depth, systematic relevancy testing (avoid anecdote-driven development), and data governance as search systems naturally evolve into organizational data hubs.</p><p>Performance optimization requires careful tradeoffs between index-time vs query-time computation, with even 1-2% improvements being significant in mature systems.</p><p>Success requires testing against production data (staging environments prove unreliable), implementing proper evaluation infrastructure (golden query sets, A/B testing, interleaving), and avoiding the local maxima trap where improving one query set unknowingly damages others.</p><p>The end goal is finding an acceptable balance between corpus size, latency requirements, and cost constraints while maintaining system manageability and relevance quality.</p><p>"It's quite easy to end up in local maxima, whereby you improve a query for one set and then you end up destroying it for another set."</p><p>"A good marker of a sophisticated system is one where you actually see it's getting worse... you might be discovering a maxima."</p><p>"There's no free lunch in all of this. Often it's a case that, to service billions of documents on a vector search, less than 10 millis, you can do those kinds of things. They're just incredibly expensive. It's really about trying to manage all of the overall system to find what is an acceptable balance."</p><p><strong>Search Pioneers:</strong></p><ul><li><a href="https://searchpioneer.com/">Website</a></li><li><a href="https://github.com/searchpioneer">GitHub</a></li></ul><p><strong>Stuart Cam:</strong></p><ul><li><a href="https://www.linkedin.com/in/codebrain/">LinkedIn</a></li></ul><p><strong>Russ Cam:</strong></p><ul><li><a href="https://github.com/russcam">Github</a></li><li><a href="https://www.linkedin.com/in/russellcam/">LinkedIn</a></li><li><a href="https://x.com/forloop">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Systems 00:13 Challenges in Search: Relevancy vs Latency 00:27 Insights from Industry Experts 01:00 Evolution of Search Technologies 03:16 Storage and Compute in Search Systems 06:22 Common Mistakes in Building Search Systems 09:10 Evaluating and Improving Search Systems 19:27 Architectural Components of Search Systems 29:17 Understanding Search Query Expectations 29:39 Balancing Speed, Cost, and Corpus Size 32:03 Trade-offs in Search System Design 32:53 Indexing vs Querying: Key Considerations 35:28 Re-ranking and Personalization Challenges 38:11 Evaluating Search System Performance 44:51 Overrated vs Underrated Search Techniques 48:31 Final Thoughts and Contact Information</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Modern search systems face a complex balancing act between performance, relevancy, and cost, requiring careful architectural decisions at each layer.</p><p>While vector search generates buzz, hybrid approaches combining traditional text search with vector capabilities yield better results.</p><p>The architecture typically splits into three core components:</p><ol><li>ingestion/indexing (requiring decisions between batch vs streaming)</li><li>query processing (balancing understanding vs performance)</li><li>analytics/feedback loops for continuous improvement.</li></ol><p>Critical but often overlooked aspects include query understanding depth, systematic relevancy testing (avoid anecdote-driven development), and data governance as search systems naturally evolve into organizational data hubs.</p><p>Performance optimization requires careful tradeoffs between index-time vs query-time computation, with even 1-2% improvements being significant in mature systems.</p><p>Success requires testing against production data (staging environments prove unreliable), implementing proper evaluation infrastructure (golden query sets, A/B testing, interleaving), and avoiding the local maxima trap where improving one query set unknowingly damages others.</p><p>The end goal is finding an acceptable balance between corpus size, latency requirements, and cost constraints while maintaining system manageability and relevance quality.</p><p>"It's quite easy to end up in local maxima, whereby you improve a query for one set and then you end up destroying it for another set."</p><p>"A good marker of a sophisticated system is one where you actually see it's getting worse... you might be discovering a maxima."</p><p>"There's no free lunch in all of this. Often it's a case that, to service billions of documents on a vector search, less than 10 millis, you can do those kinds of things. They're just incredibly expensive. It's really about trying to manage all of the overall system to find what is an acceptable balance."</p><p><strong>Search Pioneers:</strong></p><ul><li><a href="https://searchpioneer.com/">Website</a></li><li><a href="https://github.com/searchpioneer">GitHub</a></li></ul><p><strong>Stuart Cam:</strong></p><ul><li><a href="https://www.linkedin.com/in/codebrain/">LinkedIn</a></li></ul><p><strong>Russ Cam:</strong></p><ul><li><a href="https://github.com/russcam">Github</a></li><li><a href="https://www.linkedin.com/in/russellcam/">LinkedIn</a></li><li><a href="https://x.com/forloop">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Systems 00:13 Challenges in Search: Relevancy vs Latency 00:27 Insights from Industry Experts 01:00 Evolution of Search Technologies 03:16 Storage and Compute in Search Systems 06:22 Common Mistakes in Building Search Systems 09:10 Evaluating and Improving Search Systems 19:27 Architectural Components of Search Systems 29:17 Understanding Search Query Expectations 29:39 Balancing Speed, Cost, and Corpus Size 32:03 Trade-offs in Search System Design 32:53 Indexing vs Querying: Key Considerations 35:28 Re-ranking and Personalization Challenges 38:11 Evaluating Search System Performance 44:51 Overrated vs Underrated Search Techniques 48:31 Final Thoughts and Contact Information</p>]]>
      </content:encoded>
      <pubDate>Thu, 31 Oct 2024 05:12:08 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/80d9d655/11a376ac.mp3" length="52648243" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/qr-IHrQRfmbwwkS1MXWLeRuQ3S2u0Wj4iTTaS8nJ5ZI/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS81ZmIw/N2I0MjdkOWMxMjc4/ZTNhODg5YmQ1ZDFm/ZjUzNy5wbmc.jpg"/>
      <itunes:duration>3287</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Modern search systems face a complex balancing act between performance, relevancy, and cost, requiring careful architectural decisions at each layer.</p><p>While vector search generates buzz, hybrid approaches combining traditional text search with vector capabilities yield better results.</p><p>The architecture typically splits into three core components:</p><ol><li>ingestion/indexing (requiring decisions between batch vs streaming)</li><li>query processing (balancing understanding vs performance)</li><li>analytics/feedback loops for continuous improvement.</li></ol><p>Critical but often overlooked aspects include query understanding depth, systematic relevancy testing (avoid anecdote-driven development), and data governance as search systems naturally evolve into organizational data hubs.</p><p>Performance optimization requires careful tradeoffs between index-time vs query-time computation, with even 1-2% improvements being significant in mature systems.</p><p>Success requires testing against production data (staging environments prove unreliable), implementing proper evaluation infrastructure (golden query sets, A/B testing, interleaving), and avoiding the local maxima trap where improving one query set unknowingly damages others.</p><p>The end goal is finding an acceptable balance between corpus size, latency requirements, and cost constraints while maintaining system manageability and relevance quality.</p><p>"It's quite easy to end up in local maxima, whereby you improve a query for one set and then you end up destroying it for another set."</p><p>"A good marker of a sophisticated system is one where you actually see it's getting worse... you might be discovering a maxima."</p><p>"There's no free lunch in all of this. Often it's a case that, to service billions of documents on a vector search, less than 10 millis, you can do those kinds of things. They're just incredibly expensive. It's really about trying to manage all of the overall system to find what is an acceptable balance."</p><p><strong>Search Pioneers:</strong></p><ul><li><a href="https://searchpioneer.com/">Website</a></li><li><a href="https://github.com/searchpioneer">GitHub</a></li></ul><p><strong>Stuart Cam:</strong></p><ul><li><a href="https://www.linkedin.com/in/codebrain/">LinkedIn</a></li></ul><p><strong>Russ Cam:</strong></p><ul><li><a href="https://github.com/russcam">Github</a></li><li><a href="https://www.linkedin.com/in/russellcam/">LinkedIn</a></li><li><a href="https://x.com/forloop">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Search Systems 00:13 Challenges in Search: Relevancy vs Latency 00:27 Insights from Industry Experts 01:00 Evolution of Search Technologies 03:16 Storage and Compute in Search Systems 06:22 Common Mistakes in Building Search Systems 09:10 Evaluating and Improving Search Systems 19:27 Architectural Components of Search Systems 29:17 Understanding Search Query Expectations 29:39 Balancing Speed, Cost, and Corpus Size 32:03 Trade-offs in Search System Design 32:53 Indexing vs Querying: Key Considerations 35:28 Re-ranking and Personalization Challenges 38:11 Evaluating Search System Performance 44:51 Overrated vs Underrated Search Techniques 48:31 Final Thoughts and Contact Information</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/80d9d655/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/80d9d655/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#028 Training Multi-Modal AI, Inside the Jina CLIP Embedding Model</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>11</itunes:episode>
      <podcast:episode>11</podcast:episode>
      <itunes:title>#028 Training Multi-Modal AI, Inside the Jina CLIP Embedding Model</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">a250dd7f-f90c-480c-8ec3-a911b1b8cd95</guid>
      <link>https://share.transistor.fm/s/0f1e0b52</link>
      <description>
        <![CDATA[<p>Today we are talking to Michael G√ºnther, a senior machine learning scientist at Jina about his work on JINA Clip.</p><p>Some key points:</p><ul><li><strong>Uni-modal embeddings</strong> convert a single type of input (text, images, audio) into vectors</li><li><strong>Multimodal embeddings</strong> learn a joint embedding space that can handle multiple types of input, enabling cross-modal search (e.g., searching images with text)</li><li>Multimodal models can potentially learn richer representations of the world, including concepts that are difficult or impossible to put into words</li></ul><p>Types of Text-Image Models</p><ol><li><strong>CLIP-like Models</strong><ul><li>Separate vision and text transformer models</li><li>Each tower maps inputs to a shared vector space</li><li>Optimized for efficient retrieval</li></ul></li><li><strong>Vision-Language Models</strong><ul><li>Process image patches as tokens</li><li>Use transformer architecture to combine image and text information</li><li>Better suited for complex document matching</li></ul></li><li><strong>Hybrid Models</strong><ul><li>Combine separate encoders with additional transformer components</li><li>Allow for more complex interactions between modalities</li><li>Example: Google's Magic Lens model</li></ul></li></ol><p>Training Insights from Jina CLIP</p><ol><li><strong>Key Learnings</strong><ul><li>Freezing the text encoder during training can significantly hinder performance</li><li>Short image captions limit the model's ability to learn rich text representations</li><li>Large batch sizes are crucial for training embedding models effectively</li></ul></li><li><strong>Training Process</strong><ul><li>Three-stage training approach:¬†<ul><li>Stage 1: Training on image captions and text pairs</li><li>Stage 2: Adding longer image captions</li><li>Stage 3: Including triplet data with hard negatives</li></ul></li></ul></li></ol><p>Practical Considerations</p><ul><li><strong>Similarity Scales</strong><ul><li>Different modalities can produce different similarity value scales</li><li>Important to consider when combining multiple embedding types</li><li>Can affect threshold-based filtering</li></ul></li><li><strong>Model Selection</strong><ul><li>Evaluate models based on relevant benchmarks</li><li>Consider the domain similarity between training data and intended use case</li><li>Assessment of computational requirements and efficiency needs</li></ul></li></ul><p>Future Directions</p><ol><li><strong>Areas for Development</strong><ul><li>More comprehensive benchmarks for multimodal tasks</li><li>Better support for semi-structured data</li><li>Improved handling of non-photographic images</li></ul></li><li><strong>Upcoming Developments at Jina AI</strong><ul><li>Multilingual support for Jina ColBERT</li><li>New version of text embedding models</li><li>Focus on complex multimodal search applications</li></ul></li></ol><p>Practical Applications</p><ul><li><strong>E-commerce</strong><ul><li>Product search and recommendations</li><li>Combined text-image embeddings for better results</li><li>Synthetic data generation for fine-tuning</li></ul></li><li><strong>Fine-tuning Strategies</strong><ul><li>Using click data and query logs</li><li>Generative pseudo-labeling for creating training data</li><li>Domain-specific adaptations</li></ul></li></ul><p>Key Takeaways for Engineers</p><ol><li>Be aware of similarity value scales and their implications</li><li>Establish quantitative evaluation metrics before optimization</li><li>Consider model limitations (e.g., image resolution, text length)</li><li>Use performance optimizations like flash attention and activation checkpointing</li><li>Universal embedding models might not be optimal for specific use cases</li></ol><p><strong>Michael Guenther</strong></p><ul><li><a href="https://www.linkedin.com/in/michael-g%C3%BCnther-3519a6133/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/michael_g_u">X (Twitter)</a></li><li><a href="https://jina.ai/">Jina AI</a></li><li><a href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model">New Multilingual Embedding Modal</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Uni-modal and Multimodal Embeddings 00:16 Exploring Multimodal Embeddings and Their Applications 01:06 Training Multimodal Embedding Models 02:21 Challenges and Solutions in Embedding Models 07:29 Advanced Techniques and Future Directions 29:19 Understanding Model Interference in Search Specialization 30:17 Fine-Tuning Jina CLIP for E-Commerce 32:18 Synthetic Data Generation and Pseudo-Labeling 33:36 Challenges and Learnings in Embedding Models 40:52 Future Directions and Takeaways</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today we are talking to Michael G√ºnther, a senior machine learning scientist at Jina about his work on JINA Clip.</p><p>Some key points:</p><ul><li><strong>Uni-modal embeddings</strong> convert a single type of input (text, images, audio) into vectors</li><li><strong>Multimodal embeddings</strong> learn a joint embedding space that can handle multiple types of input, enabling cross-modal search (e.g., searching images with text)</li><li>Multimodal models can potentially learn richer representations of the world, including concepts that are difficult or impossible to put into words</li></ul><p>Types of Text-Image Models</p><ol><li><strong>CLIP-like Models</strong><ul><li>Separate vision and text transformer models</li><li>Each tower maps inputs to a shared vector space</li><li>Optimized for efficient retrieval</li></ul></li><li><strong>Vision-Language Models</strong><ul><li>Process image patches as tokens</li><li>Use transformer architecture to combine image and text information</li><li>Better suited for complex document matching</li></ul></li><li><strong>Hybrid Models</strong><ul><li>Combine separate encoders with additional transformer components</li><li>Allow for more complex interactions between modalities</li><li>Example: Google's Magic Lens model</li></ul></li></ol><p>Training Insights from Jina CLIP</p><ol><li><strong>Key Learnings</strong><ul><li>Freezing the text encoder during training can significantly hinder performance</li><li>Short image captions limit the model's ability to learn rich text representations</li><li>Large batch sizes are crucial for training embedding models effectively</li></ul></li><li><strong>Training Process</strong><ul><li>Three-stage training approach:¬†<ul><li>Stage 1: Training on image captions and text pairs</li><li>Stage 2: Adding longer image captions</li><li>Stage 3: Including triplet data with hard negatives</li></ul></li></ul></li></ol><p>Practical Considerations</p><ul><li><strong>Similarity Scales</strong><ul><li>Different modalities can produce different similarity value scales</li><li>Important to consider when combining multiple embedding types</li><li>Can affect threshold-based filtering</li></ul></li><li><strong>Model Selection</strong><ul><li>Evaluate models based on relevant benchmarks</li><li>Consider the domain similarity between training data and intended use case</li><li>Assessment of computational requirements and efficiency needs</li></ul></li></ul><p>Future Directions</p><ol><li><strong>Areas for Development</strong><ul><li>More comprehensive benchmarks for multimodal tasks</li><li>Better support for semi-structured data</li><li>Improved handling of non-photographic images</li></ul></li><li><strong>Upcoming Developments at Jina AI</strong><ul><li>Multilingual support for Jina ColBERT</li><li>New version of text embedding models</li><li>Focus on complex multimodal search applications</li></ul></li></ol><p>Practical Applications</p><ul><li><strong>E-commerce</strong><ul><li>Product search and recommendations</li><li>Combined text-image embeddings for better results</li><li>Synthetic data generation for fine-tuning</li></ul></li><li><strong>Fine-tuning Strategies</strong><ul><li>Using click data and query logs</li><li>Generative pseudo-labeling for creating training data</li><li>Domain-specific adaptations</li></ul></li></ul><p>Key Takeaways for Engineers</p><ol><li>Be aware of similarity value scales and their implications</li><li>Establish quantitative evaluation metrics before optimization</li><li>Consider model limitations (e.g., image resolution, text length)</li><li>Use performance optimizations like flash attention and activation checkpointing</li><li>Universal embedding models might not be optimal for specific use cases</li></ol><p><strong>Michael Guenther</strong></p><ul><li><a href="https://www.linkedin.com/in/michael-g%C3%BCnther-3519a6133/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/michael_g_u">X (Twitter)</a></li><li><a href="https://jina.ai/">Jina AI</a></li><li><a href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model">New Multilingual Embedding Modal</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Uni-modal and Multimodal Embeddings 00:16 Exploring Multimodal Embeddings and Their Applications 01:06 Training Multimodal Embedding Models 02:21 Challenges and Solutions in Embedding Models 07:29 Advanced Techniques and Future Directions 29:19 Understanding Model Interference in Search Specialization 30:17 Fine-Tuning Jina CLIP for E-Commerce 32:18 Synthetic Data Generation and Pseudo-Labeling 33:36 Challenges and Learnings in Embedding Models 40:52 Future Directions and Takeaways</p>]]>
      </content:encoded>
      <pubDate>Fri, 25 Oct 2024 09:32:36 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/0f1e0b52/886257cd.mp3" length="47432177" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/abUd22gfZqyT2tMf5talOnsNVlvjn2m8gSAjW1yYpno/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84YmNj/YTUxNzVkMGU3ZThj/YWU3YWNkYjE5NDc2/MjBjMS5wbmc.jpg"/>
      <itunes:duration>2962</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today we are talking to Michael G√ºnther, a senior machine learning scientist at Jina about his work on JINA Clip.</p><p>Some key points:</p><ul><li><strong>Uni-modal embeddings</strong> convert a single type of input (text, images, audio) into vectors</li><li><strong>Multimodal embeddings</strong> learn a joint embedding space that can handle multiple types of input, enabling cross-modal search (e.g., searching images with text)</li><li>Multimodal models can potentially learn richer representations of the world, including concepts that are difficult or impossible to put into words</li></ul><p>Types of Text-Image Models</p><ol><li><strong>CLIP-like Models</strong><ul><li>Separate vision and text transformer models</li><li>Each tower maps inputs to a shared vector space</li><li>Optimized for efficient retrieval</li></ul></li><li><strong>Vision-Language Models</strong><ul><li>Process image patches as tokens</li><li>Use transformer architecture to combine image and text information</li><li>Better suited for complex document matching</li></ul></li><li><strong>Hybrid Models</strong><ul><li>Combine separate encoders with additional transformer components</li><li>Allow for more complex interactions between modalities</li><li>Example: Google's Magic Lens model</li></ul></li></ol><p>Training Insights from Jina CLIP</p><ol><li><strong>Key Learnings</strong><ul><li>Freezing the text encoder during training can significantly hinder performance</li><li>Short image captions limit the model's ability to learn rich text representations</li><li>Large batch sizes are crucial for training embedding models effectively</li></ul></li><li><strong>Training Process</strong><ul><li>Three-stage training approach:¬†<ul><li>Stage 1: Training on image captions and text pairs</li><li>Stage 2: Adding longer image captions</li><li>Stage 3: Including triplet data with hard negatives</li></ul></li></ul></li></ol><p>Practical Considerations</p><ul><li><strong>Similarity Scales</strong><ul><li>Different modalities can produce different similarity value scales</li><li>Important to consider when combining multiple embedding types</li><li>Can affect threshold-based filtering</li></ul></li><li><strong>Model Selection</strong><ul><li>Evaluate models based on relevant benchmarks</li><li>Consider the domain similarity between training data and intended use case</li><li>Assessment of computational requirements and efficiency needs</li></ul></li></ul><p>Future Directions</p><ol><li><strong>Areas for Development</strong><ul><li>More comprehensive benchmarks for multimodal tasks</li><li>Better support for semi-structured data</li><li>Improved handling of non-photographic images</li></ul></li><li><strong>Upcoming Developments at Jina AI</strong><ul><li>Multilingual support for Jina ColBERT</li><li>New version of text embedding models</li><li>Focus on complex multimodal search applications</li></ul></li></ol><p>Practical Applications</p><ul><li><strong>E-commerce</strong><ul><li>Product search and recommendations</li><li>Combined text-image embeddings for better results</li><li>Synthetic data generation for fine-tuning</li></ul></li><li><strong>Fine-tuning Strategies</strong><ul><li>Using click data and query logs</li><li>Generative pseudo-labeling for creating training data</li><li>Domain-specific adaptations</li></ul></li></ul><p>Key Takeaways for Engineers</p><ol><li>Be aware of similarity value scales and their implications</li><li>Establish quantitative evaluation metrics before optimization</li><li>Consider model limitations (e.g., image resolution, text length)</li><li>Use performance optimizations like flash attention and activation checkpointing</li><li>Universal embedding models might not be optimal for specific use cases</li></ol><p><strong>Michael Guenther</strong></p><ul><li><a href="https://www.linkedin.com/in/michael-g%C3%BCnther-3519a6133/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/michael_g_u">X (Twitter)</a></li><li><a href="https://jina.ai/">Jina AI</a></li><li><a href="https://jina.ai/news/jina-embeddings-v3-a-frontier-multilingual-embedding-model">New Multilingual Embedding Modal</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Uni-modal and Multimodal Embeddings 00:16 Exploring Multimodal Embeddings and Their Applications 01:06 Training Multimodal Embedding Models 02:21 Challenges and Solutions in Embedding Models 07:29 Advanced Techniques and Future Directions 29:19 Understanding Model Interference in Search Specialization 30:17 Fine-Tuning Jina CLIP for E-Commerce 32:18 Synthetic Data Generation and Pseudo-Labeling 33:36 Challenges and Learnings in Embedding Models 40:52 Future Directions and Takeaways</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, embeddings</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/0f1e0b52/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/0f1e0b52/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#027 Building the database for AI, Multi-modal AI, Multi-modal Storage</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>10</itunes:episode>
      <podcast:episode>10</podcast:episode>
      <itunes:title>#027 Building the database for AI, Multi-modal AI, Multi-modal Storage</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">a0201f88-254b-427e-baa3-333b780e80bd</guid>
      <link>https://share.transistor.fm/s/b7dc57f9</link>
      <description>
        <![CDATA[<p>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.</p><p>Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.</p><p>"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."</p><p>‚ÄúWe're big believers in the composable data systems vision."</p><p>"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."</p><p>"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."</p><p>"LanceDB offers up to 1,000 times faster performance than Parquet."</p><p><br>Change She:</p><ul><li><a href="https://www.linkedin.com/in/changshe/">LinkedIn</a></li><li><a href="https://twitter.com/changhiskhan">X (Twitter)</a></li></ul><p>LanceDB:</p><ul><li><a href="https://twitter.com/lancedb">X (Twitter)</a></li><li><a href="https://github.com/lancedb/lancedb">GitHub</a></li><li><a href="https://lancedb.com/">Web</a></li><li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li><li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li></ul><p>Nicolay Gerold:</p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>00:00 Introduction to Multimodal Embeddings<br>00:26 Challenges in Storage and Serving<br>02:51 LanceDB: The Solution for Multimodal Data<br>04:25 Interview with Chang She: Origins and Vision<br>10:37 Technical Deep Dive: LanceDB and Rust<br>18:11 Innovations in Data Storage Formats<br>19:00 Optimizing Performance in Lakehouse Ecosystems<br>21:22 Future Use Cases for LanceDB<br>26:04 Building Effective Recommendation Systems<br>32:10 Exciting Applications and Future Directions</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.</p><p>Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.</p><p>"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."</p><p>‚ÄúWe're big believers in the composable data systems vision."</p><p>"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."</p><p>"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."</p><p>"LanceDB offers up to 1,000 times faster performance than Parquet."</p><p><br>Change She:</p><ul><li><a href="https://www.linkedin.com/in/changshe/">LinkedIn</a></li><li><a href="https://twitter.com/changhiskhan">X (Twitter)</a></li></ul><p>LanceDB:</p><ul><li><a href="https://twitter.com/lancedb">X (Twitter)</a></li><li><a href="https://github.com/lancedb/lancedb">GitHub</a></li><li><a href="https://lancedb.com/">Web</a></li><li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li><li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li></ul><p>Nicolay Gerold:</p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>00:00 Introduction to Multimodal Embeddings<br>00:26 Challenges in Storage and Serving<br>02:51 LanceDB: The Solution for Multimodal Data<br>04:25 Interview with Chang She: Origins and Vision<br>10:37 Technical Deep Dive: LanceDB and Rust<br>18:11 Innovations in Data Storage Formats<br>19:00 Optimizing Performance in Lakehouse Ecosystems<br>21:22 Future Use Cases for LanceDB<br>26:04 Building Effective Recommendation Systems<br>32:10 Exciting Applications and Future Directions</p>]]>
      </content:encoded>
      <pubDate>Wed, 23 Oct 2024 11:26:56 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/b7dc57f9/71626ad8.mp3" length="43137654" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/U0hOhP7Mv8MGSzSWd65JvcMOf8QCrB-4B5w4Qgnjmp8/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9hNDYw/NGRlZWJmMTc0MDdl/ZjNkMjFjMjY0ZWI5/M2Y4MC5wbmc.jpg"/>
      <itunes:duration>2694</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.</p><p>Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.</p><p>"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."</p><p>‚ÄúWe're big believers in the composable data systems vision."</p><p>"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."</p><p>"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."</p><p>"LanceDB offers up to 1,000 times faster performance than Parquet."</p><p><br>Change She:</p><ul><li><a href="https://www.linkedin.com/in/changshe/">LinkedIn</a></li><li><a href="https://twitter.com/changhiskhan">X (Twitter)</a></li></ul><p>LanceDB:</p><ul><li><a href="https://twitter.com/lancedb">X (Twitter)</a></li><li><a href="https://github.com/lancedb/lancedb">GitHub</a></li><li><a href="https://lancedb.com/">Web</a></li><li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li><li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li></ul><p>Nicolay Gerold:</p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>00:00 Introduction to Multimodal Embeddings<br>00:26 Challenges in Storage and Serving<br>02:51 LanceDB: The Solution for Multimodal Data<br>04:25 Interview with Chang She: Origins and Vision<br>10:37 Technical Deep Dive: LanceDB and Rust<br>18:11 Innovations in Data Storage Formats<br>19:00 Optimizing Performance in Lakehouse Ecosystems<br>21:22 Future Use Cases for LanceDB<br>26:04 Building Effective Recommendation Systems<br>32:10 Exciting Applications and Future Directions</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, llm, search, vector, multi-modal</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/b7dc57f9/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/b7dc57f9/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#026 Embedding Numbers, Categories, Locations, Images, Text, and The World </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>9</itunes:episode>
      <podcast:episode>9</podcast:episode>
      <itunes:title>#026 Embedding Numbers, Categories, Locations, Images, Text, and The World </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">3704de84-d17d-4635-afc5-db64071b85a8</guid>
      <link>https://share.transistor.fm/s/203316c7</link>
      <description>
        <![CDATA[<p>Today‚Äôs guest is M√≥r Kapronczay. M√≥r is the Head of ML at superlinked. Superlinked is a compute framework for your information retrieval and feature engineering systems, where they turn anything into embeddings.</p><p>When most people think about embeddings, they think about ada, openai.</p><p>You just take your text and throw it in there.</p><p>But that‚Äôs too crude.</p><p>OpenAI embeddings are trained on the internet.</p><p>But your data set (most likely) is not the internet.</p><p>You have different nuances.</p><p>And you have more than just text.</p><p>So why not use it.</p><p>Some highlights:</p><ol><li>Text Embeddings are Not a Magic Bullet</li></ol><p>‚û°Ô∏è Pouring everything into a text embedding model won't yield magical results ‚û°Ô∏è Language is lossy - it's a poor compression method for complex information</p><ol><li>Embedding Numerical Data</li></ol><p>‚û°Ô∏è Direct number embeddings don't work well for vector search ‚û°Ô∏è Consider projecting number ranges onto a quarter circle ‚û°Ô∏è Apply logarithmic transforms for skewed distributions</p><ol><li>Multi-Modal Embeddings</li></ol><p>‚û°Ô∏è Create separate vector parts for different data aspects ‚û°Ô∏è Normalize individual parts ‚û°Ô∏è Weight vector parts based on importance</p><p>A Multi-Vector approach can help you understand the contributions of each modality or embedding and give you an easier time to fine-tune your retrieval system without fine-tuning your embedding models by tuning your vector database like you would a search database (like Elastic).</p><p><strong>M√≥r Kapronczay</strong></p><ul><li><a href="https://www.linkedin.com/in/m%C3%B3r-kapronczay-49447692/?originalSubdomain=hu">LinkedIn</a></li><li><a href="https://www.superlinked.com/">Superlinked</a></li><li><a href="https://x.com/morkapronczay">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Embeddings 00:30 Beyond Text: Expanding Embedding Capabilities 02:09 Challenges and Innovations in Embedding Techniques 03:49 Unified Representations and Vector Computers 05:54 Embedding Complex Data Types 07:21 Recommender Systems and Interaction Data 08:59 Combining and Weighing Embeddings 14:58 Handling Numerical and Categorical Data 20:35 Optimizing Embedding Efficiency 22:46 Dynamic Weighting and Evaluation 24:35 Exploring AB Testing with Embeddings 25:08 Joint vs Separate Embedding Spaces 27:30 Understanding Embedding Dimensions 29:59 Libraries and Frameworks for Embeddings 32:08 Challenges in Embedding Models 33:03 Vector Database Connectors 34:09 Balancing Production and Updates 36:50 Future of Vector Search and Modalities 39:36 Building with Embeddings: Tips and Tricks 42:26 Concluding Thoughts and Next Steps</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today‚Äôs guest is M√≥r Kapronczay. M√≥r is the Head of ML at superlinked. Superlinked is a compute framework for your information retrieval and feature engineering systems, where they turn anything into embeddings.</p><p>When most people think about embeddings, they think about ada, openai.</p><p>You just take your text and throw it in there.</p><p>But that‚Äôs too crude.</p><p>OpenAI embeddings are trained on the internet.</p><p>But your data set (most likely) is not the internet.</p><p>You have different nuances.</p><p>And you have more than just text.</p><p>So why not use it.</p><p>Some highlights:</p><ol><li>Text Embeddings are Not a Magic Bullet</li></ol><p>‚û°Ô∏è Pouring everything into a text embedding model won't yield magical results ‚û°Ô∏è Language is lossy - it's a poor compression method for complex information</p><ol><li>Embedding Numerical Data</li></ol><p>‚û°Ô∏è Direct number embeddings don't work well for vector search ‚û°Ô∏è Consider projecting number ranges onto a quarter circle ‚û°Ô∏è Apply logarithmic transforms for skewed distributions</p><ol><li>Multi-Modal Embeddings</li></ol><p>‚û°Ô∏è Create separate vector parts for different data aspects ‚û°Ô∏è Normalize individual parts ‚û°Ô∏è Weight vector parts based on importance</p><p>A Multi-Vector approach can help you understand the contributions of each modality or embedding and give you an easier time to fine-tune your retrieval system without fine-tuning your embedding models by tuning your vector database like you would a search database (like Elastic).</p><p><strong>M√≥r Kapronczay</strong></p><ul><li><a href="https://www.linkedin.com/in/m%C3%B3r-kapronczay-49447692/?originalSubdomain=hu">LinkedIn</a></li><li><a href="https://www.superlinked.com/">Superlinked</a></li><li><a href="https://x.com/morkapronczay">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Embeddings 00:30 Beyond Text: Expanding Embedding Capabilities 02:09 Challenges and Innovations in Embedding Techniques 03:49 Unified Representations and Vector Computers 05:54 Embedding Complex Data Types 07:21 Recommender Systems and Interaction Data 08:59 Combining and Weighing Embeddings 14:58 Handling Numerical and Categorical Data 20:35 Optimizing Embedding Efficiency 22:46 Dynamic Weighting and Evaluation 24:35 Exploring AB Testing with Embeddings 25:08 Joint vs Separate Embedding Spaces 27:30 Understanding Embedding Dimensions 29:59 Libraries and Frameworks for Embeddings 32:08 Challenges in Embedding Models 33:03 Vector Database Connectors 34:09 Balancing Production and Updates 36:50 Future of Vector Search and Modalities 39:36 Building with Embeddings: Tips and Tricks 42:26 Concluding Thoughts and Next Steps</p>]]>
      </content:encoded>
      <pubDate>Thu, 10 Oct 2024 10:55:14 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/203316c7/b48af278.mp3" length="44899773" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/wvfQm-ZzvZU8FwVfln3uF87lWBpL3XwhPmiNUcff-Uo/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8xMzdh/OGY3MzM5ZGFiNzU2/OThjZDZiM2UzMTdj/ODcxMC5wbmc.jpg"/>
      <itunes:duration>2804</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today‚Äôs guest is M√≥r Kapronczay. M√≥r is the Head of ML at superlinked. Superlinked is a compute framework for your information retrieval and feature engineering systems, where they turn anything into embeddings.</p><p>When most people think about embeddings, they think about ada, openai.</p><p>You just take your text and throw it in there.</p><p>But that‚Äôs too crude.</p><p>OpenAI embeddings are trained on the internet.</p><p>But your data set (most likely) is not the internet.</p><p>You have different nuances.</p><p>And you have more than just text.</p><p>So why not use it.</p><p>Some highlights:</p><ol><li>Text Embeddings are Not a Magic Bullet</li></ol><p>‚û°Ô∏è Pouring everything into a text embedding model won't yield magical results ‚û°Ô∏è Language is lossy - it's a poor compression method for complex information</p><ol><li>Embedding Numerical Data</li></ol><p>‚û°Ô∏è Direct number embeddings don't work well for vector search ‚û°Ô∏è Consider projecting number ranges onto a quarter circle ‚û°Ô∏è Apply logarithmic transforms for skewed distributions</p><ol><li>Multi-Modal Embeddings</li></ol><p>‚û°Ô∏è Create separate vector parts for different data aspects ‚û°Ô∏è Normalize individual parts ‚û°Ô∏è Weight vector parts based on importance</p><p>A Multi-Vector approach can help you understand the contributions of each modality or embedding and give you an easier time to fine-tune your retrieval system without fine-tuning your embedding models by tuning your vector database like you would a search database (like Elastic).</p><p><strong>M√≥r Kapronczay</strong></p><ul><li><a href="https://www.linkedin.com/in/m%C3%B3r-kapronczay-49447692/?originalSubdomain=hu">LinkedIn</a></li><li><a href="https://www.superlinked.com/">Superlinked</a></li><li><a href="https://x.com/morkapronczay">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Embeddings 00:30 Beyond Text: Expanding Embedding Capabilities 02:09 Challenges and Innovations in Embedding Techniques 03:49 Unified Representations and Vector Computers 05:54 Embedding Complex Data Types 07:21 Recommender Systems and Interaction Data 08:59 Combining and Weighing Embeddings 14:58 Handling Numerical and Categorical Data 20:35 Optimizing Embedding Efficiency 22:46 Dynamic Weighting and Evaluation 24:35 Exploring AB Testing with Embeddings 25:08 Joint vs Separate Embedding Spaces 27:30 Understanding Embedding Dimensions 29:59 Libraries and Frameworks for Embeddings 32:08 Challenges in Embedding Models 33:03 Vector Database Connectors 34:09 Balancing Production and Updates 36:50 Future of Vector Search and Modalities 39:36 Building with Embeddings: Tips and Tricks 42:26 Concluding Thoughts and Next Steps</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, rag, embeddings</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/203316c7/transcript.json" type="application/json"/>
      <podcast:transcript url="https://share.transistor.fm/s/203316c7/transcript.vtt" type="text/vtt" rel="captions"/>
    </item>
    <item>
      <title>#025 Data Models to Remove Ambiguity from AI and Search </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>8</itunes:episode>
      <podcast:episode>8</podcast:episode>
      <itunes:title>#025 Data Models to Remove Ambiguity from AI and Search </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">621c5691-62f9-46c3-b4bc-b217745106c6</guid>
      <link>https://share.transistor.fm/s/4d35ec6d</link>
      <description>
        <![CDATA[<p>Today we have Jessica Talisman with us, who is working as an Information Architect at Adobe. She is (in my opinion) the expert on taxonomies and ontologies.</p><p>That‚Äôs what you will learn today in this episode of How AI Is Built. Taxonomies, ontologies, knowledge graphs.</p><p>Everyone is talking about them no-one knows how to build them.</p><p>But before we look into that, what are they good for in search?</p><p>Imagine a large corpus of academic papers. When a user searches for "machine learning in healthcare", the system can:</p><ul><li>Recognize "machine learning" as a subcategory of "artificial intelligence"</li><li>Identify "healthcare" as a broad field with subfields like "diagnostics" and "patient care"</li><li>We can use these to expand the query or narrow it down.</li><li>We can return results that include papers on "neural networks for medical imaging" or "predictive analytics in patient outcomes", even if these exact phrases weren't in the search query</li><li>We can also filter down and remove papers not tagged with AI that might just mention it in a side not.</li></ul><p>So we are building the plumbing, the necessary infrastructure for tagging, categorization, query expansion and relexation, filtering.</p><p>So how can we build them?</p><p>1Ô∏è‚É£ Start with Industry Standards ‚Ä¢ Leverage established taxonomies (e.g., Google, GS1, IAB) ‚Ä¢ Audit them for relevance to your project ‚Ä¢ Use as a foundation, not a final solution</p><p>2Ô∏è‚É£ Customize and Fill Gaps ‚Ä¢ Adapt industry taxonomies to your specific domain ‚Ä¢ Create a "coverage model" for your unique needs ‚Ä¢ Mine internal docs to identify domain-specific concepts</p><p>3Ô∏è‚É£ Follow Ontology Best Practices ‚Ä¢ Use clear, unique primary labels for each concept ‚Ä¢ Include definitions to avoid ambiguity ‚Ä¢ Provide context for each taxonomy node</p><p><strong>Jessica Talisman:</strong></p><ul><li><a href="https://www.linkedin.com/in/jmtalisman/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Taxonomies and Knowledge Graphs 02:03 Building the Foundation: Metadata to Knowledge Graphs 04:35 Industry Taxonomies and Coverage Models 06:32 Clustering and Labeling Techniques 11:00 Evaluating and Maintaining Taxonomies 31:41 Exploring Taxonomy Granularity 32:18 Differentiating Taxonomies for Experts and Users 33:35 Mapping and Equivalency in Taxonomies 34:02 Best Practices and Examples of Taxonomies 40:50 Building Multilingual Taxonomies 44:33 Creative Applications of Taxonomies 48:54 Overrated and Underappreciated Technologies 53:00 The Importance of Human Involvement in AI 53:57 Connecting with the Speaker 55:05 Final Thoughts and Takeaways</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today we have Jessica Talisman with us, who is working as an Information Architect at Adobe. She is (in my opinion) the expert on taxonomies and ontologies.</p><p>That‚Äôs what you will learn today in this episode of How AI Is Built. Taxonomies, ontologies, knowledge graphs.</p><p>Everyone is talking about them no-one knows how to build them.</p><p>But before we look into that, what are they good for in search?</p><p>Imagine a large corpus of academic papers. When a user searches for "machine learning in healthcare", the system can:</p><ul><li>Recognize "machine learning" as a subcategory of "artificial intelligence"</li><li>Identify "healthcare" as a broad field with subfields like "diagnostics" and "patient care"</li><li>We can use these to expand the query or narrow it down.</li><li>We can return results that include papers on "neural networks for medical imaging" or "predictive analytics in patient outcomes", even if these exact phrases weren't in the search query</li><li>We can also filter down and remove papers not tagged with AI that might just mention it in a side not.</li></ul><p>So we are building the plumbing, the necessary infrastructure for tagging, categorization, query expansion and relexation, filtering.</p><p>So how can we build them?</p><p>1Ô∏è‚É£ Start with Industry Standards ‚Ä¢ Leverage established taxonomies (e.g., Google, GS1, IAB) ‚Ä¢ Audit them for relevance to your project ‚Ä¢ Use as a foundation, not a final solution</p><p>2Ô∏è‚É£ Customize and Fill Gaps ‚Ä¢ Adapt industry taxonomies to your specific domain ‚Ä¢ Create a "coverage model" for your unique needs ‚Ä¢ Mine internal docs to identify domain-specific concepts</p><p>3Ô∏è‚É£ Follow Ontology Best Practices ‚Ä¢ Use clear, unique primary labels for each concept ‚Ä¢ Include definitions to avoid ambiguity ‚Ä¢ Provide context for each taxonomy node</p><p><strong>Jessica Talisman:</strong></p><ul><li><a href="https://www.linkedin.com/in/jmtalisman/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Taxonomies and Knowledge Graphs 02:03 Building the Foundation: Metadata to Knowledge Graphs 04:35 Industry Taxonomies and Coverage Models 06:32 Clustering and Labeling Techniques 11:00 Evaluating and Maintaining Taxonomies 31:41 Exploring Taxonomy Granularity 32:18 Differentiating Taxonomies for Experts and Users 33:35 Mapping and Equivalency in Taxonomies 34:02 Best Practices and Examples of Taxonomies 40:50 Building Multilingual Taxonomies 44:33 Creative Applications of Taxonomies 48:54 Overrated and Underappreciated Technologies 53:00 The Importance of Human Involvement in AI 53:57 Connecting with the Speaker 55:05 Final Thoughts and Takeaways</p>]]>
      </content:encoded>
      <pubDate>Fri, 04 Oct 2024 10:44:10 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/4d35ec6d/a394615f.mp3" length="56353529" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/F7qOOXcxdHDk0TalxEJ9imYqXQ0wrhA0CMoeA6xH9pM/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jZjg2/OTFhZTYzYTc5ZWM5/NjI0NzU2YmM5ODBi/MzJhNi5wbmc.jpg"/>
      <itunes:duration>3520</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today we have Jessica Talisman with us, who is working as an Information Architect at Adobe. She is (in my opinion) the expert on taxonomies and ontologies.</p><p>That‚Äôs what you will learn today in this episode of How AI Is Built. Taxonomies, ontologies, knowledge graphs.</p><p>Everyone is talking about them no-one knows how to build them.</p><p>But before we look into that, what are they good for in search?</p><p>Imagine a large corpus of academic papers. When a user searches for "machine learning in healthcare", the system can:</p><ul><li>Recognize "machine learning" as a subcategory of "artificial intelligence"</li><li>Identify "healthcare" as a broad field with subfields like "diagnostics" and "patient care"</li><li>We can use these to expand the query or narrow it down.</li><li>We can return results that include papers on "neural networks for medical imaging" or "predictive analytics in patient outcomes", even if these exact phrases weren't in the search query</li><li>We can also filter down and remove papers not tagged with AI that might just mention it in a side not.</li></ul><p>So we are building the plumbing, the necessary infrastructure for tagging, categorization, query expansion and relexation, filtering.</p><p>So how can we build them?</p><p>1Ô∏è‚É£ Start with Industry Standards ‚Ä¢ Leverage established taxonomies (e.g., Google, GS1, IAB) ‚Ä¢ Audit them for relevance to your project ‚Ä¢ Use as a foundation, not a final solution</p><p>2Ô∏è‚É£ Customize and Fill Gaps ‚Ä¢ Adapt industry taxonomies to your specific domain ‚Ä¢ Create a "coverage model" for your unique needs ‚Ä¢ Mine internal docs to identify domain-specific concepts</p><p>3Ô∏è‚É£ Follow Ontology Best Practices ‚Ä¢ Use clear, unique primary labels for each concept ‚Ä¢ Include definitions to avoid ambiguity ‚Ä¢ Provide context for each taxonomy node</p><p><strong>Jessica Talisman:</strong></p><ul><li><a href="https://www.linkedin.com/in/jmtalisman/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction to Taxonomies and Knowledge Graphs 02:03 Building the Foundation: Metadata to Knowledge Graphs 04:35 Industry Taxonomies and Coverage Models 06:32 Clustering and Labeling Techniques 11:00 Evaluating and Maintaining Taxonomies 31:41 Exploring Taxonomy Granularity 32:18 Differentiating Taxonomies for Experts and Users 33:35 Mapping and Equivalency in Taxonomies 34:02 Best Practices and Examples of Taxonomies 40:50 Building Multilingual Taxonomies 44:33 Creative Applications of Taxonomies 48:54 Overrated and Underappreciated Technologies 53:00 The Importance of Human Involvement in AI 53:57 Connecting with the Speaker 55:05 Final Thoughts and Takeaways</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, taxonomies, knowledge graphs</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/4d35ec6d/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/4d35ec6d/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#024 How ColPali is Changing Information Retrieval</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>7</itunes:episode>
      <podcast:episode>7</podcast:episode>
      <itunes:title>#024 How ColPali is Changing Information Retrieval</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">b517e266-06d9-471e-859d-e53e0796b767</guid>
      <link>https://youtu.be/FGt7JvbzFx8</link>
      <description>
        <![CDATA[<p>ColPali makes us rethink how we approach document processing.</p><p>ColPali revolutionizes visual document search by combining late interaction scoring with visual language models. This approach eliminates the need for extensive text extraction and preprocessing, handling messy real-world data more effectively than traditional methods.</p><p>In this episode, Jo Bergum, chief scientist at Vespa, shares his insights on how ColPali is changing the way we approach complex document formats like PDFs and HTML pages.</p><p>Introduction to ColPali:</p><ul><li>Combines late interaction scoring from Colbert with visual language model (PoliGemma)</li><li>Represents screenshots of documents as multi-vector representations</li><li>Enables searching across complex document formats (PDFs, HTML)</li><li>Eliminates need for extensive text extraction and preprocessing</li></ul><p>Advantages of ColPali:</p><ul><li>Handles messy, real-world data better than traditional methods</li><li>Considers both textual and visual elements in documents</li><li>Potential applications in various domains (finance, medical, legal)</li><li>Scalable to large document collections with proper optimization</li></ul><p><strong>Jo Bergum:</strong></p><ul><li><a href="https://www.linkedin.com/in/jo-bergum/?originalSubdomain=no">LinkedIn</a></li><li><a href="https://vespa.ai/">Vespa</a></li><li><a href="https://x.com/jobergum">X (Twitter)</a></li><li><a href="https://blog.vespa.ai/retrieval-with-vision-language-models-colpali/">PDF Retrieval with Vision Language Models</a></li><li><a href="https://blog.vespa.ai/scaling-colpali-to-billions/">Scaling ColPali to billions of PDFs with Vespa</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Messy Data in AI 01:19 Challenges in Search Systems 03:41 Understanding Representational Approaches 08:18 Dense vs Sparse Representations 19:49 Advanced Retrieval Models and ColPali 30:59 Exploring Image-Based AI Progress 32:25 Challenges and Innovations in OCR 33:45 Understanding ColPali and MaxSim 38:13 Scaling and Practical Applications of ColPali 44:01 Future Directions and Use Cases</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>ColPali makes us rethink how we approach document processing.</p><p>ColPali revolutionizes visual document search by combining late interaction scoring with visual language models. This approach eliminates the need for extensive text extraction and preprocessing, handling messy real-world data more effectively than traditional methods.</p><p>In this episode, Jo Bergum, chief scientist at Vespa, shares his insights on how ColPali is changing the way we approach complex document formats like PDFs and HTML pages.</p><p>Introduction to ColPali:</p><ul><li>Combines late interaction scoring from Colbert with visual language model (PoliGemma)</li><li>Represents screenshots of documents as multi-vector representations</li><li>Enables searching across complex document formats (PDFs, HTML)</li><li>Eliminates need for extensive text extraction and preprocessing</li></ul><p>Advantages of ColPali:</p><ul><li>Handles messy, real-world data better than traditional methods</li><li>Considers both textual and visual elements in documents</li><li>Potential applications in various domains (finance, medical, legal)</li><li>Scalable to large document collections with proper optimization</li></ul><p><strong>Jo Bergum:</strong></p><ul><li><a href="https://www.linkedin.com/in/jo-bergum/?originalSubdomain=no">LinkedIn</a></li><li><a href="https://vespa.ai/">Vespa</a></li><li><a href="https://x.com/jobergum">X (Twitter)</a></li><li><a href="https://blog.vespa.ai/retrieval-with-vision-language-models-colpali/">PDF Retrieval with Vision Language Models</a></li><li><a href="https://blog.vespa.ai/scaling-colpali-to-billions/">Scaling ColPali to billions of PDFs with Vespa</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Messy Data in AI 01:19 Challenges in Search Systems 03:41 Understanding Representational Approaches 08:18 Dense vs Sparse Representations 19:49 Advanced Retrieval Models and ColPali 30:59 Exploring Image-Based AI Progress 32:25 Challenges and Innovations in OCR 33:45 Understanding ColPali and MaxSim 38:13 Scaling and Practical Applications of ColPali 44:01 Future Directions and Use Cases</p>]]>
      </content:encoded>
      <pubDate>Fri, 27 Sep 2024 04:10:21 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/72655906/144d3916.mp3" length="52795437" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/eMV3Ig-yDPEDRwDvB06PwuukmCh_FeZbSERALq9mPbU/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8yM2I0/ZGZjYjdmNjk0NDZl/ZTNkOWRlYWMzZDhj/MTA2MS5wbmc.jpg"/>
      <itunes:duration>3297</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>ColPali makes us rethink how we approach document processing.</p><p>ColPali revolutionizes visual document search by combining late interaction scoring with visual language models. This approach eliminates the need for extensive text extraction and preprocessing, handling messy real-world data more effectively than traditional methods.</p><p>In this episode, Jo Bergum, chief scientist at Vespa, shares his insights on how ColPali is changing the way we approach complex document formats like PDFs and HTML pages.</p><p>Introduction to ColPali:</p><ul><li>Combines late interaction scoring from Colbert with visual language model (PoliGemma)</li><li>Represents screenshots of documents as multi-vector representations</li><li>Enables searching across complex document formats (PDFs, HTML)</li><li>Eliminates need for extensive text extraction and preprocessing</li></ul><p>Advantages of ColPali:</p><ul><li>Handles messy, real-world data better than traditional methods</li><li>Considers both textual and visual elements in documents</li><li>Potential applications in various domains (finance, medical, legal)</li><li>Scalable to large document collections with proper optimization</li></ul><p><strong>Jo Bergum:</strong></p><ul><li><a href="https://www.linkedin.com/in/jo-bergum/?originalSubdomain=no">LinkedIn</a></li><li><a href="https://vespa.ai/">Vespa</a></li><li><a href="https://x.com/jobergum">X (Twitter)</a></li><li><a href="https://blog.vespa.ai/retrieval-with-vision-language-models-colpali/">PDF Retrieval with Vision Language Models</a></li><li><a href="https://blog.vespa.ai/scaling-colpali-to-billions/">Scaling ColPali to billions of PDFs with Vespa</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Messy Data in AI 01:19 Challenges in Search Systems 03:41 Understanding Representational Approaches 08:18 Dense vs Sparse Representations 19:49 Advanced Retrieval Models and ColPali 30:59 Exploring Image-Based AI Progress 32:25 Challenges and Innovations in OCR 33:45 Understanding ColPali and MaxSim 38:13 Scaling and Practical Applications of ColPali 44:01 Future Directions and Use Cases</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, rag, embedding, colpali</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/72655906/transcript.vtt" type="text/vtt" rel="captions"/>
      <podcast:transcript url="https://share.transistor.fm/s/72655906/transcript.json" type="application/json"/>
    </item>
    <item>
      <title>#023 The Power of Rerankers in Modern Search</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>6</itunes:episode>
      <podcast:episode>6</podcast:episode>
      <itunes:title>#023 The Power of Rerankers in Modern Search</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">fb3af199-8c0d-4da7-8828-b405fd4cce98</guid>
      <link>https://share.transistor.fm/s/b7fd3017</link>
      <description>
        <![CDATA[<p>Today, we're talking to <strong>Aamir Shakir</strong>, the founder and baker at <a href="https://mixedbread.ai/">mixedbread.ai</a>, where he's building some of the best embedding and re-ranking models out there. We go into the world of rerankers, looking at how they can classify, deduplicate documents, prioritize LLM outputs, and delve into models like ColBERT.</p><p>We discuss:</p><ul><li>The role of rerankers in retrieval pipelines</li><li>Advantages of late interaction models like ColBERT for interpretability</li><li>Training rerankers vs. embedding models and their impact on performance</li><li>Incorporating metadata and context into rerankers for enhanced relevance</li><li>Creative applications of rerankers beyond traditional search</li><li>Challenges and future directions in the retrieval space</li></ul><p>Still not sure whether to listen? Here are some teasers:</p><ul><li>Rerankers can significantly boost your retrieval system's performance without overhauling your existing setup.</li><li>Late interaction models like ColBERT offer greater explainability by allowing token-level comparisons between queries and documents.</li><li>Training a reranker often yields a higher impact on retrieval performance than training an embedding model.</li><li>Incorporating metadata directly into rerankers enables nuanced search results based on factors like recency and pricing.</li><li>Rerankers aren't just for search‚Äîthey can be used for zero-shot classification, deduplication, and prioritizing outputs from large language models.</li><li>The future of retrieval may involve compound models capable of handling multiple modalities, offering a more unified approach to search.</li></ul><p><strong>Aamir Shakir:</strong></p><ul><li><a href="https://www.linkedin.com/in/aamir-shakir/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/aaxsh18">X (Twitter)</a></li><li><a href="https://www.mixedbread.ai/">Mixedbread.ai</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction and Overview 00:25 Understanding Rerankers 01:46 Maxsim and Token-Level Embeddings 02:40 Setting Thresholds and Similarity 03:19 Guest Introduction: Aamir Shakir 03:50 Training and Using Rerankers (Episode Start) 04:50 Challenges and Solutions in Reranking 08:03 Future of Retrieval and Recommendation 26:05 Multimodal Retrieval and Reranking 38:04 Conclusion and Takeaways</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today, we're talking to <strong>Aamir Shakir</strong>, the founder and baker at <a href="https://mixedbread.ai/">mixedbread.ai</a>, where he's building some of the best embedding and re-ranking models out there. We go into the world of rerankers, looking at how they can classify, deduplicate documents, prioritize LLM outputs, and delve into models like ColBERT.</p><p>We discuss:</p><ul><li>The role of rerankers in retrieval pipelines</li><li>Advantages of late interaction models like ColBERT for interpretability</li><li>Training rerankers vs. embedding models and their impact on performance</li><li>Incorporating metadata and context into rerankers for enhanced relevance</li><li>Creative applications of rerankers beyond traditional search</li><li>Challenges and future directions in the retrieval space</li></ul><p>Still not sure whether to listen? Here are some teasers:</p><ul><li>Rerankers can significantly boost your retrieval system's performance without overhauling your existing setup.</li><li>Late interaction models like ColBERT offer greater explainability by allowing token-level comparisons between queries and documents.</li><li>Training a reranker often yields a higher impact on retrieval performance than training an embedding model.</li><li>Incorporating metadata directly into rerankers enables nuanced search results based on factors like recency and pricing.</li><li>Rerankers aren't just for search‚Äîthey can be used for zero-shot classification, deduplication, and prioritizing outputs from large language models.</li><li>The future of retrieval may involve compound models capable of handling multiple modalities, offering a more unified approach to search.</li></ul><p><strong>Aamir Shakir:</strong></p><ul><li><a href="https://www.linkedin.com/in/aamir-shakir/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/aaxsh18">X (Twitter)</a></li><li><a href="https://www.mixedbread.ai/">Mixedbread.ai</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction and Overview 00:25 Understanding Rerankers 01:46 Maxsim and Token-Level Embeddings 02:40 Setting Thresholds and Similarity 03:19 Guest Introduction: Aamir Shakir 03:50 Training and Using Rerankers (Episode Start) 04:50 Challenges and Solutions in Reranking 08:03 Future of Retrieval and Recommendation 26:05 Multimodal Retrieval and Reranking 38:04 Conclusion and Takeaways</p>]]>
      </content:encoded>
      <pubDate>Thu, 26 Sep 2024 11:21:32 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/b7fd3017/b03ce20e.mp3" length="40824768" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/F8frvIjl7QtGjmbkotqqareL-2gGQiDWNDN9UujDKKU/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS81YTdh/YzJjZDJmZTI0MTQ5/ZTY0ODVhMDI2YzVh/MDRkMi5wbmc.jpg"/>
      <itunes:duration>2549</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today, we're talking to <strong>Aamir Shakir</strong>, the founder and baker at <a href="https://mixedbread.ai/">mixedbread.ai</a>, where he's building some of the best embedding and re-ranking models out there. We go into the world of rerankers, looking at how they can classify, deduplicate documents, prioritize LLM outputs, and delve into models like ColBERT.</p><p>We discuss:</p><ul><li>The role of rerankers in retrieval pipelines</li><li>Advantages of late interaction models like ColBERT for interpretability</li><li>Training rerankers vs. embedding models and their impact on performance</li><li>Incorporating metadata and context into rerankers for enhanced relevance</li><li>Creative applications of rerankers beyond traditional search</li><li>Challenges and future directions in the retrieval space</li></ul><p>Still not sure whether to listen? Here are some teasers:</p><ul><li>Rerankers can significantly boost your retrieval system's performance without overhauling your existing setup.</li><li>Late interaction models like ColBERT offer greater explainability by allowing token-level comparisons between queries and documents.</li><li>Training a reranker often yields a higher impact on retrieval performance than training an embedding model.</li><li>Incorporating metadata directly into rerankers enables nuanced search results based on factors like recency and pricing.</li><li>Rerankers aren't just for search‚Äîthey can be used for zero-shot classification, deduplication, and prioritizing outputs from large language models.</li><li>The future of retrieval may involve compound models capable of handling multiple modalities, offering a more unified approach to search.</li></ul><p><strong>Aamir Shakir:</strong></p><ul><li><a href="https://www.linkedin.com/in/aamir-shakir/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/aaxsh18">X (Twitter)</a></li><li><a href="https://www.mixedbread.ai/">Mixedbread.ai</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>00:00 Introduction and Overview 00:25 Understanding Rerankers 01:46 Maxsim and Token-Level Embeddings 02:40 Setting Thresholds and Similarity 03:19 Guest Introduction: Aamir Shakir 03:50 Training and Using Rerankers (Episode Start) 04:50 Challenges and Solutions in Reranking 08:03 Future of Retrieval and Recommendation 26:05 Multimodal Retrieval and Reranking 38:04 Conclusion and Takeaways</p>]]>
      </itunes:summary>
      <itunes:keywords>rag, reranker, search, embedding, retrieval</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/b7fd3017/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#022 The Limits of Embeddings, Out-of-Domain Data, Long Context, Finetuning (and How We're Fixing It)</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>5</itunes:episode>
      <podcast:episode>5</podcast:episode>
      <itunes:title>#022 The Limits of Embeddings, Out-of-Domain Data, Long Context, Finetuning (and How We're Fixing It)</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">8fef5aa0-d632-493f-b84e-c7c1b4a2496e</guid>
      <link>https://share.transistor.fm/s/fe7e36a8</link>
      <description>
        <![CDATA[<p>Text embeddings have limitations when it comes to handling long documents and out-of-domain data.</p><p>Today, we are talking to Nils Reimers. He is one of the researchers who kickstarted the field of dense embeddings, developed sentence transformers, started HuggingFace‚Äôs Neural Search team and now leads the development of search foundational models at Cohere. Tbh, he has too many accolades to count off here.</p><p>We talk about the main limitations of embeddings:</p><ul><li>Failing out of domain</li><li>Struggling with long documents</li><li>Very hard to debug</li><li>Hard to find formalize what actually is similar</li></ul><p>Are you still not sure whether to listen? Here are some teasers:</p><ul><li>Interpreting embeddings can be challenging, and current models are not easily explainable.</li><li>Fine-tuning is necessary to adapt embeddings to specific domains, but it requires careful consideration of the data and objectives.</li><li>Re-ranking is an effective approach to handle long documents and incorporate additional factors like recency and trustworthiness.</li><li>The future of embeddings lies in addressing scalability issues and exploring new research directions.</li></ul><p><strong>Nils Reimers:</strong></p><ul><li><a href="https://www.linkedin.com/in/reimersnils/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/Nils_Reimers">X (Twitter)</a></li><li><a href="https://www.nils-reimers.de/">Website</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>text embeddings, limitations, long documents, interpretation, fine-tuning, re-ranking, future research</p><p>00:00 Introduction and Guest Introduction 00:43 Early Work with BERT and Argument Mining 02:24 Evolution and Innovations in Embeddings 03:39 Constructive Learning and Hard Negatives 05:17 Training and Fine-Tuning Embedding Models 12:48 Challenges and Limitations of Embeddings 18:16 Adapting Embeddings to New Domains 22:41 Handling Long Documents and Re-Ranking 31:08 Combining Embeddings with Traditional ML 45:16 Conclusion and Upcoming Episodes</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Text embeddings have limitations when it comes to handling long documents and out-of-domain data.</p><p>Today, we are talking to Nils Reimers. He is one of the researchers who kickstarted the field of dense embeddings, developed sentence transformers, started HuggingFace‚Äôs Neural Search team and now leads the development of search foundational models at Cohere. Tbh, he has too many accolades to count off here.</p><p>We talk about the main limitations of embeddings:</p><ul><li>Failing out of domain</li><li>Struggling with long documents</li><li>Very hard to debug</li><li>Hard to find formalize what actually is similar</li></ul><p>Are you still not sure whether to listen? Here are some teasers:</p><ul><li>Interpreting embeddings can be challenging, and current models are not easily explainable.</li><li>Fine-tuning is necessary to adapt embeddings to specific domains, but it requires careful consideration of the data and objectives.</li><li>Re-ranking is an effective approach to handle long documents and incorporate additional factors like recency and trustworthiness.</li><li>The future of embeddings lies in addressing scalability issues and exploring new research directions.</li></ul><p><strong>Nils Reimers:</strong></p><ul><li><a href="https://www.linkedin.com/in/reimersnils/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/Nils_Reimers">X (Twitter)</a></li><li><a href="https://www.nils-reimers.de/">Website</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>text embeddings, limitations, long documents, interpretation, fine-tuning, re-ranking, future research</p><p>00:00 Introduction and Guest Introduction 00:43 Early Work with BERT and Argument Mining 02:24 Evolution and Innovations in Embeddings 03:39 Constructive Learning and Hard Negatives 05:17 Training and Fine-Tuning Embedding Models 12:48 Challenges and Limitations of Embeddings 18:16 Adapting Embeddings to New Domains 22:41 Handling Long Documents and Re-Ranking 31:08 Combining Embeddings with Traditional ML 45:16 Conclusion and Upcoming Episodes</p>]]>
      </content:encoded>
      <pubDate>Thu, 19 Sep 2024 10:59:14 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/fe7e36a8/159ed463.mp3" length="44304246" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/qTuTTAUTrJNttPUyx4voqtbs2iu6z82bbu61AZU6I3g/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9hOGU5/ZWQxZDQ1MTNkNjdh/NzBkZmNkOWM2NWNi/Y2E4MC5wbmc.jpg"/>
      <itunes:duration>2766</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Text embeddings have limitations when it comes to handling long documents and out-of-domain data.</p><p>Today, we are talking to Nils Reimers. He is one of the researchers who kickstarted the field of dense embeddings, developed sentence transformers, started HuggingFace‚Äôs Neural Search team and now leads the development of search foundational models at Cohere. Tbh, he has too many accolades to count off here.</p><p>We talk about the main limitations of embeddings:</p><ul><li>Failing out of domain</li><li>Struggling with long documents</li><li>Very hard to debug</li><li>Hard to find formalize what actually is similar</li></ul><p>Are you still not sure whether to listen? Here are some teasers:</p><ul><li>Interpreting embeddings can be challenging, and current models are not easily explainable.</li><li>Fine-tuning is necessary to adapt embeddings to specific domains, but it requires careful consideration of the data and objectives.</li><li>Re-ranking is an effective approach to handle long documents and incorporate additional factors like recency and trustworthiness.</li><li>The future of embeddings lies in addressing scalability issues and exploring new research directions.</li></ul><p><strong>Nils Reimers:</strong></p><ul><li><a href="https://www.linkedin.com/in/reimersnils/?originalSubdomain=de">LinkedIn</a></li><li><a href="https://x.com/Nils_Reimers">X (Twitter)</a></li><li><a href="https://www.nils-reimers.de/">Website</a></li><li><a href="https://cohere.com/">Cohere</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>text embeddings, limitations, long documents, interpretation, fine-tuning, re-ranking, future research</p><p>00:00 Introduction and Guest Introduction 00:43 Early Work with BERT and Argument Mining 02:24 Evolution and Innovations in Embeddings 03:39 Constructive Learning and Hard Negatives 05:17 Training and Fine-Tuning Embedding Models 12:48 Challenges and Limitations of Embeddings 18:16 Adapting Embeddings to New Domains 22:41 Handling Long Documents and Re-Ranking 31:08 Combining Embeddings with Traditional ML 45:16 Conclusion and Upcoming Episodes</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, embeddings, llm, search, rag</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#021 The Problems You Will Encounter With RAG At Scale And How To Prevent (or fix) Them</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>4</itunes:episode>
      <podcast:episode>4</podcast:episode>
      <itunes:title>#021 The Problems You Will Encounter With RAG At Scale And How To Prevent (or fix) Them</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">31422e24-e324-441f-b3b9-db8847601660</guid>
      <link>https://share.transistor.fm/s/f9a27478</link>
      <description>
        <![CDATA[<p>Hey! Welcome back.</p><p>Today we look at how we can get our RAG system ready for scale.</p><p>We discuss common problems and their solutions, when you introduce more users and more requests to your system.</p><p>For this we are joined by Nirant Kasliwal, the author of fastembed.</p><p>Nirant shares practical insights on metadata extraction, evaluation strategies, and emerging technologies like Colipali. This episode is a must-listen for anyone looking to level up their RAG implementations.</p><p>"Naive RAG has a lot of problems on the retrieval end and then there's a lot of problems on how LLMs look at these data points as well."</p><p>"The first 30 to 50% of gains are relatively quick. The rest 50% takes forever."</p><p>"You do not want to give the same answer about company's history to the co-founding CEO and the intern who has just joined."</p><p>"Embedding similarity is the signal on which you want to build your entire search is just not quite complete."</p><p><strong>Key insights:</strong></p><ul><li>Naive RAG often fails due to limitations of embeddings and LLMs' sensitivity to input ordering.</li><li>Query profiling and expansion:¬†<ul><li>Use clustering and tools like latent Scope to identify problematic query types</li><li>Expand queries offline and use parallel searches for better results</li></ul></li><li>Metadata extraction:¬†<ul><li>Extract temporal, entity, and other relevant information from queries</li><li>Use LLMs for extraction, with checks against libraries like Stanford NLP</li></ul></li><li>User personalization:¬†<ul><li>Include user role, access privileges, and conversation history</li><li>Adapt responses based on user expertise and readability scores</li></ul></li><li>Evaluation and improvement:¬†<ul><li>Create synthetic datasets and use real user feedback</li><li>Employ tools like DSPY for prompt engineering</li></ul></li><li>Advanced techniques:¬†<ul><li>Query routing based on type and urgency</li><li>Use smaller models (1-3B parameters) for easier iteration and error spotting</li><li>Implement error handling and cross-validation for extracted metadata</li></ul></li></ul><p><strong>Nirant Kasliwal:</strong></p><ul><li><a href="https://x.com/NirantK">X (Twitter)</a></li><li><a href="https://www.linkedin.com/in/nirant/">LinkedIn</a></li><li><a href="https://maven.com/nirantk/search-for-rag">Search in the LLM Era for AI Engineers (course)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>query understanding, AI-powered search, Lambda Mart, e-commerce ranking, networking, experts, recommendation, search</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Hey! Welcome back.</p><p>Today we look at how we can get our RAG system ready for scale.</p><p>We discuss common problems and their solutions, when you introduce more users and more requests to your system.</p><p>For this we are joined by Nirant Kasliwal, the author of fastembed.</p><p>Nirant shares practical insights on metadata extraction, evaluation strategies, and emerging technologies like Colipali. This episode is a must-listen for anyone looking to level up their RAG implementations.</p><p>"Naive RAG has a lot of problems on the retrieval end and then there's a lot of problems on how LLMs look at these data points as well."</p><p>"The first 30 to 50% of gains are relatively quick. The rest 50% takes forever."</p><p>"You do not want to give the same answer about company's history to the co-founding CEO and the intern who has just joined."</p><p>"Embedding similarity is the signal on which you want to build your entire search is just not quite complete."</p><p><strong>Key insights:</strong></p><ul><li>Naive RAG often fails due to limitations of embeddings and LLMs' sensitivity to input ordering.</li><li>Query profiling and expansion:¬†<ul><li>Use clustering and tools like latent Scope to identify problematic query types</li><li>Expand queries offline and use parallel searches for better results</li></ul></li><li>Metadata extraction:¬†<ul><li>Extract temporal, entity, and other relevant information from queries</li><li>Use LLMs for extraction, with checks against libraries like Stanford NLP</li></ul></li><li>User personalization:¬†<ul><li>Include user role, access privileges, and conversation history</li><li>Adapt responses based on user expertise and readability scores</li></ul></li><li>Evaluation and improvement:¬†<ul><li>Create synthetic datasets and use real user feedback</li><li>Employ tools like DSPY for prompt engineering</li></ul></li><li>Advanced techniques:¬†<ul><li>Query routing based on type and urgency</li><li>Use smaller models (1-3B parameters) for easier iteration and error spotting</li><li>Implement error handling and cross-validation for extracted metadata</li></ul></li></ul><p><strong>Nirant Kasliwal:</strong></p><ul><li><a href="https://x.com/NirantK">X (Twitter)</a></li><li><a href="https://www.linkedin.com/in/nirant/">LinkedIn</a></li><li><a href="https://maven.com/nirantk/search-for-rag">Search in the LLM Era for AI Engineers (course)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>query understanding, AI-powered search, Lambda Mart, e-commerce ranking, networking, experts, recommendation, search</p>]]>
      </content:encoded>
      <pubDate>Thu, 12 Sep 2024 10:46:25 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/f9a27478/3dda2101.mp3" length="48200111" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/rW3c2lGnbRYYSXKzgILHbagYdf13oAvgP9cb7rlGRWQ/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9hNjg4/ZWYzOGIyZGNiNmI3/YTQ2MzUyNzRjYjk2/NDRjYi5wbmc.jpg"/>
      <itunes:duration>3009</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Hey! Welcome back.</p><p>Today we look at how we can get our RAG system ready for scale.</p><p>We discuss common problems and their solutions, when you introduce more users and more requests to your system.</p><p>For this we are joined by Nirant Kasliwal, the author of fastembed.</p><p>Nirant shares practical insights on metadata extraction, evaluation strategies, and emerging technologies like Colipali. This episode is a must-listen for anyone looking to level up their RAG implementations.</p><p>"Naive RAG has a lot of problems on the retrieval end and then there's a lot of problems on how LLMs look at these data points as well."</p><p>"The first 30 to 50% of gains are relatively quick. The rest 50% takes forever."</p><p>"You do not want to give the same answer about company's history to the co-founding CEO and the intern who has just joined."</p><p>"Embedding similarity is the signal on which you want to build your entire search is just not quite complete."</p><p><strong>Key insights:</strong></p><ul><li>Naive RAG often fails due to limitations of embeddings and LLMs' sensitivity to input ordering.</li><li>Query profiling and expansion:¬†<ul><li>Use clustering and tools like latent Scope to identify problematic query types</li><li>Expand queries offline and use parallel searches for better results</li></ul></li><li>Metadata extraction:¬†<ul><li>Extract temporal, entity, and other relevant information from queries</li><li>Use LLMs for extraction, with checks against libraries like Stanford NLP</li></ul></li><li>User personalization:¬†<ul><li>Include user role, access privileges, and conversation history</li><li>Adapt responses based on user expertise and readability scores</li></ul></li><li>Evaluation and improvement:¬†<ul><li>Create synthetic datasets and use real user feedback</li><li>Employ tools like DSPY for prompt engineering</li></ul></li><li>Advanced techniques:¬†<ul><li>Query routing based on type and urgency</li><li>Use smaller models (1-3B parameters) for easier iteration and error spotting</li><li>Implement error handling and cross-validation for extracted metadata</li></ul></li></ul><p><strong>Nirant Kasliwal:</strong></p><ul><li><a href="https://x.com/NirantK">X (Twitter)</a></li><li><a href="https://www.linkedin.com/in/nirant/">LinkedIn</a></li><li><a href="https://maven.com/nirantk/search-for-rag">Search in the LLM Era for AI Engineers (course)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>query understanding, AI-powered search, Lambda Mart, e-commerce ranking, networking, experts, recommendation, search</p>]]>
      </itunes:summary>
      <itunes:keywords>llm, rag, search, embedding</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/f9a27478/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#020 The Evolution of Search, Finding Search Signals, GenAI Augmented Retrieval</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:title>#020 The Evolution of Search, Finding Search Signals, GenAI Augmented Retrieval</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">f8f781a5-3a21-4bc7-84a5-b96aee052c3a</guid>
      <link>https://share.transistor.fm/s/e29da3ea</link>
      <description>
        <![CDATA[<p>In this episode of How AI is Built, Nicolay Gerold interviews Doug Turnbull, a search engineer at Reddit and author on ‚ÄúRelevant Search‚Äù. They discuss how methods and technologies, including large language models (LLMs) and semantic search, contribute to relevant search results.</p><p>Key Highlights:</p><ul><li>Defining relevance is challenging and depends heavily on user intent and context</li><li>Combining multiple search techniques (keyword, semantic, etc.) in tiers can improve results</li><li>LLMs are emerging as a powerful tool for augmenting traditional search approaches</li><li>Operational concerns often drive architectural decisions in large-scale search systems</li><li>Underappreciated techniques like LambdaMART may see a resurgence</li></ul><p>Key Quotes:</p><p>"There's not like a perfect measure or definition of what a relevant search result is for a given application. There are a lot of really good proxies, and a lot of really good like things, but you can't just like blindly follow the one objective, if you want to build a good search product." - Doug Turnbull</p><p>"I think 10 years ago, what people would do is they would just put everything in Solr, Elasticsearch or whatever, and they would make the query to Elasticsearch pretty complicated to rank what they wanted... What I see people doing more and more these days is that they'll use each retrieval source as like an independent piece of infrastructure." - Doug Turnbull on the evolution of search architecture</p><p>"Honestly, I feel like that's a very practical and underappreciated thing. People talk about RAG and I talk, I call this GAR - generative AI augmented retrieval, so you're making search smarter with generative AI." - Doug Turnbull on using LLMs to enhance search</p><p>"LambdaMART and gradient boosted decision trees are really powerful, especially for when you're expressing your re-ranking as some kind of structured learning problem... I feel like we'll see that and like you're seeing papers now where people are like finding new ways of making BM25 better." - Doug Turnbull on underappreciated techniques</p><p><strong>Doug Turnbull</strong></p><ul><li><a href="https://www.linkedin.com/in/softwaredoug/">LinkedIn</a></li><li><a href="https://x.com/softwaredoug">X (Twitter)</a></li><li><a href="https://softwaredoug.com/">Web</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction and Guest Introduction 00:52 Understanding Relevant Search Results 01:18 Search Behavior on Social Media 02:14 Challenges in Defining Relevance 05:12 Query Understanding and Ranking Signals 10:57 Evolution of Search Technologies 15:15 Combining Search Techniques 21:49 Leveraging LLMs and Embeddings 25:49 Operational Considerations in Search Systems 39:09 Concluding Thoughts and Future Directions</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode of How AI is Built, Nicolay Gerold interviews Doug Turnbull, a search engineer at Reddit and author on ‚ÄúRelevant Search‚Äù. They discuss how methods and technologies, including large language models (LLMs) and semantic search, contribute to relevant search results.</p><p>Key Highlights:</p><ul><li>Defining relevance is challenging and depends heavily on user intent and context</li><li>Combining multiple search techniques (keyword, semantic, etc.) in tiers can improve results</li><li>LLMs are emerging as a powerful tool for augmenting traditional search approaches</li><li>Operational concerns often drive architectural decisions in large-scale search systems</li><li>Underappreciated techniques like LambdaMART may see a resurgence</li></ul><p>Key Quotes:</p><p>"There's not like a perfect measure or definition of what a relevant search result is for a given application. There are a lot of really good proxies, and a lot of really good like things, but you can't just like blindly follow the one objective, if you want to build a good search product." - Doug Turnbull</p><p>"I think 10 years ago, what people would do is they would just put everything in Solr, Elasticsearch or whatever, and they would make the query to Elasticsearch pretty complicated to rank what they wanted... What I see people doing more and more these days is that they'll use each retrieval source as like an independent piece of infrastructure." - Doug Turnbull on the evolution of search architecture</p><p>"Honestly, I feel like that's a very practical and underappreciated thing. People talk about RAG and I talk, I call this GAR - generative AI augmented retrieval, so you're making search smarter with generative AI." - Doug Turnbull on using LLMs to enhance search</p><p>"LambdaMART and gradient boosted decision trees are really powerful, especially for when you're expressing your re-ranking as some kind of structured learning problem... I feel like we'll see that and like you're seeing papers now where people are like finding new ways of making BM25 better." - Doug Turnbull on underappreciated techniques</p><p><strong>Doug Turnbull</strong></p><ul><li><a href="https://www.linkedin.com/in/softwaredoug/">LinkedIn</a></li><li><a href="https://x.com/softwaredoug">X (Twitter)</a></li><li><a href="https://softwaredoug.com/">Web</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction and Guest Introduction 00:52 Understanding Relevant Search Results 01:18 Search Behavior on Social Media 02:14 Challenges in Defining Relevance 05:12 Query Understanding and Ranking Signals 10:57 Evolution of Search Technologies 15:15 Combining Search Techniques 21:49 Leveraging LLMs and Embeddings 25:49 Operational Considerations in Search Systems 39:09 Concluding Thoughts and Future Directions</p>]]>
      </content:encoded>
      <pubDate>Thu, 05 Sep 2024 10:47:02 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/e29da3ea/adbca54a.mp3" length="50227946" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/O9QAxhZYxLGDhp6nBlTg8GmLEFHNRWEwbEbdCo9MzSg/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jZjc3/ZDFkNTU5MTYzMTE5/OGJhMDE2YWRlOWI1/NjhjMC5wbmc.jpg"/>
      <itunes:duration>3136</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>In this episode of How AI is Built, Nicolay Gerold interviews Doug Turnbull, a search engineer at Reddit and author on ‚ÄúRelevant Search‚Äù. They discuss how methods and technologies, including large language models (LLMs) and semantic search, contribute to relevant search results.</p><p>Key Highlights:</p><ul><li>Defining relevance is challenging and depends heavily on user intent and context</li><li>Combining multiple search techniques (keyword, semantic, etc.) in tiers can improve results</li><li>LLMs are emerging as a powerful tool for augmenting traditional search approaches</li><li>Operational concerns often drive architectural decisions in large-scale search systems</li><li>Underappreciated techniques like LambdaMART may see a resurgence</li></ul><p>Key Quotes:</p><p>"There's not like a perfect measure or definition of what a relevant search result is for a given application. There are a lot of really good proxies, and a lot of really good like things, but you can't just like blindly follow the one objective, if you want to build a good search product." - Doug Turnbull</p><p>"I think 10 years ago, what people would do is they would just put everything in Solr, Elasticsearch or whatever, and they would make the query to Elasticsearch pretty complicated to rank what they wanted... What I see people doing more and more these days is that they'll use each retrieval source as like an independent piece of infrastructure." - Doug Turnbull on the evolution of search architecture</p><p>"Honestly, I feel like that's a very practical and underappreciated thing. People talk about RAG and I talk, I call this GAR - generative AI augmented retrieval, so you're making search smarter with generative AI." - Doug Turnbull on using LLMs to enhance search</p><p>"LambdaMART and gradient boosted decision trees are really powerful, especially for when you're expressing your re-ranking as some kind of structured learning problem... I feel like we'll see that and like you're seeing papers now where people are like finding new ways of making BM25 better." - Doug Turnbull on underappreciated techniques</p><p><strong>Doug Turnbull</strong></p><ul><li><a href="https://www.linkedin.com/in/softwaredoug/">LinkedIn</a></li><li><a href="https://x.com/softwaredoug">X (Twitter)</a></li><li><a href="https://softwaredoug.com/">Web</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction and Guest Introduction 00:52 Understanding Relevant Search Results 01:18 Search Behavior on Social Media 02:14 Challenges in Defining Relevance 05:12 Query Understanding and Ranking Signals 10:57 Evolution of Search Technologies 15:15 Combining Search Techniques 21:49 Leveraging LLMs and Embeddings 25:49 Operational Considerations in Search Systems 39:09 Concluding Thoughts and Future Directions</p>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, semantic search, rag, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/e29da3ea/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#019 Data-driven Search Optimization, Analysing Relevance</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>2</itunes:episode>
      <podcast:episode>2</podcast:episode>
      <itunes:title>#019 Data-driven Search Optimization, Analysing Relevance</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">e8e09481-303a-4258-a421-15f9d1048a1e</guid>
      <link>https://share.transistor.fm/s/3c73cd4c</link>
      <description>
        <![CDATA[<p>In this episode, we talk data-driven search optimizations with Charlie Hull.</p><p>Charlie is a search expert from Open Source Connections. He has built Flax, one of the leading open source search companies in the UK, has written ‚ÄúSearching the Enterprise‚Äù, and is one of the main voices on data-driven search.</p><p>We discuss strategies to improve search systems quantitatively and much more.</p><p>Key Points:</p><ol><li>Relevance in search is subjective and context-dependent, making it challenging to measure consistently.</li><li>Common mistakes in assessing search systems include overemphasizing processing speed and relying solely on user complaints.</li><li>Three main methods to measure search system performance:¬†<ul><li>Human evaluation</li><li>User interaction data analysis</li><li>AI-assisted judgment (with caution)</li></ul></li><li>Importance of balancing business objectives with user needs when optimizing search results.</li><li>Technical components for assessing search systems:¬†<ul><li>Query logs analysis</li><li>Source data quality examination</li><li>Test queries and cases setup</li></ul></li></ol><p><strong>Resources mentioned:</strong></p><ul><li><a href="https://quepid.com/">Quepid</a>: Open-source tool for search quality testing</li><li><a href="https://haystackconf.com/">Haystack conference</a>: Upcoming event in Berlin (September 30 - October 1)</li><li><a href="https://opensourceconnections.com/blog/2021/07/06/building-the-search-community-with-relevance-slack/">Relevance Slack community</a></li><li><a href="https://opensourceconnections.com/">OpenSource Connections</a></li></ul><p><strong>Charlie Hull:</strong></p><ul><li><a href="https://www.linkedin.com/in/charliehullsearch/">LinkedIn</a></li><li><a href="https://x.com/FlaxSearch">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>search results, search systems, assessing, evaluation, improvement, data quality, user behavior, proactive, test dataset, search engine optimization, SEO, search quality, metadata, query classification, user intent, search results, metrics, business objectives, user objectives, experimentation, continuous improvement, data modeling, embeddings, machine learning, information retrieval</p><p>00:00 Introduction<br>01:35 Challenges in Measuring Search Relevance<br>02:19 Common Mistakes in Search System Assessment<br>03:22 Methods to Measure Search System Performance<br>04:28 Human Evaluation in Search Systems<br>05:18 Leveraging User Interaction Data<br>06:04 Implementing AI for Search Evaluation<br>09:14 Technical Components for Assessing Search Systems<br>12:07 Improving Search Quality Through Data Analysis<br>17:16 Proactive Search System Monitoring<br>24:26 Balancing Business and User Objectives in Search<br>25:08 Search Metrics and KPIs: A Contract Between Teams<br>26:56 The Role of Recency and Popularity in Search Algorithms<br>28:56 Experimentation: The Key to Optimizing Search<br>30:57 Offline Search Labs and A/B Testing<br>34:05 Simple Levers to Improve Search<br>37:38 Data Modeling and Its Importance in Search<br>43:29 Combining Keyword and Vector Search<br>44:24 Bridging the Gap Between Machine Learning and Information Retrieval<br>47:13 Closing Remarks and Contact Information</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode, we talk data-driven search optimizations with Charlie Hull.</p><p>Charlie is a search expert from Open Source Connections. He has built Flax, one of the leading open source search companies in the UK, has written ‚ÄúSearching the Enterprise‚Äù, and is one of the main voices on data-driven search.</p><p>We discuss strategies to improve search systems quantitatively and much more.</p><p>Key Points:</p><ol><li>Relevance in search is subjective and context-dependent, making it challenging to measure consistently.</li><li>Common mistakes in assessing search systems include overemphasizing processing speed and relying solely on user complaints.</li><li>Three main methods to measure search system performance:¬†<ul><li>Human evaluation</li><li>User interaction data analysis</li><li>AI-assisted judgment (with caution)</li></ul></li><li>Importance of balancing business objectives with user needs when optimizing search results.</li><li>Technical components for assessing search systems:¬†<ul><li>Query logs analysis</li><li>Source data quality examination</li><li>Test queries and cases setup</li></ul></li></ol><p><strong>Resources mentioned:</strong></p><ul><li><a href="https://quepid.com/">Quepid</a>: Open-source tool for search quality testing</li><li><a href="https://haystackconf.com/">Haystack conference</a>: Upcoming event in Berlin (September 30 - October 1)</li><li><a href="https://opensourceconnections.com/blog/2021/07/06/building-the-search-community-with-relevance-slack/">Relevance Slack community</a></li><li><a href="https://opensourceconnections.com/">OpenSource Connections</a></li></ul><p><strong>Charlie Hull:</strong></p><ul><li><a href="https://www.linkedin.com/in/charliehullsearch/">LinkedIn</a></li><li><a href="https://x.com/FlaxSearch">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>search results, search systems, assessing, evaluation, improvement, data quality, user behavior, proactive, test dataset, search engine optimization, SEO, search quality, metadata, query classification, user intent, search results, metrics, business objectives, user objectives, experimentation, continuous improvement, data modeling, embeddings, machine learning, information retrieval</p><p>00:00 Introduction<br>01:35 Challenges in Measuring Search Relevance<br>02:19 Common Mistakes in Search System Assessment<br>03:22 Methods to Measure Search System Performance<br>04:28 Human Evaluation in Search Systems<br>05:18 Leveraging User Interaction Data<br>06:04 Implementing AI for Search Evaluation<br>09:14 Technical Components for Assessing Search Systems<br>12:07 Improving Search Quality Through Data Analysis<br>17:16 Proactive Search System Monitoring<br>24:26 Balancing Business and User Objectives in Search<br>25:08 Search Metrics and KPIs: A Contract Between Teams<br>26:56 The Role of Recency and Popularity in Search Algorithms<br>28:56 Experimentation: The Key to Optimizing Search<br>30:57 Offline Search Labs and A/B Testing<br>34:05 Simple Levers to Improve Search<br>37:38 Data Modeling and Its Importance in Search<br>43:29 Combining Keyword and Vector Search<br>44:24 Bridging the Gap Between Machine Learning and Information Retrieval<br>47:13 Closing Remarks and Contact Information</p>]]>
      </content:encoded>
      <pubDate>Fri, 30 Aug 2024 11:05:19 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/3c73cd4c/e471bfa6.mp3" length="49228344" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/qheJCLwfvKQH-nOAPwlHJYCRTAW1W5IcopxsW3QJgo4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8yMWFj/MDYzOGNhZDVlYTUz/NWRjZmMxYWI1OTA5/YmVlOC5wbmc.jpg"/>
      <itunes:duration>3074</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>In this episode, we talk data-driven search optimizations with Charlie Hull.</p><p>Charlie is a search expert from Open Source Connections. He has built Flax, one of the leading open source search companies in the UK, has written ‚ÄúSearching the Enterprise‚Äù, and is one of the main voices on data-driven search.</p><p>We discuss strategies to improve search systems quantitatively and much more.</p><p>Key Points:</p><ol><li>Relevance in search is subjective and context-dependent, making it challenging to measure consistently.</li><li>Common mistakes in assessing search systems include overemphasizing processing speed and relying solely on user complaints.</li><li>Three main methods to measure search system performance:¬†<ul><li>Human evaluation</li><li>User interaction data analysis</li><li>AI-assisted judgment (with caution)</li></ul></li><li>Importance of balancing business objectives with user needs when optimizing search results.</li><li>Technical components for assessing search systems:¬†<ul><li>Query logs analysis</li><li>Source data quality examination</li><li>Test queries and cases setup</li></ul></li></ol><p><strong>Resources mentioned:</strong></p><ul><li><a href="https://quepid.com/">Quepid</a>: Open-source tool for search quality testing</li><li><a href="https://haystackconf.com/">Haystack conference</a>: Upcoming event in Berlin (September 30 - October 1)</li><li><a href="https://opensourceconnections.com/blog/2021/07/06/building-the-search-community-with-relevance-slack/">Relevance Slack community</a></li><li><a href="https://opensourceconnections.com/">OpenSource Connections</a></li></ul><p><strong>Charlie Hull:</strong></p><ul><li><a href="https://www.linkedin.com/in/charliehullsearch/">LinkedIn</a></li><li><a href="https://x.com/FlaxSearch">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>search results, search systems, assessing, evaluation, improvement, data quality, user behavior, proactive, test dataset, search engine optimization, SEO, search quality, metadata, query classification, user intent, search results, metrics, business objectives, user objectives, experimentation, continuous improvement, data modeling, embeddings, machine learning, information retrieval</p><p>00:00 Introduction<br>01:35 Challenges in Measuring Search Relevance<br>02:19 Common Mistakes in Search System Assessment<br>03:22 Methods to Measure Search System Performance<br>04:28 Human Evaluation in Search Systems<br>05:18 Leveraging User Interaction Data<br>06:04 Implementing AI for Search Evaluation<br>09:14 Technical Components for Assessing Search Systems<br>12:07 Improving Search Quality Through Data Analysis<br>17:16 Proactive Search System Monitoring<br>24:26 Balancing Business and User Objectives in Search<br>25:08 Search Metrics and KPIs: A Contract Between Teams<br>26:56 The Role of Recency and Popularity in Search Algorithms<br>28:56 Experimentation: The Key to Optimizing Search<br>30:57 Offline Search Labs and A/B Testing<br>34:05 Simple Levers to Improve Search<br>37:38 Data Modeling and Its Importance in Search<br>43:29 Combining Keyword and Vector Search<br>44:24 Bridging the Gap Between Machine Learning and Information Retrieval<br>47:13 Closing Remarks and Contact Information</p>]]>
      </itunes:summary>
      <itunes:keywords>search, ai, elastic</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/3c73cd4c/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#018 Query Understanding: Doing The Work Before The Query Hits The Database </title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:title>#018 Query Understanding: Doing The Work Before The Query Hits The Database </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">796732ce-6697-477a-8f80-9c856f3cc04b</guid>
      <link>https://share.transistor.fm/s/01fedbd0</link>
      <description>
        <![CDATA[<p>Welcome back to How AI Is Built.¬†</p><p>We have got a very special episode to kick off season two.¬†</p><p>Daniel Tunkelang is a search consultant currently working with Algolia. He is a leader in the field of information retrieval, recommender systems, and AI-powered search. He worked for Canva, Algolia, Cisco, Gartner, Handshake, to pick a few.¬†</p><p>His core focus is query understanding. ¬†</p><p>**Query understanding is about focusing less on the results and more on the query.** The query of the user is the first-class citizen. It is about figuring out what the user wants and than finding, scoring, and ranking results based on it. So most of the work happens before you hit the database.¬†</p><p>**Key Takeaways:**</p><p>- The "bag of documents" model for queries and "bag of queries" model for documents are useful approaches for representing queries and documents in search systems.<br>- Query specificity is an important factor in query understanding. It can be measured using cosine similarity between query vectors and document vectors.<br>- Query classification into broad categories (e.g., product taxonomy) is a high-leverage technique for improving search relevance and can act as a guardrail for query expansion and relaxation.<br>- Large Language Models (LLMs) can be useful for search, but simpler techniques like query similarity using embeddings can often solve many problems without the complexity and cost of full LLM implementations.<br>- Offline processing to enhance document representations (e.g., filling in missing metadata, inferring categories) can significantly improve search quality.</p><p>**Daniel Tunkelang**</p><p>- [LinkedIn](https://www.linkedin.com/in/dtunkelang/)<br>- [Medium](https://queryunderstanding.com/)</p><p>**Nicolay Gerold:**</p><p>- [‚Å†LinkedIn‚Å†](https://www.linkedin.com/in/nicolay-gerold/)<br>- [‚Å†X (Twitter)](https://twitter.com/nicolaygerold)<br>- [Substack](https://nicolaygerold.substack.com/)</p><p>Query understanding, search relevance, bag of documents, bag of queries, query specificity, query classification, named entity recognition, pre-retrieval processing, caching, large language models (LLMs), embeddings, offline processing, metadata enhancement, FastText, MiniLM, sentence transformers, visualization, precision, recall</p><p>[00:00:00] 1. Introduction to Query Understanding</p><ul><li>Definition and importance in search systems</li><li>Evolution of query understanding techniques</li></ul><p>[00:05:30] 2. Query Representation Models</p><ul><li>The "bag of documents" model for queries</li><li>The "bag of queries" model for documents</li><li>Advantages of holistic query representation</li></ul><p>[00:12:00] 3. Query Specificity and Classification</p><ul><li>Measuring query specificity using cosine similarity</li><li>Importance of query classification in search relevance</li><li>Implementing and leveraging query classifiers</li></ul><p>[00:19:30] 4. Named Entity Recognition in Query Understanding</p><ul><li>Role of NER in query processing</li><li>Challenges with unique or tail entities</li></ul><p>[00:24:00] 5. Pre-Retrieval Query Processing</p><ul><li>Importance of early-stage query analysis</li><li>Balancing computational resources and impact</li></ul><p>[00:28:30] 6. Performance Optimization Techniques</p><ul><li>Caching strategies for query understanding</li><li>Offline processing for document enhancement</li></ul><p>[00:33:00] 7. Advanced Techniques: Embeddings and Language Models</p><ul><li>Using embeddings for query similarity</li><li>Role of Large Language Models (LLMs) in search</li><li>When to use simpler techniques vs. complex models</li></ul><p>[00:39:00] 8. Practical Implementation Strategies</p><ul><li>Starting points for engineers new to query understanding</li><li>Tools and libraries for query understanding (FastText, MiniLM, etc.)</li><li>Balancing precision and recall in search systems</li></ul><p>[00:44:00] 9. Visualization and Analysis of Query Spaces</p><ul><li>Discussion on t-SNE, UMAP, and other visualization techniques</li><li>Limitations and alternatives to embedding visualizations</li></ul><p>[00:47:00] 10. Future Directions and Closing Thoughts - Emerging trends in query understanding - Key takeaways for search system engineers</p><p>[00:53:00] End of Episode</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Welcome back to How AI Is Built.¬†</p><p>We have got a very special episode to kick off season two.¬†</p><p>Daniel Tunkelang is a search consultant currently working with Algolia. He is a leader in the field of information retrieval, recommender systems, and AI-powered search. He worked for Canva, Algolia, Cisco, Gartner, Handshake, to pick a few.¬†</p><p>His core focus is query understanding. ¬†</p><p>**Query understanding is about focusing less on the results and more on the query.** The query of the user is the first-class citizen. It is about figuring out what the user wants and than finding, scoring, and ranking results based on it. So most of the work happens before you hit the database.¬†</p><p>**Key Takeaways:**</p><p>- The "bag of documents" model for queries and "bag of queries" model for documents are useful approaches for representing queries and documents in search systems.<br>- Query specificity is an important factor in query understanding. It can be measured using cosine similarity between query vectors and document vectors.<br>- Query classification into broad categories (e.g., product taxonomy) is a high-leverage technique for improving search relevance and can act as a guardrail for query expansion and relaxation.<br>- Large Language Models (LLMs) can be useful for search, but simpler techniques like query similarity using embeddings can often solve many problems without the complexity and cost of full LLM implementations.<br>- Offline processing to enhance document representations (e.g., filling in missing metadata, inferring categories) can significantly improve search quality.</p><p>**Daniel Tunkelang**</p><p>- [LinkedIn](https://www.linkedin.com/in/dtunkelang/)<br>- [Medium](https://queryunderstanding.com/)</p><p>**Nicolay Gerold:**</p><p>- [‚Å†LinkedIn‚Å†](https://www.linkedin.com/in/nicolay-gerold/)<br>- [‚Å†X (Twitter)](https://twitter.com/nicolaygerold)<br>- [Substack](https://nicolaygerold.substack.com/)</p><p>Query understanding, search relevance, bag of documents, bag of queries, query specificity, query classification, named entity recognition, pre-retrieval processing, caching, large language models (LLMs), embeddings, offline processing, metadata enhancement, FastText, MiniLM, sentence transformers, visualization, precision, recall</p><p>[00:00:00] 1. Introduction to Query Understanding</p><ul><li>Definition and importance in search systems</li><li>Evolution of query understanding techniques</li></ul><p>[00:05:30] 2. Query Representation Models</p><ul><li>The "bag of documents" model for queries</li><li>The "bag of queries" model for documents</li><li>Advantages of holistic query representation</li></ul><p>[00:12:00] 3. Query Specificity and Classification</p><ul><li>Measuring query specificity using cosine similarity</li><li>Importance of query classification in search relevance</li><li>Implementing and leveraging query classifiers</li></ul><p>[00:19:30] 4. Named Entity Recognition in Query Understanding</p><ul><li>Role of NER in query processing</li><li>Challenges with unique or tail entities</li></ul><p>[00:24:00] 5. Pre-Retrieval Query Processing</p><ul><li>Importance of early-stage query analysis</li><li>Balancing computational resources and impact</li></ul><p>[00:28:30] 6. Performance Optimization Techniques</p><ul><li>Caching strategies for query understanding</li><li>Offline processing for document enhancement</li></ul><p>[00:33:00] 7. Advanced Techniques: Embeddings and Language Models</p><ul><li>Using embeddings for query similarity</li><li>Role of Large Language Models (LLMs) in search</li><li>When to use simpler techniques vs. complex models</li></ul><p>[00:39:00] 8. Practical Implementation Strategies</p><ul><li>Starting points for engineers new to query understanding</li><li>Tools and libraries for query understanding (FastText, MiniLM, etc.)</li><li>Balancing precision and recall in search systems</li></ul><p>[00:44:00] 9. Visualization and Analysis of Query Spaces</p><ul><li>Discussion on t-SNE, UMAP, and other visualization techniques</li><li>Limitations and alternatives to embedding visualizations</li></ul><p>[00:47:00] 10. Future Directions and Closing Thoughts - Emerging trends in query understanding - Key takeaways for search system engineers</p><p>[00:53:00] End of Episode</p>]]>
      </content:encoded>
      <pubDate>Thu, 15 Aug 2024 11:23:27 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/01fedbd0/9ddc39d1.mp3" length="50960795" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/2zgDVYpWyKuoOMklbO-1d8PQIvEi3UpK1wmNqi83Olk/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS82MmJl/NzAyMjY0NWQzZWU3/OTE3M2Y1ZjMzMzdl/NGQxMC5wbmc.jpg"/>
      <itunes:duration>3182</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Welcome back to How AI Is Built.¬†</p><p>We have got a very special episode to kick off season two.¬†</p><p>Daniel Tunkelang is a search consultant currently working with Algolia. He is a leader in the field of information retrieval, recommender systems, and AI-powered search. He worked for Canva, Algolia, Cisco, Gartner, Handshake, to pick a few.¬†</p><p>His core focus is query understanding. ¬†</p><p>**Query understanding is about focusing less on the results and more on the query.** The query of the user is the first-class citizen. It is about figuring out what the user wants and than finding, scoring, and ranking results based on it. So most of the work happens before you hit the database.¬†</p><p>**Key Takeaways:**</p><p>- The "bag of documents" model for queries and "bag of queries" model for documents are useful approaches for representing queries and documents in search systems.<br>- Query specificity is an important factor in query understanding. It can be measured using cosine similarity between query vectors and document vectors.<br>- Query classification into broad categories (e.g., product taxonomy) is a high-leverage technique for improving search relevance and can act as a guardrail for query expansion and relaxation.<br>- Large Language Models (LLMs) can be useful for search, but simpler techniques like query similarity using embeddings can often solve many problems without the complexity and cost of full LLM implementations.<br>- Offline processing to enhance document representations (e.g., filling in missing metadata, inferring categories) can significantly improve search quality.</p><p>**Daniel Tunkelang**</p><p>- [LinkedIn](https://www.linkedin.com/in/dtunkelang/)<br>- [Medium](https://queryunderstanding.com/)</p><p>**Nicolay Gerold:**</p><p>- [‚Å†LinkedIn‚Å†](https://www.linkedin.com/in/nicolay-gerold/)<br>- [‚Å†X (Twitter)](https://twitter.com/nicolaygerold)<br>- [Substack](https://nicolaygerold.substack.com/)</p><p>Query understanding, search relevance, bag of documents, bag of queries, query specificity, query classification, named entity recognition, pre-retrieval processing, caching, large language models (LLMs), embeddings, offline processing, metadata enhancement, FastText, MiniLM, sentence transformers, visualization, precision, recall</p><p>[00:00:00] 1. Introduction to Query Understanding</p><ul><li>Definition and importance in search systems</li><li>Evolution of query understanding techniques</li></ul><p>[00:05:30] 2. Query Representation Models</p><ul><li>The "bag of documents" model for queries</li><li>The "bag of queries" model for documents</li><li>Advantages of holistic query representation</li></ul><p>[00:12:00] 3. Query Specificity and Classification</p><ul><li>Measuring query specificity using cosine similarity</li><li>Importance of query classification in search relevance</li><li>Implementing and leveraging query classifiers</li></ul><p>[00:19:30] 4. Named Entity Recognition in Query Understanding</p><ul><li>Role of NER in query processing</li><li>Challenges with unique or tail entities</li></ul><p>[00:24:00] 5. Pre-Retrieval Query Processing</p><ul><li>Importance of early-stage query analysis</li><li>Balancing computational resources and impact</li></ul><p>[00:28:30] 6. Performance Optimization Techniques</p><ul><li>Caching strategies for query understanding</li><li>Offline processing for document enhancement</li></ul><p>[00:33:00] 7. Advanced Techniques: Embeddings and Language Models</p><ul><li>Using embeddings for query similarity</li><li>Role of Large Language Models (LLMs) in search</li><li>When to use simpler techniques vs. complex models</li></ul><p>[00:39:00] 8. Practical Implementation Strategies</p><ul><li>Starting points for engineers new to query understanding</li><li>Tools and libraries for query understanding (FastText, MiniLM, etc.)</li><li>Balancing precision and recall in search systems</li></ul><p>[00:44:00] 9. Visualization and Analysis of Query Spaces</p><ul><li>Discussion on t-SNE, UMAP, and other visualization techniques</li><li>Limitations and alternatives to embedding visualizations</li></ul><p>[00:47:00] 10. Future Directions and Closing Thoughts - Emerging trends in query understanding - Key takeaways for search system engineers</p><p>[00:53:00] End of Episode</p>]]>
      </itunes:summary>
      <itunes:keywords>query understanding, search, llms, embeddings, NER</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/01fedbd0/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>Season 2 Trailer: Mastering Search</title>
      <itunes:season>2</itunes:season>
      <podcast:season>2</podcast:season>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:title>Season 2 Trailer: Mastering Search</itunes:title>
      <itunes:episodeType>trailer</itunes:episodeType>
      <guid isPermaLink="false">f26d1839-13d0-4445-b4e9-7d3739f798c7</guid>
      <link>https://share.transistor.fm/s/67703f0f</link>
      <description>
        <![CDATA[<p>Today we are launching the season 2 of How AI Is Built.</p><p>The last few weeks, we spoke to a lot of regular listeners and past guests and collected feedback. Analyzed our episode data. And we will be applying the learnings to season 2.</p><p>This season will be all about search.</p><p>We are trying to make it better, more actionable, and more in-depth. The goal is that at the end of this season, you have a full-fleshed course on search in podcast form, which mini-courses on specific elements like RAG.</p><p>We will be talking to experts from information retrieval, information architecture, recommendation systems, and RAG; from academia and industry. Fields that do not really talk to each other.</p><p>We will try to unify and transfer the knowledge and give you a full tour of search, so you can build your next search application or feature with confidence.</p><p>We will be talking to Charlie Hull on how to systematically improve search systems, with Nils Reimers on the fundamental flaws of embeddings and how to fix them, with Daniel Tunkelang on how to actually understand the queries of the user, and many more.</p><p><br>We will try to bridge the gaps. How to use decades of research and practice in iteratively improving traditional search and apply it to RAG.¬†How to take new methods from recommendation systems and vector databases and bring it into traditional search systems. How to use all of the different methods as search signals and combine them to deliver the results your user actually wants.</p><p>We will be using two types of episodes:</p><ol><li>Traditional deep dives, like we have done them so far. Each one will dive into one specific topic within search interviewing an expert on that topic.</li><li>Supplementary episodes, which answer one additional question; often either complementary or precursory knowledge for the episode, which we did not get to in the deep dive.</li></ol><p>We will be starting with episodes next week, looking at the first, last, and overarching action in search: understanding user intent and understanding the queries with Daniel Tunkelang.</p><p>I am really excited to kick this off.</p><p>I would love to hear from you:</p><ul><li>What would you love to learn in this season?</li><li>What guest should I have on?</li><li>What topics should I make a deep dive on (try to be specific)?</li></ul><p>Yeah, let me know in the comments or just slide into my DMs on Twitter or LinkedIn.</p><p>I am looking forward to hearing from you guys.</p><p>I want to try to be more interactive. So anytime you encounter anything unclear or any question pops up in one of the episode, give me a shout and I will try to answer it to you and to everyone.</p><p>Enough of me rambling. Let‚Äôs kick this off. I will see you next Thursday, when we start with query understanding.</p><p><strong>Shoot me a message and stay up to date:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today we are launching the season 2 of How AI Is Built.</p><p>The last few weeks, we spoke to a lot of regular listeners and past guests and collected feedback. Analyzed our episode data. And we will be applying the learnings to season 2.</p><p>This season will be all about search.</p><p>We are trying to make it better, more actionable, and more in-depth. The goal is that at the end of this season, you have a full-fleshed course on search in podcast form, which mini-courses on specific elements like RAG.</p><p>We will be talking to experts from information retrieval, information architecture, recommendation systems, and RAG; from academia and industry. Fields that do not really talk to each other.</p><p>We will try to unify and transfer the knowledge and give you a full tour of search, so you can build your next search application or feature with confidence.</p><p>We will be talking to Charlie Hull on how to systematically improve search systems, with Nils Reimers on the fundamental flaws of embeddings and how to fix them, with Daniel Tunkelang on how to actually understand the queries of the user, and many more.</p><p><br>We will try to bridge the gaps. How to use decades of research and practice in iteratively improving traditional search and apply it to RAG.¬†How to take new methods from recommendation systems and vector databases and bring it into traditional search systems. How to use all of the different methods as search signals and combine them to deliver the results your user actually wants.</p><p>We will be using two types of episodes:</p><ol><li>Traditional deep dives, like we have done them so far. Each one will dive into one specific topic within search interviewing an expert on that topic.</li><li>Supplementary episodes, which answer one additional question; often either complementary or precursory knowledge for the episode, which we did not get to in the deep dive.</li></ol><p>We will be starting with episodes next week, looking at the first, last, and overarching action in search: understanding user intent and understanding the queries with Daniel Tunkelang.</p><p>I am really excited to kick this off.</p><p>I would love to hear from you:</p><ul><li>What would you love to learn in this season?</li><li>What guest should I have on?</li><li>What topics should I make a deep dive on (try to be specific)?</li></ul><p>Yeah, let me know in the comments or just slide into my DMs on Twitter or LinkedIn.</p><p>I am looking forward to hearing from you guys.</p><p>I want to try to be more interactive. So anytime you encounter anything unclear or any question pops up in one of the episode, give me a shout and I will try to answer it to you and to everyone.</p><p>Enough of me rambling. Let‚Äôs kick this off. I will see you next Thursday, when we start with query understanding.</p><p><strong>Shoot me a message and stay up to date:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </content:encoded>
      <pubDate>Thu, 08 Aug 2024 04:56:49 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/67703f0f/4f603413.mp3" length="4131858" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/V6GZpuCXXQ5l1RvMST9T_AV3VlYZOiPEgtBukcjtjEQ/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS80Nzlm/NTE4YjVjMWIyM2M5/NGE3MmMxNmUwMzUy/YTZkNy5wbmc.jpg"/>
      <itunes:duration>256</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>Today we are launching the season 2 of How AI Is Built.</p><p>The last few weeks, we spoke to a lot of regular listeners and past guests and collected feedback. Analyzed our episode data. And we will be applying the learnings to season 2.</p><p>This season will be all about search.</p><p>We are trying to make it better, more actionable, and more in-depth. The goal is that at the end of this season, you have a full-fleshed course on search in podcast form, which mini-courses on specific elements like RAG.</p><p>We will be talking to experts from information retrieval, information architecture, recommendation systems, and RAG; from academia and industry. Fields that do not really talk to each other.</p><p>We will try to unify and transfer the knowledge and give you a full tour of search, so you can build your next search application or feature with confidence.</p><p>We will be talking to Charlie Hull on how to systematically improve search systems, with Nils Reimers on the fundamental flaws of embeddings and how to fix them, with Daniel Tunkelang on how to actually understand the queries of the user, and many more.</p><p><br>We will try to bridge the gaps. How to use decades of research and practice in iteratively improving traditional search and apply it to RAG.¬†How to take new methods from recommendation systems and vector databases and bring it into traditional search systems. How to use all of the different methods as search signals and combine them to deliver the results your user actually wants.</p><p>We will be using two types of episodes:</p><ol><li>Traditional deep dives, like we have done them so far. Each one will dive into one specific topic within search interviewing an expert on that topic.</li><li>Supplementary episodes, which answer one additional question; often either complementary or precursory knowledge for the episode, which we did not get to in the deep dive.</li></ol><p>We will be starting with episodes next week, looking at the first, last, and overarching action in search: understanding user intent and understanding the queries with Daniel Tunkelang.</p><p>I am really excited to kick this off.</p><p>I would love to hear from you:</p><ul><li>What would you love to learn in this season?</li><li>What guest should I have on?</li><li>What topics should I make a deep dive on (try to be specific)?</li></ul><p>Yeah, let me know in the comments or just slide into my DMs on Twitter or LinkedIn.</p><p>I am looking forward to hearing from you guys.</p><p>I want to try to be more interactive. So anytime you encounter anything unclear or any question pops up in one of the episode, give me a shout and I will try to answer it to you and to everyone.</p><p>Enough of me rambling. Let‚Äôs kick this off. I will see you next Thursday, when we start with query understanding.</p><p><strong>Shoot me a message and stay up to date:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </itunes:summary>
      <itunes:keywords>ai, search, recommendation system, information retrieval, rag, artificial intelligence, machine learning</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/67703f0f/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#017 Unlocking Value from Unstructured Data, Real-World Applications of Generative AI</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>17</itunes:episode>
      <podcast:episode>17</podcast:episode>
      <itunes:title>#017 Unlocking Value from Unstructured Data, Real-World Applications of Generative AI</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">31b35d5d-b997-41b7-9ddf-947e50da9085</guid>
      <link>https://share.transistor.fm/s/9f117b9d</link>
      <description>
        <![CDATA[<p>In this episode of "How AI is Built," host Nicolay Gerold interviews Jonathan Yarkoni, founder of Reach Latent. Jonathan shares his expertise in extracting value from unstructured data using AI, discussing challenging projects, the impact of ChatGPT, and the future of generative AI. From weather prediction to legal tech, Jonathan provides valuable insights into the practical applications of AI across various industries.</p><p><strong>Key Takeaways</strong></p><ul><li>Generative AI projects often require less data cleaning due to the models' tolerance for "dirty" data, allowing for faster implementation in some cases.</li><li>The success of AI projects post-delivery is ensured through monitoring, but automatic retraining of generative AI applications is not yet common due to evaluation challenges.</li><li>Industries ripe for AI disruption include text-heavy fields like legal, education, software engineering, and marketing, as well as biotech and entertainment.</li><li>The adoption of AI is expected to occur in waves, with 2024 likely focusing on internal use cases and 2025 potentially seeing more customer-facing applications as models improve.</li><li>Synthetic data generation, using models like GPT-4, can be a valuable approach for training AI systems when real data is scarce or sensitive.</li><li>Evaluation frameworks like RAGAS and custom metrics are essential for assessing the quality of synthetic data and AI model outputs.</li><li>Jonathan‚Äôs ideal tech stack for generative AI projects includes tools like Instructor, Guardrails, Semantic Routing, DSPY, LangChain, and LlamaIndex, with a growing emphasis on evaluation stacks.</li></ul><p><strong>Key Quotes</strong></p><p>"I think we're going to see another wave in 2024 and another one in 2025. And people are familiarized. That's kind of the wave of 2023. 2024 is probably still going to be a lot of internal use cases because it's a low risk environment and there was a lot of opportunity to be had."</p><p>"To really get to production reliably, we have to have these tools evolve further and get more standardized so people can still use the old ways of doing production with the new technology."</p><p><strong>Jonathan Yarkoni</strong></p><ul><li><a href="https://il.linkedin.com/in/jonathanyarkoni">LinkedIn</a></li><li><a href="https://www.youtube.com/channel/UCtV3rZxUOnkVBGV08E9KGOw">YouTube</a></li><li><a href="https://x.com/jon_yarkoni">X (Twitter)</a></li><li><a href="https://www.reachlatent.com/">Reach Latent</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction: Extracting Value from Unstructured Data¬†<br>03:16 Flexible Tailoring Solutions to Client Needs¬†<br>05:39 Monitoring and Retraining Models in the Evolving AI Landscape¬†<br>09:15 Generative AI: Disrupting Industries and Unlocking New Possibilities¬†<br>17:47 Balancing Immediate Results and Cutting-Edge Solutions in AI Development¬†<br>28:29 Dream Tech Stack for Generative AI</p><p>unstructured data, textual data, automation, weather prediction, data cleaning, chat GPT, AI disruption, legal, education, software engineering, marketing, biotech, immediate results, cutting-edge solutions, tech stack</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode of "How AI is Built," host Nicolay Gerold interviews Jonathan Yarkoni, founder of Reach Latent. Jonathan shares his expertise in extracting value from unstructured data using AI, discussing challenging projects, the impact of ChatGPT, and the future of generative AI. From weather prediction to legal tech, Jonathan provides valuable insights into the practical applications of AI across various industries.</p><p><strong>Key Takeaways</strong></p><ul><li>Generative AI projects often require less data cleaning due to the models' tolerance for "dirty" data, allowing for faster implementation in some cases.</li><li>The success of AI projects post-delivery is ensured through monitoring, but automatic retraining of generative AI applications is not yet common due to evaluation challenges.</li><li>Industries ripe for AI disruption include text-heavy fields like legal, education, software engineering, and marketing, as well as biotech and entertainment.</li><li>The adoption of AI is expected to occur in waves, with 2024 likely focusing on internal use cases and 2025 potentially seeing more customer-facing applications as models improve.</li><li>Synthetic data generation, using models like GPT-4, can be a valuable approach for training AI systems when real data is scarce or sensitive.</li><li>Evaluation frameworks like RAGAS and custom metrics are essential for assessing the quality of synthetic data and AI model outputs.</li><li>Jonathan‚Äôs ideal tech stack for generative AI projects includes tools like Instructor, Guardrails, Semantic Routing, DSPY, LangChain, and LlamaIndex, with a growing emphasis on evaluation stacks.</li></ul><p><strong>Key Quotes</strong></p><p>"I think we're going to see another wave in 2024 and another one in 2025. And people are familiarized. That's kind of the wave of 2023. 2024 is probably still going to be a lot of internal use cases because it's a low risk environment and there was a lot of opportunity to be had."</p><p>"To really get to production reliably, we have to have these tools evolve further and get more standardized so people can still use the old ways of doing production with the new technology."</p><p><strong>Jonathan Yarkoni</strong></p><ul><li><a href="https://il.linkedin.com/in/jonathanyarkoni">LinkedIn</a></li><li><a href="https://www.youtube.com/channel/UCtV3rZxUOnkVBGV08E9KGOw">YouTube</a></li><li><a href="https://x.com/jon_yarkoni">X (Twitter)</a></li><li><a href="https://www.reachlatent.com/">Reach Latent</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction: Extracting Value from Unstructured Data¬†<br>03:16 Flexible Tailoring Solutions to Client Needs¬†<br>05:39 Monitoring and Retraining Models in the Evolving AI Landscape¬†<br>09:15 Generative AI: Disrupting Industries and Unlocking New Possibilities¬†<br>17:47 Balancing Immediate Results and Cutting-Edge Solutions in AI Development¬†<br>28:29 Dream Tech Stack for Generative AI</p><p>unstructured data, textual data, automation, weather prediction, data cleaning, chat GPT, AI disruption, legal, education, software engineering, marketing, biotech, immediate results, cutting-edge solutions, tech stack</p>]]>
      </content:encoded>
      <pubDate>Tue, 16 Jul 2024 05:12:31 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/9f117b9d/d4133064.mp3" length="35054890" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/VdIfgl15KFgzAYcYxMGzCNfsxt0a5N_4vYfAWQvjiH4/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS85N2Q4/MWVjNTQ2OTdmMmIy/M2M0ODkzZGI5MmU3/MzVhYi5wbmc.jpg"/>
      <itunes:duration>2188</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>In this episode of "How AI is Built," host Nicolay Gerold interviews Jonathan Yarkoni, founder of Reach Latent. Jonathan shares his expertise in extracting value from unstructured data using AI, discussing challenging projects, the impact of ChatGPT, and the future of generative AI. From weather prediction to legal tech, Jonathan provides valuable insights into the practical applications of AI across various industries.</p><p><strong>Key Takeaways</strong></p><ul><li>Generative AI projects often require less data cleaning due to the models' tolerance for "dirty" data, allowing for faster implementation in some cases.</li><li>The success of AI projects post-delivery is ensured through monitoring, but automatic retraining of generative AI applications is not yet common due to evaluation challenges.</li><li>Industries ripe for AI disruption include text-heavy fields like legal, education, software engineering, and marketing, as well as biotech and entertainment.</li><li>The adoption of AI is expected to occur in waves, with 2024 likely focusing on internal use cases and 2025 potentially seeing more customer-facing applications as models improve.</li><li>Synthetic data generation, using models like GPT-4, can be a valuable approach for training AI systems when real data is scarce or sensitive.</li><li>Evaluation frameworks like RAGAS and custom metrics are essential for assessing the quality of synthetic data and AI model outputs.</li><li>Jonathan‚Äôs ideal tech stack for generative AI projects includes tools like Instructor, Guardrails, Semantic Routing, DSPY, LangChain, and LlamaIndex, with a growing emphasis on evaluation stacks.</li></ul><p><strong>Key Quotes</strong></p><p>"I think we're going to see another wave in 2024 and another one in 2025. And people are familiarized. That's kind of the wave of 2023. 2024 is probably still going to be a lot of internal use cases because it's a low risk environment and there was a lot of opportunity to be had."</p><p>"To really get to production reliably, we have to have these tools evolve further and get more standardized so people can still use the old ways of doing production with the new technology."</p><p><strong>Jonathan Yarkoni</strong></p><ul><li><a href="https://il.linkedin.com/in/jonathanyarkoni">LinkedIn</a></li><li><a href="https://www.youtube.com/channel/UCtV3rZxUOnkVBGV08E9KGOw">YouTube</a></li><li><a href="https://x.com/jon_yarkoni">X (Twitter)</a></li><li><a href="https://www.reachlatent.com/">Reach Latent</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Introduction: Extracting Value from Unstructured Data¬†<br>03:16 Flexible Tailoring Solutions to Client Needs¬†<br>05:39 Monitoring and Retraining Models in the Evolving AI Landscape¬†<br>09:15 Generative AI: Disrupting Industries and Unlocking New Possibilities¬†<br>17:47 Balancing Immediate Results and Cutting-Edge Solutions in AI Development¬†<br>28:29 Dream Tech Stack for Generative AI</p><p>unstructured data, textual data, automation, weather prediction, data cleaning, chat GPT, AI disruption, legal, education, software engineering, marketing, biotech, immediate results, cutting-edge solutions, tech stack</p>]]>
      </itunes:summary>
      <itunes:keywords>llm, generative ai, chatgpt</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/9f117b9d/transcript.txt" type="text/plain"/>
      <podcast:chapters url="https://share.transistor.fm/s/9f117b9d/chapters.json" type="application/json+chapters"/>
    </item>
    <item>
      <title>#016 Data Processing for AI, Integrating AI into Data Pipelines, Spark</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>16</itunes:episode>
      <podcast:episode>16</podcast:episode>
      <itunes:title>#016 Data Processing for AI, Integrating AI into Data Pipelines, Spark</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">e27000f0-b7a7-48d1-abe0-ea1112929632</guid>
      <link>https://share.transistor.fm/s/fda85f44</link>
      <description>
        <![CDATA[<p>This episode of "How AI Is Built" is all about data processing for AI. Abhishek Choudhary and Nicolay discuss Spark and alternatives to process data so it is AI-ready.</p><p>Spark is a distributed system that allows for fast data processing by utilizing memory. It uses a dataframe representation "RDD" to simplify data processing.</p><p>When should you use Spark to process your data for your AI Systems?</p><p>‚Üí Use Spark when:</p><ul><li>Your data exceeds terabytes in volume</li><li>You expect unpredictable data growth</li><li>Your pipeline involves multiple complex operations</li><li>You already have a Spark cluster (e.g., Databricks)</li><li>Your team has strong Spark expertise</li><li>You need distributed computing for performance</li><li>Budget allows for Spark infrastructure costs</li></ul><p>‚Üí Consider alternatives when:</p><ul><li>Dealing with datasets under 1TB</li><li>In early stages of AI development</li><li>Budget constraints limit infrastructure spending</li><li>Simpler tools like Pandas or DuckDB suffice</li></ul><p>Spark isn't always necessary. Evaluate your specific needs and resources before committing to a Spark-based solution for AI data processing.</p><p>In today‚Äôs episode of How AI Is Built, Abhishek and I discuss data processing:</p><ul><li>When to use Spark vs. alternatives for data processing</li><li>Key components of Spark: RDDs, DataFrames, and SQL</li><li>Integrating AI into data pipelines</li><li>Challenges with LLM latency and consistency</li><li>Data storage strategies for AI workloads</li><li>Orchestration tools for data pipelines</li><li>Tips for making LLMs more reliable in production</li></ul><p><strong>Abhishek Choudhary:</strong></p><ul><li><a href="https://www.linkedin.com/in/iamabhishekchoudhary/">LinkedIn</a></li><li><a href="https://github.com/abhishek-ch">GitHub</a></li><li><a href="https://x.com/ubunta">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>This episode of "How AI Is Built" is all about data processing for AI. Abhishek Choudhary and Nicolay discuss Spark and alternatives to process data so it is AI-ready.</p><p>Spark is a distributed system that allows for fast data processing by utilizing memory. It uses a dataframe representation "RDD" to simplify data processing.</p><p>When should you use Spark to process your data for your AI Systems?</p><p>‚Üí Use Spark when:</p><ul><li>Your data exceeds terabytes in volume</li><li>You expect unpredictable data growth</li><li>Your pipeline involves multiple complex operations</li><li>You already have a Spark cluster (e.g., Databricks)</li><li>Your team has strong Spark expertise</li><li>You need distributed computing for performance</li><li>Budget allows for Spark infrastructure costs</li></ul><p>‚Üí Consider alternatives when:</p><ul><li>Dealing with datasets under 1TB</li><li>In early stages of AI development</li><li>Budget constraints limit infrastructure spending</li><li>Simpler tools like Pandas or DuckDB suffice</li></ul><p>Spark isn't always necessary. Evaluate your specific needs and resources before committing to a Spark-based solution for AI data processing.</p><p>In today‚Äôs episode of How AI Is Built, Abhishek and I discuss data processing:</p><ul><li>When to use Spark vs. alternatives for data processing</li><li>Key components of Spark: RDDs, DataFrames, and SQL</li><li>Integrating AI into data pipelines</li><li>Challenges with LLM latency and consistency</li><li>Data storage strategies for AI workloads</li><li>Orchestration tools for data pipelines</li><li>Tips for making LLMs more reliable in production</li></ul><p><strong>Abhishek Choudhary:</strong></p><ul><li><a href="https://www.linkedin.com/in/iamabhishekchoudhary/">LinkedIn</a></li><li><a href="https://github.com/abhishek-ch">GitHub</a></li><li><a href="https://x.com/ubunta">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </content:encoded>
      <pubDate>Fri, 12 Jul 2024 08:57:02 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/fda85f44/6e1d070b.mp3" length="44628345" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/-lEC4NS9xyZpZS6bnwH59mWEb78nVefIrt0aTRg5qdQ/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mMmIy/ZWNhNWIyYmIzODgy/NmQzZDc2MGEyNGFl/M2U2YS5wbmc.jpg"/>
      <itunes:duration>2786</itunes:duration>
      <itunes:summary>
        <![CDATA[<p>This episode of "How AI Is Built" is all about data processing for AI. Abhishek Choudhary and Nicolay discuss Spark and alternatives to process data so it is AI-ready.</p><p>Spark is a distributed system that allows for fast data processing by utilizing memory. It uses a dataframe representation "RDD" to simplify data processing.</p><p>When should you use Spark to process your data for your AI Systems?</p><p>‚Üí Use Spark when:</p><ul><li>Your data exceeds terabytes in volume</li><li>You expect unpredictable data growth</li><li>Your pipeline involves multiple complex operations</li><li>You already have a Spark cluster (e.g., Databricks)</li><li>Your team has strong Spark expertise</li><li>You need distributed computing for performance</li><li>Budget allows for Spark infrastructure costs</li></ul><p>‚Üí Consider alternatives when:</p><ul><li>Dealing with datasets under 1TB</li><li>In early stages of AI development</li><li>Budget constraints limit infrastructure spending</li><li>Simpler tools like Pandas or DuckDB suffice</li></ul><p>Spark isn't always necessary. Evaluate your specific needs and resources before committing to a Spark-based solution for AI data processing.</p><p>In today‚Äôs episode of How AI Is Built, Abhishek and I discuss data processing:</p><ul><li>When to use Spark vs. alternatives for data processing</li><li>Key components of Spark: RDDs, DataFrames, and SQL</li><li>Integrating AI into data pipelines</li><li>Challenges with LLM latency and consistency</li><li>Data storage strategies for AI workloads</li><li>Orchestration tools for data pipelines</li><li>Tips for making LLMs more reliable in production</li></ul><p><strong>Abhishek Choudhary:</strong></p><ul><li><a href="https://www.linkedin.com/in/iamabhishekchoudhary/">LinkedIn</a></li><li><a href="https://github.com/abhishek-ch">GitHub</a></li><li><a href="https://x.com/ubunta">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul>]]>
      </itunes:summary>
      <itunes:keywords>data processing, ai, spark, data engineering, llm</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
      <podcast:transcript url="https://share.transistor.fm/s/fda85f44/transcript.txt" type="text/plain"/>
    </item>
    <item>
      <title>#015 Building AI Agents for the Enterprise, Agent Cost Controls, Seamless UX</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>15</itunes:episode>
      <podcast:episode>15</podcast:episode>
      <itunes:title>#015 Building AI Agents for the Enterprise, Agent Cost Controls, Seamless UX</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">83a40101-5db5-4d48-a7e3-8cc588610fa5</guid>
      <link>https://share.transistor.fm/s/6c6e2159</link>
      <description>
        <![CDATA[<p>In this episode, Nicolay talks with Rahul Parundekar, founder of AI Hero, about the current state and future of AI agents. Drawing from over a decade of experience working on agent technology at companies like Toyota, Rahul emphasizes the importance of focusing on realistic, bounded use cases rather than chasing full autonomy.</p><p>They dive into the key challenges, like effectively capturing expert workflows and decision processes, delivering seamless user experiences that integrate into existing routines, and managing costs through techniques like guardrails and optimized model choices. The conversation also explores potential new paradigms for agent interactions beyond just chat.</p><p><strong>Key Takeaways:</strong></p><ul><li>Agents need to focus on realistic use cases rather than trying to be fully autonomous. Enterprises are unlikely to allow agents full autonomy anytime soon.</li><li>Capturing the logic and workflows in the user's head is the key challenge. Shadowing experts and having them demonstrate workflows is more effective than asking them to document processes.</li><li>User experience is crucial - agents must integrate seamlessly into existing user workflows without major disruptions. Interfaces beyond just chat may be needed.</li><li>Cost control is important - techniques like guardrails, context windowing, model choice optimization, and dev vs production modes can help manage costs.</li><li>New paradigms beyond just chat could be powerful - e.g. workflow specification, state/declarative definition of desired end-state.</li><li>Prompt engineering and dynamic prompt improvement based on feedback remain an open challenge.</li></ul><p><strong>Key Quotes:</strong></p><ul><li>"Empowering users to create their own workflows is essential for effective agent usage."</li><li>"Capturing workflows accurately is a significant challenge in agent development."</li><li>"Preferences, right? So a lot of the work becomes like, hey, can you do preference learning for this user so that the next time the user doesn't have to enter the same information again, things like that."</li></ul><p><strong>Rahul Parundekar:</strong></p><ul><li><a href="https://aihero.studio/">AI Hero</a></li><li><a href="https://www.notion.so/bdc873ee9bd443eb8f388aa7f79b14cf?pvs=21">AI Hero Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Exploring the Potential of Autonomous Agents</p><p><strong>02:23</strong> Challenges of Accuracy and Repeatability in Agents</p><p><strong>08:31</strong> Capturing User Workflows and Improving Prompts</p><p><strong>13:37</strong> Tech Stack for Implementing Agents in the Enterprise</p><p>agent development, determinism, user experience, agent paradigms, private use, human-agent interaction, user workflows, agent deployment, human-in-the-loop, LLMs, declarative ways, scalability, AI Hero</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode, Nicolay talks with Rahul Parundekar, founder of AI Hero, about the current state and future of AI agents. Drawing from over a decade of experience working on agent technology at companies like Toyota, Rahul emphasizes the importance of focusing on realistic, bounded use cases rather than chasing full autonomy.</p><p>They dive into the key challenges, like effectively capturing expert workflows and decision processes, delivering seamless user experiences that integrate into existing routines, and managing costs through techniques like guardrails and optimized model choices. The conversation also explores potential new paradigms for agent interactions beyond just chat.</p><p><strong>Key Takeaways:</strong></p><ul><li>Agents need to focus on realistic use cases rather than trying to be fully autonomous. Enterprises are unlikely to allow agents full autonomy anytime soon.</li><li>Capturing the logic and workflows in the user's head is the key challenge. Shadowing experts and having them demonstrate workflows is more effective than asking them to document processes.</li><li>User experience is crucial - agents must integrate seamlessly into existing user workflows without major disruptions. Interfaces beyond just chat may be needed.</li><li>Cost control is important - techniques like guardrails, context windowing, model choice optimization, and dev vs production modes can help manage costs.</li><li>New paradigms beyond just chat could be powerful - e.g. workflow specification, state/declarative definition of desired end-state.</li><li>Prompt engineering and dynamic prompt improvement based on feedback remain an open challenge.</li></ul><p><strong>Key Quotes:</strong></p><ul><li>"Empowering users to create their own workflows is essential for effective agent usage."</li><li>"Capturing workflows accurately is a significant challenge in agent development."</li><li>"Preferences, right? So a lot of the work becomes like, hey, can you do preference learning for this user so that the next time the user doesn't have to enter the same information again, things like that."</li></ul><p><strong>Rahul Parundekar:</strong></p><ul><li><a href="https://aihero.studio/">AI Hero</a></li><li><a href="https://www.notion.so/bdc873ee9bd443eb8f388aa7f79b14cf?pvs=21">AI Hero Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Exploring the Potential of Autonomous Agents</p><p><strong>02:23</strong> Challenges of Accuracy and Repeatability in Agents</p><p><strong>08:31</strong> Capturing User Workflows and Improving Prompts</p><p><strong>13:37</strong> Tech Stack for Implementing Agents in the Enterprise</p><p>agent development, determinism, user experience, agent paradigms, private use, human-agent interaction, user workflows, agent deployment, human-in-the-loop, LLMs, declarative ways, scalability, AI Hero</p>]]>
      </content:encoded>
      <pubDate>Thu, 04 Jul 2024 05:11:50 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/6c6e2159/6e765e0a.mp3" length="33780304" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/_Vs3V6ELtH0vf21wJsO7f9CdJJB59uzbB_etjetgUa8/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS80YmFj/NmRhZjc2YTdmY2Fl/NzU4NDliYjNkZjU0/ZGI5MC5qcGc.jpg"/>
      <itunes:duration>2112</itunes:duration>
      <itunes:summary>In this episode, Nicolay talks with Rahul Parundekar, founder of AI Hero, about the current state and future of AI agents. Drawing from over a decade of experience working on agent technology at companies like Toyota, Rahul emphasizes the importance of focusing on realistic, bounded use cases rather than chasing full autonomy.
They dive into the key challenges, like effectively capturing expert workflows and decision processes, delivering seamless user experiences that integrate into existing routines, and managing costs through techniques like guardrails and optimized model choices. The conversation also explores potential new paradigms for agent interactions beyond just chat.
Key Takeaways:

 Agents need to focus on realistic use cases rather than trying to be fully autonomous. Enterprises are unlikely to allow agents full autonomy anytime soon.
 Capturing the logic and workflows in the user's head is the key challenge. Shadowing experts and having them demonstrate workflows is more effective than asking them to document processes.
  User experience is crucial - agents must integrate seamlessly into existing user workflows without major disruptions. Interfaces beyond just chat may be needed.
  Cost control is important - techniques like guardrails, context windowing, model choice optimization, and dev vs production modes can help manage costs.
  New paradigms beyond just chat could be powerful - e.g. workflow specification, state/declarative definition of desired end-state.
  Prompt engineering and dynamic prompt improvement based on feedback remain an open challenge.

Key Quotes:

  "Empowering users to create their own workflows is essential for effective agent usage."
  "Capturing workflows accurately is a significant challenge in agent development."
  "Preferences, right? So a lot of the work becomes like, hey, can you do preference learning for this user so that the next time the user doesn't have to enter the same information again, things like that."

Rahul Parundekar:

  AI Hero
  AI Hero Docs

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

00:00 Exploring the Potential of Autonomous Agents
02:23 Challenges of Accuracy and Repeatability in Agents
08:31 Capturing User Workflows and Improving Prompts
13:37 Tech Stack for Implementing Agents in the Enterprise
agent development, determinism, user experience, agent paradigms, private use, human-agent interaction, user workflows, agent deployment, human-in-the-loop, LLMs, declarative ways, scalability, AI Hero</itunes:summary>
      <itunes:subtitle>In this episode, Nicolay talks with Rahul Parundekar, founder of AI Hero, about the current state and future of AI agents. Drawing from over a decade of experience working on agent technology at companies like Toyota, Rahul emphasizes the importance of fo</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#014 Building Predictable Agents through Prompting, Compression, and Memory Strategies </title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>14</itunes:episode>
      <podcast:episode>14</podcast:episode>
      <itunes:title>#014 Building Predictable Agents through Prompting, Compression, and Memory Strategies </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">29600760-92c3-44bc-9d9b-2106f9a45090</guid>
      <link>https://share.transistor.fm/s/0c2267f7</link>
      <description>
        <![CDATA[<p>In this conversation, Nicolay and Richmond Alake discuss various topics related to building AI agents and using MongoDB in the AI space. They cover the use of agents and multi-agents, the challenges of controlling agent behavior, and the importance of prompt compression.</p><p>When you are building agents. Build them iteratively. Start with simple LLM calls before moving to multi-agent systems.</p><p><strong>Main Takeaways:</strong></p><ol><li><strong>Prompt Compression</strong>: Using techniques like prompt compression can significantly reduce the cost of running LLM-based applications by reducing the number of tokens sent to the model. This becomes crucial when scaling to production.</li><li><strong>Memory Management</strong>: Effective memory management is key for building reliable agents. Consider different memory components like long-term memory (knowledge base), short-term memory (conversation history), semantic cache, and operational data (system logs). Store each in separate collections for easy access and reference.</li><li><strong>Performance Optimization</strong>: Optimize performance across multiple dimensions - output quality (by tuning context and knowledge base), latency (using semantic caching), and scalability (using auto-scaling databases like MongoDB).</li><li><strong>Prompting Techniques</strong>: Leverage prompting techniques like ReAct (observe, plan, act) and structured prompts (JSON, pseudo-code) to improve agent predictability and output quality.</li><li><strong>Experimentation</strong>: Continuous experimentation is crucial in this rapidly evolving field. Try different frameworks (LangChain, Crew AI, Haystack), models (Claude, Anthropic, open-source), and techniques to find the best fit for your use case.</li></ol><p><strong>Richmond Alake:</strong></p><ul><li><a href="https://www.linkedin.com/in/richmondalake/">LinkedIn</a></li><li><a href="https://medium.com/@richmondalake">Medium</a></li><li><a href="https://www.mongodb.com/developer/author/richmond-alake/">Find Richmond on MongoDB</a></li><li><a href="https://x.com/richmondalake?lang=en">X (Twitter)</a></li><li><a href="https://www.youtube.com/@richmond_a">YouTube</a></li><li><a href="https://github.com/mongodb-developer/GenAI-Showcase">GenAI Showcase MongoDB</a></li><li><a href="https://www.mongodb.com/resources/basics/ai-stack">MongoDB AI Stack</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Reducing the Scope of AI Agents</p><p><strong>01:55</strong> Seamless Data Ingestion¬†</p><p><strong>03:20</strong> Challenges and Considerations in Implementing Multi-Agents</p><p><strong>06:05</strong> Memory Modeling for Robust Agents with MongoDB</p><p><strong>15:05</strong> Performance Optimization in AI Agents</p><p><strong>18:19</strong> RAG Setup</p><p>AI agents, multi-agents, prompt compression, MongoDB, data storage, data ingestion, performance optimization, tooling, generative AI</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this conversation, Nicolay and Richmond Alake discuss various topics related to building AI agents and using MongoDB in the AI space. They cover the use of agents and multi-agents, the challenges of controlling agent behavior, and the importance of prompt compression.</p><p>When you are building agents. Build them iteratively. Start with simple LLM calls before moving to multi-agent systems.</p><p><strong>Main Takeaways:</strong></p><ol><li><strong>Prompt Compression</strong>: Using techniques like prompt compression can significantly reduce the cost of running LLM-based applications by reducing the number of tokens sent to the model. This becomes crucial when scaling to production.</li><li><strong>Memory Management</strong>: Effective memory management is key for building reliable agents. Consider different memory components like long-term memory (knowledge base), short-term memory (conversation history), semantic cache, and operational data (system logs). Store each in separate collections for easy access and reference.</li><li><strong>Performance Optimization</strong>: Optimize performance across multiple dimensions - output quality (by tuning context and knowledge base), latency (using semantic caching), and scalability (using auto-scaling databases like MongoDB).</li><li><strong>Prompting Techniques</strong>: Leverage prompting techniques like ReAct (observe, plan, act) and structured prompts (JSON, pseudo-code) to improve agent predictability and output quality.</li><li><strong>Experimentation</strong>: Continuous experimentation is crucial in this rapidly evolving field. Try different frameworks (LangChain, Crew AI, Haystack), models (Claude, Anthropic, open-source), and techniques to find the best fit for your use case.</li></ol><p><strong>Richmond Alake:</strong></p><ul><li><a href="https://www.linkedin.com/in/richmondalake/">LinkedIn</a></li><li><a href="https://medium.com/@richmondalake">Medium</a></li><li><a href="https://www.mongodb.com/developer/author/richmond-alake/">Find Richmond on MongoDB</a></li><li><a href="https://x.com/richmondalake?lang=en">X (Twitter)</a></li><li><a href="https://www.youtube.com/@richmond_a">YouTube</a></li><li><a href="https://github.com/mongodb-developer/GenAI-Showcase">GenAI Showcase MongoDB</a></li><li><a href="https://www.mongodb.com/resources/basics/ai-stack">MongoDB AI Stack</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Reducing the Scope of AI Agents</p><p><strong>01:55</strong> Seamless Data Ingestion¬†</p><p><strong>03:20</strong> Challenges and Considerations in Implementing Multi-Agents</p><p><strong>06:05</strong> Memory Modeling for Robust Agents with MongoDB</p><p><strong>15:05</strong> Performance Optimization in AI Agents</p><p><strong>18:19</strong> RAG Setup</p><p>AI agents, multi-agents, prompt compression, MongoDB, data storage, data ingestion, performance optimization, tooling, generative AI</p>]]>
      </content:encoded>
      <pubDate>Thu, 27 Jun 2024 08:00:18 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/0c2267f7/dbb7ad13.mp3" length="30940677" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/4IF9dlh6BQ0_ThtbJnWXS0iGdOe3q9KnvMlKolUkNC0/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS81MWFi/YTJmOTBmZDZhZTdl/OWI4Mjg1MmRlNGMz/ZjcwNi5qcGc.jpg"/>
      <itunes:duration>1934</itunes:duration>
      <itunes:summary>In this conversation, Nicolay and Richmond Alake discuss various topics related to building AI agents and using MongoDB in the AI space. They cover the use of agents and multi-agents, the challenges of controlling agent behavior, and the importance of prompt compression.
When you are building agents. Build them iteratively. Start with simple LLM calls before moving to multi-agent systems.
Main Takeaways:

 Prompt Compression: Using techniques like prompt compression can significantly reduce the cost of running LLM-based applications by reducing the number of tokens sent to the model. This becomes crucial when scaling to production.
 Memory Management: Effective memory management is key for building reliable agents. Consider different memory components like long-term memory (knowledge base), short-term memory (conversation history), semantic cache, and operational data (system logs). Store each in separate collections for easy access and reference.
 Performance Optimization: Optimize performance across multiple dimensions - output quality (by tuning context and knowledge base), latency (using semantic caching), and scalability (using auto-scaling databases like MongoDB).
 Prompting Techniques: Leverage prompting techniques like ReAct (observe, plan, act) and structured prompts (JSON, pseudo-code) to improve agent predictability and output quality.
  Experimentation: Continuous experimentation is crucial in this rapidly evolving field. Try different frameworks (LangChain, Crew AI, Haystack), models (Claude, Anthropic, open-source), and techniques to find the best fit for your use case.

Richmond Alake:

  LinkedIn
  Medium
  Find Richmond on MongoDB
  X (Twitter)
  YouTube
  GenAI Showcase MongoDB
  MongoDB AI Stack

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

00:00 Reducing the Scope of AI Agents
01:55 Seamless Data Ingestion 
03:20 Challenges and Considerations in Implementing Multi-Agents
06:05 Memory Modeling for Robust Agents with MongoDB
15:05 Performance Optimization in AI Agents
18:19 RAG Setup
AI agents, multi-agents, prompt compression, MongoDB, data storage, data ingestion, performance optimization, tooling, generative AI</itunes:summary>
      <itunes:subtitle>In this conversation, Nicolay and Richmond Alake discuss various topics related to building AI agents and using MongoDB in the AI space. They cover the use of agents and multi-agents, the challenges of controlling agent behavior, and the importance of pro</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>Data Integration and Ingestion for AI &amp; LLMs, Architecting Data Flows | changelog 3</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>14</itunes:episode>
      <podcast:episode>14</podcast:episode>
      <itunes:title>Data Integration and Ingestion for AI &amp; LLMs, Architecting Data Flows | changelog 3</itunes:title>
      <itunes:episodeType>bonus</itunes:episodeType>
      <guid isPermaLink="false">5ba7af9d-3727-4bb8-96ec-ef527fe5a778</guid>
      <link>https://share.transistor.fm/s/8673984a</link>
      <description>
        <![CDATA[<p>In this episode, Kirk Marple, CEO and founder of Graphlit, shares his expertise on building efficient data integrations.</p>
<p>Kirk breaks down his approach using relatable concepts:</p>
<ol>
 <li>The "Two-Sided Funnel": This model streamlines data flow by converting various data sources into a standard format before distributing it.</li>
 <li>Universal Data Streams: Kirk explains how he transforms diverse data into a single, manageable stream of information.</li>
  <li>Parallel Processing: Learn about the "competing consumer model" that allows for faster data handling.</li>
  <li>Building Blocks for Success: Discover the importance of well-defined interfaces and actor models in creating robust data systems.</li>
  <li>Tech Talk: Kirk discusses data normalization techniques and the potential shift towards a more streamlined "Kappa architecture."</li>
  <li>Reusable Patterns: Find out how Kirk's methods can speed up the integration of new data sources.</li>
</ol>
<p><strong>Kirk Marple:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/kirkmarple/">LinkedIn</a></li>
  <li><a href="https://twitter.com/KirkMarple">X (Twitter)</a></li>
  <li><a href="https://www.graphlit.com/">Graphlit</a></li>
  <li><a href="https://docs.graphlit.dev/">Graphlit Docs</a></li>
</ul>
<p><strong>Nicolay Gerold:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li>
  <li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li>
</ul>
<p><strong>Chapters</strong></p>
<p><strong>00:00</strong> Building Integrations into Different Tools</p>
<p><strong>00:44</strong> The Two-Sided Funnel Model for Data Flow</p>
<p><strong>04:07</strong> Using Well-Defined Interfaces for Faster Integration</p>
<p><strong>04:36</strong> Managing Feeds and State with Actor Models</p>
<p><strong>06:05</strong> The Importance of Data Normalization</p>
<p><strong>10:54</strong> Tech Stack for Data Flow</p>
<p><strong>11:52</strong> Progression towards a Kappa Architecture</p>
<p><strong>13:45</strong> Reusability of Patterns for Faster Integration</p>
<p>data integration, data sources, data flow, two-sided funnel model, canonical format, stream of ingestible objects, competing consumer model, well-defined interfaces, actor model, data normalization, tech stack, Kappa architecture, reusability of patterns</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode, Kirk Marple, CEO and founder of Graphlit, shares his expertise on building efficient data integrations.</p>
<p>Kirk breaks down his approach using relatable concepts:</p>
<ol>
 <li>The "Two-Sided Funnel": This model streamlines data flow by converting various data sources into a standard format before distributing it.</li>
 <li>Universal Data Streams: Kirk explains how he transforms diverse data into a single, manageable stream of information.</li>
  <li>Parallel Processing: Learn about the "competing consumer model" that allows for faster data handling.</li>
  <li>Building Blocks for Success: Discover the importance of well-defined interfaces and actor models in creating robust data systems.</li>
  <li>Tech Talk: Kirk discusses data normalization techniques and the potential shift towards a more streamlined "Kappa architecture."</li>
  <li>Reusable Patterns: Find out how Kirk's methods can speed up the integration of new data sources.</li>
</ol>
<p><strong>Kirk Marple:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/kirkmarple/">LinkedIn</a></li>
  <li><a href="https://twitter.com/KirkMarple">X (Twitter)</a></li>
  <li><a href="https://www.graphlit.com/">Graphlit</a></li>
  <li><a href="https://docs.graphlit.dev/">Graphlit Docs</a></li>
</ul>
<p><strong>Nicolay Gerold:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li>
  <li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li>
</ul>
<p><strong>Chapters</strong></p>
<p><strong>00:00</strong> Building Integrations into Different Tools</p>
<p><strong>00:44</strong> The Two-Sided Funnel Model for Data Flow</p>
<p><strong>04:07</strong> Using Well-Defined Interfaces for Faster Integration</p>
<p><strong>04:36</strong> Managing Feeds and State with Actor Models</p>
<p><strong>06:05</strong> The Importance of Data Normalization</p>
<p><strong>10:54</strong> Tech Stack for Data Flow</p>
<p><strong>11:52</strong> Progression towards a Kappa Architecture</p>
<p><strong>13:45</strong> Reusability of Patterns for Faster Integration</p>
<p>data integration, data sources, data flow, two-sided funnel model, canonical format, stream of ingestible objects, competing consumer model, well-defined interfaces, actor model, data normalization, tech stack, Kappa architecture, reusability of patterns</p>]]>
      </content:encoded>
      <pubDate>Tue, 25 Jun 2024 05:19:06 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/8673984a/d3625846.mp3" length="14281661" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/zwAcsqe6rVX53Hlx_fySzvTGCUbP9WjKLMl1ug7nUfU/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9lYzE4/M2UxZDUwNWJkZDY4/MGMxZDFmODg5YmEy/YTQ2ZC5qcGc.jpg"/>
      <itunes:duration>893</itunes:duration>
      <itunes:summary>In this episode, Kirk Marple, CEO and founder of Graphlit, shares his expertise on building efficient data integrations.
Kirk breaks down his approach using relatable concepts:

 The "Two-Sided Funnel": This model streamlines data flow by converting various data sources into a standard format before distributing it.
 Universal Data Streams: Kirk explains how he transforms diverse data into a single, manageable stream of information.
  Parallel Processing: Learn about the "competing consumer model" that allows for faster data handling.
  Building Blocks for Success: Discover the importance of well-defined interfaces and actor models in creating robust data systems.
  Tech Talk: Kirk discusses data normalization techniques and the potential shift towards a more streamlined "Kappa architecture."
  Reusable Patterns: Find out how Kirk's methods can speed up the integration of new data sources.

Kirk Marple:

  LinkedIn
  X (Twitter)
  Graphlit
  Graphlit Docs

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Chapters
00:00 Building Integrations into Different Tools
00:44 The Two-Sided Funnel Model for Data Flow
04:07 Using Well-Defined Interfaces for Faster Integration
04:36 Managing Feeds and State with Actor Models
06:05 The Importance of Data Normalization
10:54 Tech Stack for Data Flow
11:52 Progression towards a Kappa Architecture
13:45 Reusability of Patterns for Faster Integration
data integration, data sources, data flow, two-sided funnel model, canonical format, stream of ingestible objects, competing consumer model, well-defined interfaces, actor model, data normalization, tech stack, Kappa architecture, reusability of patterns</itunes:summary>
      <itunes:subtitle>In this episode, Kirk Marple, CEO and founder of Graphlit, shares his expertise on building efficient data integrations.
Kirk breaks down his approach using relatable concepts:

 The "Two-Sided Funnel": This model streamlines data flow by converting vario</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#013 ETL for LLMs, Integrating and Normalizing Unstructured Data</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>13</itunes:episode>
      <podcast:episode>13</podcast:episode>
      <itunes:title>#013 ETL for LLMs, Integrating and Normalizing Unstructured Data</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">f291ec97-9013-4e65-a3c8-6df96611e14f</guid>
      <link>https://share.transistor.fm/s/9839e24f</link>
      <description>
        <![CDATA[<p>In our latest episode, we sit down with Derek Tu, Founder and CEO of Carbon, a cutting-edge ETL tool designed specifically for large language models (LLMs).</p><p>Carbon is streamlining AI development by providing a platform for integrating unstructured data from various sources, enabling businesses to build innovative AI applications more efficiently while addressing data privacy and ethical concerns.</p><ul><li>"I think people are trying to optimize around the chunking strategy... But for me, that seems a bit maybe not focusing on the right area of optimization. These embedding models themselves have gone just like, so much more advanced over the past five to 10 years that regardless of what representation you're passing in, they do a pretty good job of being able to understand that information semantically and returning the relevant chunks." - Derek Tu on the importance of embedding models over chunking strategies</li><li>"If you are cost conscious and if you're worried about performance, I would definitely look at quantizing your embeddings. I think we've probably been able to, I don't have like the exact numbers here, but I think we might be saving at least half, right, in storage costs by quantizing everything." - Derek Tu on optimizing costs and performance with vector databases</li></ul><p><strong>Derek Tu:</strong></p><ul><li><a href="https://www.linkedin.com/in/derek2tu/">LinkedIn</a></li><li><a href="https://carbon.ai/">Carbon</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Key Takeaways:</strong></p><ul><li>Understand your data sources: Before building your ETL pipeline, thoroughly assess the various data sources you'll be working with, such as Slack, Email, Google Docs, and more. Consider the unique characteristics of each source, including data format, structure, and metadata.</li><li>Normalize and preprocess data: Develop strategies to normalize and preprocess the unstructured data from different sources. This may involve parsing, cleaning, and transforming the data into a standardized format that can be easily consumed by your AI models.</li><li>Experiment with chunking strategies: While there's no one-size-fits-all approach to chunking, it's essential to experiment with different strategies to find what works best for your specific use case. Consider factors like data format, structure, and the desired granularity of the chunks.</li><li>Leverage metadata and tagging: Metadata and tagging can play a crucial role in organizing and retrieving relevant data for your AI models. Implement mechanisms to capture and store important metadata, such as document types, topics, and timestamps, and consider using AI-powered tagging to automatically categorize your data.</li><li>Choose the right embedding model: Embedding models have advanced significantly in recent years, so focus on selecting the right model for your needs rather than over-optimizing chunking strategies. Consider factors like model performance, dimensionality, and compatibility with your data types.</li><li>Optimize vector database usage: When working with vector databases, consider techniques like quantization to reduce storage costs and improve performance. Experiment with different configurations and settings to find the optimal balance for your specific use case.</li></ul><p>00:00 Introduction and Optimizing Embedding Models</p><p>03:00 The Evolution of Carbon and Focus on Unstructured Data</p><p>06:19 Customer Progression and Target Group</p><p>09:43 Interesting Use Cases and Handling Different Data Representations</p><p>13:30 Chunking Strategies and Normalization</p><p>20:14 Approach to Chunking and Choosing a Vector Database</p><p>23:06 Tech Stack and Recommended Tools</p><p>28:19 Future of Carbon: Multimodal Models and Building a Platform</p><p>Carbon, LLMs, RAG, chunking, data processing, global customer base, GDPR compliance, AI founders, AI agents, enterprises</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In our latest episode, we sit down with Derek Tu, Founder and CEO of Carbon, a cutting-edge ETL tool designed specifically for large language models (LLMs).</p><p>Carbon is streamlining AI development by providing a platform for integrating unstructured data from various sources, enabling businesses to build innovative AI applications more efficiently while addressing data privacy and ethical concerns.</p><ul><li>"I think people are trying to optimize around the chunking strategy... But for me, that seems a bit maybe not focusing on the right area of optimization. These embedding models themselves have gone just like, so much more advanced over the past five to 10 years that regardless of what representation you're passing in, they do a pretty good job of being able to understand that information semantically and returning the relevant chunks." - Derek Tu on the importance of embedding models over chunking strategies</li><li>"If you are cost conscious and if you're worried about performance, I would definitely look at quantizing your embeddings. I think we've probably been able to, I don't have like the exact numbers here, but I think we might be saving at least half, right, in storage costs by quantizing everything." - Derek Tu on optimizing costs and performance with vector databases</li></ul><p><strong>Derek Tu:</strong></p><ul><li><a href="https://www.linkedin.com/in/derek2tu/">LinkedIn</a></li><li><a href="https://carbon.ai/">Carbon</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Key Takeaways:</strong></p><ul><li>Understand your data sources: Before building your ETL pipeline, thoroughly assess the various data sources you'll be working with, such as Slack, Email, Google Docs, and more. Consider the unique characteristics of each source, including data format, structure, and metadata.</li><li>Normalize and preprocess data: Develop strategies to normalize and preprocess the unstructured data from different sources. This may involve parsing, cleaning, and transforming the data into a standardized format that can be easily consumed by your AI models.</li><li>Experiment with chunking strategies: While there's no one-size-fits-all approach to chunking, it's essential to experiment with different strategies to find what works best for your specific use case. Consider factors like data format, structure, and the desired granularity of the chunks.</li><li>Leverage metadata and tagging: Metadata and tagging can play a crucial role in organizing and retrieving relevant data for your AI models. Implement mechanisms to capture and store important metadata, such as document types, topics, and timestamps, and consider using AI-powered tagging to automatically categorize your data.</li><li>Choose the right embedding model: Embedding models have advanced significantly in recent years, so focus on selecting the right model for your needs rather than over-optimizing chunking strategies. Consider factors like model performance, dimensionality, and compatibility with your data types.</li><li>Optimize vector database usage: When working with vector databases, consider techniques like quantization to reduce storage costs and improve performance. Experiment with different configurations and settings to find the optimal balance for your specific use case.</li></ul><p>00:00 Introduction and Optimizing Embedding Models</p><p>03:00 The Evolution of Carbon and Focus on Unstructured Data</p><p>06:19 Customer Progression and Target Group</p><p>09:43 Interesting Use Cases and Handling Different Data Representations</p><p>13:30 Chunking Strategies and Normalization</p><p>20:14 Approach to Chunking and Choosing a Vector Database</p><p>23:06 Tech Stack and Recommended Tools</p><p>28:19 Future of Carbon: Multimodal Models and Building a Platform</p><p>Carbon, LLMs, RAG, chunking, data processing, global customer base, GDPR compliance, AI founders, AI agents, enterprises</p>]]>
      </content:encoded>
      <pubDate>Wed, 19 Jun 2024 05:55:32 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/9839e24f/082be538.mp3" length="35327144" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/BlT4R19cw4TantvcDnr4CQ7ElGTlVwoGhKMV8vm5zXQ/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jYmE5/Zjg5OWNhZDc1ZjAw/MmExMjFhZTZlYTA4/MmQ1Ny5qcGc.jpg"/>
      <itunes:duration>2208</itunes:duration>
      <itunes:summary>In our latest episode, we sit down with Derek Tu, Founder and CEO of Carbon, a cutting-edge ETL tool designed specifically for large language models (LLMs).
Carbon is streamlining AI development by providing a platform for integrating unstructured data from various sources, enabling businesses to build innovative AI applications more efficiently while addressing data privacy and ethical concerns.

 "I think people are trying to optimize around the chunking strategy... But for me, that seems a bit maybe not focusing on the right area of optimization. These embedding models themselves have gone just like, so much more advanced over the past five to 10 years that regardless of what representation you're passing in, they do a pretty good job of being able to understand that information semantically and returning the relevant chunks." - Derek Tu on the importance of embedding models over chunking strategies
 "If you are cost conscious and if you're worried about performance, I would definitely look at quantizing your embeddings. I think we've probably been able to, I don't have like the exact numbers here, but I think we might be saving at least half, right, in storage costs by quantizing everything." - Derek Tu on optimizing costs and performance with vector databases

Derek Tu:

  LinkedIn
  Carbon

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Key Takeaways:

  Understand your data sources: Before building your ETL pipeline, thoroughly assess the various data sources you'll be working with, such as Slack, Email, Google Docs, and more. Consider the unique characteristics of each source, including data format, structure, and metadata.
  Normalize and preprocess data: Develop strategies to normalize and preprocess the unstructured data from different sources. This may involve parsing, cleaning, and transforming the data into a standardized format that can be easily consumed by your AI models.
  Experiment with chunking strategies: While there's no one-size-fits-all approach to chunking, it's essential to experiment with different strategies to find what works best for your specific use case. Consider factors like data format, structure, and the desired granularity of the chunks.
  Leverage metadata and tagging: Metadata and tagging can play a crucial role in organizing and retrieving relevant data for your AI models. Implement mechanisms to capture and store important metadata, such as document types, topics, and timestamps, and consider using AI-powered tagging to automatically categorize your data.
  Choose the right embedding model: Embedding models have advanced significantly in recent years, so focus on selecting the right model for your needs rather than over-optimizing chunking strategies. Consider factors like model performance, dimensionality, and compatibility with your data types.
  Optimize vector database usage: When working with vector databases, consider techniques like quantization to reduce storage costs and improve performance. Experiment with different configurations and settings to find the optimal balance for your specific use case.

00:00 Introduction and Optimizing Embedding Models
03:00 The Evolution of Carbon and Focus on Unstructured Data
06:19 Customer Progression and Target Group
09:43 Interesting Use Cases and Handling Different Data Representations
13:30 Chunking Strategies and Normalization
20:14 Approach to Chunking and Choosing a Vector Database
23:06 Tech Stack and Recommended Tools
28:19 Future of Carbon: Multimodal Models and Building a Platform
Carbon, LLMs, RAG, chunking, data processing, global customer base, GDPR compliance, AI founders, AI agents, enterprises</itunes:summary>
      <itunes:subtitle>In our latest episode, we sit down with Derek Tu, Founder and CEO of Carbon, a cutting-edge ETL tool designed specifically for large language models (LLMs).
Carbon is streamlining AI development by providing a platform for integrating unstructured data f</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#012 Serverless Data Orchestration, AI in the Data Stack, AI Pipelines </title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>12</itunes:episode>
      <podcast:episode>12</podcast:episode>
      <itunes:title>#012 Serverless Data Orchestration, AI in the Data Stack, AI Pipelines </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">1ef3d39c-0056-49e0-8a42-b742b31f72d6</guid>
      <link>https://share.transistor.fm/s/5adaa99a</link>
      <description>
        <![CDATA[<p>In this episode, Nicolay sits down with Hugo Lu, founder and CEO of Orchestra, a modern data orchestration platform. As data pipelines and analytics workflows become increasingly complex, spanning multiple teams, tools and cloud services, the need for unified orchestration and visibility has never been greater.</p><p>Orchestra is a serverless data orchestration tool that aims to provide a unified control plane for managing data pipelines, infrastructure, and analytics across an organization's modern data stack.</p><p>The core architecture involves users building pipelines as code which then run on Orchestra's serverless infrastructure. It can orchestrate tasks like data ingestion, transformation, AI calls, as well as monitoring and getting analytics on data products. All with end-to-end visibility, data lineage and governance even when organizations have a scattered, modular data architecture across teams and tools.</p><p><strong>Key Quotes:</strong></p><ul><li>Find the right level of abstraction when building data orchestration tasks/workflows. "I think the right level of abstraction is always good. I think like Prefect do this really well, right? Their big sell was, just put a decorator on a function and it becomes a task. That is a great idea. You know, just make tasks modular and have them do all the boilerplate stuff like error logging, monitoring of data, all of that stuff.‚Äù</li><li>Modularize data pipeline components: "It's just around understanding what that dev workflow should look like. I think it should be a bit more modular." Having a modular architecture where different components like data ingestion, transformation, model training are decoupled allows better flexibility and scalability.</li><li>Adopt a streaming/event-driven architecture for low-latency AI use cases: "If you've got an event-driven architecture, then, you know, that's not what you use an orchestration tool for...if you're having a conversation with a chatbot, like, you know, you're sending messages, you're sending events, you're getting a response back. That I would argue should be dealt with by microservices."</li></ul><p><strong>Hugo Lu:</strong></p><ul><li><a href="https://www.linkedin.com/in/hugo-lu-confirmed/">LinkedIn</a></li><li><a href="https://dataopsleadership.substack.com/">Newsletter</a></li><li><a href="https://www.getorchestra.io/">Orchestra</a></li><li><a href="https://orchestra-1.gitbook.io/orchestra-portal">Orchestra Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Introduction to Orchestra and its Focus on Data Products</p><p><strong>08:03</strong> Unified Control Plane for Data Stack and End-to-End Control</p><p><strong>14:42</strong> Use Cases and Unique Applications of Orchestra</p><p><strong>19:31</strong> Retaining Existing Dev Workflows and Best Practices in Orchestra</p><p><strong>22:23</strong> Event-Driven Architectures and Monitoring in Orchestra</p><p><strong>23:49</strong> Putting Data Products First and Monitoring Health and Usage</p><p><strong>25:40</strong> The Future of Data Orchestration: Stream-Based and Cost-Effective</p><p>data orchestration, Orchestra, serverless architecture, versatility, use cases, maturity levels, challenges, AI workloads</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode, Nicolay sits down with Hugo Lu, founder and CEO of Orchestra, a modern data orchestration platform. As data pipelines and analytics workflows become increasingly complex, spanning multiple teams, tools and cloud services, the need for unified orchestration and visibility has never been greater.</p><p>Orchestra is a serverless data orchestration tool that aims to provide a unified control plane for managing data pipelines, infrastructure, and analytics across an organization's modern data stack.</p><p>The core architecture involves users building pipelines as code which then run on Orchestra's serverless infrastructure. It can orchestrate tasks like data ingestion, transformation, AI calls, as well as monitoring and getting analytics on data products. All with end-to-end visibility, data lineage and governance even when organizations have a scattered, modular data architecture across teams and tools.</p><p><strong>Key Quotes:</strong></p><ul><li>Find the right level of abstraction when building data orchestration tasks/workflows. "I think the right level of abstraction is always good. I think like Prefect do this really well, right? Their big sell was, just put a decorator on a function and it becomes a task. That is a great idea. You know, just make tasks modular and have them do all the boilerplate stuff like error logging, monitoring of data, all of that stuff.‚Äù</li><li>Modularize data pipeline components: "It's just around understanding what that dev workflow should look like. I think it should be a bit more modular." Having a modular architecture where different components like data ingestion, transformation, model training are decoupled allows better flexibility and scalability.</li><li>Adopt a streaming/event-driven architecture for low-latency AI use cases: "If you've got an event-driven architecture, then, you know, that's not what you use an orchestration tool for...if you're having a conversation with a chatbot, like, you know, you're sending messages, you're sending events, you're getting a response back. That I would argue should be dealt with by microservices."</li></ul><p><strong>Hugo Lu:</strong></p><ul><li><a href="https://www.linkedin.com/in/hugo-lu-confirmed/">LinkedIn</a></li><li><a href="https://dataopsleadership.substack.com/">Newsletter</a></li><li><a href="https://www.getorchestra.io/">Orchestra</a></li><li><a href="https://orchestra-1.gitbook.io/orchestra-portal">Orchestra Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Introduction to Orchestra and its Focus on Data Products</p><p><strong>08:03</strong> Unified Control Plane for Data Stack and End-to-End Control</p><p><strong>14:42</strong> Use Cases and Unique Applications of Orchestra</p><p><strong>19:31</strong> Retaining Existing Dev Workflows and Best Practices in Orchestra</p><p><strong>22:23</strong> Event-Driven Architectures and Monitoring in Orchestra</p><p><strong>23:49</strong> Putting Data Products First and Monitoring Health and Usage</p><p><strong>25:40</strong> The Future of Data Orchestration: Stream-Based and Cost-Effective</p><p>data orchestration, Orchestra, serverless architecture, versatility, use cases, maturity levels, challenges, AI workloads</p>]]>
      </content:encoded>
      <pubDate>Fri, 14 Jun 2024 05:16:07 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/5adaa99a/3a5d5014.mp3" length="26962533" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/QIEU1JXC7t2Au0Hpfj8rTQkvIHi6SpcCMJQ0a0HTDIw/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mYmYz/NDk0NmNjNTNjYWE0/ODcxNjY0ZjFmM2Jh/ZGE5NS5qcGc.jpg"/>
      <itunes:duration>1686</itunes:duration>
      <itunes:summary>In this episode, Nicolay sits down with Hugo Lu, founder and CEO of Orchestra, a modern data orchestration platform. As data pipelines and analytics workflows become increasingly complex, spanning multiple teams, tools and cloud services, the need for unified orchestration and visibility has never been greater.
Orchestra is a serverless data orchestration tool that aims to provide a unified control plane for managing data pipelines, infrastructure, and analytics across an organization's modern data stack.
The core architecture involves users building pipelines as code which then run on Orchestra's serverless infrastructure. It can orchestrate tasks like data ingestion, transformation, AI calls, as well as monitoring and getting analytics on data products. All with end-to-end visibility, data lineage and governance even when organizations have a scattered, modular data architecture across teams and tools.
Key Quotes:

 Find the right level of abstraction when building data orchestration tasks/workflows.
"I think the right level of abstraction is always good. I think like Prefect do this really well, right? Their big sell was, just put a decorator on a function and it becomes a task. That is a great idea. You know, just make tasks modular and have them do all the boilerplate stuff like error logging, monitoring of data, all of that stuff.‚Äù
 Modularize data pipeline components:
"It's just around understanding what that dev workflow should look like. I think it should be a bit more modular."
Having a modular architecture where different components like data ingestion, transformation, model training are decoupled allows better flexibility and scalability.
  Adopt a streaming/event-driven architecture for low-latency AI use cases:
"If you've got an event-driven architecture, then, you know, that's not what you use an orchestration tool for...if you're having a conversation with a chatbot, like, you know, you're sending messages, you're sending events, you're getting a response back. That I would argue should be dealt with by microservices."

Hugo Lu:

  LinkedIn
  Newsletter
  Orchestra
  Orchestra Docs

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

00:00 Introduction to Orchestra and its Focus on Data Products
08:03 Unified Control Plane for Data Stack and End-to-End Control
14:42 Use Cases and Unique Applications of Orchestra
19:31 Retaining Existing Dev Workflows and Best Practices in Orchestra
22:23 Event-Driven Architectures and Monitoring in Orchestra
23:49 Putting Data Products First and Monitoring Health and Usage
25:40 The Future of Data Orchestration: Stream-Based and Cost-Effective
data orchestration, Orchestra, serverless architecture, versatility, use cases, maturity levels, challenges, AI workloads</itunes:summary>
      <itunes:subtitle>In this episode, Nicolay sits down with Hugo Lu, founder and CEO of Orchestra, a modern data orchestration platform. As data pipelines and analytics workflows become increasingly complex, spanning multiple teams, tools and cloud services, the need for uni</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#011 Mastering Vector Databases, Product &amp; Binary Quantization, Multi-Vector Search</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>11</itunes:episode>
      <podcast:episode>11</podcast:episode>
      <itunes:title>#011 Mastering Vector Databases, Product &amp; Binary Quantization, Multi-Vector Search</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">156edf75-25cd-4272-98f7-cdb1b68924db</guid>
      <link>https://share.transistor.fm/s/3860c97c</link>
      <description>
        <![CDATA[<p>Ever wondered how AI systems handle images and videos, or how they make lightning-fast recommendations? Tune in as Nicolay chats with Zain Hassan, an expert in vector databases from Weaviate. They break down complex topics like quantization, multi-vector search, and the potential of multimodal search, making them accessible for all listeners. Zain even shares a sneak peek into the future, where vector databases might connect our brains with computers!</p><p><strong>Zain Hasan:</strong></p><ul><li><a href="https://www.linkedin.com/in/zainhas">LinkedIn</a></li><li><a href="https://x.com/zainhasan6">X (Twitter)</a></li><li><a href="https://weaviate.io/">Weaviate</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Key Insights:</strong></p><ul><li>Vector databases can handle not just text, but also image, audio, and video data</li><li>Quantization is a powerful technique to significantly reduce costs and enable in-memory search</li><li>Binary quantization allows efficient brute force search for smaller datasets</li><li>Multi-vector search enables retrieval of heterogeneous data types within the same index</li><li>The future lies in multimodal search and recommendations across different senses</li><li>Brain-computer interfaces and EEG foundation models are exciting areas to watch</li></ul><p><strong>Key Quotes:</strong></p><ul><li>"Vector databases are pretty much the commercialization and the productization of representation learning."</li><li>"I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."</li><li>"Going from text to multimedia in vector databases is really simple."</li><li>"Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."</li></ul><p><strong>Chapters</strong></p><p>00:00 - 01:24 Introduction</p><p>01:24 - 03:48 Underappreciated aspects of vector databases</p><p>03:48 - 06:06 Quantization trade-offs and techniques</p><ul><li>Various quantization techniques: binary quantization, product quantization, scalar quantization</li></ul><p>06:06 - 08:24 Binary quantization</p><ul><li>Reducing vectors from 32-bits per dimension down to 1-bit</li><li>Enables efficient in-memory brute force search for smaller datasets</li><li>Requires normally distributed data between negative and positive values</li></ul><p>08:24 - 10:44 Product quantization and other techniques</p><ul><li>Alternative to binary quantization, segments vectors and clusters each segment</li><li>Scalar quantization reduces vectors to 8-bits per dimension</li></ul><p>10:44 - 13:08 Quantization as a "superpower" to reduce costs</p><p>13:08 - 15:34 Comparing quantization approaches</p><p>15:34 - 17:51 Placing vector databases in the database landscape</p><p>17:51 - 20:12 Pruning unused vectors and nodes</p><p>20:12 - 22:37 Improving precision beyond similarity thresholds</p><p>22:37 - 25:03 Multi-vector search</p><p>25:03 - 27:11 Impact of vector databases on data interaction</p><p>27:11 - 29:35 Interesting and weird use cases</p><p>29:35 - 32:00 Future of multimodal search and recommendations</p><p>32:00 - 34:22 Extending recommendations to user data</p><p>34:22 - 36:39 What's next for Weaviate</p><p>36:39 - 38:57 Exciting technologies beyond vector databases and LLMs</p><p>vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Ever wondered how AI systems handle images and videos, or how they make lightning-fast recommendations? Tune in as Nicolay chats with Zain Hassan, an expert in vector databases from Weaviate. They break down complex topics like quantization, multi-vector search, and the potential of multimodal search, making them accessible for all listeners. Zain even shares a sneak peek into the future, where vector databases might connect our brains with computers!</p><p><strong>Zain Hasan:</strong></p><ul><li><a href="https://www.linkedin.com/in/zainhas">LinkedIn</a></li><li><a href="https://x.com/zainhasan6">X (Twitter)</a></li><li><a href="https://weaviate.io/">Weaviate</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Key Insights:</strong></p><ul><li>Vector databases can handle not just text, but also image, audio, and video data</li><li>Quantization is a powerful technique to significantly reduce costs and enable in-memory search</li><li>Binary quantization allows efficient brute force search for smaller datasets</li><li>Multi-vector search enables retrieval of heterogeneous data types within the same index</li><li>The future lies in multimodal search and recommendations across different senses</li><li>Brain-computer interfaces and EEG foundation models are exciting areas to watch</li></ul><p><strong>Key Quotes:</strong></p><ul><li>"Vector databases are pretty much the commercialization and the productization of representation learning."</li><li>"I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."</li><li>"Going from text to multimedia in vector databases is really simple."</li><li>"Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."</li></ul><p><strong>Chapters</strong></p><p>00:00 - 01:24 Introduction</p><p>01:24 - 03:48 Underappreciated aspects of vector databases</p><p>03:48 - 06:06 Quantization trade-offs and techniques</p><ul><li>Various quantization techniques: binary quantization, product quantization, scalar quantization</li></ul><p>06:06 - 08:24 Binary quantization</p><ul><li>Reducing vectors from 32-bits per dimension down to 1-bit</li><li>Enables efficient in-memory brute force search for smaller datasets</li><li>Requires normally distributed data between negative and positive values</li></ul><p>08:24 - 10:44 Product quantization and other techniques</p><ul><li>Alternative to binary quantization, segments vectors and clusters each segment</li><li>Scalar quantization reduces vectors to 8-bits per dimension</li></ul><p>10:44 - 13:08 Quantization as a "superpower" to reduce costs</p><p>13:08 - 15:34 Comparing quantization approaches</p><p>15:34 - 17:51 Placing vector databases in the database landscape</p><p>17:51 - 20:12 Pruning unused vectors and nodes</p><p>20:12 - 22:37 Improving precision beyond similarity thresholds</p><p>22:37 - 25:03 Multi-vector search</p><p>25:03 - 27:11 Impact of vector databases on data interaction</p><p>27:11 - 29:35 Interesting and weird use cases</p><p>29:35 - 32:00 Future of multimodal search and recommendations</p><p>32:00 - 34:22 Extending recommendations to user data</p><p>34:22 - 36:39 What's next for Weaviate</p><p>36:39 - 38:57 Exciting technologies beyond vector databases and LLMs</p><p>vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</p>]]>
      </content:encoded>
      <pubDate>Fri, 07 Jun 2024 03:49:08 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/3860c97c/14d1e728.mp3" length="38488180" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/wbw5RvHxZoWDdzCvwgLSoWkUhWd82O7dnfUoy_kNyqs/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9jZTVh/ZTgyZjU3MWIwZDQ3/ZjFjZDcwYjViYWNj/ODBlOS5qcGc.jpg"/>
      <itunes:duration>2406</itunes:duration>
      <itunes:summary>Ever wondered how AI systems handle images and videos, or how they make lightning-fast recommendations? Tune in as Nicolay chats with Zain Hassan, an expert in vector databases from Weaviate. They break down complex topics like quantization, multi-vector search, and the potential of multimodal search, making them accessible for all listeners. Zain even shares a sneak peek into the future, where vector databases might connect our brains with computers!
Zain Hasan:

 LinkedIn
 X (Twitter)
  Weaviate

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Key Insights:

  Vector databases can handle not just text, but also image, audio, and video data
  Quantization is a powerful technique to significantly reduce costs and enable in-memory search
  Binary quantization allows efficient brute force search for smaller datasets


  Multi-vector search enables retrieval of heterogeneous data types within the same index
  The future lies in multimodal search and recommendations across different senses
  Brain-computer interfaces and EEG foundation models are exciting areas to watch

Key Quotes:

  "Vector databases are pretty much the commercialization and the productization of representation learning."
  "I think quantization, it builds on the assumption that there is still noise in the embeddings. And if I'm looking, it's pretty similar as well to the thought of Matryoshka embeddings that I can reduce the dimensionality."
  "Going from text to multimedia in vector databases is really simple."
  "Vector databases allow you to take all the advances that are happening in machine learning and now just simply turn a switch and use them for your application."

Chapters
00:00 - 01:24 Introduction
01:24 - 03:48 Underappreciated aspects of vector databases
03:48 - 06:06 Quantization trade-offs and techniques

  Various quantization techniques: binary quantization, product quantization, scalar quantization

06:06 - 08:24 Binary quantization

  Reducing vectors from 32-bits per dimension down to 1-bit
  Enables efficient in-memory brute force search for smaller datasets
  Requires normally distributed data between negative and positive values

08:24 - 10:44 Product quantization and other techniques

  Alternative to binary quantization, segments vectors and clusters each segment
  Scalar quantization reduces vectors to 8-bits per dimension

10:44 - 13:08 Quantization as a "superpower" to reduce costs
13:08 - 15:34 Comparing quantization approaches
15:34 - 17:51 Placing vector databases in the database landscape
17:51 - 20:12 Pruning unused vectors and nodes
20:12 - 22:37 Improving precision beyond similarity thresholds
22:37 - 25:03 Multi-vector search
25:03 - 27:11 Impact of vector databases on data interaction
27:11 - 29:35 Interesting and weird use cases
29:35 - 32:00 Future of multimodal search and recommendations
32:00 - 34:22 Extending recommendations to user data
34:22 - 36:39 What's next for Weaviate
36:39 - 38:57 Exciting technologies beyond vector databases and LLMs
vector databases, quantization, hybrid search, multi-vector support, representation learning, cost reduction, memory optimization, multimodal recommender systems, brain-computer interfaces, weather prediction models, AI applications</itunes:summary>
      <itunes:subtitle>Ever wondered how AI systems handle images and videos, or how they make lightning-fast recommendations? Tune in as Nicolay chats with Zain Hassan, an expert in vector databases from Weaviate. They break down complex topics like quantization, multi-vector </itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#010 Building Robust AI and Data Systems, Data Architecture, Data Quality, Data Storage</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>10</itunes:episode>
      <podcast:episode>10</podcast:episode>
      <itunes:title>#010 Building Robust AI and Data Systems, Data Architecture, Data Quality, Data Storage</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">0edb244b-f311-4efa-b531-bd9306d92704</guid>
      <link>https://share.transistor.fm/s/01e58a08</link>
      <description>
        <![CDATA[<p>In this episode of "How AI is Built", data architect Anjan Banerjee provides an in-depth look at the world of data architecture and building complex AI and data systems. Anjan breaks down the basics using simple analogies, explaining how data architecture involves sorting, cleaning, and painting a picture with data, much like organizing Lego bricks to build a structure.</p><p><strong>Summary by Section</strong></p><p>Introduction</p><ul><li>Anjan Banerjee, a data architect, discusses building complex AI and data systems</li><li>Explains the basics of data architecture using Lego and chat app examples</li></ul><p>Sources and Tools</p><ul><li>Identifying data sources is the first step in designing a data architecture</li><li>Pick the right tools to extract data based on use cases (block storage for images, time series DB, etc.)</li><li>Use one tool for most activities if possible, but specialized tools offer benefits</li><li>Multi-modal storage engines are gaining popularity (Snowflake, Databricks, BigQuery)</li></ul><p>Airflow and Orchestration</p><ul><li>Airflow is versatile but has a learning curve; good for orgs with Python/data engineering skills</li><li>For less technical orgs, GUI-based tools like Talend, Alteryx may be better</li><li>AWS Step Functions and managed Airflow are improving native orchestration capabilities</li><li>For multi-cloud, prefer platform-agnostic tools like Astronomer, Prefect, Airbyte</li></ul><p>AI and Data Processing</p><ul><li>ML is key for data-intensive use cases to avoid storing/processing petabytes in cloud</li><li>TinyML and edge computing enable ML inference on device (drones, manufacturing)</li><li>Cloud batch processing still dominates for user targeting, recommendations</li></ul><p>Data Lakes and Storage</p><ul><li>Storage choice depends on data types, use cases, cloud ecosystem</li><li>Delta Lake excels at data versioning and consistency; Iceberg at partitioning and metadata</li><li>Pulling data into separate system often needed for advanced analytics beyond source system</li></ul><p>Data Quality and Standardization</p><ul><li>"Poka-yoke" error-proofing of input screens is vital for downstream data quality</li><li>Impose data quality rules and unified schemas (e.g. UTC timestamps) during ingestion</li><li>Complexity arises with multi-region compliance (GDPR, CCPA) requiring encryption, sanitization</li></ul><p>Hot Takes and Wishes</p><ul><li>Snowflake is overhyped; great UX but costly at scale. Databricks is preferred.</li><li>Automated data set joining and entity resolution across systems would be a game-changer</li></ul><p><strong>Anjan Banerjee:</strong></p><ul><li><a href="https://www.linkedin.com/in/anjanban212/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Understanding Data Architecture</p><p><strong>12:36</strong> Choosing the Right Tools</p><p><strong>20:36</strong> The Benefits of Serverless Functions</p><p><strong>21:34</strong> Integrating AI in Data Acquisition</p><p><strong>24:31</strong> The Trend Towards Single Node Engines</p><p><strong>26:51</strong> Choosing the Right Database Management System and Storage</p><p><strong>29:45</strong> Adding Additional Storage Components</p><p><strong>32:35</strong> Reducing Human Errors for Better Data Quality</p><p><strong>39:07</strong> Overhyped and Underutilized Tools</p><p>Data architecture, AI, data systems, data sources, data extraction, data storage, multi-modal storage engines, data orchestration, Airflow, edge computing, batch processing, data lakes, Delta Lake, Iceberg, data quality, standardization, poka-yoke, compliance, entity resolution</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode of "How AI is Built", data architect Anjan Banerjee provides an in-depth look at the world of data architecture and building complex AI and data systems. Anjan breaks down the basics using simple analogies, explaining how data architecture involves sorting, cleaning, and painting a picture with data, much like organizing Lego bricks to build a structure.</p><p><strong>Summary by Section</strong></p><p>Introduction</p><ul><li>Anjan Banerjee, a data architect, discusses building complex AI and data systems</li><li>Explains the basics of data architecture using Lego and chat app examples</li></ul><p>Sources and Tools</p><ul><li>Identifying data sources is the first step in designing a data architecture</li><li>Pick the right tools to extract data based on use cases (block storage for images, time series DB, etc.)</li><li>Use one tool for most activities if possible, but specialized tools offer benefits</li><li>Multi-modal storage engines are gaining popularity (Snowflake, Databricks, BigQuery)</li></ul><p>Airflow and Orchestration</p><ul><li>Airflow is versatile but has a learning curve; good for orgs with Python/data engineering skills</li><li>For less technical orgs, GUI-based tools like Talend, Alteryx may be better</li><li>AWS Step Functions and managed Airflow are improving native orchestration capabilities</li><li>For multi-cloud, prefer platform-agnostic tools like Astronomer, Prefect, Airbyte</li></ul><p>AI and Data Processing</p><ul><li>ML is key for data-intensive use cases to avoid storing/processing petabytes in cloud</li><li>TinyML and edge computing enable ML inference on device (drones, manufacturing)</li><li>Cloud batch processing still dominates for user targeting, recommendations</li></ul><p>Data Lakes and Storage</p><ul><li>Storage choice depends on data types, use cases, cloud ecosystem</li><li>Delta Lake excels at data versioning and consistency; Iceberg at partitioning and metadata</li><li>Pulling data into separate system often needed for advanced analytics beyond source system</li></ul><p>Data Quality and Standardization</p><ul><li>"Poka-yoke" error-proofing of input screens is vital for downstream data quality</li><li>Impose data quality rules and unified schemas (e.g. UTC timestamps) during ingestion</li><li>Complexity arises with multi-region compliance (GDPR, CCPA) requiring encryption, sanitization</li></ul><p>Hot Takes and Wishes</p><ul><li>Snowflake is overhyped; great UX but costly at scale. Databricks is preferred.</li><li>Automated data set joining and entity resolution across systems would be a game-changer</li></ul><p><strong>Anjan Banerjee:</strong></p><ul><li><a href="https://www.linkedin.com/in/anjanban212/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Understanding Data Architecture</p><p><strong>12:36</strong> Choosing the Right Tools</p><p><strong>20:36</strong> The Benefits of Serverless Functions</p><p><strong>21:34</strong> Integrating AI in Data Acquisition</p><p><strong>24:31</strong> The Trend Towards Single Node Engines</p><p><strong>26:51</strong> Choosing the Right Database Management System and Storage</p><p><strong>29:45</strong> Adding Additional Storage Components</p><p><strong>32:35</strong> Reducing Human Errors for Better Data Quality</p><p><strong>39:07</strong> Overhyped and Underutilized Tools</p><p>Data architecture, AI, data systems, data sources, data extraction, data storage, multi-modal storage engines, data orchestration, Airflow, edge computing, batch processing, data lakes, Delta Lake, Iceberg, data quality, standardization, poka-yoke, compliance, entity resolution</p>]]>
      </content:encoded>
      <pubDate>Fri, 31 May 2024 03:43:39 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/01e58a08/756d2a3d.mp3" length="43728564" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/8rPkodsOy5tilgNW2aav76j4sGGnk-gy7Pr_51BEr14/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS82NmE4/M2Y3YjQ1NWI3ZDg5/NzcxMDg4NzE3NmIy/NDA1OS5qcGc.jpg"/>
      <itunes:duration>2733</itunes:duration>
      <itunes:summary>In this episode of "How AI is Built", data architect Anjan Banerjee provides an in-depth look at the world of data architecture and building complex AI and data systems. Anjan breaks down the basics using simple analogies, explaining how data architecture involves sorting, cleaning, and painting a picture with data, much like organizing Lego bricks to build a structure.
Summary by Section
Introduction

 Anjan Banerjee, a data architect, discusses building complex AI and data systems
 Explains the basics of data architecture using Lego and chat app examples

Sources and Tools

  Identifying data sources is the first step in designing a data architecture
  Pick the right tools to extract data based on use cases (block storage for images, time series DB, etc.)
  Use one tool for most activities if possible, but specialized tools offer benefits
  Multi-modal storage engines are gaining popularity (Snowflake, Databricks, BigQuery)

Airflow and Orchestration

  Airflow is versatile but has a learning curve; good for orgs with Python/data engineering skills
  For less technical orgs, GUI-based tools like Talend, Alteryx may be better
  AWS Step Functions and managed Airflow are improving native orchestration capabilities
  For multi-cloud, prefer platform-agnostic tools like Astronomer, Prefect, Airbyte

AI and Data Processing

  ML is key for data-intensive use cases to avoid storing/processing petabytes in cloud
  TinyML and edge computing enable ML inference on device (drones, manufacturing)
  Cloud batch processing still dominates for user targeting, recommendations

Data Lakes and Storage

  Storage choice depends on data types, use cases, cloud ecosystem
  Delta Lake excels at data versioning and consistency; Iceberg at partitioning and metadata
  Pulling data into separate system often needed for advanced analytics beyond source system

Data Quality and Standardization

  "Poka-yoke" error-proofing of input screens is vital for downstream data quality
  Impose data quality rules and unified schemas (e.g. UTC timestamps) during ingestion
  Complexity arises with multi-region compliance (GDPR, CCPA) requiring encryption, sanitization

Hot Takes and Wishes

  Snowflake is overhyped; great UX but costly at scale. Databricks is preferred.
  Automated data set joining and entity resolution across systems would be a game-changer

Anjan Banerjee:

  LinkedIn

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

00:00 Understanding Data Architecture
12:36 Choosing the Right Tools
20:36 The Benefits of Serverless Functions
21:34 Integrating AI in Data Acquisition
24:31 The Trend Towards Single Node Engines
26:51 Choosing the Right Database Management System and Storage
29:45 Adding Additional Storage Components
32:35 Reducing Human Errors for Better Data Quality
39:07 Overhyped and Underutilized Tools
Data architecture, AI, data systems, data sources, data extraction, data storage, multi-modal storage engines, data orchestration, Airflow, edge computing, batch processing, data lakes, Delta Lake, Iceberg, data quality, standardization, poka-yoke, compliance, entity resolution</itunes:summary>
      <itunes:subtitle>In this episode of "How AI is Built", data architect Anjan Banerjee provides an in-depth look at the world of data architecture and building complex AI and data systems. Anjan breaks down the basics using simple analogies, explaining how data architecture</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#009 Modern Data Infrastructure for Analytics and AI, Lakehouses, Open Source Data Stack</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>9</itunes:episode>
      <podcast:episode>9</podcast:episode>
      <itunes:title>#009 Modern Data Infrastructure for Analytics and AI, Lakehouses, Open Source Data Stack</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">4fd3f6c5-bb6d-4c9f-89cd-3a69d454fc60</guid>
      <link>https://share.transistor.fm/s/68c53143</link>
      <description>
        <![CDATA[<p>Jorrit Sandbrink, a data engineer specializing on open table formats, discusses the advantages of decoupling storage and compute, the importance of choosing the right table format, and strategies for optimizing your data pipelines. This episode is full of practical advice for anyone looking to build a high-performance data analytics platform.</p><ul><li><strong>Lake house architecture:</strong> A blend of data warehouse and data lake, addressing their shortcomings and providing a unified platform for diverse workloads.</li><li><strong>Key components and decisions:</strong> Storage options (cloud or on-prem), table formats (Delta Lake, Iceberg, Apache Hoodie), and query engines (Apache Spark, Polars).</li><li><strong>Optimizations:</strong> Partitioning strategies, file size considerations, and auto-optimization tools for efficient data layout and query performance.</li><li><strong>Orchestration tools:</strong> Airflow, Dagster, Prefect, and their roles in triggering and managing data pipelines.</li><li><strong>Data ingress with DLT:</strong> An open-source Python library for building data pipelines, focusing on efficient data extraction and loading.</li></ul><p><strong>Key Takeaways:</strong></p><ul><li>Lake houses offer a powerful and flexible architecture for modern data analytics.</li><li>Open-source solutions provide cost-effective and customizable alternatives.</li><li>Carefully consider your specific use cases and preferences when choosing tools and components.</li><li>Tools like DLT simplify data ingress and can be easily integrated with serverless functions.</li><li>The data landscape is constantly evolving, so staying informed about new tools and trends is crucial.</li></ul><p><strong>Sound Bites</strong></p><p>"The Lake house is sort of a modular setup where you decouple the storage and the compute." "A lake house is an architecture, an architecture for data analytics platforms." "The most popular table formats for a lake house are Delta, Iceberg, and Apache Hoodie."</p><p><strong>Jorrit Sandbrink:</strong></p><ul><li><a href="https://www.linkedin.com/in/jorritsandbrink?originalSubdomain=ae">LinkedIn</a></li><li><a href="https://dlthub.com/">dlt</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction to the Lake House Architecture</p><p><strong>03:59</strong> Choosing Storage and Table Formats</p><p><strong>06:19</strong> Comparing Compute Engines</p><p><strong>21:37</strong> Simplifying Data Ingress</p><p><strong>25:01</strong> Building a Preferred Data Stack</p><p>lake house, data analytics, architecture, storage, table format, query execution engine, document store, DuckDB, Polars, orchestration, Airflow, Dexter, DLT, data ingress, data processing, data storage</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Jorrit Sandbrink, a data engineer specializing on open table formats, discusses the advantages of decoupling storage and compute, the importance of choosing the right table format, and strategies for optimizing your data pipelines. This episode is full of practical advice for anyone looking to build a high-performance data analytics platform.</p><ul><li><strong>Lake house architecture:</strong> A blend of data warehouse and data lake, addressing their shortcomings and providing a unified platform for diverse workloads.</li><li><strong>Key components and decisions:</strong> Storage options (cloud or on-prem), table formats (Delta Lake, Iceberg, Apache Hoodie), and query engines (Apache Spark, Polars).</li><li><strong>Optimizations:</strong> Partitioning strategies, file size considerations, and auto-optimization tools for efficient data layout and query performance.</li><li><strong>Orchestration tools:</strong> Airflow, Dagster, Prefect, and their roles in triggering and managing data pipelines.</li><li><strong>Data ingress with DLT:</strong> An open-source Python library for building data pipelines, focusing on efficient data extraction and loading.</li></ul><p><strong>Key Takeaways:</strong></p><ul><li>Lake houses offer a powerful and flexible architecture for modern data analytics.</li><li>Open-source solutions provide cost-effective and customizable alternatives.</li><li>Carefully consider your specific use cases and preferences when choosing tools and components.</li><li>Tools like DLT simplify data ingress and can be easily integrated with serverless functions.</li><li>The data landscape is constantly evolving, so staying informed about new tools and trends is crucial.</li></ul><p><strong>Sound Bites</strong></p><p>"The Lake house is sort of a modular setup where you decouple the storage and the compute." "A lake house is an architecture, an architecture for data analytics platforms." "The most popular table formats for a lake house are Delta, Iceberg, and Apache Hoodie."</p><p><strong>Jorrit Sandbrink:</strong></p><ul><li><a href="https://www.linkedin.com/in/jorritsandbrink?originalSubdomain=ae">LinkedIn</a></li><li><a href="https://dlthub.com/">dlt</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction to the Lake House Architecture</p><p><strong>03:59</strong> Choosing Storage and Table Formats</p><p><strong>06:19</strong> Comparing Compute Engines</p><p><strong>21:37</strong> Simplifying Data Ingress</p><p><strong>25:01</strong> Building a Preferred Data Stack</p><p>lake house, data analytics, architecture, storage, table format, query execution engine, document store, DuckDB, Polars, orchestration, Airflow, Dexter, DLT, data ingress, data processing, data storage</p>]]>
      </content:encoded>
      <pubDate>Fri, 24 May 2024 00:35:28 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/68c53143/41cb8fbe.mp3" length="26765272" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/GfCnxTaRIQ_9qmjgpHZlEw-TRsrofZkl2cbZvQ0VfCo/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8wYWZl/YTZmNDA4M2M3MWVj/NWIwMTBhNzA5OGJl/MGM3ZS5qcGc.jpg"/>
      <itunes:duration>1673</itunes:duration>
      <itunes:summary>Jorrit Sandbrink, a data engineer specializing on open table formats, discusses the advantages of decoupling storage and compute, the importance of choosing the right table format, and strategies for optimizing your data pipelines. This episode is full of practical advice for anyone looking to build a high-performance data analytics platform.

 Lake house architecture: A blend of data warehouse and data lake, addressing their shortcomings and providing a unified platform for diverse workloads.
 Key components and decisions: Storage options (cloud or on-prem), table formats (Delta Lake, Iceberg, Apache Hoodie), and query engines (Apache Spark, Polars).
  Optimizations: Partitioning strategies, file size considerations, and auto-optimization tools for efficient data layout and query performance.
  Orchestration tools: Airflow, Dagster, Prefect, and their roles in triggering and managing data pipelines.
  Data ingress with DLT: An open-source Python library for building data pipelines, focusing on efficient data extraction and loading.

Key Takeaways:

  Lake houses offer a powerful and flexible architecture for modern data analytics.
  Open-source solutions provide cost-effective and customizable alternatives.
  Carefully consider your specific use cases and preferences when choosing tools and components.
  Tools like DLT simplify data ingress and can be easily integrated with serverless functions.
  The data landscape is constantly evolving, so staying informed about new tools and trends is crucial.

Sound Bites
"The Lake house is sort of a modular setup where you decouple the storage and the compute."
"A lake house is an architecture, an architecture for data analytics platforms."
"The most popular table formats for a lake house are Delta, Iceberg, and Apache Hoodie."
Jorrit Sandbrink:

  LinkedIn
  dlt

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Chapters
00:00 Introduction to the Lake House Architecture
03:59 Choosing Storage and Table Formats
06:19 Comparing Compute Engines
21:37 Simplifying Data Ingress
25:01 Building a Preferred Data Stack
lake house, data analytics, architecture, storage, table format, query execution engine, document store, DuckDB, Polars, orchestration, Airflow, Dexter, DLT, data ingress, data processing, data storage</itunes:summary>
      <itunes:subtitle>Jorrit Sandbrink, a data engineer specializing on open table formats, discusses the advantages of decoupling storage and compute, the importance of choosing the right table format, and strategies for optimizing your data pipelines. This episode is full of</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#008 Knowledge Graphs for Better RAG, Virtual Entities, Hybrid Data Models</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>8</itunes:episode>
      <podcast:episode>8</podcast:episode>
      <itunes:title>#008 Knowledge Graphs for Better RAG, Virtual Entities, Hybrid Data Models</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">b5fa09fe-e06b-49ae-b011-d1d043e36f00</guid>
      <link>https://share.transistor.fm/s/a550e243</link>
      <description>
        <![CDATA[<p>Kirk Marple, CEO and founder of Graphlit, discusses the evolution of his company from a data cataloging tool to an platform designed for ETL (Extract, Transform, Load) and knowledge retrieval for Large Language Models (LLMs). Graphlit empowers users to build custom applications on top of its API that go beyond naive RAG.</p><p><strong>Key Points:</strong></p><ul><li><strong>Knowledge Graphs:</strong> Graphlet utilizes knowledge graphs as a filtering layer on top of keyword metadata and vector search, aiding in information retrieval.</li><li><strong>Storage for KGs:</strong> A single piece of content in their data model resides across multiple systems: a document store with JSON, a graph node, and a search index. This hybrid approach creates a virtual entity with representations in different databases.</li><li><strong>Entity Extraction:</strong> Azure Cognitive Services and other models are employed to extract entities from text for improved understanding.</li><li><strong>Metadata-first approach:</strong> The metadata-first strategy involves extracting comprehensive metadata from various sources, ensuring it is canonicalized and filterable. This approach aids in better indexing and retrieval of data, crucial for effective RAG.</li><li><strong>Challenges:</strong> Entity resolution and deduplication remain significant challenges in knowledge graph development.</li></ul><p><strong>Notable Quotes:</strong></p><ul><li>"Knowledge graphs is a filtering [mechanism]...but then I think also the kind of spidering and pulling extra content in is the other place this comes into play."</li><li>"Knowledge graphs to me are kind of like index per se...you're providing a new type of index on top of that."</li><li>"[For RAG]...you have to find constraints to make it workable."</li><li>"Entity resolution, deduping, I think is probably the number one thing."</li><li>"I've essentially built a connector infrastructure that would be like a FiveTran or something that Airflow would have..."</li><li>"One of the reasons is because we're a platform as a service, the burstability of it is really important. We can spin up to a hundred instances without any problem, and we don't have to think about it."</li><li>"Once cost and performance become a no-brainer, we're going to start seeing LLMs be more of a compute tool. I think that would be a game-changer for how applications are built in the future."</li></ul><p><strong>Kirk Marple:</strong></p><ul><li><a href="https://www.linkedin.com/in/kirkmarple/">LinkedIn</a></li><li><a href="https://twitter.com/KirkMarple">X (Twitter)</a></li><li><a href="https://www.graphlit.com/">Graphlit</a></li><li><a href="https://docs.graphlit.dev/">Graphlit Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Graphlit‚Äôs Hybrid Approach 02:23 Use Cases and Transition to Graphlit 04:19 Knowledge Graphs as a Filtering Mechanism 13:23 Using Gremlin for Querying the Graph 32:36 XML in Prompts for Better Segmentation 35:04 The Future of LLMs and Graphlit 36:25 Getting Started with Graphlit</p><p>Graphlit, knowledge graphs, AI, document store, graph database, search index co-pilot, entity extraction, Azure Cognitive Services, XML, event-driven architecture, serverless architecture graph rag, developer portal</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Kirk Marple, CEO and founder of Graphlit, discusses the evolution of his company from a data cataloging tool to an platform designed for ETL (Extract, Transform, Load) and knowledge retrieval for Large Language Models (LLMs). Graphlit empowers users to build custom applications on top of its API that go beyond naive RAG.</p><p><strong>Key Points:</strong></p><ul><li><strong>Knowledge Graphs:</strong> Graphlet utilizes knowledge graphs as a filtering layer on top of keyword metadata and vector search, aiding in information retrieval.</li><li><strong>Storage for KGs:</strong> A single piece of content in their data model resides across multiple systems: a document store with JSON, a graph node, and a search index. This hybrid approach creates a virtual entity with representations in different databases.</li><li><strong>Entity Extraction:</strong> Azure Cognitive Services and other models are employed to extract entities from text for improved understanding.</li><li><strong>Metadata-first approach:</strong> The metadata-first strategy involves extracting comprehensive metadata from various sources, ensuring it is canonicalized and filterable. This approach aids in better indexing and retrieval of data, crucial for effective RAG.</li><li><strong>Challenges:</strong> Entity resolution and deduplication remain significant challenges in knowledge graph development.</li></ul><p><strong>Notable Quotes:</strong></p><ul><li>"Knowledge graphs is a filtering [mechanism]...but then I think also the kind of spidering and pulling extra content in is the other place this comes into play."</li><li>"Knowledge graphs to me are kind of like index per se...you're providing a new type of index on top of that."</li><li>"[For RAG]...you have to find constraints to make it workable."</li><li>"Entity resolution, deduping, I think is probably the number one thing."</li><li>"I've essentially built a connector infrastructure that would be like a FiveTran or something that Airflow would have..."</li><li>"One of the reasons is because we're a platform as a service, the burstability of it is really important. We can spin up to a hundred instances without any problem, and we don't have to think about it."</li><li>"Once cost and performance become a no-brainer, we're going to start seeing LLMs be more of a compute tool. I think that would be a game-changer for how applications are built in the future."</li></ul><p><strong>Kirk Marple:</strong></p><ul><li><a href="https://www.linkedin.com/in/kirkmarple/">LinkedIn</a></li><li><a href="https://twitter.com/KirkMarple">X (Twitter)</a></li><li><a href="https://www.graphlit.com/">Graphlit</a></li><li><a href="https://docs.graphlit.dev/">Graphlit Docs</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p>00:00 Graphlit‚Äôs Hybrid Approach 02:23 Use Cases and Transition to Graphlit 04:19 Knowledge Graphs as a Filtering Mechanism 13:23 Using Gremlin for Querying the Graph 32:36 XML in Prompts for Better Segmentation 35:04 The Future of LLMs and Graphlit 36:25 Getting Started with Graphlit</p><p>Graphlit, knowledge graphs, AI, document store, graph database, search index co-pilot, entity extraction, Azure Cognitive Services, XML, event-driven architecture, serverless architecture graph rag, developer portal</p>]]>
      </content:encoded>
      <pubDate>Mon, 20 May 2024 06:18:28 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/a550e243/25ca3f9b.mp3" length="35187553" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/gpLyR4a3bg2AR4wR0EHBQtoBYTs0dIL9GI-8H9rXf6s/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS82Njk5/YWFkNzdmYzI0OTE5/ODQ2NDMzZTI5NTU1/YTUzMy5qcGc.jpg"/>
      <itunes:duration>2200</itunes:duration>
      <itunes:summary>Kirk Marple, CEO and founder of Graphlit, discusses the evolution of his company from a data cataloging tool to an platform designed for ETL (Extract, Transform, Load) and knowledge retrieval for Large Language Models (LLMs). Graphlit empowers users to build custom applications on top of its API that go beyond naive RAG.
Key Points:

 Knowledge Graphs: Graphlet utilizes knowledge graphs as a filtering layer on top of keyword metadata and vector search, aiding in information retrieval.
 Storage for KGs: A single piece of content in their data model resides across multiple systems: a document store with JSON, a graph node, and a search index. This hybrid approach creates a virtual entity with representations in different databases.
  Entity Extraction: Azure Cognitive Services and other models are employed to extract entities from text for improved understanding.
  Metadata-first approach: The metadata-first strategy involves extracting comprehensive metadata from various sources, ensuring it is canonicalized and filterable. This approach aids in better indexing and retrieval of data, crucial for effective RAG.
  Challenges: Entity resolution and deduplication remain significant challenges in knowledge graph development.

Notable Quotes:

  "Knowledge graphs is a filtering [mechanism]...but then I think also the kind of spidering and pulling extra content in is the other place this comes into play."
  "Knowledge graphs to me are kind of like index per se...you're providing a new type of index on top of that."
  "[For RAG]...you have to find constraints to make it workable."
  "Entity resolution, deduping, I think is probably the number one thing."
  "I've essentially built a connector infrastructure that would be like a FiveTran or something that Airflow would have..."
  "One of the reasons is because we're a platform as a service, the burstability of it is really important. We can spin up to a hundred instances without any problem, and we don't have to think about it."
  "Once cost and performance become a no-brainer, we're going to start seeing LLMs be more of a compute tool. I think that would be a game-changer for how applications are built in the future."

Kirk Marple:

  LinkedIn
  X (Twitter)
  Graphlit
  Graphlit Docs

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Chapters
00:00 Graphlit‚Äôs Hybrid Approach
02:23 Use Cases and Transition to Graphlit
04:19 Knowledge Graphs as a Filtering Mechanism
13:23 Using Gremlin for Querying the Graph
32:36 XML in Prompts for Better Segmentation
35:04 The Future of LLMs and Graphlit
36:25 Getting Started with Graphlit
Graphlit, knowledge graphs, AI, document store, graph database, search index co-pilot, entity extraction, Azure Cognitive Services, XML, event-driven architecture, serverless architecture graph rag, developer portal</itunes:summary>
      <itunes:subtitle>Kirk Marple, CEO and founder of Graphlit, discusses the evolution of his company from a data cataloging tool to an platform designed for ETL (Extract, Transform, Load) and knowledge retrieval for Large Language Models (LLMs). Graphlit empowers users to bu</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#007 Navigating the Modern Data Stack, Choosing the Right OSS Tools, From Problem to Requirements to Architecture</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>7</itunes:episode>
      <podcast:episode>7</podcast:episode>
      <itunes:title>#007 Navigating the Modern Data Stack, Choosing the Right OSS Tools, From Problem to Requirements to Architecture</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">cc9752af-3072-4d35-9c6d-fa6bcf076a9e</guid>
      <link>https://share.transistor.fm/s/c0af7b71</link>
      <description>
        <![CDATA[<p>From Problem to Requirements to Architecture.</p><p>In this episode, Nicolay Gerold and Jon Erich Kemi Warghed discuss the landscape of data engineering, sharing insights on selecting the right tools, implementing effective data governance, and leveraging powerful concepts like software-defined assets. They discuss the challenges of keeping up with the ever-evolving tech landscape and offer practical advice for building sustainable data platforms. Tune in to discover how to simplify complex data pipelines, unlock the power of orchestration tools, and ultimately create more value from your data.</p><ul><li>"Don't overcomplicate what you're actually doing."</li><li>"Getting your basic programming software development skills down is super important to becoming a good data engineer."</li><li>"Who has time to learn 500 new tools? It's like, this is not humanly possible anymore."</li></ul><p><strong>Key Takeaways:</strong></p><ul><li><strong>Data Governance:</strong> Data governance is about transparency and understanding the data you have. It's crucial for organizations as they scale and data becomes more complex. Tools like dbt and Dagster can help achieve this.</li><li><strong>Open Source Tooling:</strong> When choosing open source tools, assess their backing, commit frequency, community support, and ease of use.</li><li><strong>Agile Data Platforms:</strong> Focus on the capabilities you want to enable and prioritize solving the core problems of your data engineers and analysts.</li><li><strong>Software Defined Assets:</strong> This concept, exemplified by Dagster, shifts the focus from how data is processed to what data should exist. This change in mindset can greatly simplify data orchestration and management.</li><li><strong>The Importance of Fundamentals:</strong> Strong programming and software development skills are crucial for data engineers, and understanding the basics of data management and orchestration is essential for success.</li><li><strong>The Importance of Versioning Data: </strong>Data has to be versioned so you can easily track changes, revert to previous states if needed, and ensure reproducibility in your data pipelines. <a href="https://lakefs.io/?kw=lake%20fs&amp;cpn=20625638839">lakeFS</a> applies the concepts of Git to your data lake. This gives you the ability to create branches for different development environments, commit changes to specific versions, and merge branches together once changes have been tested and validated.</li></ul><p><strong>Jon Erik Kemi Warghed</strong>:</p><ul><li><a href="https://www.linkedin.com/in/jonerikkemiwarghed/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> The Problem with the Modern Data Stack: Too many tools and buzzwords</p><p><strong>00:57</strong> How to Choose the Right Tools: Considerations for startups and large companies</p><p><strong>03:13</strong> Evaluating Open Source Tools: Background checks and due diligence</p><p><strong>07:52</strong> Defining Data Governance: Transparency and understanding of data</p><p><strong>10:15</strong> The Importance of Data Governance: Challenges and solutions</p><p><strong>12:21</strong> Data Governance Tools: dbt and Dagster</p><p><strong>17:05</strong> The Impact of Dagster: Software-defined assets and declarative thinking</p><p><strong>19:31</strong> The Power of Software Defined Assets: How Dagster differs from Airflow and Mage</p><p><strong>21:52</strong> State Management and Orchestration in Dagster: Real-time updates and dependency management</p><p><strong>26:24</strong> Why Use Orchestration Tools?: The role of orchestration in complex data pipelines</p><p><strong>28:47</strong> The Importance of Tool Selection: Thinking about long-term sustainability</p><p><strong>31:10</strong> When to Adopt Orchestration: Identifying the need for orchestration tools</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>From Problem to Requirements to Architecture.</p><p>In this episode, Nicolay Gerold and Jon Erich Kemi Warghed discuss the landscape of data engineering, sharing insights on selecting the right tools, implementing effective data governance, and leveraging powerful concepts like software-defined assets. They discuss the challenges of keeping up with the ever-evolving tech landscape and offer practical advice for building sustainable data platforms. Tune in to discover how to simplify complex data pipelines, unlock the power of orchestration tools, and ultimately create more value from your data.</p><ul><li>"Don't overcomplicate what you're actually doing."</li><li>"Getting your basic programming software development skills down is super important to becoming a good data engineer."</li><li>"Who has time to learn 500 new tools? It's like, this is not humanly possible anymore."</li></ul><p><strong>Key Takeaways:</strong></p><ul><li><strong>Data Governance:</strong> Data governance is about transparency and understanding the data you have. It's crucial for organizations as they scale and data becomes more complex. Tools like dbt and Dagster can help achieve this.</li><li><strong>Open Source Tooling:</strong> When choosing open source tools, assess their backing, commit frequency, community support, and ease of use.</li><li><strong>Agile Data Platforms:</strong> Focus on the capabilities you want to enable and prioritize solving the core problems of your data engineers and analysts.</li><li><strong>Software Defined Assets:</strong> This concept, exemplified by Dagster, shifts the focus from how data is processed to what data should exist. This change in mindset can greatly simplify data orchestration and management.</li><li><strong>The Importance of Fundamentals:</strong> Strong programming and software development skills are crucial for data engineers, and understanding the basics of data management and orchestration is essential for success.</li><li><strong>The Importance of Versioning Data: </strong>Data has to be versioned so you can easily track changes, revert to previous states if needed, and ensure reproducibility in your data pipelines. <a href="https://lakefs.io/?kw=lake%20fs&amp;cpn=20625638839">lakeFS</a> applies the concepts of Git to your data lake. This gives you the ability to create branches for different development environments, commit changes to specific versions, and merge branches together once changes have been tested and validated.</li></ul><p><strong>Jon Erik Kemi Warghed</strong>:</p><ul><li><a href="https://www.linkedin.com/in/jonerikkemiwarghed/">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> The Problem with the Modern Data Stack: Too many tools and buzzwords</p><p><strong>00:57</strong> How to Choose the Right Tools: Considerations for startups and large companies</p><p><strong>03:13</strong> Evaluating Open Source Tools: Background checks and due diligence</p><p><strong>07:52</strong> Defining Data Governance: Transparency and understanding of data</p><p><strong>10:15</strong> The Importance of Data Governance: Challenges and solutions</p><p><strong>12:21</strong> Data Governance Tools: dbt and Dagster</p><p><strong>17:05</strong> The Impact of Dagster: Software-defined assets and declarative thinking</p><p><strong>19:31</strong> The Power of Software Defined Assets: How Dagster differs from Airflow and Mage</p><p><strong>21:52</strong> State Management and Orchestration in Dagster: Real-time updates and dependency management</p><p><strong>26:24</strong> Why Use Orchestration Tools?: The role of orchestration in complex data pipelines</p><p><strong>28:47</strong> The Importance of Tool Selection: Thinking about long-term sustainability</p><p><strong>31:10</strong> When to Adopt Orchestration: Identifying the need for orchestration tools</p>]]>
      </content:encoded>
      <pubDate>Fri, 17 May 2024 03:36:28 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/c0af7b71/44b31812.mp3" length="36673437" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/32gnkrFbeg5g-ycJszN8NX8V8tvGMm50pU4EO-_8anE/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9lYWI1/N2NhZTE5YWRhMTI1/MTYxNmUwNjdmYjc0/MDQ5Yi5qcGc.jpg"/>
      <itunes:duration>2292</itunes:duration>
      <itunes:summary>From Problem to Requirements to Architecture.
In this episode, Nicolay Gerold and Jon Erich Kemi Warghed discuss the landscape of data engineering, sharing insights on selecting the right tools, implementing effective data governance, and leveraging powerful concepts like software-defined assets. They discuss the challenges of keeping up with the ever-evolving tech landscape and offer practical advice for building sustainable data platforms. Tune in to discover how to simplify complex data pipelines, unlock the power of orchestration tools, and ultimately create more value from your data.

 "Don't overcomplicate what you're actually doing."
 "Getting your basic programming software development skills down is super important to becoming a good data engineer."
  "Who has time to learn 500 new tools? It's like, this is not humanly possible anymore."

Key Takeaways:

  Data Governance: Data governance is about transparency and understanding the data you have. It's crucial for organizations as they scale and data becomes more complex. Tools like dbt and Dagster can help achieve this.
  Open Source Tooling: When choosing open source tools, assess their backing, commit frequency, community support, and ease of use.
  Agile Data Platforms: Focus on the capabilities you want to enable and prioritize solving the core problems of your data engineers and analysts.
  Software Defined Assets: This concept, exemplified by Dagster, shifts the focus from how data is processed to what data should exist. This change in mindset can greatly simplify data orchestration and management.
  The Importance of Fundamentals: Strong programming and software development skills are crucial for data engineers, and understanding the basics of data management and orchestration is essential for success.
  The Importance of Versioning Data: Data has to be versioned so you can easily track changes, revert to previous states if needed, and ensure reproducibility in your data pipelines. lakeFS applies the concepts of Git to your data lake. This gives you the ability to create branches for different development environments, commit changes to specific versions, and merge branches together once changes have been tested and validated.

Jon Erik Kemi Warghed:

  LinkedIn

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Chapters
00:00 The Problem with the Modern Data Stack: Too many tools and buzzwords
00:57 How to Choose the Right Tools: Considerations for startups and large companies
03:13 Evaluating Open Source Tools: Background checks and due diligence
07:52 Defining Data Governance: Transparency and understanding of data
10:15 The Importance of Data Governance: Challenges and solutions
12:21 Data Governance Tools: dbt and Dagster
17:05 The Impact of Dagster: Software-defined assets and declarative thinking
19:31 The Power of Software Defined Assets: How Dagster differs from Airflow and Mage
21:52 State Management and Orchestration in Dagster: Real-time updates and dependency management
26:24 Why Use Orchestration Tools?: The role of orchestration in complex data pipelines
28:47 The Importance of Tool Selection: Thinking about long-term sustainability
31:10 When to Adopt Orchestration: Identifying the need for orchestration tools</itunes:summary>
      <itunes:subtitle>From Problem to Requirements to Architecture.
In this episode, Nicolay Gerold and Jon Erich Kemi Warghed discuss the landscape of data engineering, sharing insights on selecting the right tools, implementing effective data governance, and leveraging powe</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#006 Data Orchestration Tools, Choosing the right one for your needs </title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>6</itunes:episode>
      <podcast:episode>6</podcast:episode>
      <itunes:title>#006 Data Orchestration Tools, Choosing the right one for your needs </itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">c3b535a6-493e-42fc-bc43-cf7c11533346</guid>
      <link>https://share.transistor.fm/s/9a9fbbd0</link>
      <description>
        <![CDATA[<p>In this episode, Nicolay Gerold interviews John Wessel, the founder of Agreeable Data, about data orchestration. They discuss the evolution of data orchestration tools, the popularity of Apache Airflow, the crowded market of orchestration tools, and the key problem that orchestrators solve. They also explore the components of a data orchestrator, the role of AI in data orchestration, and how to choose the right orchestrator for a project. They touch on the challenges of managing orchestrators, the importance of monitoring and optimization, and the need for product people to be more involved in the orchestration space. They also discuss data residency considerations and the future of orchestration tools.</p><p><strong>Sound Bites</strong></p><p>"The modern era, definitely airflow. Took the market share, a lot of people running it themselves." "It's like people are launching new orchestrators every day. This is a funny one. This was like two weeks ago, somebody launched an orchestrator that was like a meta-orchestrator." "The DAG introduced two other components. It's directed acyclic graph is what DAG means, but direct is like there's a start and there's a finish and the acyclic is there's no loops."</p><p><strong>Key Topics</strong></p><ul><li><strong>The evolution of data orchestration:</strong> From basic task scheduling to complex DAG-based solutions</li><li><strong>What is a data orchestrator and when do you need one?</strong> Understanding the role of orchestrators in handling complex dependencies and scaling data pipelines.</li><li><strong>The crowded market:</strong> A look at popular options like Airflow, Daxter, Prefect, and more.</li><li><strong>Best practices:</strong> Choosing the right tool, prioritizing serverless solutions when possible, and focusing on solving the use case before implementing complex tools.</li><li><strong>Data residency and GDPR:</strong> How regulations influence tool selection, especially in Europe.</li><li><strong>Future of the field:</strong> The need for consolidation and finding the right balance between features and usability.</li></ul><p><strong>John Wessel</strong>:</p><ul><li><a href="https://www.linkedin.com/in/wesseljt/">LinkedIn</a></li><li><a href="https://datastackshow.com/">Data Stack Show</a></li><li><a href="https://www.agreeabledata.com/">Agreeable Data</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>Data orchestration, data movement, Apache Airflow, orchestrator selection, DAG, AI in orchestration, serverless, Kubernetes, infrastructure as code, monitoring, optimization, data residency, product involvement, generative AI.</p><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction and Overview</p><p><strong>00:34</strong> The Evolution of Data Orchestration Tools</p><p><strong>04:54</strong> Components and Flow of Data in Orchestrators</p><p><strong>08:24</strong> Deployment Options: Serverless vs. Kubernetes</p><p><strong>11:14</strong> Considerations for Data Residency and Security</p><p><strong>13:02</strong> The Need for a Clear Winner in the Orchestration Space</p><p><strong>20:47</strong> Optimization Techniques for Memory and Time-Limited Issues</p><p><strong>23:09</strong> Integrating Orchestrators with Infrastructure-as-Code</p><p><strong>24:33</strong> Bridging the Gap Between Data and Engineering Practices</p><p><strong>27:2 2</strong>Exciting Technologies Outside of Data Orchestration</p><p><strong>30:09</strong> The Feature of Dagster</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode, Nicolay Gerold interviews John Wessel, the founder of Agreeable Data, about data orchestration. They discuss the evolution of data orchestration tools, the popularity of Apache Airflow, the crowded market of orchestration tools, and the key problem that orchestrators solve. They also explore the components of a data orchestrator, the role of AI in data orchestration, and how to choose the right orchestrator for a project. They touch on the challenges of managing orchestrators, the importance of monitoring and optimization, and the need for product people to be more involved in the orchestration space. They also discuss data residency considerations and the future of orchestration tools.</p><p><strong>Sound Bites</strong></p><p>"The modern era, definitely airflow. Took the market share, a lot of people running it themselves." "It's like people are launching new orchestrators every day. This is a funny one. This was like two weeks ago, somebody launched an orchestrator that was like a meta-orchestrator." "The DAG introduced two other components. It's directed acyclic graph is what DAG means, but direct is like there's a start and there's a finish and the acyclic is there's no loops."</p><p><strong>Key Topics</strong></p><ul><li><strong>The evolution of data orchestration:</strong> From basic task scheduling to complex DAG-based solutions</li><li><strong>What is a data orchestrator and when do you need one?</strong> Understanding the role of orchestrators in handling complex dependencies and scaling data pipelines.</li><li><strong>The crowded market:</strong> A look at popular options like Airflow, Daxter, Prefect, and more.</li><li><strong>Best practices:</strong> Choosing the right tool, prioritizing serverless solutions when possible, and focusing on solving the use case before implementing complex tools.</li><li><strong>Data residency and GDPR:</strong> How regulations influence tool selection, especially in Europe.</li><li><strong>Future of the field:</strong> The need for consolidation and finding the right balance between features and usability.</li></ul><p><strong>John Wessel</strong>:</p><ul><li><a href="https://www.linkedin.com/in/wesseljt/">LinkedIn</a></li><li><a href="https://datastackshow.com/">Data Stack Show</a></li><li><a href="https://www.agreeabledata.com/">Agreeable Data</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p>Data orchestration, data movement, Apache Airflow, orchestrator selection, DAG, AI in orchestration, serverless, Kubernetes, infrastructure as code, monitoring, optimization, data residency, product involvement, generative AI.</p><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction and Overview</p><p><strong>00:34</strong> The Evolution of Data Orchestration Tools</p><p><strong>04:54</strong> Components and Flow of Data in Orchestrators</p><p><strong>08:24</strong> Deployment Options: Serverless vs. Kubernetes</p><p><strong>11:14</strong> Considerations for Data Residency and Security</p><p><strong>13:02</strong> The Need for a Clear Winner in the Orchestration Space</p><p><strong>20:47</strong> Optimization Techniques for Memory and Time-Limited Issues</p><p><strong>23:09</strong> Integrating Orchestrators with Infrastructure-as-Code</p><p><strong>24:33</strong> Bridging the Gap Between Data and Engineering Practices</p><p><strong>27:2 2</strong>Exciting Technologies Outside of Data Orchestration</p><p><strong>30:09</strong> The Feature of Dagster</p>]]>
      </content:encoded>
      <pubDate>Fri, 10 May 2024 06:01:33 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/9a9fbbd0/dc66e7a3.mp3" length="31306378" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/MLOMh6TfiNBRSgWFIZ2S3JD7UzP3_Z-cvD05KPlxszk/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8xYzg0/NDA3MGE4OWU5YzI1/OWY4MDhkNDZhNGRi/NDQxYi5qcGc.jpg"/>
      <itunes:duration>1957</itunes:duration>
      <itunes:summary>In this episode, Nicolay Gerold interviews John Wessel, the founder of Agreeable Data, about data orchestration. They discuss the evolution of data orchestration tools, the popularity of Apache Airflow, the crowded market of orchestration tools, and the key problem that orchestrators solve. They also explore the components of a data orchestrator, the role of AI in data orchestration, and how to choose the right orchestrator for a project. They touch on the challenges of managing orchestrators, the importance of monitoring and optimization, and the need for product people to be more involved in the orchestration space. They also discuss data residency considerations and the future of orchestration tools.
Sound Bites
"The modern era, definitely airflow. Took the market share, a lot of people running it themselves."
"It's like people are launching new orchestrators every day. This is a funny one. This was like two weeks ago, somebody launched an orchestrator that was like a meta-orchestrator."
"The DAG introduced two other components. It's directed acyclic graph is what DAG means, but direct is like there's a start and there's a finish and the acyclic is there's no loops."
Key Topics

 The evolution of data orchestration:¬†From basic task scheduling to complex DAG-based solutions
 What is a data orchestrator and when do you need one?¬†Understanding the role of orchestrators in handling complex dependencies and scaling data pipelines.
  The crowded market:¬†A look at popular options like Airflow,¬†Daxter,¬†Prefect,¬†and more.
  Best practices:¬†Choosing the right tool,¬†prioritizing serverless solutions when possible,¬†and focusing on solving the use case before implementing complex tools.
  Data residency and GDPR:¬†How regulations influence tool selection,¬†especially in Europe.
  Future of the field:¬†The need for consolidation and finding the right balance between features and usability.

John Wessel:

  LinkedIn
  Data Stack Show
  Agreeable Data

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Data orchestration, data movement, Apache Airflow, orchestrator selection, DAG, AI in orchestration, serverless, Kubernetes, infrastructure as code, monitoring, optimization, data residency, product involvement, generative AI.
Chapters
00:00 Introduction and Overview
00:34 The Evolution of Data Orchestration Tools
04:54 Components and Flow of Data in Orchestrators
08:24 Deployment Options: Serverless vs. Kubernetes
11:14 Considerations for Data Residency and Security
13:02 The Need for a Clear Winner in the Orchestration Space
20:47 Optimization Techniques for Memory and Time-Limited Issues
23:09 Integrating Orchestrators with Infrastructure-as-Code
24:33 Bridging the Gap Between Data and Engineering Practices
27:2 2Exciting Technologies Outside of Data Orchestration
30:09 The Feature of Dagster</itunes:summary>
      <itunes:subtitle>In this episode, Nicolay Gerold interviews John Wessel, the founder of Agreeable Data, about data orchestration. They discuss the evolution of data orchestration tools, the popularity of Apache Airflow, the crowded market of orchestration tools, and the k</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#005 Building Reliable LLM Applications, Production-Ready RAG, Data-Driven Evals</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>4</itunes:episode>
      <podcast:episode>4</podcast:episode>
      <itunes:title>#005 Building Reliable LLM Applications, Production-Ready RAG, Data-Driven Evals</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">5cc68b56-a365-4c63-af7c-86a8330d7441</guid>
      <link>https://share.transistor.fm/s/059b578a</link>
      <description>
        <![CDATA[<p>In this episode of "How AI is Built", we learn how to build and evaluate real-world language model applications with Shahul and Jithin, creators of Ragas. Ragas is a powerful open-source library that helps developers test, evaluate, and fine-tune Retrieval Augmented Generation (RAG) applications, streamlining their path to production readiness.</p><p><strong>Main Insights</strong></p><ul><li><strong>Challenges of Open-Source Models:</strong> Open-source large language models (LLMs) can be powerful tools, but require significant post-training optimization for specific use cases.</li><li><strong>Evaluation Before Deployment:</strong> Thorough testing and evaluation are key to preventing unexpected behaviors and hallucinations in deployed RAGs. Ragas offers metrics and synthetic data generation to support this process.</li><li><strong>Data is Key:</strong> The quality and distribution of data used to train and evaluate LLMs dramatically impact their performance. Ragas is enabling novel synthetic data generation techniques to make this process more effective and cost-efficient.</li><li><strong>RAG Evolution:</strong> Techniques for improving RAGs are continuously evolving. Developers must be prepared to experiment and keep up with the latest advancements in chunk embedding, query transformation, and model alignment.</li></ul><p><strong>Practical Takeaways</strong></p><ul><li><strong>Start with a solid testing strategy:</strong> Before launching, define the quality metrics aligned with your RAG's purpose. Ragas helps in this process.</li><li><strong>Embrace synthetic data:</strong> Manually creating test data sets is time-consuming. Tools within Ragas help automate the creation of synthetic data to mirror real-world use cases.</li><li><strong>RAGs are iterative:</strong> Be prepared for continuous improvement as better techniques and models emerge.</li></ul><p><strong>Interesting Quotes</strong></p><ul><li>"...models are very stochastic and grading it directly would rather trigger them to give some random number..." - Shahul, on the dangers of naive model evaluation.</li><li>"Reducing the developer time in acquiring these test data sets by 90%." - Shahul, on the efficiency gains of Ragas' synthetic data generation.</li><li>"We want to ensure maximum diversity..." - Shahul, on creating realistic and challenging test data for RAG evaluation.</li></ul><p><strong>Ragas</strong>:</p><ul><li><a href="https://www.linkedin.com/company/ragas-io/">Web</a></li><li><a href="https://docs.ragas.io/en/stable/getstarted/index.html">Docs</a></li></ul><p><strong>Jithin James:</strong></p><ul><li><a href="https://www.linkedin.com/in/jjmachan/">LinkedIn</a></li></ul><p>Shahul ES:</p><ul><li><a href="https://www.linkedin.com/in/shahules/">LinkedIn</a></li><li><a href="https://twitter.com/Shahules786">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Introduction</p><p><strong>02:03</strong> Introduction to Open Assistant project</p><p><strong>04:05</strong> Creating Customizable and Fine-Tunable Models</p><p><strong>06:07</strong> Ragas and the LLM Use Case</p><p><strong>08:09</strong> Introduction to Language Model Metrics (LLMs)</p><p><strong>11:12</strong> Reducing the Cost of Data Generation</p><p><strong>13:19</strong> Evaluation of Components at Melvess</p><p><strong>15:40</strong> Combining Ragas Metrics with AutoML Providers</p><p><strong>20:08</strong> Improving Performance with Fine-tuning and Reranking</p><p><strong>22:56</strong> End-to-End Metrics and Component-Specific Metrics</p><p><strong>25:14</strong> The Importance of Deep Knowledge and Understanding</p><p><strong>25:53</strong> Robustness vs Optimization</p><p><strong>26:32</strong> Challenges of Evaluating Models</p><p><strong>27:18</strong> Creating a Dream Tech Stack</p><p><strong>27:47</strong> The Future Roadmap for Ragas</p><p><strong>28:02</strong> Doubling Down on Grid Data Generation</p><p><strong>28:12</strong> Open-Source Models and Expanded Support</p><p><strong>28:20</strong> More Metrics for Different Applications</p><p>RAG, Ragas, LLM, Evaluation, Synthetic Data, Open-Source, Language Model Applications, Testing.</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode of "How AI is Built", we learn how to build and evaluate real-world language model applications with Shahul and Jithin, creators of Ragas. Ragas is a powerful open-source library that helps developers test, evaluate, and fine-tune Retrieval Augmented Generation (RAG) applications, streamlining their path to production readiness.</p><p><strong>Main Insights</strong></p><ul><li><strong>Challenges of Open-Source Models:</strong> Open-source large language models (LLMs) can be powerful tools, but require significant post-training optimization for specific use cases.</li><li><strong>Evaluation Before Deployment:</strong> Thorough testing and evaluation are key to preventing unexpected behaviors and hallucinations in deployed RAGs. Ragas offers metrics and synthetic data generation to support this process.</li><li><strong>Data is Key:</strong> The quality and distribution of data used to train and evaluate LLMs dramatically impact their performance. Ragas is enabling novel synthetic data generation techniques to make this process more effective and cost-efficient.</li><li><strong>RAG Evolution:</strong> Techniques for improving RAGs are continuously evolving. Developers must be prepared to experiment and keep up with the latest advancements in chunk embedding, query transformation, and model alignment.</li></ul><p><strong>Practical Takeaways</strong></p><ul><li><strong>Start with a solid testing strategy:</strong> Before launching, define the quality metrics aligned with your RAG's purpose. Ragas helps in this process.</li><li><strong>Embrace synthetic data:</strong> Manually creating test data sets is time-consuming. Tools within Ragas help automate the creation of synthetic data to mirror real-world use cases.</li><li><strong>RAGs are iterative:</strong> Be prepared for continuous improvement as better techniques and models emerge.</li></ul><p><strong>Interesting Quotes</strong></p><ul><li>"...models are very stochastic and grading it directly would rather trigger them to give some random number..." - Shahul, on the dangers of naive model evaluation.</li><li>"Reducing the developer time in acquiring these test data sets by 90%." - Shahul, on the efficiency gains of Ragas' synthetic data generation.</li><li>"We want to ensure maximum diversity..." - Shahul, on creating realistic and challenging test data for RAG evaluation.</li></ul><p><strong>Ragas</strong>:</p><ul><li><a href="https://www.linkedin.com/company/ragas-io/">Web</a></li><li><a href="https://docs.ragas.io/en/stable/getstarted/index.html">Docs</a></li></ul><p><strong>Jithin James:</strong></p><ul><li><a href="https://www.linkedin.com/in/jjmachan/">LinkedIn</a></li></ul><p>Shahul ES:</p><ul><li><a href="https://www.linkedin.com/in/shahules/">LinkedIn</a></li><li><a href="https://twitter.com/Shahules786">X (Twitter)</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li><li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li></ul><p><strong>00:00</strong> Introduction</p><p><strong>02:03</strong> Introduction to Open Assistant project</p><p><strong>04:05</strong> Creating Customizable and Fine-Tunable Models</p><p><strong>06:07</strong> Ragas and the LLM Use Case</p><p><strong>08:09</strong> Introduction to Language Model Metrics (LLMs)</p><p><strong>11:12</strong> Reducing the Cost of Data Generation</p><p><strong>13:19</strong> Evaluation of Components at Melvess</p><p><strong>15:40</strong> Combining Ragas Metrics with AutoML Providers</p><p><strong>20:08</strong> Improving Performance with Fine-tuning and Reranking</p><p><strong>22:56</strong> End-to-End Metrics and Component-Specific Metrics</p><p><strong>25:14</strong> The Importance of Deep Knowledge and Understanding</p><p><strong>25:53</strong> Robustness vs Optimization</p><p><strong>26:32</strong> Challenges of Evaluating Models</p><p><strong>27:18</strong> Creating a Dream Tech Stack</p><p><strong>27:47</strong> The Future Roadmap for Ragas</p><p><strong>28:02</strong> Doubling Down on Grid Data Generation</p><p><strong>28:12</strong> Open-Source Models and Expanded Support</p><p><strong>28:20</strong> More Metrics for Different Applications</p><p>RAG, Ragas, LLM, Evaluation, Synthetic Data, Open-Source, Language Model Applications, Testing.</p>]]>
      </content:encoded>
      <pubDate>Fri, 03 May 2024 08:15:10 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/059b578a/33ecc920.mp3" length="28470537" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/cAiC-FubmRRxOG9E4tFNa-vuiPoywGVtyGqHoppd1Eo/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8wNWZk/ODAwZTc0MDM0NWFj/MzA5MTYxYjJhNGVi/ZDhiZi5qcGc.jpg"/>
      <itunes:duration>1780</itunes:duration>
      <itunes:summary>In this episode of "How AI is Built", we learn how to build and evaluate real-world language model applications with Shahul and Jithin, creators of Ragas. Ragas is a powerful open-source library that helps developers test, evaluate, and fine-tune Retrieval Augmented Generation (RAG) applications, streamlining their path to production readiness.
Main Insights

 Challenges of Open-Source Models: Open-source large language models (LLMs) can be powerful tools, but require significant post-training optimization for specific use cases.
 Evaluation Before Deployment: Thorough testing and evaluation are key to preventing unexpected behaviors and hallucinations in deployed RAGs. Ragas offers metrics and synthetic data generation to support this process.
 Data is Key: The quality and distribution of data used to train and evaluate LLMs dramatically impact their performance. Ragas is enabling novel synthetic data generation techniques to make this process more effective and cost-efficient.
 RAG Evolution: Techniques for improving RAGs are continuously evolving. Developers must be prepared to experiment and keep up with the latest advancements in chunk embedding, query transformation, and model alignment.

Practical Takeaways

  Start with a solid testing strategy: Before launching, define the quality metrics aligned with your RAG's purpose. Ragas helps in this process.
  Embrace synthetic data: Manually creating test data sets is time-consuming. Tools within Ragas help automate the creation of synthetic data to mirror real-world use cases.
  RAGs are iterative: Be prepared for continuous improvement as better techniques and models emerge.

Interesting Quotes

  "...models are very stochastic and grading it directly would rather trigger them to give some random number..." - Shahul, on the dangers of naive model evaluation.
  "Reducing the developer time in acquiring these test data sets by 90%." - Shahul, on the efficiency gains of Ragas' synthetic data generation.
  "We want to ensure maximum diversity..." - Shahul, on creating realistic and challenging test data for RAG evaluation.

Ragas:

  Web
  Docs

Jithin James:

  LinkedIn

Shahul ES:

  LinkedIn
  X (Twitter)

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

00:00 Introduction
02:03 Introduction to Open Assistant project
04:05 Creating Customizable and Fine-Tunable Models
06:07 Ragas and the LLM Use Case
08:09 Introduction to Language Model Metrics (LLMs)
11:12 Reducing the Cost of Data Generation
13:19 Evaluation of Components at Melvess
15:40 Combining Ragas Metrics with AutoML Providers
20:08 Improving Performance with Fine-tuning and Reranking
22:56 End-to-End Metrics and Component-Specific Metrics
25:14 The Importance of Deep Knowledge and Understanding
25:53 Robustness vs Optimization
26:32 Challenges of Evaluating Models
27:18 Creating a Dream Tech Stack
27:47 The Future Roadmap for Ragas
28:02 Doubling Down on Grid Data Generation
28:12 Open-Source Models and Expanded Support
28:20 More Metrics for Different Applications
RAG, Ragas, LLM, Evaluation, Synthetic Data, Open-Source, Language Model Applications, Testing.</itunes:summary>
      <itunes:subtitle>In this episode of "How AI is Built", we learn how to build and evaluate real-world language model applications with Shahul and Jithin, creators of Ragas. Ragas is a powerful open-source library that helps developers test, evaluate, and fine-tune Retrieva</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>Lance v2: Rethinking Columnar Storage for Faster Lookups, Nulls, and Flexible Encodings | changelog 2</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>5</itunes:episode>
      <podcast:episode>5</podcast:episode>
      <itunes:title>Lance v2: Rethinking Columnar Storage for Faster Lookups, Nulls, and Flexible Encodings | changelog 2</itunes:title>
      <itunes:episodeType>bonus</itunes:episodeType>
      <guid isPermaLink="false">4c7afe9e-32c7-4b8f-aff9-3f6dff9c4591</guid>
      <link>https://share.transistor.fm/s/7aaf9fa9</link>
      <description>
        <![CDATA[<p>In this episode of Changelog, Weston Pace dives into the latest updates to LanceDB, an open-source vector database and file format. Lance's new V2 file format redefines the traditional notion of columnar storage, allowing for more efficient handling of large multimodal datasets like images and embeddings. Weston discusses the goals driving LanceDB's development, including null value support, multimodal data handling, and finding an optimal balance for search performance.</p>
<p><strong>Sound Bites</strong></p>
<p>"A little bit more power to actually just try."
"We're becoming a little bit more feature complete with returns of arrow."
"Weird data representations that are actually really optimized for your use case."</p>
<p><strong>Key Points</strong></p>
<ul>
 <li>Weston introduces LanceDB, an open-source multimodal vector database and file format.</li>
 <li>The goals behind LanceDB's design: handling null values, multimodal data, and finding the right balance between point lookups and full dataset scan performance.</li>
  <li><strong>Lance V2 File Format:</strong></li>
  <li><strong>Potential Use Cases</strong></li>
</ul>
<p><strong>Conversation Highlights</strong></p>
<ul>
  <li><strong>On the benefits of Arrow integration:</strong> Strengthening the connection with the Arrow data ecosystem for seamless data handling.</li>
  <li><strong>Why "columnar container format"?:</strong> A broader definition than "table format" to encompass more unconventional use cases.</li>
  <li><strong>Tackling multimodal data:</strong> How LanceDB V2 enables storage of large multimodal data efficiently and without needing tons of memory.</li>
  <li><strong>Python's role in encoding experimentation:</strong> Providing a way to rapidly prototype custom encodings and plug them into LanceDB.</li>
</ul>
<p>LanceDB:</p>
<ul>
  <li><a href="https://twitter.com/lancedb">X (Twitter)</a></li>
  <li><a href="https://github.com/lancedb/lancedb">GitHub</a></li>
  <li><a href="https://lancedb.com/">Web</a></li>
  <li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li>
  <li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li>
  <li><a href="https://blog.lancedb.com/lance-v2/">Lance V2</a></li>
</ul>
<p><strong>Weston Pace:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/weston-pace-cool-dude/">LinkedIn</a></li>
  <li><a href="https://github.com/westonpace">GitHub</a></li>
</ul>
<p><strong>Nicolay Gerold:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li>
  <li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li>
</ul>
<p><strong>Chapters</strong></p>
<p><strong>00:00</strong> Introducing Lance: A New File Format</p>
<p><strong>06:46</strong> Enabling Custom Encodings in Lance</p>
<p><strong>11:51</strong> Exploring the Relationship Between Lance and Arrow</p>
<p><strong>20:04</strong> New Chapter</p>
<p>Lance file format, nulls, round-tripping data, optimized data representations, full-text search, encodings, downsides, multimodal data, compression, point lookups, full scan performance, non-contiguous columns, custom encodings</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>In this episode of Changelog, Weston Pace dives into the latest updates to LanceDB, an open-source vector database and file format. Lance's new V2 file format redefines the traditional notion of columnar storage, allowing for more efficient handling of large multimodal datasets like images and embeddings. Weston discusses the goals driving LanceDB's development, including null value support, multimodal data handling, and finding an optimal balance for search performance.</p>
<p><strong>Sound Bites</strong></p>
<p>"A little bit more power to actually just try."
"We're becoming a little bit more feature complete with returns of arrow."
"Weird data representations that are actually really optimized for your use case."</p>
<p><strong>Key Points</strong></p>
<ul>
 <li>Weston introduces LanceDB, an open-source multimodal vector database and file format.</li>
 <li>The goals behind LanceDB's design: handling null values, multimodal data, and finding the right balance between point lookups and full dataset scan performance.</li>
  <li><strong>Lance V2 File Format:</strong></li>
  <li><strong>Potential Use Cases</strong></li>
</ul>
<p><strong>Conversation Highlights</strong></p>
<ul>
  <li><strong>On the benefits of Arrow integration:</strong> Strengthening the connection with the Arrow data ecosystem for seamless data handling.</li>
  <li><strong>Why "columnar container format"?:</strong> A broader definition than "table format" to encompass more unconventional use cases.</li>
  <li><strong>Tackling multimodal data:</strong> How LanceDB V2 enables storage of large multimodal data efficiently and without needing tons of memory.</li>
  <li><strong>Python's role in encoding experimentation:</strong> Providing a way to rapidly prototype custom encodings and plug them into LanceDB.</li>
</ul>
<p>LanceDB:</p>
<ul>
  <li><a href="https://twitter.com/lancedb">X (Twitter)</a></li>
  <li><a href="https://github.com/lancedb/lancedb">GitHub</a></li>
  <li><a href="https://lancedb.com/">Web</a></li>
  <li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li>
  <li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li>
  <li><a href="https://blog.lancedb.com/lance-v2/">Lance V2</a></li>
</ul>
<p><strong>Weston Pace:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/weston-pace-cool-dude/">LinkedIn</a></li>
  <li><a href="https://github.com/westonpace">GitHub</a></li>
</ul>
<p><strong>Nicolay Gerold:</strong></p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">‚Å†LinkedIn‚Å†</a></li>
  <li><a href="https://twitter.com/nicolaygerold">‚Å†X (Twitter)</a></li>
</ul>
<p><strong>Chapters</strong></p>
<p><strong>00:00</strong> Introducing Lance: A New File Format</p>
<p><strong>06:46</strong> Enabling Custom Encodings in Lance</p>
<p><strong>11:51</strong> Exploring the Relationship Between Lance and Arrow</p>
<p><strong>20:04</strong> New Chapter</p>
<p>Lance file format, nulls, round-tripping data, optimized data representations, full-text search, encodings, downsides, multimodal data, compression, point lookups, full scan performance, non-contiguous columns, custom encodings</p>]]>
      </content:encoded>
      <pubDate>Mon, 29 Apr 2024 08:33:40 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/7aaf9fa9/6636d17d.mp3" length="20685231" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:duration>1293</itunes:duration>
      <itunes:summary>In this episode of Changelog, Weston Pace dives into the latest updates to LanceDB, an open-source vector database and file format. Lance's new V2 file format redefines the traditional notion of columnar storage, allowing for more efficient handling of large multimodal datasets like images and embeddings. Weston discusses the goals driving LanceDB's development, including null value support, multimodal data handling, and finding an optimal balance for search performance.
Sound Bites
"A little bit more power to actually just try."
"We're becoming a little bit more feature complete with returns of arrow."
"Weird data representations that are actually really optimized for your use case."
Key Points

 Weston introduces LanceDB, an open-source multimodal vector database and file format.
 The goals behind LanceDB's design: handling null values, multimodal data, and finding the right balance between point lookups and full dataset scan performance.
  Lance V2 File Format:
  Potential Use Cases

Conversation Highlights

  On the benefits of Arrow integration: Strengthening the connection with the Arrow data ecosystem for seamless data handling.
  Why "columnar container format"?: A broader definition than "table format" to encompass more unconventional use cases.
  Tackling multimodal data: How LanceDB V2 enables storage of large multimodal data efficiently and without needing tons of memory.
  Python's role in encoding experimentation: Providing a way to rapidly prototype custom encodings and plug them into LanceDB.

LanceDB:

  X (Twitter)
  GitHub
  Web
  Discord
  VectorDB Recipes
  Lance V2

Weston Pace:

  LinkedIn
  GitHub

Nicolay Gerold:

  ‚Å†LinkedIn‚Å†
  ‚Å†X (Twitter)

Chapters
00:00 Introducing Lance: A New File Format
06:46 Enabling Custom Encodings in Lance
11:51 Exploring the Relationship Between Lance and Arrow
20:04 New Chapter
Lance file format, nulls, round-tripping data, optimized data representations, full-text search, encodings, downsides, multimodal data, compression, point lookups, full scan performance, non-contiguous columns, custom encodings</itunes:summary>
      <itunes:subtitle>In this episode of Changelog, Weston Pace dives into the latest updates to LanceDB, an open-source vector database and file format. Lance's new V2 file format redefines the traditional notion of columnar storage, allowing for more efficient handling of la</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#004 AI with Supabase, Postgres Configuration, Real-Time Processing, and more</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>4</itunes:episode>
      <podcast:episode>4</podcast:episode>
      <itunes:title>#004 AI with Supabase, Postgres Configuration, Real-Time Processing, and more</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">26ed6971-d6c9-4f80-9dc3-2d0460161c7d</guid>
      <link>https://share.transistor.fm/s/2fb6c668</link>
      <description>
        <![CDATA[<p>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:</p><ul><li>Core components and how they power real-time AI solutions</li><li>Optimizing Postgres for AI workloads</li><li>The magic of PG Vector and other key extensions</li><li>Supabase‚Äôs future and exciting new features</li></ul><p>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:</p><ul><li>Core components and how they power real-time AI solutions</li><li>Optimizing Postgres for AI workloads</li><li>The magic of PG Vector and other key extensions</li><li>Supabase‚Äôs future and exciting new features</li></ul>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:</p><ul><li>Core components and how they power real-time AI solutions</li><li>Optimizing Postgres for AI workloads</li><li>The magic of PG Vector and other key extensions</li><li>Supabase‚Äôs future and exciting new features</li></ul><p>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:</p><ul><li>Core components and how they power real-time AI solutions</li><li>Optimizing Postgres for AI workloads</li><li>The magic of PG Vector and other key extensions</li><li>Supabase‚Äôs future and exciting new features</li></ul>]]>
      </content:encoded>
      <pubDate>Fri, 26 Apr 2024 08:09:46 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/2fb6c668/ef675f49.mp3" length="30667344" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/_MUh6yH70ntaSkIvMlvZWNln8lAjce-2LN8VhKFRnPA/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS84OTFj/Mjg4MjIyOWQ3NWE0/ZjlkMmNhODE5ZGMw/MmQzNC5qcGc.jpg"/>
      <itunes:duration>1917</itunes:duration>
      <itunes:summary>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:

 Core components and how they power real-time AI solutions
 Optimizing Postgres for AI workloads
 The magic of PG Vector and other key extensions
 Supabase‚Äôs future and exciting new features

Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:

 Core components and how they power real-time AI solutions
 Optimizing Postgres for AI workloads
  The magic of PG Vector and other key extensions
  Supabase‚Äôs future and exciting new features</itunes:summary>
      <itunes:subtitle>Had a fantastic conversation with Christopher Williams, Solutions Architect at Supabase, about setting up Postgres the right way for AI. We dug deep into Supabase, exploring:

 Core components and how they power real-time AI solutions
 Optimizing Postg</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#003 AI Inside Your Database, Real-Time AI, Declarative ML/AI</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:title>#003 AI Inside Your Database, Real-Time AI, Declarative ML/AI</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">704b8683-386d-4534-b591-9263ef22e5be</guid>
      <link>https://share.transistor.fm/s/2be28195</link>
      <description>
        <![CDATA[<p>If you've ever wanted a simpler way to integrate AI directly into your database, SuperDuperDB might be the answer. SuperDuperDB lets you easily apply AI processes to your data while keeping everything up-to-date with real-time calculations. It works with various databases and aims to make AI development less of a headache.</p><p><strong>In this podcast, we explore:</strong></p><ul><li>How SuperDuperDB bridges the gap between AI and databases.</li><li>The benefits of real-time AI processes within your data deployment.</li><li>SuperDuperDB's framework for configuring AI workflows.</li><li>The future of AI-powered databases.</li></ul><p><strong>Takeaways</strong></p><ul><li>SuperDuperDB enables developers to apply AI processes directly to their data stores</li><li>The platform supports real-time computation of embeddings or classifications, keeping the data deployment up to date</li><li>SuperDuperDB provides a framework for configuring AI processes that work in close combination with the data deployment</li><li>The platform supports a variety of databases, including operational and analytical databases</li><li>SuperDuperDB aims to simplify AI development by abstracting the data layer and infrastructure</li></ul><p><strong>Duncan Blythe:</strong></p><ul><li><a href="https://www.linkedin.com/company/superduperdb/">LinkedIn</a></li></ul><p><strong>SuperDuperDB:</strong></p><ul><li><a href="https://docs.superduperdb.com/docs/docs/intro/">Docs</a></li><li><a href="https://www.superduperdb.com/">Website</a></li><li><a href="https://www.linkedin.com/search/results/all/?fetchDeterministicClustersOnly=true&amp;heroEntityKey=urn:li:organization:93607276&amp;keywords=superduperdb&amp;origin=RICH_QUERY_TYPEAHEAD_HISTORY&amp;position=0&amp;searchId=df4ab1f0-8c9f-4890-951c-897746a9a108&amp;sid=Jvw&amp;spellCorrectionEnabled=true">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction to SuperDuperDB</p><p><strong>04:19</strong> Real-time Computation and Data Deployment</p><p><strong>13:46</strong> Bringing Compute and Database Closer Together</p><p><strong>29:30</strong> Declarative Machine Learning with SuperDuperDB</p><p><strong>35:09</strong> Future Plans for SuperDuperDB</p><p>SuperDuperDB, AI, databases, embeddings, classifications, data deployment, operational databases, analytical databases, AI development, data science</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>If you've ever wanted a simpler way to integrate AI directly into your database, SuperDuperDB might be the answer. SuperDuperDB lets you easily apply AI processes to your data while keeping everything up-to-date with real-time calculations. It works with various databases and aims to make AI development less of a headache.</p><p><strong>In this podcast, we explore:</strong></p><ul><li>How SuperDuperDB bridges the gap between AI and databases.</li><li>The benefits of real-time AI processes within your data deployment.</li><li>SuperDuperDB's framework for configuring AI workflows.</li><li>The future of AI-powered databases.</li></ul><p><strong>Takeaways</strong></p><ul><li>SuperDuperDB enables developers to apply AI processes directly to their data stores</li><li>The platform supports real-time computation of embeddings or classifications, keeping the data deployment up to date</li><li>SuperDuperDB provides a framework for configuring AI processes that work in close combination with the data deployment</li><li>The platform supports a variety of databases, including operational and analytical databases</li><li>SuperDuperDB aims to simplify AI development by abstracting the data layer and infrastructure</li></ul><p><strong>Duncan Blythe:</strong></p><ul><li><a href="https://www.linkedin.com/company/superduperdb/">LinkedIn</a></li></ul><p><strong>SuperDuperDB:</strong></p><ul><li><a href="https://docs.superduperdb.com/docs/docs/intro/">Docs</a></li><li><a href="https://www.superduperdb.com/">Website</a></li><li><a href="https://www.linkedin.com/search/results/all/?fetchDeterministicClustersOnly=true&amp;heroEntityKey=urn:li:organization:93607276&amp;keywords=superduperdb&amp;origin=RICH_QUERY_TYPEAHEAD_HISTORY&amp;position=0&amp;searchId=df4ab1f0-8c9f-4890-951c-897746a9a108&amp;sid=Jvw&amp;spellCorrectionEnabled=true">LinkedIn</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p><strong>Chapters</strong></p><p><strong>00:00</strong> Introduction to SuperDuperDB</p><p><strong>04:19</strong> Real-time Computation and Data Deployment</p><p><strong>13:46</strong> Bringing Compute and Database Closer Together</p><p><strong>29:30</strong> Declarative Machine Learning with SuperDuperDB</p><p><strong>35:09</strong> Future Plans for SuperDuperDB</p><p>SuperDuperDB, AI, databases, embeddings, classifications, data deployment, operational databases, analytical databases, AI development, data science</p>]]>
      </content:encoded>
      <pubDate>Fri, 19 Apr 2024 13:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/2be28195/377d5e01.mp3" length="34624131" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/BInBeOtxvl07jaQQj1WQJDu4wKmBlpp3JyJurDEO_OU/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS8xYmZj/YjNiZjk1YTFmNjRi/YzRkZDgyMjhjZTk4/MzRjNi5qcGc.jpg"/>
      <itunes:duration>2164</itunes:duration>
      <itunes:summary>If you've ever wanted a simpler way to integrate AI directly into your database, SuperDuperDB might be the answer. SuperDuperDB lets you easily apply AI processes to your data while keeping everything up-to-date with real-time calculations. It works with various databases and aims to make AI development less of a headache.
In this podcast, we explore:

 How SuperDuperDB bridges the gap between AI and databases.
 The benefits of real-time AI processes within your data deployment.
 SuperDuperDB's framework for configuring AI workflows.
  The future of AI-powered databases.

Takeaways

  SuperDuperDB enables developers to apply AI processes directly to their data stores
  The platform supports real-time computation of embeddings or classifications, keeping the data deployment up to date
  SuperDuperDB provides a framework for configuring AI processes that work in close combination with the data deployment
  The platform supports a variety of databases, including operational and analytical databases
  SuperDuperDB aims to simplify AI development by abstracting the data layer and infrastructure

Duncan Blythe:

  LinkedIn

SuperDuperDB:

  Docs
  Website
  LinkedIn

Nicolay Gerold:

  LinkedIn
  X (Twitter)

Chapters
00:00 Introduction to SuperDuperDB
04:19 Real-time Computation and Data Deployment
13:46 Bringing Compute and Database Closer Together
29:30 Declarative Machine Learning with SuperDuperDB
35:09 Future Plans for SuperDuperDB
SuperDuperDB, AI, databases, embeddings, classifications, data deployment, operational databases, analytical databases, AI development, data science</itunes:summary>
      <itunes:subtitle>If you've ever wanted a simpler way to integrate AI directly into your database, SuperDuperDB might be the answer. SuperDuperDB lets you easily apply AI processes to your data while keeping everything up-to-date with real-time calculations. It works with </itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>Supabase acquires OrioleDB, A New Database Engine for PostgreSQL | changelog 1</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>3</itunes:episode>
      <podcast:episode>3</podcast:episode>
      <itunes:title>Supabase acquires OrioleDB, A New Database Engine for PostgreSQL | changelog 1</itunes:title>
      <itunes:episodeType>bonus</itunes:episodeType>
      <guid isPermaLink="false">19ed9c48-644b-4f52-bb4f-ef6cfe3e4129</guid>
      <link>https://share.transistor.fm/s/4c562883</link>
      <description>
        <![CDATA[<p>Supabase just acquired OrioleDB, a storage engine for PostgreSQL. </p>
<p>Oriole gets creative with MVCC! It uses an UNDO log rather than keeping multiple versions of an entire data row (tuple). This means when you update data, Oriole tracks the changes needed to "undo" the update if necessary. Think of this like the "undo" function in a text editor. Instead of keeping a full copy of the old text, it just remembers what changed. This can be much smaller. This also saves space by eliminating the need for a garbage collection process. </p>
<p><br></p>
<p>It also has a bunch of additional performance boosters like data compression, easy integration with data lakes, and index-organized tables. </p>
<p>Show notes:</p>
<ul>
 <li><a href="https://supabase.com/blog/supabase-aquires-oriole" rel="noopener noreferer">Oriole joins Supabase</a></li>
 <li><a href="https://github.com/orioledb/orioledb" rel="noopener noreferer">Oriole Git</a></li>
 <li><a href="https://www.youtube.com/watch?v=coaJCB_H9cU" rel="noopener noreferer">Percona Talk on OrioleDB</a></li>
 <li><a href="https://supabase.com/" rel="noopener noreferer">Supabase</a></li>
</ul>
<p>Chris Gwilliams:</p>
<ul>
  <li><a href="https://www.linkedin.com/in/christopher-gwilliams-51322924?originalSubdomain=fi" rel="noopener noreferer">LinkedIn</a></li>
</ul>
<p>Nicolay Gerold:</p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li>
  <li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li>
</ul>
<p>00:42 Introduction to OrioleDB</p>
<p>04:38 The Undo Log Approach</p>
<p>08:39 Improving Performance for High Throughput Databases</p>
<p>11:08 My take on OrioleDB</p>
<p>OrioleDB, storage engine, Postgres, table access methods, undo log, high throughput databases, automated features, new use cases, S3, data migration</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Supabase just acquired OrioleDB, a storage engine for PostgreSQL. </p>
<p>Oriole gets creative with MVCC! It uses an UNDO log rather than keeping multiple versions of an entire data row (tuple). This means when you update data, Oriole tracks the changes needed to "undo" the update if necessary. Think of this like the "undo" function in a text editor. Instead of keeping a full copy of the old text, it just remembers what changed. This can be much smaller. This also saves space by eliminating the need for a garbage collection process. </p>
<p><br></p>
<p>It also has a bunch of additional performance boosters like data compression, easy integration with data lakes, and index-organized tables. </p>
<p>Show notes:</p>
<ul>
 <li><a href="https://supabase.com/blog/supabase-aquires-oriole" rel="noopener noreferer">Oriole joins Supabase</a></li>
 <li><a href="https://github.com/orioledb/orioledb" rel="noopener noreferer">Oriole Git</a></li>
 <li><a href="https://www.youtube.com/watch?v=coaJCB_H9cU" rel="noopener noreferer">Percona Talk on OrioleDB</a></li>
 <li><a href="https://supabase.com/" rel="noopener noreferer">Supabase</a></li>
</ul>
<p>Chris Gwilliams:</p>
<ul>
  <li><a href="https://www.linkedin.com/in/christopher-gwilliams-51322924?originalSubdomain=fi" rel="noopener noreferer">LinkedIn</a></li>
</ul>
<p>Nicolay Gerold:</p>
<ul>
  <li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li>
  <li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li>
</ul>
<p>00:42 Introduction to OrioleDB</p>
<p>04:38 The Undo Log Approach</p>
<p>08:39 Improving Performance for High Throughput Databases</p>
<p>11:08 My take on OrioleDB</p>
<p>OrioleDB, storage engine, Postgres, table access methods, undo log, high throughput databases, automated features, new use cases, S3, data migration</p>]]>
      </content:encoded>
      <pubDate>Wed, 17 Apr 2024 07:05:07 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/4c562883/0f953a00.mp3" length="13065812" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:duration>817</itunes:duration>
      <itunes:summary>Supabase just acquired OrioleDB, a storage engine for PostgreSQL. 
Oriole gets creative with MVCC! It uses an UNDO log rather than keeping multiple versions of an entire data row (tuple). This means when you update data, Oriole tracks the changes needed to "undo" the update if necessary. Think of this like the "undo" function in a text editor. Instead of keeping a full copy of the old text, it just remembers what changed. This can be much smaller. This also saves space by eliminating the need for a garbage collection process. 

It also has a bunch of additional performance boosters like data compression, easy integration with data lakes, and index-organized tables. 
Show notes:

 Oriole joins Supabase
 Oriole Git
 Percona Talk on OrioleDB
 Supabase

Chris Gwilliams:

  LinkedIn

Nicolay Gerold:

  LinkedIn
  X (Twitter)

00:42 Introduction to OrioleDB
04:38 The Undo Log Approach
08:39 Improving Performance for High Throughput Databases
11:08 My take on OrioleDB
OrioleDB, storage engine, Postgres, table access methods, undo log, high throughput databases, automated features, new use cases, S3, data migration</itunes:summary>
      <itunes:subtitle>Supabase just acquired OrioleDB, a storage engine for PostgreSQL. 
Oriole gets creative with MVCC! It uses an UNDO log rather than keeping multiple versions of an entire data row (tuple). This means when you update data, Oriole tracks the changes needed t</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#002 AI Powered Data Transformation, Combining gen &amp; trad AI, Semantic Validation</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>2</itunes:episode>
      <podcast:episode>2</podcast:episode>
      <itunes:title>#002 AI Powered Data Transformation, Combining gen &amp; trad AI, Semantic Validation</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">f1cfd735-c6cc-4713-b229-c574772d413a</guid>
      <link>https://share.transistor.fm/s/b04de0e1</link>
      <description>
        <![CDATA[<p>Today‚Äôs guest is Antonio Bustamante, a serial entrepreneur who previously built Kite and Silo and is now working to fix bad data. He is building bem, the data tool to transform any data into the schema your AI and software needs.</p><p><a href="http://bem.ai">bem.ai</a> is a data tool that focuses on transforming any data into the schema needed for AI and software. It acts as a system's interoperability layer, allowing systems that couldn't communicate before to exchange information. Learn what place LLMs play in data transformation, how to build reliable data infrastructure and more.</p><p>"Surprisingly, the hardest was semi-structured data. That is data that should be structured, but is unreliable, undocumented, hard to work with."</p><p>"We were spending close to four or five million dollars a year just in integrations, which is no small budget for a company that size. So I was pretty much determined to fix this problem once and for all."</p><p>"bem focuses on being the system's interoperability layer."</p><p>"We basically take in anything you send us, we transform it exactly into your internal data schema so that you don't have to parse, process, transform anything of that sort."</p><p>"LLMs are a 30% of it... A lot of it is very, very like thorough validation layers, great infrastructure, just ensuring reliability and connection to our user systems.‚Äù</p><p>"You can use a million token context window and feed an entire document to an LLM. I can guarantee you if you don't, semantically chunk it out before you're not going to get the right results.‚Äù</p><p>"We're obsessed with time to value... Our milestone is basically five minute onboarding max, and then you're ready to go."</p><p><strong>Antonio Bustamante</strong></p><ul><li><a href="https://www.linkedin.com/in/abmirayo/">LinkedIn</a></li><li><a href="https://twitter.com/abustamante?lang=en">X (Twitter)</a></li></ul><p><a href="http://bem.ai">bem.ai</a></p><ul><li><a href="https://www.linkedin.com/company/bem-ai/">LinkedIn</a></li><li><a href="https://www.bem.ai/">Website</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>Semi-structured data, Data integrations, Large language models (LLMs), Data transformation, Schema interoperability, Fault tolerance, Validation layers, System reliability, Schema evolution, Enterprise software, Data pipelines.</p><p><strong>Chapters</strong></p><p><strong>00:00</strong> The Problem of Integrations</p><p><strong>05:58</strong> Building Fault Tolerant Systems</p><p><strong>13:51</strong> Versioning and Semantic Validation</p><p><strong>27:33</strong> BEM in the Data Ecosystem</p><p><strong>34:40</strong> Future Plans and Onboarding</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Today‚Äôs guest is Antonio Bustamante, a serial entrepreneur who previously built Kite and Silo and is now working to fix bad data. He is building bem, the data tool to transform any data into the schema your AI and software needs.</p><p><a href="http://bem.ai">bem.ai</a> is a data tool that focuses on transforming any data into the schema needed for AI and software. It acts as a system's interoperability layer, allowing systems that couldn't communicate before to exchange information. Learn what place LLMs play in data transformation, how to build reliable data infrastructure and more.</p><p>"Surprisingly, the hardest was semi-structured data. That is data that should be structured, but is unreliable, undocumented, hard to work with."</p><p>"We were spending close to four or five million dollars a year just in integrations, which is no small budget for a company that size. So I was pretty much determined to fix this problem once and for all."</p><p>"bem focuses on being the system's interoperability layer."</p><p>"We basically take in anything you send us, we transform it exactly into your internal data schema so that you don't have to parse, process, transform anything of that sort."</p><p>"LLMs are a 30% of it... A lot of it is very, very like thorough validation layers, great infrastructure, just ensuring reliability and connection to our user systems.‚Äù</p><p>"You can use a million token context window and feed an entire document to an LLM. I can guarantee you if you don't, semantically chunk it out before you're not going to get the right results.‚Äù</p><p>"We're obsessed with time to value... Our milestone is basically five minute onboarding max, and then you're ready to go."</p><p><strong>Antonio Bustamante</strong></p><ul><li><a href="https://www.linkedin.com/in/abmirayo/">LinkedIn</a></li><li><a href="https://twitter.com/abustamante?lang=en">X (Twitter)</a></li></ul><p><a href="http://bem.ai">bem.ai</a></p><ul><li><a href="https://www.linkedin.com/company/bem-ai/">LinkedIn</a></li><li><a href="https://www.bem.ai/">Website</a></li></ul><p><strong>Nicolay Gerold:</strong></p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>Semi-structured data, Data integrations, Large language models (LLMs), Data transformation, Schema interoperability, Fault tolerance, Validation layers, System reliability, Schema evolution, Enterprise software, Data pipelines.</p><p><strong>Chapters</strong></p><p><strong>00:00</strong> The Problem of Integrations</p><p><strong>05:58</strong> Building Fault Tolerant Systems</p><p><strong>13:51</strong> Versioning and Semantic Validation</p><p><strong>27:33</strong> BEM in the Data Ecosystem</p><p><strong>34:40</strong> Future Plans and Onboarding</p>]]>
      </content:encoded>
      <pubDate>Fri, 12 Apr 2024 13:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/b04de0e1/dfaed89d.mp3" length="35655257" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/59LmJp4WaPt_mOf73CwviSxCGdbV2DXpYxmMpVpr77E/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS85NDhk/OTZkMzhhOTNjOTA4/YjIwYTFiMmJmMTZk/ZTQ5MS5qcGc.jpg"/>
      <itunes:duration>2229</itunes:duration>
      <itunes:summary>Today‚Äôs guest is Antonio Bustamante, a serial entrepreneur who previously built Kite and Silo and is now working to fix bad data. He is building bem, the data tool to transform any data into the schema your AI and software needs.
bem.ai is a data tool that focuses on transforming any data into the schema needed for AI and software. It acts as a system's interoperability layer, allowing systems that couldn't communicate before to exchange information. Learn what place LLMs play in data transformation, how to build reliable data infrastructure and more.
"Surprisingly, the hardest was semi-structured data. That is data that should be structured, but is unreliable, undocumented, hard to work with."
"We were spending close to four or five million dollars a year just in integrations, which is no small budget for a company that size. So I was pretty much determined to fix this problem once and for all."
"bem focuses on being the system's interoperability layer."
"We basically take in anything you send us, we transform it exactly into your internal data schema so that you don't have to parse, process, transform anything of that sort."
"LLMs are a 30% of it... A lot of it is very, very like thorough validation layers, great infrastructure, just ensuring reliability and connection to our user systems.‚Äù
"You can use a million token context window and feed an entire document to an LLM. I can guarantee you if you don't, semantically chunk it out before you're not going to get the right results.‚Äù
"We're obsessed with time to value... Our milestone is basically five minute onboarding max, and then you're ready to go."
Antonio Bustamante

 LinkedIn
 X (Twitter)

bem.ai

 LinkedIn
 Website

Nicolay Gerold:

  LinkedIn
  X (Twitter)

Semi-structured data, Data integrations, Large language models (LLMs), Data transformation, Schema interoperability, Fault tolerance, Validation layers, System reliability, Schema evolution, Enterprise software, Data pipelines.
Chapters
00:00 The Problem of Integrations
05:58 Building Fault Tolerant Systems
13:51 Versioning and Semantic Validation
27:33 BEM in the Data Ecosystem
34:40 Future Plans and Onboarding</itunes:summary>
      <itunes:subtitle>Today‚Äôs guest is Antonio Bustamante, a serial entrepreneur who previously built Kite and Silo and is now working to fix bad data. He is building bem, the data tool to transform any data into the schema your AI and software needs.
bem.ai is a data tool th</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
    <item>
      <title>#001 Multimodal AI, Storing 1 Billion Vectors, Building Data Infrastructure at LanceDB</title>
      <itunes:season>1</itunes:season>
      <podcast:season>1</podcast:season>
      <itunes:episode>1</itunes:episode>
      <podcast:episode>1</podcast:episode>
      <itunes:title>#001 Multimodal AI, Storing 1 Billion Vectors, Building Data Infrastructure at LanceDB</itunes:title>
      <itunes:episodeType>full</itunes:episodeType>
      <guid isPermaLink="false">7b0fbe70-6b74-40f3-a2ad-fb8ee283a0b6</guid>
      <link>https://share.transistor.fm/s/f66d6ebe</link>
      <description>
        <![CDATA[<p>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.</p><p>Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.</p><p>"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."</p><p>‚ÄúWe're big believers in the composable data systems vision."</p><p>"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."</p><p>"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."</p><p>"LanceDB offers up to 1,000 times faster performance than Parquet."</p><p>Chang She:</p><ul><li><a href="https://www.linkedin.com/in/changshe/">LinkedIn</a></li><li><a href="https://twitter.com/changhiskhan">X (Twitter)</a></li></ul><p>LanceDB:</p><ul><li><a href="https://twitter.com/lancedb">X (Twitter)</a></li><li><a href="https://github.com/lancedb/lancedb">GitHub</a></li><li><a href="https://lancedb.com/">Web</a></li><li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li><li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li></ul><p>Nicolay Gerold:</p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>Chapters:</p><p><strong>00:00</strong> Introduction to LanceDB</p><p><strong>02:16</strong> Building LanceDB in Rust</p><p><strong>12:10</strong> Optimizing Data Infrastructure</p><p><strong>26:20</strong> Surprising Use Cases for LanceDB</p><p><strong>32:01</strong> The Future of LanceDB</p><p>LanceDB, AI, database, Rust, multimodal AI, data infrastructure, embeddings, images, performance, Parquet, machine learning, model database, function registries, agents.</p>]]>
      </description>
      <content:encoded>
        <![CDATA[<p>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.</p><p>Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.</p><p>"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."</p><p>‚ÄúWe're big believers in the composable data systems vision."</p><p>"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."</p><p>"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."</p><p>"LanceDB offers up to 1,000 times faster performance than Parquet."</p><p>Chang She:</p><ul><li><a href="https://www.linkedin.com/in/changshe/">LinkedIn</a></li><li><a href="https://twitter.com/changhiskhan">X (Twitter)</a></li></ul><p>LanceDB:</p><ul><li><a href="https://twitter.com/lancedb">X (Twitter)</a></li><li><a href="https://github.com/lancedb/lancedb">GitHub</a></li><li><a href="https://lancedb.com/">Web</a></li><li><a href="https://discord.gg/zMM32dvNtd">Discord</a></li><li><a href="https://github.com/lancedb/vectordb-recipes/tree/main">VectorDB Recipes</a></li></ul><p>Nicolay Gerold:</p><ul><li><a href="https://www.linkedin.com/in/nicolay-gerold/">LinkedIn</a></li><li><a href="https://twitter.com/nicolaygerold">X (Twitter)</a></li></ul><p>Chapters:</p><p><strong>00:00</strong> Introduction to LanceDB</p><p><strong>02:16</strong> Building LanceDB in Rust</p><p><strong>12:10</strong> Optimizing Data Infrastructure</p><p><strong>26:20</strong> Surprising Use Cases for LanceDB</p><p><strong>32:01</strong> The Future of LanceDB</p><p>LanceDB, AI, database, Rust, multimodal AI, data infrastructure, embeddings, images, performance, Parquet, machine learning, model database, function registries, agents.</p>]]>
      </content:encoded>
      <pubDate>Fri, 05 Apr 2024 13:00:00 -0400</pubDate>
      <author>Nicolay Gerold</author>
      <enclosure url="https://media.transistor.fm/f66d6ebe/18d2195d.mp3" length="32699443" type="audio/mpeg"/>
      <itunes:author>Nicolay Gerold</itunes:author>
      <itunes:image href="https://img.transistor.fm/ryRPITFyvwJG7pcnbqrX8MZVjMjePKJB0xpKv5F8dJA/rs:fill:3000:3000:1/q:60/aHR0cHM6Ly9pbWct/dXBsb2FkLXByb2R1/Y3Rpb24udHJhbnNp/c3Rvci5mbS9mNjhh/NzJmN2Y0M2I3YmZh/NDA3MTZiODIzMTk1/NjliNC5qcGc.jpg"/>
      <itunes:duration>2044</itunes:duration>
      <itunes:summary>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.
Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabytes of unstructured data. It is the database for AI. Dive with us into how LanceDB was built, what went into the decision to use Rust as the main implementation language, the potential of AI on top of LanceDB, and more.
"LanceDB is the database for AI...to manage their data, to do a performant billion scale vector search."
‚ÄúWe're big believers in the composable data systems vision."
"You can insert data into LanceDB using Panda's data frames...to sort of really large 'embed the internet' kind of workflows."
"We wanted to create a new generation of data infrastructure that makes their [AI engineers] lives a lot easier."
"LanceDB offers up to 1,000 times faster performance than Parquet."
Change She:

 LinkedIn
 X (Twitter)

LanceDB:

 X (Twitter)
 GitHub
  Web
  Discord
  VectorDB Recipes

Nicolay Gerold:

  LinkedIn
  X (Twitter)

Chapters:
00:00 Introduction to LanceDB
02:16 Building LanceDB in Rust
12:10 Optimizing Data Infrastructure
26:20 Surprising Use Cases for LanceDB
32:01 The Future of LanceDB
LanceDB, AI, database, Rust, multimodal AI, data infrastructure, embeddings, images, performance, Parquet, machine learning, model database, function registries, agents.</itunes:summary>
      <itunes:subtitle>Imagine a world where data bottlenecks, slow data loaders, or memory issues on the VM don't hold back machine learning.
Machine learning and AI success depends on the speed you can iterate. LanceDB is here to to enable fast experiments on top of terabyte</itunes:subtitle>
      <itunes:keywords>ai, technology, llm, machine learning, data engineering</itunes:keywords>
      <itunes:explicit>No</itunes:explicit>
    </item>
  </channel>
</rss>
