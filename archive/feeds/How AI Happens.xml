<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:media="http://search.yahoo.com/mrss/" xmlns:podcast="https://podcastindex.org/namespace/1.0">
  <channel>
    <atom:link href="https://feeds.simplecast.com/qc2rXup_" rel="self" title="MP3 Audio" type="application/atom+xml"/>
    <atom:link href="https://simplecast.superfeedr.com" rel="hub" xmlns="http://www.w3.org/2005/Atom"/>
    <generator>https://simplecast.com</generator>
    <title>How AI Happens</title>
    <description>How AI Happens features experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field. Powered by Sama.</description>
    <copyright>2021-2025 Sama, Inc</copyright>
    <language>en</language>
    <pubDate>Mon, 5 May 2025 17:46:01 +0000</pubDate>
    <lastBuildDate>Fri, 23 May 2025 03:24:37 +0000</lastBuildDate>
    <image>
      <link>https://howaihappens.com</link>
      <title>How AI Happens</title>
      <url>https://image.simplecastcdn.com/images/e9af7d3a-9b46-4861-8721-2429b421754e/43114c15-e286-4e1e-b1d9-25afefc01e5b/3000x3000/how-ai-happens-cover.jpg?aid=rss_feed</url>
    </image>
    <link>https://howaihappens.com</link>
    <itunes:type>episodic</itunes:type>
    <itunes:summary>How AI Happens features experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field. Powered by Sama.</itunes:summary>
    <itunes:author>Sama</itunes:author>
    <itunes:explicit>false</itunes:explicit>
    <itunes:image href="https://image.simplecastcdn.com/images/e9af7d3a-9b46-4861-8721-2429b421754e/43114c15-e286-4e1e-b1d9-25afefc01e5b/3000x3000/how-ai-happens-cover.jpg?aid=rss_feed"/>
    <itunes:new-feed-url>https://feeds.simplecast.com/qc2rXup_</itunes:new-feed-url>
    <itunes:keywords>autonomous, computer science, computer vision, big data, training data, artificial intelligence, machine learning, ml, generative ai, agentic ai, llm, gen ai, large language models</itunes:keywords>
    <itunes:owner>
      <itunes:name>Sama</itunes:name>
      <itunes:email>eschwartze@samasource.org</itunes:email>
    </itunes:owner>
    <itunes:applepodcastsverify>ce384ad0-213e-11f0-9d76-0bfcd44199fc</itunes:applepodcastsverify>
    <itunes:category text="Technology"/>
    <itunes:category text="Science">
      <itunes:category text="Mathematics"/>
    </itunes:category>
    <itunes:category text="Business"/>
    <item>
      <guid isPermaLink="false">21baa5d5-8626-4374-8aec-8336b1088de5</guid>
      <title>Amdocs Group President Anthony Goonetilleke</title>
      <description><![CDATA[<ul><li>The rapid evolution of technology excites Anthony, especially in AI.</li><li>User preferences are shifting towards more human-like AI interactions.</li><li>Empathy in AI is crucial for better customer service experiences.</li><li>The partnership between Amdocs and NVIDIA emphasizes the importance of software efficiency</li><li>Software and hardware advancements must progress in parallel to maximize productivity.</li><li>Physical AI integration will enhance daily life through automation and smart devices.</li><li>Emergent behavior in AI represents a new frontier in reasoning and decision-making.</li><li>Generative AI can learn and adapt beyond traditional if-then programming.</li><li>An audit trail is essential for transparency in AI decision-making processes.</li></ul><p> </p><p> </p>
]]></description>
      <pubDate>Mon, 5 May 2025 17:46:01 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/amdocs-group-president-anthony-goonetilleke-BiVl2j44</link>
      <content:encoded><![CDATA[<ul><li>The rapid evolution of technology excites Anthony, especially in AI.</li><li>User preferences are shifting towards more human-like AI interactions.</li><li>Empathy in AI is crucial for better customer service experiences.</li><li>The partnership between Amdocs and NVIDIA emphasizes the importance of software efficiency</li><li>Software and hardware advancements must progress in parallel to maximize productivity.</li><li>Physical AI integration will enhance daily life through automation and smart devices.</li><li>Emergent behavior in AI represents a new frontier in reasoning and decision-making.</li><li>Generative AI can learn and adapt beyond traditional if-then programming.</li><li>An audit trail is essential for transparency in AI decision-making processes.</li></ul><p> </p><p> </p>
]]></content:encoded>
      <enclosure length="41528083" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/eb752f35-2dbe-43c9-9431-5c4eeaf74d44/audio/2367791b-399e-44e6-9a3d-d741391301e9/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Amdocs Group President Anthony Goonetilleke</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:43:15</itunes:duration>
      <itunes:summary>In this episode, Rob interviews Anthony Goonetilleke, the Group President and Head of Technology at Amdocs, who shares insights from his 26-year career at the company. They discuss the rapid evolution of technology, the democratization of coding, and the importance of empathy in AI interactions. Anthony also shares his experiences from the Nvidia GTC conference, highlighting user preferences for AI avatars and the future of customer service in an AI-driven world. The conversation emphasizes the evolving role of humans in technology and the need for understanding user needs to create effective AI solutions. </itunes:summary>
      <itunes:subtitle>In this episode, Rob interviews Anthony Goonetilleke, the Group President and Head of Technology at Amdocs, who shares insights from his 26-year career at the company. They discuss the rapid evolution of technology, the democratization of coding, and the importance of empathy in AI interactions. Anthony also shares his experiences from the Nvidia GTC conference, highlighting user preferences for AI avatars and the future of customer service in an AI-driven world. The conversation emphasizes the evolving role of humans in technology and the need for understanding user needs to create effective AI solutions. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>121</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">3513ea9c-9494-436d-90e8-ec5a62970083</guid>
      <title>Physics &amp; Machine Health with Algorithms Lead Mica Rubinson, Ph.D</title>
      <description><![CDATA[<p>Mica shares the methods behind Augury’s fault testing processes, why they use the highest quality data available, how in-house experts help them filter their data reliably, and their approach to communicating with customers. Our conversation also explores the balance between edge computing and cloud computing, and why both are necessary for optimal performance and monitoring.</p><p>Key Points From This Episode:</p><ul><li>Mica’s journey from studying physics at the Weizmann Institute to her current role at Augury.</li><li>How her background in physics and neuroscience inform her work in AI.</li><li>Why physicists are drawn to AI and data science; how scientists follow their curiosity.</li><li>Mica’s responsibilities in her role as algorithms team lead at Augury.</li><li>How they develop algorithms and test for faults; why this requires the highest quality data.</li><li>Understanding the role of their in-house expert vibration analysts.</li><li>The importance of domain expertise in labeling and annotating data.</li><li>Finding the balance between manual and automated processes in data labeling.</li><li>How to communicate with customers and present metrics that matter to them.</li><li>Augury’s use of edge and cloud computing for optimal performance and monitoring.</li></ul><p>Quotes:</p><p>“We look for better ways to adjust our algorithms and also develop new ones for all kinds of faults that could happen in the machines catching events that are trickier to catch, and for that we need highest quality data.” — Mica Rubinson [0:08:20]</p><p>“At Aubrey, we have internal vibration analysts that are experts in their field. They go through very rigorous training process. There are international standards to how you do vibration analysis, and we have them in-house.” — Mica Rubinson [0:09:07]</p><p>“[It’s] really helpful for us to have [these] in-house experts. We have massive amounts of records – signal recordings from 10 years of machine monitoring. Thanks to these experts [in] labeling, we can filter out a lot of noisy parts of this data.” — Mica Rubinson [0:10:32]</p><p>“We quantify [our services] for the customer as their ROI [and] how much they saved by using Augury. You had this [issue, and] we avoided this downtime. [We show] how much does it translates eventually [into] money that you saved.” — Mica Rubinson [0:22:28]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/mica-rubinson/?originalSubdomain=il">Mica Rubinson on LinkedIn</a></p><p><a href="https://www.researchgate.net/scientific-contributions/Mica-Rubinson-2125815397">Mica Rubinson on ResearchGate</a></p><p><a href="https://www.augury.com/">Augury</a><br /><a href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 20 Mar 2025 16:56:50 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/physics-machine-health-with-algorithms-lead-mica-rubinson-phd-F9aN1n4P</link>
      <content:encoded><![CDATA[<p>Mica shares the methods behind Augury’s fault testing processes, why they use the highest quality data available, how in-house experts help them filter their data reliably, and their approach to communicating with customers. Our conversation also explores the balance between edge computing and cloud computing, and why both are necessary for optimal performance and monitoring.</p><p>Key Points From This Episode:</p><ul><li>Mica’s journey from studying physics at the Weizmann Institute to her current role at Augury.</li><li>How her background in physics and neuroscience inform her work in AI.</li><li>Why physicists are drawn to AI and data science; how scientists follow their curiosity.</li><li>Mica’s responsibilities in her role as algorithms team lead at Augury.</li><li>How they develop algorithms and test for faults; why this requires the highest quality data.</li><li>Understanding the role of their in-house expert vibration analysts.</li><li>The importance of domain expertise in labeling and annotating data.</li><li>Finding the balance between manual and automated processes in data labeling.</li><li>How to communicate with customers and present metrics that matter to them.</li><li>Augury’s use of edge and cloud computing for optimal performance and monitoring.</li></ul><p>Quotes:</p><p>“We look for better ways to adjust our algorithms and also develop new ones for all kinds of faults that could happen in the machines catching events that are trickier to catch, and for that we need highest quality data.” — Mica Rubinson [0:08:20]</p><p>“At Aubrey, we have internal vibration analysts that are experts in their field. They go through very rigorous training process. There are international standards to how you do vibration analysis, and we have them in-house.” — Mica Rubinson [0:09:07]</p><p>“[It’s] really helpful for us to have [these] in-house experts. We have massive amounts of records – signal recordings from 10 years of machine monitoring. Thanks to these experts [in] labeling, we can filter out a lot of noisy parts of this data.” — Mica Rubinson [0:10:32]</p><p>“We quantify [our services] for the customer as their ROI [and] how much they saved by using Augury. You had this [issue, and] we avoided this downtime. [We show] how much does it translates eventually [into] money that you saved.” — Mica Rubinson [0:22:28]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/mica-rubinson/?originalSubdomain=il">Mica Rubinson on LinkedIn</a></p><p><a href="https://www.researchgate.net/scientific-contributions/Mica-Rubinson-2125815397">Mica Rubinson on ResearchGate</a></p><p><a href="https://www.augury.com/">Augury</a><br /><a href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="30516529" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e6463430-3dd8-45ae-b555-3e0fcff77ec8/audio/2909eeea-3171-454e-87a6-a2cf899f2c7b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Physics &amp; Machine Health with Algorithms Lead Mica Rubinson, Ph.D</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:47</itunes:duration>
      <itunes:summary>What can physics teach us about machine health in manufacturing? Joining us today to unpack this question is Mica Rubinson, a physicist with a PhD from the Weizmann Institute of Science. She currently serves as the algorithms lead for Augury, a company providing AI-driven insights into machines, processes, and operations in manufacturing. We sit down to discuss her transition from physics and neuroscience to working in AI, and how her background has informed her understanding of complex systems and improving machine health algorithms</itunes:summary>
      <itunes:subtitle>What can physics teach us about machine health in manufacturing? Joining us today to unpack this question is Mica Rubinson, a physicist with a PhD from the Weizmann Institute of Science. She currently serves as the algorithms lead for Augury, a company providing AI-driven insights into machines, processes, and operations in manufacturing. We sit down to discuss her transition from physics and neuroscience to working in AI, and how her background has informed her understanding of complex systems and improving machine health algorithms</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>120</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">696bad9e-740e-4b4a-aaa6-1fe1525acf9d</guid>
      <title>AWS Director of Generative AI Apps Srini Iragavarapu</title>
      <description><![CDATA[<p>Srini highlights the importance of integrating these agents into real-world applications, enhancing productivity and user experiences across industries. Srini also delves into the challenges of building reliable, ethical, and secure AI systems while fostering developer innovation. His insights offer a roadmap for harnessing advanced agents to drive meaningful technological progress. Don’t miss this informative conversation. </p><p>Key Points From This Episode:</p><ul><li>Introducing today’s guest, Srini Iragavarapu, a leader at AWS. </li><li>His thoughts on how Agentic and AI are intersecting today. </li><li>The state of the union of agents in the world and at AWS.</li><li>How AWS is leveraging agents to build specific tasks for customers.</li><li>Two mechanisms that software agents use to operate.</li><li>Understanding the reasoning capabilities of large foundational models.</li><li>How AWS makes use of a test agent. </li><li>Qdeveloper’s instantaneous conversational capabilities.</li><li>Bringing different options to the customers as a long-term strategy.</li><li>Three layers at which AWS is innovating today.</li><li>Why the end user is ultimately the person who benefits. </li></ul><p>Quotes:</p><p>“Think of it as an iterative way of solving a problem rather than just calling a single API and coming back: that’s in a nutshell how generative AI and the foundation models are working with reasoning capabilities.” — Srini Iragavarapu [0:03:04]</p><p>“The models are becoming more powerful and more available, faster,  a lot more dependable.” — Srini Iragavarapu [0:29:57]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/isvas/">Srini Iragavarapu on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 28 Feb 2025 19:03:22 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/aws-director-of-generative-ai-apps-srini-iragavarapu-3BIkavMA</link>
      <content:encoded><![CDATA[<p>Srini highlights the importance of integrating these agents into real-world applications, enhancing productivity and user experiences across industries. Srini also delves into the challenges of building reliable, ethical, and secure AI systems while fostering developer innovation. His insights offer a roadmap for harnessing advanced agents to drive meaningful technological progress. Don’t miss this informative conversation. </p><p>Key Points From This Episode:</p><ul><li>Introducing today’s guest, Srini Iragavarapu, a leader at AWS. </li><li>His thoughts on how Agentic and AI are intersecting today. </li><li>The state of the union of agents in the world and at AWS.</li><li>How AWS is leveraging agents to build specific tasks for customers.</li><li>Two mechanisms that software agents use to operate.</li><li>Understanding the reasoning capabilities of large foundational models.</li><li>How AWS makes use of a test agent. </li><li>Qdeveloper’s instantaneous conversational capabilities.</li><li>Bringing different options to the customers as a long-term strategy.</li><li>Three layers at which AWS is innovating today.</li><li>Why the end user is ultimately the person who benefits. </li></ul><p>Quotes:</p><p>“Think of it as an iterative way of solving a problem rather than just calling a single API and coming back: that’s in a nutshell how generative AI and the foundation models are working with reasoning capabilities.” — Srini Iragavarapu [0:03:04]</p><p>“The models are becoming more powerful and more available, faster,  a lot more dependable.” — Srini Iragavarapu [0:29:57]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/isvas/">Srini Iragavarapu on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31481597" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/ebfd67d4-0142-45c7-8736-f90183095773/audio/c0f8c08d-bf4c-4a21-8d9b-ec0a4d24db3a/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AWS Director of Generative AI Apps Srini Iragavarapu</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:47</itunes:duration>
      <itunes:summary>Generative AI is still part of the conversation, but perhaps more relevant today is the question of how to develop and leverage more advanced agents. Srini Iragavarapu is the Director of Generative AI applications and Developer Experiences at AWS, and he joins us today to discuss this key topic. Srini explores the evolution from basic generative AI models to sophisticated agents capable of autonomous decision-making and task execution.</itunes:summary>
      <itunes:subtitle>Generative AI is still part of the conversation, but perhaps more relevant today is the question of how to develop and leverage more advanced agents. Srini Iragavarapu is the Director of Generative AI applications and Developer Experiences at AWS, and he joins us today to discuss this key topic. Srini explores the evolution from basic generative AI models to sophisticated agents capable of autonomous decision-making and task execution.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>119</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">71e34454-26e0-4e99-97a3-3024bde01e05</guid>
      <title>Exploring Retail in AI with Freshworks CMO Mika Yamamoto &amp; Sama VPM Lisa Avvocato</title>
      <description><![CDATA[<p> We explore the current trends of AI-based solutions in retail, what has driven its adoption in the industry, and how AI-based customer service technology has improved over time. We also discuss the correct mix of technology and humans, the importance of establishing boundaries for AI, and why it won't replace humans but will augment workflow. Hear examples of AI retail success stories, what companies got AI wrong, and the reasons behind the wins and failures. Gain insights into the value of copilots, business strategies to avoid investing in ineffective AI solutions, and much more. Tune in now!</p><p>Key Points From This Episode:</p><ul><li>Learn about Lisa and Mika's backgrounds in retail technology and AI-based solutions. </li><li>Hear how AI has become more accessible to businesses beyond the typical tech giants.</li><li>Explore how AI-powered chatbots and copilots have evolved to improve customer service.</li><li>The Coca-Cola AI ad controversy and why oversight on AI-generated content is vital.</li><li>Discover the innovative and exciting ways AI can be leveraged in the retail industry.</li><li>AI success stories: Target’s AI copilot for employees and Nordstrom’s personalization tool.</li><li>How AI is making the return process more efficient and improving inventory management.</li><li>Uncover the multimodal connections of AI and how it will enhance customer personalization.</li><li>Important considerations for businesses regarding the adoption of AI and the pitfalls to avoid.</li></ul><p>Quotes:</p><p>“I think [the evolution] in terms of accessibility to AI-solutions for people who don't have the massive IT departments and massive data analytics departments is really remarkable.” — Mika Yamamoto [0:04:25]</p><p>“Whether it's generative AI for creative or content or whatever, it's not going to replace humans. It's going to augment our workflows.” — Lisa Avvocato [0:10:46]</p><p>“Retail is actually one of the fastest adopting industries out there [of] AI.” — Mika Yamamoto [0:14:17]</p><p>“Having conversations with peers, I think, is absolutely invaluable to figure out what's hype and what's reality [regarding AI].” — Mika Yamamoto [0:30:19]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/lisaavvocato/">Lisa Avvocato on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/mikayamamoto/">Mika Yamamoto on LinkedIn</a></p><p><a href="https://www.freshworks.com">Freshworks</a></p><p><a href="https://www.coca-colacompany.com/">The Coca‑Cola Company</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 21 Feb 2025 18:03:14 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/exploring-retail-in-ai-with-freshworks-cmo-mika-yamamoto-sama-vpm-lisa-avvocato-rDkPxHSE</link>
      <content:encoded><![CDATA[<p> We explore the current trends of AI-based solutions in retail, what has driven its adoption in the industry, and how AI-based customer service technology has improved over time. We also discuss the correct mix of technology and humans, the importance of establishing boundaries for AI, and why it won't replace humans but will augment workflow. Hear examples of AI retail success stories, what companies got AI wrong, and the reasons behind the wins and failures. Gain insights into the value of copilots, business strategies to avoid investing in ineffective AI solutions, and much more. Tune in now!</p><p>Key Points From This Episode:</p><ul><li>Learn about Lisa and Mika's backgrounds in retail technology and AI-based solutions. </li><li>Hear how AI has become more accessible to businesses beyond the typical tech giants.</li><li>Explore how AI-powered chatbots and copilots have evolved to improve customer service.</li><li>The Coca-Cola AI ad controversy and why oversight on AI-generated content is vital.</li><li>Discover the innovative and exciting ways AI can be leveraged in the retail industry.</li><li>AI success stories: Target’s AI copilot for employees and Nordstrom’s personalization tool.</li><li>How AI is making the return process more efficient and improving inventory management.</li><li>Uncover the multimodal connections of AI and how it will enhance customer personalization.</li><li>Important considerations for businesses regarding the adoption of AI and the pitfalls to avoid.</li></ul><p>Quotes:</p><p>“I think [the evolution] in terms of accessibility to AI-solutions for people who don't have the massive IT departments and massive data analytics departments is really remarkable.” — Mika Yamamoto [0:04:25]</p><p>“Whether it's generative AI for creative or content or whatever, it's not going to replace humans. It's going to augment our workflows.” — Lisa Avvocato [0:10:46]</p><p>“Retail is actually one of the fastest adopting industries out there [of] AI.” — Mika Yamamoto [0:14:17]</p><p>“Having conversations with peers, I think, is absolutely invaluable to figure out what's hype and what's reality [regarding AI].” — Mika Yamamoto [0:30:19]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/lisaavvocato/">Lisa Avvocato on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/mikayamamoto/">Mika Yamamoto on LinkedIn</a></p><p><a href="https://www.freshworks.com">Freshworks</a></p><p><a href="https://www.coca-colacompany.com/">The Coca‑Cola Company</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="30898544" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/08e6fd3e-17ab-4570-b149-63a20ffb404f/audio/a7c5d4f1-bd8c-49b4-8002-a76c64c74a77/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Exploring Retail in AI with Freshworks CMO Mika Yamamoto &amp; Sama VPM Lisa Avvocato</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:11</itunes:duration>
      <itunes:summary>AI is transforming industries worldwide, but how is it reshaping the retail experience? In this episode, we sit down with Lisa Avvocato and Mika Yamamoto to delve into the role of AI in retail and marketing. Lisa and Mika are seasoned marketing and business leaders specializing in AI, customer experience, and enterprise transformation. Lisa is the VP of Global Marketing and AI Community at Sama, where she champions ethical AI development through high-quality training data. Mika serves as the Chief Customer and Marketing Officer at Freshworks, a company driving global growth with AI-powered solutions that enhance customer and employee experiences. In our conversation, we unpack how AI is transforming retail operations, customer service, and online shopping experiences.</itunes:summary>
      <itunes:subtitle>AI is transforming industries worldwide, but how is it reshaping the retail experience? In this episode, we sit down with Lisa Avvocato and Mika Yamamoto to delve into the role of AI in retail and marketing. Lisa and Mika are seasoned marketing and business leaders specializing in AI, customer experience, and enterprise transformation. Lisa is the VP of Global Marketing and AI Community at Sama, where she champions ethical AI development through high-quality training data. Mika serves as the Chief Customer and Marketing Officer at Freshworks, a company driving global growth with AI-powered solutions that enhance customer and employee experiences. In our conversation, we unpack how AI is transforming retail operations, customer service, and online shopping experiences.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>118</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">26657fe7-6005-4992-be27-39c22e5a6d56</guid>
      <title>eBay Chief AI Officer Nitzan Mekel-Bobrov</title>
      <description><![CDATA[<p>We hear about Nitzan’s AI expertise, motivation for joining eBay, and approach to implementing AI into eBay's business model. Gain insights into the impacts of centralizing and federating AI, leveraging generative AI to create personalized content, and why patience is essential to AI development. We also unpack eBay's approach to LLM development, tailoring AI tools for eBay sellers, the pitfalls of generic marketing content, and the future of AI in retail. Join us to discover how AI is revolutionizing e-commerce and disrupting the retail sector with Nitzan Mekel-Bobrov! </p><p>Key Points From This Episode:</p><ul><li>Nitzan's career experience, his interest in sustainability, and his sneaker collection.</li><li>Why he decided to begin a career at eBay and his role at the company.</li><li>His approach to aligning the implementation of AI with eBay's overall strategy.</li><li>How he identifies the components of eBay's business model that will benefit from AI.</li><li>What makes eBay highly suitable for the implementation of AI tools.</li><li>Challenges of using generative AI models to create personalized content for users.</li><li>Why experimentation is vital to the AI development and implementation process.</li><li>Aspects of the user experience that Nitzan uses to train and develop eBay's LLMs.</li><li>The potential of knowledge graphs to uncover the complexity of user behavior.</li><li>Reasons that the unstructured nature of eBay's data is fundamental to its business model.</li><li>Incorporating a seller's style into AI tools to avoid creating generic marketing material.</li><li>Details about Nitzan’s team and their diverse array of expertise.</li><li>Final takeaways and how companies can ensure they survive the AI transition. </li></ul><p>Quotes:</p><p>“It’s tricky to balance the short-term wins with the long-term transformation.” — Nitzan Mekel-Bobrov [0:06:50]</p><p>“An experiment is only a failure if you haven’t learned anything yourself and – generated institutional knowledge from it.” — Nitzan Mekel-Bobrov [0:09:36]</p><p>“What's nice about [eBay's] business model — is that our incentive is to enable each seller to maintain their own uniqueness.” — Nitzan Mekel-Bobrov [0:27:33]</p><p>“The companies that will thrive in this AI transformation are the ones that can figure out how to marry parts of their current culture and what all of their talent brings with what the AI delivers.” — Nitzan Mekel-Bobrov [0:33:58]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/nmekelbobrov/">Nitzan Mekel-Bobrov on LinkedIn</a></p><p><a href="https://www.ebayinc.com">eBay</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 30 Jan 2025 20:03:56 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ebay-chief-ai-officer-nitzan-mekel-bobrov-BR1y858m</link>
      <content:encoded><![CDATA[<p>We hear about Nitzan’s AI expertise, motivation for joining eBay, and approach to implementing AI into eBay's business model. Gain insights into the impacts of centralizing and federating AI, leveraging generative AI to create personalized content, and why patience is essential to AI development. We also unpack eBay's approach to LLM development, tailoring AI tools for eBay sellers, the pitfalls of generic marketing content, and the future of AI in retail. Join us to discover how AI is revolutionizing e-commerce and disrupting the retail sector with Nitzan Mekel-Bobrov! </p><p>Key Points From This Episode:</p><ul><li>Nitzan's career experience, his interest in sustainability, and his sneaker collection.</li><li>Why he decided to begin a career at eBay and his role at the company.</li><li>His approach to aligning the implementation of AI with eBay's overall strategy.</li><li>How he identifies the components of eBay's business model that will benefit from AI.</li><li>What makes eBay highly suitable for the implementation of AI tools.</li><li>Challenges of using generative AI models to create personalized content for users.</li><li>Why experimentation is vital to the AI development and implementation process.</li><li>Aspects of the user experience that Nitzan uses to train and develop eBay's LLMs.</li><li>The potential of knowledge graphs to uncover the complexity of user behavior.</li><li>Reasons that the unstructured nature of eBay's data is fundamental to its business model.</li><li>Incorporating a seller's style into AI tools to avoid creating generic marketing material.</li><li>Details about Nitzan’s team and their diverse array of expertise.</li><li>Final takeaways and how companies can ensure they survive the AI transition. </li></ul><p>Quotes:</p><p>“It’s tricky to balance the short-term wins with the long-term transformation.” — Nitzan Mekel-Bobrov [0:06:50]</p><p>“An experiment is only a failure if you haven’t learned anything yourself and – generated institutional knowledge from it.” — Nitzan Mekel-Bobrov [0:09:36]</p><p>“What's nice about [eBay's] business model — is that our incentive is to enable each seller to maintain their own uniqueness.” — Nitzan Mekel-Bobrov [0:27:33]</p><p>“The companies that will thrive in this AI transformation are the ones that can figure out how to marry parts of their current culture and what all of their talent brings with what the AI delivers.” — Nitzan Mekel-Bobrov [0:33:58]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/nmekelbobrov/">Nitzan Mekel-Bobrov on LinkedIn</a></p><p><a href="https://www.ebayinc.com">eBay</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31684759" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/18571488-ad5b-4372-ba56-5ca38ba5c522/audio/889f5390-4164-433e-af80-1e2abf351345/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>eBay Chief AI Officer Nitzan Mekel-Bobrov</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:00</itunes:duration>
      <itunes:summary>How is AI disrupting the retail landscape? In this episode, we welcome Nitzan Mekel-Bobrov to explore the transformative role of AI in reshaping online marketplaces. Nitzan is a visionary leader and AI expert driving innovation at the intersection of technology and commerce. As Chief AI Officer at eBay, he spearheads cutting-edge AI initiatives that transform the online marketplace experience. Committed to empowering people and creating economic opportunity, eBay uses advanced technology to deliver a seamless, secure, personalized shopping experience for all users. </itunes:summary>
      <itunes:subtitle>How is AI disrupting the retail landscape? In this episode, we welcome Nitzan Mekel-Bobrov to explore the transformative role of AI in reshaping online marketplaces. Nitzan is a visionary leader and AI expert driving innovation at the intersection of technology and commerce. As Chief AI Officer at eBay, he spearheads cutting-edge AI initiatives that transform the online marketplace experience. Committed to empowering people and creating economic opportunity, eBay uses advanced technology to deliver a seamless, secure, personalized shopping experience for all users. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>117</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">20db056d-be76-4e58-b8a7-aae89da27283</guid>
      <title>Unilever Head of Data Science Dr. Satyajit Wattamwar</title>
      <description><![CDATA[<p>Satya unpacks how Unilever utilizes its database to inform its models and how to determine the right amount of data needed to solve complex problems. Dr. Wattamwar explains why contextual problem-solving is vital, the notion of time constraints in data science, the system point of view of modeling, and how Unilever incorporates AI into its models. Gain insights into how AI can increase operational efficiency, exciting trends in the AI space, how AI makes experimentation accessible, and more! Tune in to learn about the power of data science and AI with Dr. Satyajit Wattamwar.</p><p> </p><p>Key Points From This Episode:</p><ul><li>Background on Dr. Wattamwar, his PhD research, and data science expertise.</li><li>Unpacking some of the commonalities between data science and physics. </li><li>Why the outcome of using significantly large data sets depends on the situation. </li><li>The minimum amount of data needed to make meaningful and quality models.</li><li>Examples of the common mistakes and pitfalls that data scientists make.</li><li>How Unilever works with partner organizations to integrate AI into its models.</li><li>Ways that Dr. Wattamwar uses AI-based tools to increase his productivity.</li><li>The difference between using AI for innovation versus operational efficiency.</li><li>Insight into the shifting data science landscape and advice for budding data scientists.</li></ul><p>Quotes:</p><p>“Around – 30 or 40 years ago, people started realizing the importance of data-driven modeling because you can never capture physics perfectly in an equation.” — Dr. Satyajit Wattamwar [0:03:10]</p><p>“Having large volumes of data which are less related with each other is a different thing than a large volume of data for one problem.” — Dr. Satyajit Wattamwar [0:09:12]</p><p>“More data [does] not always lead to good quality models. Unless it is for the same use-case.” — Dr. Satyajit Wattamwar [0:11:56]</p><p>“If somebody is looking [to] grow in their career ladder, then it's not about one's own interest.” — Dr. Satyajit Wattamwar [0:24:07]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dr-satyajit-wattamwar-472a83b/">Dr. Satyajit Wattamwar on LinkedIn</a></p><p><a href="https://www.unilever.com">Unilever</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 24 Jan 2025 21:15:15 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/unilever-head-of-data-science-dr-satyajit-wattamwar-Cb9OAXzn</link>
      <content:encoded><![CDATA[<p>Satya unpacks how Unilever utilizes its database to inform its models and how to determine the right amount of data needed to solve complex problems. Dr. Wattamwar explains why contextual problem-solving is vital, the notion of time constraints in data science, the system point of view of modeling, and how Unilever incorporates AI into its models. Gain insights into how AI can increase operational efficiency, exciting trends in the AI space, how AI makes experimentation accessible, and more! Tune in to learn about the power of data science and AI with Dr. Satyajit Wattamwar.</p><p> </p><p>Key Points From This Episode:</p><ul><li>Background on Dr. Wattamwar, his PhD research, and data science expertise.</li><li>Unpacking some of the commonalities between data science and physics. </li><li>Why the outcome of using significantly large data sets depends on the situation. </li><li>The minimum amount of data needed to make meaningful and quality models.</li><li>Examples of the common mistakes and pitfalls that data scientists make.</li><li>How Unilever works with partner organizations to integrate AI into its models.</li><li>Ways that Dr. Wattamwar uses AI-based tools to increase his productivity.</li><li>The difference between using AI for innovation versus operational efficiency.</li><li>Insight into the shifting data science landscape and advice for budding data scientists.</li></ul><p>Quotes:</p><p>“Around – 30 or 40 years ago, people started realizing the importance of data-driven modeling because you can never capture physics perfectly in an equation.” — Dr. Satyajit Wattamwar [0:03:10]</p><p>“Having large volumes of data which are less related with each other is a different thing than a large volume of data for one problem.” — Dr. Satyajit Wattamwar [0:09:12]</p><p>“More data [does] not always lead to good quality models. Unless it is for the same use-case.” — Dr. Satyajit Wattamwar [0:11:56]</p><p>“If somebody is looking [to] grow in their career ladder, then it's not about one's own interest.” — Dr. Satyajit Wattamwar [0:24:07]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dr-satyajit-wattamwar-472a83b/">Dr. Satyajit Wattamwar on LinkedIn</a></p><p><a href="https://www.unilever.com">Unilever</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24091243" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/0114e758-44d0-4f93-8e96-0e31132fabc6/audio/3fe6db35-923b-4ed2-96bd-63fd5d4e02d6/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Unilever Head of Data Science Dr. Satyajit Wattamwar</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:05</itunes:duration>
      <itunes:summary>How can data science and AI drive sustainable innovation in a rapidly evolving world? In this episode, we speak with Dr. Satyajit Wattamwar, Data Science and Statistical Leader at Unilever, to explore how these technologies are shaping novel solutions. Unilever is a global leader in consumer goods committed to creating responsible, impactful products that improve lives. Leveraging cutting-edge research and development, the company addresses some of the world’s most pressing challenges, from reducing environmental impact to enhancing well-being. </itunes:summary>
      <itunes:subtitle>How can data science and AI drive sustainable innovation in a rapidly evolving world? In this episode, we speak with Dr. Satyajit Wattamwar, Data Science and Statistical Leader at Unilever, to explore how these technologies are shaping novel solutions. Unilever is a global leader in consumer goods committed to creating responsible, impactful products that improve lives. Leveraging cutting-edge research and development, the company addresses some of the world’s most pressing challenges, from reducing environmental impact to enhancing well-being. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>116</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">199119c4-67b0-485b-b168-0f3568205bd0</guid>
      <title>Vanguard Principal of Center for Analytics &amp; Insights Jing Wang</title>
      <description><![CDATA[<p>Jing explains how Vanguard uses machine learning and reinforcement learning to deliver personalized "nudges," helping investors make smarter financial decisions. Jing dives into the importance of aligning AI efforts with Vanguard’s mission and discusses generative AI’s potential for boosting employee productivity while improving customer experiences. She also reveals how generative AI is poised to play a key role in transforming the company's future, all while maintaining strict data privacy standards.</p><p>Key Points From This Episode:</p><ul><li>Jing Wang’s time at Fermilab and the research behind her PhD in high-energy physics.</li><li>What she misses most about academia and what led to her current role at Vanguard.</li><li>How she aligns her team’s AI strategy with Vanguard’s business goals.</li><li>Ways they are utilizing AI for nudging investors to make better decisions.</li><li>Their process for delivering highly personalized recommendations for any given investor.</li><li>Steps that ensure they adhere to finance industry regulations with their AI tools.</li><li>The role of reinforcement learning and their ‘next best action’ models in personalization.</li><li>Their approach to determining the best use of their datasets while protecting privacy.</li><li>Vanguard’s plans for generative AI, from internal productivity to serving clients.</li><li>How Jing stays abreast of all the latest developments in physics.</li></ul><p>Quotes:</p><p>“We make sure all our AI work is aligned with [Vanguard’s] four pillars to deliver business impact.” — Jing Wang [0:08:56]</p><p>“We found those simple nudges have tremendous power in terms of guiding the investors to adopt the right things. And this year, we started to use a machine learning model to actually personalize those nudges.” — Jing Wang [0:19:39]</p><p>“Ultimately, we see that generative AI could help us to build more differentiated products. – We want to have AI be able to train language models [to have] much more of a Vanguard mindset.” — Jing Wang [0:29:22]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/jing-wang-6a22b8/">Jing Wang on LinkedIn</a></p><p><a href="https://investor.vanguard.com/corporate-portal">Vanguard</a><br /><a href="https://www.fnal.gov/">Fermilab</a><br /><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Mon, 30 Dec 2024 15:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/vanguard-principal-of-center-for-analytics-insights-jing-wang-O4cfFuyj</link>
      <content:encoded><![CDATA[<p>Jing explains how Vanguard uses machine learning and reinforcement learning to deliver personalized "nudges," helping investors make smarter financial decisions. Jing dives into the importance of aligning AI efforts with Vanguard’s mission and discusses generative AI’s potential for boosting employee productivity while improving customer experiences. She also reveals how generative AI is poised to play a key role in transforming the company's future, all while maintaining strict data privacy standards.</p><p>Key Points From This Episode:</p><ul><li>Jing Wang’s time at Fermilab and the research behind her PhD in high-energy physics.</li><li>What she misses most about academia and what led to her current role at Vanguard.</li><li>How she aligns her team’s AI strategy with Vanguard’s business goals.</li><li>Ways they are utilizing AI for nudging investors to make better decisions.</li><li>Their process for delivering highly personalized recommendations for any given investor.</li><li>Steps that ensure they adhere to finance industry regulations with their AI tools.</li><li>The role of reinforcement learning and their ‘next best action’ models in personalization.</li><li>Their approach to determining the best use of their datasets while protecting privacy.</li><li>Vanguard’s plans for generative AI, from internal productivity to serving clients.</li><li>How Jing stays abreast of all the latest developments in physics.</li></ul><p>Quotes:</p><p>“We make sure all our AI work is aligned with [Vanguard’s] four pillars to deliver business impact.” — Jing Wang [0:08:56]</p><p>“We found those simple nudges have tremendous power in terms of guiding the investors to adopt the right things. And this year, we started to use a machine learning model to actually personalize those nudges.” — Jing Wang [0:19:39]</p><p>“Ultimately, we see that generative AI could help us to build more differentiated products. – We want to have AI be able to train language models [to have] much more of a Vanguard mindset.” — Jing Wang [0:29:22]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/jing-wang-6a22b8/">Jing Wang on LinkedIn</a></p><p><a href="https://investor.vanguard.com/corporate-portal">Vanguard</a><br /><a href="https://www.fnal.gov/">Fermilab</a><br /><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33754069" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/164ca716-90f5-4bdb-9ddc-a87986d83928/audio/b99d435d-c2d2-48b4-b963-b175289a39d5/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Vanguard Principal of Center for Analytics &amp; Insights Jing Wang</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:09</itunes:duration>
      <itunes:summary>Jing Wang, Principal and Head of the Center for Analytics and Insights at Vanguard, shares her fascinating journey from high-energy physics to leading AI initiatives that are reshaping investor outcomes for the better. </itunes:summary>
      <itunes:subtitle>Jing Wang, Principal and Head of the Center for Analytics and Insights at Vanguard, shares her fascinating journey from high-energy physics to leading AI initiatives that are reshaping investor outcomes for the better. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>115</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e956b0b5-6eaf-490c-9aa5-a8e0341754cf</guid>
      <title>Sema4 CTO Ram Venkatesh</title>
      <description><![CDATA[<p>Key Points From This Episode:</p><ul><li>Ram Venkatesh describes his career journey to founding Sema4.ai. </li><li>The pain points he was trying to ease with Sema4.ai.</li><li>How our general approach to big data is becoming more streamlined, albeit rather slowly. </li><li>The ins and outs of Sema4.ai and how it serves its clients. </li><li>What Ram means by “agent” and “agent agency” when referring to machine learning copilots.</li><li>The difference between writing a program to execute versus an agent reasoning with it.  </li><li>Understanding the contextual work training method for agents. </li><li>The relationship between an LLM and an agent and the risks of training LLMs on agent data.</li><li>Exploring the next generation of LLM training protocols in the hopes of improving efficiency. </li><li>The requirements of an LLM if you’re not training it and unpacking modality improvements. </li><li>Why agent input and feedback are major disruptions to SaaS and beyond. </li><li>Our guest shares his hopes for the future of AI. </li></ul><p>Quotes:</p><p>“I’ve spent the last 30 years in data. So, if there’s a database out there, whether it’s relational or object or XML or JSON, I’ve done something unspeakable to it at some point.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:01:46]</p><p>“As people are getting more experienced with how they could apply GenAI to solve their problems, then they’re realizing that they do need to organize their data and that data is really important.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:18:58]</p><p>“Following the technology and where it can go, there’s a lot of fun to be had with that.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:23:29]</p><p>“Now that we can see how software development itself is evolving, I think that 12-year-old me would’ve built so many more cooler things than I did with all the tech that’s out here now.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:29:14]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ram-venkatesh-34166/">Ram Venkatesh on LinkedIn</a></p><p><a href="https://x.com/ramvzz">Ram Venkatesh on X</a></p><p><a href="https://sema4.ai/">Sema4.ai</a></p><p><a href="https://www.cloudera.com/">Cloudera</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Mon, 23 Dec 2024 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/sema4-cto-ram-venkatesh-1w3y2SNV</link>
      <content:encoded><![CDATA[<p>Key Points From This Episode:</p><ul><li>Ram Venkatesh describes his career journey to founding Sema4.ai. </li><li>The pain points he was trying to ease with Sema4.ai.</li><li>How our general approach to big data is becoming more streamlined, albeit rather slowly. </li><li>The ins and outs of Sema4.ai and how it serves its clients. </li><li>What Ram means by “agent” and “agent agency” when referring to machine learning copilots.</li><li>The difference between writing a program to execute versus an agent reasoning with it.  </li><li>Understanding the contextual work training method for agents. </li><li>The relationship between an LLM and an agent and the risks of training LLMs on agent data.</li><li>Exploring the next generation of LLM training protocols in the hopes of improving efficiency. </li><li>The requirements of an LLM if you’re not training it and unpacking modality improvements. </li><li>Why agent input and feedback are major disruptions to SaaS and beyond. </li><li>Our guest shares his hopes for the future of AI. </li></ul><p>Quotes:</p><p>“I’ve spent the last 30 years in data. So, if there’s a database out there, whether it’s relational or object or XML or JSON, I’ve done something unspeakable to it at some point.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:01:46]</p><p>“As people are getting more experienced with how they could apply GenAI to solve their problems, then they’re realizing that they do need to organize their data and that data is really important.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:18:58]</p><p>“Following the technology and where it can go, there’s a lot of fun to be had with that.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:23:29]</p><p>“Now that we can see how software development itself is evolving, I think that 12-year-old me would’ve built so many more cooler things than I did with all the tech that’s out here now.” — <a href="https://x.com/ramvzz">@ramvzz</a> [0:29:14]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ram-venkatesh-34166/">Ram Venkatesh on LinkedIn</a></p><p><a href="https://x.com/ramvzz">Ram Venkatesh on X</a></p><p><a href="https://sema4.ai/">Sema4.ai</a></p><p><a href="https://www.cloudera.com/">Cloudera</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29085855" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/77184bc2-ab82-4566-9c07-6955c00b0f5a/audio/b6a7113e-196b-47f5-8354-441d009c8344/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Sema4 CTO Ram Venkatesh</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:17</itunes:duration>
      <itunes:summary>Today, we are joined by Ram Venkatesh, the founder of Sema4.ai – an enterprise AI agent platform that enables businesses to build, operate, and scale AI agents. Ram shares the risks of training LLMs from agent data, and the contextual work training protocol for agents. We also unpack the requirements of a large language model when you’re not responsible for training it, the various modalities and how they can be improved, the threat that agents pose to SaaS, and Ram’s vision of the future of AI. </itunes:summary>
      <itunes:subtitle>Today, we are joined by Ram Venkatesh, the founder of Sema4.ai – an enterprise AI agent platform that enables businesses to build, operate, and scale AI agents. Ram shares the risks of training LLMs from agent data, and the contextual work training protocol for agents. We also unpack the requirements of a large language model when you’re not responsible for training it, the various modalities and how they can be improved, the threat that agents pose to SaaS, and Ram’s vision of the future of AI. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>114</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">21de43b2-9b58-447d-9c1d-461e01c7f8b2</guid>
      <title>Unpacking Meta&apos;s SAM-2 with Sama Experts Pascal &amp; Yannick</title>
      <description><![CDATA[<p>Pascal & Yannick delve into the kind of human involvement SAM-2 needs before discussing the use cases it enables. Hear all about the importance of having realistic expectations of AI, what the cost of SAM-2 looks like, and the the importance of humans in LLMs.</p><p>Key Points From This Episode:</p><ul><li>Introducing Pascal Jauffret and Yannick Donnelly to the show.</li><li>Our guests explain what the SAM-2 model is. </li><li>A description of what getting information from video entails.</li><li>What made our guests interested in researching SAM-2. </li><li>A few things that stand out about this tool. </li><li>The level of human involvement that SAM-2 needs. </li><li>Some of the use cases they see SAM-2 enabling. </li><li>Whether manually annotating is easier than simply validating data. </li><li>The importance of setting realistic expectations of what AI can do. </li><li>When LLM models work best, according to our experts.</li><li>A discussion about the cost of the models at the moment. </li><li>Why humans are so important in coaching people to use models. </li><li>What we can expect from Sama in the near future. </li></ul><p>Quotes:</p><p>“We’re kind of shifting towards more of a validation period than just annotating from scratch.” — Yannick Donnelly [0:22:01]</p><p>“Models have their place but they need to be evaluated.” — Yannick Donnelly [0:25:16]</p><p>“You’re never just using a model for the sake of using a model. You’re trying to solve something and you’re trying to improve a business metric.” — Pascal Jauffret [0:32:59]</p><p>“We really shouldn’t underestimate the human aspect of using models.” — Pascal Jauffret [0:40:08]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jauffretpascal/">Pascal Jauffret on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/ydonnelly/">Yannick Donnelly on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 18 Dec 2024 21:04:01 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/unpacking-metas-sam-2-with-sama-experts-pascal-yannick-zHEFnljm</link>
      <content:encoded><![CDATA[<p>Pascal & Yannick delve into the kind of human involvement SAM-2 needs before discussing the use cases it enables. Hear all about the importance of having realistic expectations of AI, what the cost of SAM-2 looks like, and the the importance of humans in LLMs.</p><p>Key Points From This Episode:</p><ul><li>Introducing Pascal Jauffret and Yannick Donnelly to the show.</li><li>Our guests explain what the SAM-2 model is. </li><li>A description of what getting information from video entails.</li><li>What made our guests interested in researching SAM-2. </li><li>A few things that stand out about this tool. </li><li>The level of human involvement that SAM-2 needs. </li><li>Some of the use cases they see SAM-2 enabling. </li><li>Whether manually annotating is easier than simply validating data. </li><li>The importance of setting realistic expectations of what AI can do. </li><li>When LLM models work best, according to our experts.</li><li>A discussion about the cost of the models at the moment. </li><li>Why humans are so important in coaching people to use models. </li><li>What we can expect from Sama in the near future. </li></ul><p>Quotes:</p><p>“We’re kind of shifting towards more of a validation period than just annotating from scratch.” — Yannick Donnelly [0:22:01]</p><p>“Models have their place but they need to be evaluated.” — Yannick Donnelly [0:25:16]</p><p>“You’re never just using a model for the sake of using a model. You’re trying to solve something and you’re trying to improve a business metric.” — Pascal Jauffret [0:32:59]</p><p>“We really shouldn’t underestimate the human aspect of using models.” — Pascal Jauffret [0:40:08]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jauffretpascal/">Pascal Jauffret on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/ydonnelly/">Yannick Donnelly on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="47895272" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/aba7a9f7-2c82-4ad8-a079-18a8020552de/audio/4cf6c89e-370e-4bb7-b569-a029d8cdcf8f/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Unpacking Meta&apos;s SAM-2 with Sama Experts Pascal &amp; Yannick</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:49:53</itunes:duration>
      <itunes:summary>Fresh from Sama&apos;s AI Research Book Club are Solutions Engineer Yannick Donnelly and Sr. Applied Scientist Pascal Jauffret, who join the podcast to unpack the use cases, limitations, and implications of Meta&apos;s SAM-2.</itunes:summary>
      <itunes:subtitle>Fresh from Sama&apos;s AI Research Book Club are Solutions Engineer Yannick Donnelly and Sr. Applied Scientist Pascal Jauffret, who join the podcast to unpack the use cases, limitations, and implications of Meta&apos;s SAM-2.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>113</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e8b15e77-3d7d-4356-9ccd-769afed9d2a5</guid>
      <title>Qualcomm Senior Director Siddhika Nevrekar</title>
      <description><![CDATA[<p>Today we are joined by Siddhika Nevrekar, an experienced product leader passionate about solving complex problems in ML by bringing people and products together in an environment of trust.  We  unpack the state of free computing, the challenges of training AI models for edge, what Siddhika hopes to achieve in her role at Qualcomm, and her methods for solving common industry problems that developers face.</p><p>Key Points From This Episode:</p><ul><li>Siddhika Nevrekar walks us through her career pivot from cloud to edge computing. </li><li>Why she’s passionate about overcoming her fears and achieving the impossible. </li><li>Increasing compute on edge devices versus developing more efficient AI models.</li><li>Siddhika explains what makes Apple a truly unique company. </li><li>The original inspirations for edge computing and how the conversation has evolved. </li><li>Unpacking the current state of free computing and what may happen in the near future. </li><li>The challenges of training AI models for edge. </li><li>Exploring Siddhika’s role at Qualcomm and what she hopes to achieve. </li><li>Diving deeper into her process for achieving her goals. </li><li>Common industry challenges that developers are facing and her methods for solving them</li></ul><p>Quotes:</p><p>“Ultimately, we are constrained with the size of the device. It’s all physics. How much can you compress a small little chip to do what hundreds and thousands of chips can do which you can stack up in a cloud? Can you actually replicate that experience on the device?” — <a href="https://x.com/siddhika_">@siddhika_</a> </p><p>“By the time I left Apple, we had 1000-plus [AI] models running on devices and 10,000 applications that were powered by AI on the device, exclusively on the device. Which means the model is entirely on the device and is not going into the cloud. To me, that was the realization that now the moment has arrived where something magical is going to start happening with AI and ML.” — <a href="https://x.com/siddhika_">@siddhika_</a> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/siddhika/">Siddhika Nevrekar on LinkedIn</a></p><p><a href="https://x.com/siddhika_">Siddhika Nevrekar on X</a></p><p><a href="https://aihub.qualcomm.com/">Qualcomm AI Hub</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Mon, 16 Dec 2024 20:14:05 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/qualcomm-senior-director-siddhika-nevrekar-1myszbgP</link>
      <content:encoded><![CDATA[<p>Today we are joined by Siddhika Nevrekar, an experienced product leader passionate about solving complex problems in ML by bringing people and products together in an environment of trust.  We  unpack the state of free computing, the challenges of training AI models for edge, what Siddhika hopes to achieve in her role at Qualcomm, and her methods for solving common industry problems that developers face.</p><p>Key Points From This Episode:</p><ul><li>Siddhika Nevrekar walks us through her career pivot from cloud to edge computing. </li><li>Why she’s passionate about overcoming her fears and achieving the impossible. </li><li>Increasing compute on edge devices versus developing more efficient AI models.</li><li>Siddhika explains what makes Apple a truly unique company. </li><li>The original inspirations for edge computing and how the conversation has evolved. </li><li>Unpacking the current state of free computing and what may happen in the near future. </li><li>The challenges of training AI models for edge. </li><li>Exploring Siddhika’s role at Qualcomm and what she hopes to achieve. </li><li>Diving deeper into her process for achieving her goals. </li><li>Common industry challenges that developers are facing and her methods for solving them</li></ul><p>Quotes:</p><p>“Ultimately, we are constrained with the size of the device. It’s all physics. How much can you compress a small little chip to do what hundreds and thousands of chips can do which you can stack up in a cloud? Can you actually replicate that experience on the device?” — <a href="https://x.com/siddhika_">@siddhika_</a> </p><p>“By the time I left Apple, we had 1000-plus [AI] models running on devices and 10,000 applications that were powered by AI on the device, exclusively on the device. Which means the model is entirely on the device and is not going into the cloud. To me, that was the realization that now the moment has arrived where something magical is going to start happening with AI and ML.” — <a href="https://x.com/siddhika_">@siddhika_</a> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/siddhika/">Siddhika Nevrekar on LinkedIn</a></p><p><a href="https://x.com/siddhika_">Siddhika Nevrekar on X</a></p><p><a href="https://aihub.qualcomm.com/">Qualcomm AI Hub</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31640004" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/9f2d5895-dc1a-4bd5-a5bd-866b57d5db2d/audio/a98efb68-31ce-4122-ab71-7ae711c8772b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Qualcomm Senior Director Siddhika Nevrekar</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:57</itunes:duration>
      <itunes:summary>Siddhika worked on groundbreaking projects at Microsoft and Apple before co-founding Tetra AI Hub, later acquired by Qualcomm, where she now serves as the Senior Director of Project Management. Our guest explains why she switched focus from cloud to edge computing, why there’s a need to both increase compute on edge devices and develop more efficient AI models, and how the conversation around edge has evolved since the very first murmurs.</itunes:summary>
      <itunes:subtitle>Siddhika worked on groundbreaking projects at Microsoft and Apple before co-founding Tetra AI Hub, later acquired by Qualcomm, where she now serves as the Senior Director of Project Management. Our guest explains why she switched focus from cloud to edge computing, why there’s a need to both increase compute on edge devices and develop more efficient AI models, and how the conversation around edge has evolved since the very first murmurs.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>112</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">39682a39-dcfe-47d4-ac6e-76700d8b2145</guid>
      <title>Block Developer Advocate Rizel Scarlett</title>
      <description><![CDATA[<p>Today we are joined by Developer Advocate at Block, Rizel Scarlett, who is here to explain how to bridge the gap between the technical and non-technical aspects of a business. We also learn about AI hallucinations and how Rizel and Block approach this particular pain point, the burdens of responsibility of AI users, why it’s important to make AI tools accessible to all, and the ins and outs of G{Code} House – a learning community for Indigenous and women of color in tech. To end, Rizel explains what needs to be done to break down barriers to entry for the G{Code} population in tech, and she describes the ideal relationship between a developer advocate and the technical arm of a business. </p><p>Key Points From This Episode:</p><ul><li>Rizel Scarlett describes the role and responsibilities of a developer advocate. </li><li>Her role in getting others to understand how GitHub Copilot should be used. </li><li>Exploring her ongoing projects and current duties at Block. </li><li>How the conversation around AI copilot tools has shifted in the last 18 months.   </li><li>The importance of objection handling and why companies must pay more attention to it.  </li><li>AI hallucinations and Rizel’s advice for approaching this particular pain point. </li><li>Why “I don’t know” should be encouraged as a response from AI companions, not shunned. </li><li>Taking a closer look at how Block addresses AI hallucinations. </li><li>The burdens of responsibility of users of AI, and the need to democratize access to AI tools. </li><li>Unpacking G{Code} House and Rizel’s working relationship with this learning community.</li><li>Understanding what prevents Indigenous and women of color from having careers in tech.</li><li>The ideal relationship between a developer advocate and the technical arm of a business. </li></ul><p>Quotes:</p><p>“Every company is embedding AI into their product someway somehow, so it’s being more embraced.” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:11:37]</p><p>“I always respect someone that’s like, ‘I don’t know, but this is the closest I can get to it.’” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:15:25]</p><p>“With AI tools, when you’re more specific, the results are more refined.” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:16:29]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://blackgirlbytes.dev/">Rizel Scarlett</a></p><p><a href="https://www.linkedin.com/in/rizel-bobb-semple/">Rizel Scarlett on LinkedIn</a></p><p><a href="https://www.instagram.com/blackgirlbytes/">Rizel Scarlett on Instagram</a></p><p><a href="https://x.com/blackgirlbytes">Rizel Scarlett on X</a></p><p><a href="https://block.xyz/">Block</a></p><p><a href="https://block.github.io/goose/">Goose</a></p><p><a href="https://github.com/">GitHub</a></p><p><a href="https://github.com/features/copilot">GitHub Copilot</a></p><p><a href="https://thegcodehouse.com/">G{Code} House</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Tue, 3 Dec 2024 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/block-developer-advocate-rizel-scarlett-BqZlxkkm</link>
      <content:encoded><![CDATA[<p>Today we are joined by Developer Advocate at Block, Rizel Scarlett, who is here to explain how to bridge the gap between the technical and non-technical aspects of a business. We also learn about AI hallucinations and how Rizel and Block approach this particular pain point, the burdens of responsibility of AI users, why it’s important to make AI tools accessible to all, and the ins and outs of G{Code} House – a learning community for Indigenous and women of color in tech. To end, Rizel explains what needs to be done to break down barriers to entry for the G{Code} population in tech, and she describes the ideal relationship between a developer advocate and the technical arm of a business. </p><p>Key Points From This Episode:</p><ul><li>Rizel Scarlett describes the role and responsibilities of a developer advocate. </li><li>Her role in getting others to understand how GitHub Copilot should be used. </li><li>Exploring her ongoing projects and current duties at Block. </li><li>How the conversation around AI copilot tools has shifted in the last 18 months.   </li><li>The importance of objection handling and why companies must pay more attention to it.  </li><li>AI hallucinations and Rizel’s advice for approaching this particular pain point. </li><li>Why “I don’t know” should be encouraged as a response from AI companions, not shunned. </li><li>Taking a closer look at how Block addresses AI hallucinations. </li><li>The burdens of responsibility of users of AI, and the need to democratize access to AI tools. </li><li>Unpacking G{Code} House and Rizel’s working relationship with this learning community.</li><li>Understanding what prevents Indigenous and women of color from having careers in tech.</li><li>The ideal relationship between a developer advocate and the technical arm of a business. </li></ul><p>Quotes:</p><p>“Every company is embedding AI into their product someway somehow, so it’s being more embraced.” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:11:37]</p><p>“I always respect someone that’s like, ‘I don’t know, but this is the closest I can get to it.’” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:15:25]</p><p>“With AI tools, when you’re more specific, the results are more refined.” — <a href="https://x.com/blackgirlbytes">@blackgirlbytes</a> [0:16:29]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://blackgirlbytes.dev/">Rizel Scarlett</a></p><p><a href="https://www.linkedin.com/in/rizel-bobb-semple/">Rizel Scarlett on LinkedIn</a></p><p><a href="https://www.instagram.com/blackgirlbytes/">Rizel Scarlett on Instagram</a></p><p><a href="https://x.com/blackgirlbytes">Rizel Scarlett on X</a></p><p><a href="https://block.xyz/">Block</a></p><p><a href="https://block.github.io/goose/">Goose</a></p><p><a href="https://github.com/">GitHub</a></p><p><a href="https://github.com/features/copilot">GitHub Copilot</a></p><p><a href="https://thegcodehouse.com/">G{Code} House</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27049976" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/5faf3147-1df4-485b-bbda-364b2db58591/audio/e7620a00-f6ef-4e87-abb7-0fdc04d758fe/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Block Developer Advocate Rizel Scarlett</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:10</itunes:duration>
      <itunes:summary>Rizel describes how she helped others to understand how GitHub Copilot should be used, her duties and ongoing projects at Block, how the conversation around AI copilots has evolved in the last 18 months, and the importance of having a refined system for objection handling.</itunes:summary>
      <itunes:subtitle>Rizel describes how she helped others to understand how GitHub Copilot should be used, her duties and ongoing projects at Block, how the conversation around AI copilots has evolved in the last 18 months, and the importance of having a refined system for objection handling.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>111</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4edeaa6a-f7fe-41d4-9cdd-880b411bfb37</guid>
      <title>dbt Labs Co-Founder Drew Banin</title>
      <description><![CDATA[<p><br /><br />Key Points From This Episode:</p><ul><li>Drew and his co-founders’ background working together at RJ Metrics.</li><li>The lack of existing data solutions for Amazon Redshift and how they started dbt Labs.</li><li>Initial adoption of dbt Labs and why it was so well-received from the very beginning.</li><li>The concept of a semantic layer and how dbt Labs uses it in conjunction with LLMs.</li><li>Drew’s insights on a recent paper by Apple on the limitations of LLMs’ reasoning.</li><li>Unpacking examples where LLMs struggle with specific questions, like math problems.</li><li>The importance of thoughtful prompt engineering and application design with LLMs.</li><li>What is needed to maximize the utility of LLMs in enterprise settings.</li><li>How understanding the specific use case can help you get better results from LLMs.</li><li>What developers can do to constrain the search space and provide better output.</li><li>Why Drew believes prompt engineering will become less important for the average user.</li><li>The exciting potential of vector embeddings and the ongoing evolution of LLMs.</li></ul><p>Quotes:</p><p>“Our observation was [that] there needs to be some sort of way to prepare and curate data sets inside of a cloud data warehouse. And there was nothing out there that could do that on [Amazon] Redshift, so we set out to build it.” — Drew Banin [0:02:18]</p><p>“One of the things we're thinking a ton about today is how AI and the semantic layer intersect.” — Drew Banin [0:08:49]</p><p>“I don't fundamentally think that LLMs are reasoning in the way that human beings reason.” — Drew Banin [0:15:36]</p><p>“My belief is that prompt engineering will – become less important – over time for most use cases. I just think that there are enough people that are not well versed in this skill that the people building LLMs will work really hard to solve that problem.” — Drew Banin [0:23:06]</p><p>Links Mentioned in Today’s Episode:<br /> </p><p><a href="https://machinelearning.apple.com/research/gsm-symbolic">Understanding the Limitations of Mathematical Reasoning in Large Language Models</a><br /><br /><a href="https://www.linkedin.com/in/drewbanin/">Drew Banin on LinkedIn</a><br /><br /><a href="https://www.getdbt.com/">dbt Labs</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p><p> </p>
]]></description>
      <pubDate>Thu, 21 Nov 2024 20:47:47 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/dbt-labs-co-founder-drew-banin-44QePY4W</link>
      <content:encoded><![CDATA[<p><br /><br />Key Points From This Episode:</p><ul><li>Drew and his co-founders’ background working together at RJ Metrics.</li><li>The lack of existing data solutions for Amazon Redshift and how they started dbt Labs.</li><li>Initial adoption of dbt Labs and why it was so well-received from the very beginning.</li><li>The concept of a semantic layer and how dbt Labs uses it in conjunction with LLMs.</li><li>Drew’s insights on a recent paper by Apple on the limitations of LLMs’ reasoning.</li><li>Unpacking examples where LLMs struggle with specific questions, like math problems.</li><li>The importance of thoughtful prompt engineering and application design with LLMs.</li><li>What is needed to maximize the utility of LLMs in enterprise settings.</li><li>How understanding the specific use case can help you get better results from LLMs.</li><li>What developers can do to constrain the search space and provide better output.</li><li>Why Drew believes prompt engineering will become less important for the average user.</li><li>The exciting potential of vector embeddings and the ongoing evolution of LLMs.</li></ul><p>Quotes:</p><p>“Our observation was [that] there needs to be some sort of way to prepare and curate data sets inside of a cloud data warehouse. And there was nothing out there that could do that on [Amazon] Redshift, so we set out to build it.” — Drew Banin [0:02:18]</p><p>“One of the things we're thinking a ton about today is how AI and the semantic layer intersect.” — Drew Banin [0:08:49]</p><p>“I don't fundamentally think that LLMs are reasoning in the way that human beings reason.” — Drew Banin [0:15:36]</p><p>“My belief is that prompt engineering will – become less important – over time for most use cases. I just think that there are enough people that are not well versed in this skill that the people building LLMs will work really hard to solve that problem.” — Drew Banin [0:23:06]</p><p>Links Mentioned in Today’s Episode:<br /> </p><p><a href="https://machinelearning.apple.com/research/gsm-symbolic">Understanding the Limitations of Mathematical Reasoning in Large Language Models</a><br /><br /><a href="https://www.linkedin.com/in/drewbanin/">Drew Banin on LinkedIn</a><br /><br /><a href="https://www.getdbt.com/">dbt Labs</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p><p> </p>
]]></content:encoded>
      <enclosure length="26921663" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/1a0d3b27-60da-49c5-b986-53a28727a42d/audio/d8e5a526-e902-4954-bcf9-3b92fd779b55/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>dbt Labs Co-Founder Drew Banin</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:02</itunes:duration>
      <itunes:summary>Drew details the emergence of cloud data warehouses and the rapid adoption that followed,  unpacks the practical uses of LLMs , and demystifies some of their reasoning-based limitations. He also sheds light on vector embeddings, their transformative potential, and what’s next for this dynamic space.  </itunes:summary>
      <itunes:subtitle>Drew details the emergence of cloud data warehouses and the rapid adoption that followed,  unpacks the practical uses of LLMs , and demystifies some of their reasoning-based limitations. He also sheds light on vector embeddings, their transformative potential, and what’s next for this dynamic space.  </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>110</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">c77416f9-f548-4b73-ac36-ed8d6d6e379a</guid>
      <title>Saidot CEO Meeri Haataja</title>
      <description><![CDATA[<p>In this episode, you’ll hear about Meeri's incredible career, insights from the recent AI Pact conference she attended, her company's involvement, and how we can articulate the reality of holding companies accountable to AI governance practices. We discuss how to know if you have an AI problem, what makes third-party generative AI more risky, and so much more! Meeri even shares how she thinks the Use AI Act will impact AI companies and what companies can do to take stock of their risk factors and ensure that they are building responsibly. You don’t want to miss this one, so be sure to tune in now!</p><p>Key Points From This Episode:</p><ul><li>Insights from the AI Pact conference. </li><li>The reality of holding AI companies accountable. </li><li>What inspired her to start Saidot to offer solutions for AI transparency and accountability.</li><li>How Meeri assesses companies and their organizational culture. </li><li>What makes generative AI more risky than other forms of machine learning. </li><li>Reasons that use-related risks are the most common sources of AI risks.</li><li>Meeri’s thoughts on the impact of the Use AI Act in the EU. </li></ul><p>Quotes:</p><p>“It’s best to work with companies who know that they already have a problem.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:09:58]</p><p>“Third-party risks are way bigger in the context of [generative AI].” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:14:22]</p><p>“Use and use-context-related risks are the major source of risks.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:17:56]</p><p>“Risk is fine if it’s on an acceptable level. That’s what governance seeks to do.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:21:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.saidot.ai/">Saidot</a></p><p><a href="https://www.linkedin.com/in/meerihaataja/">Meeri Haataja on LinkedIn</a></p><p><a href="https://www.instagram.com/meerihaataja/">Meeri Haataja on Instagram</a></p><p><a href="https://x.com/meerihaataja">Meeri Haataja on X</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 31 Oct 2024 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/saidot-ceo-meeri-haataja-B4V9HEAZ</link>
      <content:encoded><![CDATA[<p>In this episode, you’ll hear about Meeri's incredible career, insights from the recent AI Pact conference she attended, her company's involvement, and how we can articulate the reality of holding companies accountable to AI governance practices. We discuss how to know if you have an AI problem, what makes third-party generative AI more risky, and so much more! Meeri even shares how she thinks the Use AI Act will impact AI companies and what companies can do to take stock of their risk factors and ensure that they are building responsibly. You don’t want to miss this one, so be sure to tune in now!</p><p>Key Points From This Episode:</p><ul><li>Insights from the AI Pact conference. </li><li>The reality of holding AI companies accountable. </li><li>What inspired her to start Saidot to offer solutions for AI transparency and accountability.</li><li>How Meeri assesses companies and their organizational culture. </li><li>What makes generative AI more risky than other forms of machine learning. </li><li>Reasons that use-related risks are the most common sources of AI risks.</li><li>Meeri’s thoughts on the impact of the Use AI Act in the EU. </li></ul><p>Quotes:</p><p>“It’s best to work with companies who know that they already have a problem.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:09:58]</p><p>“Third-party risks are way bigger in the context of [generative AI].” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:14:22]</p><p>“Use and use-context-related risks are the major source of risks.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:17:56]</p><p>“Risk is fine if it’s on an acceptable level. That’s what governance seeks to do.” — <a href="https://x.com/meerihaataja">@meerihaataja</a> [0:21:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.saidot.ai/">Saidot</a></p><p><a href="https://www.linkedin.com/in/meerihaataja/">Meeri Haataja on LinkedIn</a></p><p><a href="https://www.instagram.com/meerihaataja/">Meeri Haataja on Instagram</a></p><p><a href="https://x.com/meerihaataja">Meeri Haataja on X</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24293953" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/a139ec3b-1668-4873-b99f-a3c332ba6d07/audio/8afdf3b9-3fb0-4e4d-a6ef-8f3f33059cf1/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Saidot CEO Meeri Haataja</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:18</itunes:duration>
      <itunes:summary>There will always be a certain level of risk associated with building AI models, but it is the responsibility of the creators to minimize those risks and ensure sustainable development. Today, we are joined by Meeri Haataja, the Founder of AI governance platform Saidot, to discuss all things responsible AI-building and risk mitigation. </itunes:summary>
      <itunes:subtitle>There will always be a certain level of risk associated with building AI models, but it is the responsibility of the creators to minimize those risks and ensure sustainable development. Today, we are joined by Meeri Haataja, the Founder of AI governance platform Saidot, to discuss all things responsible AI-building and risk mitigation. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>109</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">83b2fc6e-0c10-4df7-b9c0-96186a989145</guid>
      <title>FICO Chief Analytics Officer Dr. Scott Zoldi</title>
      <description><![CDATA[<p>In this episode, Dr. Zoldi offers insight into the transformative potential of blockchain for ensuring transparency in AI development, the critical need for explainability over mere predictive power, and how FICO maintains trust in its AI systems through rigorous model development standards. We also delve into the essential integration of data science and software engineering teams, emphasizing that collaboration from the outset is key to operationalizing AI effectively. </p><p><br /><strong>Key Points From This Episode:</strong></p><ul><li>How Scott integrates his role as an inventor with his duties as FICO CAO.</li><li>Why he believes that mindshare is an essential leadership quality.</li><li>What sparked his interest in responsible AI as a physicist.</li><li>The shifting demographics of those who develop machine learning models.</li><li>Insight into the use of blockchain to advance responsible AI.</li><li>How FICO uses blockchain to ensure auditable ML decision-making.</li><li>Operationalizing AI and the typical mistakes companies make in the process.</li><li>The value of integrating data science and software engineering teams from the start.</li><li>A fear-free perspective on what Scott finds so uniquely exciting about AI.</li></ul><p><strong>Quotes:</strong></p><p>“I have to stay ahead of where the industry is moving and plot out the directions for FICO in terms of where AI and machine learning is going – [Being an inventor is critical for] being effective as a chief analytics officer.” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:01:53]</p><p>“[AI and machine learning] is software like any other type of software. It's just software that learns by itself and, therefore, we need [stricter] levels of control.” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:23:59]</p><p>“Data scientists and AI scientists need to have partners in software engineering. That's probably the number one reason why [companies fail during the operationalization process].” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:29:02]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.fico.com/" target="_blank">FICO</a></p><p><a href="https://www.fico.com/blogs/author/scott-zoldi" target="_blank">Dr. Scott Zoldi</a></p><p><a href="https://www.linkedin.com/in/scottzoldi/" target="_blank">Dr. Scott Zoldi on LinkedIn</a></p><p><a href="https://x.com/ScottZoldi" target="_blank">Dr. Scott Zoldi on X</a></p><p><a href="https://www.fico.com/en/products/fico-falcon-fraud-manager" target="_blank">FICO Falcon Fraud Manager</a></p><p><a href="https://www.howaihappens.com/" target="_blank">How AI Happens</a></p><p><a href="https://www.sama.com/" target="_blank">Sama</a></p>
]]></description>
      <pubDate>Fri, 18 Oct 2024 17:33:48 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/fico-chief-analytics-officer-dr-scott-zoldi-FlWrGYy8</link>
      <content:encoded><![CDATA[<p>In this episode, Dr. Zoldi offers insight into the transformative potential of blockchain for ensuring transparency in AI development, the critical need for explainability over mere predictive power, and how FICO maintains trust in its AI systems through rigorous model development standards. We also delve into the essential integration of data science and software engineering teams, emphasizing that collaboration from the outset is key to operationalizing AI effectively. </p><p><br /><strong>Key Points From This Episode:</strong></p><ul><li>How Scott integrates his role as an inventor with his duties as FICO CAO.</li><li>Why he believes that mindshare is an essential leadership quality.</li><li>What sparked his interest in responsible AI as a physicist.</li><li>The shifting demographics of those who develop machine learning models.</li><li>Insight into the use of blockchain to advance responsible AI.</li><li>How FICO uses blockchain to ensure auditable ML decision-making.</li><li>Operationalizing AI and the typical mistakes companies make in the process.</li><li>The value of integrating data science and software engineering teams from the start.</li><li>A fear-free perspective on what Scott finds so uniquely exciting about AI.</li></ul><p><strong>Quotes:</strong></p><p>“I have to stay ahead of where the industry is moving and plot out the directions for FICO in terms of where AI and machine learning is going – [Being an inventor is critical for] being effective as a chief analytics officer.” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:01:53]</p><p>“[AI and machine learning] is software like any other type of software. It's just software that learns by itself and, therefore, we need [stricter] levels of control.” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:23:59]</p><p>“Data scientists and AI scientists need to have partners in software engineering. That's probably the number one reason why [companies fail during the operationalization process].” — <a href="https://x.com/ScottZoldi" target="_blank">@ScottZoldi</a> [0:29:02]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.fico.com/" target="_blank">FICO</a></p><p><a href="https://www.fico.com/blogs/author/scott-zoldi" target="_blank">Dr. Scott Zoldi</a></p><p><a href="https://www.linkedin.com/in/scottzoldi/" target="_blank">Dr. Scott Zoldi on LinkedIn</a></p><p><a href="https://x.com/ScottZoldi" target="_blank">Dr. Scott Zoldi on X</a></p><p><a href="https://www.fico.com/en/products/fico-falcon-fraud-manager" target="_blank">FICO Falcon Fraud Manager</a></p><p><a href="https://www.howaihappens.com/" target="_blank">How AI Happens</a></p><p><a href="https://www.sama.com/" target="_blank">Sama</a></p>
]]></content:encoded>
      <enclosure length="32319215" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/c881f963-bd39-4e1c-9157-9c5462cf92dd/audio/7f85e400-dced-4f8a-a669-b4e0c15329e7/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>FICO Chief Analytics Officer Dr. Scott Zoldi</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:39</itunes:duration>
      <itunes:summary> Today, we&apos;re joined by Dr. Scott Zoldi, Chief Analytics Officer at FICO, a global analytics software company that empowers businesses to improve customer experiences, lower risks, and operate more efficiently through its FICO Platform. Dr. Zoldi is also a named inventor on over 130 active and pending patents, including a recent breakthrough in using blockchain for auditable machine learning decision-making.His research and work have earned him a spot as one of American Banker’s 2024 Innovators of the Year. </itunes:summary>
      <itunes:subtitle> Today, we&apos;re joined by Dr. Scott Zoldi, Chief Analytics Officer at FICO, a global analytics software company that empowers businesses to improve customer experiences, lower risks, and operate more efficiently through its FICO Platform. Dr. Zoldi is also a named inventor on over 130 active and pending patents, including a recent breakthrough in using blockchain for auditable machine learning decision-making.His research and work have earned him a spot as one of American Banker’s 2024 Innovators of the Year. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>108</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">6fc3f751-6218-4bfc-8a8f-504a40a585ca</guid>
      <title>Lemurian Labs CEO Jay Dawani</title>
      <description><![CDATA[<p>Jay breaks down the critical role of software optimizations and how they drive performance gains in AI, highlighting the importance of reducing inefficiencies in hardware. He also discusses the long-term vision for Lemurian Labs and the broader future of AI, pointing to the potential breakthroughs that could redefine industries and accelerate innovation, plus a whole lot more. </p><p>Key Points From This Episode:</p><ul><li>Jay’s diverse professional background and his attraction to solving unsolvable problems.</li><li>How his unfinished business in robotics led him to his current work at Lemurian Labs.</li><li>What he has learned from being CEO and the biggest obstacles he has had to overcome.</li><li>Why he believes engineers with a problem-solving mindset can be effective CEOs.</li><li>Lemurian Labs: making AI computing more efficient, affordable, and environmentally friendly.</li><li>The critical role of software in increasing AI efficiency.</li><li>Some of the biggest challenges in programming GPUs.</li><li>Why better software is needed to optimize the use of hardware.</li><li>Common inefficiencies in AI development and how to solve them.</li><li>Reflections on the future of Lemurian Labs and AI more broadly.</li></ul><p>Quotes:</p><p>“Every single problem I've tried to pick up has been one that – most people have considered as being almost impossible. There’s something appealing about that.” — Jay Dawani [0:02:58]</p><p>“No matter how good of an idea you put out into the world, most people don't have the motivation to go and solve it. You have to have an insane amount of belief and optimism that this problem is solvable, regardless of how much time it's going to take.” — Jay Dawani [0:07:14]</p><p>“If the world's just betting on one company, then the amount of compute you can have available is pretty limited. But if there's a lot of different kinds of compute that are slightly optimized with different resources, making them accessible allows us to get there faster.” — Jay Dawani [0:19:36]</p><p>“Basically what we're trying to do [at Lemurian Labs] is make it easy for programmers to get [the best] performance out of any hardware.” — Jay Dawani [0:20:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jaydawani/">Jay Dawani on LinkedIn</a></p><p><a href="https://www.lemurianlabs.com/">Lemurian Labs</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 10 Oct 2024 17:06:24 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/lemurian-labs-ceo-jay-dawani-V0ZqhWRd</link>
      <content:encoded><![CDATA[<p>Jay breaks down the critical role of software optimizations and how they drive performance gains in AI, highlighting the importance of reducing inefficiencies in hardware. He also discusses the long-term vision for Lemurian Labs and the broader future of AI, pointing to the potential breakthroughs that could redefine industries and accelerate innovation, plus a whole lot more. </p><p>Key Points From This Episode:</p><ul><li>Jay’s diverse professional background and his attraction to solving unsolvable problems.</li><li>How his unfinished business in robotics led him to his current work at Lemurian Labs.</li><li>What he has learned from being CEO and the biggest obstacles he has had to overcome.</li><li>Why he believes engineers with a problem-solving mindset can be effective CEOs.</li><li>Lemurian Labs: making AI computing more efficient, affordable, and environmentally friendly.</li><li>The critical role of software in increasing AI efficiency.</li><li>Some of the biggest challenges in programming GPUs.</li><li>Why better software is needed to optimize the use of hardware.</li><li>Common inefficiencies in AI development and how to solve them.</li><li>Reflections on the future of Lemurian Labs and AI more broadly.</li></ul><p>Quotes:</p><p>“Every single problem I've tried to pick up has been one that – most people have considered as being almost impossible. There’s something appealing about that.” — Jay Dawani [0:02:58]</p><p>“No matter how good of an idea you put out into the world, most people don't have the motivation to go and solve it. You have to have an insane amount of belief and optimism that this problem is solvable, regardless of how much time it's going to take.” — Jay Dawani [0:07:14]</p><p>“If the world's just betting on one company, then the amount of compute you can have available is pretty limited. But if there's a lot of different kinds of compute that are slightly optimized with different resources, making them accessible allows us to get there faster.” — Jay Dawani [0:19:36]</p><p>“Basically what we're trying to do [at Lemurian Labs] is make it easy for programmers to get [the best] performance out of any hardware.” — Jay Dawani [0:20:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jaydawani/">Jay Dawani on LinkedIn</a></p><p><a href="https://www.lemurianlabs.com/">Lemurian Labs</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28278804" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/857f6c7c-d3b8-4b63-8793-1e0591af3f9a/audio/46538a62-9704-4642-8a5c-8ff55702d7c7/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Lemurian Labs CEO Jay Dawani</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:27</itunes:duration>
      <itunes:summary>The future of AI depends on overcoming its biggest challenges, chief among them being hardware limitations. Joining us today is Jay Dawani, Founder and CEO of Lemurian Labs, to share how his company is addressing this central issue by building a platform designed to make AI development more efficient, affordable, and environmentally friendly.</itunes:summary>
      <itunes:subtitle>The future of AI depends on overcoming its biggest challenges, chief among them being hardware limitations. Joining us today is Jay Dawani, Founder and CEO of Lemurian Labs, to share how his company is addressing this central issue by building a platform designed to make AI development more efficient, affordable, and environmentally friendly.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>107</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e3a47261-c1f8-4b26-b08d-7795ba766521</guid>
      <title>Intel VP &amp; GM of Strategy &amp; Execution Melissa Evers</title>
      <description><![CDATA[<p>Melissa explains the importance of giving developers the choice of working with open source or proprietary options, experimenting with flexible application models, and choosing the size of your model according to the use case you have in mind. Discussing the democratization of technology, we explore common challenges in the context of AI including the potential of generative AI versus the challenge of its implementation, where true innovation lies, and what Melissa is most excited about seeing in the future.</p><p>Key Points From This Episode:</p><ul><li>An introduction to Melissa Evers, Vice President and General Manager of Strategy and Execution at Intel Corporation.</li><li>More on the communities she has played a leadership role in.</li><li>Why open source governance is not an oxymoron and why it is critical.</li><li>The hard work that goes on behind the scenes at open source.</li><li>What to strive for when building a healthy open source community.</li><li>Intel’s perspective on the importance of open source and open AI.</li><li>Enabling developer choices about open source or proprietary options.</li><li>Growing awareness around building architecture around the freedom of choice.</li><li>Identifying that a model is a bad choice or lacking in accuracy.</li><li>Thinking critically about future-proofing yourself with regard to model choice. </li><li>Opportunities for large and smaller models.</li><li>Finding the perfect intersection between value delivery, value creation, and cost. </li><li>Common challenges in the context of AI, including the potential of generative AI and its implementation.</li><li>Why there is such a commonality of use cases in the realm of generative AI.</li><li>Where true innovation and value lies even though there may be commonality in use cases.</li><li>Examples of creative uses of generative AI; retail, compound AI systems, manufacturing, and more.</li><li>Understanding that innovation in this area is still in its early development stages. </li><li>How Wardley Mapping can support an understanding of scale. </li><li>What she is most excited about for the future of AI: Rapid learning in healthcare. </li></ul><p>Quotes:</p><p>“One of the things that is true about software in general is that the role that open source plays within the ecosystem has dramatically shifted and accelerated technology development at large.” — <a href="https://x.com/melisevers">@melisevers</a> [0:03:02]</p><p>“It’s important for all citizens of the open source community, corporate or not, to understand and own their responsibilities with regard to the hard work of driving the technology forward.” — <a href="https://x.com/melisevers">@melisevers</a> [0:05:18]</p><p>“We believe that innovation is best served when folks have the tools at their disposal on which to innovate.” — <a href="https://x.com/melisevers">@melisevers</a> [0:09:38]</p><p>“I think the focus for open source broadly should be on the elements that are going to be commodified.” — <a href="https://x.com/melisevers">@melisevers</a> [0:25:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/melissaevers/">Melissa Evers on LinkedIn</a></p><p><a href="https://x.com/melisevers">Melissa Evers on X</a></p><p><a href="https://www.intel.com/">Intel Corporation</a></p><p> </p>
]]></description>
      <pubDate>Mon, 30 Sep 2024 20:31:26 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/intel-vp-gm-of-strategy-execution-melissa-evers-5ebvpgC_</link>
      <content:encoded><![CDATA[<p>Melissa explains the importance of giving developers the choice of working with open source or proprietary options, experimenting with flexible application models, and choosing the size of your model according to the use case you have in mind. Discussing the democratization of technology, we explore common challenges in the context of AI including the potential of generative AI versus the challenge of its implementation, where true innovation lies, and what Melissa is most excited about seeing in the future.</p><p>Key Points From This Episode:</p><ul><li>An introduction to Melissa Evers, Vice President and General Manager of Strategy and Execution at Intel Corporation.</li><li>More on the communities she has played a leadership role in.</li><li>Why open source governance is not an oxymoron and why it is critical.</li><li>The hard work that goes on behind the scenes at open source.</li><li>What to strive for when building a healthy open source community.</li><li>Intel’s perspective on the importance of open source and open AI.</li><li>Enabling developer choices about open source or proprietary options.</li><li>Growing awareness around building architecture around the freedom of choice.</li><li>Identifying that a model is a bad choice or lacking in accuracy.</li><li>Thinking critically about future-proofing yourself with regard to model choice. </li><li>Opportunities for large and smaller models.</li><li>Finding the perfect intersection between value delivery, value creation, and cost. </li><li>Common challenges in the context of AI, including the potential of generative AI and its implementation.</li><li>Why there is such a commonality of use cases in the realm of generative AI.</li><li>Where true innovation and value lies even though there may be commonality in use cases.</li><li>Examples of creative uses of generative AI; retail, compound AI systems, manufacturing, and more.</li><li>Understanding that innovation in this area is still in its early development stages. </li><li>How Wardley Mapping can support an understanding of scale. </li><li>What she is most excited about for the future of AI: Rapid learning in healthcare. </li></ul><p>Quotes:</p><p>“One of the things that is true about software in general is that the role that open source plays within the ecosystem has dramatically shifted and accelerated technology development at large.” — <a href="https://x.com/melisevers">@melisevers</a> [0:03:02]</p><p>“It’s important for all citizens of the open source community, corporate or not, to understand and own their responsibilities with regard to the hard work of driving the technology forward.” — <a href="https://x.com/melisevers">@melisevers</a> [0:05:18]</p><p>“We believe that innovation is best served when folks have the tools at their disposal on which to innovate.” — <a href="https://x.com/melisevers">@melisevers</a> [0:09:38]</p><p>“I think the focus for open source broadly should be on the elements that are going to be commodified.” — <a href="https://x.com/melisevers">@melisevers</a> [0:25:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/melissaevers/">Melissa Evers on LinkedIn</a></p><p><a href="https://x.com/melisevers">Melissa Evers on X</a></p><p><a href="https://www.intel.com/">Intel Corporation</a></p><p> </p>
]]></content:encoded>
      <enclosure length="33616143" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8c6c649e-d1ab-4034-b63b-780dfe2eb0f0/audio/73467075-fc9c-4ca9-800b-19da46288c1c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Intel VP &amp; GM of Strategy &amp; Execution Melissa Evers</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:00</itunes:duration>
      <itunes:summary>Melissa shares the factors that determine whether an open-source community is healthy, speaks to Intel’s philosophy on innovation and open AI. </itunes:summary>
      <itunes:subtitle>Melissa shares the factors that determine whether an open-source community is healthy, speaks to Intel’s philosophy on innovation and open AI. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>106</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">1962c280-79ff-4e1d-861d-082da1e5a05c</guid>
      <title>Synopsys VP of AI Thomas Andersen</title>
      <description><![CDATA[<p> VP of AI and ML at Synopsys, Thomas Andersen joins us to discuss designing AI chips. Tuning in, you’ll hear all about our guest’s illustrious career, how he became interested in technology, tech in East Germany, what it was like growing up there, and so much more! We delve into his company, Synopsys, and the chips they build before discussing his role in building algorithms. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to today’s guest, Thomas Andersen. </li><li>How he got into the tech world and his experience growing up in East Germany. </li><li>The cost of Compute AI coming down at the same time the demand is going up. </li><li>Thomas tells us about Synopsys and what goes into building their chips. </li><li>Other traditional software companies that are now designing their own AI chips. </li><li>What Thomas’ role looks like in machine learning and building AI algorithms. </li><li>How the constantly changing rules of AI chip design continue to create new obstacles. </li><li>Thomas tells us how they use reinforcement learning in their processes.</li><li>The different applications for generative AI and why it needs good input data.  </li><li>Thomas’ advice for anyone wanting to get into the world of AI. </li></ul><p>Quotes:</p><p>“It’s not really the technology that makes life great, it’s how you use it, and what you make of it.” — Thomas Andersen [0:07:31]</p><p>“There is, of course, a lot of opportunities to use AI in chip design.” — Thomas Andersen [0:25:39]</p><p>“Be bold, try as many new things [as you can, and] make sure you use the right approach for the right tasks.” — Thomas Andersen [0:40:09]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/kutzsche/">Thomas Andersen on LinkedIn</a></p><p><a href="https://www.synopsys.com/">Synopsys</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 27 Sep 2024 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/synopsys-vp-of-ai-thomas-andersen-XQvbrHkc</link>
      <content:encoded><![CDATA[<p> VP of AI and ML at Synopsys, Thomas Andersen joins us to discuss designing AI chips. Tuning in, you’ll hear all about our guest’s illustrious career, how he became interested in technology, tech in East Germany, what it was like growing up there, and so much more! We delve into his company, Synopsys, and the chips they build before discussing his role in building algorithms. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to today’s guest, Thomas Andersen. </li><li>How he got into the tech world and his experience growing up in East Germany. </li><li>The cost of Compute AI coming down at the same time the demand is going up. </li><li>Thomas tells us about Synopsys and what goes into building their chips. </li><li>Other traditional software companies that are now designing their own AI chips. </li><li>What Thomas’ role looks like in machine learning and building AI algorithms. </li><li>How the constantly changing rules of AI chip design continue to create new obstacles. </li><li>Thomas tells us how they use reinforcement learning in their processes.</li><li>The different applications for generative AI and why it needs good input data.  </li><li>Thomas’ advice for anyone wanting to get into the world of AI. </li></ul><p>Quotes:</p><p>“It’s not really the technology that makes life great, it’s how you use it, and what you make of it.” — Thomas Andersen [0:07:31]</p><p>“There is, of course, a lot of opportunities to use AI in chip design.” — Thomas Andersen [0:25:39]</p><p>“Be bold, try as many new things [as you can, and] make sure you use the right approach for the right tasks.” — Thomas Andersen [0:40:09]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/kutzsche/">Thomas Andersen on LinkedIn</a></p><p><a href="https://www.synopsys.com/">Synopsys</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="39878007" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/6fc05fcd-cb7e-475e-bb7c-b4b65c10d991/audio/b5b2d384-c419-4004-9e21-ffd9f7619594/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Synopsys VP of AI Thomas Andersen</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:41:32</itunes:duration>
      <itunes:summary>Thomas tells us all about reinforcement learning, their constant process of learning and reinvention, and the power of generative AI (with good data). Finally, Thomas shares some words of wisdom for anyone looking to forge a career in the world of AI. </itunes:summary>
      <itunes:subtitle>Thomas tells us all about reinforcement learning, their constant process of learning and reinvention, and the power of generative AI (with good data). Finally, Thomas shares some words of wisdom for anyone looking to forge a career in the world of AI. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>105</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">5b22ebbe-8224-4314-ab76-bcbad34840a2</guid>
      <title>Xactly SVP Engineering Kandarp Desai</title>
      <description><![CDATA[<p>Developing AI and generative AI initiatives demands significant investment, and without delivering on customer satisfaction, these costs can be tough to justify. Today, SVP of Engineering and General Manager of Xactly India, Kandarp Desai joins us to discuss Xactly's AI initiatives and why customer satisfaction remains their top priority. <br />Key Points From This Episode:</p><ul><li>An introduction to Kandarp and his transition from hardware to software.</li><li>How he became SVP of Engineering and General Manager of Xactly India.</li><li>His move to Bangalore and the expansion of Xactly’s presence in India.</li><li>The rapid modernization of India as a key factor in Xactly’s growth strategy.</li><li>An overview of Xactly’s AI and generative AI initiatives.</li><li>Insight into the development of Xactly’s AI Copilot.</li><li>Four key stakeholders served by the Xactly AI Copilot.</li><li>The Xactly Extend, an enterprise platform for building custom apps.</li><li>Challenges in justifying the ROI of AI initiatives.</li><li>Why customer satisfaction and business outcomes are essential.</li><li>How AI is overhyped in the short term and underhyped in the long term.</li><li>The difficulties in quantifying the value of AI.</li><li>Kandarp’s career advice to AI practitioners, from taking risks to networking.</li></ul><p>Quotes:</p><p>“[Generative AI] is only useful if it drives higher customer satisfaction. Otherwise, it doesn't matter.” — Kandarp Desai [0:11:36]</p><p>“Justifying the ROI of anything is hard – If you can tie any new invention back to its ROI in customer satisfaction, that can drive an easy sell across an organization.” — Kandarp Desai [0:15:35]</p><p>“The whole AI trend is overhyped in the short term and underhyped long term. [It’s experienced an] oversell recently, and people are still trying to figure it out.” — Kandarp Desai [0:20:48]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/kandarpdesai/">Kandarp Desai on LinkedIn</a></p><p><a href="https://www.xactlycorp.com/">Xactly</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Tue, 24 Sep 2024 20:51:01 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/xactly-svp-engineering-kandarp-desai-4gXdto_k</link>
      <content:encoded><![CDATA[<p>Developing AI and generative AI initiatives demands significant investment, and without delivering on customer satisfaction, these costs can be tough to justify. Today, SVP of Engineering and General Manager of Xactly India, Kandarp Desai joins us to discuss Xactly's AI initiatives and why customer satisfaction remains their top priority. <br />Key Points From This Episode:</p><ul><li>An introduction to Kandarp and his transition from hardware to software.</li><li>How he became SVP of Engineering and General Manager of Xactly India.</li><li>His move to Bangalore and the expansion of Xactly’s presence in India.</li><li>The rapid modernization of India as a key factor in Xactly’s growth strategy.</li><li>An overview of Xactly’s AI and generative AI initiatives.</li><li>Insight into the development of Xactly’s AI Copilot.</li><li>Four key stakeholders served by the Xactly AI Copilot.</li><li>The Xactly Extend, an enterprise platform for building custom apps.</li><li>Challenges in justifying the ROI of AI initiatives.</li><li>Why customer satisfaction and business outcomes are essential.</li><li>How AI is overhyped in the short term and underhyped in the long term.</li><li>The difficulties in quantifying the value of AI.</li><li>Kandarp’s career advice to AI practitioners, from taking risks to networking.</li></ul><p>Quotes:</p><p>“[Generative AI] is only useful if it drives higher customer satisfaction. Otherwise, it doesn't matter.” — Kandarp Desai [0:11:36]</p><p>“Justifying the ROI of anything is hard – If you can tie any new invention back to its ROI in customer satisfaction, that can drive an easy sell across an organization.” — Kandarp Desai [0:15:35]</p><p>“The whole AI trend is overhyped in the short term and underhyped long term. [It’s experienced an] oversell recently, and people are still trying to figure it out.” — Kandarp Desai [0:20:48]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/kandarpdesai/">Kandarp Desai on LinkedIn</a></p><p><a href="https://www.xactlycorp.com/">Xactly</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24163578" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/4f43e603-45c6-499f-91c3-2a0d2bf1ba2f/audio/39b73612-65c2-41de-a09c-db8dbf10e407/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Xactly SVP Engineering Kandarp Desai</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:10</itunes:duration>
      <itunes:summary>Kandarp dives into the development of the Xactly AI Copilot before expanding on the complexities of measuring AI’s true value and impact. We also explore the future of AI, with Kandarp sharing his view that while AI may be overhyped in the short term, its long-term potential is vastly underappreciated.</itunes:summary>
      <itunes:subtitle>Kandarp dives into the development of the Xactly AI Copilot before expanding on the complexities of measuring AI’s true value and impact. We also explore the future of AI, with Kandarp sharing his view that while AI may be overhyped in the short term, its long-term potential is vastly underappreciated.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>104</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">675b3916-216b-4247-8ff2-3a9251e91ca4</guid>
      <title>AI Industry Leader Srujana Kaddevarmuth</title>
      <description><![CDATA[<p> Srujana is Vice President and Group Director at Walmart’s Machine Learning Center of Excellence and is an experienced and respected AI, machine learning, and data science professional. She has a strong background in developing AI and machine learning models, with expertise in natural language processing, deep learning, and data-driven decision-making. Srujana has worked in various capacities in the tech industry, contributing to advancing AI technologies and their applications in solving complex problems. In our conversation, we unpack the trends shaping AI governance, the importance of consumer data protection, and the role of human-centered AI. Explore why upskilling the workforce is vital, the potential impact AI could have on white-collar jobs, and which roles AI cannot replace. We discuss the interplay between bias and transparency, the role of governments in creating AI development guardrails, and how the regulatory framework has evolved. Join us to learn about the essential considerations of deploying algorithms at scale, striking a balance between latency and accuracy, the pros and cons of generative AI, and more. </p><p>Key Points From This Episode:</p><ul><li>Srujana breaks down the top concerns surrounding technology and data.</li><li>Learn how AI can be utilized to drive innovation and economic growth.</li><li>Navigating the adoption of AI with upskilling and workforce retention.</li><li>The AI gaps that upskilling should focus on to avoid workforce displacement.</li><li>Common misconceptions about biases in AI and how they can be mitigated. </li><li>Why establishing regulations, laws, and policies is vital for ethical AI development.</li><li>Outline of the nuances of creating an effective worldwide regulatory framework.</li><li>She explains the challenges and opportunities of deploying algorithms at scale. </li><li>Hear about the strategies for building architecture that can adapt to future changes. </li><li>She shares her perspective on generative AI and what its best use cases are.</li><li>Find out what area of AI Srujana is most excited about.</li></ul><p>Quotes:</p><p>“By deploying [bias] algorithms we may be going ahead and causing some unintended consequences.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:03:11]</p><p>“I think it is extremely important to have the right regulations and guardrails in place.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:11:32]</p><p>“Just using generative AI for the sake of it is not necessarily a great idea.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:25:27]</p><p>“I think there are a lot of applications in terms of how generative AI can be used but not everybody is seeing the return on investment.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:27:12]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.srujanakaddevarmuth.com/">Srujana Kaddevarmuth</a></p><p><a href="https://x.com/Srujanadev">Srujana Kaddevarmuth on X</a></p><p><a href="https://www.linkedin.com/in/srujana-kaddevarmuth-37a32b18/">Srujana Kaddevarmuth on LinkedIn</a></p><p><a href="https://www.una-sf.org/">United Nations Association (UNA) San Francisco </a></p><p><a href="https://inatba.org/the-world-in-2050/">The World in 2050</a></p><p><a href="https://americaninsight.org/">American INSIGHT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Mon, 9 Sep 2024 19:37:09 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-industry-leader-srujana-kaddevarmuth-7c7u09X8</link>
      <content:encoded><![CDATA[<p> Srujana is Vice President and Group Director at Walmart’s Machine Learning Center of Excellence and is an experienced and respected AI, machine learning, and data science professional. She has a strong background in developing AI and machine learning models, with expertise in natural language processing, deep learning, and data-driven decision-making. Srujana has worked in various capacities in the tech industry, contributing to advancing AI technologies and their applications in solving complex problems. In our conversation, we unpack the trends shaping AI governance, the importance of consumer data protection, and the role of human-centered AI. Explore why upskilling the workforce is vital, the potential impact AI could have on white-collar jobs, and which roles AI cannot replace. We discuss the interplay between bias and transparency, the role of governments in creating AI development guardrails, and how the regulatory framework has evolved. Join us to learn about the essential considerations of deploying algorithms at scale, striking a balance between latency and accuracy, the pros and cons of generative AI, and more. </p><p>Key Points From This Episode:</p><ul><li>Srujana breaks down the top concerns surrounding technology and data.</li><li>Learn how AI can be utilized to drive innovation and economic growth.</li><li>Navigating the adoption of AI with upskilling and workforce retention.</li><li>The AI gaps that upskilling should focus on to avoid workforce displacement.</li><li>Common misconceptions about biases in AI and how they can be mitigated. </li><li>Why establishing regulations, laws, and policies is vital for ethical AI development.</li><li>Outline of the nuances of creating an effective worldwide regulatory framework.</li><li>She explains the challenges and opportunities of deploying algorithms at scale. </li><li>Hear about the strategies for building architecture that can adapt to future changes. </li><li>She shares her perspective on generative AI and what its best use cases are.</li><li>Find out what area of AI Srujana is most excited about.</li></ul><p>Quotes:</p><p>“By deploying [bias] algorithms we may be going ahead and causing some unintended consequences.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:03:11]</p><p>“I think it is extremely important to have the right regulations and guardrails in place.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:11:32]</p><p>“Just using generative AI for the sake of it is not necessarily a great idea.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:25:27]</p><p>“I think there are a lot of applications in terms of how generative AI can be used but not everybody is seeing the return on investment.” — <a href="https://x.com/Srujanadev">@Srujanadev</a> [0:27:12]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.srujanakaddevarmuth.com/">Srujana Kaddevarmuth</a></p><p><a href="https://x.com/Srujanadev">Srujana Kaddevarmuth on X</a></p><p><a href="https://www.linkedin.com/in/srujana-kaddevarmuth-37a32b18/">Srujana Kaddevarmuth on LinkedIn</a></p><p><a href="https://www.una-sf.org/">United Nations Association (UNA) San Francisco </a></p><p><a href="https://inatba.org/the-world-in-2050/">The World in 2050</a></p><p><a href="https://americaninsight.org/">American INSIGHT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29973662" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d7e03f6f-da03-421e-b378-be4b0cb32248/audio/db90a97d-b6fe-45de-88f7-6e841f02399c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI Industry Leader Srujana Kaddevarmuth</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:13</itunes:duration>
      <itunes:summary>How can we ensure that AI is used ethically in a rapidly evolving world? Today, we sit down with Srujana Kaddevarmuth to delve into AI ethics, workforce upskilling, and the need for global regulations to ensure ethical AI adoption and deployment.</itunes:summary>
      <itunes:subtitle>How can we ensure that AI is used ethically in a rapidly evolving world? Today, we sit down with Srujana Kaddevarmuth to delve into AI ethics, workforce upskilling, and the need for global regulations to ensure ethical AI adoption and deployment.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>103</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">90ee53a9-da03-4af7-a8fa-aae38c842539</guid>
      <title>UPS Sr. Director &amp; Head of Innovation Sunzay Passari</title>
      <description><![CDATA[<p>Our guest goes on to share the different kinds of research they use for machine learning development before explaining why he is more conservative when it comes to driving generative AI use cases. He even shares some examples of generative use cases he feels are worthwhile. We hear about how these changes will benefit all UPS customers and how they avoid sharing private and non-compliant information with chatbots. Finally, Sunzay shares some advice for anyone wanting to become a leader in the tech world.</p><p>Key Points From This Episode:</p><ul><li>Introducing Sunzay Passari to the show and how he landed his current role at UPS.</li><li>Why Sunzay believes that this huge operation he’s part of will drive transformational change. </li><li>How AI and machine learning have made their way into UPS over the past few years. </li><li>The way Sunzay and his team have decided where AI will be most disruptive within UPS. </li><li>Qualitative and qualitative research and what that looks like for this project. </li><li>Why Sunzay is conservative when it comes to driving generative AI use cases. </li><li>Sunzay shares some of the generative use cases that he thinks are worthwhile. </li><li>The way these new technologies will benefit everyday UPS customers. </li><li>How they are preventing people from accessing non-compliant data through chatbots. </li><li>Sunzay passes on some advice for anyone looking to forge their career as a leader in tech. </li></ul><p>Quotes:</p><p>“There’s a lot of complexities in the kind of global operations we are running on a day-to-day basis [at UPS].” — Sunzay Passari [0:04:35]</p><p>“There is no magic wand – so it becomes very important for us to better our resources at the right time in the right initiative.” — Sunzay Passari [0:09:15]</p><p>“Keep learning on a daily basis, keep experimenting and learning, and don’t be afraid of the failures.” — Sunzay Passari [0:22:48]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/sunzaypassari/">Sunzay Passari on LinkedIn</a></p><p><a href="https://www.ups.com/">UPS</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 29 Aug 2024 17:26:21 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ups-sr-director-head-of-innovation-sunzay-passari-hv_HYuoK</link>
      <content:encoded><![CDATA[<p>Our guest goes on to share the different kinds of research they use for machine learning development before explaining why he is more conservative when it comes to driving generative AI use cases. He even shares some examples of generative use cases he feels are worthwhile. We hear about how these changes will benefit all UPS customers and how they avoid sharing private and non-compliant information with chatbots. Finally, Sunzay shares some advice for anyone wanting to become a leader in the tech world.</p><p>Key Points From This Episode:</p><ul><li>Introducing Sunzay Passari to the show and how he landed his current role at UPS.</li><li>Why Sunzay believes that this huge operation he’s part of will drive transformational change. </li><li>How AI and machine learning have made their way into UPS over the past few years. </li><li>The way Sunzay and his team have decided where AI will be most disruptive within UPS. </li><li>Qualitative and qualitative research and what that looks like for this project. </li><li>Why Sunzay is conservative when it comes to driving generative AI use cases. </li><li>Sunzay shares some of the generative use cases that he thinks are worthwhile. </li><li>The way these new technologies will benefit everyday UPS customers. </li><li>How they are preventing people from accessing non-compliant data through chatbots. </li><li>Sunzay passes on some advice for anyone looking to forge their career as a leader in tech. </li></ul><p>Quotes:</p><p>“There’s a lot of complexities in the kind of global operations we are running on a day-to-day basis [at UPS].” — Sunzay Passari [0:04:35]</p><p>“There is no magic wand – so it becomes very important for us to better our resources at the right time in the right initiative.” — Sunzay Passari [0:09:15]</p><p>“Keep learning on a daily basis, keep experimenting and learning, and don’t be afraid of the failures.” — Sunzay Passari [0:22:48]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/sunzaypassari/">Sunzay Passari on LinkedIn</a></p><p><a href="https://www.ups.com/">UPS</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24155637" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/33a42107-2229-43b1-b854-91f827e5abe2/audio/53af4c3b-a832-4739-bd3e-c13825bfb5fb/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>UPS Sr. Director &amp; Head of Innovation Sunzay Passari</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:09</itunes:duration>
      <itunes:summary>Today on How AI Happens we are joined by the leader of digital change at UPS, Sunzay Passari. You’ll hear all about Sunzay’s extensive career, how he landed his role at UPS, how he plans on driving technological transformation, and how AI has made its way into the company in recent years. </itunes:summary>
      <itunes:subtitle>Today on How AI Happens we are joined by the leader of digital change at UPS, Sunzay Passari. You’ll hear all about Sunzay’s extensive career, how he landed his role at UPS, how he plans on driving technological transformation, and how AI has made its way into the company in recent years. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>102</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">545b8a43-f401-4f06-9449-d3f30eed0489</guid>
      <title>Google DeepMind Research Director Dr. Martin Riedmiller</title>
      <description><![CDATA[<p>Martin shares what reinforcement learning does differently in executing complex tasks, overcoming feedback loops in reinforcement learning, the pitfalls of typical agent-based learning methods, and how being a robotic soccer champion exposed the value of deep learning. We unpack the advantages of deep learning over modeling agent approaches, how finding a solution can inspire a solution in an unrelated field, and why he is currently focusing on data efficiency. Gain insights into the trade-offs between exploration and exploitation, how Google DeepMind is leveraging large language models for data efficiency, the potential risk of using large language models, and much more.</p><p> </p><p>Key Points From This Episode:</p><ul><li>What it is like being a five times world robotic soccer champion.</li><li>The process behind training a winning robotic soccer team.</li><li>Why standard machine learning tools could not train his team effectively. </li><li>Discover the challenges AI and machine learning are currently facing.</li><li>Explore the various exciting use cases of reinforcement learning.</li><li>Details about Google DeepMind and the role of him and his team. </li><li>Learn about Google DeepMind’s overall mission and its current focus.</li><li>Hear about the advantages of being a scientist in the AI industry. </li><li>Martin explains the benefits of exploration to reinforcement learning.</li><li>How data mining using large language models for training is implemented. </li><li>Ways reinforcement learning will impact people in the tech industry.</li><li>Unpack how AI will continue to disrupt industries and drive innovation.</li></ul><p>Quotes:</p><p>“You really want to go all the way down to learn the direct connections to actions only via learning [for training AI].” — Martin Riedmiller [0:07:55]</p><p>“I think engineers often work with analogies or things that they have learned from different [projects].” — Martin Riedmiller [0:11:16]</p><p>“[With reinforcement learning], you are spending the precious real robots time only on things that you don’t know and not on the things you probably already know.” — Martin Riedmiller [0:17:04]</p><p>“We have not achieved AGI (Artificial General Intelligence) until we have removed the human completely out of the loop.” — Martin Riedmiller [0:21:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.riedmiller.me">Martin Riedmiller</a></p><p><a href="https://www.linkedin.com/in/martin-riedmiller-636b3471/">Martin Riedmiller on LinkedIn</a></p><p><a href="https://deepmind.google">Google DeepMind</a></p><p><a href="https://www.robocup.org">RoboCup</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 23 Aug 2024 19:39:17 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/google-deepmind-research-director-dr-martin-riedmiller-O9a8lXys</link>
      <content:encoded><![CDATA[<p>Martin shares what reinforcement learning does differently in executing complex tasks, overcoming feedback loops in reinforcement learning, the pitfalls of typical agent-based learning methods, and how being a robotic soccer champion exposed the value of deep learning. We unpack the advantages of deep learning over modeling agent approaches, how finding a solution can inspire a solution in an unrelated field, and why he is currently focusing on data efficiency. Gain insights into the trade-offs between exploration and exploitation, how Google DeepMind is leveraging large language models for data efficiency, the potential risk of using large language models, and much more.</p><p> </p><p>Key Points From This Episode:</p><ul><li>What it is like being a five times world robotic soccer champion.</li><li>The process behind training a winning robotic soccer team.</li><li>Why standard machine learning tools could not train his team effectively. </li><li>Discover the challenges AI and machine learning are currently facing.</li><li>Explore the various exciting use cases of reinforcement learning.</li><li>Details about Google DeepMind and the role of him and his team. </li><li>Learn about Google DeepMind’s overall mission and its current focus.</li><li>Hear about the advantages of being a scientist in the AI industry. </li><li>Martin explains the benefits of exploration to reinforcement learning.</li><li>How data mining using large language models for training is implemented. </li><li>Ways reinforcement learning will impact people in the tech industry.</li><li>Unpack how AI will continue to disrupt industries and drive innovation.</li></ul><p>Quotes:</p><p>“You really want to go all the way down to learn the direct connections to actions only via learning [for training AI].” — Martin Riedmiller [0:07:55]</p><p>“I think engineers often work with analogies or things that they have learned from different [projects].” — Martin Riedmiller [0:11:16]</p><p>“[With reinforcement learning], you are spending the precious real robots time only on things that you don’t know and not on the things you probably already know.” — Martin Riedmiller [0:17:04]</p><p>“We have not achieved AGI (Artificial General Intelligence) until we have removed the human completely out of the loop.” — Martin Riedmiller [0:21:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.riedmiller.me">Martin Riedmiller</a></p><p><a href="https://www.linkedin.com/in/martin-riedmiller-636b3471/">Martin Riedmiller on LinkedIn</a></p><p><a href="https://deepmind.google">Google DeepMind</a></p><p><a href="https://www.robocup.org">RoboCup</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25220179" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/0d606250-cc8a-481e-a6c5-7ab6b2224f6c/audio/2ee3f293-1750-40e6-824e-c02c47a201d5/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Google DeepMind Research Director Dr. Martin Riedmiller</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:16</itunes:duration>
      <itunes:summary>Martin is a former University Professor and renowned Research Scientist at Google DeepMind, whose work focuses on advancing the field of artificial intelligence through deep reinforcement learning. His work continues to push the boundaries of AI capabilities, making him a leading figure in the quest to build AI systems that can learn and adapt to complex environments. In our conversation, we discuss what reinforcement learning does differently in executing complex tasks, overcoming feedback loops in reinforcement learning, the pitfalls of typical agent-based learning methods, and how being a robotic soccer champion exposed the value of deep learning. We unpack the advantages of deep learning over modeling agent approaches, how finding a solution can inspire a solution in an unrelated field, and why he is currently focusing on data efficiency. Gain insights into the trade-offs between exploration and exploitation, how Google DeepMind is leveraging large language models for data efficiency, the potential risk of using large language models, and much more. Tune in now!</itunes:summary>
      <itunes:subtitle>Martin is a former University Professor and renowned Research Scientist at Google DeepMind, whose work focuses on advancing the field of artificial intelligence through deep reinforcement learning. His work continues to push the boundaries of AI capabilities, making him a leading figure in the quest to build AI systems that can learn and adapt to complex environments. In our conversation, we discuss what reinforcement learning does differently in executing complex tasks, overcoming feedback loops in reinforcement learning, the pitfalls of typical agent-based learning methods, and how being a robotic soccer champion exposed the value of deep learning. We unpack the advantages of deep learning over modeling agent approaches, how finding a solution can inspire a solution in an unrelated field, and why he is currently focusing on data efficiency. Gain insights into the trade-offs between exploration and exploitation, how Google DeepMind is leveraging large language models for data efficiency, the potential risk of using large language models, and much more. Tune in now!</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>101</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">5434c5d8-af50-4f48-b4d1-c08b1e176a9c</guid>
      <title>LiveX Chief AI Officer, President, &amp; Co-Founder Jia Li</title>
      <description><![CDATA[<p>Jia  shares the kinds of AI courses she teaches at Stanford, how students are receiving machine learning education, and the impact of AI agents, as well as understanding technical boundaries, being realistic about the limitations of AI agents, and the importance of interdisciplinary collaboration. We also delve into how Jia prioritizes latency at LiveX before finding out how machine learning has changed the way people interact with agents; both human and AI. </p><p>Key Points From This Episode:</p><ul><li>The AI courses that Jia teaches at Stanford. </li><li>Jia’s perspective on the future of AI. </li><li>What the potential impact of AI agents is. </li><li>The importance of understanding technical boundaries. </li><li>Why interdisciplinary collaboration is imperative. </li><li>How Jia is empowering other businesses through LiveX AI. </li><li>Why she prioritizes latency and believes that it’s crucial. </li><li>How AI has changed people’s expectations and level of courtesy.</li><li>A glimpse into Jia’s vision for the future of AI agents. </li><li>Why she is not satisfied with the multi-model AI models out there. </li><li>Challenges associated with data in multi-model machine learning. </li></ul><p>Quotes:</p><p>“[The field of AI] is advancing so fast every day.” — Jia Li [0:03:05]</p><p>“It is very important to have more sharing and collaboration within the [AI field].” — Jia Li [0:12:40]</p><p>“Having an efficient algorithm [and] having efficient hardware and software optimization is really valuable.” — Jia Li [0:14:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/lijiali/">Jia Li on LinkedIn</a></p><p><a href="https://livex.ai/">LiveX AI</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 25 Jul 2024 21:32:10 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/livex-chief-ai-officer-president-co-founder-jia-li-m7uoRn8A</link>
      <content:encoded><![CDATA[<p>Jia  shares the kinds of AI courses she teaches at Stanford, how students are receiving machine learning education, and the impact of AI agents, as well as understanding technical boundaries, being realistic about the limitations of AI agents, and the importance of interdisciplinary collaboration. We also delve into how Jia prioritizes latency at LiveX before finding out how machine learning has changed the way people interact with agents; both human and AI. </p><p>Key Points From This Episode:</p><ul><li>The AI courses that Jia teaches at Stanford. </li><li>Jia’s perspective on the future of AI. </li><li>What the potential impact of AI agents is. </li><li>The importance of understanding technical boundaries. </li><li>Why interdisciplinary collaboration is imperative. </li><li>How Jia is empowering other businesses through LiveX AI. </li><li>Why she prioritizes latency and believes that it’s crucial. </li><li>How AI has changed people’s expectations and level of courtesy.</li><li>A glimpse into Jia’s vision for the future of AI agents. </li><li>Why she is not satisfied with the multi-model AI models out there. </li><li>Challenges associated with data in multi-model machine learning. </li></ul><p>Quotes:</p><p>“[The field of AI] is advancing so fast every day.” — Jia Li [0:03:05]</p><p>“It is very important to have more sharing and collaboration within the [AI field].” — Jia Li [0:12:40]</p><p>“Having an efficient algorithm [and] having efficient hardware and software optimization is really valuable.” — Jia Li [0:14:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/lijiali/">Jia Li on LinkedIn</a></p><p><a href="https://livex.ai/">LiveX AI</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28622366" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e629ad01-38f5-46f2-a51f-8e2ffa4016f4/audio/1dacf1de-75e6-43ec-b66f-4c339e64854a/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>LiveX Chief AI Officer, President, &amp; Co-Founder Jia Li</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:48</itunes:duration>
      <itunes:summary>Jia shares her background as an adjunct professor at Stanford University as well as her journey to Co-Founding and serving as President &amp; Chief AI Officer at LiveX, as well as why she is so excited about the field of AI agents and the crucial import of a multi-modal approach.</itunes:summary>
      <itunes:subtitle>Jia shares her background as an adjunct professor at Stanford University as well as her journey to Co-Founding and serving as President &amp; Chief AI Officer at LiveX, as well as why she is so excited about the field of AI agents and the crucial import of a multi-modal approach.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>100</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">70947e10-15a1-429f-9f2e-8a4c350fdcbc</guid>
      <title>Zapier Lead AI PM Reid Robinson</title>
      <description><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>Reid Robinson's professional background, and how he ended up at Zapier. </li><li>What he learned during his year as an NFT founder, and how it serves him in his work today.</li><li>How he gained his diverse array of professional skills.</li><li>Whether one can differentiate between AI and mere automation. </li><li>How Reid knew that partnering with OpenAI and ChatGPT would be the perfect fit. </li><li>The way the Zapier team understands and approaches ML accuracy and generative data.</li><li>Why real-world data is better as it stands, and whether generative data will one day catch up. </li><li>How Zapier uses generative data with its clients. </li><li>Why AI is still mostly beneficial for those with a technical background. </li><li>Reid Robinson's next big idea, and his parting words of advice.</li></ul><p>Quotes:</p><p>“Sometimes, people are very bad at asking for what they want. If you do any stint in, particularly, the more hardcore sales jobs out there, it's one of the things you're going to have to learn how to do to survive. You have to be uncomfortable and learn how to ask for things.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:05:07]</p><p>“In order to really start to drive the accuracy of [our AI models], we needed to understand, what were users trying to do with this?” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:15:34]</p><p>“The people who being enabled the most with AI in the current stage are the technical tinkerers. I think a lot of these tools are too technical for average-knowledge workers.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:28:32]</p><p>“Quick advice for anyone listening to this, do not start a company when you have your first kid! Horrible idea.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:29:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/reidtrobinson">Reid Robinson on LinkedIn</a></p><p><a href="https://x.com/Reidoutloud_">Reid Robinson on X</a></p><p><a href="https://zapier.com/">Zapier</a></p><p><a href="https://linktr.ee/coconft">CocoNFT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Mon, 22 Jul 2024 18:04:37 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/zapier-lead-ai-pm-reid-robinson-CdgMZH28</link>
      <content:encoded><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>Reid Robinson's professional background, and how he ended up at Zapier. </li><li>What he learned during his year as an NFT founder, and how it serves him in his work today.</li><li>How he gained his diverse array of professional skills.</li><li>Whether one can differentiate between AI and mere automation. </li><li>How Reid knew that partnering with OpenAI and ChatGPT would be the perfect fit. </li><li>The way the Zapier team understands and approaches ML accuracy and generative data.</li><li>Why real-world data is better as it stands, and whether generative data will one day catch up. </li><li>How Zapier uses generative data with its clients. </li><li>Why AI is still mostly beneficial for those with a technical background. </li><li>Reid Robinson's next big idea, and his parting words of advice.</li></ul><p>Quotes:</p><p>“Sometimes, people are very bad at asking for what they want. If you do any stint in, particularly, the more hardcore sales jobs out there, it's one of the things you're going to have to learn how to do to survive. You have to be uncomfortable and learn how to ask for things.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:05:07]</p><p>“In order to really start to drive the accuracy of [our AI models], we needed to understand, what were users trying to do with this?” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:15:34]</p><p>“The people who being enabled the most with AI in the current stage are the technical tinkerers. I think a lot of these tools are too technical for average-knowledge workers.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:28:32]</p><p>“Quick advice for anyone listening to this, do not start a company when you have your first kid! Horrible idea.” — <a href="https://x.com/Reidoutloud_">@Reidoutloud_</a> [0:29:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/reidtrobinson">Reid Robinson on LinkedIn</a></p><p><a href="https://x.com/Reidoutloud_">Reid Robinson on X</a></p><p><a href="https://zapier.com/">Zapier</a></p><p><a href="https://linktr.ee/coconft">CocoNFT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29491304" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/29a7efa6-6e4f-40a6-af70-f9f3bde7ac0b/audio/0ce50cc7-bd22-4261-bb21-5468c73affa0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Zapier Lead AI PM Reid Robinson</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:43</itunes:duration>
      <itunes:summary>Here to shed more light on  issues of generative data quality is the Lead Project Manager for AI at Zapier, Reid Robinson. Reid begins by explaining how he ended up at Zapier, and how his journey as a founder helps him in the work he does today. Then, we discuss whether AI can be differentiated from automation, how the Zapier team engages with ML accuracy and generative data, how Zapier uses generative data with its clients, and why AI is still best enjoyed by those who already have some technical knowledge. To end, Rob hints at his next big idea and venture, and he shares some important advice for listeners who want to do more in today’s world of machine learning. </itunes:summary>
      <itunes:subtitle>Here to shed more light on  issues of generative data quality is the Lead Project Manager for AI at Zapier, Reid Robinson. Reid begins by explaining how he ended up at Zapier, and how his journey as a founder helps him in the work he does today. Then, we discuss whether AI can be differentiated from automation, how the Zapier team engages with ML accuracy and generative data, how Zapier uses generative data with its clients, and why AI is still best enjoyed by those who already have some technical knowledge. To end, Rob hints at his next big idea and venture, and he shares some important advice for listeners who want to do more in today’s world of machine learning. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>99</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4381fb87-2b29-4a40-a41d-08cbaffce8e7</guid>
      <title>Leveraging Technology to Preserve Creativity with Justin Kilb</title>
      <description><![CDATA[<p> In this episode of How AI Happens, Justin explains how his project, Wondr Search, injects creativity into AI in a way that doesn’t alienate creators. You’ll learn how this new form of AI uses evolutionary algorithms (EAs) and differential evolution (DE) to generate music without learning from or imitating existing creative work. We also touch on the success of the six songs created by Wondr Search, why AI will never fully replace artists, and so much more. For a fascinating conversation at the intersection of art and AI, be sure to tune in today!</p><p>Key Points From This Episode:</p><ul><li>How genetic algorithms can preserve human creativity in the age of AI.</li><li>Ways that Wondr Search differs from current generative AI models.</li><li>Why the songs produced by Wondr Search were so well-received by record labels.</li><li>Justin’s motivations for creating an AI model that doesn’t learn from existing music.</li><li>Differentiating between AI-generated content and creative work made by humans.</li><li>Insight into Justin’s PhD topic focused on mathematical optimization.</li><li>Key differences between operations research and data science.</li><li>An understanding of the relationship between machine learning and physics.</li><li>Our guest’s take on “big data” and why more data isn’t always better.</li><li>Problems Justin focuses on as a technical advisor to Fortune 500 companies.</li><li>What he is most excited (and most concerned) about for the future of AI.</li></ul><p>Quotes:</p><p>“[Wondr Search] is definitely not an effort to stand up against generative AI that uses traditional ML methods. I use those a lot and there’s going to be a lot of good that comes from those – but I also think there’s going to be a market for more human-centric generative methods.” — Justin Kilb [0:06:12]</p><p>“The definition of intelligence continues to change as [humans and artificial systems] progress.” — Justin Kilb [0:24:29]</p><p>“As we make progress, people can access [AI] everywhere as long as they have an internet connection. That's exciting because you see a lot of people doing a lot of great things.” — Justin Kilb [0:26:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/justinkilb/">Justin Kilb on LinkedIn</a></p><p><a href="https://www.wondrsearch.com/">Wondr Search</a></p><p><a href="https://arxiv.org/html/2406.05873v1">‘Conserving Human Creativity with Evolutionary Generative Algorithms: A Case Study in Music Generation’</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 28 Jun 2024 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/leveraging-technology-to-preserve-creativity-with-justin-kilb-7faCPpV0</link>
      <content:encoded><![CDATA[<p> In this episode of How AI Happens, Justin explains how his project, Wondr Search, injects creativity into AI in a way that doesn’t alienate creators. You’ll learn how this new form of AI uses evolutionary algorithms (EAs) and differential evolution (DE) to generate music without learning from or imitating existing creative work. We also touch on the success of the six songs created by Wondr Search, why AI will never fully replace artists, and so much more. For a fascinating conversation at the intersection of art and AI, be sure to tune in today!</p><p>Key Points From This Episode:</p><ul><li>How genetic algorithms can preserve human creativity in the age of AI.</li><li>Ways that Wondr Search differs from current generative AI models.</li><li>Why the songs produced by Wondr Search were so well-received by record labels.</li><li>Justin’s motivations for creating an AI model that doesn’t learn from existing music.</li><li>Differentiating between AI-generated content and creative work made by humans.</li><li>Insight into Justin’s PhD topic focused on mathematical optimization.</li><li>Key differences between operations research and data science.</li><li>An understanding of the relationship between machine learning and physics.</li><li>Our guest’s take on “big data” and why more data isn’t always better.</li><li>Problems Justin focuses on as a technical advisor to Fortune 500 companies.</li><li>What he is most excited (and most concerned) about for the future of AI.</li></ul><p>Quotes:</p><p>“[Wondr Search] is definitely not an effort to stand up against generative AI that uses traditional ML methods. I use those a lot and there’s going to be a lot of good that comes from those – but I also think there’s going to be a market for more human-centric generative methods.” — Justin Kilb [0:06:12]</p><p>“The definition of intelligence continues to change as [humans and artificial systems] progress.” — Justin Kilb [0:24:29]</p><p>“As we make progress, people can access [AI] everywhere as long as they have an internet connection. That's exciting because you see a lot of people doing a lot of great things.” — Justin Kilb [0:26:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/justinkilb/">Justin Kilb on LinkedIn</a></p><p><a href="https://www.wondrsearch.com/">Wondr Search</a></p><p><a href="https://arxiv.org/html/2406.05873v1">‘Conserving Human Creativity with Evolutionary Generative Algorithms: A Case Study in Music Generation’</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="26934647" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/9f3abe6e-bfd0-4974-be94-2e337939ea8c/audio/a786e796-d0b3-4472-b7a8-8e78bd7729e0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Leveraging Technology to Preserve Creativity with Justin Kilb</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:03</itunes:duration>
      <itunes:summary>As generative AI continues to scale, the likelihood of computer-generated content outpacing human creation increases. Today, we explore how evolutionary generative algorithms in music production can preserve and enhance human creativity rather than overshadow it. Joining us is Justin Kilb, a data scientist and PhD student who serves as an AI technical advisor to Fortune 500 companies.</itunes:summary>
      <itunes:subtitle>As generative AI continues to scale, the likelihood of computer-generated content outpacing human creation increases. Today, we explore how evolutionary generative algorithms in music production can preserve and enhance human creativity rather than overshadow it. Joining us is Justin Kilb, a data scientist and PhD student who serves as an AI technical advisor to Fortune 500 companies.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>98</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">77f4eadc-0760-4427-aada-e880842dadb0</guid>
      <title>Gong VP of AI Platform Division Jacob Eckel</title>
      <description><![CDATA[<p>Jacob shares how Gong uses AI, how it empowers its customers to build their own models, and how this ease of access for users holds the promise of a brighter future. We also learn more about the inner workings of Gong and how it trains its own models, why it’s not too interested in tracking soft skills right now, what we need to be doing more of to build more trust in chatbots, and our guest’s summation of why technology is advancing like a runaway train.</p><p>Key Points From This Episode:</p><ul><li>Jacob Eckel walks us through his professional background and how he ended up at Gong.</li><li>The ins and outs of Gong, and where AI fits in. </li><li>How Gong empowers its customers to build their own models, and the results thereof. </li><li>Understanding the data ramifications when customers build their own models on Gong.</li><li>How Gong trains its own models, and the way the platform assists users in real time. </li><li>Why its models aren’t tracking softer skills like rapport-building, yet.</li><li>Everything that needs to be solved before we can fully trust chatbots. </li><li>Jacob’s summation of why technology is growing at an increasingly rapid rate. </li></ul><p>Quotes:</p><p>“We don’t expect our customers to suddenly become data scientists and learn about modeling and everything, so we give them a very intuitive, relatively simple environment in which they can define their own models.” — <a href="https://x.com/eckely">@eckely</a> [0:07:03]</p><p>“[Data] is not a huge obstacle to adopting smart trackers.” — <a href="https://x.com/eckely">@eckely</a> [0:12:13]</p><p>“Our current vibe is there’s a limit to this technology. We are still unevolved apes.” — <a href="https://x.com/eckely">@eckely</a> [0:16:27]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/eckel">Jacob Eckel on LinkedIn</a></p><p><a href="https://x.com/eckely">Jacob Eckel on X</a></p><p><a href="https://www.gong.io/">Gong</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 26 Jun 2024 16:59:26 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/gong-vp-of-ai-platform-division-jacob-eckel-V6RhTDhk</link>
      <content:encoded><![CDATA[<p>Jacob shares how Gong uses AI, how it empowers its customers to build their own models, and how this ease of access for users holds the promise of a brighter future. We also learn more about the inner workings of Gong and how it trains its own models, why it’s not too interested in tracking soft skills right now, what we need to be doing more of to build more trust in chatbots, and our guest’s summation of why technology is advancing like a runaway train.</p><p>Key Points From This Episode:</p><ul><li>Jacob Eckel walks us through his professional background and how he ended up at Gong.</li><li>The ins and outs of Gong, and where AI fits in. </li><li>How Gong empowers its customers to build their own models, and the results thereof. </li><li>Understanding the data ramifications when customers build their own models on Gong.</li><li>How Gong trains its own models, and the way the platform assists users in real time. </li><li>Why its models aren’t tracking softer skills like rapport-building, yet.</li><li>Everything that needs to be solved before we can fully trust chatbots. </li><li>Jacob’s summation of why technology is growing at an increasingly rapid rate. </li></ul><p>Quotes:</p><p>“We don’t expect our customers to suddenly become data scientists and learn about modeling and everything, so we give them a very intuitive, relatively simple environment in which they can define their own models.” — <a href="https://x.com/eckely">@eckely</a> [0:07:03]</p><p>“[Data] is not a huge obstacle to adopting smart trackers.” — <a href="https://x.com/eckely">@eckely</a> [0:12:13]</p><p>“Our current vibe is there’s a limit to this technology. We are still unevolved apes.” — <a href="https://x.com/eckely">@eckely</a> [0:16:27]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/eckel">Jacob Eckel on LinkedIn</a></p><p><a href="https://x.com/eckely">Jacob Eckel on X</a></p><p><a href="https://www.gong.io/">Gong</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="26296424" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/575743d9-c525-4579-9096-69a8532055c8/audio/51c4e7fd-99eb-4fb0-a3f6-81e02eb2c173/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Gong VP of AI Platform Division Jacob Eckel</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:23</itunes:duration>
      <itunes:summary>Jacob is the Vice President of the AI Platform Division at Gong – the AI platform that transforms your revenue growth – and he joins us today to share his joy of giving people the freedom of a data scientist even if they have a limited technological background. </itunes:summary>
      <itunes:subtitle>Jacob is the Vice President of the AI Platform Division at Gong – the AI platform that transforms your revenue growth – and he joins us today to share his joy of giving people the freedom of a data scientist even if they have a limited technological background. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>97</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">1a7d3a7e-b3b3-4326-a666-82a6b3783aa1</guid>
      <title>Brilliant Labs CEO Bobak Tavangar</title>
      <description><![CDATA[<p>Bobak further opines on the pros and cons of Perplexity and GPT 4.0, why the technology uses both models, the differences, and the pros and cons. Finally, our guest tells us why Brilliant Labs is open-source and reminds us why public participation is so important. </p><p>Key Points From This Episode:</p><ul><li>Introducing Bobak Tavangar to today’s episode of How AI Happens. </li><li>Bobak tells us about his background and what led him to start his company, Brilliant Labs. </li><li>Our guest shares his interesting <i>Lord of the Rings</i> analogy and how it relates to his business. </li><li>How wearable technology is creeping more and more into our lives. </li><li>The hurdles they face with generative AI glasses and how they’re overcoming them. </li><li>How Bobak chose the most important factors to incorporate into the glasses. </li><li>What the glasses can do at this stage of development. </li><li>Bobak explains how the glasses know whether to query GPT 4.0 or Perplexity AI. </li><li>GPT 4.0 versus Perplexity and why Bobak prefers to use them both. </li><li>The importance of gauging public reaction and why Brilliant Labs is open-source. </li></ul><p>Quotes:</p><p>“To have a second pair of eyes that can connect everything we see with all the information on the web and everything we’ve seen previously – is an incredible thing.” — <a href="https://x.com/btavangar">@btavangar</a> [0:13:12]</p><p>“For live web search, Perplexity – is the most precise [and] it gives the most meaningful answers from the live web.” — <a href="https://x.com/btavangar">@btavangar</a> [0:26:40]</p><p>“The [AI] space is changing so fast. It’s exciting [and] it’s good for all of us but we don’t believe you should ever be locked to one model or another.” — <a href="https://x.com/btavangar">@btavangar</a> [0:28:45]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bobak-t-29445012/">Bobak Tavangar on LinkedIn</a></p><p><a href="https://x.com/btavangar">Bobak Tavangar on X</a></p><p><a href="https://www.instagram.com/btavangar/">Bobak Tavangar on Instagram</a></p><p><a href="https://brilliant.xyz/">Brilliant Labs</a></p><p><a href="https://www.perplexity.ai/">Perplexity AI</a></p><p><a href="https://chatbotapp.ai/landing">GPT 4.0</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 14 Jun 2024 00:04:52 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/brilliant-labs-ceo-bobak-tavangar-ZXdcNocg</link>
      <content:encoded><![CDATA[<p>Bobak further opines on the pros and cons of Perplexity and GPT 4.0, why the technology uses both models, the differences, and the pros and cons. Finally, our guest tells us why Brilliant Labs is open-source and reminds us why public participation is so important. </p><p>Key Points From This Episode:</p><ul><li>Introducing Bobak Tavangar to today’s episode of How AI Happens. </li><li>Bobak tells us about his background and what led him to start his company, Brilliant Labs. </li><li>Our guest shares his interesting <i>Lord of the Rings</i> analogy and how it relates to his business. </li><li>How wearable technology is creeping more and more into our lives. </li><li>The hurdles they face with generative AI glasses and how they’re overcoming them. </li><li>How Bobak chose the most important factors to incorporate into the glasses. </li><li>What the glasses can do at this stage of development. </li><li>Bobak explains how the glasses know whether to query GPT 4.0 or Perplexity AI. </li><li>GPT 4.0 versus Perplexity and why Bobak prefers to use them both. </li><li>The importance of gauging public reaction and why Brilliant Labs is open-source. </li></ul><p>Quotes:</p><p>“To have a second pair of eyes that can connect everything we see with all the information on the web and everything we’ve seen previously – is an incredible thing.” — <a href="https://x.com/btavangar">@btavangar</a> [0:13:12]</p><p>“For live web search, Perplexity – is the most precise [and] it gives the most meaningful answers from the live web.” — <a href="https://x.com/btavangar">@btavangar</a> [0:26:40]</p><p>“The [AI] space is changing so fast. It’s exciting [and] it’s good for all of us but we don’t believe you should ever be locked to one model or another.” — <a href="https://x.com/btavangar">@btavangar</a> [0:28:45]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bobak-t-29445012/">Bobak Tavangar on LinkedIn</a></p><p><a href="https://x.com/btavangar">Bobak Tavangar on X</a></p><p><a href="https://www.instagram.com/btavangar/">Bobak Tavangar on Instagram</a></p><p><a href="https://brilliant.xyz/">Brilliant Labs</a></p><p><a href="https://www.perplexity.ai/">Perplexity AI</a></p><p><a href="https://chatbotapp.ai/landing">GPT 4.0</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="30927411" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d9b95e00-147e-4087-bbe6-420dca7353fe/audio/514b41bf-b753-41fc-831e-f64b5bf98ec0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Brilliant Labs CEO Bobak Tavangar</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:12</itunes:duration>
      <itunes:summary>Bobak shares the process of developing Brilliant Labs&apos; AR glasses, including the function calling they developed to train the device to decide which LLMs to query.</itunes:summary>
      <itunes:subtitle>Bobak shares the process of developing Brilliant Labs&apos; AR glasses, including the function calling they developed to train the device to decide which LLMs to query.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>96</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">5a2263b3-a2e4-4ae8-9a54-8a86ff4da533</guid>
      <title>Dremio Tech Evangelist Andrew Madson</title>
      <description><![CDATA[<p>Andrew shares how generative AI is used by academic institutions, why employers and educators need to curb their fear of AI, what we need to consider for using AI responsibly, and the ins and outs of Andrew’s podcast, Insight x Design. </p><p>Key Points From This Episode:</p><ul><li>Andrew Madson explains what a tech evangelist is and what his role at Dremio entails. </li><li>The ins and outs of Dremio. </li><li>Understanding the pain points that Andrew wanted to alleviate by joining Dremio. </li><li>How Andrew became a tech evangelist, and why he values this role.</li><li>Why all tech roles now require one to upskill and branch out into other areas of expertise. </li><li>The problems that Andrew most commonly faces at work, and how he overcomes them. </li><li>How Dremio uses generative AI, and how the technology is used in academia. </li><li>Why employers and educators need to do more to encourage the use of AI. </li><li>The provenance of training data, and other considerations for the responsible use of AI. </li><li>Learning more about Andrew’s new podcast, Insight x Design. </li></ul><p>Quotes:</p><p>“Once I learned about lakehouses and Apache Iceberg and how you can just do all of your work on top of the data lake itself, it really made my life a lot easier with doing real-time analytics.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:04:24]</p><p>“Data analysts have always been expected to be technical, but now, given the rise of the amount of data that we’re dealing with and the limitations of data engineering teams and their capacity, data analysts are expected to do a lot more data engineering.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:07:49]</p><p>“Keeping it simple and short is ideal when dealing with AI.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:12:58]</p><p>“The purpose of higher education isn’t to get a piece of paper, it’s to learn something and to gain new skills.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:17:35]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.insightsxdesign.com/">Andrew Madson</a></p><p><a href="https://www.linkedin.com/in/andrew-madson/">Andrew Madson on LinkedIn</a></p><p><a href="https://twitter.com/insightsxdesign">Andrew Madson on X</a></p><p><a href="https://www.instagram.com/insightsxdesign/">Andrew Madson on Instagram</a></p><p><a href="https://www.dremio.com/">Dremio </a></p><p><a href="https://www.youtube.com/@insightsxdesign">Insights x Design</a></p><p><a href="https://iceberg.apache.org/">Apache Iceberg</a></p><p><a href="https://chatgpt.com/">ChatGPT</a></p><p><a href="https://www.perplexity.ai/">Perplexity AI</a></p><p><a href="https://gemini.google.com/">Gemini</a></p><p><a href="https://www.anaconda.com/">Anaconda </a></p><p><a href="https://www.linkedin.com/in/pzwang/">Peter Wang on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 30 May 2024 21:18:22 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/dremio-tech-evangelist-andrew-madson-obn_WlS2</link>
      <content:encoded><![CDATA[<p>Andrew shares how generative AI is used by academic institutions, why employers and educators need to curb their fear of AI, what we need to consider for using AI responsibly, and the ins and outs of Andrew’s podcast, Insight x Design. </p><p>Key Points From This Episode:</p><ul><li>Andrew Madson explains what a tech evangelist is and what his role at Dremio entails. </li><li>The ins and outs of Dremio. </li><li>Understanding the pain points that Andrew wanted to alleviate by joining Dremio. </li><li>How Andrew became a tech evangelist, and why he values this role.</li><li>Why all tech roles now require one to upskill and branch out into other areas of expertise. </li><li>The problems that Andrew most commonly faces at work, and how he overcomes them. </li><li>How Dremio uses generative AI, and how the technology is used in academia. </li><li>Why employers and educators need to do more to encourage the use of AI. </li><li>The provenance of training data, and other considerations for the responsible use of AI. </li><li>Learning more about Andrew’s new podcast, Insight x Design. </li></ul><p>Quotes:</p><p>“Once I learned about lakehouses and Apache Iceberg and how you can just do all of your work on top of the data lake itself, it really made my life a lot easier with doing real-time analytics.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:04:24]</p><p>“Data analysts have always been expected to be technical, but now, given the rise of the amount of data that we’re dealing with and the limitations of data engineering teams and their capacity, data analysts are expected to do a lot more data engineering.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:07:49]</p><p>“Keeping it simple and short is ideal when dealing with AI.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:12:58]</p><p>“The purpose of higher education isn’t to get a piece of paper, it’s to learn something and to gain new skills.” — <a href="https://twitter.com/insightsxdesign">@insightsxdesign</a> [0:17:35]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.insightsxdesign.com/">Andrew Madson</a></p><p><a href="https://www.linkedin.com/in/andrew-madson/">Andrew Madson on LinkedIn</a></p><p><a href="https://twitter.com/insightsxdesign">Andrew Madson on X</a></p><p><a href="https://www.instagram.com/insightsxdesign/">Andrew Madson on Instagram</a></p><p><a href="https://www.dremio.com/">Dremio </a></p><p><a href="https://www.youtube.com/@insightsxdesign">Insights x Design</a></p><p><a href="https://iceberg.apache.org/">Apache Iceberg</a></p><p><a href="https://chatgpt.com/">ChatGPT</a></p><p><a href="https://www.perplexity.ai/">Perplexity AI</a></p><p><a href="https://gemini.google.com/">Gemini</a></p><p><a href="https://www.anaconda.com/">Anaconda </a></p><p><a href="https://www.linkedin.com/in/pzwang/">Peter Wang on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28152162" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e92fa39e-4a49-4fb0-87f8-6e3935750c49/audio/1451c0db-8837-44c3-8fc2-59a68b07b253/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Dremio Tech Evangelist Andrew Madson</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:19</itunes:duration>
      <itunes:summary>Tech evangelism is a relatively new term, so Andrew graciously explains what a tech evangelist is, how he became one, how he embodies this role at Dremio, and why he values this designation among modern tech professionals. Our guest then shares the pain points that inspired his choice to join Dremio, what Dremio as an organization is all about, how the company uses generative AI, and the common obstacles that Andrew is faced with at work.</itunes:summary>
      <itunes:subtitle>Tech evangelism is a relatively new term, so Andrew graciously explains what a tech evangelist is, how he became one, how he embodies this role at Dremio, and why he values this designation among modern tech professionals. Our guest then shares the pain points that inspired his choice to join Dremio, what Dremio as an organization is all about, how the company uses generative AI, and the common obstacles that Andrew is faced with at work.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>95</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">da8e9769-45cd-40d9-8ac9-487a3f3ff423</guid>
      <title>Theory Ventures General Partner Tom Tunguz</title>
      <description><![CDATA[<p>Tom shares further thoughts on financing AI tech venture capital and whether or not data centers pose a threat to the relevance of the Cloud, as well as his predictions for the future of GPUs and much more. </p><p>Key Points From This Episode:</p><ul><li>Introducing Tomasz Tunguz, General Partner at Theory Ventures.</li><li>What he is currently working on including AI research and growing the team at Theory.</li><li>How he goes about researching the present to predict the future.</li><li>Why professionals often work in both academia and the field of AI.</li><li>What stands out to Tom when he is looking for companies to invest in.</li><li>Varying applications where an 80% answer has differing relevance.</li><li>The importance of being at the forefront of AI developments as a leader. </li><li>Why the metrics of risk and success used in the past are no longer relevant.</li><li>Tom’s thoughts on whether or not Generative AI will replace search.</li><li>Financing in the AI tech venture capital space.</li><li>Differentiating between the Cloud and data centers.</li><li>Predictions for the future of GPUs.</li><li>Why ‘hello’ is the best opener for a cold email.</li></ul><p>Quotes:</p><p>“Innovation is happening at such a deep technological level and that is at the core of machine learning models.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:03:37]</p><p>“Right now, we’re looking at where [is] there rote work or human toil that can be repeated with AI? That’s one big question where there’s not a really big incumbent.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:05:51]</p><p>“If you are the leader of a team or a department or a business unit or a company, you can not be in a position where you are caught off guard by AI. You need to be on the forefront.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:08:30]</p><p>“The dominant dynamic within consumer products is the least friction in a user experience always wins.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:14:05]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://tomtunguz.com/">Tomasz Tunguz</a></p><p><a href="https://www.linkedin.com/in/tomasztunguz/">Tomasz Tunguz on LinkedIn</a></p><p><a href="https://twitter.com/ttunguz">Tomasz Tunguz on X</a></p><p><a href="https://theory.ventures/">Theory Ventures</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 22 May 2024 21:06:21 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/theory-ventures-general-partner-tom-tunguz-3xgM8NYg</link>
      <content:encoded><![CDATA[<p>Tom shares further thoughts on financing AI tech venture capital and whether or not data centers pose a threat to the relevance of the Cloud, as well as his predictions for the future of GPUs and much more. </p><p>Key Points From This Episode:</p><ul><li>Introducing Tomasz Tunguz, General Partner at Theory Ventures.</li><li>What he is currently working on including AI research and growing the team at Theory.</li><li>How he goes about researching the present to predict the future.</li><li>Why professionals often work in both academia and the field of AI.</li><li>What stands out to Tom when he is looking for companies to invest in.</li><li>Varying applications where an 80% answer has differing relevance.</li><li>The importance of being at the forefront of AI developments as a leader. </li><li>Why the metrics of risk and success used in the past are no longer relevant.</li><li>Tom’s thoughts on whether or not Generative AI will replace search.</li><li>Financing in the AI tech venture capital space.</li><li>Differentiating between the Cloud and data centers.</li><li>Predictions for the future of GPUs.</li><li>Why ‘hello’ is the best opener for a cold email.</li></ul><p>Quotes:</p><p>“Innovation is happening at such a deep technological level and that is at the core of machine learning models.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:03:37]</p><p>“Right now, we’re looking at where [is] there rote work or human toil that can be repeated with AI? That’s one big question where there’s not a really big incumbent.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:05:51]</p><p>“If you are the leader of a team or a department or a business unit or a company, you can not be in a position where you are caught off guard by AI. You need to be on the forefront.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:08:30]</p><p>“The dominant dynamic within consumer products is the least friction in a user experience always wins.” — <a href="https://twitter.com/ttunguz">@tomastungusz</a> [0:14:05]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://tomtunguz.com/">Tomasz Tunguz</a></p><p><a href="https://www.linkedin.com/in/tomasztunguz/">Tomasz Tunguz on LinkedIn</a></p><p><a href="https://twitter.com/ttunguz">Tomasz Tunguz on X</a></p><p><a href="https://theory.ventures/">Theory Ventures</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28988917" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/79a7b5c4-a0c8-4053-b7e1-725d7c8fedae/audio/13d1b7b8-4e03-4e07-b3ea-d5b6408baddd/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Theory Ventures General Partner Tom Tunguz</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:11</itunes:duration>
      <itunes:summary>AI has become the single largest driver of revenue spend for venture capitalists. 

Today’s guest has sat on the board for many companies and currently serves as a General Partner at Theory Ventures. Tom Tunguz joins us to share his predictions for the future of software along with many other insights from his research into AI, including the importance of being at the forefront of AI developments as a leader, changing metrics to predict future success, and whether or not Generative AI is gearing up to replace Google search. </itunes:summary>
      <itunes:subtitle>AI has become the single largest driver of revenue spend for venture capitalists. 

Today’s guest has sat on the board for many companies and currently serves as a General Partner at Theory Ventures. Tom Tunguz joins us to share his predictions for the future of software along with many other insights from his research into AI, including the importance of being at the forefront of AI developments as a leader, changing metrics to predict future success, and whether or not Generative AI is gearing up to replace Google search. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>94</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4c7b9729-3e0b-4675-9e6f-c8b6d235566f</guid>
      <title>Teaching Machines to Smell with Theta Diagnostics CTO Kordel France</title>
      <description><![CDATA[<p>Kordel is the CTO and Founder of Theta Diagnostics, and today he joins us to discuss the work he is doing to develop a sense of smell in AI. We discuss the current and future use cases they’ve been working on, the advancements they’ve made, and how to answer the question “What is smell?” in the context of AI. Kordel also provides a breakdown of their software program Alchemy, their approach to collecting and interpreting data on scents, and how he plans to help machines recognize the context for different smells. To learn all about the fascinating work that Kordel is doing in AI and the science of smell, be sure to tune in!</p><p>Key Points From This Episode:</p><ul><li>Introducing today’s guest, Kordel France.</li><li>How growing up on a farm encouraged his interest in AI.</li><li>An overview of Kordel’s education and the subjects he focused on.</li><li>His work today and how he is teaching machines to smell.</li><li>Existing use cases for smell detection, like the breathalyzer test and smoke detectors.</li><li>The fascinating ways that the ability to pick up certain smells differs between people.</li><li>Unpacking the elusive question “What is smell?”</li><li>How to apply this question to AI development.</li><li>Conceptualizing smell as a pattern that machines can recognize.</li><li>Examples of current and future use cases that Kordel is working on.</li><li>How he trains his devices to recognize smells and compounds.</li><li>A breakdown of their autonomous gas system (AGS).</li><li>How their software program, Alchemy, helps them make sense of their data.</li><li>Kordel’s aspiration to add modalities to his sensors that will create context for smells.</li></ul><p>Quotes:</p><p>“I became interested in machine smell because I didn't see a lot of work being done on that.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:08:25]</p><p>“There's a lot of people that argue we can't actually achieve human-level intelligence until we've met we've incorporated all five senses into an artificial being.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:08:36]</p><p>“To me, a smell is a collection of compounds that represent something that we can recognize. A pattern that we can recognize.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:17:28]</p><p>“Right now we have about three dozen to four dozen compounds that we can with confidence detect.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:19:04]</p><p>“[Our autonomous gas system] is really this interesting system that's hooked up to a bunch of machine learning, that helps calibrate and detect and determine what a smell looks like for a specific use case and breaking that down into its constituent compounds.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:23:20]</p><p>“The success of our device is not just the sensing technology, but also the ability of Alchemy [our software program] to go in and make sense of all of these noise patterns and just make sense of the signals themselves.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:25:41]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://kordelfrance.ai/">Kordel France</a></p><p><a href="https://www.linkedin.com/in/kordel-france-10349811b/">Kordel France on LinkedIn</a></p><p><a href="https://twitter.com/kordelkfrance">Kordel France on X</a></p><p><a href="https://thetadx.ai/">Theta Diagnostics</a></p><p><a href="https://thetadx.ai/alchemy">Alchemy by Theta Diagnostics</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 15 May 2024 18:46:30 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/teaching-machines-to-smell-with-theta-diagnostics-cto-kordel-france-2X2yKDiP</link>
      <content:encoded><![CDATA[<p>Kordel is the CTO and Founder of Theta Diagnostics, and today he joins us to discuss the work he is doing to develop a sense of smell in AI. We discuss the current and future use cases they’ve been working on, the advancements they’ve made, and how to answer the question “What is smell?” in the context of AI. Kordel also provides a breakdown of their software program Alchemy, their approach to collecting and interpreting data on scents, and how he plans to help machines recognize the context for different smells. To learn all about the fascinating work that Kordel is doing in AI and the science of smell, be sure to tune in!</p><p>Key Points From This Episode:</p><ul><li>Introducing today’s guest, Kordel France.</li><li>How growing up on a farm encouraged his interest in AI.</li><li>An overview of Kordel’s education and the subjects he focused on.</li><li>His work today and how he is teaching machines to smell.</li><li>Existing use cases for smell detection, like the breathalyzer test and smoke detectors.</li><li>The fascinating ways that the ability to pick up certain smells differs between people.</li><li>Unpacking the elusive question “What is smell?”</li><li>How to apply this question to AI development.</li><li>Conceptualizing smell as a pattern that machines can recognize.</li><li>Examples of current and future use cases that Kordel is working on.</li><li>How he trains his devices to recognize smells and compounds.</li><li>A breakdown of their autonomous gas system (AGS).</li><li>How their software program, Alchemy, helps them make sense of their data.</li><li>Kordel’s aspiration to add modalities to his sensors that will create context for smells.</li></ul><p>Quotes:</p><p>“I became interested in machine smell because I didn't see a lot of work being done on that.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:08:25]</p><p>“There's a lot of people that argue we can't actually achieve human-level intelligence until we've met we've incorporated all five senses into an artificial being.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:08:36]</p><p>“To me, a smell is a collection of compounds that represent something that we can recognize. A pattern that we can recognize.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:17:28]</p><p>“Right now we have about three dozen to four dozen compounds that we can with confidence detect.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:19:04]</p><p>“[Our autonomous gas system] is really this interesting system that's hooked up to a bunch of machine learning, that helps calibrate and detect and determine what a smell looks like for a specific use case and breaking that down into its constituent compounds.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:23:20]</p><p>“The success of our device is not just the sensing technology, but also the ability of Alchemy [our software program] to go in and make sense of all of these noise patterns and just make sense of the signals themselves.” — <a href="https://twitter.com/kordelkfrance">@kordelkfrance</a> [0:25:41]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://kordelfrance.ai/">Kordel France</a></p><p><a href="https://www.linkedin.com/in/kordel-france-10349811b/">Kordel France on LinkedIn</a></p><p><a href="https://twitter.com/kordelkfrance">Kordel France on X</a></p><p><a href="https://thetadx.ai/">Theta Diagnostics</a></p><p><a href="https://thetadx.ai/alchemy">Alchemy by Theta Diagnostics</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33055660" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/335f8a72-5b19-41dd-8cbc-e9bff81a7f8f/audio/a93192cd-61e9-4c91-949d-48df209c4489/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Teaching Machines to Smell with Theta Diagnostics CTO Kordel France</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:34:25</itunes:duration>
      <itunes:summary>Out of all five human senses, our ability to smell is considered to be the most strongly linked to memory, learning, and emotion, and is arguably the most elusive. Existing AI development has largely been focused on more concrete senses like sight and hearing. But until we’ve incorporated all five senses into an artificial being, it’s unlikely we’ll ever be able to achieve human-level intelligence. That is why today’s guest, Kordel France, has chosen to take on the complex and challenging task of developing machines’ ability to smell. </itunes:summary>
      <itunes:subtitle>Out of all five human senses, our ability to smell is considered to be the most strongly linked to memory, learning, and emotion, and is arguably the most elusive. Existing AI development has largely been focused on more concrete senses like sight and hearing. But until we’ve incorporated all five senses into an artificial being, it’s unlikely we’ll ever be able to achieve human-level intelligence. That is why today’s guest, Kordel France, has chosen to take on the complex and challenging task of developing machines’ ability to smell. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>93</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">f9238620-fc6f-49a3-bb69-68ad802844d5</guid>
      <title>StoneX Group Director of Data Science Elettra Damaggio</title>
      <description><![CDATA[<p>After describing the work done at StoneX and her role at the organization, Elettra explains what drew her to neural networks, defines data science and how she overcame the challenges of learning something new on the job, breaks down what a data scientist needs to succeed, and shares her thoughts on why many still don’t fully understand the industry. Our guest also tells us how she identifies an inadequate data set, the recent innovations that are under construction at StoneX, how to ensure that your AI and ML models are compliant, and the importance of understanding AI as a mere tool to help you solve a problem. </p><p>Key Points From This Episode:</p><ul><li>Elettra Damaggio explains what StoneX Group does and how she ended up there. </li><li>Her professional journey and how she acquired her skills. </li><li>The state of neural networks while she was studying them, why she was drawn to the subject, and how it’s changed. </li><li>StoneX’s data science and ML capabilities when she arrived, and Elettra’s role in the system. </li><li>Her first experience of being thrown into the deep end of data science, and how she swam. </li><li>A data scientist’s tools for success. </li><li>The multidisciplinary leaders and departments that she sought to learn from when she entered data science.  </li><li>Defining data science, and why many do not fully understand the industry. </li><li>How Elettra knows when her data set is inadequate. </li><li>The recent projects and ML models that she’s been working on. </li><li>Exploring the types of guardrails that are needed when training chatbots to be compliant.</li><li>Elettra’s advice to those following a similar career path as hers. </li></ul><p>Quotes:</p><p>“The best thing that you can have as a data scientist to be set up for success is to have a decent data warehouse.” — Elettra Damaggio [0:09:17]</p><p>“I am very much an introverted person. With age, I learned how to talk to people, but that wasn’t [always] the case.” — Elettra Damaggio [0:12:38]</p><p>“In reality, the hard part is to get to the data set – and the way you get to that data set is by being curious about the business you’re working with.” — Elettra Damaggio [0:13:58]</p><p>“[First], you need to have an idea of what is doable, what is not doable, [and] more importantly, what might solve the problem that [the client may] have, and then you can have a conversation with them.” — Elettra Damaggio [0:19:58]</p><p>“AI and ML is not the goal; it’s the tool. The goal is solving the problem.” — Elettra Damaggio [0:28:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/elettradamaggio">Elettra Damaggio on LinkedIn</a></p><p><a href="https://www.stonex.com/">StoneX Group</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 28 Mar 2024 20:33:45 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/stonex-group-director-of-data-science-elettra-damaggio-_8MSm49h</link>
      <content:encoded><![CDATA[<p>After describing the work done at StoneX and her role at the organization, Elettra explains what drew her to neural networks, defines data science and how she overcame the challenges of learning something new on the job, breaks down what a data scientist needs to succeed, and shares her thoughts on why many still don’t fully understand the industry. Our guest also tells us how she identifies an inadequate data set, the recent innovations that are under construction at StoneX, how to ensure that your AI and ML models are compliant, and the importance of understanding AI as a mere tool to help you solve a problem. </p><p>Key Points From This Episode:</p><ul><li>Elettra Damaggio explains what StoneX Group does and how she ended up there. </li><li>Her professional journey and how she acquired her skills. </li><li>The state of neural networks while she was studying them, why she was drawn to the subject, and how it’s changed. </li><li>StoneX’s data science and ML capabilities when she arrived, and Elettra’s role in the system. </li><li>Her first experience of being thrown into the deep end of data science, and how she swam. </li><li>A data scientist’s tools for success. </li><li>The multidisciplinary leaders and departments that she sought to learn from when she entered data science.  </li><li>Defining data science, and why many do not fully understand the industry. </li><li>How Elettra knows when her data set is inadequate. </li><li>The recent projects and ML models that she’s been working on. </li><li>Exploring the types of guardrails that are needed when training chatbots to be compliant.</li><li>Elettra’s advice to those following a similar career path as hers. </li></ul><p>Quotes:</p><p>“The best thing that you can have as a data scientist to be set up for success is to have a decent data warehouse.” — Elettra Damaggio [0:09:17]</p><p>“I am very much an introverted person. With age, I learned how to talk to people, but that wasn’t [always] the case.” — Elettra Damaggio [0:12:38]</p><p>“In reality, the hard part is to get to the data set – and the way you get to that data set is by being curious about the business you’re working with.” — Elettra Damaggio [0:13:58]</p><p>“[First], you need to have an idea of what is doable, what is not doable, [and] more importantly, what might solve the problem that [the client may] have, and then you can have a conversation with them.” — Elettra Damaggio [0:19:58]</p><p>“AI and ML is not the goal; it’s the tool. The goal is solving the problem.” — Elettra Damaggio [0:28:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/elettradamaggio">Elettra Damaggio on LinkedIn</a></p><p><a href="https://www.stonex.com/">StoneX Group</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27699096" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e938272b-6525-4b93-8d77-491bf9eaaadd/audio/9328d692-5908-47d0-8c67-2e229637dfc8/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>StoneX Group Director of Data Science Elettra Damaggio</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:51</itunes:duration>
      <itunes:summary>To help us paint a clearer picture of the inner workings of data science, we are joined today by Elettra Damaggio, the Director of Data Science at StoneX Group Inc., a business that connects other companies and people to various markets. Elettra’s foundations in ML are in neural networks and when she joined StoneX, she was thrown into the deep end of data science. </itunes:summary>
      <itunes:subtitle>To help us paint a clearer picture of the inner workings of data science, we are joined today by Elettra Damaggio, the Director of Data Science at StoneX Group Inc., a business that connects other companies and people to various markets. Elettra’s foundations in ML are in neural networks and when she joined StoneX, she was thrown into the deep end of data science. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>92</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e935af6a-a20c-4b5f-aa5c-eeb654bf4265</guid>
      <title>AWS Director of Product Management Mike Miller</title>
      <description><![CDATA[<p> Mike Miller is the Director of Project Management at AWS, and he joins us today to share about the inspirational AI-powered products and services that are making waves at Amazon, particularly those with generative prompt engineering capabilities. We discuss how Mike and his team choose which products to bring to market, the ins and outs of PartyRock including the challenges of developing it, AWS’s strategy for generative AI, and how the company aims to serve everyone, even those with very little technical knowledge. Mike also explains how customers are using his products and what he’s learned from their behaviors, and we discuss what may lie ahead in the future of generative prompt engineering. </p><p>Key Points From This Episode:</p><ul><li>Mike Miller’s professional background, and how he got into AI and AWS. </li><li>How Mike and his team decide on the products to bring to market for developers. </li><li>Where PartyRock came from and how it fits into AWS’s strategy. </li><li>How AWS decided on the timing to make PartyRock accessible to all.   </li><li>What AWS’s products mean for those with zero coding experience. </li><li>The level of oversight that is required to service clients who have no technical background. </li><li>Taking a closer look at AWS’s strategy for generative AI. </li><li>How customers are using PartyRock, and what Mike has learned from these observations.</li><li>The challenges that the team faced whilst developing PartyRock, and how they persevered. </li><li>Trying to understand the future of generative prompt engineering. </li><li>A reminder that PartyRock is free, so go try it out! </li></ul><p>Quotes:</p><p>“We were working on AI and ML [at Amazon] and discovered that developers learned best when they found relevant, interesting, [and] hands-on projects that they could work on. So, we built DeepLens as a way to provide a fun opportunity to get hands-on with some of these new technologies.” — Mike Miller [0:02:20]</p><p>“When we look at AIML and generative AI, these things are transformative technologies that really require almost a new set of intuition for developers who want to build on these things.” — Mike Miller [0:05:19]</p><p>“In the long run, innovations are going to come from everywhere; from all walks of life, from all skill levels, [and] from different backgrounds. The more of those people that we can provide the tools and the intuition and the power to create innovations, the better off we all are.” — Mike Miller [0:13:58]</p><p>“Given a paintbrush and a blank canvas, most people don’t wind up with The Sistine Chapel. [But] I think it’s important to give people an idea of what is possible.” — Mike Miller [0:25:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/camikemiller/">Mike Miller on LinkedIn</a></p><p><a href="https://aws.amazon.com/">Amazon Web Services</a></p><p><a href="https://pages.awscloud.com/Get-Started-with-Machine-Learning-Introducing-AWS-DeepLens-2019-Edition_2019_0704-MCL_OD.html">AWS DeepLens</a></p><p><a href="https://aws.amazon.com/deepracer/">AWS DeepRacer</a></p><p><a href="https://aws.amazon.com/deepcomposer/">AWS DeepComposer</a></p><p><a href="https://partyrock.aws/">PartyRock</a></p><p><a href="https://aws.amazon.com/bedrock/">Amazon Bedrock</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 22 Mar 2024 17:30:31 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/aws-director-of-product-management-mike-miller-xkmRVlq4</link>
      <content:encoded><![CDATA[<p> Mike Miller is the Director of Project Management at AWS, and he joins us today to share about the inspirational AI-powered products and services that are making waves at Amazon, particularly those with generative prompt engineering capabilities. We discuss how Mike and his team choose which products to bring to market, the ins and outs of PartyRock including the challenges of developing it, AWS’s strategy for generative AI, and how the company aims to serve everyone, even those with very little technical knowledge. Mike also explains how customers are using his products and what he’s learned from their behaviors, and we discuss what may lie ahead in the future of generative prompt engineering. </p><p>Key Points From This Episode:</p><ul><li>Mike Miller’s professional background, and how he got into AI and AWS. </li><li>How Mike and his team decide on the products to bring to market for developers. </li><li>Where PartyRock came from and how it fits into AWS’s strategy. </li><li>How AWS decided on the timing to make PartyRock accessible to all.   </li><li>What AWS’s products mean for those with zero coding experience. </li><li>The level of oversight that is required to service clients who have no technical background. </li><li>Taking a closer look at AWS’s strategy for generative AI. </li><li>How customers are using PartyRock, and what Mike has learned from these observations.</li><li>The challenges that the team faced whilst developing PartyRock, and how they persevered. </li><li>Trying to understand the future of generative prompt engineering. </li><li>A reminder that PartyRock is free, so go try it out! </li></ul><p>Quotes:</p><p>“We were working on AI and ML [at Amazon] and discovered that developers learned best when they found relevant, interesting, [and] hands-on projects that they could work on. So, we built DeepLens as a way to provide a fun opportunity to get hands-on with some of these new technologies.” — Mike Miller [0:02:20]</p><p>“When we look at AIML and generative AI, these things are transformative technologies that really require almost a new set of intuition for developers who want to build on these things.” — Mike Miller [0:05:19]</p><p>“In the long run, innovations are going to come from everywhere; from all walks of life, from all skill levels, [and] from different backgrounds. The more of those people that we can provide the tools and the intuition and the power to create innovations, the better off we all are.” — Mike Miller [0:13:58]</p><p>“Given a paintbrush and a blank canvas, most people don’t wind up with The Sistine Chapel. [But] I think it’s important to give people an idea of what is possible.” — Mike Miller [0:25:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/camikemiller/">Mike Miller on LinkedIn</a></p><p><a href="https://aws.amazon.com/">Amazon Web Services</a></p><p><a href="https://pages.awscloud.com/Get-Started-with-Machine-Learning-Introducing-AWS-DeepLens-2019-Edition_2019_0704-MCL_OD.html">AWS DeepLens</a></p><p><a href="https://aws.amazon.com/deepracer/">AWS DeepRacer</a></p><p><a href="https://aws.amazon.com/deepcomposer/">AWS DeepComposer</a></p><p><a href="https://partyrock.aws/">PartyRock</a></p><p><a href="https://aws.amazon.com/bedrock/">Amazon Bedrock</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="30931174" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/6d2584ae-006a-4e95-a0b7-da699def3158/audio/6c364529-5189-433a-9d12-364534213b9d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AWS Director of Product Management Mike Miller</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:13</itunes:duration>
      <itunes:summary>As generative AI enjoys its time in the spotlight, exciting innovations are being developed for experts and also those with limited technical knowledge, and PartyRock from Amazon Web Services (AWS) is becoming a popular playground for both professional and novice developers. </itunes:summary>
      <itunes:subtitle>As generative AI enjoys its time in the spotlight, exciting innovations are being developed for experts and also those with limited technical knowledge, and PartyRock from Amazon Web Services (AWS) is becoming a popular playground for both professional and novice developers. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>91</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">9d945fba-2fb2-4c04-9efc-fc496089c593</guid>
      <title>Carrier Head of AI Seth Walker</title>
      <description><![CDATA[<p>Key Points From This Episode:</p><ul><li>Welcoming Seth Walker to the podcast.</li><li>The importance of being agile in AI.</li><li>All about Seth’s company, Carrier, and what they do.</li><li>Seth tells us about his background and how he ended up at Carrier.</li><li>How Seth goes about unlocking the power of AI.</li><li>The different levels of success when it comes to AI creation and how to measure them.</li><li>Seth breaks down the different things Carrier focuses on.</li><li>The importance of prompt engineering.</li><li>What makes him excited about the new iterations of machine learning.</li></ul><p>Quotes:</p><p>“In many ways, Carrier is going to be a necessary condition in order for AI to exist.” — Seth Walker [0:04:08]</p><p>“What’s hard about generating value with AI is doing it in a way that is actually actionable toward a specific business problem.” — Seth Walker [0:09:49]</p><p>“One of the things that we’ve found through experimentation with generative AI models is that they’re very sensitive to your content. I mean, there’s a reason that prompt engineering has become such an important skill to have.” — Seth Walker [0:25:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/sethjwalker">Seth Walker on LinkedIn</a></p><p><a href="https://www.corporate.carrier.com/">Carrier</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 15 Mar 2024 18:39:21 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/carrier-head-of-ai-seth-walker-k6TDlLlq</link>
      <content:encoded><![CDATA[<p>Key Points From This Episode:</p><ul><li>Welcoming Seth Walker to the podcast.</li><li>The importance of being agile in AI.</li><li>All about Seth’s company, Carrier, and what they do.</li><li>Seth tells us about his background and how he ended up at Carrier.</li><li>How Seth goes about unlocking the power of AI.</li><li>The different levels of success when it comes to AI creation and how to measure them.</li><li>Seth breaks down the different things Carrier focuses on.</li><li>The importance of prompt engineering.</li><li>What makes him excited about the new iterations of machine learning.</li></ul><p>Quotes:</p><p>“In many ways, Carrier is going to be a necessary condition in order for AI to exist.” — Seth Walker [0:04:08]</p><p>“What’s hard about generating value with AI is doing it in a way that is actually actionable toward a specific business problem.” — Seth Walker [0:09:49]</p><p>“One of the things that we’ve found through experimentation with generative AI models is that they’re very sensitive to your content. I mean, there’s a reason that prompt engineering has become such an important skill to have.” — Seth Walker [0:25:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/sethjwalker">Seth Walker on LinkedIn</a></p><p><a href="https://www.corporate.carrier.com/">Carrier</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33657522" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/2e5e6b76-f09e-41de-bbae-f9b6902148bd/audio/c03b38a9-f2e3-4035-bd4e-249ffe3ce5e7/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Carrier Head of AI Seth Walker</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:03</itunes:duration>
      <itunes:summary>Using Data Science to Solve Business Problems with AI with Seth Walker

Episode 89: Show Notes.

Today on How AI Happens, we are joined by Seth Walker from Carrier, one of the leading companies in generative AI creation, to discuss how he and his team use an agile approach to solving business problems with AI. We delve into how to measure success when it comes to building AI models before our guest stresses the importance of prompt engineering skills. Finally, Seth tells us about all of the new AI inventions he is excited about.</itunes:summary>
      <itunes:subtitle>Using Data Science to Solve Business Problems with AI with Seth Walker

Episode 89: Show Notes.

Today on How AI Happens, we are joined by Seth Walker from Carrier, one of the leading companies in generative AI creation, to discuss how he and his team use an agile approach to solving business problems with AI. We delve into how to measure success when it comes to building AI models before our guest stresses the importance of prompt engineering skills. Finally, Seth tells us about all of the new AI inventions he is excited about.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>90</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">cf3aec5d-b2e9-44b7-9ed9-8a4ebf139c2c</guid>
      <title>Google Cloud&apos;s VP Global AI Business Philip Moyer</title>
      <description><![CDATA[<p> Philip recently had the opportunity to speak with 371 customers from 15 different countries to hear their thoughts, fears, and hopes for AI. Tuning in you’ll hear Philip share his biggest takeaways from these conversations, his opinion on the current state of AI, and his hopes and predictions for the future. Our conversation explores key topics, like government and company attitudes toward AI, why adversarial datasets will need to be audited, and much more. To hear the full scope of our conversation with Philip – and to find out how 2024 resembles 1997 – be sure to tune in today!<br /><br /> </p><p>Key Points From This Episode:</p><ul><li>Some background on Philip Moyer and his role as part of Google’s AI engineering team.</li><li>What he learned from speaking with 371 customers from 15 different countries about AI.</li><li>Philip shares his insights on how governments and companies are approaching AI.</li><li>Recognizing the risks and requirements of models and how to manage them.</li><li>Adversarial datasets; what they are and why they need to be audited.</li><li>Understanding how adversarial datasets can vary between industries.</li><li>A breakdown of Google’s approach to adversarial datasets in different languages.</li><li>The most relevant takeaways from Philip’s cross-continental survey.</li><li>How 2024 resembles the technological and competitive business landscape of 1997.</li><li>Google’s partnership with Nvidia and how they are providing technologies at every layer.</li><li>The new class of applications that come with generative AI.</li><li>Using a company’s proprietary data to train generative AI models.</li><li>The collective challenges we are all facing when it comes to creating generative AI at scale.</li><li>Understanding the vectorization of knowledge and why it will need to be auditable.</li><li>Philip shares what he is most excited about when it comes to AI.</li></ul><p>Quotes:</p><p>“What's been so incredible to me is how forward-thinking – a lot of governments are on this topic [of AI] and their understanding of – the need to be able to make sure that both their citizens as well as their businesses make the best use of artificial intelligence.” — Philip Moyer [0:02:52]</p><p>“Nobody's ahead and nobody's behind. Every single company that I'm speaking to, has about one to five use cases live. And they have hundreds that are on the docket.” — Philip Moyer [0:15:36]</p><p>“All of us are facing the exact same challenges right now of doing [generative AI] at scale.” — Philip Moyer [0:17:03]</p><p><br />“You should just make an assumption that you're going to be somewhere on the order of about 10 to 15% more productive with AI.” — Philip Moyer [0:25:22]<br /><br /> </p><p>“[With AI] I get excited around proficiency and job satisfaction because I really do think – we have an opportunity to make work fun again.” — Philip Moyer [0:27:10]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/phmoyer/">Philip Moyer on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 29 Feb 2024 18:47:08 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/google-clouds-vp-global-ai-business-philip-moyer-_rmhY6k9</link>
      <content:encoded><![CDATA[<p> Philip recently had the opportunity to speak with 371 customers from 15 different countries to hear their thoughts, fears, and hopes for AI. Tuning in you’ll hear Philip share his biggest takeaways from these conversations, his opinion on the current state of AI, and his hopes and predictions for the future. Our conversation explores key topics, like government and company attitudes toward AI, why adversarial datasets will need to be audited, and much more. To hear the full scope of our conversation with Philip – and to find out how 2024 resembles 1997 – be sure to tune in today!<br /><br /> </p><p>Key Points From This Episode:</p><ul><li>Some background on Philip Moyer and his role as part of Google’s AI engineering team.</li><li>What he learned from speaking with 371 customers from 15 different countries about AI.</li><li>Philip shares his insights on how governments and companies are approaching AI.</li><li>Recognizing the risks and requirements of models and how to manage them.</li><li>Adversarial datasets; what they are and why they need to be audited.</li><li>Understanding how adversarial datasets can vary between industries.</li><li>A breakdown of Google’s approach to adversarial datasets in different languages.</li><li>The most relevant takeaways from Philip’s cross-continental survey.</li><li>How 2024 resembles the technological and competitive business landscape of 1997.</li><li>Google’s partnership with Nvidia and how they are providing technologies at every layer.</li><li>The new class of applications that come with generative AI.</li><li>Using a company’s proprietary data to train generative AI models.</li><li>The collective challenges we are all facing when it comes to creating generative AI at scale.</li><li>Understanding the vectorization of knowledge and why it will need to be auditable.</li><li>Philip shares what he is most excited about when it comes to AI.</li></ul><p>Quotes:</p><p>“What's been so incredible to me is how forward-thinking – a lot of governments are on this topic [of AI] and their understanding of – the need to be able to make sure that both their citizens as well as their businesses make the best use of artificial intelligence.” — Philip Moyer [0:02:52]</p><p>“Nobody's ahead and nobody's behind. Every single company that I'm speaking to, has about one to five use cases live. And they have hundreds that are on the docket.” — Philip Moyer [0:15:36]</p><p>“All of us are facing the exact same challenges right now of doing [generative AI] at scale.” — Philip Moyer [0:17:03]</p><p><br />“You should just make an assumption that you're going to be somewhere on the order of about 10 to 15% more productive with AI.” — Philip Moyer [0:25:22]<br /><br /> </p><p>“[With AI] I get excited around proficiency and job satisfaction because I really do think – we have an opportunity to make work fun again.” — Philip Moyer [0:27:10]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/phmoyer/">Philip Moyer on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27392732" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/6150106b-ecd5-4d5b-9495-1ae1c494715c/audio/244d0224-cd50-45d9-8c5d-3243cf9ce01d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Google Cloud&apos;s VP Global AI Business Philip Moyer</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:32</itunes:duration>
      <itunes:summary>Whether you’re an individual or an organization, the recent advancements in AI are bound to have left you with a few mixed feelings: from concerns over the unanticipated harms that could arise with this new technology, to excitement for all the opportunities it could bring. Joining us today to explore this topic is Philip Moyer, VP of Google Cloud&apos;s Global AI Business.</itunes:summary>
      <itunes:subtitle>Whether you’re an individual or an organization, the recent advancements in AI are bound to have left you with a few mixed feelings: from concerns over the unanticipated harms that could arise with this new technology, to excitement for all the opportunities it could bring. Joining us today to explore this topic is Philip Moyer, VP of Google Cloud&apos;s Global AI Business.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>89</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">25069aab-a1fd-4972-9cf3-fa01d27f33e0</guid>
      <title>Meta VP of AI Research Joelle Pineau</title>
      <description><![CDATA[<p>Joelle further discusses the relationship between her work, AI, and the end users of her products as well as her summation of information modalities, world models versus word models, and the role of responsibility in the current high-stakes of technology development.  </p><p>Key Points From This Episode:</p><ul><li>Joelle Pineau's professional background and how she ended up at Meta.</li><li>The aspects of AI robotics that fascinate her the most.</li><li>Why elegance is an important element in Joelle's machine learning systems.</li><li>How asking the right question is the most vital part of research and how to get better at it.</li><li>FRESCO: how Joelle chooses which projects to work on.</li><li>The relationship between her work, AI, and the end users of her final products.</li><li>What success looks like for her and her team at Meta.</li><li>World models versus word models and her summation of information modalities.</li><li>What Joelle thinks about responsibility in the current high-stakes of technology development.</li></ul><p>Quotes:</p><p>“Perhaps, the most important thing in research is asking the right question.” — <a href="https://x.com/jpineau1">@jpineau1</a> [0:05:10]</p><p>“My role isn't to set the problems for [the research team], it's to set the conditions for them to be successful.” —  <a href="https://x.com/jpineau1">@jpineau1</a> [0:07:29]</p><p>“If we're going to push for state-of-the-art on the scientific and engineering aspects, we must push for state-of-the-art in terms of social responsibility.” —  <a href="https://x.com/jpineau1">@jpineau1</a> [0:20:26]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/joelle-pineau-371574141">Joelle Pineau on LinkedIn</a></p><p><a href="https://x.com/jpineau1">Joelle Pineau on X</a></p><p><a href="https://about.meta.com/">Meta</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 16 Feb 2024 22:00:52 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/meta-vp-of-ai-research-joelle-pineau-_nX_kY1X</link>
      <content:encoded><![CDATA[<p>Joelle further discusses the relationship between her work, AI, and the end users of her products as well as her summation of information modalities, world models versus word models, and the role of responsibility in the current high-stakes of technology development.  </p><p>Key Points From This Episode:</p><ul><li>Joelle Pineau's professional background and how she ended up at Meta.</li><li>The aspects of AI robotics that fascinate her the most.</li><li>Why elegance is an important element in Joelle's machine learning systems.</li><li>How asking the right question is the most vital part of research and how to get better at it.</li><li>FRESCO: how Joelle chooses which projects to work on.</li><li>The relationship between her work, AI, and the end users of her final products.</li><li>What success looks like for her and her team at Meta.</li><li>World models versus word models and her summation of information modalities.</li><li>What Joelle thinks about responsibility in the current high-stakes of technology development.</li></ul><p>Quotes:</p><p>“Perhaps, the most important thing in research is asking the right question.” — <a href="https://x.com/jpineau1">@jpineau1</a> [0:05:10]</p><p>“My role isn't to set the problems for [the research team], it's to set the conditions for them to be successful.” —  <a href="https://x.com/jpineau1">@jpineau1</a> [0:07:29]</p><p>“If we're going to push for state-of-the-art on the scientific and engineering aspects, we must push for state-of-the-art in terms of social responsibility.” —  <a href="https://x.com/jpineau1">@jpineau1</a> [0:20:26]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/joelle-pineau-371574141">Joelle Pineau on LinkedIn</a></p><p><a href="https://x.com/jpineau1">Joelle Pineau on X</a></p><p><a href="https://about.meta.com/">Meta</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="20889705" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f3899846-1e8a-49ee-8cfa-9b391fc74249/audio/0ea569df-e577-4379-884a-faaf717e6e31/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Meta VP of AI Research Joelle Pineau</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:21:45</itunes:duration>
      <itunes:summary>Joelle explains how she ended up at Meta and what her role as VP of AI Research entails before telling us what fascinated her most about AI robotics, why elegance is a key factor in her work, how asking the right questions opens the right doors, and the FRESCO philosophy that forms the foundation off of which Joelle makes all her business decisions.</itunes:summary>
      <itunes:subtitle>Joelle explains how she ended up at Meta and what her role as VP of AI Research entails before telling us what fascinated her most about AI robotics, why elegance is a key factor in her work, how asking the right questions opens the right doors, and the FRESCO philosophy that forms the foundation off of which Joelle makes all her business decisions.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>88</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e7d95867-cc5a-4bb2-b635-9f5a3757694c</guid>
      <title>Alberta Machine Intelligence Institute Product Owner Mara Cairo</title>
      <description><![CDATA[<p>Key Points From This Episode:</p><ul><li>Amii’s machine learning project management tool: MLPL.</li><li>Amii’s ultimate goal of building capacity and how it differs from an agency model. </li><li>Asking the right questions to ascertain the appropriate use for AI. </li><li>Instances where AI is not a relevant solution. </li><li>Common challenges people face when adopting AI strategies. </li><li>Mara’s perspective on the education necessary to excel in a career in machine learning.</li></ul><p>Quotes:</p><p>“Amii is all about capacity building, so we’re not a traditional agent in that sense. We are trying to educate and inform industry on how to do this work, with Amii at first, but then without Amii at the end.” — Mara Cairo [0:06:20]</p><p>“We need to ask the right questions. That’s one of the first things we need to do, is to explore where the problems are.” — Mara Cairo [0:07:46]</p><p>“We certainly are comfortable turning certain business problems away if we don’t feel it’s an ethical match or if we truly feel it isn’t a problem that will benefit much from machine learning.” — Mara Cairo [0:11:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.amii.ca/about/our-people/mara-cairo/">Maria Cairo</a></p><p><a href="https://www.linkedin.com/in/mara-c/">Maria Cairo on LinkedIn</a></p><p><a href="https://www.amii.ca/">Alberta Machine Intelligence Unit</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 24 Jan 2024 18:18:08 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/alberta-machine-intelligence-institute-product-owner-mara-cairo-3IwDDtPe</link>
      <content:encoded><![CDATA[<p>Key Points From This Episode:</p><ul><li>Amii’s machine learning project management tool: MLPL.</li><li>Amii’s ultimate goal of building capacity and how it differs from an agency model. </li><li>Asking the right questions to ascertain the appropriate use for AI. </li><li>Instances where AI is not a relevant solution. </li><li>Common challenges people face when adopting AI strategies. </li><li>Mara’s perspective on the education necessary to excel in a career in machine learning.</li></ul><p>Quotes:</p><p>“Amii is all about capacity building, so we’re not a traditional agent in that sense. We are trying to educate and inform industry on how to do this work, with Amii at first, but then without Amii at the end.” — Mara Cairo [0:06:20]</p><p>“We need to ask the right questions. That’s one of the first things we need to do, is to explore where the problems are.” — Mara Cairo [0:07:46]</p><p>“We certainly are comfortable turning certain business problems away if we don’t feel it’s an ethical match or if we truly feel it isn’t a problem that will benefit much from machine learning.” — Mara Cairo [0:11:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.amii.ca/about/our-people/mara-cairo/">Maria Cairo</a></p><p><a href="https://www.linkedin.com/in/mara-c/">Maria Cairo on LinkedIn</a></p><p><a href="https://www.amii.ca/">Alberta Machine Intelligence Unit</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="23794521" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/9d384bd8-b2e8-4685-a6b4-ee659f65cf67/audio/9b54586e-734e-442f-9b80-0c84d3488823/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Alberta Machine Intelligence Institute Product Owner Mara Cairo</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:24:47</itunes:duration>
      <itunes:summary>Mara explains how the team at Amii decides when ML is and isn&apos;t appropriate to use. We discuss Amii’s process and its ultimate goal, along with common challenges their partners face when implementing AI solutions.</itunes:summary>
      <itunes:subtitle>Mara explains how the team at Amii decides when ML is and isn&apos;t appropriate to use. We discuss Amii’s process and its ultimate goal, along with common challenges their partners face when implementing AI solutions.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>87</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">20450295-eab1-40dc-a2b3-ec77dc613d50</guid>
      <title>10 Years of FAIR at Meta with Sama Director of ML Jerome Pasquero</title>
      <description><![CDATA[<p>Jerome discusses Meta's Segment Anything Model, Ego Exo 4D, the nature of Self Supervised Learning, and what it would mean to have a non-language based approach to machine teaching. </p><p>For more, including quotes from Meta Researchers, check out the<a href="https://www.sama.com/blog/4-tech-quotes-from-meta-fairs-10-year-anniversary/" target="_blank"> Sama Blog</a></p>
]]></description>
      <pubDate>Fri, 8 Dec 2023 00:07:48 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/10-years-of-fair-at-meta-with-sama-director-of-ml-jerome-pasquero-vxoq3tv2</link>
      <content:encoded><![CDATA[<p>Jerome discusses Meta's Segment Anything Model, Ego Exo 4D, the nature of Self Supervised Learning, and what it would mean to have a non-language based approach to machine teaching. </p><p>For more, including quotes from Meta Researchers, check out the<a href="https://www.sama.com/blog/4-tech-quotes-from-meta-fairs-10-year-anniversary/" target="_blank"> Sama Blog</a></p>
]]></content:encoded>
      <enclosure length="25854615" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/6058e6fb-ba20-47cb-b9f5-7904c47ec3aa/audio/ddf332b8-43a3-40d9-ab5b-51ef46936a11/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>10 Years of FAIR at Meta with Sama Director of ML Jerome Pasquero</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:55</itunes:duration>
      <itunes:summary>After attending Meta&apos;s event celebrating 10 Years of AI progress at FAIR, Rob shares what he learned with Sama&apos;s Director of Machine Learning, Jerome Pasquero, for some much needed technical insight. </itunes:summary>
      <itunes:subtitle>After attending Meta&apos;s event celebrating 10 Years of AI progress at FAIR, Rob shares what he learned with Sama&apos;s Director of Machine Learning, Jerome Pasquero, for some much needed technical insight. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>86</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e1c05f40-694e-428b-aa06-d106e3455271</guid>
      <title>RoviSys Director of Industrial AI Bryan DeBois</title>
      <description><![CDATA[<p>Bryan discusses what constitutes industrial AI, its applications, and how it differs from standard AI processes. We explore the innovative process of deep reinforcement learning (DRL), replicating human expertise with machines, and the types of AI approaches available. Gain insights into the current trends and the future of generative AI, the existing gaps and opportunities, why  DRL is a game-changer and much more! Join us as we unpack the nuances of industrial AI, its vast potential, and how it is shaping the industries of tomorrow. Tune in now!</p><p>Key Points From This Episode:</p><ul><li>Bryan’s professional background and his role in the company.</li><li>Unpack the concept of “industrial AI” and its various applications.</li><li>The current state and trends of AI in the industrial landscape.</li><li>Deep reinforcement learning (DRL) and how it applies to industrial AI.</li><li>Why deep RL is a game-changer for solving industrial problems.</li><li>Learn about autonomous AI, machine teaching, and explainable AI.</li><li>Discover the approach for replicating human expertise with machines.</li><li>Opportunities and challenges of using machine teaching techniques.</li><li>Differences between monolithic deep learning and standard deep learning.</li><li>His perspective on current trends and the future of generative AI. </li></ul><p>Quotes:</p><p>“We typically look at industrial [AI] as you are either making something or you are moving something.” — Bryan DeBois [0:04:36]</p><p>“One of the key distinctions with deep reinforcement learning is that it learns by doing and not by data.” — Bryan DeBois [0:10:22]</p><p>“Autonomous AI is more of a technique than a technology.” — Bryan DeBois [0:16:00]</p><p>“We have to have [AI] systems that we can count on, that work within constraints, and give right answers every time.” — Bryan DeBois [0:29:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bryan-debois/">Bryan DeBois on LinkedIn</a></p><p><a href="mailto:bryan.debois@rovisys.com">Bryan DeBois Email</a></p><p><a href="https://www.rovisys.com">RoviSys</a></p><p><a href="https://www.rovisys.com/capabilities/industrial-artificial-intelligence/">RoviSys AI</a></p><p><a href="https://www.amazon.com/Designing-Autonomous-AI-Machine-Teaching/dp/1098110757"><i>Designing Autonomous AI</i></a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Tue, 5 Dec 2023 19:19:05 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/rovisys-director-of-industrial-ai-bryan-debois-bp2DoYjz</link>
      <content:encoded><![CDATA[<p>Bryan discusses what constitutes industrial AI, its applications, and how it differs from standard AI processes. We explore the innovative process of deep reinforcement learning (DRL), replicating human expertise with machines, and the types of AI approaches available. Gain insights into the current trends and the future of generative AI, the existing gaps and opportunities, why  DRL is a game-changer and much more! Join us as we unpack the nuances of industrial AI, its vast potential, and how it is shaping the industries of tomorrow. Tune in now!</p><p>Key Points From This Episode:</p><ul><li>Bryan’s professional background and his role in the company.</li><li>Unpack the concept of “industrial AI” and its various applications.</li><li>The current state and trends of AI in the industrial landscape.</li><li>Deep reinforcement learning (DRL) and how it applies to industrial AI.</li><li>Why deep RL is a game-changer for solving industrial problems.</li><li>Learn about autonomous AI, machine teaching, and explainable AI.</li><li>Discover the approach for replicating human expertise with machines.</li><li>Opportunities and challenges of using machine teaching techniques.</li><li>Differences between monolithic deep learning and standard deep learning.</li><li>His perspective on current trends and the future of generative AI. </li></ul><p>Quotes:</p><p>“We typically look at industrial [AI] as you are either making something or you are moving something.” — Bryan DeBois [0:04:36]</p><p>“One of the key distinctions with deep reinforcement learning is that it learns by doing and not by data.” — Bryan DeBois [0:10:22]</p><p>“Autonomous AI is more of a technique than a technology.” — Bryan DeBois [0:16:00]</p><p>“We have to have [AI] systems that we can count on, that work within constraints, and give right answers every time.” — Bryan DeBois [0:29:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bryan-debois/">Bryan DeBois on LinkedIn</a></p><p><a href="mailto:bryan.debois@rovisys.com">Bryan DeBois Email</a></p><p><a href="https://www.rovisys.com">RoviSys</a></p><p><a href="https://www.rovisys.com/capabilities/industrial-artificial-intelligence/">RoviSys AI</a></p><p><a href="https://www.amazon.com/Designing-Autonomous-AI-Machine-Teaching/dp/1098110757"><i>Designing Autonomous AI</i></a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31021453" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/76464eb6-540c-43f9-bfde-336330f9e044/audio/4b67b741-d8a2-41c8-8b24-efcf56872aeb/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>RoviSys Director of Industrial AI Bryan DeBois</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:18</itunes:duration>
      <itunes:summary>The application of AI technologies within industry is growing in popularity. It has the capacity to transform traditional industries while paving the way for innovation in a rapidly evolving landscape. In this episode, we are joined by Bryan DeBois, Director of Industrial AI at RoviSys, to discuss the realm of Industrial AI and its range of applications. RoviSys is a company that specializes in providing automation and information solutions to various industries. It focuses on developing solutions where technical expertise and vendor independence intersect. In our conversation, we discuss the concept of industrial AI, its applications, and how it differs from standard AI processes.</itunes:summary>
      <itunes:subtitle>The application of AI technologies within industry is growing in popularity. It has the capacity to transform traditional industries while paving the way for innovation in a rapidly evolving landscape. In this episode, we are joined by Bryan DeBois, Director of Industrial AI at RoviSys, to discuss the realm of Industrial AI and its range of applications. RoviSys is a company that specializes in providing automation and information solutions to various industries. It focuses on developing solutions where technical expertise and vendor independence intersect. In our conversation, we discuss the concept of industrial AI, its applications, and how it differs from standard AI processes.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>85</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">ce53418e-f259-48a9-8ae3-331945d0f1bf</guid>
      <title>ML Pulse Report with Voxel51 CSO Jason Corso and Sama VP Duncan Curtis</title>
      <description><![CDATA[<p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/">2023 ML Pulse Report</a></p><p> </p><p>Joining us today are our panelists, Duncan Curtis, SVP of AI products and technology at Sama, and Jason Corso, a professor of robotics, electrical engineering, and computer science at the University of Michigan. Jason is also the chief science officer at Voxel51, an AI software company specializing in developer tools for machine learning. We use today’s conversation to discuss the findings of the latest Machine Learning (ML) Pulse report, published each year by our friends at Sama. This year’s  report focused on the role of generative AI by surveying thousands of practitioners in this space. Its findings include feedback on how respondents are measuring their model’s effectiveness, how confident they feel that their models will survive production, and whether they believe generative AI is worth the hype. Tuning in you’ll hear our panelists’ thoughts on key questions in the report and its findings, along with their suggested solutions for some of the biggest challenges faced by professionals in the AI space today. We also get into a bunch of fascinating topics like the opportunities presented by synthetic data, the latent space in language processing approaches, the iterative nature of model development, and much more. Be sure to tune in for all the latest insights on the ML Pulse Report!</p><p>Key Points From This Episode:</p><ul><li>Introducing today’s panelists, Duncan Curtis and Jason Corso.</li><li>An overview of what the Machine Learning (ML) Pulse report focuses on.</li><li>Breaking down what the term generative means in AI.</li><li>Our thoughts on key findings from the ML Pulse Report.</li><li>What respondents, and our panelists, think of hype around generative AI.</li><li>Unpacking one of the biggest advances in generative AI: accessibility.</li><li>Insights on cloud versus local in an AI context.</li><li>Generative AI use cases in the field of computer vision.</li><li>The powerful opportunities presented by synthetic data.</li><li>Why the role of human feedback in synthetic data is so important.</li><li>Finding a middle ground between human language and machine understanding.</li><li>Unpacking the notion of latent space in language processing approaches.</li><li>How confident respondents feel that their models will survive production.</li><li>The challenges of predicting how well a model will perform.</li><li>An overview of the biggest challenges reported by respondents.</li><li>Suggested solutions from panelists on key challenges from the report.</li><li>How respondents are measuring the effectiveness of their models.</li><li>What Duncan and Jason focus on to measure success.</li><li>Career advice from our panelists on making meaningful contributions to this space.</li></ul><p>Quotes:</p><p>“It's really hard to know how well your model is going to do.” — Jason Corso [0:27:10]</p><p>“With debugging and detecting errors in your data, I would definitely say look at some of the tooling that can enable you to move more quickly and understand your data better.” — Duncan Curtis [0:33:55]</p><p>“Work with experts – there's no replacement for good experience when it comes to actually boxing in a problem, especially in AI.” — Jason Corso [0:35:37]</p><p>“It's not just about how your model performs. It's how your model performs when it's interacting with the end user.” — Duncan Curtis [0:41:11]</p><p>“Remember, what we do in this field, and in all fields really, is by humans, for humans, and with humans. And I think if you miss that idea [then] you will not achieve – either your own potential, the group you're working with, or the tool.” — Jason Corso [0:48:20]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/duncan-curtis/">Duncan Curtis on LinkedIn</a><br /><a href="https://web.eecs.umich.edu/~jjcorso/">Jason Corso</a></p><p><a href="https://www.linkedin.com/in/jason-corso/">Jason Corso on LinkedIn</a></p><p><a href="https://voxel51.com/">Voxel51</a></p><p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/">2023 ML Pulse Report</a></p><p><a href="https://openai.com/chatgpt">ChatGPT</a></p><p><a href="https://bard.google.com/">Bard</a></p><p><a href="https://openai.com/dall-e-3">DALL·E 3</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 22 Nov 2023 17:55:44 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ml-pulse-report-with-voxel51-cso-jason-corso-and-sama-vp-duncan-jones-DrILIlL_</link>
      <content:encoded><![CDATA[<p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/">2023 ML Pulse Report</a></p><p> </p><p>Joining us today are our panelists, Duncan Curtis, SVP of AI products and technology at Sama, and Jason Corso, a professor of robotics, electrical engineering, and computer science at the University of Michigan. Jason is also the chief science officer at Voxel51, an AI software company specializing in developer tools for machine learning. We use today’s conversation to discuss the findings of the latest Machine Learning (ML) Pulse report, published each year by our friends at Sama. This year’s  report focused on the role of generative AI by surveying thousands of practitioners in this space. Its findings include feedback on how respondents are measuring their model’s effectiveness, how confident they feel that their models will survive production, and whether they believe generative AI is worth the hype. Tuning in you’ll hear our panelists’ thoughts on key questions in the report and its findings, along with their suggested solutions for some of the biggest challenges faced by professionals in the AI space today. We also get into a bunch of fascinating topics like the opportunities presented by synthetic data, the latent space in language processing approaches, the iterative nature of model development, and much more. Be sure to tune in for all the latest insights on the ML Pulse Report!</p><p>Key Points From This Episode:</p><ul><li>Introducing today’s panelists, Duncan Curtis and Jason Corso.</li><li>An overview of what the Machine Learning (ML) Pulse report focuses on.</li><li>Breaking down what the term generative means in AI.</li><li>Our thoughts on key findings from the ML Pulse Report.</li><li>What respondents, and our panelists, think of hype around generative AI.</li><li>Unpacking one of the biggest advances in generative AI: accessibility.</li><li>Insights on cloud versus local in an AI context.</li><li>Generative AI use cases in the field of computer vision.</li><li>The powerful opportunities presented by synthetic data.</li><li>Why the role of human feedback in synthetic data is so important.</li><li>Finding a middle ground between human language and machine understanding.</li><li>Unpacking the notion of latent space in language processing approaches.</li><li>How confident respondents feel that their models will survive production.</li><li>The challenges of predicting how well a model will perform.</li><li>An overview of the biggest challenges reported by respondents.</li><li>Suggested solutions from panelists on key challenges from the report.</li><li>How respondents are measuring the effectiveness of their models.</li><li>What Duncan and Jason focus on to measure success.</li><li>Career advice from our panelists on making meaningful contributions to this space.</li></ul><p>Quotes:</p><p>“It's really hard to know how well your model is going to do.” — Jason Corso [0:27:10]</p><p>“With debugging and detecting errors in your data, I would definitely say look at some of the tooling that can enable you to move more quickly and understand your data better.” — Duncan Curtis [0:33:55]</p><p>“Work with experts – there's no replacement for good experience when it comes to actually boxing in a problem, especially in AI.” — Jason Corso [0:35:37]</p><p>“It's not just about how your model performs. It's how your model performs when it's interacting with the end user.” — Duncan Curtis [0:41:11]</p><p>“Remember, what we do in this field, and in all fields really, is by humans, for humans, and with humans. And I think if you miss that idea [then] you will not achieve – either your own potential, the group you're working with, or the tool.” — Jason Corso [0:48:20]</p><p>Links Mentioned in Today’s Episode:</p><p><br /><a href="https://www.linkedin.com/in/duncan-curtis/">Duncan Curtis on LinkedIn</a><br /><a href="https://web.eecs.umich.edu/~jjcorso/">Jason Corso</a></p><p><a href="https://www.linkedin.com/in/jason-corso/">Jason Corso on LinkedIn</a></p><p><a href="https://voxel51.com/">Voxel51</a></p><p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/">2023 ML Pulse Report</a></p><p><a href="https://openai.com/chatgpt">ChatGPT</a></p><p><a href="https://bard.google.com/">Bard</a></p><p><a href="https://openai.com/dall-e-3">DALL·E 3</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="47889868" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/cf1f9c05-179b-42f0-a0cb-29f108164a04/audio/3d8465b5-aa1e-4f7f-b049-5dde724dd254/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>ML Pulse Report with Voxel51 CSO Jason Corso and Sama VP Duncan Curtis</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:49:53</itunes:duration>
      <itunes:summary>Jason &amp; Duncan discuss the results of Sama&apos;s ML Pulse Report, focusing on how to measure model effectiveness, how to increase confidence when moving models into production, and whether they believe generative AI is worth the hype. </itunes:summary>
      <itunes:subtitle>Jason &amp; Duncan discuss the results of Sama&apos;s ML Pulse Report, focusing on how to measure model effectiveness, how to increase confidence when moving models into production, and whether they believe generative AI is worth the hype. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>84</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">0b2bc2c4-0e64-4573-ad90-bf5daf189261</guid>
      <title>AMD Senior Director of AI Software Ian Ferreira</title>
      <description><![CDATA[<p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/?utm_campaign=2023%20ML%20Pulse%20Report&utm_content=269533535&utm_medium=social&utm_source=podcast" target="_blank">Sama 2023 ML Pulse Report</a></p><p><a href="https://www.linkedin.com/events/7127380119060434945/about/" target="_blank">ML Pulse Report: How AI Happens Live Webinar</a></p><p><a href="https://www.amd.com/en/corporate/events/advancing-ai.html" target="_blank">AMD's Advancing AI Event</a></p><p>Our guest today is Ian Ferreira,  the Chief Product Officer for Artificial Intelligence over at Core Scientific until they were purchased by his current employer Advanced Micro Devices, AMD, where he is now the Senior Director of AI Software. In our conversation, we talk about when in his career he shifted his focus to AI, his thoughts on the nobility of ChatGPT and applications beyond advertising for AI, and he touches on the scary aspect of Large Language Models (LLMs). We explore the possibility of replacing our standard conceptions of search, how he conceptualizes his role at AMD, and Ian shares his insights and thoughts on the “Arms Race for GPUs”. Be sure not to miss out on this episode as Ian shares valuable insights from his perspective as the Senior Director of AI Software at AMD. </p><p>Key Points From This Episode:</p><ul><li>An introduction to our guest on today’s episode: Ian Ferreira.</li><li>The point in his career when AI became the main focus. </li><li>His thoughts on the idea that ChatGPT is noble. </li><li>The scary aspect of Large Language Models (LLMs).</li><li>The possibilities of replacing our standard conceptions of search.</li><li>Ian shares how he conceptualizes his role as Senior Director of AI Software at AMD, and the projects they’re currently working on. </li><li>His thoughts on the “Arms Race” for GPUs. </li><li>Ian underlines their partnership with research companies like the Allen Institute.</li><li>Attempting to make a powerful GPU model easily available to the general public.</li><li>He explains what he means by a sovereign model. </li><li>Ian talks about AMD’s upcoming events and announcements. </li></ul><p>Quotes:</p><p>“It’s just remarkable, the potential of AI —and now I’m fully in it and I think it’s a game-changer.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:03:41]</p><p>“There are significantly more noble applications than advertising for AI and ChatGPT was great in that it put a face on AI for a lot of people who couldn’t really get their heads wrapped around [AI].” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:04:25]</p><p>“An LLM allows you to have a natural conversation with the search agent, so to speak.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:09:21]</p><p>“All our stuff is open-sourced. AMD has a strong ethos, both in open-source and in partnerships. We don’t compete with our customers, and so being open allows you to go and look at all our code and make sure that whatever you are going to deploy is something you’ve looked at.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:12:15]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.amd.com/en/corporate/events/advancing-ai.html" target="_blank">Advancing AI Event</a></p><p><a href="https://www.linkedin.com/in/ianfe/">Ian Ferreira on LinkedIn</a></p><p><a href="https://twitter.com/Ianfe">Ian Ferreira on X</a></p><p><a href="https://www.amd.com/en.html">AMD</a></p><p><a href="https://www.amd.com/en/graphics/servers-solutions-rocm">AMD Software Stack</a></p><p><a href="https://huggingface.co/">Hugging Face</a></p><p><a href="https://alleninstitute.org/">Allen Institute</a></p><p><a href="https://open.ai/">Open AI</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 10 Nov 2023 18:46:05 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/amd-senior-director-of-ai-software-ian-ferreira-7TOJwu9z</link>
      <content:encoded><![CDATA[<p><a href="https://www.sama.com/ebook/2023-ml-pulse-report/?utm_campaign=2023%20ML%20Pulse%20Report&utm_content=269533535&utm_medium=social&utm_source=podcast" target="_blank">Sama 2023 ML Pulse Report</a></p><p><a href="https://www.linkedin.com/events/7127380119060434945/about/" target="_blank">ML Pulse Report: How AI Happens Live Webinar</a></p><p><a href="https://www.amd.com/en/corporate/events/advancing-ai.html" target="_blank">AMD's Advancing AI Event</a></p><p>Our guest today is Ian Ferreira,  the Chief Product Officer for Artificial Intelligence over at Core Scientific until they were purchased by his current employer Advanced Micro Devices, AMD, where he is now the Senior Director of AI Software. In our conversation, we talk about when in his career he shifted his focus to AI, his thoughts on the nobility of ChatGPT and applications beyond advertising for AI, and he touches on the scary aspect of Large Language Models (LLMs). We explore the possibility of replacing our standard conceptions of search, how he conceptualizes his role at AMD, and Ian shares his insights and thoughts on the “Arms Race for GPUs”. Be sure not to miss out on this episode as Ian shares valuable insights from his perspective as the Senior Director of AI Software at AMD. </p><p>Key Points From This Episode:</p><ul><li>An introduction to our guest on today’s episode: Ian Ferreira.</li><li>The point in his career when AI became the main focus. </li><li>His thoughts on the idea that ChatGPT is noble. </li><li>The scary aspect of Large Language Models (LLMs).</li><li>The possibilities of replacing our standard conceptions of search.</li><li>Ian shares how he conceptualizes his role as Senior Director of AI Software at AMD, and the projects they’re currently working on. </li><li>His thoughts on the “Arms Race” for GPUs. </li><li>Ian underlines their partnership with research companies like the Allen Institute.</li><li>Attempting to make a powerful GPU model easily available to the general public.</li><li>He explains what he means by a sovereign model. </li><li>Ian talks about AMD’s upcoming events and announcements. </li></ul><p>Quotes:</p><p>“It’s just remarkable, the potential of AI —and now I’m fully in it and I think it’s a game-changer.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:03:41]</p><p>“There are significantly more noble applications than advertising for AI and ChatGPT was great in that it put a face on AI for a lot of people who couldn’t really get their heads wrapped around [AI].” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:04:25]</p><p>“An LLM allows you to have a natural conversation with the search agent, so to speak.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:09:21]</p><p>“All our stuff is open-sourced. AMD has a strong ethos, both in open-source and in partnerships. We don’t compete with our customers, and so being open allows you to go and look at all our code and make sure that whatever you are going to deploy is something you’ve looked at.” — <a href="https://twitter.com/Ianfe">@Ianfe</a> [0:12:15]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.amd.com/en/corporate/events/advancing-ai.html" target="_blank">Advancing AI Event</a></p><p><a href="https://www.linkedin.com/in/ianfe/">Ian Ferreira on LinkedIn</a></p><p><a href="https://twitter.com/Ianfe">Ian Ferreira on X</a></p><p><a href="https://www.amd.com/en.html">AMD</a></p><p><a href="https://www.amd.com/en/graphics/servers-solutions-rocm">AMD Software Stack</a></p><p><a href="https://huggingface.co/">Hugging Face</a></p><p><a href="https://alleninstitute.org/">Allen Institute</a></p><p><a href="https://open.ai/">Open AI</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27021166" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e3f5a202-fc04-4709-8eae-3abc19715ee2/audio/8d920965-be54-475f-90d1-9e59645b16f0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AMD Senior Director of AI Software Ian Ferreira</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:08</itunes:duration>
      <itunes:summary>Ian shares how AMD partnerships are making powerful models available to the general public and large tech companies alike. Also, will LLMs disrupt search? Clippy is back, and he&apos;s BAD.</itunes:summary>
      <itunes:subtitle>Ian shares how AMD partnerships are making powerful models available to the general public and large tech companies alike. Also, will LLMs disrupt search? Clippy is back, and he&apos;s BAD.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>83</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">0f91525d-2463-4c77-8973-fd558ac602b5</guid>
      <title>GM for Amazon CodeWhisperer Doug Seven</title>
      <description><![CDATA[<p>Generative AI is becoming more common in our lives as the technology grows and evolves. There are now AI companions to help other AI models execute their tasks more efficiently, and Amazon CodeWhisperer (ACW) is among the best in the game. We are joined today by the General Manager of Amazon CodeWhisperer and Director of Software Development at Amazon Web Services (AWS), Doug Seven. We discuss how Doug and his team are able to remain agile in such a huge organization like Amazon before getting a crash course on the two-pizza-team philosophy and everything you need to know about ACW and how it works. Then, we dive into the characteristics that make up a generative AI model, why Amazon felt it necessary to create its own AI companion, why AI is not here to take our jobs, how Doug and his team ensure that ACW is safe and responsible, and how generative AI will become common in most households much sooner than we may think.  </p><p> </p><p>Key Points From This Episode:</p><ul><li>Introducing the Director of Software Development and General Manager of Amazon CodeWhisperer at Amazon Web Services, Doug Seven. </li><li>A day in the life of Doug in his role at Amazon. </li><li>What his team currently looks like.</li><li>Whether he and his team retain their agility in a massive organization like Amazon. </li><li>A crash course on the two-pizza-team philosophy. </li><li>How Doug ended up at Amazon Web Services (AWS) and leading ACW. </li><li>What ACW is, how it works, and why you need it for you and your business. </li><li>Assessing if generative AI models need to produce new code to be considered generative. </li><li>Why Amazon felt it pertinent to create its own AI companion in ACW. </li><li>How to use ACW to its full potential. </li><li>The way recommendations change and improve once ACW has access to your code base. </li><li>Examples that reiterate how AI is not here to take your job but to do the jobs you hate.</li><li>Guardrails that ACW is putting up to ensure that it remains safe, secure, and responsible. </li><li>How generative AI will become more accessible to the masses as it evolves. </li></ul>
]]></description>
      <pubDate>Tue, 31 Oct 2023 21:57:52 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/gm-for-amazon-codewhisperer-doug-seven-EzMQUthZ</link>
      <content:encoded><![CDATA[<p>Generative AI is becoming more common in our lives as the technology grows and evolves. There are now AI companions to help other AI models execute their tasks more efficiently, and Amazon CodeWhisperer (ACW) is among the best in the game. We are joined today by the General Manager of Amazon CodeWhisperer and Director of Software Development at Amazon Web Services (AWS), Doug Seven. We discuss how Doug and his team are able to remain agile in such a huge organization like Amazon before getting a crash course on the two-pizza-team philosophy and everything you need to know about ACW and how it works. Then, we dive into the characteristics that make up a generative AI model, why Amazon felt it necessary to create its own AI companion, why AI is not here to take our jobs, how Doug and his team ensure that ACW is safe and responsible, and how generative AI will become common in most households much sooner than we may think.  </p><p> </p><p>Key Points From This Episode:</p><ul><li>Introducing the Director of Software Development and General Manager of Amazon CodeWhisperer at Amazon Web Services, Doug Seven. </li><li>A day in the life of Doug in his role at Amazon. </li><li>What his team currently looks like.</li><li>Whether he and his team retain their agility in a massive organization like Amazon. </li><li>A crash course on the two-pizza-team philosophy. </li><li>How Doug ended up at Amazon Web Services (AWS) and leading ACW. </li><li>What ACW is, how it works, and why you need it for you and your business. </li><li>Assessing if generative AI models need to produce new code to be considered generative. </li><li>Why Amazon felt it pertinent to create its own AI companion in ACW. </li><li>How to use ACW to its full potential. </li><li>The way recommendations change and improve once ACW has access to your code base. </li><li>Examples that reiterate how AI is not here to take your job but to do the jobs you hate.</li><li>Guardrails that ACW is putting up to ensure that it remains safe, secure, and responsible. </li><li>How generative AI will become more accessible to the masses as it evolves. </li></ul>
]]></content:encoded>
      <enclosure length="27944438" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/09a7fe31-4c94-4557-ab94-8e9fb7108a04/audio/cfe471b4-d0f3-4195-a253-91bf7790b5bd/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>GM for Amazon CodeWhisperer Doug Seven</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:06</itunes:duration>
      <itunes:summary>Doug explains how Amazon CodeWhisperer was designed to save engineering time, and reflects on what it means for something to be truly &quot;generative&quot;</itunes:summary>
      <itunes:subtitle>Doug explains how Amazon CodeWhisperer was designed to save engineering time, and reflects on what it means for something to be truly &quot;generative&quot;</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>82</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">924a2457-cdd3-4395-a954-b95853fdab86</guid>
      <title>Bell Senior Data Scientist Dalia Shanshal</title>
      <description><![CDATA[<p>In today’s episode, we are joined by Dalia Shanshal, Senior Data Scientist at Bell, Canada's largest communications company that offers advanced broadband wireless, Internet, TV, media, and business communications services. With over five years of experience working on hands-on projects, Dalia has a diverse background in data science and AI. We start our conversation by talking about the recent GeekFest Conference, what it is about, and key takeaways from the event. We then delve into her professional career journey and how a fascinating article inspired her to become a data scientist. During our conversation, Dalia reflects on the evolving nature of data science, discussing the skills and qualities that are now more crucial than ever for excelling in the field. We also explore why creativity is essential for problem-solving, the value of starting simple, and how to stand out as a data scientist before she explains her unique root cause analysis framework.Key Points From This Episode:</p><ul><li>Highlights of the recent Bell GeekFest Conference.</li><li>AI-related topics focused on at the event.</li><li>Why Bell’s GeekFest is only an internal conference.</li><li>Details about Bell and Dalia’s role at the company.</li><li>Her background and professional career journey.</li><li>How the role of a data scientist has changed over time.</li><li>The importance of creativity in problem-solving.</li><li>Overview of why quality data is fundamental.</li><li>Qualities of a good data scientist.</li><li>The research side of data science.</li><li>Dalia reveals her root cause analysis framework.</li><li>Exciting projects she is currently working on.</li></ul><p>Tweetables:</p><p>“What I do is to try leverage AI and machine learning to speed up and fastrack investigative processes.” — Dalia Shanshal [0:06:52]</p><p>“Data scientists today are key in business decisions. We always need business decisions based on facts and data, so the ability to mine that data is super important.” — Dalia Shanshal [0:08:35]</p><p>“The most important skill set [of a data scientist] is to be able to [develop] creative approaches to problem-solving. That is why we are called scientists.” — Dalia Shanshal [0:11:24]</p><p>“I think it is very important for data scientists to keep up to date with the science. Whenever I am [faced] with a problem, I start by researching what is out there.” — Dalia Shanshal [0:22:18]</p><p>“One of the things that is really important to me is making sure that whatever [data scientists] are doing has an impact.” — Dalia Shanshal [0:33:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.d-dataresearch.com">Dalia Shanshal</a></p><p><a href="https://www.linkedin.com/in/dalia-shanshal-79769bba/">Dalia Shanshal on LinkedIn</a></p><p><a href="https://github.com/Dalia-Sh">Dalia Shanshal on GitHub</a></p><p><a href="mailto:%20daliashanshal@d-dataresearch.com">Dalia Shanshal Email</a></p><p><a href="https://www.bell.ca">Bell</a></p><p><a href="https://www.bellntsconference.ca/become-a-sponsor/">GeekFest 2023 | Bell</a></p><p><a href="https://www.caiac.ca/en/conferences/canadianai-2023/home">Canadian Conference on Artificial Intelligence (CANAI)</a></p><p><a href="https://caiac.pubpub.org/pub/jpm6os03/release/1">‘Towards an Automated Framework of Root Cause Analysis in the Canadian Telecom Industry’</a></p><p><a href="https://saulnassau.com/ohm-dome/">Ohm Dome Project</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 27 Oct 2023 17:46:08 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/bell-senior-data-scientist-dalia-shanshal-_Q7DmYN9</link>
      <content:encoded><![CDATA[<p>In today’s episode, we are joined by Dalia Shanshal, Senior Data Scientist at Bell, Canada's largest communications company that offers advanced broadband wireless, Internet, TV, media, and business communications services. With over five years of experience working on hands-on projects, Dalia has a diverse background in data science and AI. We start our conversation by talking about the recent GeekFest Conference, what it is about, and key takeaways from the event. We then delve into her professional career journey and how a fascinating article inspired her to become a data scientist. During our conversation, Dalia reflects on the evolving nature of data science, discussing the skills and qualities that are now more crucial than ever for excelling in the field. We also explore why creativity is essential for problem-solving, the value of starting simple, and how to stand out as a data scientist before she explains her unique root cause analysis framework.Key Points From This Episode:</p><ul><li>Highlights of the recent Bell GeekFest Conference.</li><li>AI-related topics focused on at the event.</li><li>Why Bell’s GeekFest is only an internal conference.</li><li>Details about Bell and Dalia’s role at the company.</li><li>Her background and professional career journey.</li><li>How the role of a data scientist has changed over time.</li><li>The importance of creativity in problem-solving.</li><li>Overview of why quality data is fundamental.</li><li>Qualities of a good data scientist.</li><li>The research side of data science.</li><li>Dalia reveals her root cause analysis framework.</li><li>Exciting projects she is currently working on.</li></ul><p>Tweetables:</p><p>“What I do is to try leverage AI and machine learning to speed up and fastrack investigative processes.” — Dalia Shanshal [0:06:52]</p><p>“Data scientists today are key in business decisions. We always need business decisions based on facts and data, so the ability to mine that data is super important.” — Dalia Shanshal [0:08:35]</p><p>“The most important skill set [of a data scientist] is to be able to [develop] creative approaches to problem-solving. That is why we are called scientists.” — Dalia Shanshal [0:11:24]</p><p>“I think it is very important for data scientists to keep up to date with the science. Whenever I am [faced] with a problem, I start by researching what is out there.” — Dalia Shanshal [0:22:18]</p><p>“One of the things that is really important to me is making sure that whatever [data scientists] are doing has an impact.” — Dalia Shanshal [0:33:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.d-dataresearch.com">Dalia Shanshal</a></p><p><a href="https://www.linkedin.com/in/dalia-shanshal-79769bba/">Dalia Shanshal on LinkedIn</a></p><p><a href="https://github.com/Dalia-Sh">Dalia Shanshal on GitHub</a></p><p><a href="mailto:%20daliashanshal@d-dataresearch.com">Dalia Shanshal Email</a></p><p><a href="https://www.bell.ca">Bell</a></p><p><a href="https://www.bellntsconference.ca/become-a-sponsor/">GeekFest 2023 | Bell</a></p><p><a href="https://www.caiac.ca/en/conferences/canadianai-2023/home">Canadian Conference on Artificial Intelligence (CANAI)</a></p><p><a href="https://caiac.pubpub.org/pub/jpm6os03/release/1">‘Towards an Automated Framework of Root Cause Analysis in the Canadian Telecom Industry’</a></p><p><a href="https://saulnassau.com/ohm-dome/">Ohm Dome Project</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29742889" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/9c00ee79-e89d-4f51-8647-6ef3ad294f68/audio/16be9ec2-2006-40f3-b4e4-843aa462a2d6/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Bell Senior Data Scientist Dalia Shanshal</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:58</itunes:duration>
      <itunes:summary>Dalia reflects on the evolving nature of data science, discussing the skills and qualities that are now more crucial than ever for excelling in the field. We also explore why creativity is essential for problem-solving, the value of starting simple, and how to stand out as a data scientist before she explains her unique root cause analysis framework. </itunes:summary>
      <itunes:subtitle>Dalia reflects on the evolving nature of data science, discussing the skills and qualities that are now more crucial than ever for excelling in the field. We also explore why creativity is essential for problem-solving, the value of starting simple, and how to stand out as a data scientist before she explains her unique root cause analysis framework. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>81</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e8130b7b-0f5c-44cc-a4fc-3805a55efc97</guid>
      <title>AgriSynth Founder &amp; CEO Colin Herbert</title>
      <description><![CDATA[<p> </p><p><a href="https://imgur.com/a/1EQ1vAj" target="_blank">EXAMPLE: AgriSynth Synthetic Data-- Weeds as Seen By AI</a></p><p>Data is the backbone of agricultural innovation when it comes to increasing yields, reducing pests, and improving overall efficiency, but generating high-quality real-world data is an expensive and time-consuming process. Today, we are joined by Colin Herbert, the CEO and Founder of AgriSynth, to find out how the advent of synthetic data will ultimately transform the industry for the better. AgriSynth is revolutionizing how AI can be trained for agricultural solutions using synthetic imagery.  He also gives us an overview of his non-linear career journey (from engineering to medical school to agriculture, then through clinical trials and back to agriculture with a detour in Deep Learning), shares the fascinating origin story of AgriSynth, and more. </p><p>Key Points From This Episode:</p><ul><li>Colin’s career trajectory and the surprising role that Star Wars plays in AgriSynth’s origin story.</li><li>Reasons that the use of AI in agriculture is still limited, despite its vast potential.</li><li>Ways that AgriSynth seeks to bridge these gaps in the industry using synthetic imagery.</li><li>Insight into the vast amount of parameters and values required.</li><li>What synthetic data looks like in AgriSynth’s “closed-loop train/test system.”</li><li>Why photorealistic data is completely unnecessary for AI models.</li><li>How AgriSynth is working towards eliminating human cognition from the process.</li><li>Dispelling some of the criticism often directed at synthetic data.</li><li>Just a few of the many applications for AgriSynth’s tech and how their output will evolve.</li><li>Why real-world images aren’t necessarily superior to synthetic data!</li></ul><p>Quotes:</p><p>“The complexity of biological images and agricultural images is way beyond driverless cars and most other applications [of AI].” — Colin Herbert [0:06:45]</p><p>“It’s parameter rich to represent the rules of growth of a plant.” — Colin Herbert [0:09:21]</p><p>“We know exactly where the edge cases are – we know the distribution of every parameter in that dataset, so we can design the dataset exactly how we want it and generate imagery accordingly. We could never collect such imagery in the real world.” — Colin Herbert [0:10:33]</p><p>“Ultimately, the way we look at an image is not the way AI looks at an image.” — Colin Herbert [0:21:11]</p><p>“It may not be a real-world image that we’re looking at, but it will be data from the real world. There is a crucial difference.” — Colin Herbert [0:32:01]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/colin-herbert-3327397/">Colin Herbert on LinkedIn</a></p><p><a href="https://agrisynth.io/">AgriSynth</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 12 Oct 2023 19:13:18 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/agrisynth-founder-ceo-colin-herbert-HaqVy85M</link>
      <content:encoded><![CDATA[<p> </p><p><a href="https://imgur.com/a/1EQ1vAj" target="_blank">EXAMPLE: AgriSynth Synthetic Data-- Weeds as Seen By AI</a></p><p>Data is the backbone of agricultural innovation when it comes to increasing yields, reducing pests, and improving overall efficiency, but generating high-quality real-world data is an expensive and time-consuming process. Today, we are joined by Colin Herbert, the CEO and Founder of AgriSynth, to find out how the advent of synthetic data will ultimately transform the industry for the better. AgriSynth is revolutionizing how AI can be trained for agricultural solutions using synthetic imagery.  He also gives us an overview of his non-linear career journey (from engineering to medical school to agriculture, then through clinical trials and back to agriculture with a detour in Deep Learning), shares the fascinating origin story of AgriSynth, and more. </p><p>Key Points From This Episode:</p><ul><li>Colin’s career trajectory and the surprising role that Star Wars plays in AgriSynth’s origin story.</li><li>Reasons that the use of AI in agriculture is still limited, despite its vast potential.</li><li>Ways that AgriSynth seeks to bridge these gaps in the industry using synthetic imagery.</li><li>Insight into the vast amount of parameters and values required.</li><li>What synthetic data looks like in AgriSynth’s “closed-loop train/test system.”</li><li>Why photorealistic data is completely unnecessary for AI models.</li><li>How AgriSynth is working towards eliminating human cognition from the process.</li><li>Dispelling some of the criticism often directed at synthetic data.</li><li>Just a few of the many applications for AgriSynth’s tech and how their output will evolve.</li><li>Why real-world images aren’t necessarily superior to synthetic data!</li></ul><p>Quotes:</p><p>“The complexity of biological images and agricultural images is way beyond driverless cars and most other applications [of AI].” — Colin Herbert [0:06:45]</p><p>“It’s parameter rich to represent the rules of growth of a plant.” — Colin Herbert [0:09:21]</p><p>“We know exactly where the edge cases are – we know the distribution of every parameter in that dataset, so we can design the dataset exactly how we want it and generate imagery accordingly. We could never collect such imagery in the real world.” — Colin Herbert [0:10:33]</p><p>“Ultimately, the way we look at an image is not the way AI looks at an image.” — Colin Herbert [0:21:11]</p><p>“It may not be a real-world image that we’re looking at, but it will be data from the real world. There is a crucial difference.” — Colin Herbert [0:32:01]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/colin-herbert-3327397/">Colin Herbert on LinkedIn</a></p><p><a href="https://agrisynth.io/">AgriSynth</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="32161646" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/aac422ca-1a8e-4be9-9ce9-8bd3ebd06da8/audio/b2a6e542-39ad-4a67-890b-fca8207c9850/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AgriSynth Founder &amp; CEO Colin Herbert</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:30</itunes:duration>
      <itunes:summary>In this episode, Colin explains how AgriSynth is “getting humans out of the way” with its closed-loop control system and offers some insight into the sheer volume of data required to train its AI models.</itunes:summary>
      <itunes:subtitle>In this episode, Colin explains how AgriSynth is “getting humans out of the way” with its closed-loop control system and offers some insight into the sheer volume of data required to train its AI models.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>80</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">daa8f742-51a5-43d0-b476-8e07f9e292a7</guid>
      <title>Data Relish Founder Jennifer Stirrup</title>
      <description><![CDATA[<p>Jennifer is the founder of Data Relish, a boutique consultancy firm dedicated to providing strategic guidance and executing data technology solutions that generate tangible business benefits for organizations of diverse scales across the globe. In our conversation, we unpack why a data platform is not the same as a database, working as a freelancer in the industry, common problems companies face, the cultural aspect of her work, and starting with the end in mind. We also delve into her approach to helping companies in crisis, why ‘small’ data is just as important as ‘big’ data, building companies for the future, the idea of a ‘data dictionary’, good and bad examples of data culture, and the importance of identifying an executive sponsor.</p><p>Key Points From This Episode:</p><ul><li>Introducing Jennifer Stirrup and an overview of her professional background.</li><li>Jennifer’s passion for technology and the exciting projects she is currently working on.</li><li>Alan Turing’s legacy in terms of AI and how the landscape is evolving.</li><li>The reason for starting her own business and working as a freelancer.</li><li>Forging a career in the technology and AI space: advice from an expert.</li><li>Challenges and opportunities of working as a consultant in the technology sector.</li><li>Characteristics of AI that make it a high-pressure and high-risk environment.</li><li>She breaks down the value and role of an executive sponsor.</li><li>Common hurdles companies face regarding data and AI operations.</li><li>Circumstances when companies hire Jennifer to help them.</li><li>Safeguarding her reputation and managing unrealistic expectations. </li><li>Advice for healthy data practices to avoid problems in the future.</li><li>Why Jennifer decided on the name Data Relish.</li><li>Discover how good and reliable data can help change lives.</li></ul><p>Quotes:</p><p>“Something that is important in AI is having an executive sponsor, someone who can really unblock any obstacles for you.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:08:50]</p><p>“Probably the biggest [challenge companies face] is access to the right data and having a really good data platform.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:10:50]</p><p>“If the crisis is not being handled by an executive sponsor, then there is nothing I can do.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:20:55]</p><p>“I want people to understand the value that [data] can have because when your data is good it can change lives.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:32:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://jenstirrup.com">Jennifer Stirrup</a></p><p><a href="https://www.linkedin.com/in/jenstirrup/">Jennifer Stirrup on LinkedIn</a></p><p><a href="https://twitter.com/jenstirrup">Jennifer Stirrup on X</a></p><p><a href="https://smart.bio/data_relish/">Data Relish</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 21 Sep 2023 21:25:02 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/data-relish-founder-jennifer-stirrup-BaKMLxPf</link>
      <content:encoded><![CDATA[<p>Jennifer is the founder of Data Relish, a boutique consultancy firm dedicated to providing strategic guidance and executing data technology solutions that generate tangible business benefits for organizations of diverse scales across the globe. In our conversation, we unpack why a data platform is not the same as a database, working as a freelancer in the industry, common problems companies face, the cultural aspect of her work, and starting with the end in mind. We also delve into her approach to helping companies in crisis, why ‘small’ data is just as important as ‘big’ data, building companies for the future, the idea of a ‘data dictionary’, good and bad examples of data culture, and the importance of identifying an executive sponsor.</p><p>Key Points From This Episode:</p><ul><li>Introducing Jennifer Stirrup and an overview of her professional background.</li><li>Jennifer’s passion for technology and the exciting projects she is currently working on.</li><li>Alan Turing’s legacy in terms of AI and how the landscape is evolving.</li><li>The reason for starting her own business and working as a freelancer.</li><li>Forging a career in the technology and AI space: advice from an expert.</li><li>Challenges and opportunities of working as a consultant in the technology sector.</li><li>Characteristics of AI that make it a high-pressure and high-risk environment.</li><li>She breaks down the value and role of an executive sponsor.</li><li>Common hurdles companies face regarding data and AI operations.</li><li>Circumstances when companies hire Jennifer to help them.</li><li>Safeguarding her reputation and managing unrealistic expectations. </li><li>Advice for healthy data practices to avoid problems in the future.</li><li>Why Jennifer decided on the name Data Relish.</li><li>Discover how good and reliable data can help change lives.</li></ul><p>Quotes:</p><p>“Something that is important in AI is having an executive sponsor, someone who can really unblock any obstacles for you.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:08:50]</p><p>“Probably the biggest [challenge companies face] is access to the right data and having a really good data platform.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:10:50]</p><p>“If the crisis is not being handled by an executive sponsor, then there is nothing I can do.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:20:55]</p><p>“I want people to understand the value that [data] can have because when your data is good it can change lives.” — <a href="https://twitter.com/jenstirrup">@jenstirrup</a> [0:32:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://jenstirrup.com">Jennifer Stirrup</a></p><p><a href="https://www.linkedin.com/in/jenstirrup/">Jennifer Stirrup on LinkedIn</a></p><p><a href="https://twitter.com/jenstirrup">Jennifer Stirrup on X</a></p><p><a href="https://smart.bio/data_relish/">Data Relish</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33860650" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/74e5577a-2501-4b04-a29a-94acce5d1b69/audio/d725190f-2417-4a9f-b99e-1c71c79ca64d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Data Relish Founder Jennifer Stirrup</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:16</itunes:duration>
      <itunes:summary>Healthy data culture and practices are essential for modern businesses. They promote informed decision-making, efficiency, innovation, and accountability while helping organizations stay competitive and adaptable in a data-driven world. In this episode, we tackle the age-old struggle many companies face: how to unleash the potential of data while overcoming the hurdles that stand in the way of building a truly healthy data culture. To help us navigate this topic is Jennifer Stirrup, a distinguished expert in artificial intelligence, business intelligence, big data, and data visualization solutions. </itunes:summary>
      <itunes:subtitle>Healthy data culture and practices are essential for modern businesses. They promote informed decision-making, efficiency, innovation, and accountability while helping organizations stay competitive and adaptable in a data-driven world. In this episode, we tackle the age-old struggle many companies face: how to unleash the potential of data while overcoming the hurdles that stand in the way of building a truly healthy data culture. To help us navigate this topic is Jennifer Stirrup, a distinguished expert in artificial intelligence, business intelligence, big data, and data visualization solutions. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>79</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">95571e5d-a133-4fdb-8244-50c10897efc8</guid>
      <title>BNY Mellon AI Hub Managing Director Michael Demissie</title>
      <description><![CDATA[<p> Joining us today to provide insight on how to put together a credible AI solutions team is Mike Demissie, Managing Director of the AI Hub at BNY Mellon. We talk with Mike about what to consider when putting together and managing such a diverse team and how BNY Mellon is implementing powerful AI and ML capabilities to solve the problems that matter most to their clients and employees.   To learn how BNY Mellon is continually innovating for the benefit of their customers and their employees, along with Mike’s thoughts on the future of generative AI, be sure to tune in!<br /><br /> </p><p>Key Points From This Episode:</p><ul><li>Mike’s background in engineering and his role at BNY Mellon.</li><li>The history of BNY Mellon and how they are applying AI and ML in financial services.</li><li>An overview of the diverse range of specialists that make up their enterprise AI team.</li><li>Making it easier for their organization to tap into AI capabilities responsibly.</li><li>Identifying the problems that matter most to their clients and employees.</li><li>Finding the best ways to build solutions and deploy them in a scalable fashion.</li><li>Insight into the AI solutions currently being implemented by BNY Mellon.</li><li>How their enterprise AI team chooses what to prioritize and why it can be so challenging.</li><li>The value of having a diverse set of use cases: it builds confidence and awareness.</li><li>Their internal PR strategy for educating the rest of the organization on AI implementations.</li><li>Insight into generative AI's potential to enhance BNY Mellon’s products and services.</li><li>Ensuring the proper guardrails and regulations are put in place for generative AI.</li><li>Mike’s advice on pursuing a career in the AI, ML, and data science space.</li></ul><p>Quotes:</p><p>“Building AI solutions is very much a team sport. So you need experts across many disciplines.” —Mike Demissie [0:06:40]</p><p>“The engineers need to really find a way in terms of ‘okay, look, how are we going to stitch together the various applications to run it in the most optimal way?’” —Mike Demissie [0:09:23]</p><p>“It is not only opportunity identification, but also developing the solution and deploying it and making sure there's a sustainable model to take care of afterwards, after production — so you can go after the next new challenge.” —Mike Demissie [0:09:33]</p><p>“There's endless use of opportunities. And every time we deploy each of these solutions [it] actually sparks ideas and new opportunities in that line of business.” —Mike Demissie [0:11:58]</p><p>“Not only is it important to raise the level of awareness and education for everyone involved, but you can also tap into the domain expertise of folks, regardless of where they sit in the organization.” —Mike Demissie [0:15:36]</p><p>“Demystifying, and really just making this abstract capability real for people is an important part of the practice as well.” —Mike Demissie [0:16:10]</p><p>“Remember, [this] still is day one. As much as all the talk that is out there, we're still figuring out the best way to navigate and the best way to apply this capability. So continue to explore that, too.” —Mike Demissie [0:24:21]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/michaeldemissie/">Mike Demissie on LinkedIn</a></p><p><a href="https://www.bnymellon.com/us/en.html">BNY Mellon</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Tue, 12 Sep 2023 22:55:56 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/bny-mellon-ai-hub-managing-director-michael-demissie-vyUkjQ_s</link>
      <content:encoded><![CDATA[<p> Joining us today to provide insight on how to put together a credible AI solutions team is Mike Demissie, Managing Director of the AI Hub at BNY Mellon. We talk with Mike about what to consider when putting together and managing such a diverse team and how BNY Mellon is implementing powerful AI and ML capabilities to solve the problems that matter most to their clients and employees.   To learn how BNY Mellon is continually innovating for the benefit of their customers and their employees, along with Mike’s thoughts on the future of generative AI, be sure to tune in!<br /><br /> </p><p>Key Points From This Episode:</p><ul><li>Mike’s background in engineering and his role at BNY Mellon.</li><li>The history of BNY Mellon and how they are applying AI and ML in financial services.</li><li>An overview of the diverse range of specialists that make up their enterprise AI team.</li><li>Making it easier for their organization to tap into AI capabilities responsibly.</li><li>Identifying the problems that matter most to their clients and employees.</li><li>Finding the best ways to build solutions and deploy them in a scalable fashion.</li><li>Insight into the AI solutions currently being implemented by BNY Mellon.</li><li>How their enterprise AI team chooses what to prioritize and why it can be so challenging.</li><li>The value of having a diverse set of use cases: it builds confidence and awareness.</li><li>Their internal PR strategy for educating the rest of the organization on AI implementations.</li><li>Insight into generative AI's potential to enhance BNY Mellon’s products and services.</li><li>Ensuring the proper guardrails and regulations are put in place for generative AI.</li><li>Mike’s advice on pursuing a career in the AI, ML, and data science space.</li></ul><p>Quotes:</p><p>“Building AI solutions is very much a team sport. So you need experts across many disciplines.” —Mike Demissie [0:06:40]</p><p>“The engineers need to really find a way in terms of ‘okay, look, how are we going to stitch together the various applications to run it in the most optimal way?’” —Mike Demissie [0:09:23]</p><p>“It is not only opportunity identification, but also developing the solution and deploying it and making sure there's a sustainable model to take care of afterwards, after production — so you can go after the next new challenge.” —Mike Demissie [0:09:33]</p><p>“There's endless use of opportunities. And every time we deploy each of these solutions [it] actually sparks ideas and new opportunities in that line of business.” —Mike Demissie [0:11:58]</p><p>“Not only is it important to raise the level of awareness and education for everyone involved, but you can also tap into the domain expertise of folks, regardless of where they sit in the organization.” —Mike Demissie [0:15:36]</p><p>“Demystifying, and really just making this abstract capability real for people is an important part of the practice as well.” —Mike Demissie [0:16:10]</p><p>“Remember, [this] still is day one. As much as all the talk that is out there, we're still figuring out the best way to navigate and the best way to apply this capability. So continue to explore that, too.” —Mike Demissie [0:24:21]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/michaeldemissie/">Mike Demissie on LinkedIn</a></p><p><a href="https://www.bnymellon.com/us/en.html">BNY Mellon</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25813298" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/a282f9b5-efb9-49f3-b5db-44e4ca0c534c/audio/054659f3-8c33-4856-9a52-e33b0e13388a/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>BNY Mellon AI Hub Managing Director Michael Demissie</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:53</itunes:duration>
      <itunes:summary>Mike breaks down some of the key AI solutions being used at BNY Mellon and shares his thoughts on the many possible future implementations of these emerging technologies. He also unpacks how their enterprise AI team chooses what to prioritize before addressing the importance of demystifying AI capabilities — both within and outside of an organization.</itunes:summary>
      <itunes:subtitle>Mike breaks down some of the key AI solutions being used at BNY Mellon and shares his thoughts on the many possible future implementations of these emerging technologies. He also unpacks how their enterprise AI team chooses what to prioritize before addressing the importance of demystifying AI capabilities — both within and outside of an organization.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>78</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">42f33043-7e96-487e-95dd-24c90a4893eb</guid>
      <title>Mercedes-Benz Executive Manager for AI Alex Dogariu</title>
      <description><![CDATA[<p>Mercedes-Benz is a juggernaut in the automobile industry and in recent times, it has been deliberate in advancing the use of AI throughout the organization. Today, we welcome to the show the Executive Manager for AI at Mercedes-Benz, Alex Dogariu. Alex explains his role at the company, he tells us how realistic chatbots need to be, how he and his team measure the accuracy of their AI programs, and why people should be given more access to AI and time to play around with it. Tune in for a breakdown of Alex's principles for the responsible use of AI. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to the Executive Manager for AI at Mercedes-Benz, Alex Dogariu.</li><li>Alex’s professional background and how he ended up at Mercedes-Benz.</li><li>When Mercedes-Benz decided that it needed a team dedicated to AI.</li><li>An example of the output of descriptive analytics as a result of machine learning at Mercedes.</li><li>Alex explains his role as Executive Manager for AI. </li><li>How realistic chatbots need to be, according to Alex. </li><li>The way he measures the accuracy of his AI programs. </li><li>How Mercedes-Benz assigns AI teams to specific departments within the organization. </li><li>Why it’s important to give people access to AI technology and allow them to play with it.  </li><li>Using vendors versus doing everything in-house. </li><li>Alex gives us a brief breakdown of his principles for the responsible use of AI.</li><li>What he was trying to express and accomplish with his TEDx talk. </li></ul><p>Tweetables:</p><p>“[Chatbots] are useful helpers, they’re not replacing humans.” — Alex Dogariu [09:38]</p><p>“This [AI] technology is so new that we really just have to give people access to it and let them play with it.” — Alex Dogariu [15:50]</p><p>“I want to make people aware that AI has not only benefits but also downsides, and we should account for those. And also, that we use AI in a responsible way and manner.” — Alex Dogariu [25:12]</p><p>“It’s always a balancing act. It’s the same with certification of AI models — you don’t want to stifle innovation with legislation and laws and compliance rules but, to a certain extent, it’s necessary, it makes sense.” — Alex Dogariu [26:14]</p><p>“To all the AI enthusiasts out there, keep going, and let’s make it a better world with this new technology.” — Alex Dogariu [27:00]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/alex-dogariu-ai-in-sales">Alex Dogariu on LinkedIn</a></p><p><a href="https://www.mercedes-benz.com/en/">Mercedes-Benz</a></p><p><a href="https://www.youtube.com/watch?v=nDu7qA45Gv8">‘Principles for responsible use of AI | Alex Dogariu | TEDxWHU’</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 31 Aug 2023 20:48:45 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/mercedes-benz-executive-manager-for-ai-alex-dogariu-09i2FoOF</link>
      <content:encoded><![CDATA[<p>Mercedes-Benz is a juggernaut in the automobile industry and in recent times, it has been deliberate in advancing the use of AI throughout the organization. Today, we welcome to the show the Executive Manager for AI at Mercedes-Benz, Alex Dogariu. Alex explains his role at the company, he tells us how realistic chatbots need to be, how he and his team measure the accuracy of their AI programs, and why people should be given more access to AI and time to play around with it. Tune in for a breakdown of Alex's principles for the responsible use of AI. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to the Executive Manager for AI at Mercedes-Benz, Alex Dogariu.</li><li>Alex’s professional background and how he ended up at Mercedes-Benz.</li><li>When Mercedes-Benz decided that it needed a team dedicated to AI.</li><li>An example of the output of descriptive analytics as a result of machine learning at Mercedes.</li><li>Alex explains his role as Executive Manager for AI. </li><li>How realistic chatbots need to be, according to Alex. </li><li>The way he measures the accuracy of his AI programs. </li><li>How Mercedes-Benz assigns AI teams to specific departments within the organization. </li><li>Why it’s important to give people access to AI technology and allow them to play with it.  </li><li>Using vendors versus doing everything in-house. </li><li>Alex gives us a brief breakdown of his principles for the responsible use of AI.</li><li>What he was trying to express and accomplish with his TEDx talk. </li></ul><p>Tweetables:</p><p>“[Chatbots] are useful helpers, they’re not replacing humans.” — Alex Dogariu [09:38]</p><p>“This [AI] technology is so new that we really just have to give people access to it and let them play with it.” — Alex Dogariu [15:50]</p><p>“I want to make people aware that AI has not only benefits but also downsides, and we should account for those. And also, that we use AI in a responsible way and manner.” — Alex Dogariu [25:12]</p><p>“It’s always a balancing act. It’s the same with certification of AI models — you don’t want to stifle innovation with legislation and laws and compliance rules but, to a certain extent, it’s necessary, it makes sense.” — Alex Dogariu [26:14]</p><p>“To all the AI enthusiasts out there, keep going, and let’s make it a better world with this new technology.” — Alex Dogariu [27:00]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/alex-dogariu-ai-in-sales">Alex Dogariu on LinkedIn</a></p><p><a href="https://www.mercedes-benz.com/en/">Mercedes-Benz</a></p><p><a href="https://www.youtube.com/watch?v=nDu7qA45Gv8">‘Principles for responsible use of AI | Alex Dogariu | TEDxWHU’</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="26645037" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f0389810-b915-4b1b-b70e-94459236f774/audio/f890e939-df9f-460d-b284-1c20bd1ed6f6/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Mercedes-Benz Executive Manager for AI Alex Dogariu</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:45</itunes:duration>
      <itunes:summary>Alex and his team are keen on using AI to increase proficiency at Mercedes while being hyperaware of using this new technology in the most responsible way possible. In our conversation, we learn why Mercedes-Benz thought it necessary to have an entire team dedicated to AI, how they assign AI teams to specific departments in the company, and how the output of descriptive analytics has been improved by machine learning.</itunes:summary>
      <itunes:subtitle>Alex and his team are keen on using AI to increase proficiency at Mercedes while being hyperaware of using this new technology in the most responsible way possible. In our conversation, we learn why Mercedes-Benz thought it necessary to have an entire team dedicated to AI, how they assign AI teams to specific departments in the company, and how the output of descriptive analytics has been improved by machine learning.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>77</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">bf4d30f1-2fa3-4212-8b0e-30fab453b832</guid>
      <title>Watsonx.ai with IBM VP Data &amp; AI Tarun Chopra</title>
      <description><![CDATA[<p>Tarun  dives into the game-changing components of Watsonx, before delivering some noteworthy advice for those who are eager to forge a career in AI and machine learning. </p><p>Key Points From This Episode:</p><ul><li>Introducing Tarun Chopra and a brief look at his professional background. </li><li>His intellectual diet: what Tarun is consuming to stay up to date with technological trends. </li><li>Common challenges in technology and AI that he encounters daily. </li><li>The importance of fully understating what problem you want your new technology to solve.  </li><li>IBM’s role in AI and how the company is helping to accelerate change in the space.</li><li>Exploring IBM’s decision to remove facial recognition from its endeavors in biometrics. </li><li>The development of IBM’s Watsonx and how it’s helping business tell their unique AI stories. </li><li>Why IBM’s consultative approach to introducing their customers to AI is so effective. </li><li>Tarun’s thoughts on computer power and all related costs. </li><li>Diving deeper into the three components of Watsonx. </li><li>Our guest’s words of advice to those looking to forge a career in AI and ML. </li></ul><p>Tweetables:</p><p>“One of the first things I tell clients is, ‘If you don’t know what problems we are solving, then we’re on the wrong path.’” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [05:14]</p><p>“A lot of our customers have adopted AI — but if the workflow is, let’s say 10 steps, they have applied AI to only one or two steps. They don’t get to realize the full value of that innovation.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [05:24]</p><p>“Every client that I talk to, they’re all looking to build their own unique story; their own unique point of view with their own unique data and their own unique customer pain points. So, I look at Watsonx as a vehicle to help customers build their own unique AI story.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [14:16]</p><p>“The most important thing you need is curiosity. [And] be strong-hearted, because this [industry] is not for the weak-hearted.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [27:41]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://tachopra.wordpress.com/">Tarun Chopra</a></p><p><a href="https://www.linkedin.com/in/tarun-chopra-78125842/">Tarun Chopra on LinkedIn</a></p><p><a href="https://twitter.com/tc20640n">Tarun Chopra on Twitter</a></p><p><a href="https://www.ibm.com/blog/author/tarunchopra/">Tarun Chopra on IBM</a></p><p><a href="https://www.ibm.com/us-en">IBM</a></p><p><a href="https://www.ibm.com/watson">IBM Watson</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Tue, 29 Aug 2023 17:15:50 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/watsonxai-with-ibm-vp-data-ai-tarun-chopra-JWeUsLOs</link>
      <content:encoded><![CDATA[<p>Tarun  dives into the game-changing components of Watsonx, before delivering some noteworthy advice for those who are eager to forge a career in AI and machine learning. </p><p>Key Points From This Episode:</p><ul><li>Introducing Tarun Chopra and a brief look at his professional background. </li><li>His intellectual diet: what Tarun is consuming to stay up to date with technological trends. </li><li>Common challenges in technology and AI that he encounters daily. </li><li>The importance of fully understating what problem you want your new technology to solve.  </li><li>IBM’s role in AI and how the company is helping to accelerate change in the space.</li><li>Exploring IBM’s decision to remove facial recognition from its endeavors in biometrics. </li><li>The development of IBM’s Watsonx and how it’s helping business tell their unique AI stories. </li><li>Why IBM’s consultative approach to introducing their customers to AI is so effective. </li><li>Tarun’s thoughts on computer power and all related costs. </li><li>Diving deeper into the three components of Watsonx. </li><li>Our guest’s words of advice to those looking to forge a career in AI and ML. </li></ul><p>Tweetables:</p><p>“One of the first things I tell clients is, ‘If you don’t know what problems we are solving, then we’re on the wrong path.’” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [05:14]</p><p>“A lot of our customers have adopted AI — but if the workflow is, let’s say 10 steps, they have applied AI to only one or two steps. They don’t get to realize the full value of that innovation.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [05:24]</p><p>“Every client that I talk to, they’re all looking to build their own unique story; their own unique point of view with their own unique data and their own unique customer pain points. So, I look at Watsonx as a vehicle to help customers build their own unique AI story.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [14:16]</p><p>“The most important thing you need is curiosity. [And] be strong-hearted, because this [industry] is not for the weak-hearted.” — <a href="https://twitter.com/tc20640n">@tc20640n</a> [27:41]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://tachopra.wordpress.com/">Tarun Chopra</a></p><p><a href="https://www.linkedin.com/in/tarun-chopra-78125842/">Tarun Chopra on LinkedIn</a></p><p><a href="https://twitter.com/tc20640n">Tarun Chopra on Twitter</a></p><p><a href="https://www.ibm.com/blog/author/tarunchopra/">Tarun Chopra on IBM</a></p><p><a href="https://www.ibm.com/us-en">IBM</a></p><p><a href="https://www.ibm.com/watson">IBM Watson</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28357833" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8bd46225-ede0-4a87-a13c-b41d09a0be6b/audio/d1e4c6b9-1533-40f0-b4aa-70e0ce47484c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Watsonx.ai with IBM VP Data &amp; AI Tarun Chopra</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:32</itunes:duration>
      <itunes:summary> Tarun is the VP of Project Management, Data, and AI at IBM, and he is here today to tell us how IBM is keeping up with (and innovating its own) technological trends. We learn of the common struggles in AI and ML, why you need to understand the problem you’re trying to solve before using any new technology, how IBM and Watsonx are helping businesses to tell their own unique AI stories, and why using a consultative method to introduce new users to AI is the most effective method.</itunes:summary>
      <itunes:subtitle> Tarun is the VP of Project Management, Data, and AI at IBM, and he is here today to tell us how IBM is keeping up with (and innovating its own) technological trends. We learn of the common struggles in AI and ML, why you need to understand the problem you’re trying to solve before using any new technology, how IBM and Watsonx are helping businesses to tell their own unique AI stories, and why using a consultative method to introduce new users to AI is the most effective method.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>76</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">7023ac22-d48c-4cb1-9c90-14414f4a675e</guid>
      <title>Veritone Head of Product &amp; Engineering Chris Doe</title>
      <description><![CDATA[<p>Creating AI workflows can be a challenging process. And while purchasing these types of technologies may be straightforward, implementing them across multiple teams is often anything but. That’s where a company like Veritone can offer unparalleled support. With over 400 AI engines on their platform, they’ve created a unique operating system that helps companies orchestrate AI workflows with ease and efficacy.  Chris discusses the differences between legacy and generative AI, how LLMs have transformed chatbots, and what you can do to identify potential AI use cases within an organization. AI innovations are taking place at a remarkable pace and companies are feeling the pressure to innovate or be left behind, so tune in to learn more about AI applications in business and how you can revolutionize your workflow!</p><p>Key Points From This Episode:</p><ul><li>An introduction to Chris Doe, Product Management Leader at Veritone.</li><li>How Veritone is helping clients orchestrate their AI workflows.</li><li>The four verticals Chris oversees: media, entertainment, sports, and advertising.</li><li>Building solutions that infuse AI from beginning to end.</li><li>An overview of the type of AI that Veritone is infusing.</li><li>How they are helping their clients navigate the expansive landscape of cognitive engines.</li><li>Fine-tuning generative AI to be use-case-specific for their clients.</li><li>Why now is the time to be testing and defining proof of concept for generative AI.</li><li>How LLMs have transformed chatbots to be significantly more sophisticated.</li><li>Creating bespoke chatbots for clients that can navigate complex enterprise applications.</li><li>The most common challenges clients face when it comes to integrating AI applications.</li><li>Chris’s advice on taking stock of an organization and figuring out where to apply AI.</li><li>Tips on how to identify potential AI use cases within an organization.</li></ul><p>Quotes:</p><p>“Anybody who's writing text can leverage generative AI models to make their output better.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:05:32]</p><p>“With large language models, they've basically given these chatbots a whole new life.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:12:38]</p><p>“I can foresee a scenario where most enterprise applications will have an LLM power chatbot in their UI.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:13:31]</p><p>“It's easy to buy technology, it's hard to get it adopted across multiple teams that are all moving in different directions and speeds.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:21:16]</p><p>“People can start new companies and innovate very quickly these days. And the same has to be true for large companies. They can't just sit on their existing product set. They always have to be innovating.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:23:05]</p><p>“We just have to identify the most problematic part of that workflow and then solve it.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:26:20]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/chrisdoe/">Chris Doe on LinkedIn</a></p><p><a href="https://twitter.com/chris_doe">Chris Doe on X</a></p><p><a href="https://www.veritone.com/">Veritone</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 17 Aug 2023 19:23:32 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/veritone-head-of-product-engineering-chris-doe-7uEG_y_P</link>
      <content:encoded><![CDATA[<p>Creating AI workflows can be a challenging process. And while purchasing these types of technologies may be straightforward, implementing them across multiple teams is often anything but. That’s where a company like Veritone can offer unparalleled support. With over 400 AI engines on their platform, they’ve created a unique operating system that helps companies orchestrate AI workflows with ease and efficacy.  Chris discusses the differences between legacy and generative AI, how LLMs have transformed chatbots, and what you can do to identify potential AI use cases within an organization. AI innovations are taking place at a remarkable pace and companies are feeling the pressure to innovate or be left behind, so tune in to learn more about AI applications in business and how you can revolutionize your workflow!</p><p>Key Points From This Episode:</p><ul><li>An introduction to Chris Doe, Product Management Leader at Veritone.</li><li>How Veritone is helping clients orchestrate their AI workflows.</li><li>The four verticals Chris oversees: media, entertainment, sports, and advertising.</li><li>Building solutions that infuse AI from beginning to end.</li><li>An overview of the type of AI that Veritone is infusing.</li><li>How they are helping their clients navigate the expansive landscape of cognitive engines.</li><li>Fine-tuning generative AI to be use-case-specific for their clients.</li><li>Why now is the time to be testing and defining proof of concept for generative AI.</li><li>How LLMs have transformed chatbots to be significantly more sophisticated.</li><li>Creating bespoke chatbots for clients that can navigate complex enterprise applications.</li><li>The most common challenges clients face when it comes to integrating AI applications.</li><li>Chris’s advice on taking stock of an organization and figuring out where to apply AI.</li><li>Tips on how to identify potential AI use cases within an organization.</li></ul><p>Quotes:</p><p>“Anybody who's writing text can leverage generative AI models to make their output better.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:05:32]</p><p>“With large language models, they've basically given these chatbots a whole new life.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:12:38]</p><p>“I can foresee a scenario where most enterprise applications will have an LLM power chatbot in their UI.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:13:31]</p><p>“It's easy to buy technology, it's hard to get it adopted across multiple teams that are all moving in different directions and speeds.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:21:16]</p><p>“People can start new companies and innovate very quickly these days. And the same has to be true for large companies. They can't just sit on their existing product set. They always have to be innovating.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:23:05]</p><p>“We just have to identify the most problematic part of that workflow and then solve it.” — <a href="https://twitter.com/chris_doe">@chris_doe</a> [0:26:20]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/chrisdoe/">Chris Doe on LinkedIn</a></p><p><a href="https://twitter.com/chris_doe">Chris Doe on X</a></p><p><a href="https://www.veritone.com/">Veritone</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27503943" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/3787e395-27e0-4e55-a6ee-072364b629c7/audio/164e513e-4d5b-4c6c-ba63-72865bb90387/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Veritone Head of Product &amp; Engineering Chris Doe</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:38</itunes:duration>
      <itunes:summary>We are joined today by Veritone&apos;s own Head of Engineering &amp; Product, Chris Doe, to discuss AI applications in enterprise and what is top of mind for companies when it comes to incorporating these emerging technologies. In our conversation, Chris breaks down how Veritone is helping its clients navigate the expansive landscape of AI cognitive engines and why now is the ideal time to test and define proof of concept for generative AI.</itunes:summary>
      <itunes:subtitle>We are joined today by Veritone&apos;s own Head of Engineering &amp; Product, Chris Doe, to discuss AI applications in enterprise and what is top of mind for companies when it comes to incorporating these emerging technologies. In our conversation, Chris breaks down how Veritone is helping its clients navigate the expansive landscape of AI cognitive engines and why now is the ideal time to test and define proof of concept for generative AI.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>75</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4753665c-6b77-4b31-8087-8b6d6e3ad240</guid>
      <title>Microsoft Technical Strategist Valeria Sadovykh, PhD</title>
      <description><![CDATA[<p>AI is an incredible tool that has allowed us to evolve into more efficient human beings. But, the lack of ethical and responsible design in AI can lead to a level of detachment from real people and authenticity. A wonderful technology strategist at Microsoft, Valeria Sadovykh, joins us today on How AI Happens. Valeria discusses why she is concerned about AI tools that assist users in decision-making, the responsibility she feels these companies hold, and the importance of innovation. We delve into common challenges these companies face in people, processes, and technology before exploring the effects of the democratization of AI. Finally, our guest shares her passion for emotional AI and tells us why that keeps her in the space. To hear it all, tune in now!</p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Valeria Sadovykh. </li><li>Valeria tells us about her studies at the University of Auckland and her Ph.D. </li><li>The problems with using the internet to assist in decision making. </li><li>How ethical and responsible AI frames Valeria’s career. </li><li>What she is doing to encourage AI leaders to prioritize responsible design. </li><li>The dangers of lack of authenticity, creativity, and emotion in AI. </li><li>Whether we need human interaction or not and if we want to preserve it. </li><li>What responsibility companies developing this technology have, according to Valeria. </li><li>She tells us about her job at Microsoft and what large organizations are doing to be ethical. </li><li>What kinds of AI organizations need to be most conscious of ethics and responsible design.</li><li>Other common challenges companies face when they plug in other technology.</li><li>How those challenges show up in people, processes, and technology when deploying AI.</li><li>Why Valeria expects some costs to decrease as AI technology democratizes over time.</li><li>The importance of innovating and being prepared to (potentially) fail. </li><li>Why the future of emotional AI and the ability to be authentic fascinates Valeria. </li></ul><p>Tweetables:</p><p>“We have no opportunity to learn something new outside of our predetermined environment.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:07:07]</p><p>“[Ethics] as a concept is very difficult to understand because what is ethical for me might not necessarily be ethical for you and vice versa.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:11:38]</p><p>“Ethics – should not come – [in] place of innovation.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:20:13]</p><p>“Not following up, not investing, not trying, [and] not failing is also preventing you from success.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:29:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/valeria-sadovykh/">Valeria Sadovykh on LinkedIn</a></p><p><a href="https://www.instagram.com/vsadovy/">Valeria Sadovykh on Instagram</a></p><p><a href="https://twitter.com/ValeriaSadovykh">Valeria Sadovykh on Twitter</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 11 Aug 2023 15:49:21 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/microsoft-technical-strategist-valeria-sadovykh-SsoGh1Ae</link>
      <content:encoded><![CDATA[<p>AI is an incredible tool that has allowed us to evolve into more efficient human beings. But, the lack of ethical and responsible design in AI can lead to a level of detachment from real people and authenticity. A wonderful technology strategist at Microsoft, Valeria Sadovykh, joins us today on How AI Happens. Valeria discusses why she is concerned about AI tools that assist users in decision-making, the responsibility she feels these companies hold, and the importance of innovation. We delve into common challenges these companies face in people, processes, and technology before exploring the effects of the democratization of AI. Finally, our guest shares her passion for emotional AI and tells us why that keeps her in the space. To hear it all, tune in now!</p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Valeria Sadovykh. </li><li>Valeria tells us about her studies at the University of Auckland and her Ph.D. </li><li>The problems with using the internet to assist in decision making. </li><li>How ethical and responsible AI frames Valeria’s career. </li><li>What she is doing to encourage AI leaders to prioritize responsible design. </li><li>The dangers of lack of authenticity, creativity, and emotion in AI. </li><li>Whether we need human interaction or not and if we want to preserve it. </li><li>What responsibility companies developing this technology have, according to Valeria. </li><li>She tells us about her job at Microsoft and what large organizations are doing to be ethical. </li><li>What kinds of AI organizations need to be most conscious of ethics and responsible design.</li><li>Other common challenges companies face when they plug in other technology.</li><li>How those challenges show up in people, processes, and technology when deploying AI.</li><li>Why Valeria expects some costs to decrease as AI technology democratizes over time.</li><li>The importance of innovating and being prepared to (potentially) fail. </li><li>Why the future of emotional AI and the ability to be authentic fascinates Valeria. </li></ul><p>Tweetables:</p><p>“We have no opportunity to learn something new outside of our predetermined environment.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:07:07]</p><p>“[Ethics] as a concept is very difficult to understand because what is ethical for me might not necessarily be ethical for you and vice versa.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:11:38]</p><p>“Ethics – should not come – [in] place of innovation.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:20:13]</p><p>“Not following up, not investing, not trying, [and] not failing is also preventing you from success.” — <a href="https://twitter.com/ValeriaSadovykh">@ValeriaSadovykh</a> [0:29:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/valeria-sadovykh/">Valeria Sadovykh on LinkedIn</a></p><p><a href="https://www.instagram.com/vsadovy/">Valeria Sadovykh on Instagram</a></p><p><a href="https://twitter.com/ValeriaSadovykh">Valeria Sadovykh on Twitter</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33013029" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/006be771-028a-48f1-8dc5-be57d54ff0d6/audio/c75485c1-4c3b-4702-ae25-0ac31dcaf34b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Microsoft Technical Strategist Valeria Sadovykh, PhD</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:34:23</itunes:duration>
      <itunes:summary>Valeria holds a PhD. in informative systems and has a wealth of knowledge and experience in the topic of responsible AI. She shares the findings of her doctoral research at the University of Auckland, what drew her to responsible AI, and how she encourages AI leaders to prioritize ethical design.</itunes:summary>
      <itunes:subtitle>Valeria holds a PhD. in informative systems and has a wealth of knowledge and experience in the topic of responsible AI. She shares the findings of her doctoral research at the University of Auckland, what drew her to responsible AI, and how she encourages AI leaders to prioritize ethical design.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>74</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">ee5d6ed4-992e-42c1-98f7-9ade40e1f58a</guid>
      <title>Gradient Ventures Founder Anna Patterson</title>
      <description><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>She shares her professional journey that eventually led to the founding of Gradient Ventures.</li><li>How Anna would contrast AI Winter to the standard hype cycles that exist.</li><li>Her thoughts on how the web and mobile sectors were under-hyped.</li><li>Those who decide if something falls out of favor; according to Anna.</li><li>How Anna navigates hype cycles.</li><li>Her process for evaluating early-stage AI companies. </li><li>How to assess whether someone is a tourist or truly committed to something.</li><li>Approaching problems and discerning whether AI is the right answer.</li><li>Her thoughts on the best application for AI or MLR technology. </li><li>Anna shares why she is excited about large language models (LLMs).</li><li>Thoughts on LLMs and whether we should or can we approach AGIs.</li><li>A discussion: do we limit machines when we teach them to speak the way we speak?</li><li>Quality AI and navigating fairness: the concept of the Human in the Loop.</li><li>Boring but essential data tasks: whose job is that?</li><li>How she feels about sensationalism.  </li><li>What gets her fired up when it is time to support new companies. </li><li>Advice to those forging careers in the AI and ML space. </li></ul><p>Tweetables:</p><p>“When that hype cycle happens, where it is overhyped and falls out of favor, then generally that is – what is called a winter.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:03:28]</p><p>“No matter how hyped you think AI is now, I think we are underestimating its change.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:04:06]</p><p>“When there is a lot of hype and then not as many breakthroughs or not as many applications that people think are transformational, then it starts to go through a winter.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:04:47]</p><p><a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:25:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/anna-patterson-15921ba/">Anna Patterson on LinkedIn</a></p><p><a href="https://www.gradient.com/blog/articles/eight-critical-approaches-to-llms/">‘Eight critical approaches to LLMs’</a></p><p><a href="https://www.gradient.com/blog/articles/the-next-programming-language-is-english/">‘The next programming language is English’</a></p><p><a href="http://jmc.stanford.edu/artificial-intelligence/slides/advice03-sli.pdf">‘The Advice Taker’</a></p><p><a href="https://www.gradient.com/">Gradient</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 9 Aug 2023 15:59:55 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/gradient-ventures-founder-anna-patterson-bB51NIoe</link>
      <content:encoded><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>She shares her professional journey that eventually led to the founding of Gradient Ventures.</li><li>How Anna would contrast AI Winter to the standard hype cycles that exist.</li><li>Her thoughts on how the web and mobile sectors were under-hyped.</li><li>Those who decide if something falls out of favor; according to Anna.</li><li>How Anna navigates hype cycles.</li><li>Her process for evaluating early-stage AI companies. </li><li>How to assess whether someone is a tourist or truly committed to something.</li><li>Approaching problems and discerning whether AI is the right answer.</li><li>Her thoughts on the best application for AI or MLR technology. </li><li>Anna shares why she is excited about large language models (LLMs).</li><li>Thoughts on LLMs and whether we should or can we approach AGIs.</li><li>A discussion: do we limit machines when we teach them to speak the way we speak?</li><li>Quality AI and navigating fairness: the concept of the Human in the Loop.</li><li>Boring but essential data tasks: whose job is that?</li><li>How she feels about sensationalism.  </li><li>What gets her fired up when it is time to support new companies. </li><li>Advice to those forging careers in the AI and ML space. </li></ul><p>Tweetables:</p><p>“When that hype cycle happens, where it is overhyped and falls out of favor, then generally that is – what is called a winter.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:03:28]</p><p>“No matter how hyped you think AI is now, I think we are underestimating its change.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:04:06]</p><p>“When there is a lot of hype and then not as many breakthroughs or not as many applications that people think are transformational, then it starts to go through a winter.” — <a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:04:47]</p><p><a href="https://twitter.com/annappatterson">@AnnapPatterson</a> [0:25:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/anna-patterson-15921ba/">Anna Patterson on LinkedIn</a></p><p><a href="https://www.gradient.com/blog/articles/eight-critical-approaches-to-llms/">‘Eight critical approaches to LLMs’</a></p><p><a href="https://www.gradient.com/blog/articles/the-next-programming-language-is-english/">‘The next programming language is English’</a></p><p><a href="http://jmc.stanford.edu/artificial-intelligence/slides/advice03-sli.pdf">‘The Advice Taker’</a></p><p><a href="https://www.gradient.com/">Gradient</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25118616" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f8da9ff9-c263-48fa-a8bc-db29973bf145/audio/825af0c8-c42d-4565-9100-1884df68a64e/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Gradient Ventures Founder Anna Patterson</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:09</itunes:duration>
      <itunes:summary>Anna Patterson is the Founder and Managing Partner of Gradient Ventures, a full-service seed and series A fund. We discuss the contrast between an AI winter and the standard hype cycles that exist, her thoughts on sectors that were initially under-hyped, how she navigates hype cycles, and why English is the next programming language. </itunes:summary>
      <itunes:subtitle>Anna Patterson is the Founder and Managing Partner of Gradient Ventures, a full-service seed and series A fund. We discuss the contrast between an AI winter and the standard hype cycles that exist, her thoughts on sectors that were initially under-hyped, how she navigates hype cycles, and why English is the next programming language. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>73</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">eb5a135a-f2f4-4e0d-a23d-8d02254a7b6f</guid>
      <title>Wayfair Director of Machine Learning Tulia Plumettaz</title>
      <description><![CDATA[<p>Wayfair uses AI and machine learning (ML) technology to interpret what its customers want, connect them with products nearby, and ensure that the products they see online look and feel the same as the ones that ultimately arrive in their homes. With a background in engineering and a passion for all things STEM, Wayfair’s Director of Machine Learning, Tulia Plumettaz, is an innate problem-solver. In this episode, she offers some insight into Wayfair’s ML-driven decision-making processes, how they implement AI and ML for preventative problem-solving and predictive maintenance, and how they use data enrichment and customization to help customers navigate the inspirational (and sometimes overwhelming) world of home decor. We also discuss the culture of experimentation at Wayfair and Tulia’s advice for those looking to build a career in machine learning.</p><p>Key Points From This Episode:</p><ul><li>A look at Tulia’s engineering background and how she ended up in this role at Wayfair.</li><li>Defining operations research and examples of its real-life applications.</li><li>What it means for something to be strategy-proof.</li><li>Different ways that AI and ML are being integrated at Wayfair.</li><li>The challenge of unstructured data and how Wayfair takes the onus off suppliers.</li><li>Wayfair’s North Star: detecting anomalies before they’re exposed to customers.</li><li>Preventative problem-solving and how Wayfair trains ML models to “see around corners.”</li><li>Examples of nuanced outlier detection and whether or not ML applications would be suitable.</li><li>Insight into Wayfair’s bespoke search tool and how it interprets customers’ needs.</li><li>The exploit-and-explore model Wayfair uses to measure success and improve accordingly.</li><li>Tulia’s advice for those forging a career in machine learning: go back to first principles!</li></ul><p>Tweetables:</p><p>“[Operations research is] a very broad field at the intersection between mathematics, computer science, and economics that [applies these toolkits] to solve real-life applications.” — Tulia Plumettaz [0:03:42]</p><p>“All the decision making, from which channel should I bring you in [with] to how do I bring you back if you’re taking your sweet time to make a decision to what we show you when you [visit our site], it’s all [machine learning]-driven.” — Tulia Plumettaz [0:09:58]</p><p>“We want to be in a place [where], as early as possible, before problems are even exposed to our customers, we’re able to detect them.” — Tulia Plumettaz [0:18:26]</p><p>“We have the challenge of making you buy something that you would traditionally feel, sit [on], and touch virtually, from the comfort of your sofa. How do we do that? [Through the] enrichment of information.” — Tulia Plumettaz [0:29:05]</p><p>“We knew that making it easier to navigate this very inspirational space was going to require customization.” — Tulia Plumettaz [0:29:39]</p><p>“At its core, it’s an exploit-and-explore process with a lot of hypothesis testing. Testing is at the core of [Wayfair] being able to say: this new version is better than [the previous] version.” — Tulia Plumettaz [0:31:53]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/tulia-plumettaz-20967550/">Tulia Plumettaz on LinkedIn</a></p><p><a href="https://www.wayfair.com/">Wayfair</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 28 Jul 2023 20:39:10 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/wayfair-director-of-machine-learning-tulia-plummetaz-7BQeJDBJ</link>
      <content:encoded><![CDATA[<p>Wayfair uses AI and machine learning (ML) technology to interpret what its customers want, connect them with products nearby, and ensure that the products they see online look and feel the same as the ones that ultimately arrive in their homes. With a background in engineering and a passion for all things STEM, Wayfair’s Director of Machine Learning, Tulia Plumettaz, is an innate problem-solver. In this episode, she offers some insight into Wayfair’s ML-driven decision-making processes, how they implement AI and ML for preventative problem-solving and predictive maintenance, and how they use data enrichment and customization to help customers navigate the inspirational (and sometimes overwhelming) world of home decor. We also discuss the culture of experimentation at Wayfair and Tulia’s advice for those looking to build a career in machine learning.</p><p>Key Points From This Episode:</p><ul><li>A look at Tulia’s engineering background and how she ended up in this role at Wayfair.</li><li>Defining operations research and examples of its real-life applications.</li><li>What it means for something to be strategy-proof.</li><li>Different ways that AI and ML are being integrated at Wayfair.</li><li>The challenge of unstructured data and how Wayfair takes the onus off suppliers.</li><li>Wayfair’s North Star: detecting anomalies before they’re exposed to customers.</li><li>Preventative problem-solving and how Wayfair trains ML models to “see around corners.”</li><li>Examples of nuanced outlier detection and whether or not ML applications would be suitable.</li><li>Insight into Wayfair’s bespoke search tool and how it interprets customers’ needs.</li><li>The exploit-and-explore model Wayfair uses to measure success and improve accordingly.</li><li>Tulia’s advice for those forging a career in machine learning: go back to first principles!</li></ul><p>Tweetables:</p><p>“[Operations research is] a very broad field at the intersection between mathematics, computer science, and economics that [applies these toolkits] to solve real-life applications.” — Tulia Plumettaz [0:03:42]</p><p>“All the decision making, from which channel should I bring you in [with] to how do I bring you back if you’re taking your sweet time to make a decision to what we show you when you [visit our site], it’s all [machine learning]-driven.” — Tulia Plumettaz [0:09:58]</p><p>“We want to be in a place [where], as early as possible, before problems are even exposed to our customers, we’re able to detect them.” — Tulia Plumettaz [0:18:26]</p><p>“We have the challenge of making you buy something that you would traditionally feel, sit [on], and touch virtually, from the comfort of your sofa. How do we do that? [Through the] enrichment of information.” — Tulia Plumettaz [0:29:05]</p><p>“We knew that making it easier to navigate this very inspirational space was going to require customization.” — Tulia Plumettaz [0:29:39]</p><p>“At its core, it’s an exploit-and-explore process with a lot of hypothesis testing. Testing is at the core of [Wayfair] being able to say: this new version is better than [the previous] version.” — Tulia Plumettaz [0:31:53]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/tulia-plumettaz-20967550/">Tulia Plumettaz on LinkedIn</a></p><p><a href="https://www.wayfair.com/">Wayfair</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33128803" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/5a208a76-9007-49e0-a645-3422f4d4a63e/audio/f2238f52-e560-4131-ac44-7b3a4caa9fa0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Wayfair Director of Machine Learning Tulia Plumettaz</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:34:30</itunes:duration>
      <itunes:summary>Tulia offers insight into Wayfair’s ML-driven decision-making processes, how they implement AI and ML for preventative problem-solving and predictive maintenance, and how they use data enrichment and customization to help customers navigate the inspirational (and sometimes overwhelming) world of home decor. </itunes:summary>
      <itunes:subtitle>Tulia offers insight into Wayfair’s ML-driven decision-making processes, how they implement AI and ML for preventative problem-solving and predictive maintenance, and how they use data enrichment and customization to help customers navigate the inspirational (and sometimes overwhelming) world of home decor. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>72</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">b6144b65-26e4-4b36-9c04-8985795ed029</guid>
      <title>FreeWheel&apos;s VP of Data Science Bob Bress</title>
      <description><![CDATA[<p>Bob highlights the importance of building interdepartmental relationships and growing a talented team of problem solvers, as well as the key role of continuous education. He also offers some insight into the technical and not-so-technical skills of a “data science champion,” tips for building adaptable data infrastructures, and the best career advice he has ever received, plus so much more. For an insider’s look at the data science operation at FreeWheel and valuable advice from an analytics leader with more than two decades of experience, be sure to tune in today!</p><p>Key Points From This Episode:</p><ul><li>A high-level overview of FreeWheel, Bob’s role there, and his career trajectory thus far.</li><li>Important intersections between data science and the organization at large.</li><li>Three indicators that FreeWheel is a data-driven company.</li><li>Why continuous education is a key component for agile data science teams.</li><li>The interplay between data science and the development of AI technology.</li><li>Technical (and other) skills that Bob looks for when recruiting new talent to his team.</li><li>Bob’s perspective on the value of interdepartmental collaboration.</li><li>Insight into what an adaptable data infrastructure looks like.</li><li>The importance of asking yourself, “What more can we do?”</li></ul><p>Tweetables:</p><p>“As a data science team, it’s not enough to be able to solve quantitative problems. You have to establish connections to the company in a way that uncovers those problems to begin with.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:06:42]</p><p>“The more we can do to educate folks – on the type of work that the [data science] team does, the better the position we are in to tackle more interesting problems and innovate around new ideas and concepts.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:09:49]</p><p>“There are so many interactions and dependencies across any project of sufficient complexity that it’s only through [collaboration] across teams that you’re going to be able to hone in on the right answer.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:17:34]</p><p>“There is always more you can do to enhance the work you’re doing, other questions you can ask, other ways you can go beyond just checking a box.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:23:31]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bobbress/">Bob Bress on LinkedIn</a></p><p><a href="https://twitter.com/bob_bress">Bob Bress on Twitter</a></p><p><a href="https://www.freewheel.com/">FreeWheel</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 19 Jul 2023 17:41:29 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/freewheels-vp-of-data-science-bob-bress-lVUvyaOs</link>
      <content:encoded><![CDATA[<p>Bob highlights the importance of building interdepartmental relationships and growing a talented team of problem solvers, as well as the key role of continuous education. He also offers some insight into the technical and not-so-technical skills of a “data science champion,” tips for building adaptable data infrastructures, and the best career advice he has ever received, plus so much more. For an insider’s look at the data science operation at FreeWheel and valuable advice from an analytics leader with more than two decades of experience, be sure to tune in today!</p><p>Key Points From This Episode:</p><ul><li>A high-level overview of FreeWheel, Bob’s role there, and his career trajectory thus far.</li><li>Important intersections between data science and the organization at large.</li><li>Three indicators that FreeWheel is a data-driven company.</li><li>Why continuous education is a key component for agile data science teams.</li><li>The interplay between data science and the development of AI technology.</li><li>Technical (and other) skills that Bob looks for when recruiting new talent to his team.</li><li>Bob’s perspective on the value of interdepartmental collaboration.</li><li>Insight into what an adaptable data infrastructure looks like.</li><li>The importance of asking yourself, “What more can we do?”</li></ul><p>Tweetables:</p><p>“As a data science team, it’s not enough to be able to solve quantitative problems. You have to establish connections to the company in a way that uncovers those problems to begin with.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:06:42]</p><p>“The more we can do to educate folks – on the type of work that the [data science] team does, the better the position we are in to tackle more interesting problems and innovate around new ideas and concepts.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:09:49]</p><p>“There are so many interactions and dependencies across any project of sufficient complexity that it’s only through [collaboration] across teams that you’re going to be able to hone in on the right answer.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:17:34]</p><p>“There is always more you can do to enhance the work you’re doing, other questions you can ask, other ways you can go beyond just checking a box.” — <a href="https://twitter.com/bob_bress">@Bob_Bress</a> [0:23:31]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bobbress/">Bob Bress on LinkedIn</a></p><p><a href="https://twitter.com/bob_bress">Bob Bress on Twitter</a></p><p><a href="https://www.freewheel.com/">FreeWheel</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24538070" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/603a97ae-f9fe-4062-a86a-608d2156a529/audio/b9b9e936-4ea2-4a2b-8dfa-d7e7ff827aed/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>FreeWheel&apos;s VP of Data Science Bob Bress</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:33</itunes:duration>
      <itunes:summary>Today on How AI Happens, we are joined by Bob Bress, the Vice President and Head of Data Science at FreeWheel, where he leads a team of data science experts in developing and implementing complex analytical solutions for leading-edge technology and advertising programs</itunes:summary>
      <itunes:subtitle>Today on How AI Happens, we are joined by Bob Bress, the Vice President and Head of Data Science at FreeWheel, where he leads a team of data science experts in developing and implementing complex analytical solutions for leading-edge technology and advertising programs</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>71</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">445321ed-18dc-4496-b373-b5b3c3a74340</guid>
      <title>Declarative ML with Ludwig Creator &amp; Predibase CEO &amp; Co-Founder Piero Molino</title>
      <description><![CDATA[<p>Low-code platforms provide a powerful and efficient way to develop applications and drive digital transformation and are becoming popular tools for organizations. In today’s episode, we are joined by Piero Molino, the CEO, and Co-Founder at Predibase, a company revolutionizing the field of machine learning by pioneering a low-code declarative approach. Predibase empowers engineers and data scientists to effortlessly construct, enhance, and implement cutting-edge models, ranging from linear regressions to expansive language models, using a mere handful of code lines. Piero is intrigued by the convergence of diverse cultural interests and finds great fascination in exploring the intricate ties between knowledge, language, and learning. His approach involves seeking unconventional solutions to problems and embracing a multidisciplinary approach that allows him to acquire novel and varied knowledge while gaining fresh experiences. In our conversation, we talk about his professional career journey, developing Ludwig, and how this eventually developed into Predibase. </p><p>Key Points From This Episode:</p><ul><li>Background about Piero’s professional experience and skill sets.</li><li>What his responsibilities were in his previous role at Uber.</li><li>Hear about his research at Stanford University.</li><li>Details about the motivation for Predibase: Ludwig AI. </li><li>Examples of the different Ludwig models and applications.</li><li>Challenges of software development.</li><li>How the community further developed his Ludwig machine learning tool.</li><li>The benefits of community involvement for developers.</li><li>Hear how his Ludwig project developed into Predibase.</li><li>He shares the inspiration behind the name Ludwig.</li><li>Why Predibase can be considered a low-code platform.</li><li>What the Predibase platform offers users and organizations.</li><li>Ethical considerations of democratizing data science tools.</li><li>The importance of a multidisciplinary approach to developing AI tools.</li><li>Advice for upcoming developers.</li></ul><p>Tweetables:</p><p>“One thing that I am proud of is the fact that the architecture is very extensible and really easy to plug and play new data types or new models.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:14:02]</p><p>“We are doing a bunch of things at Predibase that build on top of Ludwig and make it available and easy to use for organizations in the cloud.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:19:23]</p><p>“I believe that in the teams that actually put machine learning into production, there should be a combination of different skill sets.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:23:04]</p><p>“What made it possible for me to do the things that I have done is constant curiosity.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:26:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/pieromolino/">Piero Molino on LinkedIn</a></p><p><a href="https://twitter.com/w4nderlus7">Piero Molino on Twitter</a></p><p><a href="https://predibase.com">Predibase</a></p><p><a href="https://ludwig.ai/latest/">Ludwig</a></p><p><a href="https://www.mpg.de/en">Max-Planck-Institute</a></p><p><a href="https://www.loopr.ai">Loopr AI</a></p><p><a href="https://www.amazon.com/Wittgensteins-Mistress-David-Markson/dp/1564782115"><i>Wittgenstein's Mistress</i></a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 12 Jul 2023 21:01:48 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/declarative-ml-with-ludwig-creator-predibase-ceo-co-founder-piero-molino-3FbJ2jAo</link>
      <content:encoded><![CDATA[<p>Low-code platforms provide a powerful and efficient way to develop applications and drive digital transformation and are becoming popular tools for organizations. In today’s episode, we are joined by Piero Molino, the CEO, and Co-Founder at Predibase, a company revolutionizing the field of machine learning by pioneering a low-code declarative approach. Predibase empowers engineers and data scientists to effortlessly construct, enhance, and implement cutting-edge models, ranging from linear regressions to expansive language models, using a mere handful of code lines. Piero is intrigued by the convergence of diverse cultural interests and finds great fascination in exploring the intricate ties between knowledge, language, and learning. His approach involves seeking unconventional solutions to problems and embracing a multidisciplinary approach that allows him to acquire novel and varied knowledge while gaining fresh experiences. In our conversation, we talk about his professional career journey, developing Ludwig, and how this eventually developed into Predibase. </p><p>Key Points From This Episode:</p><ul><li>Background about Piero’s professional experience and skill sets.</li><li>What his responsibilities were in his previous role at Uber.</li><li>Hear about his research at Stanford University.</li><li>Details about the motivation for Predibase: Ludwig AI. </li><li>Examples of the different Ludwig models and applications.</li><li>Challenges of software development.</li><li>How the community further developed his Ludwig machine learning tool.</li><li>The benefits of community involvement for developers.</li><li>Hear how his Ludwig project developed into Predibase.</li><li>He shares the inspiration behind the name Ludwig.</li><li>Why Predibase can be considered a low-code platform.</li><li>What the Predibase platform offers users and organizations.</li><li>Ethical considerations of democratizing data science tools.</li><li>The importance of a multidisciplinary approach to developing AI tools.</li><li>Advice for upcoming developers.</li></ul><p>Tweetables:</p><p>“One thing that I am proud of is the fact that the architecture is very extensible and really easy to plug and play new data types or new models.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:14:02]</p><p>“We are doing a bunch of things at Predibase that build on top of Ludwig and make it available and easy to use for organizations in the cloud.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:19:23]</p><p>“I believe that in the teams that actually put machine learning into production, there should be a combination of different skill sets.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:23:04]</p><p>“What made it possible for me to do the things that I have done is constant curiosity.” — <a href="https://twitter.com/w4nderlus7">@w4nderlus7</a> [0:26:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/pieromolino/">Piero Molino on LinkedIn</a></p><p><a href="https://twitter.com/w4nderlus7">Piero Molino on Twitter</a></p><p><a href="https://predibase.com">Predibase</a></p><p><a href="https://ludwig.ai/latest/">Ludwig</a></p><p><a href="https://www.mpg.de/en">Max-Planck-Institute</a></p><p><a href="https://www.loopr.ai">Loopr AI</a></p><p><a href="https://www.amazon.com/Wittgensteins-Mistress-David-Markson/dp/1564782115"><i>Wittgenstein's Mistress</i></a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="26940500" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/1c9a3470-d855-4d82-a94c-d31037fd7356/audio/b9548cbe-174f-460f-b352-ec5c9c153998/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Declarative ML with Ludwig Creator &amp; Predibase CEO &amp; Co-Founder Piero Molino</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:03</itunes:duration>
      <itunes:summary>Piero Molino, the CEO and Co-Founder at Predibase and the creator of Ludwig.ai  discusses the various ways he applied AI at Uber, his background in machine learning, and leveraging AI to automate processes. We also unpack the benefits of configuration-based systems, democratizing data science tools, the ethical side of AI and data science, and why diverse teams are essential. </itunes:summary>
      <itunes:subtitle>Piero Molino, the CEO and Co-Founder at Predibase and the creator of Ludwig.ai  discusses the various ways he applied AI at Uber, his background in machine learning, and leveraging AI to automate processes. We also unpack the benefits of configuration-based systems, democratizing data science tools, the ethical side of AI and data science, and why diverse teams are essential. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>70</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">da763e04-5244-415d-9222-e66166337146</guid>
      <title>dRISK CEO Chess Stetson &amp; COO Rav Babbra</title>
      <description><![CDATA[<p>dRisk uses a unique approach to increasing AV safety: collecting real-life scenarios and data from accidents, insurance reports, and more to train autonomous vehicles on extreme edge cases. With their advanced simulation tool, they can accurately recreate and test these scenarios, allowing AV developers to improve the performance and safety of their vehicles. Join us as Chess and Rav delve into the exciting world of AVs and the challenges they face in creating safer and more efficient transportation systems.</p><p>Key Points From This Episode:</p><ul><li>Introducing dRisk Founder and CEO, Chess Stetson, and COO, Rav Babbra.</li><li>dRisk’s mission to help autonomous vehicles become better drivers than humans.</li><li>The UK government’s interest in autonomous vehicles to solve transportation problems.</li><li>Rav’s career background; how the CAVSim competition put dRisk on his radar.</li><li>How dRisk’s software presents real-life scenarios and extreme edge cases to test AVs.</li><li>Chess defines extreme edge cases in the AV realm and explains where AVs typically go wrong.</li><li>How the company uses natural language processing and AI-based techniques to improve simulation accuracy for AV testing.</li><li>The metrics used to ensure the accuracy of the simulations.</li><li>What makes AI different from humans in an AV context.</li><li>The benchmark for the capability of AVs; the tolerance for human driver error versus AV error.</li><li>Why third-party testing is a necessity for AI.</li><li>dRisk’s assessment process for autonomous vehicles.</li><li>The delicate balance between innovation and regulation.</li><li>Examples of AV edge cases.</li></ul><p>Tweetables:</p><p>“At the time, no autonomous vehicles could ever actually drive on the UK's roads. And that's where Chess and the team at dRisk have done such great piece of work.” — Rav Babbra [0:07:25]</p><p>“If you've got an unprotected cross-traffic turn, that's where a lot of things traditionally go wrong with AVs.” —Chess Stetson [0:08:45]</p><p>“We can, in an automated way, map out metrics for what might or might not constitute a good test and cut out things that would be something like a hallucination.” —Chess Stetson [0:13:59]</p><p>“The thing that makes AI different than humans is that if you have a good driver's test for an AI, it's also a good training environment for an AI. That's different [from] humans because humans have common sense.” — Chess Stetson [0:15:10]</p><p>“If you can really rigorously test [AI] on its ability to have common sense, you can also train it to have a certain amount of common sense.” — Chess Stetson [0:15:51]</p><p>“The difference between an AI and a human is that if you had a good test, it's equivalent to a good training environment.” — Chess Stetson [0:16:29]</p><p>“I personally think it's not unrealistic to imagine AV is getting so good that there's never a death on the road at all.” — Chess Stetson [0:18:50]</p><p>“One of the reasons that we're in the UK is precisely because the UK is going to have no tolerance for autonomous vehicle collisions.” — Chess Stetson [0:20:08]</p><p>“Now, there's never a cow in the highway here in the UK, but of course, things do fall off lorries. So if we can train against a cow sitting on the highway, then the next time a grand piano falls off the back of a truck, we've got some training data at least that helps it avoid that.” — Rav Babbra [0:35:12]</p><p>“If you target the worst case scenario, everything underneath, you've been able to capture and deal with.” — Rav Babbra [0:36:08]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://www.chessstetson.com/">Chess Stetson</a></p><p><a href="https://www.linkedin.com/in/chessstetson/">Chess Stetson on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/rav-babbra-16501819/">Rav Babbra on LinkedIn</a></p><p><a href="https://drisk.ai/">dRISK</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 30 Jun 2023 18:04:31 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/drisk-ceo-chess-stetson-coo-rav-babbra-0gzdv8dt</link>
      <content:encoded><![CDATA[<p>dRisk uses a unique approach to increasing AV safety: collecting real-life scenarios and data from accidents, insurance reports, and more to train autonomous vehicles on extreme edge cases. With their advanced simulation tool, they can accurately recreate and test these scenarios, allowing AV developers to improve the performance and safety of their vehicles. Join us as Chess and Rav delve into the exciting world of AVs and the challenges they face in creating safer and more efficient transportation systems.</p><p>Key Points From This Episode:</p><ul><li>Introducing dRisk Founder and CEO, Chess Stetson, and COO, Rav Babbra.</li><li>dRisk’s mission to help autonomous vehicles become better drivers than humans.</li><li>The UK government’s interest in autonomous vehicles to solve transportation problems.</li><li>Rav’s career background; how the CAVSim competition put dRisk on his radar.</li><li>How dRisk’s software presents real-life scenarios and extreme edge cases to test AVs.</li><li>Chess defines extreme edge cases in the AV realm and explains where AVs typically go wrong.</li><li>How the company uses natural language processing and AI-based techniques to improve simulation accuracy for AV testing.</li><li>The metrics used to ensure the accuracy of the simulations.</li><li>What makes AI different from humans in an AV context.</li><li>The benchmark for the capability of AVs; the tolerance for human driver error versus AV error.</li><li>Why third-party testing is a necessity for AI.</li><li>dRisk’s assessment process for autonomous vehicles.</li><li>The delicate balance between innovation and regulation.</li><li>Examples of AV edge cases.</li></ul><p>Tweetables:</p><p>“At the time, no autonomous vehicles could ever actually drive on the UK's roads. And that's where Chess and the team at dRisk have done such great piece of work.” — Rav Babbra [0:07:25]</p><p>“If you've got an unprotected cross-traffic turn, that's where a lot of things traditionally go wrong with AVs.” —Chess Stetson [0:08:45]</p><p>“We can, in an automated way, map out metrics for what might or might not constitute a good test and cut out things that would be something like a hallucination.” —Chess Stetson [0:13:59]</p><p>“The thing that makes AI different than humans is that if you have a good driver's test for an AI, it's also a good training environment for an AI. That's different [from] humans because humans have common sense.” — Chess Stetson [0:15:10]</p><p>“If you can really rigorously test [AI] on its ability to have common sense, you can also train it to have a certain amount of common sense.” — Chess Stetson [0:15:51]</p><p>“The difference between an AI and a human is that if you had a good test, it's equivalent to a good training environment.” — Chess Stetson [0:16:29]</p><p>“I personally think it's not unrealistic to imagine AV is getting so good that there's never a death on the road at all.” — Chess Stetson [0:18:50]</p><p>“One of the reasons that we're in the UK is precisely because the UK is going to have no tolerance for autonomous vehicle collisions.” — Chess Stetson [0:20:08]</p><p>“Now, there's never a cow in the highway here in the UK, but of course, things do fall off lorries. So if we can train against a cow sitting on the highway, then the next time a grand piano falls off the back of a truck, we've got some training data at least that helps it avoid that.” — Rav Babbra [0:35:12]</p><p>“If you target the worst case scenario, everything underneath, you've been able to capture and deal with.” — Rav Babbra [0:36:08]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://www.chessstetson.com/">Chess Stetson</a></p><p><a href="https://www.linkedin.com/in/chessstetson/">Chess Stetson on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/rav-babbra-16501819/">Rav Babbra on LinkedIn</a></p><p><a href="https://drisk.ai/">dRISK</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="33918746" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/81723b53-0262-4370-919f-b89f67e53473/audio/82605aea-1e9f-4a17-9970-9a5066534aaf/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>dRISK CEO Chess Stetson &amp; COO Rav Babbra</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:19</itunes:duration>
      <itunes:summary>In this episode of How AI Happens, we are joined by autonomous vehicle experts Rav Babbra and Chess Stetson. Respectively, Rav and Chess are the COO and Founder/CEO of dRisk and in this episode, they discuss their work at dRisk and their mission to solve a critical aspect of autonomous driving: making AVs 100x safer than human drivers.</itunes:summary>
      <itunes:subtitle>In this episode of How AI Happens, we are joined by autonomous vehicle experts Rav Babbra and Chess Stetson. Respectively, Rav and Chess are the COO and Founder/CEO of dRisk and in this episode, they discuss their work at dRisk and their mission to solve a critical aspect of autonomous driving: making AVs 100x safer than human drivers.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>69</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">6134b2fd-18cd-40ad-b0e4-e6383e619e24</guid>
      <title>Stantec GenerationAV Founder Corey Clothier</title>
      <description><![CDATA[<p> In this episode, we learn about the common challenges companies face when it comes to developing and deploying their AV and how Stantec uses military and aviation best practices to remove human error and ensure safety and reliability in AV operations. Corey explains the importance of collecting edge cases and shares his take on why the autonomous mobility industry is so meaningful. </p><p>Key Points From This Episode:</p><ul><li>Introducing Autonomous Mobility Strategist and Stantec GenerationAV Founder Corey Clothier.</li><li>Corey breaks down his typical week.</li><li>Applications for autonomously mobile wheelchairs.</li><li>Corey’s experience working in robotics for the Department of Defense.</li><li>The state of autonomy back in 2009 and 2010.</li><li>Corey’s definition of commercialization.</li><li>Why there’s less forgiveness for downtime with autonomous vehicles than human-operated vehicles.</li><li>How people’s attitudes around autonomy and robotics differ in different parts of the world.</li><li>The sensationalism around autonomous vehicle “crashes.”</li><li>Stantec’s approach to measuring and assessing the safety and risk of autonomous vehicles. </li><li>Why it’s so crucial to collect edge cases and how solving for them is applied downstream.</li><li>The common challenges companies face when it comes to deploying and developing their AV.</li><li>How Stantec uses military and aviation best practices to remove human error in AV operations.</li><li>The advantages of and opportunities behind AV.</li><li>Advice for those hoping to forge an impactful career in autonomous vehicles.</li></ul><p>Tweetables:</p><p>“For me, [commercialization] is a safe and reliable service that actually can perform the job that it's supposed to.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:07:04]</p><p>“Most of the autonomous vehicles that I've been working with, even since the beginning, most of them are pretty safe.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:08:01]</p><p>“When you start to talk to people from around the world, they absolutely have different attitudes related to autonomy and robotics.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:09:20]</p><p>“What's exciting though is about dRISK [is] it gives us a quantifiable risk measure, something that we can look at as a baseline and then something we can see as we make improvements and do mitigation strategies.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:17:18]</p><p>“The common challenges really are being able to handle all the edge cases in the operating environment that they're going to deploy.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:20:41]</p><p> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/coreyclothier/">Corey Clothier on LinkedIn</a></p><p><a href="https://twitter.com/coreyclothier">Corey Clothier on Twitter</a></p><p><a href="https://www.stantec.com/">Stantec</a></p><p><a href="https://drisk.ai/">dRISK</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 15 Jun 2023 19:24:02 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/stantec-generationav-founder-corey-clothier-nIt68nqb</link>
      <content:encoded><![CDATA[<p> In this episode, we learn about the common challenges companies face when it comes to developing and deploying their AV and how Stantec uses military and aviation best practices to remove human error and ensure safety and reliability in AV operations. Corey explains the importance of collecting edge cases and shares his take on why the autonomous mobility industry is so meaningful. </p><p>Key Points From This Episode:</p><ul><li>Introducing Autonomous Mobility Strategist and Stantec GenerationAV Founder Corey Clothier.</li><li>Corey breaks down his typical week.</li><li>Applications for autonomously mobile wheelchairs.</li><li>Corey’s experience working in robotics for the Department of Defense.</li><li>The state of autonomy back in 2009 and 2010.</li><li>Corey’s definition of commercialization.</li><li>Why there’s less forgiveness for downtime with autonomous vehicles than human-operated vehicles.</li><li>How people’s attitudes around autonomy and robotics differ in different parts of the world.</li><li>The sensationalism around autonomous vehicle “crashes.”</li><li>Stantec’s approach to measuring and assessing the safety and risk of autonomous vehicles. </li><li>Why it’s so crucial to collect edge cases and how solving for them is applied downstream.</li><li>The common challenges companies face when it comes to deploying and developing their AV.</li><li>How Stantec uses military and aviation best practices to remove human error in AV operations.</li><li>The advantages of and opportunities behind AV.</li><li>Advice for those hoping to forge an impactful career in autonomous vehicles.</li></ul><p>Tweetables:</p><p>“For me, [commercialization] is a safe and reliable service that actually can perform the job that it's supposed to.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:07:04]</p><p>“Most of the autonomous vehicles that I've been working with, even since the beginning, most of them are pretty safe.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:08:01]</p><p>“When you start to talk to people from around the world, they absolutely have different attitudes related to autonomy and robotics.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:09:20]</p><p>“What's exciting though is about dRISK [is] it gives us a quantifiable risk measure, something that we can look at as a baseline and then something we can see as we make improvements and do mitigation strategies.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:17:18]</p><p>“The common challenges really are being able to handle all the edge cases in the operating environment that they're going to deploy.” — <a href="https://twitter.com/coreyclothier">@coreyclothier</a> [0:20:41]</p><p> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/coreyclothier/">Corey Clothier on LinkedIn</a></p><p><a href="https://twitter.com/coreyclothier">Corey Clothier on Twitter</a></p><p><a href="https://www.stantec.com/">Stantec</a></p><p><a href="https://drisk.ai/">dRISK</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25704594" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/c2464c32-9a4d-4858-b5f8-671d0542103b/audio/69c5f6e0-d661-4b09-b2b0-57720b49e583/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Stantec GenerationAV Founder Corey Clothier</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:46</itunes:duration>
      <itunes:summary>Today we are joined by Autonomous Mobility Strategist and Stantec GenerationAV Founder, Corey Clothier, to discuss Stantec’s approach to measuring and assessing the safety and risk of autonomous vehicles prior to deployment. Corey specializes in helping people solve operational and go-to-market challenges for all things AV, from wheelchairs and personal mobility devices to heavy trucks and delivery robots.</itunes:summary>
      <itunes:subtitle>Today we are joined by Autonomous Mobility Strategist and Stantec GenerationAV Founder, Corey Clothier, to discuss Stantec’s approach to measuring and assessing the safety and risk of autonomous vehicles prior to deployment. Corey specializes in helping people solve operational and go-to-market challenges for all things AV, from wheelchairs and personal mobility devices to heavy trucks and delivery robots.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>68</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">c5f9e19e-b39d-4a50-ae0f-cd06536ab5b1</guid>
      <title>Credit Karma VP Engineering Vishnu Ram</title>
      <description><![CDATA[<p>Vishnu provides valuable advice for data scientists who want to help create high-quality data that can be used effectively to impact business outcomes. Tune in to gain insights from Vishnu's extensive experience in engineering leadership and data technologies.</p><p>Key Points From This Episode:</p><ul><li>An introduction to Vishnu Ram, his background, and how he came to Credit Karma. </li><li>His prior exposure to AI in the form of fuzzy logic and neural networks.</li><li>What Credit Karma needed to do before the injection of AI into its data functions. </li><li>The journey of building Credit Karma into the data science operation that it is. </li><li>Challenges of building the models in time so the data isn’t outdated by the time it can be used.</li><li>The nature of technical debt</li><li>How compensating for technical debt with people or processes is different from normal business growth.</li><li>The current data culture of Credit Karma.</li><li>Some pros and cons of a multi-team approach when introducing new platforms or frameworks.</li><li>The process of adopting TensorFlow and injecting it in a meaningful way.</li><li>How they mapped the need for this new model to a business use case and the internal education that was needed to make this change. </li><li>Insight into the shift from being an individual contributor into a management position with organization-wide challenges.</li><li>Advice to data scientists wanting to help to create a data culture that results in clean, usable, high-quality data.</li></ul><p>Tweetables:</p><p>“One of the things that we always care about [at Credit Karma] is making sure that when you are recommending any financial products in front of the users, we provide them with a sense of certainty.” — Vishnu Ram [0:05:59]</p><p>“One of the big things that we had to do, pretty much right off the bat, was make sure that our data scientists were able to get access to the data at scale — and be able to build the models in time so that the model maps to the future and performs well for the future.” — Vishnu Ram [0:08:00]</p><p>“Whenever we want to introduce new platforms or frameworks, both the teams that own that framework as well as the teams that are going to use that framework or platform would work together to build it up from scratch.” — Vishnu Ram [0:15:11]</p><p>“If your consumers have done their own research, it’s a no-brainer to start including them because they’re going to help you see around the corner and make sure you're making the right decisions at the right time.” — Vishnu Ram [0:16:43]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/vishnuvram/">Vishnu Ram</a></p><p><a href="https://www.creditkarma.com/">Credit Karma</a></p><p><a href="https://www.tensorflow.org/">TensorFlow</a></p><p><a href="https://research.google/pubs/pub46484/">TFX: A TensorFlow-Based Production-Scale Machine Learning Platform</a> [19:15] </p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 11 May 2023 19:43:41 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/credit-karma-vp-engineering-vishnu-ram-_NBOsPs_</link>
      <content:encoded><![CDATA[<p>Vishnu provides valuable advice for data scientists who want to help create high-quality data that can be used effectively to impact business outcomes. Tune in to gain insights from Vishnu's extensive experience in engineering leadership and data technologies.</p><p>Key Points From This Episode:</p><ul><li>An introduction to Vishnu Ram, his background, and how he came to Credit Karma. </li><li>His prior exposure to AI in the form of fuzzy logic and neural networks.</li><li>What Credit Karma needed to do before the injection of AI into its data functions. </li><li>The journey of building Credit Karma into the data science operation that it is. </li><li>Challenges of building the models in time so the data isn’t outdated by the time it can be used.</li><li>The nature of technical debt</li><li>How compensating for technical debt with people or processes is different from normal business growth.</li><li>The current data culture of Credit Karma.</li><li>Some pros and cons of a multi-team approach when introducing new platforms or frameworks.</li><li>The process of adopting TensorFlow and injecting it in a meaningful way.</li><li>How they mapped the need for this new model to a business use case and the internal education that was needed to make this change. </li><li>Insight into the shift from being an individual contributor into a management position with organization-wide challenges.</li><li>Advice to data scientists wanting to help to create a data culture that results in clean, usable, high-quality data.</li></ul><p>Tweetables:</p><p>“One of the things that we always care about [at Credit Karma] is making sure that when you are recommending any financial products in front of the users, we provide them with a sense of certainty.” — Vishnu Ram [0:05:59]</p><p>“One of the big things that we had to do, pretty much right off the bat, was make sure that our data scientists were able to get access to the data at scale — and be able to build the models in time so that the model maps to the future and performs well for the future.” — Vishnu Ram [0:08:00]</p><p>“Whenever we want to introduce new platforms or frameworks, both the teams that own that framework as well as the teams that are going to use that framework or platform would work together to build it up from scratch.” — Vishnu Ram [0:15:11]</p><p>“If your consumers have done their own research, it’s a no-brainer to start including them because they’re going to help you see around the corner and make sure you're making the right decisions at the right time.” — Vishnu Ram [0:16:43]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/vishnuvram/">Vishnu Ram</a></p><p><a href="https://www.creditkarma.com/">Credit Karma</a></p><p><a href="https://www.tensorflow.org/">TensorFlow</a></p><p><a href="https://research.google/pubs/pub46484/">TFX: A TensorFlow-Based Production-Scale Machine Learning Platform</a> [19:15] </p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="30221061" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/04c48075-deaf-433f-a72e-fabf32591e58/audio/f75bbfbe-432f-4358-bd83-886bcafeeb40/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Credit Karma VP Engineering Vishnu Ram</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:28</itunes:duration>
      <itunes:summary>With close to nine years of experience at Credit Karma, Vishnu has been instrumental in building the company&apos;s data science operation from the ground up. He discusses the challenges of alleviating technical debt, the importance of setting up a data culture, and the process of adopting new platforms and frameworks such as TensorFlow. </itunes:summary>
      <itunes:subtitle>With close to nine years of experience at Credit Karma, Vishnu has been instrumental in building the company&apos;s data science operation from the ground up. He discusses the challenges of alleviating technical debt, the importance of setting up a data culture, and the process of adopting new platforms and frameworks such as TensorFlow. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>67</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">329f3777-1082-4b4c-93c3-01f118794650</guid>
      <title>Vector Search with Algolia CTO Sean Mullaney</title>
      <description><![CDATA[<p>Algolia is an AI-powered search and discovery platform that helps businesses deliver fast, personalized search experiences.  In our conversation, Sean shares what ignited his passion for AI and how Algolia is using AI to deliver lightning-fast custom search results to each user. He explains how Algolia's AI algorithms learn from user behavior and talks about the challenges and opportunities of implementing AI in search and discovery processes. We discuss improving the user experience through AI, why technologies like ChatGPT are disrupting the market, and how Algolia is providing innovative solutions. Learn about “hashing,” the difference between keyword and vector searches, the company’s approach to ranking, and much more. </p><p>Key Points From This Episode:</p><ul><li>Learn about Sean’s professional journey and previous experience working with AI and e-commerce.</li><li>Discover why Sean is so passionate about the technology industry and how he was able to see gaps within the e-commerce user experience.</li><li>Gain insights into the challenges currently facing search engines and why it's not just about how you ask the search engine but also about how it responds.</li><li>Get an overview of how Algolia's search algorithm differs from the rest and how it trains results on context to deliver lightning-fast, relevant results.</li><li>Learn about the problems with vectors and how Algolia is using AI to revolutionize the search and discovery process.</li><li>Sean explains Algolia's approach to ranking search results and shares details about Algolia's new decompression algorithm.</li><li>Discover how Algolia's breakthroughs were inspired by different fields like biology and the problems facing search engine optimization for the e-commerce sector.</li><li>Find out when users can expect to see Algolia's approach to search outside of the e-commerce experience.</li></ul><p>Tweetables:</p><p>“Well, the great thing is that every 10 years the entire technology industry changes, so there is never a shortage of new technology to learn and new things to build.” — Sean Mullaney [0:05:08]</p><p>“It is not just the way that you ask the search engine the question, it is also the way the search engine responds regarding search optimization.” — Sean Mullaney [0:08:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/seanmullaney/">Sean Mullaney on LinkedIn</a></p><p><a href="https://www.algolia.com">Algolia</a></p><p><a href="https://chat.openai.com">ChatGPT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 4 May 2023 19:34:43 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/vector-search-with-algolia-cto-sean-mullaney-lVXtl5wV</link>
      <content:encoded><![CDATA[<p>Algolia is an AI-powered search and discovery platform that helps businesses deliver fast, personalized search experiences.  In our conversation, Sean shares what ignited his passion for AI and how Algolia is using AI to deliver lightning-fast custom search results to each user. He explains how Algolia's AI algorithms learn from user behavior and talks about the challenges and opportunities of implementing AI in search and discovery processes. We discuss improving the user experience through AI, why technologies like ChatGPT are disrupting the market, and how Algolia is providing innovative solutions. Learn about “hashing,” the difference between keyword and vector searches, the company’s approach to ranking, and much more. </p><p>Key Points From This Episode:</p><ul><li>Learn about Sean’s professional journey and previous experience working with AI and e-commerce.</li><li>Discover why Sean is so passionate about the technology industry and how he was able to see gaps within the e-commerce user experience.</li><li>Gain insights into the challenges currently facing search engines and why it's not just about how you ask the search engine but also about how it responds.</li><li>Get an overview of how Algolia's search algorithm differs from the rest and how it trains results on context to deliver lightning-fast, relevant results.</li><li>Learn about the problems with vectors and how Algolia is using AI to revolutionize the search and discovery process.</li><li>Sean explains Algolia's approach to ranking search results and shares details about Algolia's new decompression algorithm.</li><li>Discover how Algolia's breakthroughs were inspired by different fields like biology and the problems facing search engine optimization for the e-commerce sector.</li><li>Find out when users can expect to see Algolia's approach to search outside of the e-commerce experience.</li></ul><p>Tweetables:</p><p>“Well, the great thing is that every 10 years the entire technology industry changes, so there is never a shortage of new technology to learn and new things to build.” — Sean Mullaney [0:05:08]</p><p>“It is not just the way that you ask the search engine the question, it is also the way the search engine responds regarding search optimization.” — Sean Mullaney [0:08:04]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/seanmullaney/">Sean Mullaney on LinkedIn</a></p><p><a href="https://www.algolia.com">Algolia</a></p><p><a href="https://chat.openai.com">ChatGPT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="34114351" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/0b3c6402-ebaf-4b6c-a724-d3d4b6da398e/audio/7e5b7346-9389-4e45-b45b-4a53ed7c4614/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Vector Search with Algolia CTO Sean Mullaney</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:32</itunes:duration>
      <itunes:summary>Sean explains ins and outs of Algolia&apos;s disruptive vector search technology, and why vector search provides much more relevant results than keyword-based search.</itunes:summary>
      <itunes:subtitle>Sean explains ins and outs of Algolia&apos;s disruptive vector search technology, and why vector search provides much more relevant results than keyword-based search.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>66</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">332f0545-b8ee-4cc0-b0e5-c60ca072df10</guid>
      <title>Assessing Computer Vision Models with Roboflow&apos;s Piotr Skalski</title>
      <description><![CDATA[<p>Today’s guest is a Developer Advocate and Machine Learning Growth Engineer at Roboflow who has the pleasure of providing Roboflow users with all the information they need to use computer vision products optimally. In this episode, Piotr shares an overview of his educational and career trajectory to date; from starting out as a civil engineering graduate to founding an open source project that was way ahead of its time to breaking the million reader milestone on Medium. We also discuss Meta’s Segment Anything Model, the value of packaged models over non-packaged ones, and how computer vision models are becoming more accessible. </p><p>Key Points From This Episode:</p><ul><li>What Piotr’s current roles at Roboflow entail.</li><li>An overview of Piotr’s educational and career journey to date.</li><li>The Medium milestone that Piotr recently achieved.</li><li>The motivation behind Piotr’s open source project, Make Sense (and the impact it has had). </li><li>Piotr’s approach to assessing computer vision models. </li><li>The issue of lack of support in the computer vision space. </li><li>Why Piotr is an advocate of packaged models. </li><li>What makes Meta’s Segment Anything Model so novel and exciting. </li><li>An example that highlights how computer vision models are becoming more accessible. </li><li>Piotr’s thoughts about the future potential of ChatGPT.</li></ul><p>Tweetables:</p><p>“Not only [do] I showcase [computer vision] models but I also show people how to use them to solve some frequent problems.” — Piotr Skalski [0:10:14]</p><p>“I am always a fan of models that are packaged.” — Piotr Skalski [0:15:58]</p><p>“We are drifting towards a direction where users of those models will not necessarily have to be very good at computer vision to use them and create complicated things.” — Piotr Skalski [0:32:15]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/skalskip92/">Piotr Skalski on LinkedIn</a></p><p><a href="https://skalskip.medium.com/">Piotr Skalski on Medium</a></p><p><a href="https://skalskip.github.io/make-sense/">Make Sense</a></p><p><a href="https://roboflow.com/">Roboflow</a></p><p><a href="https://segment-anything.com/">Segment Anything by Meta AI</a></p><p><a href="https://blog.roboflow.com/how-to-use-segment-anything-model-sam/">How to Use the Segment Anything Model</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 13 Apr 2023 19:09:29 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/assessing-computer-vision-models-with-roboflows-piotr-skalski-__PycaJZ</link>
      <content:encoded><![CDATA[<p>Today’s guest is a Developer Advocate and Machine Learning Growth Engineer at Roboflow who has the pleasure of providing Roboflow users with all the information they need to use computer vision products optimally. In this episode, Piotr shares an overview of his educational and career trajectory to date; from starting out as a civil engineering graduate to founding an open source project that was way ahead of its time to breaking the million reader milestone on Medium. We also discuss Meta’s Segment Anything Model, the value of packaged models over non-packaged ones, and how computer vision models are becoming more accessible. </p><p>Key Points From This Episode:</p><ul><li>What Piotr’s current roles at Roboflow entail.</li><li>An overview of Piotr’s educational and career journey to date.</li><li>The Medium milestone that Piotr recently achieved.</li><li>The motivation behind Piotr’s open source project, Make Sense (and the impact it has had). </li><li>Piotr’s approach to assessing computer vision models. </li><li>The issue of lack of support in the computer vision space. </li><li>Why Piotr is an advocate of packaged models. </li><li>What makes Meta’s Segment Anything Model so novel and exciting. </li><li>An example that highlights how computer vision models are becoming more accessible. </li><li>Piotr’s thoughts about the future potential of ChatGPT.</li></ul><p>Tweetables:</p><p>“Not only [do] I showcase [computer vision] models but I also show people how to use them to solve some frequent problems.” — Piotr Skalski [0:10:14]</p><p>“I am always a fan of models that are packaged.” — Piotr Skalski [0:15:58]</p><p>“We are drifting towards a direction where users of those models will not necessarily have to be very good at computer vision to use them and create complicated things.” — Piotr Skalski [0:32:15]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/skalskip92/">Piotr Skalski on LinkedIn</a></p><p><a href="https://skalskip.medium.com/">Piotr Skalski on Medium</a></p><p><a href="https://skalskip.github.io/make-sense/">Make Sense</a></p><p><a href="https://roboflow.com/">Roboflow</a></p><p><a href="https://segment-anything.com/">Segment Anything by Meta AI</a></p><p><a href="https://blog.roboflow.com/how-to-use-segment-anything-model-sam/">How to Use the Segment Anything Model</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="36024425" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/78b69027-276b-401d-9d75-0ab36311269a/audio/baf0944c-b600-483e-90ff-ae85e58f076d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Assessing Computer Vision Models with Roboflow&apos;s Piotr Skalski</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:37:31</itunes:duration>
      <itunes:summary>Piotr discusses his criteria for evaluating computer vision models, as well as a breakdown of what makes Meta&apos;s recent &quot;Segment Anything&quot; Model exciting.</itunes:summary>
      <itunes:subtitle>Piotr discusses his criteria for evaluating computer vision models, as well as a breakdown of what makes Meta&apos;s recent &quot;Segment Anything&quot; Model exciting.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>65</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">33812121-3f42-4148-97dc-763fd220356c</guid>
      <title>DataRobot&apos;s Global AI Ethicist Haniyeh Mahmoudian, Ph.D</title>
      <description><![CDATA[<p>In our conversation, we learn about her professional journey and how this led to her working at DataRobot, what she realized was missing from the DataRobot platform, and what she did to fill the gap. We discuss the importance of bias in AI models, approaches to mitigate models against bias, and why incorporating ethics into AI development is essential. We also delve into the different perspectives of ethical AI, the elements of trust, what ethical “guard rails” are, and the governance side of AI. </p><p>Key Points From This Episode:</p><ul><li>Dr. Mahmoudian shares her professional background and her interest in AI.</li><li>How Dr. Mahmoudian became interested in AI ethics and building trustworthy AI.</li><li>What she hopes to achieve with her work and research. </li><li>Hear practical examples of how to build ethical and trustworthy AI.</li><li>We unpack the ethical and trustworthy aspects of AI development.</li><li>What the elements of trust are and how to implement them into a system.</li><li>An overview of the different essential processes that must be included in a model.</li><li>How to mitigate systems from bias and the role of monitoring.</li><li>Why continual improvement is key to ethical AI development.</li><li>Find out more about DataRobot and Dr. Mahmoudian’s multiple roles at the company.</li><li>She explains her approach to working with customers.</li><li>Discover simple steps to begin practicing responsible AI development.</li></ul><p>Tweetables:</p><p>“When we talk about ‘guard rails’ sometimes you can think of the best practice type of ‘guard rails’ in data science but we should also expand it to the governance and ethics side of it.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:11:03]</p><p>“Ethics should be included as part of [trust] to truly be able to think about trusting a system.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:13:15]</p><p>“[I think of] ethics as a sub-category but in a broader term of trust within a system.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:14:32]</p><p>“So depending on the [user] persona, we would need to think about what kind of [system] features we would have .” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:17:25]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/haniyeh-mahmoudian-ph-d-78a18072/">Haniyeh Mahmoudian on LinkedIn</a></p><p><a href="https://twitter.com/HaniyehMah">Haniyeh Mahmoudian on Twitter</a></p><p><a href="https://www.datarobot.com">DataRobot</a></p><p><a href="https://www.caidp.org/resources/naiac/">National AI Advisory Committee</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 30 Mar 2023 12:35:46 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/datarobots-global-ai-ethicist-haniyeh-mahmoudian-phd-Sm8_xamM</link>
      <content:encoded><![CDATA[<p>In our conversation, we learn about her professional journey and how this led to her working at DataRobot, what she realized was missing from the DataRobot platform, and what she did to fill the gap. We discuss the importance of bias in AI models, approaches to mitigate models against bias, and why incorporating ethics into AI development is essential. We also delve into the different perspectives of ethical AI, the elements of trust, what ethical “guard rails” are, and the governance side of AI. </p><p>Key Points From This Episode:</p><ul><li>Dr. Mahmoudian shares her professional background and her interest in AI.</li><li>How Dr. Mahmoudian became interested in AI ethics and building trustworthy AI.</li><li>What she hopes to achieve with her work and research. </li><li>Hear practical examples of how to build ethical and trustworthy AI.</li><li>We unpack the ethical and trustworthy aspects of AI development.</li><li>What the elements of trust are and how to implement them into a system.</li><li>An overview of the different essential processes that must be included in a model.</li><li>How to mitigate systems from bias and the role of monitoring.</li><li>Why continual improvement is key to ethical AI development.</li><li>Find out more about DataRobot and Dr. Mahmoudian’s multiple roles at the company.</li><li>She explains her approach to working with customers.</li><li>Discover simple steps to begin practicing responsible AI development.</li></ul><p>Tweetables:</p><p>“When we talk about ‘guard rails’ sometimes you can think of the best practice type of ‘guard rails’ in data science but we should also expand it to the governance and ethics side of it.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:11:03]</p><p>“Ethics should be included as part of [trust] to truly be able to think about trusting a system.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:13:15]</p><p>“[I think of] ethics as a sub-category but in a broader term of trust within a system.” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:14:32]</p><p>“So depending on the [user] persona, we would need to think about what kind of [system] features we would have .” — <a href="https://twitter.com/HaniyehMah">@HaniyehMah</a> [0:17:25]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/haniyeh-mahmoudian-ph-d-78a18072/">Haniyeh Mahmoudian on LinkedIn</a></p><p><a href="https://twitter.com/HaniyehMah">Haniyeh Mahmoudian on Twitter</a></p><p><a href="https://www.datarobot.com">DataRobot</a></p><p><a href="https://www.caidp.org/resources/naiac/">National AI Advisory Committee</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31128033" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/cfb66c24-24f8-4401-b926-a153b8ba1069/audio/b4136541-6224-48c6-be21-dbc99198407c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>DataRobot&apos;s Global AI Ethicist Haniyeh Mahmoudian, Ph.D</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:25</itunes:duration>
      <itunes:summary>Joining How AI Happens today is Dr. Haniyeh Mahmoudian,  Global AI Ethicist at DataRobot. Dr. Mahmoudian specializes in providing technical and educational guidance on the development of responsible AI. She holds a Ph.D. in Astronomy and Astrophysics from Bonn University, and was named an AI Ethics leader by Forbes. She is also a member of the National AI Advisory committee (NAIAC) that guides the President on ethical AI development and use. </itunes:summary>
      <itunes:subtitle>Joining How AI Happens today is Dr. Haniyeh Mahmoudian,  Global AI Ethicist at DataRobot. Dr. Mahmoudian specializes in providing technical and educational guidance on the development of responsible AI. She holds a Ph.D. in Astronomy and Astrophysics from Bonn University, and was named an AI Ethics leader by Forbes. She is also a member of the National AI Advisory committee (NAIAC) that guides the President on ethical AI development and use. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>64</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">0df1616b-414c-4d69-ab92-731bed883280</guid>
      <title>Data Scientist &amp; Developer Advocate Kristen Kehrer</title>
      <description><![CDATA[<p>Kristen is also the founder of Data Moves Me, a company that offers courses, live training, and career development. She  hosts The Cool Data Projects Show, where she interviews AI, machine learning (ML), and deep learning (DL) experts about their projects. Points From This Episode:</p><ul><li>Kristen’s background in the data science world and what led her to her role at Comet.</li><li>What it means to be a developer advocate and build community.</li><li>Some of the coolest AI, ML, and DL ideas from The Cool Data Projects Show!</li><li>One of the computer vision projects Kristen is working on that uses Kaggle datasets.</li><li>How Roboflow can help you deploy a computer vision model in an afternoon.</li><li>The amount of data that is actually needed for object detection.</li><li>Solving the challenge of contextualization for computer vision models.</li><li>A look at attention mechanisms in explainable AI and how to tackle large datasets.</li><li>Insight into the motivations behind Kristen’s school bus project.</li><li>The value of learning through building and solving “real” problems.</li><li>How Kristen’s background as a data scientist lends itself to computer vision.</li><li>Free and easily-available resources that others in the space have created to assist you.</li><li>Advice for those forging their own careers: get involved in the community!</li></ul><p>Tweetables:</p><p>“I’m finding people who are working on really cool things and focusing on the methodology and approach. I want to know: how did you collect your data? What algorithm are you using? What algorithms did you consider? What were the challenges that you faced?” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:05:55]</p><p>“A lot of times, it comes back to [the fact that] more data is always better!” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:15:40]</p><p>“I like [to do computer vision] projects that allow me to solve a problem that is actually going on in my life. When I do one, suddenly, it becomes a lot easier to see other ways that I can make other parts of my life easier.” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:18:59]</p><p>“The best thing you can do is to get involved in the community. It doesn’t matter whether that community is on Reddit, Slack, or LinkedIn.” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:23:32]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://datamovesme.com/">Data Moves Me</a></p><p><a href="https://www.comet.com/">Comet</a></p><p><a href="https://www.youtube.com/playlist?list=PLX9GmL8cVn_x-IDV2jyayYB6w78Fcn4I2">The Cool Data Projects Show</a></p><p><a href="https://www.amazon.com/Mothers-Data-Science-Kate-Strachnyi/dp/B08D54RCFL"><i>Mothers of Data Science</i></a></p><p><a href="https://www.linkedin.com/in/kristen-kehrer-datamovesme/">Kristen Kehrer on LinkedIn</a></p><p><a href="https://twitter.com/datamovesher">Kristen Kehrer on Twitter</a></p><p><a href="https://www.instagram.com/datamovesher/">Kristen Kehrer on Instagram</a></p><p><a href="https://www.youtube.com/channel/UCo5T7LLTg6DIrozw9UaWKsw">Kristen Kehrer on YouTube</a></p><p><a href="https://www.tiktok.com/@datamovesme">Kristen Kehrer on TikTok</a></p><p><a href="https://www.kaggle.com/">Kaggle</a></p><p><a href="https://roboflow.com/">Roboflow</a></p><p><a href="https://github.com/comet-ml/kangas">Kangas Library</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 16 Mar 2023 18:08:11 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/data-scientist-developer-advocate-kristen-kehrer-4wMgpGi_</link>
      <content:encoded><![CDATA[<p>Kristen is also the founder of Data Moves Me, a company that offers courses, live training, and career development. She  hosts The Cool Data Projects Show, where she interviews AI, machine learning (ML), and deep learning (DL) experts about their projects. Points From This Episode:</p><ul><li>Kristen’s background in the data science world and what led her to her role at Comet.</li><li>What it means to be a developer advocate and build community.</li><li>Some of the coolest AI, ML, and DL ideas from The Cool Data Projects Show!</li><li>One of the computer vision projects Kristen is working on that uses Kaggle datasets.</li><li>How Roboflow can help you deploy a computer vision model in an afternoon.</li><li>The amount of data that is actually needed for object detection.</li><li>Solving the challenge of contextualization for computer vision models.</li><li>A look at attention mechanisms in explainable AI and how to tackle large datasets.</li><li>Insight into the motivations behind Kristen’s school bus project.</li><li>The value of learning through building and solving “real” problems.</li><li>How Kristen’s background as a data scientist lends itself to computer vision.</li><li>Free and easily-available resources that others in the space have created to assist you.</li><li>Advice for those forging their own careers: get involved in the community!</li></ul><p>Tweetables:</p><p>“I’m finding people who are working on really cool things and focusing on the methodology and approach. I want to know: how did you collect your data? What algorithm are you using? What algorithms did you consider? What were the challenges that you faced?” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:05:55]</p><p>“A lot of times, it comes back to [the fact that] more data is always better!” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:15:40]</p><p>“I like [to do computer vision] projects that allow me to solve a problem that is actually going on in my life. When I do one, suddenly, it becomes a lot easier to see other ways that I can make other parts of my life easier.” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:18:59]</p><p>“The best thing you can do is to get involved in the community. It doesn’t matter whether that community is on Reddit, Slack, or LinkedIn.” — <a href="https://twitter.com/datamovesher">@DataMovesHer</a> [0:23:32]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://datamovesme.com/">Data Moves Me</a></p><p><a href="https://www.comet.com/">Comet</a></p><p><a href="https://www.youtube.com/playlist?list=PLX9GmL8cVn_x-IDV2jyayYB6w78Fcn4I2">The Cool Data Projects Show</a></p><p><a href="https://www.amazon.com/Mothers-Data-Science-Kate-Strachnyi/dp/B08D54RCFL"><i>Mothers of Data Science</i></a></p><p><a href="https://www.linkedin.com/in/kristen-kehrer-datamovesme/">Kristen Kehrer on LinkedIn</a></p><p><a href="https://twitter.com/datamovesher">Kristen Kehrer on Twitter</a></p><p><a href="https://www.instagram.com/datamovesher/">Kristen Kehrer on Instagram</a></p><p><a href="https://www.youtube.com/channel/UCo5T7LLTg6DIrozw9UaWKsw">Kristen Kehrer on YouTube</a></p><p><a href="https://www.tiktok.com/@datamovesme">Kristen Kehrer on TikTok</a></p><p><a href="https://www.kaggle.com/">Kaggle</a></p><p><a href="https://roboflow.com/">Roboflow</a></p><p><a href="https://github.com/comet-ml/kangas">Kangas Library</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25298756" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/b6793d34-4953-4072-83fc-54962d383643/audio/eba6e3f4-5582-48d2-ba17-cd59180f67c8/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Data Scientist &amp; Developer Advocate Kristen Kehrer</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:21</itunes:duration>
      <itunes:summary>In this episode, Comet Data Scientist &amp; Developer Advocate Kristen Kehrer tells us how she marries data science and content marketing in her role at Comet and what she has learned about computer vision from her guests on The Cool Data Projects Show. We also take a deep dive into object detection and the value of learning through building, and Kristen shares her advice for getting involved in an online community near you.</itunes:summary>
      <itunes:subtitle>In this episode, Comet Data Scientist &amp; Developer Advocate Kristen Kehrer tells us how she marries data science and content marketing in her role at Comet and what she has learned about computer vision from her guests on The Cool Data Projects Show. We also take a deep dive into object detection and the value of learning through building, and Kristen shares her advice for getting involved in an online community near you.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>63</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">0c4e9344-6271-4b29-b1a1-1ace5463f833</guid>
      <title>Blue Collar AI with Kirk Borne Ph.D</title>
      <description><![CDATA[<p> In this episode, we learn the benefits of blue-collar AI education and the role of company culture in employee empowerment. Dr. Borne shares the history of data collection and analysis in astronomy and the evolution of cookies on the internet and explains the concept of Web3 and the future of data ownership. Dr. Borne is of the opinion that AI serves to amplify and assist people in their jobs rather than replace them and in our conversation, we discover how everyone can benefit if adequately informed.</p><p>Key Points From This Episode:</p><ul><li>Data scientist and astrophysicist, Dr. Kirk Borne’s vast background.</li><li>The history of data collection and analysis in astronomy.</li><li>How Dr. Borne fulfills his passion for educating others.</li><li>DataPrime’s blue-collar AI education course.</li><li>How AI amplifies your work without replacing it.</li><li>The difference between efficiency and effectiveness.</li><li>The difference between educating blue-collar students and graduate students.</li><li>The goal of the blue-collar AI course. </li><li>The ways in which automation and digital transformation are changing jobs.</li><li>Comparison between the AI revolution (the fourth industrial revolution) and previous industrial revolutions.</li><li>The role of company culture in employee empowerment.</li><li>Dr. Borne’s approach to teaching AI education.</li><li>Dr. Borne shares a humorous Richard Feynman anecdote.</li><li>The concept of Web3 and the future of data ownership.</li><li>The history and evolution of cookies on the internet.</li><li>The ethical concerns of AI.</li></ul><p>Tweetables:</p><p>“[AI] amplifies and assists you in your work. It helps automate certain aspects of your work but it’s not really taking your work away. It’s just making it more efficient, or more effective.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:11:18]</p><p>“There’s a difference between efficiency and effectiveness … Efficiency is the speed at which you get something done and effective means the amount that you can get done.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:11:29]</p><p>“There are different ways that automation and digital transformation are changing a lot of jobs. Not just the high-end professional jobs, so to speak, but the blue-collar gentlemen.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:18:06]</p><p>“What we’re trying to achieve with this blue-collar AI is for people to feel confident with it and to see where it can bring benefits to their business.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:24:08]</p><p>“I have yet to see an auto-complete come over your phone and take over the world.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:26:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://kirkborne.net/">Kirk Borne, Ph.D.</a></p><p><a href="https://www.linkedin.com/in/kirkdborne/">Kirk Borne, Ph.D. on LinkedIn</a></p><p><a href="https://twitter.com/KirkDBorne">Kirk Borne, Ph.D. on Twitter</a></p><p><a href="https://www.nobelprize.org/prizes/physics/1965/feynman/biographical/">Richard Feynman</a></p><p><a href="https://www.jennyco.io/">JennyCo</a></p><p><a href="https://www.alchemy.com/">Alchemy Exchange</a></p><p><a href="https://www.boozallen.com/">Booz Allen Hamilton</a></p><p><a href="https://prime.ai/">DataPrime</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 1 Mar 2023 00:09:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/blue-collar-ai-with-kirk-borne-phd-pJoyTqIV</link>
      <content:encoded><![CDATA[<p> In this episode, we learn the benefits of blue-collar AI education and the role of company culture in employee empowerment. Dr. Borne shares the history of data collection and analysis in astronomy and the evolution of cookies on the internet and explains the concept of Web3 and the future of data ownership. Dr. Borne is of the opinion that AI serves to amplify and assist people in their jobs rather than replace them and in our conversation, we discover how everyone can benefit if adequately informed.</p><p>Key Points From This Episode:</p><ul><li>Data scientist and astrophysicist, Dr. Kirk Borne’s vast background.</li><li>The history of data collection and analysis in astronomy.</li><li>How Dr. Borne fulfills his passion for educating others.</li><li>DataPrime’s blue-collar AI education course.</li><li>How AI amplifies your work without replacing it.</li><li>The difference between efficiency and effectiveness.</li><li>The difference between educating blue-collar students and graduate students.</li><li>The goal of the blue-collar AI course. </li><li>The ways in which automation and digital transformation are changing jobs.</li><li>Comparison between the AI revolution (the fourth industrial revolution) and previous industrial revolutions.</li><li>The role of company culture in employee empowerment.</li><li>Dr. Borne’s approach to teaching AI education.</li><li>Dr. Borne shares a humorous Richard Feynman anecdote.</li><li>The concept of Web3 and the future of data ownership.</li><li>The history and evolution of cookies on the internet.</li><li>The ethical concerns of AI.</li></ul><p>Tweetables:</p><p>“[AI] amplifies and assists you in your work. It helps automate certain aspects of your work but it’s not really taking your work away. It’s just making it more efficient, or more effective.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:11:18]</p><p>“There’s a difference between efficiency and effectiveness … Efficiency is the speed at which you get something done and effective means the amount that you can get done.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:11:29]</p><p>“There are different ways that automation and digital transformation are changing a lot of jobs. Not just the high-end professional jobs, so to speak, but the blue-collar gentlemen.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:18:06]</p><p>“What we’re trying to achieve with this blue-collar AI is for people to feel confident with it and to see where it can bring benefits to their business.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:24:08]</p><p>“I have yet to see an auto-complete come over your phone and take over the world.” — <a href="https://twitter.com/KirkDBorne">@KirkDBorne</a> [0:26:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://kirkborne.net/">Kirk Borne, Ph.D.</a></p><p><a href="https://www.linkedin.com/in/kirkdborne/">Kirk Borne, Ph.D. on LinkedIn</a></p><p><a href="https://twitter.com/KirkDBorne">Kirk Borne, Ph.D. on Twitter</a></p><p><a href="https://www.nobelprize.org/prizes/physics/1965/feynman/biographical/">Richard Feynman</a></p><p><a href="https://www.jennyco.io/">JennyCo</a></p><p><a href="https://www.alchemy.com/">Alchemy Exchange</a></p><p><a href="https://www.boozallen.com/">Booz Allen Hamilton</a></p><p><a href="https://prime.ai/">DataPrime</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="34386860" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/67a6571b-ba86-47d4-a58f-ce1a7db7a708/audio/54fd3037-2ea6-4ac0-8372-00c4bbdb77d7/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Blue Collar AI with Kirk Borne Ph.D</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:49</itunes:duration>
      <itunes:summary> Today we are joined by data scientist and astrophysicist, Dr. Kirk Borne to discuss the importance of equipping people of all backgrounds and qualifications with AI literacy and fluency. Dr. Borne has a vast background in both the astronomy and tech spaces and is currently fulfilling his passion for making complex topics accessible through DataPrime’s blue-collar AI course.</itunes:summary>
      <itunes:subtitle> Today we are joined by data scientist and astrophysicist, Dr. Kirk Borne to discuss the importance of equipping people of all backgrounds and qualifications with AI literacy and fluency. Dr. Borne has a vast background in both the astronomy and tech spaces and is currently fulfilling his passion for making complex topics accessible through DataPrime’s blue-collar AI course.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>62</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">8b923be6-177e-4af3-be9c-55d6ecd9e156</guid>
      <title>Training Biometric Tech with Head of AI George Williams</title>
      <description><![CDATA[<p>Goodbye Passwords, Hello Biometrics with George Williams</p><p>Episode 61: Show Notes.</p><p>Is it <i>really</i> safer to have a system know your biometrics rather than your password? If so, who do you trust with this data? George Williams, a silicon valley tech veteran who most recently served as Head of AI at SmileIdentity, is passionate about machine learning, mathematics, and data science. In this episode, George shares his opinions on the dawn of AI, how long he believes AI has been around, and references the ancient Greeks to show the relationship between the current fifth big wave of AI and the genesis of it all. Focusing on the work done by SmileIdentity, you will understand the growth of AI in Africa, what and how biometrics works, and the mathematical vulnerabilities in machine learning. Biometrics is substantially more complex than password authentication, and George explains why he believes this is the way of the future.</p><p>Key Points From This Episode:</p><ul><li>Georges's opinions on the genesis of AI.</li><li>The link between robotics and AI.</li><li>The technology and ideas of the Ancient Greeks, in the time of Aristotle.</li><li>George’s career past: software engineer versus mathematics.</li><li>What George’s role is within SmileIdentity.</li><li>How Africa is skipping passwords and going into advanced biometrics.</li><li>How George uses biometrics in his everyday life,</li><li>Quantum supremacy: how it works and its implications.</li><li>George’s opinions on conspiracy theories about the government having personal information.</li><li>Why understanding the laws and regulations of technology is important.</li><li>The challenges of data security and privacy.</li><li>Some ethical, unbiased questions about biometrics, mass surveillance, and AI.</li><li>George explains ‘garbage in, garbage out’ and how it relates to machine learning.</li><li>How SmileIdentity is ensuring ethnic diversity and accuracy.</li><li>How to measure an unbiased algorithm.</li><li>Why machine learning is a life cycle. </li><li>The fraud detection technology in SmileIdentity biometric security.</li><li>The shift of focus in machine learning and cyber security.</li></ul><p>Tweetables:</p><p>“Robotics and artificial intelligence are very much intertwined.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:02:14]</p><p>“In my daily routine, I leverage biometrics as much as possible and I prefer this over passwords when I can do so.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:08:13]</p><p>“All of your data is already out there in one form or another.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:10:38]</p><p>“We don’t all need to be software developers or ML engineers, but we all have to understand the technology that is powering [the world] and we have to ask the right questions.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:11:53]</p><p>“[Some of the biometric] technology is imperfect in ways that make me uncomfortable and this technology is being deployed at massive scale in parts of the world and that should be a concern for all of us.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:20:33]</p><p>“In machine learning, once you train a model and deploy it you are not done. That is the start of the life cycle of activity that you have to maintain and sustain in order to have really good AI biometrics.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:22:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://twitter.com/cgeorgewilliams">George Williams on Twitter</a></p><p><a href="https://www.linkedin.com/in/george-williams-8130902/">George Williams on LinkedIn</a></p><p><a href="https://www.smileidentity.com/">SmileIdentity</a></p><p><a href="https://nyumovement.org/">NYU Movement Lab</a></p><p><a href="https://openai.com/blog/chatgpt/">ChatGPT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 23 Feb 2023 23:50:24 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/training-biometric-tech-with-head-of-ai-george-williams-YbfLGlX0</link>
      <content:encoded><![CDATA[<p>Goodbye Passwords, Hello Biometrics with George Williams</p><p>Episode 61: Show Notes.</p><p>Is it <i>really</i> safer to have a system know your biometrics rather than your password? If so, who do you trust with this data? George Williams, a silicon valley tech veteran who most recently served as Head of AI at SmileIdentity, is passionate about machine learning, mathematics, and data science. In this episode, George shares his opinions on the dawn of AI, how long he believes AI has been around, and references the ancient Greeks to show the relationship between the current fifth big wave of AI and the genesis of it all. Focusing on the work done by SmileIdentity, you will understand the growth of AI in Africa, what and how biometrics works, and the mathematical vulnerabilities in machine learning. Biometrics is substantially more complex than password authentication, and George explains why he believes this is the way of the future.</p><p>Key Points From This Episode:</p><ul><li>Georges's opinions on the genesis of AI.</li><li>The link between robotics and AI.</li><li>The technology and ideas of the Ancient Greeks, in the time of Aristotle.</li><li>George’s career past: software engineer versus mathematics.</li><li>What George’s role is within SmileIdentity.</li><li>How Africa is skipping passwords and going into advanced biometrics.</li><li>How George uses biometrics in his everyday life,</li><li>Quantum supremacy: how it works and its implications.</li><li>George’s opinions on conspiracy theories about the government having personal information.</li><li>Why understanding the laws and regulations of technology is important.</li><li>The challenges of data security and privacy.</li><li>Some ethical, unbiased questions about biometrics, mass surveillance, and AI.</li><li>George explains ‘garbage in, garbage out’ and how it relates to machine learning.</li><li>How SmileIdentity is ensuring ethnic diversity and accuracy.</li><li>How to measure an unbiased algorithm.</li><li>Why machine learning is a life cycle. </li><li>The fraud detection technology in SmileIdentity biometric security.</li><li>The shift of focus in machine learning and cyber security.</li></ul><p>Tweetables:</p><p>“Robotics and artificial intelligence are very much intertwined.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:02:14]</p><p>“In my daily routine, I leverage biometrics as much as possible and I prefer this over passwords when I can do so.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:08:13]</p><p>“All of your data is already out there in one form or another.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:10:38]</p><p>“We don’t all need to be software developers or ML engineers, but we all have to understand the technology that is powering [the world] and we have to ask the right questions.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:11:53]</p><p>“[Some of the biometric] technology is imperfect in ways that make me uncomfortable and this technology is being deployed at massive scale in parts of the world and that should be a concern for all of us.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:20:33]</p><p>“In machine learning, once you train a model and deploy it you are not done. That is the start of the life cycle of activity that you have to maintain and sustain in order to have really good AI biometrics.” — <a href="https://twitter.com/cgeorgewilliams">@georgewilliams</a> [0:22:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://twitter.com/cgeorgewilliams">George Williams on Twitter</a></p><p><a href="https://www.linkedin.com/in/george-williams-8130902/">George Williams on LinkedIn</a></p><p><a href="https://www.smileidentity.com/">SmileIdentity</a></p><p><a href="https://nyumovement.org/">NYU Movement Lab</a></p><p><a href="https://openai.com/blog/chatgpt/">ChatGPT</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="32105899" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/fc9fcb26-e416-4131-a849-318bdd2b0011/audio/76ca7419-5723-4fb8-81fa-66976ddcbe97/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Training Biometric Tech with Head of AI George Williams</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:25</itunes:duration>
      <itunes:summary>George Williams, a silicon valley tech veteran who most recently served as Head of AI at SmileIdentity, shares his views on the growth of AI in Africa, what and how biometrics works, and the mathematical vulnerabilities in machine learning. Biometrics is substantially more complex than password authentication, and George explains why he believes this is the way of the future.</itunes:summary>
      <itunes:subtitle>George Williams, a silicon valley tech veteran who most recently served as Head of AI at SmileIdentity, shares his views on the growth of AI in Africa, what and how biometrics works, and the mathematical vulnerabilities in machine learning. Biometrics is substantially more complex than password authentication, and George explains why he believes this is the way of the future.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>61</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">818e1604-3e26-499e-8fc7-37b37bf27f1f</guid>
      <title>Climate Change AI Co-Founder Dr. Priya Donti</title>
      <description><![CDATA[<p>Our discussion today dives into the climate change related applications of AI and machine learning, and how organizations are working towards mobilizing them to address the climate problem. Priya shares her thoughts on advanced technology and creating a dystopian version of humanity, what made her decide on her Ph.D. topic, and what she learned touring the world interviewing power grid experts around the world.</p><p>Key Points From This Episode:</p><ul><li>Priya shares her take on ChatGPT.</li><li>We talk about ChatGPT guard rails and whether it should be done manually or with built in technology that automatically detects issues.</li><li>Concerns with the concept of advanced technology and creating a dystopian version of humanity. </li><li>What made Priya want to get into her particular Ph.D. topic.</li><li>What surprised her about her tour around the world interviewing people. </li><li>Priya explains what she means by a 'systems problem.'</li><li>Machine learning and AI in power grids; what is the thrift of opportunity?</li><li>Priya speaks to the reason why she found a climate change AI organization.</li><li>Narrowing the focus, in AI and Climate Change, as an organization.</li><li>Priya shares an example of what work looks like for someone in a role with machine learning and climate change. </li><li>Recent wins in the climate change world and how they measure the success of their progress. </li><li>The gap between the vision of where she is now and where she wants to be in the medium term. </li></ul><p>Tweetables:</p><p>“When we are working on climate change related problems, even ones that are “technical problems” every problem is basically a socio-political technical problem, and really understanding that context when we move that forward can be really important.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:10:02]</p><p>“Machine learning in power grids and really in a lot of other climate relevance sectors can contribute along several themes or in several ways.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:12:18]</p><p>“What prompted us to found this organization, Climate Change AI, [is] to really help mobilize the AI machine learning community towards climate action by bringing them together with climate researchers, entrepreneurs, industry, policy, all of these players who are working to address the climate problems and sort of to do that together.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:17:21]</p><p>Longer quote</p><p>“So the whole idea of Climate Change AI is rather than just focusing on what can we as individuals who are already in this area do to do research projects or deployment projects in this area, how can we sort of mobilize the broader talent pool and really help them to connect with entities that are really wanting to use their skills for climate action.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:19:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://priyadonti.com/">Priya Donti</a></p><p><a href="https://twitter.com/priyald17">Priya Donti on Twitter</a></p><p><a href="https://cacm.acm.org/magazines/2012/4/147362-putting-the-smarts-into-the-smart-grid/abstract">Putting the Smarts in the Smart Grid</a></p><p><a href="https://www.climatechange.ai/">Climate Change AI</a></p><p><a href="https://www.climatechange.ai/summaries">Climate Change AI Interactive Summaries</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 15 Dec 2022 19:31:50 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/climate-change-ai-co-founder-dr-priya-donti-inPBVOtZ</link>
      <content:encoded><![CDATA[<p>Our discussion today dives into the climate change related applications of AI and machine learning, and how organizations are working towards mobilizing them to address the climate problem. Priya shares her thoughts on advanced technology and creating a dystopian version of humanity, what made her decide on her Ph.D. topic, and what she learned touring the world interviewing power grid experts around the world.</p><p>Key Points From This Episode:</p><ul><li>Priya shares her take on ChatGPT.</li><li>We talk about ChatGPT guard rails and whether it should be done manually or with built in technology that automatically detects issues.</li><li>Concerns with the concept of advanced technology and creating a dystopian version of humanity. </li><li>What made Priya want to get into her particular Ph.D. topic.</li><li>What surprised her about her tour around the world interviewing people. </li><li>Priya explains what she means by a 'systems problem.'</li><li>Machine learning and AI in power grids; what is the thrift of opportunity?</li><li>Priya speaks to the reason why she found a climate change AI organization.</li><li>Narrowing the focus, in AI and Climate Change, as an organization.</li><li>Priya shares an example of what work looks like for someone in a role with machine learning and climate change. </li><li>Recent wins in the climate change world and how they measure the success of their progress. </li><li>The gap between the vision of where she is now and where she wants to be in the medium term. </li></ul><p>Tweetables:</p><p>“When we are working on climate change related problems, even ones that are “technical problems” every problem is basically a socio-political technical problem, and really understanding that context when we move that forward can be really important.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:10:02]</p><p>“Machine learning in power grids and really in a lot of other climate relevance sectors can contribute along several themes or in several ways.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:12:18]</p><p>“What prompted us to found this organization, Climate Change AI, [is] to really help mobilize the AI machine learning community towards climate action by bringing them together with climate researchers, entrepreneurs, industry, policy, all of these players who are working to address the climate problems and sort of to do that together.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:17:21]</p><p>Longer quote</p><p>“So the whole idea of Climate Change AI is rather than just focusing on what can we as individuals who are already in this area do to do research projects or deployment projects in this area, how can we sort of mobilize the broader talent pool and really help them to connect with entities that are really wanting to use their skills for climate action.” — <a href="https://twitter.com/priyald17">@priyald17</a> [0:19:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://priyadonti.com/">Priya Donti</a></p><p><a href="https://twitter.com/priyald17">Priya Donti on Twitter</a></p><p><a href="https://cacm.acm.org/magazines/2012/4/147362-putting-the-smarts-into-the-smart-grid/abstract">Putting the Smarts in the Smart Grid</a></p><p><a href="https://www.climatechange.ai/">Climate Change AI</a></p><p><a href="https://www.climatechange.ai/summaries">Climate Change AI Interactive Summaries</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29152059" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/aec3ef5f-0acf-4f5f-a9c9-57f4fcd3a12f/audio/3ee94514-8479-4f2c-b76d-92fb8822a257/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Climate Change AI Co-Founder Dr. Priya Donti</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:20</itunes:duration>
      <itunes:summary>Priya Donti is the Co-founder and Executive Director of Climate Change AI (CCAI), a global non-profit initiative to catalyze impactful work at the intersection of climate change and machine learning. </itunes:summary>
      <itunes:subtitle>Priya Donti is the Co-founder and Executive Director of Climate Change AI (CCAI), a global non-profit initiative to catalyze impactful work at the intersection of climate change and machine learning. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>60</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">87b5fd96-d717-4b32-88fc-0ed63813c16d</guid>
      <title>Genetec Director of Video Analytics Florian Matusek</title>
      <description><![CDATA[<p> Genetec has been a software provider for the physical security industry for over 25 years, earning its spot as the world’s number one software provider in video management. We are pleased to be joined today by Florian Matusek, Genetec’s Director of Video Analytics and the host of Video Analytics 101 on YouTube. Florian explains how his company is driving innovation in the market and what his specific role is before divining into the importance of maintaining both security and privacy, this new wave of special analytics, and why real-time improvements are more difficult than back-end adjustments. Our guest then lists all the exciting things he is witnessing in the world of video analytics and what he hopes to see in re-identification and gait analysis in the future. We discuss synthetic data and whether it will ever be commoditized and close with an exploration of the probable future of grocery stores without any employees. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to the Director of Video Analytics at Genetec, Florian Matusek.</li><li>How the Video Analytics 101 YouTube channel was formed. </li><li>The purpose of his YouTube channel and its ideal viewer. </li><li>What his company does and what his role entails. </li><li>How Genetec has transformed as a company from its inception until now. </li><li>The insights Florian hopes to provide to his customers through video analytics.</li><li>Genetec’s new technology that upholds both security and privacy. </li><li>Exploring the new wave of spatial analytics. </li><li>The difference between real-time improvements and gradual, back-end adjustments. </li><li>New use cases, techniques, and trends that Florian finds exciting. </li><li>The perks and problems of re-identification. </li><li>Whether the current technology of gait analysis is reliable and how it relates to re-identification. </li><li>How technology is evolving to include time-based data collection. </li><li>The difficulties he experiences in collecting video data to train his models. </li><li>Whether there’s an opportunity for synthetic data to augment his data strategy.</li><li>Florian’s thoughts on synthetic data becoming commoditized. </li><li>Some interesting ways that Genetec’s clients are using its technology. </li><li>The video analytics behind the automated drinks system at the Denver Broncos stadium. </li><li>How close we are to a future of grocery stores with no employees or cash registers. </li></ul><p>Tweetables:</p><p>“Nowadays, it's about automation. It's about operational efficiency. It's about integrating video and access control, and license plate recognition, IoT sensors, all into one platform, and providing the user a single pane of glass.” — Florian Matusek [0:05:11]</p><p>“We will always build products that benefit our users, which is the security operators, the ones purchasing it. But at the same time, we see it as our responsibility to also do everything possible to protect the privacy of the citizens that our customers are recording.” — Florian Matusek [0:09:03]</p><p>“What gets me excited are solutions that are really targeted for a specific purpose and made perfect for this purpose.” — Florian Matusek [0:11:24]</p><p>“You need both synthetic data and real data in order to make the real applications work really well.” — Florian Matusek [0:21:42]</p><p>“It's really funny how customers come up with creative ways to solve their specific problems.” — Florian Matusek [0:26:36]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/florian-matusek-81a89613/">Florian Matusek on LinkedIn</a></p><p><a href="https://www.youtube.com/@VideoAnalytics101/featured">Video Analytics 101 on YouTube</a></p><p><a href="https://www.genetec.com/">Genetec</a></p><p><a href="https://www.youtube.com/channel/UCjmNLFXSJP3IN0vk8__Ut9g">Genetec on YouTube</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 8 Dec 2022 17:44:09 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/genetec-director-of-video-analytics-florian-matusek-lzBo32Uc</link>
      <content:encoded><![CDATA[<p> Genetec has been a software provider for the physical security industry for over 25 years, earning its spot as the world’s number one software provider in video management. We are pleased to be joined today by Florian Matusek, Genetec’s Director of Video Analytics and the host of Video Analytics 101 on YouTube. Florian explains how his company is driving innovation in the market and what his specific role is before divining into the importance of maintaining both security and privacy, this new wave of special analytics, and why real-time improvements are more difficult than back-end adjustments. Our guest then lists all the exciting things he is witnessing in the world of video analytics and what he hopes to see in re-identification and gait analysis in the future. We discuss synthetic data and whether it will ever be commoditized and close with an exploration of the probable future of grocery stores without any employees. </p><p>Key Points From This Episode:</p><ul><li>A warm welcome to the Director of Video Analytics at Genetec, Florian Matusek.</li><li>How the Video Analytics 101 YouTube channel was formed. </li><li>The purpose of his YouTube channel and its ideal viewer. </li><li>What his company does and what his role entails. </li><li>How Genetec has transformed as a company from its inception until now. </li><li>The insights Florian hopes to provide to his customers through video analytics.</li><li>Genetec’s new technology that upholds both security and privacy. </li><li>Exploring the new wave of spatial analytics. </li><li>The difference between real-time improvements and gradual, back-end adjustments. </li><li>New use cases, techniques, and trends that Florian finds exciting. </li><li>The perks and problems of re-identification. </li><li>Whether the current technology of gait analysis is reliable and how it relates to re-identification. </li><li>How technology is evolving to include time-based data collection. </li><li>The difficulties he experiences in collecting video data to train his models. </li><li>Whether there’s an opportunity for synthetic data to augment his data strategy.</li><li>Florian’s thoughts on synthetic data becoming commoditized. </li><li>Some interesting ways that Genetec’s clients are using its technology. </li><li>The video analytics behind the automated drinks system at the Denver Broncos stadium. </li><li>How close we are to a future of grocery stores with no employees or cash registers. </li></ul><p>Tweetables:</p><p>“Nowadays, it's about automation. It's about operational efficiency. It's about integrating video and access control, and license plate recognition, IoT sensors, all into one platform, and providing the user a single pane of glass.” — Florian Matusek [0:05:11]</p><p>“We will always build products that benefit our users, which is the security operators, the ones purchasing it. But at the same time, we see it as our responsibility to also do everything possible to protect the privacy of the citizens that our customers are recording.” — Florian Matusek [0:09:03]</p><p>“What gets me excited are solutions that are really targeted for a specific purpose and made perfect for this purpose.” — Florian Matusek [0:11:24]</p><p>“You need both synthetic data and real data in order to make the real applications work really well.” — Florian Matusek [0:21:42]</p><p>“It's really funny how customers come up with creative ways to solve their specific problems.” — Florian Matusek [0:26:36]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/florian-matusek-81a89613/">Florian Matusek on LinkedIn</a></p><p><a href="https://www.youtube.com/@VideoAnalytics101/featured">Video Analytics 101 on YouTube</a></p><p><a href="https://www.genetec.com/">Genetec</a></p><p><a href="https://www.youtube.com/channel/UCjmNLFXSJP3IN0vk8__Ut9g">Genetec on YouTube</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="29776433" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/522e2653-24ad-4b70-a2d4-97499ac70a88/audio/7fc15a12-ee2c-4a80-bfb4-eb8bbd2fd0e9/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Genetec Director of Video Analytics Florian Matusek</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:59</itunes:duration>
      <itunes:summary>Florian Matusek, Genetec’s Director of Video Analytics and the host of Video Analytics 101 on YouTube, explains the importance of maintaining security and privacy, new waves of special analytics, and why real-time improvements are more difficult than back-end adjustments.</itunes:summary>
      <itunes:subtitle>Florian Matusek, Genetec’s Director of Video Analytics and the host of Video Analytics 101 on YouTube, explains the importance of maintaining security and privacy, new waves of special analytics, and why real-time improvements are more difficult than back-end adjustments.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>59</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">5017bd86-c2da-4e49-acce-a08b1dfcaa23</guid>
      <title>Credo AI Founder &amp; CEO Navrina Singh</title>
      <description><![CDATA[<p>Navrina shares why trust and transparency are crucial in the AI space and why she believes  having a Chief Ethics Officer should become an industry standard. Our conversation ends with a discussion about compliance and what AI tech organizations can do to ensure reliable, trustworthy, and transparent products. To get 30 minutes of uninterrupted knowledge from The National AI Advisory Committee member, Mozilla board of directors member, and World Economic Forum young global leader Navrina Singh, tune in now!</p><p>Key Points From This Episode:</p><ul><li>Welcoming today’s guest, CEO and Founder of Credo AI, Navrina Singh. </li><li>A look at Navrina’s recent background and why she decided to start Credo AI.</li><li>Why it’s important to take responsibility for the technology you create.</li><li>The reasons why the AI technology industry chose to create its own systems of oversight.</li><li>Why trust is a crucial part of the AI technology sector. </li><li>How Credo AI helps companies engage with issues of transparency and trust. </li><li>The people at various companies who are in charge of AI governance that Credo deals with. </li><li>Who Navrina thinks should be responsible for AI governance at every company. </li><li>Where Credo’s clients usually fall short when it comes to compliance.</li><li>What AI technology companies should be thinking about beyond compliance. </li><li>Navrina’s view on what organizations can do to ensure reliable, trustworthy, and transparent tech.</li></ul><p>Tweetables:</p><p>“I always saw technology as the tool that would help me change the world. Especially growing up in an environment where women don’t have the luxury that some other people have, you tend to lean on things that can make your ideas happen, and technology was that for me.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:01:17]</p><p>“As technologists, it’s our responsibility to make sure that the technologies we are putting out in the world that are becoming the fabric of our society, we take responsibility for it.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:04:04]</p><p>“By its very nature, trust is all about saying something and then consistently delivering on what you said. That’s how you build trust.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:08:58]</p><p>“I founded Credo AI for a reason, to bring more honest accountability in artificial intelligence.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:10:45]</p><p>“We are going to see more trust officers and trust functions emerge within organizations, but I am not really sure if a chief ethics officer is going to emerge as a core persona, at least not in the next two to three years. Is it needed? Absolutely, it’s needed.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:17:32]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://twitter.com/navrinasingh">Navrina Singh on Twitter</a></p><p><a href="https://www.linkedin.com/in/navrina/">Navrina Singh on LinkedIn</a></p><p><a href="https://www.credo.ai/">Credo AI</a></p><p><a href="https://www.ai.gov/naiac/">The National AI Advisory Committee</a></p><p><a href="https://www.weforum.org/agenda/authors/navrina-singh">World Economic Forum</a></p><p><a href="https://www.linkedin.com/in/fei-fei-li-4541247/">Dr. Fei-Fei Li on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 18 Nov 2022 17:57:01 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/credo-ai-founder-ceo-navrina-singh-feM7Qz5O</link>
      <content:encoded><![CDATA[<p>Navrina shares why trust and transparency are crucial in the AI space and why she believes  having a Chief Ethics Officer should become an industry standard. Our conversation ends with a discussion about compliance and what AI tech organizations can do to ensure reliable, trustworthy, and transparent products. To get 30 minutes of uninterrupted knowledge from The National AI Advisory Committee member, Mozilla board of directors member, and World Economic Forum young global leader Navrina Singh, tune in now!</p><p>Key Points From This Episode:</p><ul><li>Welcoming today’s guest, CEO and Founder of Credo AI, Navrina Singh. </li><li>A look at Navrina’s recent background and why she decided to start Credo AI.</li><li>Why it’s important to take responsibility for the technology you create.</li><li>The reasons why the AI technology industry chose to create its own systems of oversight.</li><li>Why trust is a crucial part of the AI technology sector. </li><li>How Credo AI helps companies engage with issues of transparency and trust. </li><li>The people at various companies who are in charge of AI governance that Credo deals with. </li><li>Who Navrina thinks should be responsible for AI governance at every company. </li><li>Where Credo’s clients usually fall short when it comes to compliance.</li><li>What AI technology companies should be thinking about beyond compliance. </li><li>Navrina’s view on what organizations can do to ensure reliable, trustworthy, and transparent tech.</li></ul><p>Tweetables:</p><p>“I always saw technology as the tool that would help me change the world. Especially growing up in an environment where women don’t have the luxury that some other people have, you tend to lean on things that can make your ideas happen, and technology was that for me.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:01:17]</p><p>“As technologists, it’s our responsibility to make sure that the technologies we are putting out in the world that are becoming the fabric of our society, we take responsibility for it.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:04:04]</p><p>“By its very nature, trust is all about saying something and then consistently delivering on what you said. That’s how you build trust.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:08:58]</p><p>“I founded Credo AI for a reason, to bring more honest accountability in artificial intelligence.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:10:45]</p><p>“We are going to see more trust officers and trust functions emerge within organizations, but I am not really sure if a chief ethics officer is going to emerge as a core persona, at least not in the next two to three years. Is it needed? Absolutely, it’s needed.” —<a href="https://twitter.com/navrinasingh">@navrinasingh</a> [0:17:32]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://twitter.com/navrinasingh">Navrina Singh on Twitter</a></p><p><a href="https://www.linkedin.com/in/navrina/">Navrina Singh on LinkedIn</a></p><p><a href="https://www.credo.ai/">Credo AI</a></p><p><a href="https://www.ai.gov/naiac/">The National AI Advisory Committee</a></p><p><a href="https://www.weforum.org/agenda/authors/navrina-singh">World Economic Forum</a></p><p><a href="https://www.linkedin.com/in/fei-fei-li-4541247/">Dr. Fei-Fei Li on LinkedIn</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="28256235" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/136fe2d7-eaf7-4ed4-bd34-af8e9ee776e4/audio/5b2974b0-eebb-434f-bd67-5a72766ba22b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Credo AI Founder &amp; CEO Navrina Singh</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:25</itunes:duration>
      <itunes:summary>Credo AI is a company that provides compliance and governance protocols to AI tech companies, and today we are joined by its Founder and CEO, Navrina Singh. Navrina tells us why it was essential for her to start Credo AI and why her industry has decided to create its own systems of oversight, even before government intervention. </itunes:summary>
      <itunes:subtitle>Credo AI is a company that provides compliance and governance protocols to AI tech companies, and today we are joined by its Founder and CEO, Navrina Singh. Navrina tells us why it was essential for her to start Credo AI and why her industry has decided to create its own systems of oversight, even before government intervention. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>58</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4a1a95a4-253a-4b42-82bc-80b6b2eddd90</guid>
      <title>Arize Founding Engineer Tsion Behailu</title>
      <description><![CDATA[<p>Arize and its founding engineer, Tsion Behailu, are leaders in the machine learning observability space. After spending a few years working as a computer scientist at Google, Tsion’s curiosity drew her to the startup world where, since the beginning of the pandemic, she has been building breaking-edge technology. Rather than doing it all manually (as many companies still do to this day), Arize AI technology helps machine learning teams detect issues, understand why they happen, and improve overall model performance. During this episode, Tsion explains why this method is so advantageous, what she loves about working in the machine learning field, the issue of bias in machine learning models (and what Arize AI is doing to help mitigate that), and more! </p><p>Key Points From This Episode:</p><ul><li>Tsions’s career transition from computer science (CS) into the machine learning (ML) space.</li><li>What motivated Tsion to move from Google to the startup world.</li><li>The mission of Arize AI.</li><li>Tsion explains what ML observability is.</li><li>Examples of the Arize AI tools and the problems that they solve for customers.</li><li>What the troubleshooting process looks like in the absence of Arize AI.</li><li>The problem with in-house solutions.</li><li>Exploring the issue of bias in ML models.</li><li>How Arize AI’s bias tracing tool works.</li><li>Tsion’s thoughts on what is most responsible for bias in ML models and how to combat these problems.</li></ul><p>Tweetables:</p><p>“We focus on machine learning observability. We're helping ML teams detect issues, troubleshoot why they happen, and just improve overall model performance.” — Tsion Behailu [0:06:26]</p><p>“Models can be biased, just because they're built on biased data. Even data scientists, ML engineers who build these models have no standardized ways to know if they're perpetuating bias. So more and more of our decisions get automated, and we let software make them. We really do allow software to perpetuate real world bias issues.” — Tsion Behailu [0:12:36]</p><p>“The bias tracing tool that we have is to help data scientists and machine learning teams just monitor and take action on model fairness metrics.” — Tsion Behailu [0:13:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.tsion.me/">Tsion Behailu</a></p><p><a href="https://arize.com/blog/machine-learning-bias-tracing/">Arize Bias Tracing Tool</a></p><p><a href="https://arize.com/">Arize AI</a><br /><br /><a href="https://arize.com/blog/how-to-know-when-its-time-to-leave-your-big-tech-software-engineering-job/" target="_blank">How to Know When It's Time to Leave your Big Tech SWE Job</a> -- Tsion Behauli</p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 10 Nov 2022 17:02:07 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/arize-founding-engineer-tsion-behailu-Pr1Qo14w</link>
      <content:encoded><![CDATA[<p>Arize and its founding engineer, Tsion Behailu, are leaders in the machine learning observability space. After spending a few years working as a computer scientist at Google, Tsion’s curiosity drew her to the startup world where, since the beginning of the pandemic, she has been building breaking-edge technology. Rather than doing it all manually (as many companies still do to this day), Arize AI technology helps machine learning teams detect issues, understand why they happen, and improve overall model performance. During this episode, Tsion explains why this method is so advantageous, what she loves about working in the machine learning field, the issue of bias in machine learning models (and what Arize AI is doing to help mitigate that), and more! </p><p>Key Points From This Episode:</p><ul><li>Tsions’s career transition from computer science (CS) into the machine learning (ML) space.</li><li>What motivated Tsion to move from Google to the startup world.</li><li>The mission of Arize AI.</li><li>Tsion explains what ML observability is.</li><li>Examples of the Arize AI tools and the problems that they solve for customers.</li><li>What the troubleshooting process looks like in the absence of Arize AI.</li><li>The problem with in-house solutions.</li><li>Exploring the issue of bias in ML models.</li><li>How Arize AI’s bias tracing tool works.</li><li>Tsion’s thoughts on what is most responsible for bias in ML models and how to combat these problems.</li></ul><p>Tweetables:</p><p>“We focus on machine learning observability. We're helping ML teams detect issues, troubleshoot why they happen, and just improve overall model performance.” — Tsion Behailu [0:06:26]</p><p>“Models can be biased, just because they're built on biased data. Even data scientists, ML engineers who build these models have no standardized ways to know if they're perpetuating bias. So more and more of our decisions get automated, and we let software make them. We really do allow software to perpetuate real world bias issues.” — Tsion Behailu [0:12:36]</p><p>“The bias tracing tool that we have is to help data scientists and machine learning teams just monitor and take action on model fairness metrics.” — Tsion Behailu [0:13:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.tsion.me/">Tsion Behailu</a></p><p><a href="https://arize.com/blog/machine-learning-bias-tracing/">Arize Bias Tracing Tool</a></p><p><a href="https://arize.com/">Arize AI</a><br /><br /><a href="https://arize.com/blog/how-to-know-when-its-time-to-leave-your-big-tech-software-engineering-job/" target="_blank">How to Know When It's Time to Leave your Big Tech SWE Job</a> -- Tsion Behauli</p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="24154802" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/db2ddf40-1503-4a2a-bf8d-1f57c7b629f9/audio/4b25d5d8-2ff7-4f98-a045-511980facd46/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Arize Founding Engineer Tsion Behailu</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:09</itunes:duration>
      <itunes:summary>Tsion discusses current challenges in ML observability, and explains how Arize&apos;s Bias Tracing Tool was developed to help companies root out bias in their models.</itunes:summary>
      <itunes:subtitle>Tsion discusses current challenges in ML observability, and explains how Arize&apos;s Bias Tracing Tool was developed to help companies root out bias in their models.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>57</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">3285b8f0-8017-4cc8-8135-3747e48ad473</guid>
      <title>Autonomous Aerial Disaster Relief with Head of Engineering Ian Foster</title>
      <description><![CDATA[<p>Ian discusses what unique problems aerial automated vehicles face, how  segregations in the air affect flying, how the vehicles land, and how they know where to land. Animal Dynamics' goal is to phase out humans in their technology entirely and Ian explains the human involvement in the process before telling us where he sees this technology fitting in with disaster response in the future. </p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Ian Foster. </li><li>A brief overview of Ian’s background and how he ended up at Animal Dynamics.</li><li>Ian shares the mission of Animal Dynamics and how that’s being carried out.</li><li>What the delivery mechanism is and what the technology is delivering.</li><li>Why air is best for this kind of delivery and why it’s best not to use pilots.</li><li>The challenges in an aerial automated vehicle. </li><li>How segregations in the air affect this technology and how they’re combatting these issues. </li><li>Ian tells us which is more difficult: to park a car autonomously or land a plane autonomously. </li><li>How their vehicles land themselves. </li><li>How they are training the technology to notice safe landing zones.</li><li>How humans come into this AI technology and why they’re being phased out slowly. </li><li>What Ian thinks the future and long-term opportunities are for Animal Dynamic’s technology.</li></ul><p>Tweetables:</p><p>“Drawing inspiration from the natural world to help address problems is very much the ethos of what Animal Dynamics is all about.” — Ian Foster [0:02:06]</p><p>“Data for autonomous aircraft is definitely a big challenge, as you might imagine.” — Ian Foster [0:16:17]</p><p>We're not aiming to just jump straight to full autonomy from day one. We operate safely within a controlled environment. As we prove out more aspects of the system performance, we can grow that envelope and then prove out the next level.” — Ian Foster [0:19:01]</p><p>“Ultimately, the desire is that the systems basically look after themselves and that humans are only involved in telling the thing where to go, and then the rest is delivered autonomously.” — Ian Foster [0:23:45]</p><p>“The important thing for us is to get out there and start making a difference to people. So we need to find a pragmatic and safe way of doing that.” — Ian Foster [0:23:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ian-foster-559293b4/?originalSubdomain=uk">Ian Foster on LinkedIn</a></p><p><a href="https://www.animal-dynamics.com/">Animal Dynamics</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Fri, 28 Oct 2022 16:21:41 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/autonomous-aerial-disaster-relief-with-head-of-engineering-ian-foster-tAicjGoW</link>
      <content:encoded><![CDATA[<p>Ian discusses what unique problems aerial automated vehicles face, how  segregations in the air affect flying, how the vehicles land, and how they know where to land. Animal Dynamics' goal is to phase out humans in their technology entirely and Ian explains the human involvement in the process before telling us where he sees this technology fitting in with disaster response in the future. </p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Ian Foster. </li><li>A brief overview of Ian’s background and how he ended up at Animal Dynamics.</li><li>Ian shares the mission of Animal Dynamics and how that’s being carried out.</li><li>What the delivery mechanism is and what the technology is delivering.</li><li>Why air is best for this kind of delivery and why it’s best not to use pilots.</li><li>The challenges in an aerial automated vehicle. </li><li>How segregations in the air affect this technology and how they’re combatting these issues. </li><li>Ian tells us which is more difficult: to park a car autonomously or land a plane autonomously. </li><li>How their vehicles land themselves. </li><li>How they are training the technology to notice safe landing zones.</li><li>How humans come into this AI technology and why they’re being phased out slowly. </li><li>What Ian thinks the future and long-term opportunities are for Animal Dynamic’s technology.</li></ul><p>Tweetables:</p><p>“Drawing inspiration from the natural world to help address problems is very much the ethos of what Animal Dynamics is all about.” — Ian Foster [0:02:06]</p><p>“Data for autonomous aircraft is definitely a big challenge, as you might imagine.” — Ian Foster [0:16:17]</p><p>We're not aiming to just jump straight to full autonomy from day one. We operate safely within a controlled environment. As we prove out more aspects of the system performance, we can grow that envelope and then prove out the next level.” — Ian Foster [0:19:01]</p><p>“Ultimately, the desire is that the systems basically look after themselves and that humans are only involved in telling the thing where to go, and then the rest is delivered autonomously.” — Ian Foster [0:23:45]</p><p>“The important thing for us is to get out there and start making a difference to people. So we need to find a pragmatic and safe way of doing that.” — Ian Foster [0:23:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ian-foster-559293b4/?originalSubdomain=uk">Ian Foster on LinkedIn</a></p><p><a href="https://www.animal-dynamics.com/">Animal Dynamics</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27391478" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8bae83d8-f652-4559-98fd-82d049e84750/audio/338c6339-ddb0-4ab4-ac49-e8a4cb37d450/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Autonomous Aerial Disaster Relief with Head of Engineering Ian Foster</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:31</itunes:duration>
      <itunes:summary>Have you ever considered the risk to the humans involved in disaster response? Joining us today on How AI Happens is the Head of Engineering at Animal Dynamics Limited, Ian Foster, to discuss the technology they’re developing in the hopes to eradicate human involvement in life-threatening deliveries, rescues, and disaster response.</itunes:summary>
      <itunes:subtitle>Have you ever considered the risk to the humans involved in disaster response? Joining us today on How AI Happens is the Head of Engineering at Animal Dynamics Limited, Ian Foster, to discuss the technology they’re developing in the hopes to eradicate human involvement in life-threatening deliveries, rescues, and disaster response.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>56</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">2f145235-d594-42d8-9c96-f2817ad78c59</guid>
      <title>Johnson &amp; Johnson Sr. Director Data Science Curren Katz</title>
      <description><![CDATA[<p>Curren is a curious, driven, and creative leader with vast experience in data science and AI. Her original background was in neuroscience and cognitive neuroscience but entered the industry when she realized how much she enjoyed programming, maths, and statistics. Additionally, her biology background gave her an advantage, making her a perfect fit for managing the neuroscience portfolio for Johnson & Johnson. In our conversation with Curren, we learn about her professional background, how her biology background is an advantage, and what she enjoys most about data science, as well as the important work she does at Johnson & Johnson. We then talk about AI in the pharmaceutical industry, how it is used, what it is used for, the benefits of AI both to the company and patients, and her approach to tackling data science problems. She also tells us what it was like moving into a leadership role and shares some advice for people wanting to take the plunge into leadership. </p><p> </p><p>Key Points From This Episode:</p><ul><li>Curren’s professional background and how she ended up in her role at Johnson & Johnson.</li><li>The connection between traditional neuroscience and neural networks in AI.</li><li>Ways in which traditional scientific education in neurology informs AI.</li><li>How much we currently understand about human learning.</li><li>Curren explains her role and responsibilities in her position at Johnson & Johnson.</li><li>What the term ‘precision’ means in her line of work and examples.</li><li>Outline of Curren’s approach to data science and her role at Johnson & Johnson.</li><li>We find out what Curren’s definition of success is.</li><li>The significant benefits of optimizing processes and procedures.</li><li>Curren outlines the various ways AI is deployed at Johnson & Johnson.</li><li>Her experience moving from an individual contributor role into a leadership role.</li><li>Advice Curren has for people who are considering entering a leadership role.</li><li>The importance of trusting your team as a leader.</li></ul><p>Tweetables:</p><p>“Finding new ways to use data to drive diagnosis is a big focus for us.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:11:56]</p><p>“In data science, it can be challenging to define success. But choosing the right problem to solve can make that a lot easier.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:15:27]</p><p>“I want the best data scientists in the world and to have those people on my team or the best managers in the world. I just need to give them the space to be successful.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:23:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/currenkatz/">Curren Katz on LinkedIn</a></p><p><a href="https://twitter.com/currenkatz">Curren Katz on Twitter</a></p><p><a href="https://www.jnj.com/">Johnson & Johnson</a></p><p><a href="https://www.linkedin.com/company/johnson-&-johnson/">Johnson & Johnson on LinkedIn</a></p><p><a href="http://sama.com">Sama</a></p>
]]></description>
      <pubDate>Thu, 20 Oct 2022 22:27:28 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/johnson-johnson-sr-director-data-science-curren-katz-3aawAPSW</link>
      <content:encoded><![CDATA[<p>Curren is a curious, driven, and creative leader with vast experience in data science and AI. Her original background was in neuroscience and cognitive neuroscience but entered the industry when she realized how much she enjoyed programming, maths, and statistics. Additionally, her biology background gave her an advantage, making her a perfect fit for managing the neuroscience portfolio for Johnson & Johnson. In our conversation with Curren, we learn about her professional background, how her biology background is an advantage, and what she enjoys most about data science, as well as the important work she does at Johnson & Johnson. We then talk about AI in the pharmaceutical industry, how it is used, what it is used for, the benefits of AI both to the company and patients, and her approach to tackling data science problems. She also tells us what it was like moving into a leadership role and shares some advice for people wanting to take the plunge into leadership. </p><p> </p><p>Key Points From This Episode:</p><ul><li>Curren’s professional background and how she ended up in her role at Johnson & Johnson.</li><li>The connection between traditional neuroscience and neural networks in AI.</li><li>Ways in which traditional scientific education in neurology informs AI.</li><li>How much we currently understand about human learning.</li><li>Curren explains her role and responsibilities in her position at Johnson & Johnson.</li><li>What the term ‘precision’ means in her line of work and examples.</li><li>Outline of Curren’s approach to data science and her role at Johnson & Johnson.</li><li>We find out what Curren’s definition of success is.</li><li>The significant benefits of optimizing processes and procedures.</li><li>Curren outlines the various ways AI is deployed at Johnson & Johnson.</li><li>Her experience moving from an individual contributor role into a leadership role.</li><li>Advice Curren has for people who are considering entering a leadership role.</li><li>The importance of trusting your team as a leader.</li></ul><p>Tweetables:</p><p>“Finding new ways to use data to drive diagnosis is a big focus for us.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:11:56]</p><p>“In data science, it can be challenging to define success. But choosing the right problem to solve can make that a lot easier.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:15:27]</p><p>“I want the best data scientists in the world and to have those people on my team or the best managers in the world. I just need to give them the space to be successful.” — <a href="https://twitter.com/currenkatz">@CurrenKatz</a> [0:23:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/currenkatz/">Curren Katz on LinkedIn</a></p><p><a href="https://twitter.com/currenkatz">Curren Katz on Twitter</a></p><p><a href="https://www.jnj.com/">Johnson & Johnson</a></p><p><a href="https://www.linkedin.com/company/johnson-&-johnson/">Johnson & Johnson on LinkedIn</a></p><p><a href="http://sama.com">Sama</a></p>
]]></content:encoded>
      <enclosure length="24048222" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f1082ae8-28b9-4f58-8d44-d29f8078ab44/audio/4e40307f-0142-4864-9e25-e5c96c41b906/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Johnson &amp; Johnson Sr. Director Data Science Curren Katz</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:02</itunes:duration>
      <itunes:summary>Johnson &amp; Johnson&apos;s Senior Director of Data Science, Curren Katz, explains the parallels between neuroscience and AI development, including when we should strive to mirror human cognition in technology, and when copying human learning actually may be a hindrance.</itunes:summary>
      <itunes:subtitle>Johnson &amp; Johnson&apos;s Senior Director of Data Science, Curren Katz, explains the parallels between neuroscience and AI development, including when we should strive to mirror human cognition in technology, and when copying human learning actually may be a hindrance.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>55</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">f7831efe-7222-435a-8950-eba0586aece4</guid>
      <title>Microsoft&apos;s AI for Science Senior Director Bonnie Kruft</title>
      <description><![CDATA[<p>Dr. Kruft unpacks how she went from earning a Ph.D. focused on quantum chemistry, to working in AI and machine learning. She shares how she first discovered her love of data science, and how her Ph.D. equipped her with the skills she needed to transition into this new and exciting field. We also discuss the data science approach to problem-solving, deep learning emulators, and the impact that machine learning could have on the natural sciences. <br /> </p><p>Key Points From This Episode:</p><ul><li>Introducing today's guest, Bonnie Kruft, Senior Director at Microsoft’s AI for Science.</li><li>A quick look at Bonnie’s background and the research she is currently doing.</li><li>The work that Bonnie did on quantum chemistry for her Ph.D. dissertation.</li><li>How quantum chemistry led to her working in the field of AI.</li><li>An overview of the transferable skills that Bonnie picked up during her Ph.D.</li><li>Learn about Bonnie’s work with pharmaceutical companies.</li><li>How Bonnie became interested in data science and machine learning.</li><li>The data science approach to problem-solving.</li><li>The concept of falling faster and how to facilitate it.</li><li>What the word ‘quantum’ means and how it applies to computing.</li><li>How Bonnie’s Ph.D. prepared her for a career in machine learning.</li><li>The impact that machine learning could have on the natural sciences.</li><li>A breakdown of the four paradigms through which science has evolved.</li><li>The emulator approach and how it can apply to anywhere data science is being done.</li><li>Learn about Microsoft's AI for science and what they are doing with machine learning.</li><li>What Bonnie’s typical day looks like.</li></ul><p>Tweetables:</p><p>“Although I wasn't really working on machine learning, or data science during my Ph.D., there's a lot of transferable skills that I picked up along the way while I was working on quantum chemistry.” — Bonnie Kruft [0:03:00]</p><p>“We believe that deep learning could have a really transformational impact on the natural sciences.” — Bonnie Kruft [0:13:02]</p><p>“The idea is that deep learning emulators will be used for the things that are going to make the most impact on the world. Solving healthcare challenges, combating disease, combating climate change, and sustainability. Things like that.” — Bonnie Kruft [0:21:29]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bonniekruft/?originalSubdomain=uk">Bonnie Kruft on LinkedIn</a></p><p><a href="https://www.microsoft.com/">Microsoft</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 6 Oct 2022 20:18:46 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/microsofts-ai-for-science-senior-director-bonnie-kruft-jMreBiWq</link>
      <content:encoded><![CDATA[<p>Dr. Kruft unpacks how she went from earning a Ph.D. focused on quantum chemistry, to working in AI and machine learning. She shares how she first discovered her love of data science, and how her Ph.D. equipped her with the skills she needed to transition into this new and exciting field. We also discuss the data science approach to problem-solving, deep learning emulators, and the impact that machine learning could have on the natural sciences. <br /> </p><p>Key Points From This Episode:</p><ul><li>Introducing today's guest, Bonnie Kruft, Senior Director at Microsoft’s AI for Science.</li><li>A quick look at Bonnie’s background and the research she is currently doing.</li><li>The work that Bonnie did on quantum chemistry for her Ph.D. dissertation.</li><li>How quantum chemistry led to her working in the field of AI.</li><li>An overview of the transferable skills that Bonnie picked up during her Ph.D.</li><li>Learn about Bonnie’s work with pharmaceutical companies.</li><li>How Bonnie became interested in data science and machine learning.</li><li>The data science approach to problem-solving.</li><li>The concept of falling faster and how to facilitate it.</li><li>What the word ‘quantum’ means and how it applies to computing.</li><li>How Bonnie’s Ph.D. prepared her for a career in machine learning.</li><li>The impact that machine learning could have on the natural sciences.</li><li>A breakdown of the four paradigms through which science has evolved.</li><li>The emulator approach and how it can apply to anywhere data science is being done.</li><li>Learn about Microsoft's AI for science and what they are doing with machine learning.</li><li>What Bonnie’s typical day looks like.</li></ul><p>Tweetables:</p><p>“Although I wasn't really working on machine learning, or data science during my Ph.D., there's a lot of transferable skills that I picked up along the way while I was working on quantum chemistry.” — Bonnie Kruft [0:03:00]</p><p>“We believe that deep learning could have a really transformational impact on the natural sciences.” — Bonnie Kruft [0:13:02]</p><p>“The idea is that deep learning emulators will be used for the things that are going to make the most impact on the world. Solving healthcare challenges, combating disease, combating climate change, and sustainability. Things like that.” — Bonnie Kruft [0:21:29]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/bonniekruft/?originalSubdomain=uk">Bonnie Kruft on LinkedIn</a></p><p><a href="https://www.microsoft.com/">Microsoft</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="25385274" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/9487f7ed-bdb0-4987-ae11-2efa8aff7f1d/audio/d00d1978-4807-4346-9425-232af515bb5c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Microsoft&apos;s AI for Science Senior Director Bonnie Kruft</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:26</itunes:duration>
      <itunes:summary> Dr. Bonnie Kruft currently serves as the Senior Director at Microsoft’s AI for Science, and in our conversation, we cover everything from quantum chemistry to data science. Tuning in you’ll hear Dr. Kruft unpack how she went from earning a Ph.D. focused on quantum chemistry, to working in AI and machine learning. </itunes:summary>
      <itunes:subtitle> Dr. Bonnie Kruft currently serves as the Senior Director at Microsoft’s AI for Science, and in our conversation, we cover everything from quantum chemistry to data science. Tuning in you’ll hear Dr. Kruft unpack how she went from earning a Ph.D. focused on quantum chemistry, to working in AI and machine learning. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>54</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">3e8c5abe-7bee-4414-8462-e69ed2efbb93</guid>
      <title>Valo Health Chief AI Officer Brandon Allgood</title>
      <description><![CDATA[<p>In our conversation, we discuss Brandon's approach to problem-solving, the use of synthetic data, challenges facing the use of AI in drug development, why the diversity of both data and scientists is important, the three qualities required for innovation, and much more.</p><p>Key Points From This Episode:</p><ul><li>We hear about Brandon’s unconventional background and professional career journey. </li><li>Why he has a passion for combining AI and machine learning with biology.</li><li>An outline of the Opal platform and how it is used for drug discovery.</li><li>Brandon’s approach to innovating and improving various stages of pharmaceutical development.</li><li>Whether or not he thinks his approach can be applied outside of pharmaceutical development.</li><li>How data science is used in traditional companies and how this differs at Valo.</li><li>What signs people should look out for to ensure they are at a data-driven organization. </li><li>A brief discussion about the benefits of using non-traditional approaches. </li><li>Ways in which Brandon sees synthetic data being used in the future.</li><li>The biggest challenge currently limiting the use of synthetic data. </li><li>A breakdown of the three competing qualities that are required to innovate.</li><li>Reasons why Brandon thinks current algorithms and the underlying datasets need to be improved. </li><li>Brandon shares his approach to ensuring fairness and rooting out bias in datasets.</li><li>Another problem the industry faces with scientists: a lack of diversity.</li><li>The value of re-weighting a training set.</li><li>Innovations in AI and machine learning that keeps Brandon motivated and inspired.</li></ul><p>Tweetables:</p><p>“Instead of improving the legacy, is there a way to really innovate and break things? And that’s the way we think about it here at Valo.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:08:46]</p><p>“Here at Valo, if data scientists have good ideas, we let them run with them, you know? We let them commission experiments. That’s not generally the way that a traditional organization would work.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:11:31]</p><p>“While you might be able to get synthetic data that represents the bulk, you are not going to get the resolution within those patients, within those subgroups, within the patient set.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:15:15]</p><p>“We suffer right now from a lack of diversity of data, but then, on the other side, we also suffer as a field from lack of diversity in our scientists.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:19:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://brandonallgood.net">Brandon Allgood</a></p><p><a href="https://www.linkedin.com/in/brandonallgood/">Brandon Allgood on LinkedIn</a></p><p><a href="https://www.valohealth.com">Valo</a></p><p><a href="https://www.linkedin.com/company/valo-health/">Valo on LinkedIn</a></p><p><a href="https://www.valohealth.com/platform">Opal platform</a></p><p><a href="https://www.dali-alliance.org/">DALI Alliance</a></p><p><a href="https://logica.dev/">Logica</a></p><p><a href="https://twitter.com/allg00d?lang=en">Brandon Allgood on Twitter</a></p><p><a href="https://www.linkedin.com/in/rob-stevenson-92603541/">Rob Stevenson on LinkedIn</a></p><p><a href="http://sama.com">Sama</a></p>
]]></description>
      <pubDate>Thu, 22 Sep 2022 19:48:43 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/valo-health-chief-ai-officer-brandon-allgood-N7_BhuxS</link>
      <content:encoded><![CDATA[<p>In our conversation, we discuss Brandon's approach to problem-solving, the use of synthetic data, challenges facing the use of AI in drug development, why the diversity of both data and scientists is important, the three qualities required for innovation, and much more.</p><p>Key Points From This Episode:</p><ul><li>We hear about Brandon’s unconventional background and professional career journey. </li><li>Why he has a passion for combining AI and machine learning with biology.</li><li>An outline of the Opal platform and how it is used for drug discovery.</li><li>Brandon’s approach to innovating and improving various stages of pharmaceutical development.</li><li>Whether or not he thinks his approach can be applied outside of pharmaceutical development.</li><li>How data science is used in traditional companies and how this differs at Valo.</li><li>What signs people should look out for to ensure they are at a data-driven organization. </li><li>A brief discussion about the benefits of using non-traditional approaches. </li><li>Ways in which Brandon sees synthetic data being used in the future.</li><li>The biggest challenge currently limiting the use of synthetic data. </li><li>A breakdown of the three competing qualities that are required to innovate.</li><li>Reasons why Brandon thinks current algorithms and the underlying datasets need to be improved. </li><li>Brandon shares his approach to ensuring fairness and rooting out bias in datasets.</li><li>Another problem the industry faces with scientists: a lack of diversity.</li><li>The value of re-weighting a training set.</li><li>Innovations in AI and machine learning that keeps Brandon motivated and inspired.</li></ul><p>Tweetables:</p><p>“Instead of improving the legacy, is there a way to really innovate and break things? And that’s the way we think about it here at Valo.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:08:46]</p><p>“Here at Valo, if data scientists have good ideas, we let them run with them, you know? We let them commission experiments. That’s not generally the way that a traditional organization would work.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:11:31]</p><p>“While you might be able to get synthetic data that represents the bulk, you are not going to get the resolution within those patients, within those subgroups, within the patient set.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:15:15]</p><p>“We suffer right now from a lack of diversity of data, but then, on the other side, we also suffer as a field from lack of diversity in our scientists.” — <a href="https://twitter.com/allg00d?lang=en">@allg00d</a> [0:19:42]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="http://brandonallgood.net">Brandon Allgood</a></p><p><a href="https://www.linkedin.com/in/brandonallgood/">Brandon Allgood on LinkedIn</a></p><p><a href="https://www.valohealth.com">Valo</a></p><p><a href="https://www.linkedin.com/company/valo-health/">Valo on LinkedIn</a></p><p><a href="https://www.valohealth.com/platform">Opal platform</a></p><p><a href="https://www.dali-alliance.org/">DALI Alliance</a></p><p><a href="https://logica.dev/">Logica</a></p><p><a href="https://twitter.com/allg00d?lang=en">Brandon Allgood on Twitter</a></p><p><a href="https://www.linkedin.com/in/rob-stevenson-92603541/">Rob Stevenson on LinkedIn</a></p><p><a href="http://sama.com">Sama</a></p>
]]></content:encoded>
      <enclosure length="27751758" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/5c01c3ba-ad0f-4282-b6cc-d8aa540b84cb/audio/99da7471-3c6a-4ad3-8485-8311857c1bc0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Valo Health Chief AI Officer Brandon Allgood</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:54</itunes:duration>
      <itunes:summary>Valo Health is transforming the drug discovery and development processes while accelerating the creation of life-changing drugs. Brandon manages the development and application of Valo&apos;s AI platform and is responsible for the company&apos;s technological vision. Despite his unconventional background, he is an expert in machine learning and AI and leverages these technologies for innovating pharmaceutical drug discovery and development processes</itunes:summary>
      <itunes:subtitle>Valo Health is transforming the drug discovery and development processes while accelerating the creation of life-changing drugs. Brandon manages the development and application of Valo&apos;s AI platform and is responsible for the company&apos;s technological vision. Despite his unconventional background, he is an expert in machine learning and AI and leverages these technologies for innovating pharmaceutical drug discovery and development processes</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>53</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e1828d54-541d-46e6-8386-5a0627a00e02</guid>
      <title>AI Drones in Agriculture with Precision AI&apos;s Heather Clair</title>
      <description><![CDATA[<p>In this episode, Heather shares her background in both farming and commerce, and explains how her in-field experience and insights aid both her and the AI team in the development cycle. We learn about the advantages of drone-based precision spraying, the function of the herbicides that Precision AI’s drones spray onto crops, and the various challenges of creating AI models that can recognize plant variations. </p><p>Key Points From This Episode:</p><ul><li>Introducing Heather Clair, Product Manager at precision.ai.</li><li>Heather’s background in farming and commerce; and what led her to precision.ai.</li><li>precision.ai’s dramatically different approach to agriculture.</li><li>The advantages of drone-based precision spraying, as opposed to land-based high-clearance spraying.</li><li>The function of the herbicides that precision.ai’s drones spray onto crops.</li><li>precision.ai’s use of AI to teach their drones to identify crops and distribute herbicides with precision.  </li><li>The relationship between Heather, as product manager, and the AI experts at precision.ai.</li><li>Heather’s involvement in the development cycle.</li><li>Sama’s reliable accuracy rate.</li><li>The challenge of creating AI models that recognize and can work with plant variations.</li><li>How the varying colors of soil impact the AI models.</li><li>The phenomenon of phenoplasticity and the challenge it presents to the AI team. </li><li>The advantage Heather has of having in-field experience.</li><li>Heather’s closing tip: how to have happier, healthier houseplants.</li></ul><p>Tweetables:</p><p>“Up until now, everybody just went, ‘How do we get more efficient [with] fewer passes?’ But nobody questioned, ‘Are we doing the passes with the right equipment?’” — Heather Clair [0:07:07]</p><p>“[precision.ai is] moving from land-based high-clearance sprayers to drone-based precision spraying.” — Heather Clair [0:07:24]</p><p>“I never thought when I was a little farm kid that I would be playing with drones, but it is one of my favorite things to do.” — Heather Clair [0:07:45]</p><p>“Trying to create these AI models that can work on any stage of plant can be a challenge.” — Heather Clair [0:21:15]</p><p>“It's incredible how working with my AI team has opened up my eyes to being able to look at these plants from a very logical standpoint.” — Heather Clair [0:25:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/heather-clair-038997116">Heather Clair on LinkedIn</a></p><p><a href="https://www.precision.ai/">precision.ai</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 15 Sep 2022 17:41:52 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-drones-in-agriculture-with-precision-ais-heather-clair-kmDjT6_E</link>
      <content:encoded><![CDATA[<p>In this episode, Heather shares her background in both farming and commerce, and explains how her in-field experience and insights aid both her and the AI team in the development cycle. We learn about the advantages of drone-based precision spraying, the function of the herbicides that Precision AI’s drones spray onto crops, and the various challenges of creating AI models that can recognize plant variations. </p><p>Key Points From This Episode:</p><ul><li>Introducing Heather Clair, Product Manager at precision.ai.</li><li>Heather’s background in farming and commerce; and what led her to precision.ai.</li><li>precision.ai’s dramatically different approach to agriculture.</li><li>The advantages of drone-based precision spraying, as opposed to land-based high-clearance spraying.</li><li>The function of the herbicides that precision.ai’s drones spray onto crops.</li><li>precision.ai’s use of AI to teach their drones to identify crops and distribute herbicides with precision.  </li><li>The relationship between Heather, as product manager, and the AI experts at precision.ai.</li><li>Heather’s involvement in the development cycle.</li><li>Sama’s reliable accuracy rate.</li><li>The challenge of creating AI models that recognize and can work with plant variations.</li><li>How the varying colors of soil impact the AI models.</li><li>The phenomenon of phenoplasticity and the challenge it presents to the AI team. </li><li>The advantage Heather has of having in-field experience.</li><li>Heather’s closing tip: how to have happier, healthier houseplants.</li></ul><p>Tweetables:</p><p>“Up until now, everybody just went, ‘How do we get more efficient [with] fewer passes?’ But nobody questioned, ‘Are we doing the passes with the right equipment?’” — Heather Clair [0:07:07]</p><p>“[precision.ai is] moving from land-based high-clearance sprayers to drone-based precision spraying.” — Heather Clair [0:07:24]</p><p>“I never thought when I was a little farm kid that I would be playing with drones, but it is one of my favorite things to do.” — Heather Clair [0:07:45]</p><p>“Trying to create these AI models that can work on any stage of plant can be a challenge.” — Heather Clair [0:21:15]</p><p>“It's incredible how working with my AI team has opened up my eyes to being able to look at these plants from a very logical standpoint.” — Heather Clair [0:25:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/heather-clair-038997116">Heather Clair on LinkedIn</a></p><p><a href="https://www.precision.ai/">precision.ai</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="27669838" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/fb40826d-6c17-4c9e-bb68-c5946db80bd8/audio/6fafdf24-7bbf-4be2-bd30-0b41d0a1a123/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI Drones in Agriculture with Precision AI&apos;s Heather Clair</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:49</itunes:duration>
      <itunes:summary>Today we are joined by Product Manager Heather Clair to discuss how Precision AI is disrupting the agricultural industry by taking a dramatically different approach to the traditional land-based high-clearance crop spraying model. Instead, precision.ai uses AI trained drones to target individual crops.</itunes:summary>
      <itunes:subtitle>Today we are joined by Product Manager Heather Clair to discuss how Precision AI is disrupting the agricultural industry by taking a dramatically different approach to the traditional land-based high-clearance crop spraying model. Instead, precision.ai uses AI trained drones to target individual crops.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>52</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">982a13db-f16e-4595-9161-71e06e603258</guid>
      <title>AI in Video Games with Head of Data &amp; AI Xiaoyang</title>
      <description><![CDATA[<p>Xiaoyang Yang, Head of Data AI Security and IT over at Second Dinner Studios, explains how Second Dinner navigates the issue of excess data with intention and discover the metrics that go deeper than the surface to measure the quality of competition, balance, and fairness within gaming. Xiaoyang also describes the difference between AI and gaming AI and shows us how each can be used to enhance the other. Listen to today’s episode for a careful look at how AI can be used to improve player experience and how gaming can act as a testing ground to improve AI in everyday life. </p><p>Key Points From This Episode:</p><ul><li>Introducing Xiaoyang Yang, head of Data AI Security and IT at Second Dinner Studios.</li><li>His recently launched video game, MARVEL SNAP.</li><li>How he uses data as a tool to listen to players before translating it into insights.</li><li>The role of scale and how it changes the parameters around which players you attract.</li><li>The discrepancy between how different players experience the same feature.</li><li>Xiaoyang’s background in theoretical physics, machine learning, and gaming.</li><li>How an internship at Blizzard helped him enter a new industry.</li><li>His time working on World of Warcraft and with Riot Games.</li><li>Second Dinner’s partnership with Marvel to create MARVEL SNAP.</li><li>Xiaoyang’s aim to use data to make the game accessible to a wider audience who hasn’t tried collectible card games before. </li><li>The issue of excess data and how Second Dinner combats this with careful intention.</li><li>Data metrics that go deeper to enhance design and balance.</li><li>Competition, fairness, and balance as indicators for how fun a game will be for players.</li><li>How AI can be used to test fairness and balance in gaming.</li><li>How game AI differs from AI in general and how each can be used to inform the other. </li><li>The competitive experience you can have with gaming AI due to different skill levels.</li><li>The new experience you can offer users today that has been facilitated by AI. </li></ul><p>Tweetables:</p><p>“We try to really listen to what our players are saying. One way to do that is through data. We use data as a tool.” — Xiaoyang Yang [0:02:28]</p><p>“When you see the scale, you begin to really understand that different players have different desires. Sometimes, different players see the same feature or the same experience in a very different type of way.” — Xiaoyang Yang [0:04:46]</p><p>“We see a lot of opportunities to use technology data AI to make MARVEL SNAP approachable to a wide audience of players and, hopefully, some players who have never tried the genre of collectible card games.” — Xiaoyang Yang [0:11:25]<br /><br />“We want to make sure that there are different sets of cards you can use to have fun and still be competitive in the game. That's not an easy task.” — Xiaoyang Yang [0:19:25]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/xyyang/">Xiaoyang Yang on LinkedIn</a></p><p><a href="https://seconddinner.com/">Second Dinner Studios</a></p><p><a href="https://www.marvelsnap.com/">MARVEL SNAP</a></p><p><a href="https://www.blizzard.com/en-us/">Blizzard</a></p><p><a href="https://www.riotgames.com/en">Riot Games</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Wed, 24 Aug 2022 12:49:22 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-in-video-games-with-head-of-data-ai-xiaoyang-1BLh4yZd</link>
      <content:encoded><![CDATA[<p>Xiaoyang Yang, Head of Data AI Security and IT over at Second Dinner Studios, explains how Second Dinner navigates the issue of excess data with intention and discover the metrics that go deeper than the surface to measure the quality of competition, balance, and fairness within gaming. Xiaoyang also describes the difference between AI and gaming AI and shows us how each can be used to enhance the other. Listen to today’s episode for a careful look at how AI can be used to improve player experience and how gaming can act as a testing ground to improve AI in everyday life. </p><p>Key Points From This Episode:</p><ul><li>Introducing Xiaoyang Yang, head of Data AI Security and IT at Second Dinner Studios.</li><li>His recently launched video game, MARVEL SNAP.</li><li>How he uses data as a tool to listen to players before translating it into insights.</li><li>The role of scale and how it changes the parameters around which players you attract.</li><li>The discrepancy between how different players experience the same feature.</li><li>Xiaoyang’s background in theoretical physics, machine learning, and gaming.</li><li>How an internship at Blizzard helped him enter a new industry.</li><li>His time working on World of Warcraft and with Riot Games.</li><li>Second Dinner’s partnership with Marvel to create MARVEL SNAP.</li><li>Xiaoyang’s aim to use data to make the game accessible to a wider audience who hasn’t tried collectible card games before. </li><li>The issue of excess data and how Second Dinner combats this with careful intention.</li><li>Data metrics that go deeper to enhance design and balance.</li><li>Competition, fairness, and balance as indicators for how fun a game will be for players.</li><li>How AI can be used to test fairness and balance in gaming.</li><li>How game AI differs from AI in general and how each can be used to inform the other. </li><li>The competitive experience you can have with gaming AI due to different skill levels.</li><li>The new experience you can offer users today that has been facilitated by AI. </li></ul><p>Tweetables:</p><p>“We try to really listen to what our players are saying. One way to do that is through data. We use data as a tool.” — Xiaoyang Yang [0:02:28]</p><p>“When you see the scale, you begin to really understand that different players have different desires. Sometimes, different players see the same feature or the same experience in a very different type of way.” — Xiaoyang Yang [0:04:46]</p><p>“We see a lot of opportunities to use technology data AI to make MARVEL SNAP approachable to a wide audience of players and, hopefully, some players who have never tried the genre of collectible card games.” — Xiaoyang Yang [0:11:25]<br /><br />“We want to make sure that there are different sets of cards you can use to have fun and still be competitive in the game. That's not an easy task.” — Xiaoyang Yang [0:19:25]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/xyyang/">Xiaoyang Yang on LinkedIn</a></p><p><a href="https://seconddinner.com/">Second Dinner Studios</a></p><p><a href="https://www.marvelsnap.com/">MARVEL SNAP</a></p><p><a href="https://www.blizzard.com/en-us/">Blizzard</a></p><p><a href="https://www.riotgames.com/en">Riot Games</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="34644323" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/6f8ba8c4-0f1d-4326-8e01-4e959ca95c0f/audio/b725efb4-a237-4084-95d5-07c19fb23f0c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI in Video Games with Head of Data &amp; AI Xiaoyang</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:36:05</itunes:duration>
      <itunes:summary>Joining us in conversation today is Xiaoyang Yang, Head of Data AI Security and IT over at Second Dinner Studios. Tuning in, you’ll hear about his recently launched video game, MARVEL SNAP, and how he uses data as a tool to listen to what players want. Find out how Xiaoyang moved from a background in theoretical physics to working in video games and AI and hear how different players can experience the same feature in an entirely different way.</itunes:summary>
      <itunes:subtitle>Joining us in conversation today is Xiaoyang Yang, Head of Data AI Security and IT over at Second Dinner Studios. Tuning in, you’ll hear about his recently launched video game, MARVEL SNAP, and how he uses data as a tool to listen to what players want. Find out how Xiaoyang moved from a background in theoretical physics to working in video games and AI and hear how different players can experience the same feature in an entirely different way.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>51</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">4590e220-e8cb-4fe4-a4d3-3d0383d38832</guid>
      <title>Lead Full Stack AI Engineer Becks Simpson</title>
      <description><![CDATA[<p>Tune in to hear more about Becks’ role as a lead full stack AI engineer at Rogo, how they determine what should and should not be added into the product tier for deep learning, the types of questions you should be asking along the investigation-to-product roadmap for AI and machine learning products, and so much more!</p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Lead Full Stack AI Engineer, Becks Simpson. </li><li>Becks’ cover band Des Confitures made up of machine learning engineers and other academics. </li><li>Becks’ career background and how she ended up in her role at Rogo. </li><li>How Rogo enables people to unlock or make sense of unstructured or unorganized data.</li><li>Why Becks’ role could be compared to that of an AI Swiss Army Knife. </li><li>How they determine what should and should not be added to the product tier for deep learning. </li><li>Becks’ experience of having to give someone higher up a reality check about the technical needs of their product.  </li><li>Why Becks believes there are so many nontechnical hats you need to wear as an AI or ML expert. </li><li>Thoughts on the trend of product managers being taught how to do AI but not AI people being taught to do product management.</li><li>The importance of bringing data about data into the conversation. </li><li>The types of questions you should be asking and where the answers to understanding your dataset will then take you. </li><li>How the investigation-to-product roadmap is not something you would learn in academia for AI machine learning and why it should be.  </li><li>Thoughts as to why it is so common for someone to have one foot in the industry and one foot in academia.  </li><li>An area of AI machine learning that Becks is truly excited about: off the shelf models. </li></ul><p>Tweetables:</p><p>“People think that [AI] can do more than what it can and it has only been the last few years where we realized that actually, there’s a lot of work to put it in production successfully, there’s a lot of catastrophic ways it can fail, there are a lot of considerations that need to be put in.” — Becks Simpson [0:11:39]</p><p>“Make sure that if you ever want to put any kind of machine learning or AI or something into a product, have people who can look at a road map for doing that and who can evaluate whether it even makes sense from an ROI business standpoint, and then work with the teams.” — Becks Simpson [0:12:55]</p><p>“I think for the people who are in academia, a lot of them are doing it to push the needle, and to push the state of the art, and to build things that we didn’t have before and to see if they can answer questions that we couldn’t answer before. Having said that, there’s not always a link back to a practical use case.” — Becks Simpson [0:20:25]</p><p>“Academia will always produce really interesting things and then it’s industry that will look at whether or not they can be used for practical problems.” — Becks Simpson [0:21:59]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/becks-simpson/">Becks Simpson </a></p><p><a href="https://www.rogodata.com/">Rogo</a></p><p><a href="https://www.desconfituresjams.com/">Des Confitures</a>  </p><p><a href="https://mila.quebec/">Montreal Institute of Learning Algorithms</a></p><p><a href="http://sama.com">Sama</a></p>
]]></description>
      <pubDate>Thu, 18 Aug 2022 20:06:38 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/lead-full-stack-ai-engineer-becks-simpson-YtfkOkeG</link>
      <content:encoded><![CDATA[<p>Tune in to hear more about Becks’ role as a lead full stack AI engineer at Rogo, how they determine what should and should not be added into the product tier for deep learning, the types of questions you should be asking along the investigation-to-product roadmap for AI and machine learning products, and so much more!</p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Lead Full Stack AI Engineer, Becks Simpson. </li><li>Becks’ cover band Des Confitures made up of machine learning engineers and other academics. </li><li>Becks’ career background and how she ended up in her role at Rogo. </li><li>How Rogo enables people to unlock or make sense of unstructured or unorganized data.</li><li>Why Becks’ role could be compared to that of an AI Swiss Army Knife. </li><li>How they determine what should and should not be added to the product tier for deep learning. </li><li>Becks’ experience of having to give someone higher up a reality check about the technical needs of their product.  </li><li>Why Becks believes there are so many nontechnical hats you need to wear as an AI or ML expert. </li><li>Thoughts on the trend of product managers being taught how to do AI but not AI people being taught to do product management.</li><li>The importance of bringing data about data into the conversation. </li><li>The types of questions you should be asking and where the answers to understanding your dataset will then take you. </li><li>How the investigation-to-product roadmap is not something you would learn in academia for AI machine learning and why it should be.  </li><li>Thoughts as to why it is so common for someone to have one foot in the industry and one foot in academia.  </li><li>An area of AI machine learning that Becks is truly excited about: off the shelf models. </li></ul><p>Tweetables:</p><p>“People think that [AI] can do more than what it can and it has only been the last few years where we realized that actually, there’s a lot of work to put it in production successfully, there’s a lot of catastrophic ways it can fail, there are a lot of considerations that need to be put in.” — Becks Simpson [0:11:39]</p><p>“Make sure that if you ever want to put any kind of machine learning or AI or something into a product, have people who can look at a road map for doing that and who can evaluate whether it even makes sense from an ROI business standpoint, and then work with the teams.” — Becks Simpson [0:12:55]</p><p>“I think for the people who are in academia, a lot of them are doing it to push the needle, and to push the state of the art, and to build things that we didn’t have before and to see if they can answer questions that we couldn’t answer before. Having said that, there’s not always a link back to a practical use case.” — Becks Simpson [0:20:25]</p><p>“Academia will always produce really interesting things and then it’s industry that will look at whether or not they can be used for practical problems.” — Becks Simpson [0:21:59]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/becks-simpson/">Becks Simpson </a></p><p><a href="https://www.rogodata.com/">Rogo</a></p><p><a href="https://www.desconfituresjams.com/">Des Confitures</a>  </p><p><a href="https://mila.quebec/">Montreal Institute of Learning Algorithms</a></p><p><a href="http://sama.com">Sama</a></p>
]]></content:encoded>
      <enclosure length="24254694" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d766bf9c-6e51-42a4-8c5a-10bbdd2d6f0f/audio/1176a525-729c-40ea-af0d-a397e8a9ff6d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Lead Full Stack AI Engineer Becks Simpson</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:15</itunes:duration>
      <itunes:summary>Joining us today is the lead full stack AI engineer at Rogo as well as the lead guitarist for Des Confitures, Becks Simpson. Becks studied mechatronics in Australia and has a background in robotics. She moved into AI at a medical imaging startup before she came to Montreal to do a research project at the Montreal Institute of Learning Algorithms.</itunes:summary>
      <itunes:subtitle>Joining us today is the lead full stack AI engineer at Rogo as well as the lead guitarist for Des Confitures, Becks Simpson. Becks studied mechatronics in Australia and has a background in robotics. She moved into AI at a medical imaging startup before she came to Montreal to do a research project at the Montreal Institute of Learning Algorithms.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>50</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">7f613172-99f9-4203-86bc-1a9bb1a502e0</guid>
      <title>Neural Rendering with fxguide Co-Founder Dr. Mike Seymour</title>
      <description><![CDATA[<p> Dr. Seymour aims to take cutting-edge technology and apply it to the special effects industry, such as with the new AI platform, PLATO. He is also a lecturer at the University of Sydney and works as a consultant within the special effects industry. He is an internationally respected researcher and expert in Digital Humans and virtual production, and his experience in both visual effects and pure maths makes him perfect for AI-based visual effects. In our conversation we find out more about Dr. Seymour’s professional career journey, and what he enjoys the most about working as both a researcher and practitioner. We then get into all the details about AI in special effects as we learn about Digital Humans, the new PLATO platform, why AI dubbing is better, the biggest challenges facing the application of AI in special effects.</p><p>Key Points From This Episode:</p><ul><li>Dr. Seymour explains his background and professional career journey. </li><li>Why he enjoys bridging the gap between researcher and practitioner.</li><li>An outline of the different topics that Dr. Seymour lectures in and what he is currently working on.</li><li>He explains what he means by the term ‘digital humans’ and provides examples.</li><li>The special effects platform, PLATO, he is currently working on and what it will be used for.</li><li>An explanation of how PLATO was used in the Polish movie, <i>The Champion</i>.</li><li>He explains the future goals and aims for auto-dubbing using AI and visual effects.</li><li>Why auto-dubbing procedure will not add or encumber existing processes of making a movie. </li><li>Reasons why AI auto-dubbing is better than traditional dubbing.</li><li>Whether this is a natural language processing challenge or more of a creative filmmaking challenge.</li><li>A discussion about why new technologies take long to be applied to real-world scenarios.</li><li>How the underlying process of PLATO are different from what is required to make a deepfake video. </li><li>His approach to overcoming challenges facing the PLATO platform. </li><li>Other areas of the entertainment industry Dr. Seymour expects AI to be disruptive.</li></ul><p>Tweetables:</p><p>“In the film, half the actors are the original actors come back to just re-voice themselves, half aren’t. In the film hopefully, when you watch it, it’s indistinguishable that it wasn’t actually filmed in English. — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:10:15]</p><p>“In our process, it doesn’t apply because if you were saying in four words what I’d said in three, it would just match. We don’t have to match the timing, we don’t have to match the lip movement or jaw movement, it all gets fixed.” — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:15:15]</p><p>“My attitude is, it’s all very well for us to get this working in the lab, but it has to work in the real world.” — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:19:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/mikesfxguide/">Dr. Mike Seymour on LinkedIn</a></p><p><a href="https://twitter.com/mikeseymour?lang=en">Dr. Mike Seymour on Twitter</a></p><p><a href="https://scholar.google.com.au/citations?user=dk__LG4AAAAJ&hl=en">Dr. Mike Seymour on Google Scholar </a></p><p><a href="https://www.sydney.edu.au/">University of Sydney</a></p><p><a href="https://www.fxguide.com">fxguide</a></p><p><a href="https://www.pauldebevec.com">Dr. Paul Debevec</a></p><p><a href="https://www.pixar.com/">Pixar</a></p><p><a href="https://www.linkedin.com/in/darryl-marks-7807821b5/">Darryl Marks on LinkedIn</a></p><p><a href="https://www.adaptentertainment.com">Adapt Entertainment</a></p><p><a href="https://www.adaptentertainment.com/technology">PLATO Demonstration Link</a></p><p><a href="https://www.imdb.com/title/tt11369540/"><i>The Champion</i></a></p><p><a href="https://www.pinscreen.com/">Pinscreen</a></p><p><a href="https://www.respeecher.com/">Respeecher</a></p><p><a href="https://www.linkedin.com/in/rob-stevenson-92603541/">Rob Stevenson on LinkedIn</a></p><p><a href="https://twitter.com/robstertweets">Rob Stevenson on Twitter</a></p><p><a href="http://sama.com">Sama</a></p>
]]></description>
      <pubDate>Thu, 11 Aug 2022 19:20:58 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-in-entertainment-with-fxguide-co-founder-dr-mike-seymour-wy7WFy3w</link>
      <content:encoded><![CDATA[<p> Dr. Seymour aims to take cutting-edge technology and apply it to the special effects industry, such as with the new AI platform, PLATO. He is also a lecturer at the University of Sydney and works as a consultant within the special effects industry. He is an internationally respected researcher and expert in Digital Humans and virtual production, and his experience in both visual effects and pure maths makes him perfect for AI-based visual effects. In our conversation we find out more about Dr. Seymour’s professional career journey, and what he enjoys the most about working as both a researcher and practitioner. We then get into all the details about AI in special effects as we learn about Digital Humans, the new PLATO platform, why AI dubbing is better, the biggest challenges facing the application of AI in special effects.</p><p>Key Points From This Episode:</p><ul><li>Dr. Seymour explains his background and professional career journey. </li><li>Why he enjoys bridging the gap between researcher and practitioner.</li><li>An outline of the different topics that Dr. Seymour lectures in and what he is currently working on.</li><li>He explains what he means by the term ‘digital humans’ and provides examples.</li><li>The special effects platform, PLATO, he is currently working on and what it will be used for.</li><li>An explanation of how PLATO was used in the Polish movie, <i>The Champion</i>.</li><li>He explains the future goals and aims for auto-dubbing using AI and visual effects.</li><li>Why auto-dubbing procedure will not add or encumber existing processes of making a movie. </li><li>Reasons why AI auto-dubbing is better than traditional dubbing.</li><li>Whether this is a natural language processing challenge or more of a creative filmmaking challenge.</li><li>A discussion about why new technologies take long to be applied to real-world scenarios.</li><li>How the underlying process of PLATO are different from what is required to make a deepfake video. </li><li>His approach to overcoming challenges facing the PLATO platform. </li><li>Other areas of the entertainment industry Dr. Seymour expects AI to be disruptive.</li></ul><p>Tweetables:</p><p>“In the film, half the actors are the original actors come back to just re-voice themselves, half aren’t. In the film hopefully, when you watch it, it’s indistinguishable that it wasn’t actually filmed in English. — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:10:15]</p><p>“In our process, it doesn’t apply because if you were saying in four words what I’d said in three, it would just match. We don’t have to match the timing, we don’t have to match the lip movement or jaw movement, it all gets fixed.” — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:15:15]</p><p>“My attitude is, it’s all very well for us to get this working in the lab, but it has to work in the real world.” — <a href="https://twitter.com/mikeseymour?lang=en">@mikeseymour</a> [0:19:56]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/mikesfxguide/">Dr. Mike Seymour on LinkedIn</a></p><p><a href="https://twitter.com/mikeseymour?lang=en">Dr. Mike Seymour on Twitter</a></p><p><a href="https://scholar.google.com.au/citations?user=dk__LG4AAAAJ&hl=en">Dr. Mike Seymour on Google Scholar </a></p><p><a href="https://www.sydney.edu.au/">University of Sydney</a></p><p><a href="https://www.fxguide.com">fxguide</a></p><p><a href="https://www.pauldebevec.com">Dr. Paul Debevec</a></p><p><a href="https://www.pixar.com/">Pixar</a></p><p><a href="https://www.linkedin.com/in/darryl-marks-7807821b5/">Darryl Marks on LinkedIn</a></p><p><a href="https://www.adaptentertainment.com">Adapt Entertainment</a></p><p><a href="https://www.adaptentertainment.com/technology">PLATO Demonstration Link</a></p><p><a href="https://www.imdb.com/title/tt11369540/"><i>The Champion</i></a></p><p><a href="https://www.pinscreen.com/">Pinscreen</a></p><p><a href="https://www.respeecher.com/">Respeecher</a></p><p><a href="https://www.linkedin.com/in/rob-stevenson-92603541/">Rob Stevenson on LinkedIn</a></p><p><a href="https://twitter.com/robstertweets">Rob Stevenson on Twitter</a></p><p><a href="http://sama.com">Sama</a></p>
]]></content:encoded>
      <enclosure length="29920967" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/946dcc5a-7be1-4967-8c19-d2255820f431/audio/4981dcd4-a258-433f-9efc-1720f80dc247/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Neural Rendering with fxguide Co-Founder Dr. Mike Seymour</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:10</itunes:duration>
      <itunes:summary>The movie industry is not immune to the innovations of AI and machine learning, with many different technologies being developed for application in production and film. In particular, is the role of AI in inferring ‘Digital Humans’ for post-movie production processes. In this conversation, we hear all about this amazing new technology from special guest Dr. Mike Seymour, cofounder and contributing editor at fxguide, an Emmy-nominated veteran of the creative industry, writer, and podcaster.</itunes:summary>
      <itunes:subtitle>The movie industry is not immune to the innovations of AI and machine learning, with many different technologies being developed for application in production and film. In particular, is the role of AI in inferring ‘Digital Humans’ for post-movie production processes. In this conversation, we hear all about this amazing new technology from special guest Dr. Mike Seymour, cofounder and contributing editor at fxguide, an Emmy-nominated veteran of the creative industry, writer, and podcaster.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>49</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">096bfb1e-c7e9-43c7-b261-b22ec6ad9588</guid>
      <title>PwC UK&apos;s AI for Good Lead Maria Luciana Axente</title>
      <description><![CDATA[<p> Ethics in AI is considered vital to the healthy development of all AI technologies, but this is easier said than done. In this episode of How AI Happens, we speak to Maria Luciana Axente to help us unpack this essential topic. Maria is a seasoned AI policy expert, public speaker, and executive and has a respected track record of working with companies whose foundation is in technology. She combines her love for technology with her passion for creating positive change to help companies build and deploy responsible AI. Maria works at PwC, where her work focuses on the operationalization of AI, and data across the firm. She also plays a vital role in advising government, regulators, policymakers, civil society, and research institutions on ethically aligned AI public policy. In our conversation, we talk about the importance of building responsible and ethical AI, while leveraging technology to build a better society. We learn why companies need to create a culture of ethics for building AI, what type of values encompasses responsible technology, the role of diversity and inclusion, the challenges that companies face, and whose responsibility it is. We also learn about some basic steps your organization can take and hear about helpful resources available to guide companies and developers through the process.</p><p>Key Points From This Episode:</p><ul><li>Maria’s professional career journey and her involvement in various AI organizations. </li><li>The motivation which drives AI and machine learning professionals in their careers.</li><li>How to create and foster a system that instills people with positivity. </li><li>Examples of companies that have successfully fostered a positive and ethical culture.</li><li>What are good values for building responsible and ethical technology. </li><li>We learn about the values the responsible AI toolkit prescribes.</li><li>Some of the challenges faced when building responsible and ethical technology.</li><li>An outline of the questions a practitioner can ask to ensure operation by the universal ethics.</li><li>She shares some helpful resources concerning ethical guidelines for AI. </li><li>Why diversity and inclusion are essential to building technology. </li><li>Whose responsibility it should be to ensure the ethical and inclusive development of AI.</li><li>We wrap up the episode with a takeaway message that Maria has for listeners. </li></ul><p>Tweetables:</p><p>“How we have proceeded so far, via Silicon Valley, 'move fast and break things.' It has to stop because we are in a time when if we continue in the same way, we're going to generate more negative impacts than positive impacts.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:10:19]</p><p>“You need to build a culture that goes above and beyond technology itself.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:12:05]</p><p>“Values are contextual driven. So, each organization will have their own set of values. When I say organization, I mean both those who build AI and those who use AI.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:16:39]</p><p>“You have to be able to create a culture of a dialogue where every opinion is being listened to, and not just being listened to, but is being considered.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:29:34]</p><p>“AI doesn't have a technical problem. AI has a human problem.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:32:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/mariaaxente/">Maria Luciana Axente on LinkedIn</a></p><p><a href="https://twitter.com/maria_axente?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Maria Luciana Axente on Twitter</a></p><p><a href="https://www.pwc.co.uk/">PwC UK</a></p><p><a href="https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html">PwC responsible AI toolkit</a></p><p><a href="http://sama.com">Sama</a></p>
]]></description>
      <pubDate>Thu, 28 Jul 2022 20:52:10 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/pwc-uks-ai-for-good-lead-maria-luciana-axente-soajtB_2</link>
      <content:encoded><![CDATA[<p> Ethics in AI is considered vital to the healthy development of all AI technologies, but this is easier said than done. In this episode of How AI Happens, we speak to Maria Luciana Axente to help us unpack this essential topic. Maria is a seasoned AI policy expert, public speaker, and executive and has a respected track record of working with companies whose foundation is in technology. She combines her love for technology with her passion for creating positive change to help companies build and deploy responsible AI. Maria works at PwC, where her work focuses on the operationalization of AI, and data across the firm. She also plays a vital role in advising government, regulators, policymakers, civil society, and research institutions on ethically aligned AI public policy. In our conversation, we talk about the importance of building responsible and ethical AI, while leveraging technology to build a better society. We learn why companies need to create a culture of ethics for building AI, what type of values encompasses responsible technology, the role of diversity and inclusion, the challenges that companies face, and whose responsibility it is. We also learn about some basic steps your organization can take and hear about helpful resources available to guide companies and developers through the process.</p><p>Key Points From This Episode:</p><ul><li>Maria’s professional career journey and her involvement in various AI organizations. </li><li>The motivation which drives AI and machine learning professionals in their careers.</li><li>How to create and foster a system that instills people with positivity. </li><li>Examples of companies that have successfully fostered a positive and ethical culture.</li><li>What are good values for building responsible and ethical technology. </li><li>We learn about the values the responsible AI toolkit prescribes.</li><li>Some of the challenges faced when building responsible and ethical technology.</li><li>An outline of the questions a practitioner can ask to ensure operation by the universal ethics.</li><li>She shares some helpful resources concerning ethical guidelines for AI. </li><li>Why diversity and inclusion are essential to building technology. </li><li>Whose responsibility it should be to ensure the ethical and inclusive development of AI.</li><li>We wrap up the episode with a takeaway message that Maria has for listeners. </li></ul><p>Tweetables:</p><p>“How we have proceeded so far, via Silicon Valley, 'move fast and break things.' It has to stop because we are in a time when if we continue in the same way, we're going to generate more negative impacts than positive impacts.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:10:19]</p><p>“You need to build a culture that goes above and beyond technology itself.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:12:05]</p><p>“Values are contextual driven. So, each organization will have their own set of values. When I say organization, I mean both those who build AI and those who use AI.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:16:39]</p><p>“You have to be able to create a culture of a dialogue where every opinion is being listened to, and not just being listened to, but is being considered.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:29:34]</p><p>“AI doesn't have a technical problem. AI has a human problem.” — <a href="https://twitter.com/maria_axente">@maria_axente</a> [0:32:34]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/mariaaxente/">Maria Luciana Axente on LinkedIn</a></p><p><a href="https://twitter.com/maria_axente?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Maria Luciana Axente on Twitter</a></p><p><a href="https://www.pwc.co.uk/">PwC UK</a></p><p><a href="https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html">PwC responsible AI toolkit</a></p><p><a href="http://sama.com">Sama</a></p>
]]></content:encoded>
      <enclosure length="38654276" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/016bcf58-7c97-4ff3-b1cb-45d3c9289e07/audio/1d7563c2-c30a-4a4e-aabf-25dbb45de868/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>PwC UK&apos;s AI for Good Lead Maria Luciana Axente</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:40:15</itunes:duration>
      <itunes:summary> Ethics in AI is considered vital to the healthy development of all AI technologies, but this is easier said than done. In this episode of How AI Happens, we speak to Maria Luciana Axente to help us unpack this essential topic. Maria is a seasoned AI policy expert, public speaker, and executive and has a respected track record of working with companies whose foundation is in technology. She combines her love for technology with her passion for creating positive change to help companies build and deploy responsible AI.</itunes:summary>
      <itunes:subtitle> Ethics in AI is considered vital to the healthy development of all AI technologies, but this is easier said than done. In this episode of How AI Happens, we speak to Maria Luciana Axente to help us unpack this essential topic. Maria is a seasoned AI policy expert, public speaker, and executive and has a respected track record of working with companies whose foundation is in technology. She combines her love for technology with her passion for creating positive change to help companies build and deploy responsible AI.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>48</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">013f69bb-12d6-4b7e-84f4-a8e7094eac0c</guid>
      <title>Building Responsible AI with Mieke de Ketelaere</title>
      <description><![CDATA[<p> The gap between those creating AI systems and those using the systems is growing. After 27 years on the other side of technology, Mieke decided that it was time to do something about the issues that she was seeing in the AI space. Today she is an Adjunct Professor for Sustainable Ethical and Trustworthy AI at Vlerick Business School, and during this episode, Mieke shares her thoughts on how we can go about building responsible AI systems so that the world can experience the full range of benefits of AI.</p><p>Key Points From This Episode:</p><ul><li>An overview of Mieke’s educational and career background.</li><li>Elements of the AI space that have and haven’t changed since Mieke studied robotics AI in 1992.</li><li>What drew Mieke back into the AI space five years ago.</li><li>The importance of understanding the limitations of AI.</li><li>Mieke shares her thoughts on how to build responsible AI systems.</li><li>The challenges of building responsible AI systems.</li><li>Why the European AI Act isn’t able to address the complexities of the AI sector.</li><li>The missing link between the people creating AI systems and the people using them.</li><li>Exploring the issue of deep fakes.</li><li>The role of AI Translators, and an overview of the AI Translator course available in Belgium.</li></ul><p>Tweetables:</p><p>“The compute power had changed, and the volumes of data had changed, but the [AI] principles hadn't changed that much. Only some really important points never made the translation.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:02:03]</p><p>“[AI systems] don't automatically adapt themselves. You need to have your processes in place in order to make sure that the systems adapt to the changing context.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:04:06]</p><p>“AI systems are starting to be included into operational processes in companies, but only from the profit side, not understanding that they might have a negative impact on people especially when they start to make automated decisions.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:04:52]</p><p>“Let's move out of our silos and sit together in a multidisciplinary debate to discuss the systems we're going to create.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:07:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.gmdeketelaere.com/">Mieke de Ketelaere</a></p><p><a href="https://www.gmdeketelaere.com/books" target="_blank">Mieke's Books</a></p><p><a href="https://artificialintelligenceact.eu/">The European AI Act</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 21 Jul 2022 19:00:27 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/building-responsible-ai-with-mieke-de-ketelaere-QSkunO3W</link>
      <content:encoded><![CDATA[<p> The gap between those creating AI systems and those using the systems is growing. After 27 years on the other side of technology, Mieke decided that it was time to do something about the issues that she was seeing in the AI space. Today she is an Adjunct Professor for Sustainable Ethical and Trustworthy AI at Vlerick Business School, and during this episode, Mieke shares her thoughts on how we can go about building responsible AI systems so that the world can experience the full range of benefits of AI.</p><p>Key Points From This Episode:</p><ul><li>An overview of Mieke’s educational and career background.</li><li>Elements of the AI space that have and haven’t changed since Mieke studied robotics AI in 1992.</li><li>What drew Mieke back into the AI space five years ago.</li><li>The importance of understanding the limitations of AI.</li><li>Mieke shares her thoughts on how to build responsible AI systems.</li><li>The challenges of building responsible AI systems.</li><li>Why the European AI Act isn’t able to address the complexities of the AI sector.</li><li>The missing link between the people creating AI systems and the people using them.</li><li>Exploring the issue of deep fakes.</li><li>The role of AI Translators, and an overview of the AI Translator course available in Belgium.</li></ul><p>Tweetables:</p><p>“The compute power had changed, and the volumes of data had changed, but the [AI] principles hadn't changed that much. Only some really important points never made the translation.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:02:03]</p><p>“[AI systems] don't automatically adapt themselves. You need to have your processes in place in order to make sure that the systems adapt to the changing context.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:04:06]</p><p>“AI systems are starting to be included into operational processes in companies, but only from the profit side, not understanding that they might have a negative impact on people especially when they start to make automated decisions.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:04:52]</p><p>“Let's move out of our silos and sit together in a multidisciplinary debate to discuss the systems we're going to create.” — <a href="https://twitter.com/miekedk">@miekedk</a> [0:07:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.gmdeketelaere.com/">Mieke de Ketelaere</a></p><p><a href="https://www.gmdeketelaere.com/books" target="_blank">Mieke's Books</a></p><p><a href="https://artificialintelligenceact.eu/">The European AI Act</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="22198335" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e699b45f-dfb2-4c46-8b0a-8c74e2dfb178/audio/87037ca0-a2a1-4b1b-b75a-da41cc97e66c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Building Responsible AI with Mieke de Ketelaere</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:23:07</itunes:duration>
      <itunes:summary>Mieke is an Adjunct Professor for Sustainable Ethical and Trustworthy AI at Vlerick Business School. During this episode, Mieke shares her thoughts on how we can go about building responsible AI systems so that the world can experience the full range of benefits of AI.</itunes:summary>
      <itunes:subtitle>Mieke is an Adjunct Professor for Sustainable Ethical and Trustworthy AI at Vlerick Business School. During this episode, Mieke shares her thoughts on how we can go about building responsible AI systems so that the world can experience the full range of benefits of AI.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>47</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">c01e8079-23ef-4849-a2da-275f38f64406</guid>
      <title>Allied Digital CDO Utpal Chakraborty</title>
      <description><![CDATA[<p>Today, on How AI Happens, we are joined by the Chief Digital Officer at Allied Digital, Utpal Chakraborty, to talk all things AI at Allied Digital. You’ll hear about Utpal’s AI background, how he defines Allied Digital’s mission, and what Smart Cities are and how the company captures data to achieve them, as well as why AI learning is the right approach for Smart Cities. We also discuss what success looks like to Utpal and the importance of designing something seamless for the end-user. To find out why customer success is Allied Digital’s success, tune in today! </p><p>Key Points From This Episode:</p><ul><li>A brief overview of Utpal’s background and how he ended up in his current role at Allied. </li><li>How Utpal would characterize Allied Digital’s mission. </li><li>The definition of Smart Cities.</li><li>How Allied Digital is able to capture the data needed to make a city a Smart City. </li><li>What made it clear to Utpal that AI machine learning was the right approach for the Smart City services.</li><li>Insight into what success and an end goal looks like for Utpal. </li><li>Why it is everyone’s job to design something that is seamless for the end-user. </li><li>A look at what Utpal thinks has been truly disruptive in the AI space. </li></ul><p>Tweetables:</p><p>“I looked at how we can move this [Smart City] tool ahead and that’s where the AI machine learning came into the picture.” — <a href="https://twitter.com/utpal_bob">@utpal_bob</a> [0:11:11]</p><p>“[Allied Digital] wants to bring that wow factor into each and every service product and solution that we provide to our customers and, in turn, that they provide to the industry.” — <a href="https://twitter.com/utpal_bob">@utpal_bob</a> [0:16:27]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/utpal-chakraborty/">Utpal Chakraborty on LinkedIn</a></p><p><a href="https://twitter.com/utpal_bob">Utpal Chakraborty on Twitter</a></p><p><a href="http://www.allieddigital.net/">Allied Digital Services</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 14 Jul 2022 19:54:42 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/allied-digital-cdo-utpal-chakraborty-9BRL69sx</link>
      <content:encoded><![CDATA[<p>Today, on How AI Happens, we are joined by the Chief Digital Officer at Allied Digital, Utpal Chakraborty, to talk all things AI at Allied Digital. You’ll hear about Utpal’s AI background, how he defines Allied Digital’s mission, and what Smart Cities are and how the company captures data to achieve them, as well as why AI learning is the right approach for Smart Cities. We also discuss what success looks like to Utpal and the importance of designing something seamless for the end-user. To find out why customer success is Allied Digital’s success, tune in today! </p><p>Key Points From This Episode:</p><ul><li>A brief overview of Utpal’s background and how he ended up in his current role at Allied. </li><li>How Utpal would characterize Allied Digital’s mission. </li><li>The definition of Smart Cities.</li><li>How Allied Digital is able to capture the data needed to make a city a Smart City. </li><li>What made it clear to Utpal that AI machine learning was the right approach for the Smart City services.</li><li>Insight into what success and an end goal looks like for Utpal. </li><li>Why it is everyone’s job to design something that is seamless for the end-user. </li><li>A look at what Utpal thinks has been truly disruptive in the AI space. </li></ul><p>Tweetables:</p><p>“I looked at how we can move this [Smart City] tool ahead and that’s where the AI machine learning came into the picture.” — <a href="https://twitter.com/utpal_bob">@utpal_bob</a> [0:11:11]</p><p>“[Allied Digital] wants to bring that wow factor into each and every service product and solution that we provide to our customers and, in turn, that they provide to the industry.” — <a href="https://twitter.com/utpal_bob">@utpal_bob</a> [0:16:27]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/utpal-chakraborty/">Utpal Chakraborty on LinkedIn</a></p><p><a href="https://twitter.com/utpal_bob">Utpal Chakraborty on Twitter</a></p><p><a href="http://www.allieddigital.net/">Allied Digital Services</a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="20103105" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/43cb40fe-4825-4797-99af-4d56ed98297f/audio/64f45cae-b54e-43b4-8482-4a852d22210d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Allied Digital CDO Utpal Chakraborty</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:20:56</itunes:duration>
      <itunes:summary>Today, on How AI Happens, we are joined by the Chief Digital Officer at Allied Digital, Utpal Chakraborty, to talk all things AI at Allied Digital. You’ll hear about Utpal’s AI background, how he defines Allied Digital’s mission, and what Smart Cities are and how the company captures data to achieve them, as well as why AI learning is the right approach for Smart Cities. </itunes:summary>
      <itunes:subtitle>Today, on How AI Happens, we are joined by the Chief Digital Officer at Allied Digital, Utpal Chakraborty, to talk all things AI at Allied Digital. You’ll hear about Utpal’s AI background, how he defines Allied Digital’s mission, and what Smart Cities are and how the company captures data to achieve them, as well as why AI learning is the right approach for Smart Cities. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>46</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">85bc780c-11e2-4d11-b619-7a3326e13631</guid>
      <title>Calibrate Ventures Partners Jason Schoettler, Kevin Dunlap</title>
      <description><![CDATA[<p> In today’s conversation, we learn about Jason and Kevin’s career backgrounds, the potential that the deep technology sector has, what ideas excite them the most, the challenges when investing in AI-based companies, what kind of technology is easily understood by the consumer, what makes a technological innovation successful, and much more. </p><p>Key Points From This Episode:</p><ul><li>Background and professional paths that led Jason and Kevin to their current roles.</li><li>Reasons behind starting Calibrate Ventures and originally entering the sector.</li><li>How the deep-technology sector can solve current problems.</li><li>What kind of new technology and innovation they get most excited about.</li><li>The most essential quality of innovative technology: what people want.</li><li>Rundown of the diverse, experienced, and talented team they work with.</li><li>Jason shares an example of a technological innovation that solved a real-world problem.</li><li>How they differentiate the approach when investing in AI companies.</li><li>What influences the longer sale cycles in the AI technology sector.</li><li>An example of the challenges when integrating AI technology with the business side.</li><li>The benefits that Jason and Kevin’s experience adds to the company.</li><li>Some examples of the kind of technology that translates well to the consumer.</li><li>We find out what their opinion is about automation and augmentation.</li><li>We wrap up the show with some advice from Jason and Kevin for AI entrepreneurs. </li></ul><p>Tweetables:</p><p>“I think for me personally, the cycle-time was very long. You work on projects for a very long time. As an investor, I get to see new ideas and new concepts every day. From an intellectual curiosity standpoint, there couldn’t be a better job.” — Kevin Dunlap [0:05:17]</p><p>“So that lights me up. When I hear somebody talk about a problem that they are looking to solve and how their technology can do it uniquely with some type of competitive or differentiated advantage we think is sustainable.” — Jason Schoettler [0:08:14]</p><p>“The things that really excite us are not, where can we do better than humans but first, where are there not humans work right now where we need humans doing work.” — Jason Schoettler [0:20:44]</p><p>“Anytime that someone is doing a job that is dangerous, that is able to be solved with technology, I think we owe it to ourselves to do that.” — Kevin Dunlap [0:22:39]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jason-schoettler-5a81122/">Jason Schoettler on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/kevindunlap/">Kevin Dunlap on LinkedIn</a></p><p><a href="https://www.calibratevc.com">Calibrate Ventures</a></p><p><a href="https://www.linkedin.com/company/calibrate-ventures/">Calibrate Ventures on LinkedIn</a></p><p><a href="https://graymatter-robotics.com">GrayMatter Robotics</a></p><p><a href="https://www.linkedin.com/company/graymatter-robotics/">GrayMatter Robotics on LinkedIn</a></p>
]]></description>
      <pubDate>Thu, 7 Jul 2022 18:57:58 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/calibrate-ventures-partners-jason-schoettler-kevin-dunlap-V9l4aUPt</link>
      <content:encoded><![CDATA[<p> In today’s conversation, we learn about Jason and Kevin’s career backgrounds, the potential that the deep technology sector has, what ideas excite them the most, the challenges when investing in AI-based companies, what kind of technology is easily understood by the consumer, what makes a technological innovation successful, and much more. </p><p>Key Points From This Episode:</p><ul><li>Background and professional paths that led Jason and Kevin to their current roles.</li><li>Reasons behind starting Calibrate Ventures and originally entering the sector.</li><li>How the deep-technology sector can solve current problems.</li><li>What kind of new technology and innovation they get most excited about.</li><li>The most essential quality of innovative technology: what people want.</li><li>Rundown of the diverse, experienced, and talented team they work with.</li><li>Jason shares an example of a technological innovation that solved a real-world problem.</li><li>How they differentiate the approach when investing in AI companies.</li><li>What influences the longer sale cycles in the AI technology sector.</li><li>An example of the challenges when integrating AI technology with the business side.</li><li>The benefits that Jason and Kevin’s experience adds to the company.</li><li>Some examples of the kind of technology that translates well to the consumer.</li><li>We find out what their opinion is about automation and augmentation.</li><li>We wrap up the show with some advice from Jason and Kevin for AI entrepreneurs. </li></ul><p>Tweetables:</p><p>“I think for me personally, the cycle-time was very long. You work on projects for a very long time. As an investor, I get to see new ideas and new concepts every day. From an intellectual curiosity standpoint, there couldn’t be a better job.” — Kevin Dunlap [0:05:17]</p><p>“So that lights me up. When I hear somebody talk about a problem that they are looking to solve and how their technology can do it uniquely with some type of competitive or differentiated advantage we think is sustainable.” — Jason Schoettler [0:08:14]</p><p>“The things that really excite us are not, where can we do better than humans but first, where are there not humans work right now where we need humans doing work.” — Jason Schoettler [0:20:44]</p><p>“Anytime that someone is doing a job that is dangerous, that is able to be solved with technology, I think we owe it to ourselves to do that.” — Kevin Dunlap [0:22:39]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jason-schoettler-5a81122/">Jason Schoettler on LinkedIn</a></p><p><a href="https://www.linkedin.com/in/kevindunlap/">Kevin Dunlap on LinkedIn</a></p><p><a href="https://www.calibratevc.com">Calibrate Ventures</a></p><p><a href="https://www.linkedin.com/company/calibrate-ventures/">Calibrate Ventures on LinkedIn</a></p><p><a href="https://graymatter-robotics.com">GrayMatter Robotics</a></p><p><a href="https://www.linkedin.com/company/graymatter-robotics/">GrayMatter Robotics on LinkedIn</a></p>
]]></content:encoded>
      <enclosure length="25220180" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/3e37b7db-2e80-4e5f-9618-5117cac8f92d/audio/74e864b9-ee26-4c6b-943c-3eb88305ce5b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Calibrate Ventures Partners Jason Schoettler, Kevin Dunlap</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:16</itunes:duration>
      <itunes:summary>Venture capitalists are investing heavily in technology, but what about deep-technology and AI companies? In today’s show, we speak to Jason Schoettler and Kevin Dunlap, both veterans in the technology sector. They have both worked in a range of areas within technology, such as working on the Mars Rover, with most of their focus on robotics and AI. They then made a career change and integrated their vast technological experience and their passion for innovation to form Calibrate Ventures, a venture capitalist company investing in advanced, emerging technologies that reshape industries and the future.</itunes:summary>
      <itunes:subtitle>Venture capitalists are investing heavily in technology, but what about deep-technology and AI companies? In today’s show, we speak to Jason Schoettler and Kevin Dunlap, both veterans in the technology sector. They have both worked in a range of areas within technology, such as working on the Mars Rover, with most of their focus on robotics and AI. They then made a career change and integrated their vast technological experience and their passion for innovation to form Calibrate Ventures, a venture capitalist company investing in advanced, emerging technologies that reshape industries and the future.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>45</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">d5c417c3-c1fb-4965-8fbc-f7d692b0d825</guid>
      <title>x.AI Founder Dennis Mortensen</title>
      <description><![CDATA[<p>Whether you’re building AI for self-driving cars or for scheduling meetings, it’s all about prediction! In this episode, we’re going to explore the complexity of teaching the human power of prediction to machines.</p><p>Key Points From This Episode:</p><ul><li>Dennis shares an overview of what he has spent his career focusing on.</li><li>How Dennis defines an intelligent agent.</li><li>The role of prediction in the AI space.</li><li>Dennis explains the mission that drove his most recent entrepreneurial venture, x.ai (acquired by Bizzabo).</li><li>Challenges of transferring humans’ capacity for prediction and empathy to machines.</li><li>Some of Dennis’s key learnings from his time working on the technology for x.ai.</li><li>Unrealistic expectations that humans have of machines.</li><li>How we can teach humans to have empathy for machines. </li><li>Dennis’s hope for the next generation in terms of their approach to AI.</li><li>A lesson Dennis learned from his daughter about AI and about human nature.</li><li>What Dennis is most excited about in the AI space.</li></ul><p>Tweetables:</p><p>“The whole umbrella of AI is really just one big prediction engine.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:03:38]</p><p>“Language is not a solved science.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:06:32]</p><p>“The expectation of a machine response is different to that of a human response to the same question.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:11:36]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dennismortensen/">Dennis Mortensen on LinkedIn</a></p><p><a href="https://www.bizzabo.com/">Bizzabo [Formerly x.ai]</a></p>
]]></description>
      <pubDate>Thu, 23 Jun 2022 15:46:04 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/xai-founder-dennis-mortensen-UgwdjZSS</link>
      <content:encoded><![CDATA[<p>Whether you’re building AI for self-driving cars or for scheduling meetings, it’s all about prediction! In this episode, we’re going to explore the complexity of teaching the human power of prediction to machines.</p><p>Key Points From This Episode:</p><ul><li>Dennis shares an overview of what he has spent his career focusing on.</li><li>How Dennis defines an intelligent agent.</li><li>The role of prediction in the AI space.</li><li>Dennis explains the mission that drove his most recent entrepreneurial venture, x.ai (acquired by Bizzabo).</li><li>Challenges of transferring humans’ capacity for prediction and empathy to machines.</li><li>Some of Dennis’s key learnings from his time working on the technology for x.ai.</li><li>Unrealistic expectations that humans have of machines.</li><li>How we can teach humans to have empathy for machines. </li><li>Dennis’s hope for the next generation in terms of their approach to AI.</li><li>A lesson Dennis learned from his daughter about AI and about human nature.</li><li>What Dennis is most excited about in the AI space.</li></ul><p>Tweetables:</p><p>“The whole umbrella of AI is really just one big prediction engine.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:03:38]</p><p>“Language is not a solved science.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:06:32]</p><p>“The expectation of a machine response is different to that of a human response to the same question.” — <a href="https://twitter.com/DennisMortensen?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@DennisMortensen</a> [0:11:36]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dennismortensen/">Dennis Mortensen on LinkedIn</a></p><p><a href="https://www.bizzabo.com/">Bizzabo [Formerly x.ai]</a></p>
]]></content:encoded>
      <enclosure length="35831327" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/3c2ac1fe-5c02-4058-880b-7a64b56bfe1e/audio/26102263-2cbb-428b-8ce6-bfda3ea80d7f/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>x.AI Founder Dennis Mortensen</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:37:19</itunes:duration>
      <itunes:summary>Today’s guest, Dennis Mortensen, is a serial entrepreneur whose most recent venture (x.ai) focuses on teaching machines to schedule meetings. He shares with us what this challenging (and rewarding) journey looked like, and the valuable (and sometimes surprising) lessons he and his team learned. We also discuss giving empathy to machines, expectations, and how we can get more comfortable with imperfect progress.</itunes:summary>
      <itunes:subtitle>Today’s guest, Dennis Mortensen, is a serial entrepreneur whose most recent venture (x.ai) focuses on teaching machines to schedule meetings. He shares with us what this challenging (and rewarding) journey looked like, and the valuable (and sometimes surprising) lessons he and his team learned. We also discuss giving empathy to machines, expectations, and how we can get more comfortable with imperfect progress.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>44</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">aae651e1-bc8c-478d-8df2-ca5702bb65f5</guid>
      <title>Unity SVP of AI Danny Lange: The Industrial Metaverse</title>
      <description><![CDATA[<p>Leading AI companies are adopting simulation, synthetic data and other aspects of the metaverse at an incredibly fast rate, and the opportunities for AI/machine learning practitioners are endless. Tune in today for a fascinating conversation about how the real world and the virtual world can be blended in what Danny refers to as “the real metaverse.”</p><p>Key Points From This Episode:</p><ul><li>The career path that led Danny to his current role as Senior Vice President of AI at Unity.</li><li>Data; the machine learning challenge that Danny has dealt with in many different forms throughout his career. </li><li>An explanation of how Unity uses data to make game recommendations to players. </li><li>How deep learning embedding works.</li><li>What drew Danny to Unity.</li><li>The benefits of using synthetic data.</li><li>How Unity ensures that the synthetic data they create is as unbiased as possible. </li><li>The importance of anchoring your synthetic data to a real-world counterpart.</li><li>Danny’s thoughts on the potential of the Metaverse.</li><li>Examples of the career opportunities that the Metaverse has opened up for AI/machine learning practitioners.</li></ul><p>Tweetables:</p><p>“When you play a game, I don’t need to know your name, your age. I don’t need to know where you live, or how much you earn. All that really matters is that my system needs to learn the way you play and what you are interested in in your gameplay, to make excellent recommendations for other games. That’s what drives the gaming ecosystem.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:03:16]</p><p>“Deep learning embedding is something that is really driving a lot of progress right now in the machine learning AI space.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:06:04]</p><p>“The world is built on uncertainty and we are looking at simulation in an uncertain world, rather than in a Newtonian, deterministic world.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:23:23]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dannylange/">Danny Lange on LinkedIn</a></p><p><a href="https://unity.com/">Unity</a></p>
]]></description>
      <pubDate>Thu, 16 Jun 2022 11:05:29 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/unity-svp-of-ai-danny-lange-the-industrial-metaverse-fuXsl_zD</link>
      <content:encoded><![CDATA[<p>Leading AI companies are adopting simulation, synthetic data and other aspects of the metaverse at an incredibly fast rate, and the opportunities for AI/machine learning practitioners are endless. Tune in today for a fascinating conversation about how the real world and the virtual world can be blended in what Danny refers to as “the real metaverse.”</p><p>Key Points From This Episode:</p><ul><li>The career path that led Danny to his current role as Senior Vice President of AI at Unity.</li><li>Data; the machine learning challenge that Danny has dealt with in many different forms throughout his career. </li><li>An explanation of how Unity uses data to make game recommendations to players. </li><li>How deep learning embedding works.</li><li>What drew Danny to Unity.</li><li>The benefits of using synthetic data.</li><li>How Unity ensures that the synthetic data they create is as unbiased as possible. </li><li>The importance of anchoring your synthetic data to a real-world counterpart.</li><li>Danny’s thoughts on the potential of the Metaverse.</li><li>Examples of the career opportunities that the Metaverse has opened up for AI/machine learning practitioners.</li></ul><p>Tweetables:</p><p>“When you play a game, I don’t need to know your name, your age. I don’t need to know where you live, or how much you earn. All that really matters is that my system needs to learn the way you play and what you are interested in in your gameplay, to make excellent recommendations for other games. That’s what drives the gaming ecosystem.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:03:16]</p><p>“Deep learning embedding is something that is really driving a lot of progress right now in the machine learning AI space.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:06:04]</p><p>“The world is built on uncertainty and we are looking at simulation in an uncertain world, rather than in a Newtonian, deterministic world.” — <a href="https://twitter.com/danny_lange?lang=en">@danny_lange</a> [0:23:23]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/dannylange/">Danny Lange on LinkedIn</a></p><p><a href="https://unity.com/">Unity</a></p>
]]></content:encoded>
      <enclosure length="28194795" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/25a70595-0f69-48e3-9502-99252c9dfa40/audio/ecadc7c8-dd6b-473d-8b4c-dc460dbdfcde/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Unity SVP of AI Danny Lange: The Industrial Metaverse</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:22</itunes:duration>
      <itunes:summary>Danny Lange, the Senior Vice President of AI at Unity, discusses the simulation, synthetic data, and the opportunity of the Industrial Metaverse. </itunes:summary>
      <itunes:subtitle>Danny Lange, the Senior Vice President of AI at Unity, discusses the simulation, synthetic data, and the opportunity of the Industrial Metaverse. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>43</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">bf7e1232-e05f-4994-970d-8f8d3de9bafd</guid>
      <title>CarbonChain Head of Data &amp; Machine Learning Archy De Berker</title>
      <description><![CDATA[<p>In today’s episode, Archy De Berker, Head of Data and Machine learning at CarbonChain, explains how he and his team calculate carbon footprints, some of the challenges that they face in this line of work, the most valuable use of machine learning in their business (and for climate change solutions as a whole), and some important lessons that he has learned throughout his diverse career so far! </p><p>Key Points From This Episode:</p><ul><li>An overview of Archy’s career trajectory, from academic neuroscientist to Head of Data and Machine learning at CarbonChain.</li><li>The foundational mission of CarbonChain.</li><li>Archy explains how machine learning can be applied in the context of energy storage as a climate change solution. </li><li>Industries that CarbonChain focuses on.</li><li>How Archy and his team calculate carbon footprints.</li><li>A key challenge for carbon footprinting.</li><li>Where machine learning provides the most value for CarbonChain.</li><li>The importance of the field of document understanding. </li><li>A story from Archy’s time at Element AI that highlights the value of having technical people working as close to the design and data generation as possible. </li><li>Why Archy chose to move into the product management realm.</li><li>Additional ways that machine learning can help solve climate change issues. </li></ul><p>Tweetables:</p><p>“We build automated carbon footprinting for the world’s most polluting industries. We’re really trying to help people who are buying things from carbon-intense industries figure out where they can get lower carbon versions of the same kind of products.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:02:14]</p><p>“A key challenge for carbon footprinting is that you need to be able to understand somebody’s business in order to tell them what the carbon footprint of their activities is.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:13:01]</p><p>“Probably the most valuable place for machine learning in our business is taking all this heterogeneous customer data from all these different systems and being able to map it onto a very rigid format that we can then retrieve information from our databases for.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:13:24]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/archy-de-berker/">Archy de Berker on LinkedIn</a></p><p><a href="https://www.carbonchain.com/">Carbon Chain</a></p>
]]></description>
      <pubDate>Thu, 9 Jun 2022 18:56:21 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/carbonchain-head-of-data-machine-learning-archy-de-berker-IjAILS0K</link>
      <content:encoded><![CDATA[<p>In today’s episode, Archy De Berker, Head of Data and Machine learning at CarbonChain, explains how he and his team calculate carbon footprints, some of the challenges that they face in this line of work, the most valuable use of machine learning in their business (and for climate change solutions as a whole), and some important lessons that he has learned throughout his diverse career so far! </p><p>Key Points From This Episode:</p><ul><li>An overview of Archy’s career trajectory, from academic neuroscientist to Head of Data and Machine learning at CarbonChain.</li><li>The foundational mission of CarbonChain.</li><li>Archy explains how machine learning can be applied in the context of energy storage as a climate change solution. </li><li>Industries that CarbonChain focuses on.</li><li>How Archy and his team calculate carbon footprints.</li><li>A key challenge for carbon footprinting.</li><li>Where machine learning provides the most value for CarbonChain.</li><li>The importance of the field of document understanding. </li><li>A story from Archy’s time at Element AI that highlights the value of having technical people working as close to the design and data generation as possible. </li><li>Why Archy chose to move into the product management realm.</li><li>Additional ways that machine learning can help solve climate change issues. </li></ul><p>Tweetables:</p><p>“We build automated carbon footprinting for the world’s most polluting industries. We’re really trying to help people who are buying things from carbon-intense industries figure out where they can get lower carbon versions of the same kind of products.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:02:14]</p><p>“A key challenge for carbon footprinting is that you need to be able to understand somebody’s business in order to tell them what the carbon footprint of their activities is.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:13:01]</p><p>“Probably the most valuable place for machine learning in our business is taking all this heterogeneous customer data from all these different systems and being able to map it onto a very rigid format that we can then retrieve information from our databases for.” — <a href="https://twitter.com/archydeb?lang=en">@ArchydeB</a> [0:13:24]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/archy-de-berker/">Archy de Berker on LinkedIn</a></p><p><a href="https://www.carbonchain.com/">Carbon Chain</a></p>
]]></content:encoded>
      <enclosure length="25555801" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/166f6abd-4434-41a9-abf2-868b9647af7e/audio/13d7d898-483d-4549-a045-8f23a7dcc5fb/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>CarbonChain Head of Data &amp; Machine Learning Archy De Berker</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:37</itunes:duration>
      <itunes:summary>Archy de Berker began his journey with machine learning in the context of academic neuroscience, interested in how machine learning can help us understand the brain. Today, he is the Head of Data and Machine learning at CarbonChain, driven by his desire to apply machine learning to climate change solutions.</itunes:summary>
      <itunes:subtitle>Archy de Berker began his journey with machine learning in the context of academic neuroscience, interested in how machine learning can help us understand the brain. Today, he is the Head of Data and Machine learning at CarbonChain, driven by his desire to apply machine learning to climate change solutions.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>42</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">c74cfd8b-490a-465c-94cd-fffa72fa0540</guid>
      <title>Privacy in AI with MATR Ventures Partner Hessie Jones</title>
      <description><![CDATA[<p>MATR Ventures Partner, Hessie Jones, is dedicated to solving issues around AI ethics as well as diversity & representation in the space. In our conversation with her, she breaks down how she came to beleive something was wrong with the way companies harvest & use data, and the steps she has taken towards solving the privacy problem. We discuss the danger of intentionally convoluted terms and conditions and the problem with synthetic data. Tune in to hear about the future of biometrics and data privacy and the emerging technologies using data to increase accountability.</p><p>Key Points From This Episode:</p><ul><li>Hessie Jones’ background: from marketing to her current role at MATR Ventures.</li><li>Hessie’s focus on AI ethics and privacy, and diversity in the venture capital space.</li><li>Her mission to provide equal access to programs and investment.</li><li>What inspired her to tackle the problem of AI ethics and privacy.</li><li>The consequences of Snowden and the responsibility of tech to enforce customer privacy.</li><li>Hessie’s path of seeking the solution to the privacy problem.</li><li>The danger of blanketed terms and conditions.</li><li>The problem with synthetic data.</li><li>Crass uses of facial recognition.</li><li>Emerging technologies using data to increase accountability.</li><li>The future of biometrics and data privacy.</li><li>The mission of MATR Ventures and who they invest in.</li><li>Examples of technologies MATR Ventures employs to ensure accountability.</li></ul><p>Tweetables:</p><p>“Venture capital is not immune to the diversity problems that we see today.” — Hessie Jones [0:05:04]</p><p>“We should separate who you are as an individual from who you are as a business customer.” — Hessie Jones [0:08:49]</p><p>“The problem I see with synthetic data is the rise of deep fakes.” — Hessie Jones [0:21:24]</p><p>“The future is really about data that’s not shared, or if it’s shared, it’s shared in a way that increases accountability.” — Hessie Jones [0:26:43]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/hessiejones1">Hessie Jones on LinkedIn</a></p><p><a href="https://www.matrventures.com/">MATR Ventures</a></p><p><a href="https://www.responsible.ai/">Responsible AI</a></p>
]]></description>
      <pubDate>Fri, 3 Jun 2022 19:11:58 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/privacy-in-ai-with-matr-ventures-partner-hessie-jones-D0HDzZg2</link>
      <content:encoded><![CDATA[<p>MATR Ventures Partner, Hessie Jones, is dedicated to solving issues around AI ethics as well as diversity & representation in the space. In our conversation with her, she breaks down how she came to beleive something was wrong with the way companies harvest & use data, and the steps she has taken towards solving the privacy problem. We discuss the danger of intentionally convoluted terms and conditions and the problem with synthetic data. Tune in to hear about the future of biometrics and data privacy and the emerging technologies using data to increase accountability.</p><p>Key Points From This Episode:</p><ul><li>Hessie Jones’ background: from marketing to her current role at MATR Ventures.</li><li>Hessie’s focus on AI ethics and privacy, and diversity in the venture capital space.</li><li>Her mission to provide equal access to programs and investment.</li><li>What inspired her to tackle the problem of AI ethics and privacy.</li><li>The consequences of Snowden and the responsibility of tech to enforce customer privacy.</li><li>Hessie’s path of seeking the solution to the privacy problem.</li><li>The danger of blanketed terms and conditions.</li><li>The problem with synthetic data.</li><li>Crass uses of facial recognition.</li><li>Emerging technologies using data to increase accountability.</li><li>The future of biometrics and data privacy.</li><li>The mission of MATR Ventures and who they invest in.</li><li>Examples of technologies MATR Ventures employs to ensure accountability.</li></ul><p>Tweetables:</p><p>“Venture capital is not immune to the diversity problems that we see today.” — Hessie Jones [0:05:04]</p><p>“We should separate who you are as an individual from who you are as a business customer.” — Hessie Jones [0:08:49]</p><p>“The problem I see with synthetic data is the rise of deep fakes.” — Hessie Jones [0:21:24]</p><p>“The future is really about data that’s not shared, or if it’s shared, it’s shared in a way that increases accountability.” — Hessie Jones [0:26:43]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/hessiejones1">Hessie Jones on LinkedIn</a></p><p><a href="https://www.matrventures.com/">MATR Ventures</a></p><p><a href="https://www.responsible.ai/">Responsible AI</a></p>
]]></content:encoded>
      <enclosure length="32493505" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/ef3d560c-56f1-4c52-8eec-a4c3a1b9e44c/audio/7d16dd91-109e-4224-bdf7-bacd84660471/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Privacy in AI with MATR Ventures Partner Hessie Jones</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:50</itunes:duration>
      <itunes:summary>The question of AI ethics and privacy is becoming more relevant by the millisecond. Joining us today to discuss the complexity, evolution, and the future of privacy in the AI space, is Venture Partner of MATR Ventures, Hessie Jones.</itunes:summary>
      <itunes:subtitle>The question of AI ethics and privacy is becoming more relevant by the millisecond. Joining us today to discuss the complexity, evolution, and the future of privacy in the AI space, is Venture Partner of MATR Ventures, Hessie Jones.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>41</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">3179319b-7ef1-4eae-890e-62f0b157eb58</guid>
      <title>Qualcomm Head of AI &amp; ML Product Management Dr. Vinesh Sukumar</title>
      <description><![CDATA[<p>During Vinesh Sukumar’s colorful career he has worked at NASA, Apple, Intel, and a variety of other companies, before finding his way to Qualcomm where he is currently the Head of AI/ML Product Management. In today’s conversation, Vinesh shares his experience of developing the camera for the very first iPhone and one of the biggest lessons he learned from working with Steve Jobs. We then discuss what his current role entails and the biggest challenge that he has with it, Qualcomm’s approach to sustainability from a hardware, systems and software standpoint, and his thoughts on why edge computing is so important.</p><p>Key Points From This Episode:</p><ul><li>An overview of Vinesh’s career trajectory, including his experiences at NASA, Apple, and Intel.</li><li>The focal area of Vinesh’s PhD.  </li><li>Challenges that Vinesh faced while working on cutting edge technology for camera phones.</li><li>Some of the early AI applications that were used in smartphone cameras. </li><li>The most important factors to consider when developing cameras for phones.</li><li>Valuable lessons that Vinesh learned from working with Steve Jobs.</li><li>What Vinesh’s role as Head of AI/ML Product Management at Qualcomm consists of.</li><li>Why optimization is one of the biggest technical challenges that Vinesh faces in his role at Qualcomm. </li><li>The four buckets of MLOps. </li><li>Vinesh explains why edge computing is so important. </li><li>Benefits of building intelligence into devices rather than requiring a connection to the cloud.</li><li>Qualcomm’s approach to scalability. </li><li>Why Vinesh is excited about cognitive AI.</li></ul><p>Tweetables:</p><p>“Camera became one of the most important features for a consumer to buy a phone. Then visual analytics, AI, deep learning, ML really started seeping into images, and then into videos, and now the most important consumer influencing factor to buy a phone is the camera.” — Vinesh Sukumar [0:07:01]</p><p>“Reaction time is much better when you have intelligence on the device, rather than giving it to the cloud to make the decision for you.” — Vinesh Sukumar [0:20:48]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/vineshsukumar/">Vinesh Sukumar on LinkedIn</a></p><p><a href="https://www.qualcomm.com/">Qualcomm</a></p>
]]></description>
      <pubDate>Thu, 26 May 2022 22:46:22 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/qualcomm-head-of-ai-ml-product-management-dr-vinesh-sukumar-KJ50I4Pj</link>
      <content:encoded><![CDATA[<p>During Vinesh Sukumar’s colorful career he has worked at NASA, Apple, Intel, and a variety of other companies, before finding his way to Qualcomm where he is currently the Head of AI/ML Product Management. In today’s conversation, Vinesh shares his experience of developing the camera for the very first iPhone and one of the biggest lessons he learned from working with Steve Jobs. We then discuss what his current role entails and the biggest challenge that he has with it, Qualcomm’s approach to sustainability from a hardware, systems and software standpoint, and his thoughts on why edge computing is so important.</p><p>Key Points From This Episode:</p><ul><li>An overview of Vinesh’s career trajectory, including his experiences at NASA, Apple, and Intel.</li><li>The focal area of Vinesh’s PhD.  </li><li>Challenges that Vinesh faced while working on cutting edge technology for camera phones.</li><li>Some of the early AI applications that were used in smartphone cameras. </li><li>The most important factors to consider when developing cameras for phones.</li><li>Valuable lessons that Vinesh learned from working with Steve Jobs.</li><li>What Vinesh’s role as Head of AI/ML Product Management at Qualcomm consists of.</li><li>Why optimization is one of the biggest technical challenges that Vinesh faces in his role at Qualcomm. </li><li>The four buckets of MLOps. </li><li>Vinesh explains why edge computing is so important. </li><li>Benefits of building intelligence into devices rather than requiring a connection to the cloud.</li><li>Qualcomm’s approach to scalability. </li><li>Why Vinesh is excited about cognitive AI.</li></ul><p>Tweetables:</p><p>“Camera became one of the most important features for a consumer to buy a phone. Then visual analytics, AI, deep learning, ML really started seeping into images, and then into videos, and now the most important consumer influencing factor to buy a phone is the camera.” — Vinesh Sukumar [0:07:01]</p><p>“Reaction time is much better when you have intelligence on the device, rather than giving it to the cloud to make the decision for you.” — Vinesh Sukumar [0:20:48]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/vineshsukumar/">Vinesh Sukumar on LinkedIn</a></p><p><a href="https://www.qualcomm.com/">Qualcomm</a></p>
]]></content:encoded>
      <enclosure length="26376673" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/53031d7c-435f-4773-a79f-a7a52568f8ba/audio/24e51a48-c9c4-4bbd-bae9-541d4aa56af0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Qualcomm Head of AI &amp; ML Product Management Dr. Vinesh Sukumar</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:28</itunes:duration>
      <itunes:summary>During Vinesh Sukumar’s colorful career he has worked at NASA, Apple, Intel, and a variety of other companies, before finding his way to Qualcomm where he is currently the Head of AI/ML Product Management. In today’s conversation, Vinesh shares his experience of developing the camera for the very first iPhone and one of the biggest lessons he learned from working with Steve Jobs. We then discuss what his current role entails and the biggest challenge that he has with it, Qualcomm’s approach to sustainability from a hardware, systems and software standpoint, and his thoughts on why edge computing is so important.</itunes:summary>
      <itunes:subtitle>During Vinesh Sukumar’s colorful career he has worked at NASA, Apple, Intel, and a variety of other companies, before finding his way to Qualcomm where he is currently the Head of AI/ML Product Management. In today’s conversation, Vinesh shares his experience of developing the camera for the very first iPhone and one of the biggest lessons he learned from working with Steve Jobs. We then discuss what his current role entails and the biggest challenge that he has with it, Qualcomm’s approach to sustainability from a hardware, systems and software standpoint, and his thoughts on why edge computing is so important.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>40</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">28188584-d9fd-4064-b0ae-4a2a070d486c</guid>
      <title>AI in the Metaverse with Dr. Mark Rijmenam</title>
      <description><![CDATA[<p>Joining us on this episode of How AI Happens is four-time author, entrepreneur, future tech strategist, and The Digital Speaker himself, Dr. Mark van Rijmenam. Mark explainsthe extraordinary opportunities and challenges facing business leaders, consumers, regulators, policymakers, and other metaverse stakeholders trying to navigate the future of the internet; the important role that AI will play in the metaverse; why he believes we need to enable what he calls ‘anonymous accountability’; and how you can actively participate in building ethical AI. </p><p>Key Points From This Episode:</p><ul><li>Meet Dr. Mark van Rijmenam and gain some insight into his trajectory thus far.</li><li>The role that AI and the blockchain played in Mark’s book, <i>The Organisation of Tomorrow</i>.</li><li>What we can learn about feedback loops from the failures of Microsoft’s Tay chatbot.</li><li>At what point technology shifts from a tool employed by practitioners to autonomous agent.</li><li>Distinguishing between artificial general intelligence (AGI) and Super AI.</li><li>Mark responds to those who believe we will never reach Super AI; it’s inevitable!</li><li>The advent of the metaverse and why Mark believes it will unlock a trillion-dollar social economy, as per his book, <i>Step Into the Metaverse</i>.</li><li>How Web 3.0 will allow us to reclaim control of our data, digital assets, and identity; moving from value extraction to value creation.</li><li>Understanding the difference between the metaverse and Web 3.0 without conflating the two.</li><li>How Mark sees AI participating in the metaverse and the role it will play in this ‘new world’.</li><li>The dangers that come with the uncanny ‘deep fakes’ of the future.</li><li>Our responsibility to properly verify the digital information we consume and how AI can help.</li><li>What Mark means when he says we need to enable ‘anonymous accountability’.</li><li>How to take advantage of the career opportunities of Web 3.0 and the metaverse and how you can contribute to building ethical AI.</li></ul><p>Tweetables:</p><p>“The social and the material [systems are] very good but, for the organizations of tomorrow, we need to add a third actor, which is the artificial.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:03:05]</p><p>“Once we reach AGI, that will be a fundamental shift because, once we have AGI—which is as intelligent as a human being, but at an exponential speed—everything will change.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:08:34]</p><p>“How can we create a metaverse that doesn’t continue on the path of the internet of today? We have this blank canvas where we can construct this immersive internet in ways where we do own our data, [digital assets, identity, and reputation] using a self-sovereign approach.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:15:09]</p><p>“Technology is neutral. My objective is to help people move to the positive side of technology.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:29:24]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://au.linkedin.com/in/markvanrijmenam">Dr. Mark van Rijmenam on LinkedIn</a></p><p><a href="https://twitter.com/VanRijmenam">Dr. Mark van Rijmenam on Twitter</a></p><p><a href="https://www.thedigitalspeaker.com/">The Digital Speaker</a></p><p><a href="https://datafloq.com/">Datafloq</a></p><p><a href="https://betweentwobots.com/">Between Two Bots Podcast</a></p><p><a href="https://amzn.to/2ZtC9S3"><i>Step Into the Metaverse</i></a></p><p><a href="https://amzn.to/31mL436"><i>The Organisation of Tomorrow</i></a></p><p><a href="https://youtu.be/WU0gvPcc3jQ">‘The Matrix Awakens: An Unreal Engine 5 Experience’</a></p>
]]></description>
      <pubDate>Thu, 19 May 2022 22:28:22 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-in-the-metaverse-with-dr-mark-rijmenam-1moRsSqZ</link>
      <content:encoded><![CDATA[<p>Joining us on this episode of How AI Happens is four-time author, entrepreneur, future tech strategist, and The Digital Speaker himself, Dr. Mark van Rijmenam. Mark explainsthe extraordinary opportunities and challenges facing business leaders, consumers, regulators, policymakers, and other metaverse stakeholders trying to navigate the future of the internet; the important role that AI will play in the metaverse; why he believes we need to enable what he calls ‘anonymous accountability’; and how you can actively participate in building ethical AI. </p><p>Key Points From This Episode:</p><ul><li>Meet Dr. Mark van Rijmenam and gain some insight into his trajectory thus far.</li><li>The role that AI and the blockchain played in Mark’s book, <i>The Organisation of Tomorrow</i>.</li><li>What we can learn about feedback loops from the failures of Microsoft’s Tay chatbot.</li><li>At what point technology shifts from a tool employed by practitioners to autonomous agent.</li><li>Distinguishing between artificial general intelligence (AGI) and Super AI.</li><li>Mark responds to those who believe we will never reach Super AI; it’s inevitable!</li><li>The advent of the metaverse and why Mark believes it will unlock a trillion-dollar social economy, as per his book, <i>Step Into the Metaverse</i>.</li><li>How Web 3.0 will allow us to reclaim control of our data, digital assets, and identity; moving from value extraction to value creation.</li><li>Understanding the difference between the metaverse and Web 3.0 without conflating the two.</li><li>How Mark sees AI participating in the metaverse and the role it will play in this ‘new world’.</li><li>The dangers that come with the uncanny ‘deep fakes’ of the future.</li><li>Our responsibility to properly verify the digital information we consume and how AI can help.</li><li>What Mark means when he says we need to enable ‘anonymous accountability’.</li><li>How to take advantage of the career opportunities of Web 3.0 and the metaverse and how you can contribute to building ethical AI.</li></ul><p>Tweetables:</p><p>“The social and the material [systems are] very good but, for the organizations of tomorrow, we need to add a third actor, which is the artificial.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:03:05]</p><p>“Once we reach AGI, that will be a fundamental shift because, once we have AGI—which is as intelligent as a human being, but at an exponential speed—everything will change.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:08:34]</p><p>“How can we create a metaverse that doesn’t continue on the path of the internet of today? We have this blank canvas where we can construct this immersive internet in ways where we do own our data, [digital assets, identity, and reputation] using a self-sovereign approach.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:15:09]</p><p>“Technology is neutral. My objective is to help people move to the positive side of technology.” — <a href="https://twitter.com/VanRijmenam">@VanRijmenam</a> [0:29:24]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://au.linkedin.com/in/markvanrijmenam">Dr. Mark van Rijmenam on LinkedIn</a></p><p><a href="https://twitter.com/VanRijmenam">Dr. Mark van Rijmenam on Twitter</a></p><p><a href="https://www.thedigitalspeaker.com/">The Digital Speaker</a></p><p><a href="https://datafloq.com/">Datafloq</a></p><p><a href="https://betweentwobots.com/">Between Two Bots Podcast</a></p><p><a href="https://amzn.to/2ZtC9S3"><i>Step Into the Metaverse</i></a></p><p><a href="https://amzn.to/31mL436"><i>The Organisation of Tomorrow</i></a></p><p><a href="https://youtu.be/WU0gvPcc3jQ">‘The Matrix Awakens: An Unreal Engine 5 Experience’</a></p>
]]></content:encoded>
      <enclosure length="34483409" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/2217f76a-5ea5-499f-b883-9257a2df8f78/audio/339a7dd8-c954-4f2a-b2e4-4c279e49f3a9/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI in the Metaverse with Dr. Mark Rijmenam</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:35:55</itunes:duration>
      <itunes:summary>Big data analytics, blockchain technologies, and artificial intelligence force us to rethink existing business models and develop the organizations of tomorrow. Joining us on this episode of How AI Happens is four-time author, entrepreneur, future tech strategist, and The Digital Speaker himself, Dr. Mark van Rijmenam. As an expert on disruptive innovation like big data, blockchain, AI, and VR/AR, Mark explains how these emerging technologies can benefit organizations and how we can use them to develop products and services that are ready for the twenty-first century.</itunes:summary>
      <itunes:subtitle>Big data analytics, blockchain technologies, and artificial intelligence force us to rethink existing business models and develop the organizations of tomorrow. Joining us on this episode of How AI Happens is four-time author, entrepreneur, future tech strategist, and The Digital Speaker himself, Dr. Mark van Rijmenam. As an expert on disruptive innovation like big data, blockchain, AI, and VR/AR, Mark explains how these emerging technologies can benefit organizations and how we can use them to develop products and services that are ready for the twenty-first century.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>39</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">bc5b59f5-f5ca-49d1-a230-2b77e09440b9</guid>
      <title>IBM Master Inventor &amp; AI Advisor to the UN Neil Sahota</title>
      <description><![CDATA[<p>Neil Sahota is an AI Advisor to the UN, co-founder of the UN’s AI for Good initiative, IBM Master Inventor, and author of Own the AI Revolution.<i> </i>In today’s episode, Neil shares some of the valuable lessons he learned during his first experience working in the AI world, which involved training the Watson computer system. We then dive into a number of different topics, ranging from Neil’s thoughts on synthetic data and to the language learning capacity of AI versus a human child, to an overview of the AI for Good initiative and what Neil believes our a “cyborg future” could entail! </p><p>Key Points From This Episode:</p><ul><li>A few of the thousands of data points that humans use to make rapid judgments.</li><li>Neil’s introduction into the world of AI.</li><li>How data collection changed AI, using the Watson computer system as an example. </li><li>Lessons that Neil learned through training Watson.</li><li>The relative importance of confidence levels with regard to training AI in different fields.</li><li>Why reaching a 99.9% confidence level is not realistic.</li><li>Examples of cases where synthetic data is and isn’t helpful.</li><li>A major difference between the language learning trajectory of AI versus a human child.</li><li>Areas that Neil believes AI is best suited for.</li><li>Focus of the United Nations’ AI for Good initiative.</li><li>The UN’s approach to bringing AI technologies to remote parts of the world.</li><li>Benefits of being exposed to technology at a young age.</li><li>The cyborg future: what Neil believes this is going to look like.</li><li>Why Neil is excited about AI augmentation for human creativity. </li></ul><p>Tweetables:</p><p>“We, as human beings, have to make really rapid judgement calls, especially in sports, but there’s still thousands of data points in play and the best of us can only see seven to 12 in real time.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:01:21]</p><p>“Synthetic data can be a good bridge if we’re in a very closed ecosystem.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:11:47]</p><p>“For an AI system, if it gets exposed to about 100 billion words it becomes proficient and fluent in a language. If you think about a human child, it only needs about 30 billion words. So, it’s not the volume that matters, there’s certain words or phrases that trigger the cognitive learning for language. The problem is that we just don’t understand what that is.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:14:22]</p><p>“Things that are more hard science, or things that have the least amount of variability, are the best things for AI systems.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:16:26]</p><p>“Local problems have global solutions.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:20:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.neilsahota.com/">Neil Sahota</a></p><p><a href="https://www.linkedin.com/in/neilsahota/">Neil Sahota on LinkedIn</a></p><p><a href="https://www.amazon.com/Own-I-Revolution-Intelligence-Competition/dp/1260458377"><i>Own the A.I. Revolution</i></a></p><p><a href="https://aiforgood.itu.int/%23:~:text=More%2520than%2520a%2520Summit,%2520more,United%2520Nations%2520Sustainable%2520Development%2520Goals.">AI for Good</a></p>
]]></description>
      <pubDate>Thu, 12 May 2022 20:34:03 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ibm-master-inventor-ai-advisor-to-the-un-neil-sahota-wVfaJQvx</link>
      <content:encoded><![CDATA[<p>Neil Sahota is an AI Advisor to the UN, co-founder of the UN’s AI for Good initiative, IBM Master Inventor, and author of Own the AI Revolution.<i> </i>In today’s episode, Neil shares some of the valuable lessons he learned during his first experience working in the AI world, which involved training the Watson computer system. We then dive into a number of different topics, ranging from Neil’s thoughts on synthetic data and to the language learning capacity of AI versus a human child, to an overview of the AI for Good initiative and what Neil believes our a “cyborg future” could entail! </p><p>Key Points From This Episode:</p><ul><li>A few of the thousands of data points that humans use to make rapid judgments.</li><li>Neil’s introduction into the world of AI.</li><li>How data collection changed AI, using the Watson computer system as an example. </li><li>Lessons that Neil learned through training Watson.</li><li>The relative importance of confidence levels with regard to training AI in different fields.</li><li>Why reaching a 99.9% confidence level is not realistic.</li><li>Examples of cases where synthetic data is and isn’t helpful.</li><li>A major difference between the language learning trajectory of AI versus a human child.</li><li>Areas that Neil believes AI is best suited for.</li><li>Focus of the United Nations’ AI for Good initiative.</li><li>The UN’s approach to bringing AI technologies to remote parts of the world.</li><li>Benefits of being exposed to technology at a young age.</li><li>The cyborg future: what Neil believes this is going to look like.</li><li>Why Neil is excited about AI augmentation for human creativity. </li></ul><p>Tweetables:</p><p>“We, as human beings, have to make really rapid judgement calls, especially in sports, but there’s still thousands of data points in play and the best of us can only see seven to 12 in real time.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:01:21]</p><p>“Synthetic data can be a good bridge if we’re in a very closed ecosystem.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:11:47]</p><p>“For an AI system, if it gets exposed to about 100 billion words it becomes proficient and fluent in a language. If you think about a human child, it only needs about 30 billion words. So, it’s not the volume that matters, there’s certain words or phrases that trigger the cognitive learning for language. The problem is that we just don’t understand what that is.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:14:22]</p><p>“Things that are more hard science, or things that have the least amount of variability, are the best things for AI systems.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:16:26]</p><p>“Local problems have global solutions.” — <a href="https://twitter.com/neil_sahota?ref_src=twsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor">@neil_sahota</a> [0:20:06]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.neilsahota.com/">Neil Sahota</a></p><p><a href="https://www.linkedin.com/in/neilsahota/">Neil Sahota on LinkedIn</a></p><p><a href="https://www.amazon.com/Own-I-Revolution-Intelligence-Competition/dp/1260458377"><i>Own the A.I. Revolution</i></a></p><p><a href="https://aiforgood.itu.int/%23:~:text=More%2520than%2520a%2520Summit,%2520more,United%2520Nations%2520Sustainable%2520Development%2520Goals.">AI for Good</a></p>
]]></content:encoded>
      <enclosure length="29937685" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/39601649-7eff-4fd0-95bc-9725e8962277/audio/a64863ed-0132-4bb9-88f8-7d3a58bd27a0/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>IBM Master Inventor &amp; AI Advisor to the UN Neil Sahota</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:11</itunes:duration>
      <itunes:summary>Today’s guest is not afraid of a challenge. In fact, throughout his life, he has always sought to solve big issues through disruptive and innovative technologies. Neil Sahota is an AI Advisor to the UN, co-founder of the UN’s AI for Good initiative, IBM Master Inventor, and author of Own the AI Revolution.</itunes:summary>
      <itunes:subtitle>Today’s guest is not afraid of a challenge. In fact, throughout his life, he has always sought to solve big issues through disruptive and innovative technologies. Neil Sahota is an AI Advisor to the UN, co-founder of the UN’s AI for Good initiative, IBM Master Inventor, and author of Own the AI Revolution.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>38</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">50f92b40-7334-4116-9a53-ddf6707afd8d</guid>
      <title>Prospitalia Group CEO Dr. Marcell Vollmer</title>
      <description><![CDATA[Dr. Marcell Vollmer is the CEO of Prospitalia Group, formerly Chief Innovation Officer at Celonis and Chief Digital Officer at SAP. He joins to discuss Machine Learning advances in MedTech and how practitioners can be thoughtful about when it is appropriate to deploy ML.
]]></description>
      <pubDate>Thu, 5 May 2022 20:25:02 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/prospitalia-group-ceo-dr-marcell-vollmer-L5MUnxCz</link>
      <enclosure length="21197740" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8bd77c79-eadb-49ee-bd27-d2cd4b010baf/audio/fea349a3-009c-4a66-9a7e-efd42d202a45/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Prospitalia Group CEO Dr. Marcell Vollmer</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:22:04</itunes:duration>
      <itunes:summary>Dr. Marcell Vollmer is the CEO of Prospitalia Group, formerly Chief Innovation Officer at Celonis and Chief Digital Officer at SAP. He joins to discuss Machine Learning advances in MedTech and how practitioners can be thoughtful about when it is appropriate to deploy ML.</itunes:summary>
      <itunes:subtitle>Dr. Marcell Vollmer is the CEO of Prospitalia Group, formerly Chief Innovation Officer at Celonis and Chief Digital Officer at SAP. He joins to discuss Machine Learning advances in MedTech and how practitioners can be thoughtful about when it is appropriate to deploy ML.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>37</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">b2758abf-fd4f-4adb-9873-7e79de45c9e7</guid>
      <title>AI Safety Engineering - Dr. Roman Yampolskiy</title>
      <description><![CDATA[<p> Today’s guest has committed many years of his life to trying to understand Artificial Superintelligence and the security concerns associated with it.  Dr. Roman Yampolskiy is a computer scientist (with a Ph.D. in behavioral biometrics), and an Associate Professor at the University of Louisville. He is also the author of the book <i>Artificial Superintelligence: A Futuristic Approach</i>. Today he joins us to discuss AI safety engineering. You’ll hear about some of the safety problems  he has discovered in his 10 years of research, his thoughts on accountability and ownership when AI fails, and whether he believes it’s possible to enact any real safety measures in light of the decentralization and commoditization of processing power. You’ll discover some of the near-term risks of not prioritizing safety engineering in AI, how to make sure you’re developing it in a safe capacity, and what organizations are deploying it in a way that Dr. Yampolskiy believes to be above board. </p><p>Key Points From This Episode:</p><ul><li>An introduction to Dr. Roman Yampolskiy, his education, and how he ended up in his current role. </li><li>Insight into Dr. Yampolskiy’s Ph.D. dissertation in behavioral biometrics and what he learned from it. </li><li>A definition of AI safety engineering.</li><li>The two subcomponents of AI safety: systems we already have and future AI.</li><li>Thoughts on whether or not there is a greater need for guardrails in AI than other forms of technology.</li><li>Some of the safety problems that Dr. Yampolskiy has discovered in his 10 years of research.</li><li>Dr. Yampolskiy’s thoughts on the need for some type of AI security governing body or oversight board.</li><li>Whether it’s possible to enact any sort of safety in light of the decentralization and commoditization of processing power.</li><li>Solvable problem areas. </li><li>Trying to negotiate the tradeoff between enabling AI to have creative freedom and being able to control it.</li><li>Thoughts on whether or not there will be a time where we will have to decide whether or not to go past the point of no return in terms of AI superintelligence.</li><li>Some of the near-term risks of not prioritizing safety engineering in AI.</li><li>What led Dr. Yampolskiy to focus on this area of AI expertise.</li><li>How to make sure you’re developing AI safely.</li><li>Thoughts on accountability and ownership when AI fails, and the legal implications of this.</li><li>Other problems Dr. Yampolskiy has uncovered. </li><li>Thoughts on the need for a greater understanding of the implications of AI work and whether or not this is a conceivable solution.</li><li>Use cases or organizations that are deploying AI in a way that Dr. Yampolskiy believes to be above board.</li><li>Questions that Dr. Yampolskiy would be asking if he was on an AI development safety team.</li><li>How you can measure progress in safety work. </li></ul><p>Tweetables:</p><p>“Long term, we want to make sure that we don’t create something which is more capable than us and completely out of control.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:04:27]</p><p>“This is the tradeoff we’re facing: Either [AI] is going to be very capable, independent, and creative, or we can control it.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:12:11]</p><p>“Maybe there are problems that we really need Superintelligence [to solve]. In that case, we have to give it more creative freedom but with that comes the danger of it making decisions that we will not like.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:12:31]</p><p>“The more capable the system is, the more it is deployed, the more damage it can cause.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:14:55]</p><p>“It seems like it’s the most important problem, it’s the meta-solution to all the other problems. If you can make friendly well-controlled superintelligence, everything else is trivial. It will solve it for you.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:15:26]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/romanyam/">Dr. Roman Yampolskiy</a></p><p><a href="https://www.amazon.com/Artificial-Superintelligence-Futuristic-Roman-Yampolskiy/dp/1482234432"><i>Artificial Superintelligence: A Futuristic Approach</i></a></p><p><a href="https://twitter.com/romanyam">Dr. Roman Yampolskiy on Twitter</a></p>
]]></description>
      <pubDate>Thu, 28 Apr 2022 17:26:38 +0000</pubDate>
      <author>eschwartze@samasource.org (Roman Yampolskiy)</author>
      <link>https://howaihappens.com/episodes/ai-safety-engineering-dr-roman-yampolskiy-WUn3Dt_L</link>
      <content:encoded><![CDATA[<p> Today’s guest has committed many years of his life to trying to understand Artificial Superintelligence and the security concerns associated with it.  Dr. Roman Yampolskiy is a computer scientist (with a Ph.D. in behavioral biometrics), and an Associate Professor at the University of Louisville. He is also the author of the book <i>Artificial Superintelligence: A Futuristic Approach</i>. Today he joins us to discuss AI safety engineering. You’ll hear about some of the safety problems  he has discovered in his 10 years of research, his thoughts on accountability and ownership when AI fails, and whether he believes it’s possible to enact any real safety measures in light of the decentralization and commoditization of processing power. You’ll discover some of the near-term risks of not prioritizing safety engineering in AI, how to make sure you’re developing it in a safe capacity, and what organizations are deploying it in a way that Dr. Yampolskiy believes to be above board. </p><p>Key Points From This Episode:</p><ul><li>An introduction to Dr. Roman Yampolskiy, his education, and how he ended up in his current role. </li><li>Insight into Dr. Yampolskiy’s Ph.D. dissertation in behavioral biometrics and what he learned from it. </li><li>A definition of AI safety engineering.</li><li>The two subcomponents of AI safety: systems we already have and future AI.</li><li>Thoughts on whether or not there is a greater need for guardrails in AI than other forms of technology.</li><li>Some of the safety problems that Dr. Yampolskiy has discovered in his 10 years of research.</li><li>Dr. Yampolskiy’s thoughts on the need for some type of AI security governing body or oversight board.</li><li>Whether it’s possible to enact any sort of safety in light of the decentralization and commoditization of processing power.</li><li>Solvable problem areas. </li><li>Trying to negotiate the tradeoff between enabling AI to have creative freedom and being able to control it.</li><li>Thoughts on whether or not there will be a time where we will have to decide whether or not to go past the point of no return in terms of AI superintelligence.</li><li>Some of the near-term risks of not prioritizing safety engineering in AI.</li><li>What led Dr. Yampolskiy to focus on this area of AI expertise.</li><li>How to make sure you’re developing AI safely.</li><li>Thoughts on accountability and ownership when AI fails, and the legal implications of this.</li><li>Other problems Dr. Yampolskiy has uncovered. </li><li>Thoughts on the need for a greater understanding of the implications of AI work and whether or not this is a conceivable solution.</li><li>Use cases or organizations that are deploying AI in a way that Dr. Yampolskiy believes to be above board.</li><li>Questions that Dr. Yampolskiy would be asking if he was on an AI development safety team.</li><li>How you can measure progress in safety work. </li></ul><p>Tweetables:</p><p>“Long term, we want to make sure that we don’t create something which is more capable than us and completely out of control.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:04:27]</p><p>“This is the tradeoff we’re facing: Either [AI] is going to be very capable, independent, and creative, or we can control it.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:12:11]</p><p>“Maybe there are problems that we really need Superintelligence [to solve]. In that case, we have to give it more creative freedom but with that comes the danger of it making decisions that we will not like.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:12:31]</p><p>“The more capable the system is, the more it is deployed, the more damage it can cause.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:14:55]</p><p>“It seems like it’s the most important problem, it’s the meta-solution to all the other problems. If you can make friendly well-controlled superintelligence, everything else is trivial. It will solve it for you.” — <a href="https://twitter.com/romanyam">@romanyam</a> [0:15:26]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/romanyam/">Dr. Roman Yampolskiy</a></p><p><a href="https://www.amazon.com/Artificial-Superintelligence-Futuristic-Roman-Yampolskiy/dp/1482234432"><i>Artificial Superintelligence: A Futuristic Approach</i></a></p><p><a href="https://twitter.com/romanyam">Dr. Roman Yampolskiy on Twitter</a></p>
]]></content:encoded>
      <enclosure length="24219585" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e4b96eae-ee09-4c00-b4a3-b4089a3871a4/audio/8979168e-2ebf-482b-a660-a9e0b504edd8/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI Safety Engineering - Dr. Roman Yampolskiy</itunes:title>
      <itunes:author>Roman Yampolskiy</itunes:author>
      <itunes:duration>00:25:13</itunes:duration>
      <itunes:summary> Today’s guest has committed many years of his life to trying to understand Artificial Superintelligence and the security concerns associated with it.  Dr. Roman Yampolskiy is a computer scientist (with a Ph.D. in behavioral biometrics), and an Associate Professor at the University of Louisville. He is also the author of the book Artificial Superintelligence: A Futuristic Approach. Today he joins us to discuss AI safety engineering.</itunes:summary>
      <itunes:subtitle> Today’s guest has committed many years of his life to trying to understand Artificial Superintelligence and the security concerns associated with it.  Dr. Roman Yampolskiy is a computer scientist (with a Ph.D. in behavioral biometrics), and an Associate Professor at the University of Louisville. He is also the author of the book Artificial Superintelligence: A Futuristic Approach. Today he joins us to discuss AI safety engineering.</itunes:subtitle>
      <itunes:keywords>ai, ai safety engineering, explainable ai</itunes:keywords>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>36</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">8aa3b1cb-5c0e-4d24-9032-ddf4669505b4</guid>
      <title>GRID.ai&apos;s Lead AI Educator Sebastian Raschka</title>
      <description><![CDATA[<p>Joining us today on How AI Happens is Sebastian Raschka, Lead AI educator at <a href="https://www.grid.ai/">GRID.ai</a> and Assistant Professor of Statistics at the University of Wisconsin-Madison.  Sebastian fills us in on the coursework he’s creating in his role at GRID.ai, and we find out what can be attributed to the crossover of machine learning in academia and the private sector. We speculate on the pros and cons of the commodification of deep learning models and which machine learning framework is better: PyTorch or TensorFlow. </p><p>Key Points From This Episode:</p><ul><li>Sebastian Raschka’s journey from the computation of biology to AI and machine learning.</li><li>The focus of his current role as Lead AI educator at GRID.ai.</li><li>The ideal applications and outcomes of the coursework Sebastian is developing.</li><li>The crossover of machine learning in academia and the private sector; the theory versus the application.</li><li>Deep learning versus machine learning and what constitutes a deep learning problem.</li><li>The importance of sufficient data for deep learning to be effective.</li><li>The applications of the BERT text model.</li><li>The pros and cons of developing more accessible models.</li><li>Why Sebastian set out to write <i>Machine Learning with PyTorch and Scikit-Learn.</i></li><li>The structure of the book, including theory and application.</li><li>Why Sebastian prefers PyTorch over TensorFlow.</li><li>What he finds most exciting in the current deep learning space.</li><li>The emerging opportunities to use deep learning!</li></ul><p>Tweetables:</p><p>“In academia, the focus is more on understanding how deep learning works… On the other hand, in the industry, there are [many] use cases of machine learning.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:10:10]</p><p>“Often it is hard to formulate answers as a human to complex questions.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:12:53]</p><p>“In my experience, deep learning can be very powerful but you need a lot of data to make it work well.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:14:06]</p><p>“In [<i>Machine Learning with PyTorch and Scikit-Learn</i>], I tried to provide a resource that is a hybrid between more theoretical books and more applied books.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:23:21]</p><p>“Why I like PyTorch is that it gives me the readability [and] flexibility to customize things.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:25:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://sebastianraschka.com/">Sebastian Raschka</a></p><p><a href="https://twitter.com/rasbt">Sebastian Raschka on Twitter</a></p><p><a href="https://www.grid.ai/">GRID.ai</a></p><p><a href="https://www.amazon.com/Machine-Learning-PyTorch-Scikit-Learn-scikit-learn-ebook-dp-B09NW48MR1/dp/B09NW48MR1/"><i>Machine Learning with PyTorch and Scikit-Learn</i></a></p><p> </p>
]]></description>
      <pubDate>Thu, 21 Apr 2022 19:24:47 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/gridais-lead-ai-educator-sebastian-raschka-F_AikSEz</link>
      <content:encoded><![CDATA[<p>Joining us today on How AI Happens is Sebastian Raschka, Lead AI educator at <a href="https://www.grid.ai/">GRID.ai</a> and Assistant Professor of Statistics at the University of Wisconsin-Madison.  Sebastian fills us in on the coursework he’s creating in his role at GRID.ai, and we find out what can be attributed to the crossover of machine learning in academia and the private sector. We speculate on the pros and cons of the commodification of deep learning models and which machine learning framework is better: PyTorch or TensorFlow. </p><p>Key Points From This Episode:</p><ul><li>Sebastian Raschka’s journey from the computation of biology to AI and machine learning.</li><li>The focus of his current role as Lead AI educator at GRID.ai.</li><li>The ideal applications and outcomes of the coursework Sebastian is developing.</li><li>The crossover of machine learning in academia and the private sector; the theory versus the application.</li><li>Deep learning versus machine learning and what constitutes a deep learning problem.</li><li>The importance of sufficient data for deep learning to be effective.</li><li>The applications of the BERT text model.</li><li>The pros and cons of developing more accessible models.</li><li>Why Sebastian set out to write <i>Machine Learning with PyTorch and Scikit-Learn.</i></li><li>The structure of the book, including theory and application.</li><li>Why Sebastian prefers PyTorch over TensorFlow.</li><li>What he finds most exciting in the current deep learning space.</li><li>The emerging opportunities to use deep learning!</li></ul><p>Tweetables:</p><p>“In academia, the focus is more on understanding how deep learning works… On the other hand, in the industry, there are [many] use cases of machine learning.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:10:10]</p><p>“Often it is hard to formulate answers as a human to complex questions.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:12:53]</p><p>“In my experience, deep learning can be very powerful but you need a lot of data to make it work well.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:14:06]</p><p>“In [<i>Machine Learning with PyTorch and Scikit-Learn</i>], I tried to provide a resource that is a hybrid between more theoretical books and more applied books.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:23:21]</p><p>“Why I like PyTorch is that it gives me the readability [and] flexibility to customize things.” — <a href="https://twitter.com/rasbt">@rasbt</a> [0:25:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://sebastianraschka.com/">Sebastian Raschka</a></p><p><a href="https://twitter.com/rasbt">Sebastian Raschka on Twitter</a></p><p><a href="https://www.grid.ai/">GRID.ai</a></p><p><a href="https://www.amazon.com/Machine-Learning-PyTorch-Scikit-Learn-scikit-learn-ebook-dp-B09NW48MR1/dp/B09NW48MR1/"><i>Machine Learning with PyTorch and Scikit-Learn</i></a></p><p> </p>
]]></content:encoded>
      <enclosure length="26922398" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/febebcc9-6d7b-4e8e-b321-c368e2a6f5cc/audio/0ec7438d-cb3c-428b-8dde-3c6e018a48cf/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>GRID.ai&apos;s Lead AI Educator Sebastian Raschka</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:08</itunes:duration>
      <itunes:summary>Joining us today on How AI Happens is Sebastian Raschka, Lead AI educator at GRID.ai and Assistant Professor of Statistics at the University of Wisconsin-Madison.  Sebastian fills us in on the coursework he’s creating in his role at GRID.ai, and we find out what can be attributed to the crossover of machine learning in academia and the private sector. We speculate on the pros and cons of the commodification of deep learning models and which machine learning framework is better: PyTorch or TensorFlow. </itunes:summary>
      <itunes:subtitle>Joining us today on How AI Happens is Sebastian Raschka, Lead AI educator at GRID.ai and Assistant Professor of Statistics at the University of Wisconsin-Madison.  Sebastian fills us in on the coursework he’s creating in his role at GRID.ai, and we find out what can be attributed to the crossover of machine learning in academia and the private sector. We speculate on the pros and cons of the commodification of deep learning models and which machine learning framework is better: PyTorch or TensorFlow. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>35</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">84a20eff-6e41-4748-9a66-eca06ed2e386</guid>
      <title>Edge Computing &amp; AI Readiness with Antonio Grasso</title>
      <description><![CDATA[<p>Antonio Grasso joins us to explain how he empowers some of the biggest companies in the world to use AI in a meaningful way and explains the two ways his company goes about this. You’ll hear about what Antonio believes is coming down the pipeline in terms of the Internet of Things, especially when it comes to edge computing, and why network traffic has become a huge concern. We discuss where edge computing begins and ends with regards to the difference between the device and its computational resources. In light of the fact that one can infer at the edge but not train at the edge, Antonio shares his views on why he disagrees that the ultimate goal should be to train at the edge. He also provides a helpful resource for AI practitioners to calculate an AI readiness index.</p><p>Key Points From This Episode:</p><ul><li>How Antonio Grasso grew from a software engineer in the 80s to someone so influential in the world of AI today. </li><li>How Antonio empowers some of the biggest companies to use AI in a meaningful way. </li><li>The two faces of Antonio’s company Digital Business Innovation Srl. </li><li>One of Antonio’s biggest achievements at IBM.</li><li>How, as a technical expert, he helps people to understand what is possible with this technology and build trust. </li><li>The challenges of maintaining the pace of innovation.</li><li>What Antonio believes is coming down the pipeline in terms of Internet of Things especially when it comes to edge computing.</li><li>Why network traffic has become a huge concern and the role of edge computing in this. </li><li>What defines edge computing and the difference between the device and its computational resources.</li><li>In light of the fact that one can infer at the edge but not train at the edge, Antonio’s views on whether or not the goal should be to train at the edge. </li><li>Antonio’s advice to the AI practitioner out there on how you can calculate an AI readiness index. </li></ul><p>Tweetables:</p><p>“‘Wow, this is really unbelievable! We can also create not [only] code software with direct explicit instruction, we can also [create] code software that learns from experience!’ That really [caught] me and I fell in love with this kind of technology.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:03:13]</p><p>“I started on Social Media to share my knowledge, my experience, because I think you must share what you see because everyone can benefit of it too.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:03:39]</p><p>“We need to shift to better understand what is the meaning of edge computing but we must divide the device itself from the computational resources that we put [there] to harness the power of computational power in proximity.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:16:15]</p><p>“I can not imagine training at the edge. — We can do it, yes, but my question is why?” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:20:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/antonio-grasso-0544007/">Antonio Grasso</a>  </p><p><a href="https://www.dbi.srl/">Digital Business Innovation Srl</a></p><p><a href="https://aisingapore.org/airi/">AI Singapore (AIRI Assessment)</a></p><p><a href="https://twitter.com/antgrasso">Antonio Grasso on Twitter</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p>
]]></description>
      <pubDate>Thu, 14 Apr 2022 21:46:17 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/edge-computing-ai-readiness-with-antonio-grosso-SiiMbH7x</link>
      <content:encoded><![CDATA[<p>Antonio Grasso joins us to explain how he empowers some of the biggest companies in the world to use AI in a meaningful way and explains the two ways his company goes about this. You’ll hear about what Antonio believes is coming down the pipeline in terms of the Internet of Things, especially when it comes to edge computing, and why network traffic has become a huge concern. We discuss where edge computing begins and ends with regards to the difference between the device and its computational resources. In light of the fact that one can infer at the edge but not train at the edge, Antonio shares his views on why he disagrees that the ultimate goal should be to train at the edge. He also provides a helpful resource for AI practitioners to calculate an AI readiness index.</p><p>Key Points From This Episode:</p><ul><li>How Antonio Grasso grew from a software engineer in the 80s to someone so influential in the world of AI today. </li><li>How Antonio empowers some of the biggest companies to use AI in a meaningful way. </li><li>The two faces of Antonio’s company Digital Business Innovation Srl. </li><li>One of Antonio’s biggest achievements at IBM.</li><li>How, as a technical expert, he helps people to understand what is possible with this technology and build trust. </li><li>The challenges of maintaining the pace of innovation.</li><li>What Antonio believes is coming down the pipeline in terms of Internet of Things especially when it comes to edge computing.</li><li>Why network traffic has become a huge concern and the role of edge computing in this. </li><li>What defines edge computing and the difference between the device and its computational resources.</li><li>In light of the fact that one can infer at the edge but not train at the edge, Antonio’s views on whether or not the goal should be to train at the edge. </li><li>Antonio’s advice to the AI practitioner out there on how you can calculate an AI readiness index. </li></ul><p>Tweetables:</p><p>“‘Wow, this is really unbelievable! We can also create not [only] code software with direct explicit instruction, we can also [create] code software that learns from experience!’ That really [caught] me and I fell in love with this kind of technology.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:03:13]</p><p>“I started on Social Media to share my knowledge, my experience, because I think you must share what you see because everyone can benefit of it too.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:03:39]</p><p>“We need to shift to better understand what is the meaning of edge computing but we must divide the device itself from the computational resources that we put [there] to harness the power of computational power in proximity.” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:16:15]</p><p>“I can not imagine training at the edge. — We can do it, yes, but my question is why?” — <a href="https://twitter.com/antgrasso">@antgrasso</a> [0:20:50]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/antonio-grasso-0544007/">Antonio Grasso</a>  </p><p><a href="https://www.dbi.srl/">Digital Business Innovation Srl</a></p><p><a href="https://aisingapore.org/airi/">AI Singapore (AIRI Assessment)</a></p><p><a href="https://twitter.com/antgrasso">Antonio Grasso on Twitter</a></p><p><a href="https://www.howaihappens.com/">How AI Happens</a></p>
]]></content:encoded>
      <enclosure length="22236884" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/071a59fe-5c16-4544-83e2-6e92f6c7924b/audio/819c6597-c84a-4667-868e-f2e53f56825b/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Edge Computing &amp; AI Readiness with Antonio Grasso</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:24:04</itunes:duration>
      <itunes:summary>Antonio Grasso started his career as a software engineer in the 80s. Now he is the Founder and CEO of Digital Business Innovation Srl, a recognized member of Intel&apos;s Internet of Things Software Innovation Program, and an ambassador, fellow, and advisor to organizations too numerous to list. </itunes:summary>
      <itunes:subtitle>Antonio Grasso started his career as a software engineer in the 80s. Now he is the Founder and CEO of Digital Business Innovation Srl, a recognized member of Intel&apos;s Internet of Things Software Innovation Program, and an ambassador, fellow, and advisor to organizations too numerous to list. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>34</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">fe5f9b0e-aa52-4ad0-b3f8-824b69a8ca8d</guid>
      <title>The Future of NLP with AI Professor, Vice Rector, &amp; Researcher Aleksandra Przegalinska</title>
      <description><![CDATA[<p>Today's guest is Aleksandra Przegalinska PhD, Vice-Rector at Kozminski University, research associate, and Polish futurist. From studying pure philosophy, Aleksandra moved into AI when she started researching natural language processing in the virtual space. We kickstart our discussion with her account of how she ended up where she is now, and how she transferred her skills from philosophy to AI. We hear how Second Life was common in Asia centuries ago, why we are seeing a return to anonymization online, and why Aleksandra feels NLP should be called ‘natural language understanding’. We also discover what the real-world applications of NLP are, and why text processing is under-utilized. Moving onto more philosophical questions around AI and labor, Aleksandra explains how AI should be used to help people and why what is sometimes simple for a human can be immensely complex for AI. We wrap up with Aleksandra’s thoughts on transformers and why their applications are more important than their capabilities, as well as why she is so excited about the idea of xenobots. </p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Aleksandra Przegalinska, PhD.</li><li>What Aleksandra is researching at the moment and how she ended up in academia. </li><li>Insight into the link between her PhD topic and the Metaverse and the transfer of skills from a philosophy degree to AI. </li><li>How a properly built digital ecosystem allows people freedom of expression and other takeaways from Aleksandra’s PhD experience. </li><li>The return to online anonymization that we are currently seeing. </li><li>Aleksandra’s experience of NLP in Second Life and how AI has altered the field. </li><li>The role of NLP in Aleksandra’s work today and why she feels it should be called ‘natural language understanding’. </li><li>The real-world applications of NLP: why text processing is under-utilized. </li><li>Why people don't have to believe that programs are close to human.</li><li>Why Aleksandra feels removing the need for manually annotated data should be a key focus in the field of AI.</li><li>Tradeoffs between automation and human labor; why we should use AI to help humans first.</li><li>How the challenges of automating tasks differ between fields from creative and marketing to calendar management. </li><li>What Aleksandra thinks of the transformer arms race: why applications are more important than parameters. </li><li>Why Aleksandra feels xenobots will change the world.</li></ul><p>Tweetables:</p><p>“My major discovery [during my PhD] was that people are capable of building robust identities online and can live two lives. They can have their first life and then they can have their second life online, which can be very different from the one they pursue on-site, in the real world.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:06:42]</p><p>“We can all observe that there is a great boom in NLP. I’m not even sure we should call it NLP anymore. Maybe NLP is an improper phrase. Maybe it’s NLU: natural language understanding.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:14:51]</p><p>“Transformers seem to be a really big game-changer in the AI space.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:16:40]</p><p>“I think that using text as a resource for data analytics for businesses in the future is something that we will see happen in the coming two or three years.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:19:46]</p><p>“AI should not replace you, AI should help you at your work and make your work more effective but also more satisfying for you.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:25:31]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/aleksandra-przegalinska-5b17125/">Aleksandra Przegalinska on LinkedIn</a></p><p><a href="https://twitter.com/Przegaa">Alexandra Przegalinska on Twitter</a></p><p> </p>
]]></description>
      <pubDate>Thu, 7 Apr 2022 17:36:43 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/the-future-of-nlp-with-ai-professor-vice-rector-researcher-aleksandra-przegalinska-xMri6kgD</link>
      <content:encoded><![CDATA[<p>Today's guest is Aleksandra Przegalinska PhD, Vice-Rector at Kozminski University, research associate, and Polish futurist. From studying pure philosophy, Aleksandra moved into AI when she started researching natural language processing in the virtual space. We kickstart our discussion with her account of how she ended up where she is now, and how she transferred her skills from philosophy to AI. We hear how Second Life was common in Asia centuries ago, why we are seeing a return to anonymization online, and why Aleksandra feels NLP should be called ‘natural language understanding’. We also discover what the real-world applications of NLP are, and why text processing is under-utilized. Moving onto more philosophical questions around AI and labor, Aleksandra explains how AI should be used to help people and why what is sometimes simple for a human can be immensely complex for AI. We wrap up with Aleksandra’s thoughts on transformers and why their applications are more important than their capabilities, as well as why she is so excited about the idea of xenobots. </p><p>Key Points From This Episode:</p><ul><li>An introduction to today’s guest, Aleksandra Przegalinska, PhD.</li><li>What Aleksandra is researching at the moment and how she ended up in academia. </li><li>Insight into the link between her PhD topic and the Metaverse and the transfer of skills from a philosophy degree to AI. </li><li>How a properly built digital ecosystem allows people freedom of expression and other takeaways from Aleksandra’s PhD experience. </li><li>The return to online anonymization that we are currently seeing. </li><li>Aleksandra’s experience of NLP in Second Life and how AI has altered the field. </li><li>The role of NLP in Aleksandra’s work today and why she feels it should be called ‘natural language understanding’. </li><li>The real-world applications of NLP: why text processing is under-utilized. </li><li>Why people don't have to believe that programs are close to human.</li><li>Why Aleksandra feels removing the need for manually annotated data should be a key focus in the field of AI.</li><li>Tradeoffs between automation and human labor; why we should use AI to help humans first.</li><li>How the challenges of automating tasks differ between fields from creative and marketing to calendar management. </li><li>What Aleksandra thinks of the transformer arms race: why applications are more important than parameters. </li><li>Why Aleksandra feels xenobots will change the world.</li></ul><p>Tweetables:</p><p>“My major discovery [during my PhD] was that people are capable of building robust identities online and can live two lives. They can have their first life and then they can have their second life online, which can be very different from the one they pursue on-site, in the real world.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:06:42]</p><p>“We can all observe that there is a great boom in NLP. I’m not even sure we should call it NLP anymore. Maybe NLP is an improper phrase. Maybe it’s NLU: natural language understanding.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:14:51]</p><p>“Transformers seem to be a really big game-changer in the AI space.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:16:40]</p><p>“I think that using text as a resource for data analytics for businesses in the future is something that we will see happen in the coming two or three years.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:19:46]</p><p>“AI should not replace you, AI should help you at your work and make your work more effective but also more satisfying for you.” — <a href="https://twitter.com/Przegaa">@Przegaa</a> [0:25:31]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/aleksandra-przegalinska-5b17125/">Aleksandra Przegalinska on LinkedIn</a></p><p><a href="https://twitter.com/Przegaa">Alexandra Przegalinska on Twitter</a></p><p> </p>
]]></content:encoded>
      <enclosure length="26628936" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/4488a79d-e5a9-468a-acbb-f5a116425312/audio/f55b9ed7-ef32-4068-ad60-fd7e812a4521/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>The Future of NLP with AI Professor, Vice Rector, &amp; Researcher Aleksandra Przegalinska</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:38:15</itunes:duration>
      <itunes:summary>PhD, Vice-Rector at Kozminski University, Harvard research associate, and Polish futurist Aleksandra Przegalinska joins to discuss the future of NLP, the true value in improving transformers, and the current state of automation with regard to creative vs. mundane tasks.</itunes:summary>
      <itunes:subtitle>PhD, Vice-Rector at Kozminski University, Harvard research associate, and Polish futurist Aleksandra Przegalinska joins to discuss the future of NLP, the true value in improving transformers, and the current state of automation with regard to creative vs. mundane tasks.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>33</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">5ebc6580-2f9b-4572-8499-4c87a0b5964f</guid>
      <title>Unpacking Facial Recognition Technology at CyberLink</title>
      <description><![CDATA[<p>CyberLink's facial recognition technology routinely registers best-in-class accuracy. But how do developers deal with masks, glasses, headphones, or changes in faces over time? How can they prevent spoofing in order to protect identities? And where does computer vision & object detection stop and FRT truly begin? CyberLink Senior Vice President of Global Marketing and US General Manager Richard Carriere and Head of Sales Engineering Craig Campbell join to discuss the endless use cases for facial recognition technology, how CyberLink is improving the tech's accuracy & security, and the ethical considerations of deploying FRT at scale.</p><p><a href="https://www.cyberlink.com/faceme/insights/articles/204/Facial-Recognition-at-the-Edge-The-Ultimate-Guide" target="_blank">CyberLink's Ultimate Guide to Facial Recognition</a></p><p><a href="https://www.dropbox.com/s/3ka50ns1gkpp080/Demo%20of%20FaceMe%20SDK.mp4?dl=0" target="_blank">FaceMe Security SDK Demo</a><br /><br />Get in touch with Cyberlink: FaceMe_US@cyberlink.com</p>
]]></description>
      <pubDate>Thu, 31 Mar 2022 17:36:23 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/unpacking-facial-recognition-technology-at-cyberlink-e_ZJx8Iv</link>
      <content:encoded><![CDATA[<p>CyberLink's facial recognition technology routinely registers best-in-class accuracy. But how do developers deal with masks, glasses, headphones, or changes in faces over time? How can they prevent spoofing in order to protect identities? And where does computer vision & object detection stop and FRT truly begin? CyberLink Senior Vice President of Global Marketing and US General Manager Richard Carriere and Head of Sales Engineering Craig Campbell join to discuss the endless use cases for facial recognition technology, how CyberLink is improving the tech's accuracy & security, and the ethical considerations of deploying FRT at scale.</p><p><a href="https://www.cyberlink.com/faceme/insights/articles/204/Facial-Recognition-at-the-Edge-The-Ultimate-Guide" target="_blank">CyberLink's Ultimate Guide to Facial Recognition</a></p><p><a href="https://www.dropbox.com/s/3ka50ns1gkpp080/Demo%20of%20FaceMe%20SDK.mp4?dl=0" target="_blank">FaceMe Security SDK Demo</a><br /><br />Get in touch with Cyberlink: FaceMe_US@cyberlink.com</p>
]]></content:encoded>
      <enclosure length="25758935" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/689b04b8-a641-4ab8-a4cc-8a5a30d1bab8/audio/49b4db68-f070-42e4-844d-70539117deea/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Unpacking Facial Recognition Technology at CyberLink</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:32:48</itunes:duration>
      <itunes:summary>CyberLink Senior Vice President of Global Marketing and US General Manager Richard Carriere and Head of Sales Engineering Craig Campbell join to discuss the endless use cases for facial recognition technology, how CyberLink is improving the tech&apos;s accuracy &amp; security, and the ethical considerations of deploying FRT at scale.</itunes:summary>
      <itunes:subtitle>CyberLink Senior Vice President of Global Marketing and US General Manager Richard Carriere and Head of Sales Engineering Craig Campbell join to discuss the endless use cases for facial recognition technology, how CyberLink is improving the tech&apos;s accuracy &amp; security, and the ethical considerations of deploying FRT at scale.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>32</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">784a768c-3a87-44eb-87ef-072f7232fa27</guid>
      <title>Universal Autonomy with Oxbotica VP of Technology Ben Upcroft</title>
      <description><![CDATA[<p>Oxbotica is a vehicle software company at the forefront of autonomous technology, and today we have a fascinating chat with Ben Upcroft, the Vice President of Technology. Ben explains Oxbotica's mission of enabling industries to make the most of autonomy, and how their technological progress affects real-world situations. We also get into some of the challenges that Oxbotica and the autonomy space, in general, are currently facing, before drilling down on the important concepts of user trust, future implementations, and creating an adaptable core functionality. The last part of today's episode is spent exploring the exciting possibilities of simulated environments for data collection, and the broadening of vehicle experience. Ben talks about the importance of seeking out edge cases to improve their data, and we get into how Oxbotica applies this data across locations. </p><p>Key Points From This Episode:</p><ul><li>The constant joy and excitement that Ben feels about his work!</li><li>An introduction to Oxbotica and its main mission as an organization. </li><li>How the advances in autonomy translate into real-world progress in safety and efficiency. </li><li>Handbrakes on the widespread implementation of more autonomy; Ben looks at current limitations. </li><li>Facilitating trust in the public sphere for something new and the markers of progress. </li><li>Oxbotica's array of vehicles and goals beyond basic transportation. </li><li>Constant evolution and the question of staying on course with the rising tide of technology.  </li><li>How generic features allow for an adaptable core functionality in Oxbotica's vehicles.  </li><li>Applying data from different environments to boost performance across location types.</li><li>How Oxbotica focuses on simulated edge cases as a means to broaden the capabilities of their technologies.</li><li>The amount of real-world data that is necessary for accurate synthesis. </li><li>Assessing the idea of quality over quantity when it comes to data for AI applications. </li><li>The areas of the AI field that have Ben most excited right now; emulation of the human brain for the creation of new platforms! </li></ul><p>Tweetables:</p><p>“Oxbotica is about deploying and enabling industries to use and leverage autonomy for performance, for efficiency, and safety gains.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>“The autonomy that we bring revolutionizes how we move around the globe, through logistics transport, on wheeled vehicles.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>“The idea behind the system is that it is modular, enables a core functionality, and I am able to add little extras that customize for a particular domain.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ben-upcroft?originalSubdomain=uk">Ben Upcroft on LinkedIn</a></p><p><a href="https://www.oxbotica.com/">Oxbotica</a></p><p><a href="https://twitter.com/ben_upcroft">Ben Upcroft on Twitter</a></p>
]]></description>
      <pubDate>Thu, 24 Mar 2022 18:32:26 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/universal-autonomy-with-oxbotica-vp-of-technology-ben-upcroft-aXZdsNS6</link>
      <content:encoded><![CDATA[<p>Oxbotica is a vehicle software company at the forefront of autonomous technology, and today we have a fascinating chat with Ben Upcroft, the Vice President of Technology. Ben explains Oxbotica's mission of enabling industries to make the most of autonomy, and how their technological progress affects real-world situations. We also get into some of the challenges that Oxbotica and the autonomy space, in general, are currently facing, before drilling down on the important concepts of user trust, future implementations, and creating an adaptable core functionality. The last part of today's episode is spent exploring the exciting possibilities of simulated environments for data collection, and the broadening of vehicle experience. Ben talks about the importance of seeking out edge cases to improve their data, and we get into how Oxbotica applies this data across locations. </p><p>Key Points From This Episode:</p><ul><li>The constant joy and excitement that Ben feels about his work!</li><li>An introduction to Oxbotica and its main mission as an organization. </li><li>How the advances in autonomy translate into real-world progress in safety and efficiency. </li><li>Handbrakes on the widespread implementation of more autonomy; Ben looks at current limitations. </li><li>Facilitating trust in the public sphere for something new and the markers of progress. </li><li>Oxbotica's array of vehicles and goals beyond basic transportation. </li><li>Constant evolution and the question of staying on course with the rising tide of technology.  </li><li>How generic features allow for an adaptable core functionality in Oxbotica's vehicles.  </li><li>Applying data from different environments to boost performance across location types.</li><li>How Oxbotica focuses on simulated edge cases as a means to broaden the capabilities of their technologies.</li><li>The amount of real-world data that is necessary for accurate synthesis. </li><li>Assessing the idea of quality over quantity when it comes to data for AI applications. </li><li>The areas of the AI field that have Ben most excited right now; emulation of the human brain for the creation of new platforms! </li></ul><p>Tweetables:</p><p>“Oxbotica is about deploying and enabling industries to use and leverage autonomy for performance, for efficiency, and safety gains.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>“The autonomy that we bring revolutionizes how we move around the globe, through logistics transport, on wheeled vehicles.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>“The idea behind the system is that it is modular, enables a core functionality, and I am able to add little extras that customize for a particular domain.” — <a href="https://twitter.com/ben_upcroft">@ben_upcroft</a> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ben-upcroft?originalSubdomain=uk">Ben Upcroft on LinkedIn</a></p><p><a href="https://www.oxbotica.com/">Oxbotica</a></p><p><a href="https://twitter.com/ben_upcroft">Ben Upcroft on Twitter</a></p>
]]></content:encoded>
      <enclosure length="27974213" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f415d387-8798-41f4-a337-75184afa19f8/audio/976127d9-4de1-4ba8-93da-6a7effd64618/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Universal Autonomy with Oxbotica VP of Technology Ben Upcroft</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:27</itunes:duration>
      <itunes:summary>VP of Technology Ben Upcroft explains Oxbotica&apos;s vision of &quot;Universal Autonomy&quot;, and the process developing software that enables vehicles to seamlessly transition between on-road and off-road environments in a safe and autonomous manner.</itunes:summary>
      <itunes:subtitle>VP of Technology Ben Upcroft explains Oxbotica&apos;s vision of &quot;Universal Autonomy&quot;, and the process developing software that enables vehicles to seamlessly transition between on-road and off-road environments in a safe and autonomous manner.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>31</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">697618d5-d6de-411b-8980-f7b8412b84dd</guid>
      <title>Upleveling Data Labeling with Sama&apos;s Jerome Pasquero</title>
      <description><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>Jerome’s background, interest in AI, and how he landed his role at Sama.</li><li>Social initiatives, training data, and what attracted Jerome to Sama.</li><li>The shift from focusing on AI models to the importance of data quality.</li><li>Why academia requires the use of a foundational dataset to compare models.</li><li>The reason for the early focus on building new AI models.</li><li>Whether datasets will become open source in the future as models have.</li><li>The role of annotation in making data meaningful and useful.</li><li>Challenges of annotating data and different approaches to doing so.</li><li>The three components of data annotation: models, filtering, and the annotation pipeline.</li><li>How to hone in on goals for filtering data into valuable subsets that align with your desired outcomes.</li><li>How to measure a model’s accuracy by focusing on user experience and more.</li><li>What data drift is and how to prevent it by keeping track of it and retraining models where necessary.</li><li>How to know that your training data is close enough to your production data.</li><li>What excites Jerome most about the world of data and annotation.</li></ul><p>Tweetables:</p><p>“Most of the successful model architectures are now open source. You can get them anywhere on the web easily, but the one thing that a company is guarding with its life is its data.” — Jerome Pasquero [0:05:36]</p><p>“If you consider that we now know that a model can be highly sensitive to the quality of the data that are used to train it, there is this natural shift to try to feed models with the best data possible and data quality becomes of paramount importance.” — Jerome Pasquero [0:05:47]</p><p>“The point of this whole system is that, once you have these three components in place, you can drive your filtering strategy.” — Jerome Pasquero [0:14:06]</p><p>“You can always get more data later. What you want to avoid is getting yourself into a situation where the data that you are annotating is useless.” — Jerome Pasquero [0:17:30]</p><p>“A model is like a living thing. You need to take care of it otherwise it is going to degrade, not because it’s degrading internally, but because the data that it is used to seeing has changed.” — Jerome Pasquero [0:25:49]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jeromepasquero/">Jerome Pasquero on LinkedIn</a></p><p><a href="https://www.sama.com/blog/top-10-data-labeling-frequently-asked-questions"><strong>Jerome Pasquero Blog: Top 10 Data Labeling FAQs</strong></a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></description>
      <pubDate>Thu, 17 Mar 2022 18:24:02 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/upleveling-data-labeling-with-samas-jerome-pasquero-yeHirE6H</link>
      <content:encoded><![CDATA[<p> </p><p>Key Points From This Episode:</p><ul><li>Jerome’s background, interest in AI, and how he landed his role at Sama.</li><li>Social initiatives, training data, and what attracted Jerome to Sama.</li><li>The shift from focusing on AI models to the importance of data quality.</li><li>Why academia requires the use of a foundational dataset to compare models.</li><li>The reason for the early focus on building new AI models.</li><li>Whether datasets will become open source in the future as models have.</li><li>The role of annotation in making data meaningful and useful.</li><li>Challenges of annotating data and different approaches to doing so.</li><li>The three components of data annotation: models, filtering, and the annotation pipeline.</li><li>How to hone in on goals for filtering data into valuable subsets that align with your desired outcomes.</li><li>How to measure a model’s accuracy by focusing on user experience and more.</li><li>What data drift is and how to prevent it by keeping track of it and retraining models where necessary.</li><li>How to know that your training data is close enough to your production data.</li><li>What excites Jerome most about the world of data and annotation.</li></ul><p>Tweetables:</p><p>“Most of the successful model architectures are now open source. You can get them anywhere on the web easily, but the one thing that a company is guarding with its life is its data.” — Jerome Pasquero [0:05:36]</p><p>“If you consider that we now know that a model can be highly sensitive to the quality of the data that are used to train it, there is this natural shift to try to feed models with the best data possible and data quality becomes of paramount importance.” — Jerome Pasquero [0:05:47]</p><p>“The point of this whole system is that, once you have these three components in place, you can drive your filtering strategy.” — Jerome Pasquero [0:14:06]</p><p>“You can always get more data later. What you want to avoid is getting yourself into a situation where the data that you are annotating is useless.” — Jerome Pasquero [0:17:30]</p><p>“A model is like a living thing. You need to take care of it otherwise it is going to degrade, not because it’s degrading internally, but because the data that it is used to seeing has changed.” — Jerome Pasquero [0:25:49]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/jeromepasquero/">Jerome Pasquero on LinkedIn</a></p><p><a href="https://www.sama.com/blog/top-10-data-labeling-frequently-asked-questions"><strong>Jerome Pasquero Blog: Top 10 Data Labeling FAQs</strong></a></p><p><a href="https://www.sama.com/">Sama</a></p>
]]></content:encoded>
      <enclosure length="31058634" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/232891e6-561b-47bb-ad0c-6c44087ef136/audio/b17c1828-2d18-4e5c-848b-226518501bad/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Upleveling Data Labeling with Sama&apos;s Jerome Pasquero</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:46</itunes:duration>
      <itunes:summary>As a Senior Product Manager at Sama, Jerome Pasquero understands the power of data, and he joins us today to share a wealth of knowledge on how better annotation ensures better models.</itunes:summary>
      <itunes:subtitle>As a Senior Product Manager at Sama, Jerome Pasquero understands the power of data, and he joins us today to share a wealth of knowledge on how better annotation ensures better models.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>30</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">3f6b0658-79a4-46f6-ace5-962f37f3db59</guid>
      <title>A Highly Compositional Future with Dr. Eric Daimler</title>
      <description><![CDATA[<p>Dr. Daimler is an authority in Artificial Intelligence with over 20 years of experience in the field as an entrepreneur, executive, investor, technologist, and policy advisor. He is also the founder of data integration firm Conexus, and we kick our conversation off with the work he is doing to integrate large heterogeneous data infrastructures. This leads us into an exploration of the concept of compositionality, a structural feature that enables systems to scale, which Dr. Daimler argues is the future of IT infrastructure. We discuss how the way we apply AI to data is constantly changing, with data sources growing quadratically, and how this necessitates an understanding of newer forms of math such as category theory by AI specialists. Towards the end of our discussion, we move on to the subject of the adoption of AI in technologies that lives depend on, and Dr. Daimler gives his recommendation for how to engender trust amongst the larger population. </p><p>Key Points From This Episode:</p><ul><li>Experience Dr. Daimler has in AI in an academic, commercial, and governmental capacity.</li><li>An issue in the choices being made around how to create data that is useful in large organizations.</li><li>Dr. Daimler’s work bringing heterogeneous data together to influence better business decisions.</li><li>How much money is wasted on ETL processes and how bad the jobs in that field are.</li><li>The difference between modularity and compositionality and why the latter is the future of IT infrastructure.</li><li>How compositionality enables scalability and the need of certain branches of math to justify it.</li><li>The work Dr. Daimler is doing in the field of compositionality at Connexus.</li><li>Whether it is crucial to grasp these newer forms of math to achieve AI mastery.</li><li>How AI systems can integrate into contexts involving human labor and empathy.</li><li>The need to bring together probabilistic and deterministic AI in life and death contexts.</li><li>How to get the public to trust and believe in AI-powered tech with the capacity to save lives.</li><li>What AI practitioners can do to ensure they use their skillset to create a better future.</li></ul><p>Tweetables:</p><p>“You can create data that doesn’t add more fidelity to the knowledge you’re looking to gain for better business decisions and that is one of the limitations that I saw expressed in the government and other large organizations.” — <a href="https://twitter.com/ead">@ead</a> [0:01:32]</p><p>“That’s the world, is compositionality. That is where we are going and the math that supports that, type theory, categorical theory, categorical logic, that’s going to sweep away everything underneath IT infrastructure.” — <a href="https://twitter.com/ead">@ead</a> [0:10:23]</p><p>“At the trillions of data, a trillion data sources, each growing quadratically, what we need is category theory.” — <a href="https://twitter.com/ead">@ead</a> [0:13:51]</p><p>“People die and the way to solve that problem when you are talking about these life and death contexts for commercial airplane manufacturers or in energy exploration where the consequences of failure can be disastrous is to bring together the sensibilities of probabilistic AI and deterministic AI.” — <a href="https://twitter.com/ead">@ead</a> [0:24:07]</p><p>“Circuit breakers, oversight, and data lineage, those are three ways that I would institute a regulatory regime around AI and algorithms that will engender trust amongst the larger population.” — <a href="https://twitter.com/ead">@ead</a> [0:35:12]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ericdaimler/">Dr. Eric Daimler on LinkedIn</a></p><p><a href="https://twitter.com/ead">Dr. Eric Daimler on Twitter</a></p><p><a href="https://conexus.com/">Conexus</a></p>
]]></description>
      <pubDate>Thu, 3 Mar 2022 19:07:03 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/a-highly-compositional-future-with-dr-eric-daimler-sIR8XEl4</link>
      <content:encoded><![CDATA[<p>Dr. Daimler is an authority in Artificial Intelligence with over 20 years of experience in the field as an entrepreneur, executive, investor, technologist, and policy advisor. He is also the founder of data integration firm Conexus, and we kick our conversation off with the work he is doing to integrate large heterogeneous data infrastructures. This leads us into an exploration of the concept of compositionality, a structural feature that enables systems to scale, which Dr. Daimler argues is the future of IT infrastructure. We discuss how the way we apply AI to data is constantly changing, with data sources growing quadratically, and how this necessitates an understanding of newer forms of math such as category theory by AI specialists. Towards the end of our discussion, we move on to the subject of the adoption of AI in technologies that lives depend on, and Dr. Daimler gives his recommendation for how to engender trust amongst the larger population. </p><p>Key Points From This Episode:</p><ul><li>Experience Dr. Daimler has in AI in an academic, commercial, and governmental capacity.</li><li>An issue in the choices being made around how to create data that is useful in large organizations.</li><li>Dr. Daimler’s work bringing heterogeneous data together to influence better business decisions.</li><li>How much money is wasted on ETL processes and how bad the jobs in that field are.</li><li>The difference between modularity and compositionality and why the latter is the future of IT infrastructure.</li><li>How compositionality enables scalability and the need of certain branches of math to justify it.</li><li>The work Dr. Daimler is doing in the field of compositionality at Connexus.</li><li>Whether it is crucial to grasp these newer forms of math to achieve AI mastery.</li><li>How AI systems can integrate into contexts involving human labor and empathy.</li><li>The need to bring together probabilistic and deterministic AI in life and death contexts.</li><li>How to get the public to trust and believe in AI-powered tech with the capacity to save lives.</li><li>What AI practitioners can do to ensure they use their skillset to create a better future.</li></ul><p>Tweetables:</p><p>“You can create data that doesn’t add more fidelity to the knowledge you’re looking to gain for better business decisions and that is one of the limitations that I saw expressed in the government and other large organizations.” — <a href="https://twitter.com/ead">@ead</a> [0:01:32]</p><p>“That’s the world, is compositionality. That is where we are going and the math that supports that, type theory, categorical theory, categorical logic, that’s going to sweep away everything underneath IT infrastructure.” — <a href="https://twitter.com/ead">@ead</a> [0:10:23]</p><p>“At the trillions of data, a trillion data sources, each growing quadratically, what we need is category theory.” — <a href="https://twitter.com/ead">@ead</a> [0:13:51]</p><p>“People die and the way to solve that problem when you are talking about these life and death contexts for commercial airplane manufacturers or in energy exploration where the consequences of failure can be disastrous is to bring together the sensibilities of probabilistic AI and deterministic AI.” — <a href="https://twitter.com/ead">@ead</a> [0:24:07]</p><p>“Circuit breakers, oversight, and data lineage, those are three ways that I would institute a regulatory regime around AI and algorithms that will engender trust amongst the larger population.” — <a href="https://twitter.com/ead">@ead</a> [0:35:12]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/ericdaimler/">Dr. Eric Daimler on LinkedIn</a></p><p><a href="https://twitter.com/ead">Dr. Eric Daimler on Twitter</a></p><p><a href="https://conexus.com/">Conexus</a></p>
]]></content:encoded>
      <enclosure length="37644360" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/49757ba7-de7a-4cae-84b1-fe26545afbc7/audio/ab986a0f-1b81-4db8-bfc6-2a75dd0555b2/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>A Highly Compositional Future with Dr. Eric Daimler</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:40:51</itunes:duration>
      <itunes:summary>Dr. Eric Daimler is an authority in Artificial Intelligence with over 20 years of experience in the field as an entrepreneur, executive, investor, technologist, and policy advisor. He is also the founder of data integration firm Conexus, and we kick our conversation off with the work he is doing to integrate large heterogeneous data infrastructures. This leads us into an exploration of the concept of compositionality, a structural feature that enables systems to scale, which Dr. Daimler argues is the future of IT infrastructure.</itunes:summary>
      <itunes:subtitle>Dr. Eric Daimler is an authority in Artificial Intelligence with over 20 years of experience in the field as an entrepreneur, executive, investor, technologist, and policy advisor. He is also the founder of data integration firm Conexus, and we kick our conversation off with the work he is doing to integrate large heterogeneous data infrastructures. This leads us into an exploration of the concept of compositionality, a structural feature that enables systems to scale, which Dr. Daimler argues is the future of IT infrastructure.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>29</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">ca0927f4-dc75-4ab3-9a33-438846df1f48</guid>
      <title>Transfer Learning &amp; Solving Unstructured Data with Indico Data CTO Slater Victoroff</title>
      <description><![CDATA[<p>Irrespective of the application or the technology, a common problem among AI professionals always seems to be data. Is there enough of it? What do we prioritize? Is it clean? How do we annotate it? Today’s guest, however, believes that AI is not data-limited but compute-limited. Joining us to share some very interesting insights on the subject matter is Slater Victoroff, Founder and Chief Technology Officer at Indico, an unstructured data platform that enables users to build innovative, mission-critical enterprise workflows that maximize opportunity, reduce risk, and accelerate revenue. Slater explains how he came to co-found Indico Data despite a previous admission that he believed that deep learning was dead. He explains what happened that unlocked deep learning, how he was influenced by the AlexNet paper, and how Indico goes about solving the problem of unstructured data.  </p><p>Key Points From This Episode:</p><ul><li>How Slater Victoroff came to found Indico and how he came to understand the value of deep learning.</li><li>How Indico’s approach has evolved over time. </li><li>What happened that unlocked deep learning and what inspired Slater to incorrectly believe it was over before it began.</li><li>The event of the AlexNet paper published in 2012 and its influence on deep learning. </li><li>Insight into the application of deep learning at Indico and their focus on human-machine interaction.</li><li>What is meant by “solving the problem of unstructured data”.</li><li>How Indico is reducing the price of building unstructured use cases.</li><li>Thoughts on whether or not the downsizing of investment and hardware requirements of AI technology is a necessary outcome. </li><li>The surprisingly low percentage of projects that succeed. </li><li>Why Slater believes that AI today is not data-limited but compute-limited. </li><li>Why resolving compute won’t remove the need for clean annotated data.</li><li>Whether or not determining which data to prioritize is still a computer vision problem. </li><li>How the refocus into transfer learning has affected Indico’s approach. </li><li>What Slater is really excited about in the short and medium-term future of AI.</li></ul><p>Tweetables:</p><p>“Deep learning is particularly useful for these sorts of unstructured use-cases, image, text, audio. And it’s an incredibly powerful tool that allows us to attack these use cases in a way that we fundamentally weren’t able to otherwise.” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:02:44]</p><p>“By and large, AI today is not data-limited, it is compute limited. It is the only field in software that you can say that.” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:19:27]</p><p>“That’s really this next frontier though: This is where transfer learning is going next, this idea ‘Can I take visual information and language information? Can I understand that together in a comprehensive way, and then give you one interface to learn on top of that consolidated understanding of the world?’” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:26:05]</p><p>“We have gone from asking the question ‘Is transfer learning possible?’ to asking the question ‘What does it take to be the best in the world at transfer learning?’”. — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:27:03]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://arxiv.org/abs/1311.2901">"Visualizing and Understanding Convolutional Networks"</a></p><p><a href="https://www.linkedin.com/in/slatervictoroff/">Slater Victoroff</a></p><p><a href="https://twitter.com/sl8rv">Slater Victoroff on Twitter</a></p><p><a href="https://indicodata.ai/">Indico Data</a></p><p> </p>
]]></description>
      <pubDate>Thu, 24 Feb 2022 18:40:13 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/transfer-learning-solving-unstructured-data-with-indico-data-cto-slater-victoroff-YQ6gIrh_</link>
      <content:encoded><![CDATA[<p>Irrespective of the application or the technology, a common problem among AI professionals always seems to be data. Is there enough of it? What do we prioritize? Is it clean? How do we annotate it? Today’s guest, however, believes that AI is not data-limited but compute-limited. Joining us to share some very interesting insights on the subject matter is Slater Victoroff, Founder and Chief Technology Officer at Indico, an unstructured data platform that enables users to build innovative, mission-critical enterprise workflows that maximize opportunity, reduce risk, and accelerate revenue. Slater explains how he came to co-found Indico Data despite a previous admission that he believed that deep learning was dead. He explains what happened that unlocked deep learning, how he was influenced by the AlexNet paper, and how Indico goes about solving the problem of unstructured data.  </p><p>Key Points From This Episode:</p><ul><li>How Slater Victoroff came to found Indico and how he came to understand the value of deep learning.</li><li>How Indico’s approach has evolved over time. </li><li>What happened that unlocked deep learning and what inspired Slater to incorrectly believe it was over before it began.</li><li>The event of the AlexNet paper published in 2012 and its influence on deep learning. </li><li>Insight into the application of deep learning at Indico and their focus on human-machine interaction.</li><li>What is meant by “solving the problem of unstructured data”.</li><li>How Indico is reducing the price of building unstructured use cases.</li><li>Thoughts on whether or not the downsizing of investment and hardware requirements of AI technology is a necessary outcome. </li><li>The surprisingly low percentage of projects that succeed. </li><li>Why Slater believes that AI today is not data-limited but compute-limited. </li><li>Why resolving compute won’t remove the need for clean annotated data.</li><li>Whether or not determining which data to prioritize is still a computer vision problem. </li><li>How the refocus into transfer learning has affected Indico’s approach. </li><li>What Slater is really excited about in the short and medium-term future of AI.</li></ul><p>Tweetables:</p><p>“Deep learning is particularly useful for these sorts of unstructured use-cases, image, text, audio. And it’s an incredibly powerful tool that allows us to attack these use cases in a way that we fundamentally weren’t able to otherwise.” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:02:44]</p><p>“By and large, AI today is not data-limited, it is compute limited. It is the only field in software that you can say that.” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:19:27]</p><p>“That’s really this next frontier though: This is where transfer learning is going next, this idea ‘Can I take visual information and language information? Can I understand that together in a comprehensive way, and then give you one interface to learn on top of that consolidated understanding of the world?’” — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:26:05]</p><p>“We have gone from asking the question ‘Is transfer learning possible?’ to asking the question ‘What does it take to be the best in the world at transfer learning?’”. — <a href="https://twitter.com/sl8rv">@sl8rv</a> [0:27:03]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://arxiv.org/abs/1311.2901">"Visualizing and Understanding Convolutional Networks"</a></p><p><a href="https://www.linkedin.com/in/slatervictoroff/">Slater Victoroff</a></p><p><a href="https://twitter.com/sl8rv">Slater Victoroff on Twitter</a></p><p><a href="https://indicodata.ai/">Indico Data</a></p><p> </p>
]]></content:encoded>
      <enclosure length="28765662" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8931a2b1-c119-441e-828c-be2303f948c4/audio/79b0fe7b-95db-42b1-96b9-42817e2d3a1f/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Transfer Learning &amp; Solving Unstructured Data with Indico Data CTO Slater Victoroff</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:31:09</itunes:duration>
      <itunes:summary>Slater Victoroff, Founder and Chief Technology Officer at Indico Data, explains his company&apos;s approach to transfer learning, how they are solving the problem of unstructured data, and the current limitations in the field of AI.</itunes:summary>
      <itunes:subtitle>Slater Victoroff, Founder and Chief Technology Officer at Indico Data, explains his company&apos;s approach to transfer learning, how they are solving the problem of unstructured data, and the current limitations in the field of AI.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>28</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">dd7cb3cc-f33d-4a2b-a118-9fd79d094045</guid>
      <title>AI Opportunity in the Space Ecosystem with Space Foundation COO Shelli Brunswick</title>
      <description><![CDATA[<p>The innovations that drive space exploration not only aid us in discovering other worlds, but they also benefit us right here on earth. Today’s guest is Shelli Brunswick, who joins us to talk about the role of AI in space exploration and how the ‘space ecosystem’ can create jobs and career opportunities on Earth. Shelli is the COO at the Space Foundation and was selected as the 2020 Diversity and Inclusion Officer and Role Model of the Year by WomenTech Network and a Woman of Influence by the Colorado Springs Business Journal. We kick our discussion off by hearing how Shelli got to her current role and what it entails. She talks about how connected the space industry has become to many others, and how this amounts to a ‘space ecosystem’, a rich field for opportunity, innovation, and commerce. We talk about the many innovations that have stemmed from space exploration, the role they play on this planet, and the possibilities this holds as the space ecosystem continues to grow. She gets into the programs at the Space Foundation to encourage entrepreneurship and the ways that innovators can direct their efforts to participate in the space ecosystem. We also explore the many ways that AI plays a role in the space ecosystem and how the AI being utilized across industries on earth will find later applications in space. Tune in today to learn more!</p><p>Key Points From This Episode:</p><ul><li>Shelli’s background and career journey to her role as COO at the Space Foundation.</li><li>What made Shelli decide that she wanted to occupy her current role.</li><li>Using space innovation to benefit us on earth; the definition of ‘space ecosystem’.</li><li>The many industries and countries that participate in the space ecosystem.</li><li>Using the Center for Innovation and Education to create diversity and opportunities across industries.</li><li>The role of AI in the growing space ecosystem; satellites, space exploration, GPS, and more.</li><li>How AI regulates hydroponic agriculture on earth and can in space too.</li><li>The many challenges of living off-world and the role AI will play.</li><li>How entrepreneurship in the context of the space ecosystem is taught at the Space Commerce Institute.</li><li>The spinoff commercialization and innovations that come from the space industry.</li><li>How AI practitioners can point their expertise and technology into the space ecosystem.</li><li>What AI will change in the world of the future and the effects of this on jobs.</li></ul><p>Tweetables:</p><p>“What we really need to do is wrap it back to how that space technology, that space innovation, that investing in space, benefits us right here on planet earth and creates jobs and career opportunities.” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:05:52]</p><p>“The sky is not the limit [for the role that] AI can play in this.” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:12:12]</p><p>“It is the Wild West. It is exciting and, if you want to be an entrepreneur, buckle in because there is an opportunity for you!” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:20:36]</p><p>“You can sit in the Space Symposium sessions and hear what are those governments investing in, what are those companies investing in, and how can you as an entrepreneur create a product or service that’s related to AI that helps them fill that capability gap?” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:22:00]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/shellibrunswick/">Shelli Brunswick on LinkedIn</a></p><p><a href="https://twitter.com/shellibrunswick">Shelli Brunswick on Twitter</a></p><p><a href="https://www.spacefoundation.org/">The Space Foundation</a></p><p><a href="https://www.spacefoundation.org/cie/">The Center for Innovation and Education</a></p><p><a href="https://www.spacesymposium.org/">Space Symposium</a></p>
]]></description>
      <pubDate>Thu, 17 Feb 2022 07:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/ai-opportunity-in-the-space-ecosystem-with-space-foundation-coo-shelli-brunswick-hgNMDXvf</link>
      <content:encoded><![CDATA[<p>The innovations that drive space exploration not only aid us in discovering other worlds, but they also benefit us right here on earth. Today’s guest is Shelli Brunswick, who joins us to talk about the role of AI in space exploration and how the ‘space ecosystem’ can create jobs and career opportunities on Earth. Shelli is the COO at the Space Foundation and was selected as the 2020 Diversity and Inclusion Officer and Role Model of the Year by WomenTech Network and a Woman of Influence by the Colorado Springs Business Journal. We kick our discussion off by hearing how Shelli got to her current role and what it entails. She talks about how connected the space industry has become to many others, and how this amounts to a ‘space ecosystem’, a rich field for opportunity, innovation, and commerce. We talk about the many innovations that have stemmed from space exploration, the role they play on this planet, and the possibilities this holds as the space ecosystem continues to grow. She gets into the programs at the Space Foundation to encourage entrepreneurship and the ways that innovators can direct their efforts to participate in the space ecosystem. We also explore the many ways that AI plays a role in the space ecosystem and how the AI being utilized across industries on earth will find later applications in space. Tune in today to learn more!</p><p>Key Points From This Episode:</p><ul><li>Shelli’s background and career journey to her role as COO at the Space Foundation.</li><li>What made Shelli decide that she wanted to occupy her current role.</li><li>Using space innovation to benefit us on earth; the definition of ‘space ecosystem’.</li><li>The many industries and countries that participate in the space ecosystem.</li><li>Using the Center for Innovation and Education to create diversity and opportunities across industries.</li><li>The role of AI in the growing space ecosystem; satellites, space exploration, GPS, and more.</li><li>How AI regulates hydroponic agriculture on earth and can in space too.</li><li>The many challenges of living off-world and the role AI will play.</li><li>How entrepreneurship in the context of the space ecosystem is taught at the Space Commerce Institute.</li><li>The spinoff commercialization and innovations that come from the space industry.</li><li>How AI practitioners can point their expertise and technology into the space ecosystem.</li><li>What AI will change in the world of the future and the effects of this on jobs.</li></ul><p>Tweetables:</p><p>“What we really need to do is wrap it back to how that space technology, that space innovation, that investing in space, benefits us right here on planet earth and creates jobs and career opportunities.” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:05:52]</p><p>“The sky is not the limit [for the role that] AI can play in this.” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:12:12]</p><p>“It is the Wild West. It is exciting and, if you want to be an entrepreneur, buckle in because there is an opportunity for you!” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:20:36]</p><p>“You can sit in the Space Symposium sessions and hear what are those governments investing in, what are those companies investing in, and how can you as an entrepreneur create a product or service that’s related to AI that helps them fill that capability gap?” — <a href="https://twitter.com/shellibrunswick">@shellibrunswick</a> [0:22:00]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/shellibrunswick/">Shelli Brunswick on LinkedIn</a></p><p><a href="https://twitter.com/shellibrunswick">Shelli Brunswick on Twitter</a></p><p><a href="https://www.spacefoundation.org/">The Space Foundation</a></p><p><a href="https://www.spacefoundation.org/cie/">The Center for Innovation and Education</a></p><p><a href="https://www.spacesymposium.org/">Space Symposium</a></p>
]]></content:encoded>
      <enclosure length="27809437" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/0692575b-70e3-40b7-9b27-a6a4b3b06024/audio/797f9360-4b6c-470f-9efd-cdb80969874f/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>AI Opportunity in the Space Ecosystem with Space Foundation COO Shelli Brunswick</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:58</itunes:duration>
      <itunes:summary>The innovation that drives space exploration not only aid us in discovering other worlds, but also benefit us right here on earth. Today’s guest is Shelli Brunswick, who joins us to talk about the role of AI in space exploration and how the ‘space ecosystem’ can create jobs and career opportunities on Earth. Shelli is the COO at the Space Foundation and was selected as the 2020 Diversity and Inclusion Officer and Role Model of the Year by WomenTech Network and a Woman of Influence by the Colorado Springs Business Journal. </itunes:summary>
      <itunes:subtitle>The innovation that drives space exploration not only aid us in discovering other worlds, but also benefit us right here on earth. Today’s guest is Shelli Brunswick, who joins us to talk about the role of AI in space exploration and how the ‘space ecosystem’ can create jobs and career opportunities on Earth. Shelli is the COO at the Space Foundation and was selected as the 2020 Diversity and Inclusion Officer and Role Model of the Year by WomenTech Network and a Woman of Influence by the Colorado Springs Business Journal. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>27</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">1c2ed2c0-9264-4746-8e9c-dbc0e0f4b89d</guid>
      <title>Autonomous Vehicles&apos; Impact on Cities with Lyft&apos;s Sarah Barnes</title>
      <description><![CDATA[<p>A future filled with autonomous vehicles promises to be a driving utopia. Maximum efficiency navigation decreasing traffic and congestion, safety features that drastically reduce collisions with other cars, bikes, or pedestrians, and an electric-first approach that lowers greenhouse gas emissions.</p><p> </p><p>But as today’s guest asserts, on the back of her extensive research the implications of a huge increase in autonomous vehicles on our streets aren’t rosy by default. Sarah Barnes works on the micro-mobility team at Lyft, and has published a variety of works that document the expected implications of more autonomous vehicles in major metropolitan areas— implications that are good, bad, and ugly. Sarah argues that without a serious focus on three transport revolutions—making transport shared, electric, AND autonomous, congestion and pollution could be here to stay. Sarah walks me through what the various implications are, and how local governments and AI practitioners can partner on policy and technology to create a future that works for everyone.</p><p> </p>
]]></description>
      <pubDate>Thu, 10 Feb 2022 07:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/autonomous-vehicles-impact-on-cityscapes-with-lyfts-sarah-barnes-AWKkBLx6</link>
      <content:encoded><![CDATA[<p>A future filled with autonomous vehicles promises to be a driving utopia. Maximum efficiency navigation decreasing traffic and congestion, safety features that drastically reduce collisions with other cars, bikes, or pedestrians, and an electric-first approach that lowers greenhouse gas emissions.</p><p> </p><p>But as today’s guest asserts, on the back of her extensive research the implications of a huge increase in autonomous vehicles on our streets aren’t rosy by default. Sarah Barnes works on the micro-mobility team at Lyft, and has published a variety of works that document the expected implications of more autonomous vehicles in major metropolitan areas— implications that are good, bad, and ugly. Sarah argues that without a serious focus on three transport revolutions—making transport shared, electric, AND autonomous, congestion and pollution could be here to stay. Sarah walks me through what the various implications are, and how local governments and AI practitioners can partner on policy and technology to create a future that works for everyone.</p><p> </p>
]]></content:encoded>
      <enclosure length="33064829" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/7dd90aa3-4614-46eb-a04f-c8bc742b6d91/audio/3e3f17c7-1057-427d-8124-8c311e56c083/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Autonomous Vehicles&apos; Impact on Cities with Lyft&apos;s Sarah Barnes</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:34:26</itunes:duration>
      <itunes:summary>A future filled with autonomous vehicles promises to be a driving utopia. But as today’s guest asserts, on the back of her extensive research the implications of a huge increase in autonomous vehicles on our streets aren’t rosy by default. Sarah walks me through what the various implications are, and how local governments and AI practitioners can partner on policy and technology to create a future that works for everyone.
</itunes:summary>
      <itunes:subtitle>A future filled with autonomous vehicles promises to be a driving utopia. But as today’s guest asserts, on the back of her extensive research the implications of a huge increase in autonomous vehicles on our streets aren’t rosy by default. Sarah walks me through what the various implications are, and how local governments and AI practitioners can partner on policy and technology to create a future that works for everyone.
</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>26</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">dc82f88b-0647-4017-8364-13a00b82190c</guid>
      <title>The Opportunity of NLG with Arria CTO Neil Burnett</title>
      <description><![CDATA[<p>Arria is a Natural Language Generation company that replicates the human process of expertly analyzing and communicating data insights. We caught up with their CTO, Neil Burnett, to learn more about how Arria's technology goes beyond the standard rules-based NLP approach, as well as how the technology develops and grows once it's placed in the hands of the consumer. Neil explains the huge opportunity within NLG, and how solving for seamless language based communication between humans and machines will result in increased trust and widespread adoption in AI/ML technologies.</p>
]]></description>
      <pubDate>Thu, 3 Feb 2022 07:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/the-opportunity-of-nlg-with-arria-cto-neil-burnett-kmUWSGqh</link>
      <content:encoded><![CDATA[<p>Arria is a Natural Language Generation company that replicates the human process of expertly analyzing and communicating data insights. We caught up with their CTO, Neil Burnett, to learn more about how Arria's technology goes beyond the standard rules-based NLP approach, as well as how the technology develops and grows once it's placed in the hands of the consumer. Neil explains the huge opportunity within NLG, and how solving for seamless language based communication between humans and machines will result in increased trust and widespread adoption in AI/ML technologies.</p>
]]></content:encoded>
      <enclosure length="25981559" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/51e768e3-22ea-4836-87d0-6608d0279196/audio/d7922c05-0c48-4e99-babd-e0351d39d8ab/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>The Opportunity of NLG with Arria CTO Neil Burnett</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:29</itunes:duration>
      <itunes:summary>Arria CTO Neil Burnett explains how advances in NLG will develop trust and more widespread adoption in AI Technologies.</itunes:summary>
      <itunes:subtitle>Arria CTO Neil Burnett explains how advances in NLG will develop trust and more widespread adoption in AI Technologies.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>25</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">ed2e2981-1639-4956-ae78-b7d925ce7bfc</guid>
      <title>Developing Solid State LiDAR with Baraja CTO Cibby Pulikkaseril</title>
      <description><![CDATA[<p>Traditional LiDAR systems require moving parts to operate, making them less cost-effective, robust, and safe. Cibby Pulikkaseril is the Founder and CTO of Baraja, a company that has reinvented LiDAR for self-driving vehicles by using a color-changing laser routed by a prism. After his Ph.D. in lasers and fiber optic communications, Cibby got a job at a telecom equipment company, and that is when he discovered that a laser used in DWDM networks could be used to reinvent LiDAR. By joining this conversation, you’ll hear exactly how Baraja’s LiDAR technology works and what this means for the future of autonomous vehicles. Cibby also talks about some of the upcoming challenges we will face in the world of self-driving cars and the solutions his innovation offers. Furthermore, Cibby explains what spectrum scan LiDAR can offer the field of robotics more broadly. </p><p>Key Points From This Episode:</p><ul><li>Cibby’s background in fiber optic communications and what led him to found Baraja.</li><li>Realizing that a laser used in DWDM networks could be applied to LiDAR. </li><li>Why Cibby decided that autonomous vehicles (AVs) were a good application for the laser.</li><li>How the laser used by Baraja can steer a LiDAR beam without any moving parts thus making the system cheaper.</li><li>Velodyne’s contributions and other innovations in the LiDAR space.</li><li>A description of how the spectrum scan LiDAR works using a color-changing laser routed by a prism.</li><li>The infinite resolution made possible by colored light and how AI will make use of it.</li><li>Hazards around the over-proliferation of conventional LiDAR laser and how Baraja’s tech gets past this.</li><li>Other challenges Cibby predicts will exist once AVs start to proliferate.</li><li>How Baraja’s solid-state LiDAR technology will advance other fields of robotics.</li><li>Cibby’s level of involvement in the coding and R&D at Baraja as the CTO.</li><li>Technical areas that the Baraja team is researching and developing such as homodyne detection.</li><li>Advice from Cibby for how to innovate in the already cutting-edge space of computer vision.</li></ul><p> </p><p>Tweetables:</p><p>“We started to think, what else could we do with it. The insight was that if we could get the laser light out of the fiber and into free space, then we could start doing LiDAR.” — Cibby Pulikkaseril [0:01:23]</p><p>“We were excited by this idea that there was going to be a change in the future of mobility and we can be a part of that wave.” — Cibby Pulikkaseril [0:02:13]</p><p>“We are the inventors of what we call spectrum scan LiDAR that is harnessing the natural phenomenon of the color of light to be able to steer a beam without any moving parts.” — Cibby Pulikkaseril [0:03:37]</p><p>“We had this insight which is that if you can change the color of light very rapidly, by coupling that into prism-like optics, this can route the wavelengths based on the color and so you can steer a beam without any moving parts.” — Cibby Pulikkaseril [0:03:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/cibbyp/?originalSubdomain=au">Cibby Pulikkaseril on LinkedIn</a></p><p><a href="https://www.baraja.com/en">Baraja</a></p><p> </p>
]]></description>
      <pubDate>Mon, 20 Dec 2021 07:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/developing-solid-state-lidar-with-baraja-cto-cibby-pulikkaseril-1KhRLR6O</link>
      <content:encoded><![CDATA[<p>Traditional LiDAR systems require moving parts to operate, making them less cost-effective, robust, and safe. Cibby Pulikkaseril is the Founder and CTO of Baraja, a company that has reinvented LiDAR for self-driving vehicles by using a color-changing laser routed by a prism. After his Ph.D. in lasers and fiber optic communications, Cibby got a job at a telecom equipment company, and that is when he discovered that a laser used in DWDM networks could be used to reinvent LiDAR. By joining this conversation, you’ll hear exactly how Baraja’s LiDAR technology works and what this means for the future of autonomous vehicles. Cibby also talks about some of the upcoming challenges we will face in the world of self-driving cars and the solutions his innovation offers. Furthermore, Cibby explains what spectrum scan LiDAR can offer the field of robotics more broadly. </p><p>Key Points From This Episode:</p><ul><li>Cibby’s background in fiber optic communications and what led him to found Baraja.</li><li>Realizing that a laser used in DWDM networks could be applied to LiDAR. </li><li>Why Cibby decided that autonomous vehicles (AVs) were a good application for the laser.</li><li>How the laser used by Baraja can steer a LiDAR beam without any moving parts thus making the system cheaper.</li><li>Velodyne’s contributions and other innovations in the LiDAR space.</li><li>A description of how the spectrum scan LiDAR works using a color-changing laser routed by a prism.</li><li>The infinite resolution made possible by colored light and how AI will make use of it.</li><li>Hazards around the over-proliferation of conventional LiDAR laser and how Baraja’s tech gets past this.</li><li>Other challenges Cibby predicts will exist once AVs start to proliferate.</li><li>How Baraja’s solid-state LiDAR technology will advance other fields of robotics.</li><li>Cibby’s level of involvement in the coding and R&D at Baraja as the CTO.</li><li>Technical areas that the Baraja team is researching and developing such as homodyne detection.</li><li>Advice from Cibby for how to innovate in the already cutting-edge space of computer vision.</li></ul><p> </p><p>Tweetables:</p><p>“We started to think, what else could we do with it. The insight was that if we could get the laser light out of the fiber and into free space, then we could start doing LiDAR.” — Cibby Pulikkaseril [0:01:23]</p><p>“We were excited by this idea that there was going to be a change in the future of mobility and we can be a part of that wave.” — Cibby Pulikkaseril [0:02:13]</p><p>“We are the inventors of what we call spectrum scan LiDAR that is harnessing the natural phenomenon of the color of light to be able to steer a beam without any moving parts.” — Cibby Pulikkaseril [0:03:37]</p><p>“We had this insight which is that if you can change the color of light very rapidly, by coupling that into prism-like optics, this can route the wavelengths based on the color and so you can steer a beam without any moving parts.” — Cibby Pulikkaseril [0:03:57]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/cibbyp/?originalSubdomain=au">Cibby Pulikkaseril on LinkedIn</a></p><p><a href="https://www.baraja.com/en">Baraja</a></p><p> </p>
]]></content:encoded>
      <enclosure length="22626393" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/fa30165d-9a9f-457a-90dc-565447f4d260/audio/30d5147d-f744-4d66-b5b7-4380ace82c10/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Developing Solid State LiDAR with Baraja CTO Cibby Pulikkaseril</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:23:35</itunes:duration>
      <itunes:summary>Traditional LiDAR systems require moving parts to operate, making them less cost-effective, robust, and safe. Cibby Pulikkaseril is the Founder and CTO of Baraja, a company that has reinvented LiDAR for self-driving vehicles by using a color-changing laser routed by a prism. After his Ph.D. in lasers and fiber optic communications, Cibby got a job at a telecom equipment company, and that is when he discovered that a laser used in DWDM networks could be used to reinvent LiDAR. By joining this conversation, you’ll hear exactly how Baraja’s LiDAR technology works and what this means for the future of autonomous vehicles. Cibby also talks about some of the upcoming challenges we will face in the world of self-driving cars and the solutions his innovation offers. Furthermore, Cibby explains what spectrum scan LiDAR can offer the field of robotics more broadly. </itunes:summary>
      <itunes:subtitle>Traditional LiDAR systems require moving parts to operate, making them less cost-effective, robust, and safe. Cibby Pulikkaseril is the Founder and CTO of Baraja, a company that has reinvented LiDAR for self-driving vehicles by using a color-changing laser routed by a prism. After his Ph.D. in lasers and fiber optic communications, Cibby got a job at a telecom equipment company, and that is when he discovered that a laser used in DWDM networks could be used to reinvent LiDAR. By joining this conversation, you’ll hear exactly how Baraja’s LiDAR technology works and what this means for the future of autonomous vehicles. Cibby also talks about some of the upcoming challenges we will face in the world of self-driving cars and the solutions his innovation offers. Furthermore, Cibby explains what spectrum scan LiDAR can offer the field of robotics more broadly. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>24</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">55c804a5-1b66-400c-81a3-36840863a9c3</guid>
      <title>Building Trustworthy Behaviomedics with Blueskeye CEO Michel Valstar</title>
      <description><![CDATA[<p>Academic turned entrepreneur Michel Valstar joins How AI Happens to explain how his behaviomedics company, Blueskeye AI, prioritizes building trust with their users. Much of the approach features data opt-ins and on-device processing, which necessarily results in less data collection. Michel explains how his team is able to continue gleaning meaningful insight from smaller portions of data than your average AI practitioner is used to.</p><p> </p><p><a href="https://www.linkedin.com/in/michel-valstar-692b345/">Michel Valstar</a> on LinkedIn</p><p><a href="https://www.blueskeye.com/" target="_blank">Blueskeye AI</a></p>
]]></description>
      <pubDate>Thu, 11 Nov 2021 07:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/building-trustworthy-behaviomedics-with-blueskeye-ceo-michel-valstar-J2Zf3pMi</link>
      <content:encoded><![CDATA[<p>Academic turned entrepreneur Michel Valstar joins How AI Happens to explain how his behaviomedics company, Blueskeye AI, prioritizes building trust with their users. Much of the approach features data opt-ins and on-device processing, which necessarily results in less data collection. Michel explains how his team is able to continue gleaning meaningful insight from smaller portions of data than your average AI practitioner is used to.</p><p> </p><p><a href="https://www.linkedin.com/in/michel-valstar-692b345/">Michel Valstar</a> on LinkedIn</p><p><a href="https://www.blueskeye.com/" target="_blank">Blueskeye AI</a></p>
]]></content:encoded>
      <enclosure length="16332185" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/0b3fba0f-f962-4bb5-8b77-d2b515e077e1/audio/1a4a1279-1646-418f-a304-73b6966d6560/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Building Trustworthy Behaviomedics with Blueskeye CEO Michel Valstar</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:22:35</itunes:duration>
      <itunes:summary>Academic turned entrepreneur Michel Valstar joins How AI Happens to explain how his behaviomedics company, Blueskeye AI, prioritizes building trust with their users. Much of the approach features data opt-ins and on-device processing, which necessarily results in less data collection. Michel explains how his team is able to continue gleaning meaningful insight from smaller portions of data than your average AI practitioner is used to.</itunes:summary>
      <itunes:subtitle>Academic turned entrepreneur Michel Valstar joins How AI Happens to explain how his behaviomedics company, Blueskeye AI, prioritizes building trust with their users. Much of the approach features data opt-ins and on-device processing, which necessarily results in less data collection. Michel explains how his team is able to continue gleaning meaningful insight from smaller portions of data than your average AI practitioner is used to.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>23</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">7cc81138-2f59-401f-b023-c3fe25b51faa</guid>
      <title>Egocentric Perception with Facebook&apos;s Manohar Paluri</title>
      <description><![CDATA[<p>Joining us today is Senior Director at Facebook AI, Manohar Paluri. Mano discusses the biggest challenges facing the field of computer vision, and the commonalities and differences between first and third-person perception. Manohar dives into the complexity of detecting first-person perception, and how to overcome the privacy and ethical issues of egocentric technology. Manohar breaks down the mechanism underlying AI based on decision trees compared to those based on real-world data, and how they result in two different ideals: transparency or accuracy. </p><p>Key Points From This Episode:</p><ul><li>Talking to Manohar Paluri, his background in IT, and how he wound up at Facebook AI. </li><li>Manohar's advice on the pros and cons of doing a Ph.D.</li><li>Why computer vision is so complex for machines but so simple for humans. </li><li>Why the term “computer vision” is not a limiting definition in terms of the sensors used.</li><li>How computer vision and perception differ. </li><li>The two problems facing computer vision: recognizing entities and augmenting perception. </li><li>Personalized data; generalized learning ability; and adaptability: the three problems that are responsible for the low number of entities that computer vision recognizes.</li><li>Managing the direction Manohar's organization is going: egocentric vision, predicting the impact of modeling, and finding the balance between transparency and accuracy. </li><li>Find out what the differences are between first- and third-person perception: intention, positioning, and long-form reasoning. </li><li>The similarity between first- and third-person perception: both are trying to understand the world.</li><li>Which sensors are required to predict intention: gaze and hand-object-interaction. </li><li>What the privacy and ethical issues are with regard to egocentric technologies. </li><li>Why Manohar believes striking a balance between accuracy and transparency will set the standard. </li><li>The three prospects in AI that excite Manohar the most: the next computing platform, bringing different modalities together, and improved access to technology. </li></ul><p> </p><p>Tweetables:</p><p>“What I tell many of the new graduates when they come and ask me about ‘Should I do my Ph.D. or not?’ I tell them that ‘You’re asking the wrong question’. Because it doesn’t matter whether you do a Ph.D. or you don’t do a Ph.D., the path and the journey is going to be as long for anybody to take you seriously on the research side.” — Manohar Paluri [0:02:40]</p><p>“Just to give you a sense, there are billions of entities in the world. The best of the computer vision systems today can recognize in the order of tens of thousands or hundreds of thousands, not even a million. So abandoning the problem of core computer vision and jumping into perception would be a mistake in my opinion. There is a lot of work we still need to do in making machines understand this billion entity taxonomy.” — Manohar Paluri [0:11:33]</p><p>“We are in the research part of the organization, so whatever we are doing, it’s not like we are building something to launch over the next few months or a year, we are trying to ask ourselves how does the world look like three, five, ten years from now and what are the technological problems?” — Manohar Paluri [0:20:00]</p><p>“So my hope is, once you set a standard on transparency while maintaining the accuracy, it will be very hard for anybody to justify why they would not use such a model compared to a more black-box model for a little bit more gain in accuracy.” — Manohar Paluri [0:32:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/balamanohar/">Manohar Paluri on LinkedIn</a></p><p><a href="https://ai.facebook.com/">Facebook AI Research Website</a></p><p><a href="https://ai.facebook.com/tools/ego4d">Facebook AI Website: Ego4D</a></p>
]]></description>
      <pubDate>Fri, 5 Nov 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/egocentric-perception-with-facebooks-manohar-paluri-MT_2yS8F</link>
      <content:encoded><![CDATA[<p>Joining us today is Senior Director at Facebook AI, Manohar Paluri. Mano discusses the biggest challenges facing the field of computer vision, and the commonalities and differences between first and third-person perception. Manohar dives into the complexity of detecting first-person perception, and how to overcome the privacy and ethical issues of egocentric technology. Manohar breaks down the mechanism underlying AI based on decision trees compared to those based on real-world data, and how they result in two different ideals: transparency or accuracy. </p><p>Key Points From This Episode:</p><ul><li>Talking to Manohar Paluri, his background in IT, and how he wound up at Facebook AI. </li><li>Manohar's advice on the pros and cons of doing a Ph.D.</li><li>Why computer vision is so complex for machines but so simple for humans. </li><li>Why the term “computer vision” is not a limiting definition in terms of the sensors used.</li><li>How computer vision and perception differ. </li><li>The two problems facing computer vision: recognizing entities and augmenting perception. </li><li>Personalized data; generalized learning ability; and adaptability: the three problems that are responsible for the low number of entities that computer vision recognizes.</li><li>Managing the direction Manohar's organization is going: egocentric vision, predicting the impact of modeling, and finding the balance between transparency and accuracy. </li><li>Find out what the differences are between first- and third-person perception: intention, positioning, and long-form reasoning. </li><li>The similarity between first- and third-person perception: both are trying to understand the world.</li><li>Which sensors are required to predict intention: gaze and hand-object-interaction. </li><li>What the privacy and ethical issues are with regard to egocentric technologies. </li><li>Why Manohar believes striking a balance between accuracy and transparency will set the standard. </li><li>The three prospects in AI that excite Manohar the most: the next computing platform, bringing different modalities together, and improved access to technology. </li></ul><p> </p><p>Tweetables:</p><p>“What I tell many of the new graduates when they come and ask me about ‘Should I do my Ph.D. or not?’ I tell them that ‘You’re asking the wrong question’. Because it doesn’t matter whether you do a Ph.D. or you don’t do a Ph.D., the path and the journey is going to be as long for anybody to take you seriously on the research side.” — Manohar Paluri [0:02:40]</p><p>“Just to give you a sense, there are billions of entities in the world. The best of the computer vision systems today can recognize in the order of tens of thousands or hundreds of thousands, not even a million. So abandoning the problem of core computer vision and jumping into perception would be a mistake in my opinion. There is a lot of work we still need to do in making machines understand this billion entity taxonomy.” — Manohar Paluri [0:11:33]</p><p>“We are in the research part of the organization, so whatever we are doing, it’s not like we are building something to launch over the next few months or a year, we are trying to ask ourselves how does the world look like three, five, ten years from now and what are the technological problems?” — Manohar Paluri [0:20:00]</p><p>“So my hope is, once you set a standard on transparency while maintaining the accuracy, it will be very hard for anybody to justify why they would not use such a model compared to a more black-box model for a little bit more gain in accuracy.” — Manohar Paluri [0:32:55]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/balamanohar/">Manohar Paluri on LinkedIn</a></p><p><a href="https://ai.facebook.com/">Facebook AI Research Website</a></p><p><a href="https://ai.facebook.com/tools/ego4d">Facebook AI Website: Ego4D</a></p>
]]></content:encoded>
      <enclosure length="38603701" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/65b36d44-0edb-438a-a6ce-533f1d40c02f/audio/4e7780bf-e1f5-4420-b8f9-534824c3b72d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Egocentric Perception with Facebook&apos;s Manohar Paluri</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:42:24</itunes:duration>
      <itunes:summary>Joining us today is Senior Director at Facebook AI, Manohar Paluri. Mano discusses the biggest challenges facing the field of computer vision, and the commonalities and differences between first and third-person perception. Manohar dives into the complexity of detecting first-person perception, and how to overcome the privacy and ethical issues of egocentric technology. Manohar breaks down the mechanism underlying AI based on decision trees compared to those based on real-world data, and how they result in two different ideals: transparency or accuracy. </itunes:summary>
      <itunes:subtitle>Joining us today is Senior Director at Facebook AI, Manohar Paluri. Mano discusses the biggest challenges facing the field of computer vision, and the commonalities and differences between first and third-person perception. Manohar dives into the complexity of detecting first-person perception, and how to overcome the privacy and ethical issues of egocentric technology. Manohar breaks down the mechanism underlying AI based on decision trees compared to those based on real-world data, and how they result in two different ideals: transparency or accuracy. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>22</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">d2446c40-10cf-476d-8608-e3a101711098</guid>
      <title>Responsible AI Economics with Katya Klinova &amp; The Partnership on AI</title>
      <description><![CDATA[<p>In recent years, the focus of AI developers has been to implement technologies that replace basic human labor. Talking to us today about why this is the wrong application for AI (right now), is Katya Klinova, the Head of AI, Labor, and the Economy at The Partnership on AI. Tune in to find out why replacing human labor doesn't benefit the whole of humanity, and what our focus should be instead.  We delve into the threat of "so-so technologies" and what the developer's role should be in approaching ethical vendors and looking after the workers supplying them with data. Join us to find out more about how AI can be used to better the whole of society if there’s a shift in the field’s current aims.</p><p> </p><p>Key Points From This Episode:</p><ul><li>An introduction to Katya Klinova, Head of Al, Labor and the Economy at The Partnership on AI.</li><li>How her expectations of the world after her undergraduate degree shaped her.</li><li>Pursuing a degree in economics to understand how AI impacts labor and economics.</li><li>The role of The Partnership on AI in dissipating technological gains.</li><li>Who is impacted when AI is introduced to a market: the consumers and the workers.</li><li>How different companies are deficient in the ways they benefit everyone. </li><li>Find out what the “threat of so-so technology” is.</li><li>Should people become shareholders in AI technology that they helped to train?</li><li>How capitalism incentivizes “so-so technologies”. </li><li>The role of developers in selecting vendors and responsible sourcing. </li><li>Why it's important to realize that data labelers are employees and not just numbers.</li><li>Shifting the focus of AI from automation to complementarity. </li><li>Why now is not the time to be replacing human labor. </li></ul><p> </p><p>Tweetables:</p><p>“Creating AI that benefits all is actually a very large commitment and a statement, and I don't think many companies have really realized or thought through what they're actually saying in the economic terms when they're subscribing to something like that.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:09:45]</p><p> </p><p>"It’s not that you want to avoid all kinds of automation, no matter what. Automation, at the end of the day, has been the force that lifted living conditions and incomes around the world, and has been around for much longer than AI." — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:11:28]</p><p> </p><p>“We compensate people for the task or for their time, but we are not necessarily compensating them for the data that they generate that we use to train models that can displace their jobs in the future.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:14:49]</p><p> </p><p>"Might we be automating too much for the kind of labor market needs that we have right now?" — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:23:14]</p><p> </p><p>”It’s not the time to eliminate all of the jobs that we possibly can. It’s not the time to create machines that can match humans in everything that they do, but that’s what we are doing.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:24:50]</p><p> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/katyaklinova/">Katya Klinova on LinkedIn</a></p><p>"<a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.33.2.3">Automation and New Tasks: How Technology Displaces and Reinstates Labor</a>"</p><p><a href="https://partnershiponai.org/workstream/responsible-sourcing/">The Partnership on AI: Responsible Sourcing</a></p>
]]></description>
      <pubDate>Thu, 28 Oct 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/responsible-ai-economics-with-katya-klinova-the-partnership-on-ai-u3DnhR36</link>
      <content:encoded><![CDATA[<p>In recent years, the focus of AI developers has been to implement technologies that replace basic human labor. Talking to us today about why this is the wrong application for AI (right now), is Katya Klinova, the Head of AI, Labor, and the Economy at The Partnership on AI. Tune in to find out why replacing human labor doesn't benefit the whole of humanity, and what our focus should be instead.  We delve into the threat of "so-so technologies" and what the developer's role should be in approaching ethical vendors and looking after the workers supplying them with data. Join us to find out more about how AI can be used to better the whole of society if there’s a shift in the field’s current aims.</p><p> </p><p>Key Points From This Episode:</p><ul><li>An introduction to Katya Klinova, Head of Al, Labor and the Economy at The Partnership on AI.</li><li>How her expectations of the world after her undergraduate degree shaped her.</li><li>Pursuing a degree in economics to understand how AI impacts labor and economics.</li><li>The role of The Partnership on AI in dissipating technological gains.</li><li>Who is impacted when AI is introduced to a market: the consumers and the workers.</li><li>How different companies are deficient in the ways they benefit everyone. </li><li>Find out what the “threat of so-so technology” is.</li><li>Should people become shareholders in AI technology that they helped to train?</li><li>How capitalism incentivizes “so-so technologies”. </li><li>The role of developers in selecting vendors and responsible sourcing. </li><li>Why it's important to realize that data labelers are employees and not just numbers.</li><li>Shifting the focus of AI from automation to complementarity. </li><li>Why now is not the time to be replacing human labor. </li></ul><p> </p><p>Tweetables:</p><p>“Creating AI that benefits all is actually a very large commitment and a statement, and I don't think many companies have really realized or thought through what they're actually saying in the economic terms when they're subscribing to something like that.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:09:45]</p><p> </p><p>"It’s not that you want to avoid all kinds of automation, no matter what. Automation, at the end of the day, has been the force that lifted living conditions and incomes around the world, and has been around for much longer than AI." — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:11:28]</p><p> </p><p>“We compensate people for the task or for their time, but we are not necessarily compensating them for the data that they generate that we use to train models that can displace their jobs in the future.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:14:49]</p><p> </p><p>"Might we be automating too much for the kind of labor market needs that we have right now?" — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:23:14]</p><p> </p><p>”It’s not the time to eliminate all of the jobs that we possibly can. It’s not the time to create machines that can match humans in everything that they do, but that’s what we are doing.” — <a href="https://twitter.com/klinovakatya">@klinovakatya</a> [0:24:50]</p><p> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/katyaklinova/">Katya Klinova on LinkedIn</a></p><p>"<a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.33.2.3">Automation and New Tasks: How Technology Displaces and Reinstates Labor</a>"</p><p><a href="https://partnershiponai.org/workstream/responsible-sourcing/">The Partnership on AI: Responsible Sourcing</a></p>
]]></content:encoded>
      <enclosure length="25160357" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/b003df66-bbad-46de-91be-4a08df3a3339/audio/9928e90a-a59c-4327-b656-753d1374190c/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Responsible AI Economics with Katya Klinova &amp; The Partnership on AI</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:29:10</itunes:duration>
      <itunes:summary>In recent years, the focus of AI developers has been to implement technologies that replace basic human labor. Talking to us today about why this is the wrong application for AI is Katya Klinova, the Head of AI, Labor, and the Economy at The Partnership on AI. Tune in to find out why replacing human labor doesn&apos;t benefit the whole of humanity, and what our focus should be instead.  We delve into the threat of &quot;so-so technologies&quot; and what the developer&apos;s role should be in approaching ethical vendors and looking after the workers supplying them with data. Join us to find out more about how AI can be used to better the whole of society if there’s a shift in the field’s current aims.</itunes:summary>
      <itunes:subtitle>In recent years, the focus of AI developers has been to implement technologies that replace basic human labor. Talking to us today about why this is the wrong application for AI is Katya Klinova, the Head of AI, Labor, and the Economy at The Partnership on AI. Tune in to find out why replacing human labor doesn&apos;t benefit the whole of humanity, and what our focus should be instead.  We delve into the threat of &quot;so-so technologies&quot; and what the developer&apos;s role should be in approaching ethical vendors and looking after the workers supplying them with data. Join us to find out more about how AI can be used to better the whole of society if there’s a shift in the field’s current aims.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>21</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">fb0c9066-b2b6-41fd-8389-37586d1028a7</guid>
      <title>Moxie the Robot &amp; Embodied CTO Stefan Scherer</title>
      <description><![CDATA[<p>In this episode, we talk to Stefan Scherer (CTO of Embodied) about why he decided to focus on the more nuanced challenge of developing children’s social-emotional skills. Stefan takes us through how encouraging children to mentor Moxie (a friendly robot) through social interaction helps them develop their interpersonal relationships. We dive into the relevance of scripted versus unscripted conversation in different AI technologies, and how Embodied taught Moxie to define abstract concepts such as "kindness". </p><p>Key Points From This Episode:</p><ul><li>Welcome to Stefan Scherer, CTO of Embodied and lead researcher and developer of Embodied's SocialX™ technology, Moxie.</li><li>The goal of Embodied: using a natural mode of communication to support children’s social development. </li><li>Mentoring Moxie: how Moxie teaches children social-emotional learning without being a teacher. </li><li>Why Stefan and Embodied focused on the challenge of social-emotional skills, not STEM. </li><li>Developing a technology that captures the infinite answers to social-emotional questions: using neural networks and sentiment analysis.</li><li>How using Few-shot learning reduced the amount of data needed to train Moxie.</li><li>Why it's important to make the transition between freer- and scripted conversations seamless.</li><li>How the percentage of scripted versus non-scripted conversation differs based on the context of the technology.  </li><li>Discover how Moxie adapts to children’s changing needs and desires. </li><li>How Moxie as a springboard in teaching children to form long-term relationships. </li><li>The hardware behind Moxie: the ethical considerations around home devices, and data protection.</li><li>Why Moxie looks the way it does: making it affordable. </li></ul><p>Tweetables:</p><p>“Human behavior is very complex, and it gives us a window into our soul. We can understand so much more than just language from human behavior, we can understand an individual's wellbeing and their abilities to communicate with others.” — Stefan Scherer [0:01:04]</p><p>"It is not sufficient to work on the easy challenges at first and then expand from there. No, as a startup you have to tackle the hard ones first because that's where you set yourself apart from the rest." — Stefan Scherer [0:04:53]</p><p>“Moxie comes into the world of the child with the mission to basically learn how to be a good friend to humans. And Moxie puts the child into this position of teaching Moxie about how to do that.” — Stefan Scherer [0:17:40]</p><p>"One of the most important aspects of Moxie is that Moxie doesn't serve as the destination, Moxie is really a springboard into life." — Stefan Scherer [0:18:29]</p><p>“We did not want to overengineer Moxie, we really wanted to basically afford the ability to have a conversation, to be able to multimodally interact, and yet be as frugal with the amount of concepts that we added or the amount of capabilities that we added.” — Stefan Scherer [0:27:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.youtube.com/watch?v=7YRNjclHTHg" target="_blank">See Moxie in Action</a></p><p><a href="https://www.linkedin.com/in/stefan-scherer-aa853a39/">Stefan Scherer on LinkedIn</a></p><p><a href="https://embodied.com/">Embodied Website</a></p>
]]></description>
      <pubDate>Thu, 21 Oct 2021 11:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/moxie-the-robot-embodied-cto-stefan-scherer-pngYGq6t</link>
      <content:encoded><![CDATA[<p>In this episode, we talk to Stefan Scherer (CTO of Embodied) about why he decided to focus on the more nuanced challenge of developing children’s social-emotional skills. Stefan takes us through how encouraging children to mentor Moxie (a friendly robot) through social interaction helps them develop their interpersonal relationships. We dive into the relevance of scripted versus unscripted conversation in different AI technologies, and how Embodied taught Moxie to define abstract concepts such as "kindness". </p><p>Key Points From This Episode:</p><ul><li>Welcome to Stefan Scherer, CTO of Embodied and lead researcher and developer of Embodied's SocialX™ technology, Moxie.</li><li>The goal of Embodied: using a natural mode of communication to support children’s social development. </li><li>Mentoring Moxie: how Moxie teaches children social-emotional learning without being a teacher. </li><li>Why Stefan and Embodied focused on the challenge of social-emotional skills, not STEM. </li><li>Developing a technology that captures the infinite answers to social-emotional questions: using neural networks and sentiment analysis.</li><li>How using Few-shot learning reduced the amount of data needed to train Moxie.</li><li>Why it's important to make the transition between freer- and scripted conversations seamless.</li><li>How the percentage of scripted versus non-scripted conversation differs based on the context of the technology.  </li><li>Discover how Moxie adapts to children’s changing needs and desires. </li><li>How Moxie as a springboard in teaching children to form long-term relationships. </li><li>The hardware behind Moxie: the ethical considerations around home devices, and data protection.</li><li>Why Moxie looks the way it does: making it affordable. </li></ul><p>Tweetables:</p><p>“Human behavior is very complex, and it gives us a window into our soul. We can understand so much more than just language from human behavior, we can understand an individual's wellbeing and their abilities to communicate with others.” — Stefan Scherer [0:01:04]</p><p>"It is not sufficient to work on the easy challenges at first and then expand from there. No, as a startup you have to tackle the hard ones first because that's where you set yourself apart from the rest." — Stefan Scherer [0:04:53]</p><p>“Moxie comes into the world of the child with the mission to basically learn how to be a good friend to humans. And Moxie puts the child into this position of teaching Moxie about how to do that.” — Stefan Scherer [0:17:40]</p><p>"One of the most important aspects of Moxie is that Moxie doesn't serve as the destination, Moxie is really a springboard into life." — Stefan Scherer [0:18:29]</p><p>“We did not want to overengineer Moxie, we really wanted to basically afford the ability to have a conversation, to be able to multimodally interact, and yet be as frugal with the amount of concepts that we added or the amount of capabilities that we added.” — Stefan Scherer [0:27:17]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.youtube.com/watch?v=7YRNjclHTHg" target="_blank">See Moxie in Action</a></p><p><a href="https://www.linkedin.com/in/stefan-scherer-aa853a39/">Stefan Scherer on LinkedIn</a></p><p><a href="https://embodied.com/">Embodied Website</a></p>
]]></content:encoded>
      <enclosure length="28831765" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d62c8bb1-a757-40fd-a481-e84c1c51c271/audio/18d3b043-3322-4ab2-a112-46afa343426d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Moxie the Robot &amp; Embodied CTO Stefan Scherer</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:02</itunes:duration>
      <itunes:summary>In this episode, we talk to Stefan Scherer (CTO of Embodied) about why he decided to focus on the more nuanced challenge of developing children’s social-emotional skills. Stefan takes us through how encouraging children to mentor Moxie (a friendly robot) through social interaction helps them develop their interpersonal relationships. We dive into the relevance of scripted versus unscripted conversation in different AI technologies, and how Embodied taught Moxie to define abstract concepts such as &quot;kindness&quot;. </itunes:summary>
      <itunes:subtitle>In this episode, we talk to Stefan Scherer (CTO of Embodied) about why he decided to focus on the more nuanced challenge of developing children’s social-emotional skills. Stefan takes us through how encouraging children to mentor Moxie (a friendly robot) through social interaction helps them develop their interpersonal relationships. We dive into the relevance of scripted versus unscripted conversation in different AI technologies, and how Embodied taught Moxie to define abstract concepts such as &quot;kindness&quot;. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>20</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">7c14316a-2719-407d-a0d9-eebd796a2cd8</guid>
      <title>Using AI to Accelerate Creativity with Matevž Klanjšek</title>
      <description><![CDATA[<p>Today we talk to Celtra Founder and CPO, Matevž Klanjšek, about how AI can be used to accelerate creativity, and what would happen if it eventually replaces humans in the creative space. We discuss the limitations of the tools currently available, why Matevž isn’t interested in teaching AI variance, and how humans and AI need to work together in advertising. Tune in to hear what the future of advertising looks like, and why the human-AI feedback loop is essential. Matevž tells us about the bizarre adverts he’s seen AI produce, and talks us through the evolution of human creativity: from paintings to photographs, and how humans stay relevant when we invent something new. </p><p>Key Points From This Episode:</p><ul><li>An introduction to the founder and CPO of Celtra, Matevž Klanjšek.</li><li>Where the idea of using AI in advertising came from.</li><li>How Celtra technology helps creatives scale their media, accelerating creativity.</li><li>Why AI is the right tool for the job.</li><li>Two dangers of using AI in advertising: impacting the communication strategy, and losing uniqueness.</li><li>Can you teach AI variance?</li><li>Why it’s important to leave space for human error.</li><li>Humanity in advertising: why brands are trying to be more human.</li><li>What a collaboration between humans and AI looks like.</li><li>How human genius lies in building communication strategies.</li><li>The surprising results when AI tries to create adverts.</li><li>Playing with generative design: how AI can inspire humans.</li><li>Why AI won’t replace humans in the future.</li></ul><p>Tweetables:</p><p>“It just makes sense to automate [repetitive tasks] as much as possible, and remove that from the equation, let human genius think about big ideas and communication strategies, creativity and so on.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:03:47]</p><p>“I think on all of the levels, across the creative process, we always try to have humans involved. It’s almost like a basic principle.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:14:47]</p><p>“So that’s the nice thing, actually, perhaps using pretty advanced AI to really inspire creativity in humans instead of replacing it. It’s kind of beautiful in a way.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:17:24]</p><p>"I think the whole point of advertising, and humanity in general is precisely to be always different, to invent new things." — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:18:12]</p><p>“I think technology always gets to a point where it can perfectly imitate, and do it better than humans can, but then we invent something new.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:19:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/hyperhandsome/">Matevž Klanjšek on LinkedIn</a></p><p><a href="https://celtra.com/">Celtra Technologies</a></p>
]]></description>
      <pubDate>Thu, 14 Oct 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/using-ai-to-accelerate-creativity-with-matev-klanjek-KIq1OZM3</link>
      <content:encoded><![CDATA[<p>Today we talk to Celtra Founder and CPO, Matevž Klanjšek, about how AI can be used to accelerate creativity, and what would happen if it eventually replaces humans in the creative space. We discuss the limitations of the tools currently available, why Matevž isn’t interested in teaching AI variance, and how humans and AI need to work together in advertising. Tune in to hear what the future of advertising looks like, and why the human-AI feedback loop is essential. Matevž tells us about the bizarre adverts he’s seen AI produce, and talks us through the evolution of human creativity: from paintings to photographs, and how humans stay relevant when we invent something new. </p><p>Key Points From This Episode:</p><ul><li>An introduction to the founder and CPO of Celtra, Matevž Klanjšek.</li><li>Where the idea of using AI in advertising came from.</li><li>How Celtra technology helps creatives scale their media, accelerating creativity.</li><li>Why AI is the right tool for the job.</li><li>Two dangers of using AI in advertising: impacting the communication strategy, and losing uniqueness.</li><li>Can you teach AI variance?</li><li>Why it’s important to leave space for human error.</li><li>Humanity in advertising: why brands are trying to be more human.</li><li>What a collaboration between humans and AI looks like.</li><li>How human genius lies in building communication strategies.</li><li>The surprising results when AI tries to create adverts.</li><li>Playing with generative design: how AI can inspire humans.</li><li>Why AI won’t replace humans in the future.</li></ul><p>Tweetables:</p><p>“It just makes sense to automate [repetitive tasks] as much as possible, and remove that from the equation, let human genius think about big ideas and communication strategies, creativity and so on.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:03:47]</p><p>“I think on all of the levels, across the creative process, we always try to have humans involved. It’s almost like a basic principle.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:14:47]</p><p>“So that’s the nice thing, actually, perhaps using pretty advanced AI to really inspire creativity in humans instead of replacing it. It’s kind of beautiful in a way.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:17:24]</p><p>"I think the whole point of advertising, and humanity in general is precisely to be always different, to invent new things." — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:18:12]</p><p>“I think technology always gets to a point where it can perfectly imitate, and do it better than humans can, but then we invent something new.” — <a href="https://twitter.com/hyperhandsome">@hyperhandsome</a> [0:19:52]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/hyperhandsome/">Matevž Klanjšek on LinkedIn</a></p><p><a href="https://celtra.com/">Celtra Technologies</a></p>
]]></content:encoded>
      <enclosure length="17496400" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/b436993f-9eb4-4410-9cc0-ece33419e9ce/audio/99ca77ad-a889-490c-878a-0b86d216af23/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Using AI to Accelerate Creativity with Matevž Klanjšek</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:19:55</itunes:duration>
      <itunes:summary>Today we talk to Celtra Founder and CPO, Matevž Klanjšek, about how AI can be used to accelerate creativity, and what would happen if it eventually replaces humans in the creative space. We discuss the limitations of the tools currently available, why Matevž isn’t interested in teaching AI variance, and how humans and AI need to work together in advertising. Tune in to hear what the future of advertising looks like, and why the human-AI feedback loop is essential. Matevž tells us about the bizarre adverts he’s seen AI produce, and talks us through the evolution of human creativity: from paintings to photographs, and how humans stay relevant when we invent something new. 

Key Points From This Episode:

An introduction to the founder and CEO of Celtra, Matevž Klanjšek.
Where the idea of using AI in advertising came from.
How Celtra technology helps creatives scale their media, accelerating creativity. 
Why AI is the right tool for the job.
Two dangers of using AI in advertising: impacting the communication strategy, and losing uniqueness.
Can you teach AI variance?
Why it’s important to leave space for human error.
Humanity in advertising: why brands are trying to be more human.
What a collaboration between humans and AI looks like.
How human genius lies in building communication strategies.
The surprising results when AI tries to create adverts. 
Playing with generative design: how AI can inspire humans. 
Why AI won’t replace humans in the future.  

</itunes:summary>
      <itunes:subtitle>Today we talk to Celtra Founder and CPO, Matevž Klanjšek, about how AI can be used to accelerate creativity, and what would happen if it eventually replaces humans in the creative space. We discuss the limitations of the tools currently available, why Matevž isn’t interested in teaching AI variance, and how humans and AI need to work together in advertising. Tune in to hear what the future of advertising looks like, and why the human-AI feedback loop is essential. Matevž tells us about the bizarre adverts he’s seen AI produce, and talks us through the evolution of human creativity: from paintings to photographs, and how humans stay relevant when we invent something new. 

Key Points From This Episode:

An introduction to the founder and CEO of Celtra, Matevž Klanjšek.
Where the idea of using AI in advertising came from.
How Celtra technology helps creatives scale their media, accelerating creativity. 
Why AI is the right tool for the job.
Two dangers of using AI in advertising: impacting the communication strategy, and losing uniqueness.
Can you teach AI variance?
Why it’s important to leave space for human error.
Humanity in advertising: why brands are trying to be more human.
What a collaboration between humans and AI looks like.
How human genius lies in building communication strategies.
The surprising results when AI tries to create adverts. 
Playing with generative design: how AI can inspire humans. 
Why AI won’t replace humans in the future.  

</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>19</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">6fe921d3-e7aa-4725-b085-294ea7851b8d</guid>
      <title>Evolutionary Programming with Dr. Bill Porto</title>
      <description><![CDATA[<p>Joining us today is Dr. Bill Porto, Redpoint Senior Analytics Engineer and storied AI researcher, academic, and developer. Bill shares all his current projects,  including pattern recognition and optimization models, and he reveals what it was like to work with the father of Evolutionary Programming, Dr. Larry Fogel. We touch on a new definition for computational intelligence, and talk about where evolutionary programming is in use today, before exploring the fact that evolution is not simply survival of the fittest, but increases variance through retaining less perfect fits. What's more, we define evolution as adaptation in a dynamic environment. </p><p> </p><p>Key Points From This Episode:</p><p> </p><ul><li>Be introduced to today’s guest, Bill Porto, Redpoint Senior Analytics Engineer.</li><li>How he entered the industry, his background in applied math, and how he ended up in his current role.</li><li>The subjects he is working on now: pattern recognition and optimization models, personalized recommendation systems and business process optimization.</li><li>What it was like to work with Larry Fogel, a polymath in the true sense of the word.</li><li>How computational intelligence is just taking cues from nature.</li><li>Where evolutionary programming is in use today: commercial and government organizations, transport, the pharmaceutical industry, and more.</li><li>Why evolution is not really survival of the fittest, but increases variance by retaining more solutions.</li><li>How evolutionary processes require noise and how we should control what kind of noise it accesses.</li><li>What evolution is all about: adaptation in a dynamic environment.</li><li>Why having solutions that are medium fits can help you find exactly the right one.</li><li>How there is no single algorithm for all optimization problems.</li><li>Why, if you spend a lot of time getting a perfect solution, it may be stale by the time you implement it.</li><li>How important it is to prioritize customer satisfaction and optimize human resources</li><li>Why considering different goals and attaching different weights to them is so important.</li><li>Why a hybrid approach is good engineering practice as is using the best tool for the job.</li><li>How customer acquisition is not the same thing as customer retention.</li><li>Non-discrete, asymmetric bowl functions as a way to create solutions.</li><li>Scalability as a feature of the current landscape that enables us to tackle large problems.</li><li>Why continual learning is such a powerful approach.</li></ul><p> </p><p>Tweetables:</p><p>“Computational intelligence is just taking cues from nature. And nature adaptively learns using iterative evaluation selection. So why not put that into an application on a computer?” — Bill Porto [0:04:18]</p><p><br />“It’s not really survival of the fittest, that’s the common moniker for it, in reality evolution favors the solutions that are most fit, but it tends to retain a number of less fit solutions, and one of the benefits of that is it increases the variance in the number of solutions.” — Bill Porto [0:07:20]<br /><br />“If you spend a lot of time getting a perfect solution, by the time you have it, it very well may be stale.” — Bill Porto [0:15:17]<br /> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.redpointglobal.com/">Redpoint Global</a></p><p><a href="https://www.linkedin.com/in/bill-porto-4128417a/">Bill Porto on LinkedIn</a></p>
]]></description>
      <pubDate>Thu, 7 Oct 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/evolutionary-programming-with-dr-bill-porto-4KjqD0sL</link>
      <content:encoded><![CDATA[<p>Joining us today is Dr. Bill Porto, Redpoint Senior Analytics Engineer and storied AI researcher, academic, and developer. Bill shares all his current projects,  including pattern recognition and optimization models, and he reveals what it was like to work with the father of Evolutionary Programming, Dr. Larry Fogel. We touch on a new definition for computational intelligence, and talk about where evolutionary programming is in use today, before exploring the fact that evolution is not simply survival of the fittest, but increases variance through retaining less perfect fits. What's more, we define evolution as adaptation in a dynamic environment. </p><p> </p><p>Key Points From This Episode:</p><p> </p><ul><li>Be introduced to today’s guest, Bill Porto, Redpoint Senior Analytics Engineer.</li><li>How he entered the industry, his background in applied math, and how he ended up in his current role.</li><li>The subjects he is working on now: pattern recognition and optimization models, personalized recommendation systems and business process optimization.</li><li>What it was like to work with Larry Fogel, a polymath in the true sense of the word.</li><li>How computational intelligence is just taking cues from nature.</li><li>Where evolutionary programming is in use today: commercial and government organizations, transport, the pharmaceutical industry, and more.</li><li>Why evolution is not really survival of the fittest, but increases variance by retaining more solutions.</li><li>How evolutionary processes require noise and how we should control what kind of noise it accesses.</li><li>What evolution is all about: adaptation in a dynamic environment.</li><li>Why having solutions that are medium fits can help you find exactly the right one.</li><li>How there is no single algorithm for all optimization problems.</li><li>Why, if you spend a lot of time getting a perfect solution, it may be stale by the time you implement it.</li><li>How important it is to prioritize customer satisfaction and optimize human resources</li><li>Why considering different goals and attaching different weights to them is so important.</li><li>Why a hybrid approach is good engineering practice as is using the best tool for the job.</li><li>How customer acquisition is not the same thing as customer retention.</li><li>Non-discrete, asymmetric bowl functions as a way to create solutions.</li><li>Scalability as a feature of the current landscape that enables us to tackle large problems.</li><li>Why continual learning is such a powerful approach.</li></ul><p> </p><p>Tweetables:</p><p>“Computational intelligence is just taking cues from nature. And nature adaptively learns using iterative evaluation selection. So why not put that into an application on a computer?” — Bill Porto [0:04:18]</p><p><br />“It’s not really survival of the fittest, that’s the common moniker for it, in reality evolution favors the solutions that are most fit, but it tends to retain a number of less fit solutions, and one of the benefits of that is it increases the variance in the number of solutions.” — Bill Porto [0:07:20]<br /><br />“If you spend a lot of time getting a perfect solution, by the time you have it, it very well may be stale.” — Bill Porto [0:15:17]<br /> </p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.redpointglobal.com/">Redpoint Global</a></p><p><a href="https://www.linkedin.com/in/bill-porto-4128417a/">Bill Porto on LinkedIn</a></p>
]]></content:encoded>
      <enclosure length="20631737" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/a60edcc5-bb71-4852-bba8-da10c378fc30/audio/8b051562-790a-478d-8193-2b28966e2f07/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Evolutionary Programming with Dr. Bill Porto</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:24:33</itunes:duration>
      <itunes:summary>Joining us today is Dr. Bill Porto, Redpoint Senior Analytics Engineer and storied AI researcher, academic, and developer. Bill shares all his current projects,  including pattern recognition and optimization models, and he reveals what it was like to work with the father of Evolutionary Programming, Dr. Larry Fogel. We touch on a new definition for computational intelligence, and talk about where evolutionary programming is in use today, before exploring the fact that evolution is not simply survival of the fittest, but increases variance through retaining less perfect fits. What&apos;s more, we define evolution as adaptation in a dynamic environment. </itunes:summary>
      <itunes:subtitle>Joining us today is Dr. Bill Porto, Redpoint Senior Analytics Engineer and storied AI researcher, academic, and developer. Bill shares all his current projects,  including pattern recognition and optimization models, and he reveals what it was like to work with the father of Evolutionary Programming, Dr. Larry Fogel. We touch on a new definition for computational intelligence, and talk about where evolutionary programming is in use today, before exploring the fact that evolution is not simply survival of the fittest, but increases variance through retaining less perfect fits. What&apos;s more, we define evolution as adaptation in a dynamic environment. </itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>18</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">76571326-70c9-4b46-8d31-cea16cb01d1a</guid>
      <title>Turning Expertise into Algorithms with Mavenoid CEO Shahan Lilja</title>
      <description><![CDATA[<p>CEO Shahan Lilja joins to explain how Mavenoid is able to deploy custom chat bots in a matter of minutes, the processes by which these tools get better over time, and how the ability to automatically turn technical expertise into an algorithm that can be utilized at scale is amplifying human intelligence.</p><p> </p>
]]></description>
      <pubDate>Thu, 30 Sep 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/turning-expertise-into-algorithms-with-mavenoid-ceo-shahan-lilja-dcs6sNCE</link>
      <content:encoded><![CDATA[<p>CEO Shahan Lilja joins to explain how Mavenoid is able to deploy custom chat bots in a matter of minutes, the processes by which these tools get better over time, and how the ability to automatically turn technical expertise into an algorithm that can be utilized at scale is amplifying human intelligence.</p><p> </p>
]]></content:encoded>
      <enclosure length="24930891" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/71bf8699-9f09-46ff-8424-6d5dea8f5f79/audio/bc9dd1b1-cfff-42fa-ab61-6aac468cf981/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Turning Expertise into Algorithms with Mavenoid CEO Shahan Lilja</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:59</itunes:duration>
      <itunes:summary>CEO Shahan Lilja joins to explain how Mavenoid is able to deploy custom chat bots in a matter of minutes, the processes by which these tools get better over time, and how the ability to automatically turn technical expertise into an algorithm that can be utilized at scale is amplifying human intelligence.
</itunes:summary>
      <itunes:subtitle>CEO Shahan Lilja joins to explain how Mavenoid is able to deploy custom chat bots in a matter of minutes, the processes by which these tools get better over time, and how the ability to automatically turn technical expertise into an algorithm that can be utilized at scale is amplifying human intelligence.
</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>17</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">d28054bc-8695-46bc-95e4-316ac08224ab</guid>
      <title>Solving Conversational AI with Valyant AI CEO Rob Carpenter</title>
      <description><![CDATA[<p>Rob Carpenter is the founder and CEO of Valyant AI, which is on a journey to solve the complex problem of conversational AI in the food service industry. In today’s episode, Rob explains the three main components of AI speech processing (and the challenges that arise at each of these nodes), how conversational AI has the capacity to improve conditions for human workers in the food service industry, and what this technology is going to be like in the future. After this episode, you’ll understand the importance of being more thoughtful about how you communicate your next burger and fries order to a conversational AI system.</p><p> </p><p>Key Points From This Episode:</p><ul><li>Rob’s early interest in entrepreneurship. </li><li>The original idea that Rob wanted to center his company around, and why it didn’t work out that way. </li><li>What Valyant AI does. </li><li>Long term goals that Rob has for his company. </li><li>Challenges of conversational AI in the food service industry.  </li><li>Benefits of being an industry newcomer. </li><li>The “three amigos” of speech processing.</li><li>Examples of customer statements which highlight why a natural language processor is such a vital part of AI speech processing.</li><li>How people need to learn to communicate with AI systems. </li><li>The deficit of employees in the restaurant industry.</li><li>Ways that conversational AI improves working conditions for food service industry employees. </li><li>Progress that we have made as a society as a result of innovation. </li><li>What we can expect from conversational AI in the next five to ten years. </li></ul><p>Tweetables:</p><p>“I thought the hologram was the hard part and that the conversational AI was solved, but it was basically the inverse of that.” — Rob Carpenter [0:06:47]</p><p>“There’s benefits when you get into a new industry or technology not knowing the problems, because you don’t know what your limitations are. I think a lot of times that frees you up to be more creative and innovative.” — Rob Carpenter [0:08:38]</p><p>“If I was to postulate where things would end up, I’d say it’s probably a 90/10. 90% is that the technology has to be better, and keep getting better. 90% of everything needs to be handled by the AI. The other 10%, people need to be more thoughtful when they communicate with these systems.” — Rob Carpenter [0:17:22]</p><p>“There’s 1.7 million unfilled positions in the restaurant industry right now. 1 in 6 of every position available right now is in restaurants.” — Rob Carpenter [0:20:26]</p><p>“Innovation is not only built into economies, but it’s essential for their health and long-term safety.” — Rob Carpenter [0:23:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/rob-carpenter/">Rob Carpenter on LinkedIn</a></p><p><a href="https://valyant.ai/#/">Valyant AI</a></p>
]]></description>
      <pubDate>Thu, 23 Sep 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/solving-conversational-ai-with-valyant-ai-ceo-rob-carpenter-lPax45u2</link>
      <content:encoded><![CDATA[<p>Rob Carpenter is the founder and CEO of Valyant AI, which is on a journey to solve the complex problem of conversational AI in the food service industry. In today’s episode, Rob explains the three main components of AI speech processing (and the challenges that arise at each of these nodes), how conversational AI has the capacity to improve conditions for human workers in the food service industry, and what this technology is going to be like in the future. After this episode, you’ll understand the importance of being more thoughtful about how you communicate your next burger and fries order to a conversational AI system.</p><p> </p><p>Key Points From This Episode:</p><ul><li>Rob’s early interest in entrepreneurship. </li><li>The original idea that Rob wanted to center his company around, and why it didn’t work out that way. </li><li>What Valyant AI does. </li><li>Long term goals that Rob has for his company. </li><li>Challenges of conversational AI in the food service industry.  </li><li>Benefits of being an industry newcomer. </li><li>The “three amigos” of speech processing.</li><li>Examples of customer statements which highlight why a natural language processor is such a vital part of AI speech processing.</li><li>How people need to learn to communicate with AI systems. </li><li>The deficit of employees in the restaurant industry.</li><li>Ways that conversational AI improves working conditions for food service industry employees. </li><li>Progress that we have made as a society as a result of innovation. </li><li>What we can expect from conversational AI in the next five to ten years. </li></ul><p>Tweetables:</p><p>“I thought the hologram was the hard part and that the conversational AI was solved, but it was basically the inverse of that.” — Rob Carpenter [0:06:47]</p><p>“There’s benefits when you get into a new industry or technology not knowing the problems, because you don’t know what your limitations are. I think a lot of times that frees you up to be more creative and innovative.” — Rob Carpenter [0:08:38]</p><p>“If I was to postulate where things would end up, I’d say it’s probably a 90/10. 90% is that the technology has to be better, and keep getting better. 90% of everything needs to be handled by the AI. The other 10%, people need to be more thoughtful when they communicate with these systems.” — Rob Carpenter [0:17:22]</p><p>“There’s 1.7 million unfilled positions in the restaurant industry right now. 1 in 6 of every position available right now is in restaurants.” — Rob Carpenter [0:20:26]</p><p>“Innovation is not only built into economies, but it’s essential for their health and long-term safety.” — Rob Carpenter [0:23:28]</p><p>Links Mentioned in Today’s Episode:</p><p><a href="https://www.linkedin.com/in/rob-carpenter/">Rob Carpenter on LinkedIn</a></p><p><a href="https://valyant.ai/#/">Valyant AI</a></p>
]]></content:encoded>
      <enclosure length="26364867" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d8e06687-0741-48fc-8566-0bb0199d278a/audio/4881d72b-c07c-48a9-aeb9-a8263f72ee7e/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Solving Conversational AI with Valyant AI CEO Rob Carpenter</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:36</itunes:duration>
      <itunes:summary>Rob Carpenter is the founder and CEO of Valyant AI, which is on a journey to solve the complex problem of conversational AI in the food service industry. In today’s episode, Rob explains the three main components of AI speech processing (and the challenges that arise at each of these nodes), how conversational AI has the capacity to improve conditions for human workers in the food service industry, and what this technology is going to be like in the future. After this episode, you’ll understand the importance of being more thoughtful about how you communicate your next burger and fries order to a conversational AI system. 
</itunes:summary>
      <itunes:subtitle>Rob Carpenter is the founder and CEO of Valyant AI, which is on a journey to solve the complex problem of conversational AI in the food service industry. In today’s episode, Rob explains the three main components of AI speech processing (and the challenges that arise at each of these nodes), how conversational AI has the capacity to improve conditions for human workers in the food service industry, and what this technology is going to be like in the future. After this episode, you’ll understand the importance of being more thoughtful about how you communicate your next burger and fries order to a conversational AI system. 
</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>16</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e9fb2033-9997-4a31-bf57-310cab992ff2</guid>
      <title>Nuances of Speech Recognition with Cogito&apos;s Dr. John Kane</title>
      <description><![CDATA[<p>Dr. John Kane, Head of Signal Processing & Machine Learning at Cogito, explains the challenges brought on by the oft-repeated truism "speech is more than text", and how Cogito addresses these challenges to deliver real-time conversational insight to their users. Later, John explains the holistic approach to ensuring machine learning technology is created in a bias-free environment.</p>
]]></description>
      <pubDate>Thu, 16 Sep 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/nuances-of-speech-recognition-with-cogitos-dr-john-kane-Z4J5ujrW</link>
      <content:encoded><![CDATA[<p>Dr. John Kane, Head of Signal Processing & Machine Learning at Cogito, explains the challenges brought on by the oft-repeated truism "speech is more than text", and how Cogito addresses these challenges to deliver real-time conversational insight to their users. Later, John explains the holistic approach to ensuring machine learning technology is created in a bias-free environment.</p>
]]></content:encoded>
      <enclosure length="28059203" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/bd08eb4f-10c6-4fae-ae84-52939b8093f6/audio/1b928ab9-c152-4dc2-a2cc-e6c47ca31e5d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Nuances of Speech Recognition with Cogito&apos;s Dr. John Kane</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:30:37</itunes:duration>
      <itunes:summary>Dr. John Kane, Head of Signal Processing &amp; Machine Learning at Cogito, explains the challenges brought on by the oft-repeated truism &quot;speech is more than text&quot;, and how Cogito addresses these challenges to deliver real-time conversational insight to their users. Later, John explains the holistic approach to ensuring machine learning technology is created in a bias-free environment.</itunes:summary>
      <itunes:subtitle>Dr. John Kane, Head of Signal Processing &amp; Machine Learning at Cogito, explains the challenges brought on by the oft-repeated truism &quot;speech is more than text&quot;, and how Cogito addresses these challenges to deliver real-time conversational insight to their users. Later, John explains the holistic approach to ensuring machine learning technology is created in a bias-free environment.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>15</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">25d4b598-d805-49fe-9ba9-290cfc844f5a</guid>
      <title>Microsoft&apos;s Priyanka Roy on Design Thinking &amp; Data Governance</title>
      <description><![CDATA[<p>Data & AI Solution Specialist for Microsoft, Priyanka Roy, explains how Design Thinking is a crucial approach in the development of any AI technology, and how it's proper utilization results in better products and more effective teams. Priyanka also outlines the key pillars of a successful data governance approach, and the utility of "thick" data.</p>
]]></description>
      <pubDate>Thu, 9 Sep 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/microsofts-priyanka-roy-on-design-thinking-data-governance-uy2X4ql8</link>
      <content:encoded><![CDATA[<p>Data & AI Solution Specialist for Microsoft, Priyanka Roy, explains how Design Thinking is a crucial approach in the development of any AI technology, and how it's proper utilization results in better products and more effective teams. Priyanka also outlines the key pillars of a successful data governance approach, and the utility of "thick" data.</p>
]]></content:encoded>
      <enclosure length="20490488" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/aceb9c08-8760-493f-ba94-2bd4ab0d6151/audio/f75fe33c-4fe9-495e-bd74-f63edbef7a40/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Microsoft&apos;s Priyanka Roy on Design Thinking &amp; Data Governance</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:24:37</itunes:duration>
      <itunes:summary>Data &amp; AI Solution Specialist for Microsoft, Priyanka Roy, explains how Design Thinking is a crucial approach in the development of any AI technology, and how its proper utilization results in better products and more effective teams. Priyanka also outlines the key pillars of a successful data governance approach, and the utility of &quot;thick&quot; data.</itunes:summary>
      <itunes:subtitle>Data &amp; AI Solution Specialist for Microsoft, Priyanka Roy, explains how Design Thinking is a crucial approach in the development of any AI technology, and how its proper utilization results in better products and more effective teams. Priyanka also outlines the key pillars of a successful data governance approach, and the utility of &quot;thick&quot; data.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>14</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">c132769d-03f2-4b05-81f2-bb1ef62cfc2d</guid>
      <title>Representation in AI with Walmart Global Tech Leaders Anshu Bhardwaj &amp; Desirée Gosby</title>
      <description><![CDATA[<p>Walmart's SVP of Global Technology Anshu Bhardwaj and VP of Emerging Technology Desirée Gosby join Sama CEO Wendy Gonzalez for a roundtable discussion about representation in AI, explainable & ethical AI, and how representative teams are a key way to reduce biases in AI technology.</p>
]]></description>
      <pubDate>Thu, 2 Sep 2021 16:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/representation-in-ai-with-walmart-vps-anshu-bhardwaj-desi-gosby-UGHlT5zx</link>
      <content:encoded><![CDATA[<p>Walmart's SVP of Global Technology Anshu Bhardwaj and VP of Emerging Technology Desirée Gosby join Sama CEO Wendy Gonzalez for a roundtable discussion about representation in AI, explainable & ethical AI, and how representative teams are a key way to reduce biases in AI technology.</p>
]]></content:encoded>
      <enclosure length="25940931" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/aeb0ed8d-bf7d-4d5e-9e2e-79b623eafd6e/audio/d899554f-1a3f-4b73-a975-74d0bd991689/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Representation in AI with Walmart Global Tech Leaders Anshu Bhardwaj &amp; Desirée Gosby</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:28:29</itunes:duration>
      <itunes:summary>Walmart&apos;s SVP of Global Technology Anshu Bhardwaj and VP of Emerging Technology Desirée Gosby join Sama CEO Wendy Gonzalez for a roundtable discussion about representation in AI, explainable &amp; ethical AI, and how representative teams are a key way to reduce biases in AI technology.</itunes:summary>
      <itunes:subtitle>Walmart&apos;s SVP of Global Technology Anshu Bhardwaj and VP of Emerging Technology Desirée Gosby join Sama CEO Wendy Gonzalez for a roundtable discussion about representation in AI, explainable &amp; ethical AI, and how representative teams are a key way to reduce biases in AI technology.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>13</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">37160085-4558-40d3-a47e-79e3b92c8997</guid>
      <title>Predictive &amp; Declarative AI with Theresa Benson</title>
      <description><![CDATA[<p>Theresa Benson, Product Storyteller for InRule Technology, explains the opportunity of combining declarative AI with predictive AI, and how InRule Technology is using predictive AI to empower non AI experts to develop algorithms from their existing domain knowledge.</p>
]]></description>
      <pubDate>Thu, 26 Aug 2021 11:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/predictive-declarative-ai-with-theresa-benson-dnP3ZcfS</link>
      <content:encoded><![CDATA[<p>Theresa Benson, Product Storyteller for InRule Technology, explains the opportunity of combining declarative AI with predictive AI, and how InRule Technology is using predictive AI to empower non AI experts to develop algorithms from their existing domain knowledge.</p>
]]></content:encoded>
      <enclosure length="31872391" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/30e005fe-b6d7-461b-90dd-159bc615208d/audio/fac2baca-e94a-4f9f-a5cb-84c3c18805d9/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Predictive &amp; Declarative AI with Theresa Benson</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:33:12</itunes:duration>
      <itunes:summary>Theresa Benson, Product Storyteller for InRule Technology, explains the opportunity of combining declarative AI with predictive AI, and how InRule Technology is using predictive AI to empower non AI experts to develop algorithms from their existing domain knowledge.</itunes:summary>
      <itunes:subtitle>Theresa Benson, Product Storyteller for InRule Technology, explains the opportunity of combining declarative AI with predictive AI, and how InRule Technology is using predictive AI to empower non AI experts to develop algorithms from their existing domain knowledge.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>12</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">6e3b2d9f-d0b8-4b92-b553-eb2ea71a170f</guid>
      <title>Solving Supply &amp; Demand in Healthcare with LeanTaaS CEO Mohan Giridharadas</title>
      <description><![CDATA[<p>LeanTaas CEO Mohan Giridharadas explains how his team is solving the Supply & Demand challenge within healthcare, how the algorithms are stress tested in order to handle extreme edge cases, as well as how drift is defined, detected, and resolved in a customer-centric fashion.</p>
]]></description>
      <pubDate>Thu, 19 Aug 2021 11:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/solving-supply-demand-in-healthcare-with-leantaas-ceo-mohan-giridharadas-_iBwUIf3</link>
      <content:encoded><![CDATA[<p>LeanTaas CEO Mohan Giridharadas explains how his team is solving the Supply & Demand challenge within healthcare, how the algorithms are stress tested in order to handle extreme edge cases, as well as how drift is defined, detected, and resolved in a customer-centric fashion.</p>
]]></content:encoded>
      <enclosure length="23377312" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/e30d414c-fa1f-4404-b84b-30878f19c1c2/audio/930a3f94-914c-4519-a331-6ff531cf737d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Solving Supply &amp; Demand in Healthcare with LeanTaaS CEO Mohan Giridharadas</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:21</itunes:duration>
      <itunes:summary>LeanTaaS CEO Mohan Giridharadas explains how his team is solving the Supply &amp; Demand challenge within healthcare, how the algorithms are stress tested in order to handle extreme edge cases, as well as how drift is defined, detected, and resolved in a customer-centric fashion.</itunes:summary>
      <itunes:subtitle>LeanTaaS CEO Mohan Giridharadas explains how his team is solving the Supply &amp; Demand challenge within healthcare, how the algorithms are stress tested in order to handle extreme edge cases, as well as how drift is defined, detected, and resolved in a customer-centric fashion.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>11</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">333ac9d0-6130-41e1-918b-45b88086f5a3</guid>
      <title>Anna Susmelj: Latent Space, Causality, and Computational Biology</title>
      <description><![CDATA[<p>Anna Susmelj explains her research at Facebook AI developing optimal drug combinations for the treatment of complex diseases, as well as her background in causality research.</p><p>Anna's Facebook Research: <a href="https://ai.facebook.com/blog/ai-predicts-effective-drug-combinations-to-fight-complex-diseases-faster/" target="_blank">AI predicts effective drug combinations to fight complex diseases faster</a></p>
]]></description>
      <pubDate>Thu, 12 Aug 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/anna-susmelj-latent-space-causality-and-computational-biology-r_68RmNr</link>
      <content:encoded><![CDATA[<p>Anna Susmelj explains her research at Facebook AI developing optimal drug combinations for the treatment of complex diseases, as well as her background in causality research.</p><p>Anna's Facebook Research: <a href="https://ai.facebook.com/blog/ai-predicts-effective-drug-combinations-to-fight-complex-diseases-faster/" target="_blank">AI predicts effective drug combinations to fight complex diseases faster</a></p>
]]></content:encoded>
      <enclosure length="19525183" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/dbaf0e54-b544-4e26-92f2-86ca33de9591/audio/c9f2e724-7447-470c-ac80-deb5e82c2dee/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Anna Susmelj: Latent Space, Causality, and Computational Biology</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:13</itunes:duration>
      <itunes:summary>Anna Susmelj explains her research at Facebook AI developing optimal drug combinations for the treatment of complex diseases, as well as her background in causality research.</itunes:summary>
      <itunes:subtitle>Anna Susmelj explains her research at Facebook AI developing optimal drug combinations for the treatment of complex diseases, as well as her background in causality research.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>10</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">d6e72335-7c78-46c7-b2b3-9b4e4a3e9443</guid>
      <title>Laurence Moroney: Google&apos;s Lead AI Advocate</title>
      <description><![CDATA[<p>Laurence Moroney is an industry veteran who has authored several books on AI development, taught a series of AI/ML MooCs, and even advises British Parliament on their AI approach. His mission at google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.</p><p>Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming in to play when access to AI & ML is made global.</p><p>Pre-Order Laurence's new book, <a href="https://www.amazon.com/Machine-Learning-Device-Development-Programmers/dp/109810174X" target="_blank">AI and Machine Learning for On-Device Development: A Programmer's Guide</a></p><p>Study with Laurence on <a href="https://www.coursera.org/instructor/lmoroney">Coursera</a></p><p>Subscribe to the <a href="https://www.youtube.com/tensorflow" target="_blank">Tensor Flow YouTube Channel</a></p>
]]></description>
      <pubDate>Thu, 5 Aug 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/laurence-moroney-googles-lead-ai-advocate-J5eGjQxb</link>
      <content:encoded><![CDATA[<p>Laurence Moroney is an industry veteran who has authored several books on AI development, taught a series of AI/ML MooCs, and even advises British Parliament on their AI approach. His mission at google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.</p><p>Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming in to play when access to AI & ML is made global.</p><p>Pre-Order Laurence's new book, <a href="https://www.amazon.com/Machine-Learning-Device-Development-Programmers/dp/109810174X" target="_blank">AI and Machine Learning for On-Device Development: A Programmer's Guide</a></p><p>Study with Laurence on <a href="https://www.coursera.org/instructor/lmoroney">Coursera</a></p><p>Subscribe to the <a href="https://www.youtube.com/tensorflow" target="_blank">Tensor Flow YouTube Channel</a></p>
]]></content:encoded>
      <enclosure length="29423678" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/80fc6fa6-921a-471f-be37-f2f85b497322/audio/e96bcfcd-7261-478c-b7fd-87a5fc21db77/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Laurence Moroney: Google&apos;s Lead AI Advocate</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:36:18</itunes:duration>
      <itunes:summary>Laurence Moroney is an industry veteran who has authored several books on AI development, taught a series of AI/ML MooCs, and even advises British Parliament on their AI approach. His mission at google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology. 

Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming in to play when access to AI &amp; ML is made global.
</itunes:summary>
      <itunes:subtitle>Laurence Moroney is an industry veteran who has authored several books on AI development, taught a series of AI/ML MooCs, and even advises British Parliament on their AI approach. His mission at google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology. 

Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming in to play when access to AI &amp; ML is made global.
</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>9</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">8adb2d1e-8519-4b32-95bd-59365b3bf55a</guid>
      <title>Kelvin Wursten: Tensor Flow Models in Healthcare</title>
      <description><![CDATA[<p>Kelvin Wursten, leader of PointClickCare's Data Science team, explains how they are utilizing AI to help solve complicated supply vs. demand calculations in hospital emergency departments, as well as the challenge of balancing building awesome technology while still prioritizing the user's needs.</p>
]]></description>
      <pubDate>Fri, 30 Jul 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/kelvin-wursten-tensor-flow-models-in-healthcare-ZKt6kGSM</link>
      <content:encoded><![CDATA[<p>Kelvin Wursten, leader of PointClickCare's Data Science team, explains how they are utilizing AI to help solve complicated supply vs. demand calculations in hospital emergency departments, as well as the challenge of balancing building awesome technology while still prioritizing the user's needs.</p>
]]></content:encoded>
      <enclosure length="14902211" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8987518a-59a4-4a1f-8aab-fde9a07dff79/audio/17b52f26-f900-4702-b25c-ef07918af7f9/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Kelvin Wursten: Tensor Flow Models in Healthcare</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:19:39</itunes:duration>
      <itunes:summary>Kelvin Wursten, leader of PointClickCare&apos;s Data Science team, explains how they are utilizing AI to help solve complicated supply vs. demand calculations in hospital emergency departments, as well as the challenge of balancing building awesome technology while still prioritizing the user&apos;s needs.</itunes:summary>
      <itunes:subtitle>Kelvin Wursten, leader of PointClickCare&apos;s Data Science team, explains how they are utilizing AI to help solve complicated supply vs. demand calculations in hospital emergency departments, as well as the challenge of balancing building awesome technology while still prioritizing the user&apos;s needs.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>8</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">758a5f05-197b-465c-bea4-3f5dcd645899</guid>
      <title>Igor Susmelj: More Data is Not The Answer</title>
      <description><![CDATA[<p>Igor Susmelj, Co-Founder of Lightly.ai, explains how most companies don't have a problem of too little data, but rather of far too much irrelevant data. He details Lightly's approach of utilizing self-supervised learning to pare down massive data sets into something that can be useful to a supervised learning approach.</p>
]]></description>
      <pubDate>Thu, 22 Jul 2021 06:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/igor-susmelj-what-to-do-with-too-much-data-sSw9QJ4q</link>
      <content:encoded><![CDATA[<p>Igor Susmelj, Co-Founder of Lightly.ai, explains how most companies don't have a problem of too little data, but rather of far too much irrelevant data. He details Lightly's approach of utilizing self-supervised learning to pare down massive data sets into something that can be useful to a supervised learning approach.</p>
]]></content:encoded>
      <enclosure length="24246682" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/7c358b63-e717-41f0-868e-a055beb5135e/audio/91abc609-02d7-465d-a99b-386b099daa63/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Igor Susmelj: More Data is Not The Answer</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:00</itunes:duration>
      <itunes:summary>Igor Susmelj, Co-Founder of Lightly, explains how most companies don&apos;t have a problem of too little data, but rather of far too much irrelevant data. He details Lightly&apos;s approach of utilizing self-supervised learning to pare down massive data sets into something that can be useful to a supervised learning approach.</itunes:summary>
      <itunes:subtitle>Igor Susmelj, Co-Founder of Lightly, explains how most companies don&apos;t have a problem of too little data, but rather of far too much irrelevant data. He details Lightly&apos;s approach of utilizing self-supervised learning to pare down massive data sets into something that can be useful to a supervised learning approach.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>7</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">26486745-699b-4643-b686-d5147ae33515</guid>
      <title>Hyperscience CEO Peter Brodsky: Making AI Backwards Compatible with Reality</title>
      <description><![CDATA[<p>Hyperscience co-founder and CEO Peter Brodsky explains why standards are fundamentally at odds with innovation, and how making technology that is backwards compatible with reality is Hyperscience's approach.</p><p>Key topics:</p><ul><li>The future of Human-in-the-loop processes</li><li>Using synthetic data to train deep learning algorithms</li><li>Why the solution to data entry automation will  prove to be the solution to automation as a whole</li></ul>
]]></description>
      <pubDate>Fri, 9 Jul 2021 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/hyperscience-ceo-peter-brodsky-making-ai-backwards-compatible-with-reality-xPs8JKBl</link>
      <content:encoded><![CDATA[<p>Hyperscience co-founder and CEO Peter Brodsky explains why standards are fundamentally at odds with innovation, and how making technology that is backwards compatible with reality is Hyperscience's approach.</p><p>Key topics:</p><ul><li>The future of Human-in-the-loop processes</li><li>Using synthetic data to train deep learning algorithms</li><li>Why the solution to data entry automation will  prove to be the solution to automation as a whole</li></ul>
]]></content:encoded>
      <enclosure length="17011377" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/c9054af2-5021-4466-a030-79ee6e09f652/audio/a0940216-14d0-4f51-9e28-315306baa100/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Hyperscience CEO Peter Brodsky: Making AI Backwards Compatible with Reality</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:22:24</itunes:duration>
      <itunes:summary>Hyperscience co-founder and CEO Peter Brodsky explains why standards are fundamentally at odds with innovation, and how making technology that is backwards compatible with reality is Hyperscience&apos;s approach.</itunes:summary>
      <itunes:subtitle>Hyperscience co-founder and CEO Peter Brodsky explains why standards are fundamentally at odds with innovation, and how making technology that is backwards compatible with reality is Hyperscience&apos;s approach.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>6</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">e876c0be-0f2e-4b9a-a42a-39bc6b4d8a4d</guid>
      <title>Director of AI Research Ram: AI in the Enterprise</title>
      <description><![CDATA[<p>Director of AI Research Ram explains how ManageEngine's tools predict anomalies, the long term utility of Human-in-the-Loop AI, and how they've used sentiment analysis & transfer learning to overcome a lack of data.</p>
]]></description>
      <pubDate>Thu, 1 Jul 2021 11:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/director-of-ai-research-ram-ai-in-the-enterprise-whNOSf4f</link>
      <content:encoded><![CDATA[<p>Director of AI Research Ram explains how ManageEngine's tools predict anomalies, the long term utility of Human-in-the-Loop AI, and how they've used sentiment analysis & transfer learning to overcome a lack of data.</p>
]]></content:encoded>
      <enclosure length="18797140" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/f3dc314c-a923-4248-a113-91a7251b9d6b/audio/9a1d7ae2-616b-4a46-9030-15192f6bc29d/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Director of AI Research Ram: AI in the Enterprise</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:21:41</itunes:duration>
      <itunes:summary>Director of AI Research Ram explains how ManageEngine&apos;s tools predict anomalies, the long term utility of Human-in-the-Loop AI, and how they&apos;ve used sentiment analysis &amp; transfer learning to overcome a lack of data.</itunes:summary>
      <itunes:subtitle>Director of AI Research Ram explains how ManageEngine&apos;s tools predict anomalies, the long term utility of Human-in-the-Loop AI, and how they&apos;ve used sentiment analysis &amp; transfer learning to overcome a lack of data.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>5</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">0405beb3-1374-44b6-9a15-5cc62192e248</guid>
      <title>Gyant CEO Stefan Behrens: Building Datasets &amp; Ensuring Interpretability</title>
      <description><![CDATA[<p>Gyant CEO & Co-Founder Stefan Behrens explains the challenges inherent in creating datasets for healthcare purposes, as well as the importance of building interpretability into their AI tools.</p>
]]></description>
      <pubDate>Thu, 24 Jun 2021 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/gyant-ceo-stefan-behrens-building-datasets-ensuring-interpretability-hpkX6stN</link>
      <content:encoded><![CDATA[<p>Gyant CEO & Co-Founder Stefan Behrens explains the challenges inherent in creating datasets for healthcare purposes, as well as the importance of building interpretability into their AI tools.</p>
]]></content:encoded>
      <enclosure length="22227547" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/8086002c-511f-4245-9265-7b13d957d5ef/audio/e3b5694d-d799-4a3e-9b84-884affd79cde/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Gyant CEO Stefan Behrens: Building Datasets &amp; Ensuring Interpretability</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:25:31</itunes:duration>
      <itunes:summary>Gyant CEO &amp; Co-Founder Stefan Behrens explains the challenges inherent in creating datasets for healthcare purposes, as well as the importance of building interpretability into their AI tools.</itunes:summary>
      <itunes:subtitle>Gyant CEO &amp; Co-Founder Stefan Behrens explains the challenges inherent in creating datasets for healthcare purposes, as well as the importance of building interpretability into their AI tools.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>4</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">8a0940a2-1f5d-46f4-961a-1937d03be4a2</guid>
      <title>Sama CEO Wendy Gonzalez: Upskilling Talent in Developing Nations</title>
      <description><![CDATA[<p>Sama CEO Wendy Gonzalez explains how the Sama Digital Basics program teaches AI skills to individuals in Africa's largest slum, and reflects on the findings of MIT's 6 year study measuring the program's effect.</p><p><a href="https://www.sama.com/blog/rct-results-mit" target="_blank">RCT Results from MIT: Evaluating the Impact of Sama’s Training and Job Programs</a></p>
]]></description>
      <pubDate>Thu, 17 Jun 2021 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/sama-ceo-wendy-gonzalez-upskilling-third-world-talent-VYc2iMEm</link>
      <content:encoded><![CDATA[<p>Sama CEO Wendy Gonzalez explains how the Sama Digital Basics program teaches AI skills to individuals in Africa's largest slum, and reflects on the findings of MIT's 6 year study measuring the program's effect.</p><p><a href="https://www.sama.com/blog/rct-results-mit" target="_blank">RCT Results from MIT: Evaluating the Impact of Sama’s Training and Job Programs</a></p>
]]></content:encoded>
      <enclosure length="16835891" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/3ca38868-84a8-4dfb-baf3-c79c3cdd9081/audio/9f7077b3-08ca-4d9f-a4da-3b9f2e5ab59f/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Sama CEO Wendy Gonzalez: Upskilling Talent in Developing Nations</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:17:32</itunes:duration>
      <itunes:summary>Sama CEO Wendy Gonzalez explains how the Sama Digital Basics program teaches AI skills to individuals in Africa&apos;s largest slum, and reflects on the findings of MIT&apos;s 6 year study measuring the program&apos;s effect.</itunes:summary>
      <itunes:subtitle>Sama CEO Wendy Gonzalez explains how the Sama Digital Basics program teaches AI skills to individuals in Africa&apos;s largest slum, and reflects on the findings of MIT&apos;s 6 year study measuring the program&apos;s effect.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>3</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">6f47d16d-1e13-48b4-bb2d-7db683173f44</guid>
      <title>An Ensemble Approach to Optimization with George Corugedo</title>
      <description><![CDATA[<p>CTO George Corugedo explains how the  relationship between physics and math is a model for the relationship between business questions and artificial intelligence, as well as Redpoint Global's ensemble approach to optimization.</p>
]]></description>
      <pubDate>Thu, 10 Jun 2021 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/an-ensemble-approach-to-optimization-with-george-corugedo-6bUWUatr</link>
      <content:encoded><![CDATA[<p>CTO George Corugedo explains how the  relationship between physics and math is a model for the relationship between business questions and artificial intelligence, as well as Redpoint Global's ensemble approach to optimization.</p>
]]></content:encoded>
      <enclosure length="25938207" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d1ca7ecb-5f9a-41a8-a99f-fe6fc2b79748/audio/e088fb77-5532-4900-8e27-941800eeb9c2/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>An Ensemble Approach to Optimization with George Corugedo</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:27:02</itunes:duration>
      <itunes:summary>CTO George Corugedo explains how the  relationship between physics and math is a model for the relationship between business questions and artificial intelligence, as well as Redpoint Global&apos;s ensemble approach to optimization.</itunes:summary>
      <itunes:subtitle>CTO George Corugedo explains how the  relationship between physics and math is a model for the relationship between business questions and artificial intelligence, as well as Redpoint Global&apos;s ensemble approach to optimization.</itunes:subtitle>
      <itunes:keywords>evolutionary programming, artificial intelligence, ai</itunes:keywords>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>2</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">8e1d096f-9d67-4f86-b038-a7494fe5bbb2</guid>
      <title>Adnan Khaleel: Speed vs. Accuracy</title>
      <description><![CDATA[<p>Adnan Khaleel, Sr. Director of Global Sales Strategy for HPC & AI at Dell, explains how companies are using HPC and containerization to scale their AI implementations, as well as how Dell parallelized a radiology algorithm, drastically improving both speed and accuracy.</p><p><a href="https://conferences.oreilly.com/artificial-intelligence/ai-ca-2018/cdn.oreillystatic.com/en/assets/1/event/282/Efficient%20neural%20network%20training%20on%20Intel%20Xeon-based%20supercomputers%20Presentation.pdf" target="_blank">ChexNet Parallelization Study</a></p>
]]></description>
      <pubDate>Thu, 27 May 2021 12:00:00 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/adnan-khaleel-speed-vs-accuracy-Y9a6wqbu</link>
      <content:encoded><![CDATA[<p>Adnan Khaleel, Sr. Director of Global Sales Strategy for HPC & AI at Dell, explains how companies are using HPC and containerization to scale their AI implementations, as well as how Dell parallelized a radiology algorithm, drastically improving both speed and accuracy.</p><p><a href="https://conferences.oreilly.com/artificial-intelligence/ai-ca-2018/cdn.oreillystatic.com/en/assets/1/event/282/Efficient%20neural%20network%20training%20on%20Intel%20Xeon-based%20supercomputers%20Presentation.pdf" target="_blank">ChexNet Parallelization Study</a></p>
]]></content:encoded>
      <enclosure length="19148347" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/d02afd0c-58ef-4de1-863b-58d3e20c1fe6/audio/2f5c17bf-5b3e-4562-9e6b-726e2b389f03/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Adnan Khaleel: Speed vs. Accuracy</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:26:57</itunes:duration>
      <itunes:summary>Adnan Khaleel, Sr. Director of Global Sales Strategy for HPC &amp; AI at Dell, explains how companies are using HPC and containerization to scale their AI implementations, as well as how Dell parallelized a radiology algorithm, drastically improving both speed and accuracy.</itunes:summary>
      <itunes:subtitle>Adnan Khaleel, Sr. Director of Global Sales Strategy for HPC &amp; AI at Dell, explains how companies are using HPC and containerization to scale their AI implementations, as well as how Dell parallelized a radiology algorithm, drastically improving both speed and accuracy.</itunes:subtitle>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:episode>1</itunes:episode>
    </item>
    <item>
      <guid isPermaLink="false">1984125d-c83b-4e85-8fe9-24b022e191ea</guid>
      <title>Trailer: Introducing How AI Happens</title>
      <description><![CDATA[How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field. Powered by Sama.
]]></description>
      <pubDate>Thu, 20 May 2021 08:30:55 +0000</pubDate>
      <author>eschwartze@samasource.org (Sama)</author>
      <link>https://howaihappens.com/episodes/trailer-introducing-how-ai-happens-TxVOKxLy</link>
      <enclosure length="1252842" type="audio/mpeg" url="https://cdn.simplecast.com/audio/abe615dc-dccb-4926-944d-3097b68aa331/episodes/85370dff-ca27-4656-83b1-a411e32612fe/audio/42064f63-3359-4364-aa34-602ed988b746/default_tc.mp3?aid=rss_feed&amp;feed=qc2rXup_"/>
      <itunes:title>Trailer: Introducing How AI Happens</itunes:title>
      <itunes:author>Sama</itunes:author>
      <itunes:duration>00:01:18</itunes:duration>
      <itunes:summary>How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field. Powered by Sama.</itunes:summary>
      <itunes:subtitle>How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field. Powered by Sama.</itunes:subtitle>
      <itunes:keywords>data science, machine learning, artificial intelligence, ai, ml</itunes:keywords>
      <itunes:explicit>false</itunes:explicit>
      <itunes:episodeType>trailer</itunes:episodeType>
    </item>
  </channel>
</rss>